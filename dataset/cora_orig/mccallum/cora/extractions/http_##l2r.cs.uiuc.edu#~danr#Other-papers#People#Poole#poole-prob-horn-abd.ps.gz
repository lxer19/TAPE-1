URL: http://l2r.cs.uiuc.edu/~danr/Other-papers/People/Poole/poole-prob-horn-abd.ps.gz
Refering-URL: http://l2r.cs.uiuc.edu/~danr/Teaching/CS491-98/491-list.html
Root-URL: http://www.cs.uiuc.edu
Email: poole@cs.ubc.ca  
Phone: telephone: (604) 822 6254 fax: (604) 822 5485  
Title: Probabilistic Horn abduction and Bayesian networks  
Author: David Poole 
Date: September 15, 1993  
Address: Vancouver, B.C., Canada V6T 1Z4  
Affiliation: Department of Computer Science, University of British Columbia,  
Abstract: This paper presents a simple framework for Horn-clause abduction, with probabilities associated with hypotheses. The framework incorporates assumptions about the rule base and independence assumptions amongst hypotheses. It is shown how any probabilistic knowledge representable in a discrete Bayesian belief network can be represented in this framework. The main contribution is in finding a relationship between logical and probabilistic notions of evidential reasoning. This provides a useful representation language in its own right, providing a compromise between heuristic and epistemic adequacy. It also shows how Bayesian networks can be extended beyond a propositional language. This paper also shows how a language with only (unconditionally) independent hypotheses can represent any probabilistic knowledge, and argues that it is better to invent new hypotheses to explain dependence rather than having to worry about dependence in the language. fl Scholar, Canadian Institute for Advanced Research.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. R. Apt and M. Bezem. </author> <title> Acyclic programs. New Generation Computing, </title> <address> 9(3-4):335-363, </address> <year> 1991. </year>
Reference-contexts: H T the hypotheses, the set of h i that appears in some disjoint declaration in T . Let H 0 T be the set of ground instances of elements of H T . P T is a function H 0 T 7! <ref> [0; 1] </ref>. P (h 0 i ) = p i where h 0 i is a ground instance of hypothesis h i , and h i : p i is in a disjoint declaration in T . <p> In this case we can replace h in H by the hypothesis h happens to be true and add the rule h h happens to be true Assumption 2.8 (acyclicity <ref> [1] </ref>) If F 0 is the set of ground instances of elements of F , it is possible to assign a natural number to every ground atom such that for every rule in F 0 the atoms in the body of the rule are strictly less than the atom in the <p> This assumption is described as natural by Apt and Bezem <ref> [1] </ref>. It is a generalisation of the hierarchical constraint of Clark [8]. It implies that there are no infinite chains when backchaining from any ground goal. This does not restrict recursion, but does mean that all recursion must be well founded. <p> do (load; S)) holds (alive; S): holds (alive; 0): holds (loaded; 0): The following formula can be proved: holds (alive; do (shoot; do (wait; do (load; 0)))): The solution that is derived from the Bayesian network representation is very similar to logic programming solutions to the frame problem (see e.g., <ref> [62, 1] </ref>) using the equivalence of our negation to negation as failure for acyclic theories [4] and, considering the completion of the program, to the recent deductive solutions to the frame problem proposed by Reiter [58] and Elkan [16]. <p> Because the mapping does not depend on the world, these form "rigid designators". Probabilistic Horn abduction and Bayesian networks 49 is a 1-1 function such that (w) maps each n-ary predicate symbol into a subset of D n . P fl is a function from H 7! <ref> [0; 1] </ref>. <p> be done for all violations of the second formula. 2 We can define a measure over the syntactic formulae as follows: Definition A.7 If W n V k i j=1 h ij is an interpretable DNF formula, h ij 2 H and P fl is a function from H 7! <ref> [0; 1] </ref>, then define the function P fl by P fl @ i=1 j=1 1 X Y P fl (h ij ) The following lemma shows that equivalent formulae will always have the same measure.
Reference: [2] <author> F. Bacchus. </author> <title> Lp, a logic for representing and reasoning with statistical knowledge. </title> <journal> Computational Intelligence, </journal> <volume> 6(4) </volume> <pages> 209-231, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Thus, we cannot just sum over the possible worlds to determine the probability of a proposition (as is done in [3]). We instead provide a measure over sentences that can be described in our language (as in <ref> [2] </ref>). As we have made sure that the logic provides no constraints on the probabilities, we only need to consider sentences made of hypotheses in order to define the probability space. As discussed in section 2.4, we make the unique names assumption. <p> The elements of hW;D;;;P fl i form a sample space <ref> [2] </ref>. Elements of hW;D;;;P fl i are closed under finite union, and complementation (given that we can complement any hypothesis by using the disjunct of the remaining hypotheses). Like Bacchus [2], we do not require sigma-additivity of our sample space. <p> The elements of hW;D;;;P fl i form a sample space <ref> [2] </ref>. Elements of hW;D;;;P fl i are closed under finite union, and complementation (given that we can complement any hypothesis by using the disjunct of the remaining hypotheses). Like Bacchus [2], we do not require sigma-additivity of our sample space. Because our language is so weak, we do not need countable unions.
Reference: [3] <author> F. Bacchus. </author> <title> Representing and Reasoning with Uncertain Knowledge. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: In a different strand of research, Bayesian networks [39], have proven to be a good representation for the sort of probabilistic independence found in many domains. While the independence of Bayesian networks has been expressed in logic (e.g., <ref> [3] </ref>), there has not been a mapping between logical specifications of knowledge and Bayesian network representations, where the logic is not at the meta-level to the probabilistic knowledge. <p> Probabilistic Horn abduction is naturally non-propositional, and provides a natural extension of Bayesian Probabilistic Horn abduction and Bayesian networks 3 networks to a non-propositional language. The work presented in this paper should be contrasted with other attempts to combine logic and probability in very powerful languages (e.g., <ref> [3] </ref>). We are trying to find the simplest language that is useful for our purposes, rather than combine many different features onto one framework. Our goal in this research is to investigate a simple yet powerful logic. <p> They can write down any independence assumptions and any conditional probability statements with the system giving no guidance as to what to write. In other work, Ng and Sub-rahmanian [36] have considered how to incorporate statistical probability <ref> [3] </ref> into logic programming. This should be seen as complementary to the work in this paper. 7 Conclusion This paper has presented a pragmatically-motivated simple logic formulation that includes definite clauses and probabilities over hypotheses. <p> Probabilistic Horn abduction and Bayesian networks 48 A Formal Semantics In this section we give the formal semantics for our language. As the language is very simple, the semantics will be correspondingly simple. The semantics will basically be that of Bacchus <ref> [3] </ref>, restricted to our language, and incorporating our assumptions. The logical statements will restrict the possible worlds, and the probabilities will provide measures over the possible worlds. The language is specially designed so that the logical facts neither implies a hypothesis nor implies the negation of a hypothesis. <p> Once we have this, the probability of each possible world will be zero. Thus, we cannot just sum over the possible worlds to determine the probability of a proposition (as is done in <ref> [3] </ref>). We instead provide a measure over sentences that can be described in our language (as in [2]). As we have made sure that the logic provides no constraints on the probabilities, we only need to consider sentences made of hypotheses in order to define the probability space.
Reference: [4] <author> R. Barbuti, P. Mancarella, D. Pedreschi, and F. Turini. </author> <title> A transformational approach to negation in logic programming. </title> <journal> Journal of Logic Programming, </journal> <volume> 8 </volume> <pages> 201-228, </pages> <year> 1990. </year>
Reference-contexts: There are however, some cases for which it is useful to create the negation of atoms (see Section 5.1). This negation is an extension to a simple form of the negation of Barbuti et. al. <ref> [4] </ref>, which is used for negation as failure. 3 Representing Bayesian networks In this section we give the relationship between Bayesian networks and our probabilistic Horn abduction. We show how any probabilistic knowledge that can be represented in a discrete (and finite) Bayesian network, can be represented in our formalism. <p> can be proved: holds (alive; do (shoot; do (wait; do (load; 0)))): The solution that is derived from the Bayesian network representation is very similar to logic programming solutions to the frame problem (see e.g., [62, 1]) using the equivalence of our negation to negation as failure for acyclic theories <ref> [4] </ref> and, considering the completion of the program, to the recent deductive solutions to the frame problem proposed by Reiter [58] and Elkan [16]. The probabilistic Horn abduction representation allows us to consistently add probability to the temporal representations.
Reference: [5] <author> J. S. Breese. </author> <title> Construction of belief and decision networks. </title> <type> Technical Memorandum 30, </type> <institution> Rockwell Palo Alto Lab, Palo Alto, Cal., </institution> <year> 1989. </year>
Reference-contexts: In the uncertainty community there has also been a need to extend Bayesian networks to beyond a propositional language <ref> [5, 6, 22] </ref>. Probabilistic Horn abduction is naturally non-propositional, and provides a natural extension of Bayesian Probabilistic Horn abduction and Bayesian networks 3 networks to a non-propositional language. <p> The label of [63] plays an analogous role to our hypotheses. They however, do not use their system for computing posterior probabilities. It is also not so obvious how to extend their formalism to more powerful logics. Horsch and Poole [22], Breese <ref> [5] </ref> have defined systems that incorporate Probabilistic Horn abduction and Bayesian networks 46 Prolog style rules and Bayesian networks. These were designed to allow for dynamic construction of Bayesian networks. The rules of [22] cannot be interpreted logically but are macros that map into Bayesian network structure. <p> These were designed to allow for dynamic construction of Bayesian networks. The rules of [22] cannot be interpreted logically but are macros that map into Bayesian network structure. The rules of Breese <ref> [5] </ref> are Prolog-style rules that are used to build a network. The output of the Prolog is a Bayesian network (or more generally is an influence diagram) that can be passed to a Bayesian network solver. Ours differs in that the Prolog like rules form the Bayesian network themselves.
Reference: [6] <author> E. Charniak and R. Goldman. </author> <title> A semantics for probabilistic quantifier-free first-order languages, with particular application to story understanding. </title> <booktitle> In Proc. 11th International Joint Conf. on Artificial Intelligence, </booktitle> <pages> pages 1074-1079, </pages> <address> Detroit, Mich., </address> <month> August </month> <year> 1989. </year>
Reference-contexts: In the uncertainty community there has also been a need to extend Bayesian networks to beyond a propositional language <ref> [5, 6, 22] </ref>. Probabilistic Horn abduction is naturally non-propositional, and provides a natural extension of Bayesian Probabilistic Horn abduction and Bayesian networks 3 networks to a non-propositional language.
Reference: [7] <author> E. Charniak and S. E. Shimony. </author> <title> Probabilistic semantics for cost based abduction. </title> <booktitle> In Proc. 8th National Conference on Artificial Intelligence, </booktitle> <pages> pages 106-111, </pages> <address> Boston, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: Hobbs et. al. [21] have devised a "cost-based abduction" for interpretation of natural language. Their scheme is similar to the one presented here, but they use costs associated with assumptions rather than probabilities. These costs can be seen as -log probabilities <ref> [7] </ref>. One can view the current work as extending Hobbs et. al.'s to derive posterior probabilities in a consistent manner. 6.3 Logic and Bayesian networks The representation of Bayesian networks is related to the work by Charniak and Shimony [7, 63]. <p> These costs can be seen as -log probabilities [7]. One can view the current work as extending Hobbs et. al.'s to derive posterior probabilities in a consistent manner. 6.3 Logic and Bayesian networks The representation of Bayesian networks is related to the work by Charniak and Shimony <ref> [7, 63] </ref>. Instead of considering abduction, they consider models that consist of an assignment of values to each random variable. The label of [63] plays an analogous role to our hypotheses. They however, do not use their system for computing posterior probabilities.
Reference: [8] <author> K. L. Clark. </author> <title> Negation as failure. </title> <editor> In H. Gallaire and J. Minker, editors, </editor> <booktitle> Logic and Databases, </booktitle> <pages> pages 293-322. </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1978. </year> <title> Probabilistic Horn abduction and Bayesian networks 56 </title>
Reference-contexts: This assumption is described as natural by Apt and Bezem [1]. It is a generalisation of the hierarchical constraint of Clark <ref> [8] </ref>. It implies that there are no infinite chains when backchaining from any ground goal. This does not restrict recursion, but does mean that all recursion must be well founded. <p> Probabilistic Horn abduction and Bayesian networks 10 if a is true, one of the B i is true. The completion of a is a B 1 _ _ B n Thus the covering assumption 2.9 says that Clark's completion <ref> [8] </ref> is valid for every non-assumable. <p> Under assumptions 2.7, 2.8 and 2.9, if expl (g; T ) is the set of all minimal explanations of g from hF T ; H T i, and comp (T ) is F 0 T augmented with the completion of every ground instance of every non-assumable (including Clark's equational theory <ref> [8] </ref>), then comp (T ) j= 0 _ e i 2expl (g;T ) e i A The next assumption has to do with the status of explanations Assumption 2.11 The bodies of the rules in F 0 for an atom are mutually exclusive.
Reference: [9] <author> L. Console, D. Theseider Dupre, and P. Torasso. </author> <title> On the relationship between abduction and deduction. </title> <journal> Journal of Logic and Computation, </journal> <volume> 1(5) </volume> <pages> 661-690, </pages> <year> 1991. </year>
Reference-contexts: It implies that there are no infinite chains when backchaining from any ground goal. This does not restrict recursion, but does mean that all recursion must be well founded. These assumptions are made implicitly in [43], are explicit in <ref> [9] </ref> (who make the hierarchical constraint rather than the acyclic constraint), but are relaxed in [24]. When using abduction we often assume that the explanations are covering. <p> This can be a valid assumption if we have anticipated all eventualities, and the observations are within the domain of the expected observations (usually if this assumption is violated there are no explanations). This is also supported by recent attempts at a completion semantics for abduction <ref> [43, 9, 24] </ref>. The results show how abduction can be considered as deduction on the "closure" of the knowledge base that includes statements that the given causes are the only causes. <p> If the rules for a are not covering, we create a new hypothesis a is true f or some other reason and add the rule a a is true f or some other reason: Lemma 2.10 <ref> [9] </ref> Under assumptions 2.7, 2.8 and 2.9, if expl (g; T ) is the set of all minimal explanations of g from hF T ; H T i, and comp (T ) is F 0 T augmented with the completion of every ground instance of every non-assumable (including Clark's equational theory
Reference: [10] <author> P. T. Cox and T. Pietrzykowski. </author> <title> General diagnosis by abductive inference. </title> <type> Technical Report CS8701, </type> <institution> Computer Science, Technical University of Nove Scotia, Halifax, </institution> <month> April </month> <year> 1987. </year>
Reference-contexts: We thus only compare the representation to other proposals, and not any implementations. 6.1 Other logic-based abductive schemes There are many other proposals for logic-based abduction schemes (e.g., <ref> [53, 10, 18] </ref>). These however consider that we have to find all of the diagnoses. In practice there are prohibitively many of these.
Reference: [11] <author> J. de Kleer. </author> <title> An assumption-based TMS. </title> <journal> Artificial Intelligence, </journal> <volume> 28(2) </volume> <pages> 127-162, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: We assume that the Horn clauses are representing the object level knowledge, rather than, as in an ATMS, acting as a back end of a problem solver <ref> [11] </ref>. Probabilistic Horn abduction and Bayesian networks 9 This does not seem to be a very severe restriction, in practice. It says that we do not want rules to imply a hypothesis.
Reference: [12] <author> J. de Kleer, A. K. Mackworth, and R. Reiter. </author> <title> Characterizing diagnoses. </title> <booktitle> In Proc. 8th National Conference on Artificial Intelligence, </booktitle> <pages> pages 324-330, </pages> <address> Boston, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: It can be motivated in a number of different ways: Determining what is in a system from observations (diagnosis and recognition) is an important part of AI. There have been many logic-based proposals as to what is a diagnosis <ref> [17, 57, 13, 45, 12] </ref>. One problem with all of these proposals is that for any diagnostic problem of a reasonable size there are far too many logical possibilities to handle. <p> This is the same as the diagnoses of Peng and Reggia Probabilistic Horn abduction and Bayesian networks 45 [40] and the composite beliefs of Pearl [37], but is different from the diagnoses of de Kleer, Mackworth and Reiter <ref> [12] </ref>. We find the probabilities of explanations; we remain agnostic about the value of "irrelevant" hypotheses. de Kleer and Williams cannot distinguish between diagnoses that differ in substantial ways from those that differ only in varying values that are irrelevant to the diagnosis.
Reference: [13] <author> J. de Kleer and B. C. Williams. </author> <title> Diagnosing multiple faults. </title> <journal> Artificial Intelligence, </journal> <volume> 32(1) </volume> <pages> 97-130, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: It can be motivated in a number of different ways: Determining what is in a system from observations (diagnosis and recognition) is an important part of AI. There have been many logic-based proposals as to what is a diagnosis <ref> [17, 57, 13, 45, 12] </ref>. One problem with all of these proposals is that for any diagnostic problem of a reasonable size there are far too many logical possibilities to handle. <p> Analysis of the combinatorial explosions would however tend to suggest that we need to take into account probabilities of the diagnoses <ref> [13, 40, 34] </ref>, and not even generate the unlikely diagnoses (i.e., those with a low posterior probability). In a different strand of research, Bayesian networks [39], have proven to be a good representation for the sort of probabilistic independence found in many domains. <p> Essentially we have added probabilities to that scheme under certain assumptions about the knowledge base and independence. 6.2 Probability and diagnosis de Kleer and Williams <ref> [13, 14] </ref> and Peng and Reggia [40] both incorporate probabilistic knowledge to find the most likely diagnoses, but do not provide as flexible and simple a representation language as the one here. de Kleer and Williams [13, 14] have explored the idea of using probabilistic information in consistency-based diagnosis (see [43, <p> about the knowledge base and independence. 6.2 Probability and diagnosis de Kleer and Williams <ref> [13, 14] </ref> and Peng and Reggia [40] both incorporate probabilistic knowledge to find the most likely diagnoses, but do not provide as flexible and simple a representation language as the one here. de Kleer and Williams [13, 14] have explored the idea of using probabilistic information in consistency-based diagnosis (see [43, 45] for comparisons between abductive and consistency-based diagnoses).
Reference: [14] <author> J. de Kleer and B. C. Williams. </author> <title> Diagnosis with behavioral modes. </title> <booktitle> In Proc. 11th International Joint Conf. on Artificial Intelligence, </booktitle> <pages> pages 1324-1330, </pages> <address> Detroit, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: There have been many logic-based proposals as to what is a diagnosis [17, 57, 13, 45, 12]. One problem with all of these proposals is that for any diagnostic problem of a reasonable size there are far too many logical possibilities to handle. For example, when considering fault models <ref> [14, 45] </ref>, there is almost always an exponential number of logical possibilities (e.g., each component could be in one of its normal states or in the unknown state). For practical problems, many of the logically possible diagnoses are so unlikely that it is not worth considering them. <p> The example is based on the three cascaded inverters of <ref> [14] </ref>. Figure 1 shows the connections of the inverters. The language is an extension of pure Prolog. <p> If we want our probabilities to be correct, we must ensure that the rules for an atom are disjoint and covering. If the rules for an atom a are not covering, we can invent another cause for the goal representing "all the other possible causes" of the atom <ref> [14, 45] </ref>, and add a a true for some other reason. and make a true for some other reason into a hypothesis. Although disjointedness of rules places a restriction on the knowledge base, it does not place a restriction on the sorts of knowledge that we can represent. <p> Suppose we want to represent the gate being in an unknown state 7 (this is applicable whether or not we have fault models <ref> [14, 45] </ref>). Suppose we represent the proposition that gate G has output V at time T as val (G; V; T ). <p> Essentially we have added probabilities to that scheme under certain assumptions about the knowledge base and independence. 6.2 Probability and diagnosis de Kleer and Williams <ref> [13, 14] </ref> and Peng and Reggia [40] both incorporate probabilistic knowledge to find the most likely diagnoses, but do not provide as flexible and simple a representation language as the one here. de Kleer and Williams [13, 14] have explored the idea of using probabilistic information in consistency-based diagnosis (see [43, <p> about the knowledge base and independence. 6.2 Probability and diagnosis de Kleer and Williams <ref> [13, 14] </ref> and Peng and Reggia [40] both incorporate probabilistic knowledge to find the most likely diagnoses, but do not provide as flexible and simple a representation language as the one here. de Kleer and Williams [13, 14] have explored the idea of using probabilistic information in consistency-based diagnosis (see [43, 45] for comparisons between abductive and consistency-based diagnoses).
Reference: [15] <author> J. Doyle. </author> <title> Methodological simplicity in expert system construction: the case for judgements and reasoned assumptions. </title> <journal> The AI Magazine, </journal> <pages> pages 39-43, </pages> <month> Summer </month> <year> 1983. </year>
Reference-contexts: Dempster-Shafer theory assumes that different rules are independent. We assume they are exclusive. Another difference is that these embeddings do not do evidential reasoning (by doing abduction), determining probability of hypotheses given evidence, but rather only determine the "belief" of propositions from forward chaining. 6.5 Argument systems Doyle <ref> [15] </ref> and Loui [32] have argued that decisions can be best seen in terms of arguments for and against some propositions. Other have viewed nonmonotonic reasoning in terms of arguments [42, 29, 31, 41]. The explanations that we use can be seen as premises for logical arguments.
Reference: [16] <author> C. Elkan. </author> <title> Reasoning about action in first-order logic. </title> <booktitle> In Proc. 9th Can. Soc. Computational Studies of Intelligence Conf., </booktitle> <pages> pages 221-227, </pages> <address> Vancouver, B.C., </address> <month> May </month> <year> 1992. </year>
Reference-contexts: very similar to logic programming solutions to the frame problem (see e.g., [62, 1]) using the equivalence of our negation to negation as failure for acyclic theories [4] and, considering the completion of the program, to the recent deductive solutions to the frame problem proposed by Reiter [58] and Elkan <ref> [16] </ref>. The probabilistic Horn abduction representation allows us to consistently add probability to the temporal representations.
Reference: [17] <author> M. R. Genesereth. </author> <title> The use of design descriptions in automated diagnosis. </title> <journal> Artificial Intelligence, </journal> <volume> 24(1-3):411-436, </volume> <month> December </month> <year> 1984. </year>
Reference-contexts: It can be motivated in a number of different ways: Determining what is in a system from observations (diagnosis and recognition) is an important part of AI. There have been many logic-based proposals as to what is a diagnosis <ref> [17, 57, 13, 45, 12] </ref>. One problem with all of these proposals is that for any diagnostic problem of a reasonable size there are far too many logical possibilities to handle. <p> Example 5.2 This first example is an implementation of cascaded one bit adders (Figures 4 and 5), to form a ripple adder. The axiomatisation is adapted from the consistency-based axiomatisation of Genesereth <ref> [17] </ref>. Probabilistic Horn abduction and Bayesian networks 35 val (P; V; T ) means that port P has value V at time T . We use as simple a representation of time as is needed.
Reference: [18] <author> R. Goebel, K. Furukawa, and D. Poole. </author> <title> Using definite clauses and integrity constraints as the basis for a theory formation approach to diagnostic reasoning. </title> <editor> In E. Shapiro, editor, </editor> <booktitle> Proc. Third International Conference on Logic Programming, </booktitle> <pages> pages 211-222, </pages> <address> London, </address> <month> July </month> <year> 1986. </year>
Reference-contexts: In Appendix A, we give Probabilistic Horn abduction and Bayesian networks 8 a model theoretic characterisation that incorporates our assumptions, and show the equivalence of the formulations. The formulation of abduction used is a simplified form <ref> [18] </ref> of Theorist [51, 43]. It is simplified in being restricted to Horn clauses. This can also be seen as a generalisation of an ATMS (with predefined nogoods) [59] to be non-propositional 1 . An abductive scheme is a pair hF; Hi where F is a set of Horn clauses. <p> We thus only compare the representation to other proposals, and not any implementations. 6.1 Other logic-based abductive schemes There are many other proposals for logic-based abduction schemes (e.g., <ref> [53, 10, 18] </ref>). These however consider that we have to find all of the diagnoses. In practice there are prohibitively many of these. <p> We provide an answer to the problem of what to do with the explanations: we use them to compute posterior probabilities that can be used for making decisions. The closest version of abduction to that presented here is that of Goebel et. al. <ref> [18] </ref>, where there is also the simple abductive scheme where we do not need to do any chaining in order to determine inconsistency.
Reference: [19] <author> S. Hanks and D. V. McDermott. </author> <title> Nonmonotonic logic and temporal projection. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 379-412, </pages> <year> 1987. </year> <title> Probabilistic Horn abduction and Bayesian networks 57 </title>
Reference-contexts: This is the problem that occurs, for example, in the Yale shooting problem <ref> [19] </ref>.
Reference: [20] <author> M. Henrion. </author> <title> An introduction to algorithms for inference in belief nets. </title> <editor> In M. Henrion, et al., editor, </editor> <booktitle> Uncertainty in Artificial Intelligence 5, </booktitle> <pages> pages 129-138. </pages> <publisher> North Holland, </publisher> <year> 1990. </year>
Reference-contexts: Probabilistic Horn abduction and Bayesian networks 44 to compute posterior probabilities. There are many ways that could be used to compute posterior probabilities, we could use some form of stochastic simulation (e.g., <ref> [20] </ref>), search (e.g., [49, 50]), or even using the mapping to Bayesian networks to translate ground instances of the theory into some secondary structure for propagating evidence (e.g., [27, 23]).
Reference: [21] <author> J. R. Hobbs, M. E. Stickel, P. Martin, and D. Edwards. </author> <title> Interpretation as abduction. </title> <booktitle> In Proc. 26th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 95-103, </pages> <address> Buffalo, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: One way to look at what they are doing is to consider it as a restriction of the system presented here where the language is propositional and allows only one element in the body of a clause. It is, however, not expressed in a logical language. Hobbs et. al. <ref> [21] </ref> have devised a "cost-based abduction" for interpretation of natural language. Their scheme is similar to the one presented here, but they use costs associated with assumptions rather than probabilities. These costs can be seen as -log probabilities [7].
Reference: [22] <author> M. Horsch and D. Poole. </author> <title> A dynamic approach to probabilistic inference using Bayesian networks. </title> <booktitle> In Proc. Sixth Conference on Uncertainty in AI, </booktitle> <pages> pages 155-161, </pages> <address> Boston, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: In the uncertainty community there has also been a need to extend Bayesian networks to beyond a propositional language <ref> [5, 6, 22] </ref>. Probabilistic Horn abduction is naturally non-propositional, and provides a natural extension of Bayesian Probabilistic Horn abduction and Bayesian networks 3 networks to a non-propositional language. <p> We can use these explanations to compute arbitrary conditional probabilities. For example, P (linear ((c2); river)jimage) = 9:8438 fi 10 12 + 7:875 fi 10 13 5.4 Arbitrary Individuals One of the problems considered in <ref> [22] </ref>, is that of when there can be arbitrary individuals that affect a value, and the individuals present can only be determined at run time. <p> The label of [63] plays an analogous role to our hypotheses. They however, do not use their system for computing posterior probabilities. It is also not so obvious how to extend their formalism to more powerful logics. Horsch and Poole <ref> [22] </ref>, Breese [5] have defined systems that incorporate Probabilistic Horn abduction and Bayesian networks 46 Prolog style rules and Bayesian networks. These were designed to allow for dynamic construction of Bayesian networks. The rules of [22] cannot be interpreted logically but are macros that map into Bayesian network structure. <p> Horsch and Poole <ref> [22] </ref>, Breese [5] have defined systems that incorporate Probabilistic Horn abduction and Bayesian networks 46 Prolog style rules and Bayesian networks. These were designed to allow for dynamic construction of Bayesian networks. The rules of [22] cannot be interpreted logically but are macros that map into Bayesian network structure. The rules of Breese [5] are Prolog-style rules that are used to build a network.
Reference: [23] <author> F. V. Jensen, S. L. Lauritzen, and K. G. Olesen. </author> <title> Bayesian updating in causal probabilistic networks by local computations. </title> <journal> Computational Statistics Quaterly, </journal> <volume> 4 </volume> <pages> 269-282, </pages> <year> 1990. </year>
Reference-contexts: There are many ways that could be used to compute posterior probabilities, we could use some form of stochastic simulation (e.g., [20]), search (e.g., [49, 50]), or even using the mapping to Bayesian networks to translate ground instances of the theory into some secondary structure for propagating evidence (e.g., <ref> [27, 23] </ref>). We thus only compare the representation to other proposals, and not any implementations. 6.1 Other logic-based abductive schemes There are many other proposals for logic-based abduction schemes (e.g., [53, 10, 18]). These however consider that we have to find all of the diagnoses.
Reference: [24] <author> K. Konolige. </author> <title> Abduction versus closure in causal theories. </title> <journal> Artificial Intelligence, </journal> <volume> 53(2-3):255-272, </volume> <month> February </month> <year> 1992. </year>
Reference-contexts: This does not restrict recursion, but does mean that all recursion must be well founded. These assumptions are made implicitly in [43], are explicit in [9] (who make the hierarchical constraint rather than the acyclic constraint), but are relaxed in <ref> [24] </ref>. When using abduction we often assume that the explanations are covering. This can be a valid assumption if we have anticipated all eventualities, and the observations are within the domain of the expected observations (usually if this assumption is violated there are no explanations). <p> This can be a valid assumption if we have anticipated all eventualities, and the observations are within the domain of the expected observations (usually if this assumption is violated there are no explanations). This is also supported by recent attempts at a completion semantics for abduction <ref> [43, 9, 24] </ref>. The results show how abduction can be considered as deduction on the "closure" of the knowledge base that includes statements that the given causes are the only causes.
Reference: [25] <author> R. Kowalski. </author> <title> Logic for Problem Solving. </title> <booktitle> Artificial Intelligence Series. </booktitle> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: P (h 0 i ) will be the prior probability of h 0 i . Where T is understood from context, we omit the subscript. The disjoint declarations allow a very restricted form of integrity constraints <ref> [25] </ref>. It allow binary integrity constraints (the conjunction of two hypotheses is false) such that the ground instances of hypotheses form mutually exclusive and covering groupings that correspond to random variables. A theory will define a set of represented atoms that are a subset of the atoms of T .
Reference: [26] <author> K. B. Laskey and P. E. Lehner. </author> <title> Assumptions, beliefs and probabilities. </title> <journal> Artificial Intelligence, </journal> <volume> 41(1) </volume> <pages> 65-77, </pages> <year> 1989. </year>
Reference-contexts: We would need another, meta-level, program to transform our Prolog rules into Bayesian networks for a traditional Bayesian network interpreter to solve. 6.4 Horn abduction and Dempster-Shafer This work is also closely related to recent embeddings of Dempster-Shafer theory in ATMS <ref> [26, 54] </ref>. One difference between our embedding of Bayesian networks and Dempster-Shafer is in the independence assumptions used. Dempster-Shafer theory assumes that different rules are independent. We assume they are exclusive.
Reference: [27] <author> S. L. Lauritzen and D. J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> Journal of the Royal Statistical Society, Series B, </journal> <volume> 50(2) </volume> <pages> 157-224, </pages> <year> 1988. </year>
Reference-contexts: There are many ways that could be used to compute posterior probabilities, we could use some form of stochastic simulation (e.g., [20]), search (e.g., [49, 50]), or even using the mapping to Bayesian networks to translate ground instances of the theory into some secondary structure for propagating evidence (e.g., <ref> [27, 23] </ref>). We thus only compare the representation to other proposals, and not any implementations. 6.1 Other logic-based abductive schemes There are many other proposals for logic-based abduction schemes (e.g., [53, 10, 18]). These however consider that we have to find all of the diagnoses.
Reference: [28] <author> R. S. Ledley and L. B. Lusted. </author> <title> Reasoning foundations of medical diagnosis. </title> <journal> Science, </journal> <volume> 130(3366) </volume> <pages> 9-21, </pages> <month> July </month> <year> 1959. </year>
Reference-contexts: not clear what to do with all of the explanations; there are too many to give to a user, and the costs of tests to determine which of the diagnoses is the "real" diagnosis is usually not outweighed by the advantages of finding the real diagnosis (see Ledley and Lusted <ref> [28] </ref> for an early description of the importance of probabilistic and value information in diagnosis). We provide an answer to the problem of what to do with the explanations: we use them to compute posterior probabilities that can be used for making decisions.
Reference: [29] <author> F. Lin and Y. Shoham. </author> <title> Argument systems: a uniform basis for non-monotonic reasoning. </title> <booktitle> In Proc. First International Conf. on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 245-255, </pages> <address> Toronto, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: Other have viewed nonmonotonic reasoning in terms of arguments <ref> [42, 29, 31, 41] </ref>. The explanations that we use can be seen as premises for logical arguments. We determine the probability of some proposition by coming up with arguments for the proposition.
Reference: [30] <author> J. W. Lloyd. </author> <booktitle> Foundations of Logic Programming. Symbolic Computation Series. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <note> second edition, </note> <year> 1987. </year> <title> Probabilistic Horn abduction and Bayesian networks 58 </title>
Reference-contexts: 1 Introduction Probabilistic Horn Abduction [48, 47] is a framework for logic-based abduction that incorporates probabilities with assumptions. This is being used as a framework for diagnosis [48] that incorporates both pure Prolog <ref> [30] </ref> and Bayesian Networks [39] as special cases. This paper expands on [48, 47] and develops the formal underpinnings of probabilistic Horn abduction, shows the strong relationships to other formalisms and argues that it is a good representation language in its own right. <p> As discussed in section 2.4, we make the unique names assumption. This is specified formally by making the domain we consider be the set of ground terms in the language (similar the Herbrand Universe <ref> [30] </ref>). Definition A.1 A semantic structure is a tuple hW; D; ; ; P fl i, where W is a non-empty set. Elements of W are called possible worlds. D is a non-empty set (of individuals).
Reference: [31] <author> R. P. Loui. </author> <title> Defeat among arguments: a system for defeasible inference. </title> <journal> Computational Intelligence, </journal> <volume> 3(2) </volume> <pages> 100-106, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: Other have viewed nonmonotonic reasoning in terms of arguments <ref> [42, 29, 31, 41] </ref>. The explanations that we use can be seen as premises for logical arguments. We determine the probability of some proposition by coming up with arguments for the proposition.
Reference: [32] <author> R. P. Loui. </author> <title> Defeasible decisions: what the proposal is and isn't. </title> <editor> In M. Henrion et al., editor, </editor> <booktitle> Uncertainty in Artificial Intelligence 5, </booktitle> <pages> pages 99-116. </pages> <publisher> North Holland, </publisher> <year> 1990. </year>
Reference-contexts: We assume they are exclusive. Another difference is that these embeddings do not do evidential reasoning (by doing abduction), determining probability of hypotheses given evidence, but rather only determine the "belief" of propositions from forward chaining. 6.5 Argument systems Doyle [15] and Loui <ref> [32] </ref> have argued that decisions can be best seen in terms of arguments for and against some propositions. Other have viewed nonmonotonic reasoning in terms of arguments [42, 29, 31, 41]. The explanations that we use can be seen as premises for logical arguments.
Reference: [33] <author> J. McCarthy and P. J. Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <editor> In M. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence 4, </booktitle> <pages> pages 463-502. </pages> <publisher> Edinburgh University Press, </publisher> <year> 1969. </year>
Reference-contexts: Our goal in this research is to investigate a simple yet powerful logic. The representation proposed in this paper is interesting in its own right as a compromise between epistemic and heuristic adequacy <ref> [33] </ref>. It extends pure Prolog in a simple way to include probabilities. While all of the hypotheses are independent, by inventing new hypotheses, we can represent any probabilistic dependency. This simplicity allows us to experiment with a minimalist representation and only extend it when we need to.
Reference: [34] <author> E. M. Neufeld and D. Poole. </author> <title> Towards solving the multiple extension problem: combining defaults and probabilities. </title> <booktitle> In Proc. Third Workshop on Reasoning with Uncertainty, </booktitle> <pages> pages 305-312, </pages> <address> Seattle, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: Analysis of the combinatorial explosions would however tend to suggest that we need to take into account probabilities of the diagnoses <ref> [13, 40, 34] </ref>, and not even generate the unlikely diagnoses (i.e., those with a low posterior probability). In a different strand of research, Bayesian networks [39], have proven to be a good representation for the sort of probabilistic independence found in many domains.
Reference: [35] <author> R. T. Ng and V. S. Subrahmanian. </author> <title> Non-monotonic negation in probabilistic deductive databases. </title> <booktitle> In Proc. Seventh Conf. on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 249-256, </pages> <address> Los Angeles, </address> <institution> Cal., </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: These have typically not considered probability, but other uncer Probabilistic Horn abduction and Bayesian networks 47 tainty calculi such as certainty factors [65]. Ng and Subrahmanian <ref> [35] </ref> have combined logic programming and probability by allowing us to axiomatise probability in logic, and then use Prolog-style rules to give the probabilistic information. The Prolog rules reason about the probability, at much more of a meta-level than that proposed here.
Reference: [36] <author> R. T. Ng and V. S. Subrahmanian. </author> <title> Empirical probabilities in monadic deductive databases. </title> <booktitle> In Proc. Eighth Conf. on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 215-222, </pages> <institution> Stanford, Cal., </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: The Prolog rules reason about the probability, at much more of a meta-level than that proposed here. They can write down any independence assumptions and any conditional probability statements with the system giving no guidance as to what to write. In other work, Ng and Sub-rahmanian <ref> [36] </ref> have considered how to incorporate statistical probability [3] into logic programming. This should be seen as complementary to the work in this paper. 7 Conclusion This paper has presented a pragmatically-motivated simple logic formulation that includes definite clauses and probabilities over hypotheses.
Reference: [37] <author> J. Pearl. </author> <title> Distributed revision of composite beliefs. </title> <journal> Artificial Intelligence, </journal> <volume> 33(2) </volume> <pages> 173-215, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: This is the same as the diagnoses of Peng and Reggia Probabilistic Horn abduction and Bayesian networks 45 [40] and the composite beliefs of Pearl <ref> [37] </ref>, but is different from the diagnoses of de Kleer, Mackworth and Reiter [12].
Reference: [38] <author> J. Pearl. </author> <title> Embracing causation in default reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 35(2) </volume> <pages> 259-271, </pages> <year> 1988. </year>
Reference-contexts: It is not clear, however, how far this analogy can be pushed. Probabilistic Horn abduction and Bayesian networks 25 4.3 Causation There have been problems associated with logical formulations of causation <ref> [38] </ref>. There have been claims that Bayesian networks provide the right independencies for causation [39].
Reference: [39] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: 1 Introduction Probabilistic Horn Abduction [48, 47] is a framework for logic-based abduction that incorporates probabilities with assumptions. This is being used as a framework for diagnosis [48] that incorporates both pure Prolog [30] and Bayesian Networks <ref> [39] </ref> as special cases. This paper expands on [48, 47] and develops the formal underpinnings of probabilistic Horn abduction, shows the strong relationships to other formalisms and argues that it is a good representation language in its own right. <p> Analysis of the combinatorial explosions would however tend to suggest that we need to take into account probabilities of the diagnoses [13, 40, 34], and not even generate the unlikely diagnoses (i.e., those with a low posterior probability). In a different strand of research, Bayesian networks <ref> [39] </ref>, have proven to be a good representation for the sort of probabilistic independence found in many domains. <p> t 1 = t 2 , then h (t 1 ) ^ h (t 2 ) h (t 1 ), but P (h (t 1 )) = p, a contradiction to the fact that probabilities are a measure over propositions, and that logically equivalent terms should have the same probability <ref> [39] </ref>. Thus, we are assuming that t 1 6= t 2 for different terms t 1 and t 2 . This assumption is the unique names assumption [56]. Note that it is for the probabilistic calculation that we are making the unique names assumption. <p> We show how any probabilistic knowledge that can be represented in a discrete (and finite) Bayesian network, can be represented in our formalism. We also demonstrate the alternate, namely that any propositional probabilistic Horn abduction theory is equivalent to a Bayesian network. A Bayesian network <ref> [39] </ref> is a directed acyclic network where the nodes represent random variables, and the arcs represent a directly influencing relation. We will use the term "RV" to mean random variable so as to avoid confusion with the Prolog-style variable. <p> We represent random variable a i having value v i;j as the proposition a i (v i;j ). Suppose RV a i has parents a i = fa i 1 ; ; a i n i g in a Bayesian network. The independence assumption embedded in a Bayesian Network <ref> [39] </ref> is that a RV is independent of its non-descendents given its parents. <p> There is another close similarity between the abductive approaches and the network propagation scheme of Pearl <ref> [39] </ref>. Finding the explanations of some g conceptually corresponds to working "up" the Bayesian network from g. Given evidence fi, we first find expl (fi; T ). This conceptually involves searching up (finding ancestors) the tree from fi. The next step involves finding expl (ff ^ fi; T ). <p> This 2-phase approach is analogous to Pearl's network propagation scheme, with the initial moving up the tree corresponding to messages, and the second phase of moving down the tree from the explanations corresponds to the messages of Pearl <ref> [39] </ref>. <p> It is not clear, however, how far this analogy can be pushed. Probabilistic Horn abduction and Bayesian networks 25 4.3 Causation There have been problems associated with logical formulations of causation [38]. There have been claims that Bayesian networks provide the right independencies for causation <ref> [39] </ref>. This paper provides evidence that abducing to causes and making assumptions as to what to predict from those assumptions [44, 46] is the right logical analogue of the independence in Bayesian networks (as described in section 4.2). One of the problems in causal reasoning that Bayesian networks overcome [39] is <p> causation <ref> [39] </ref>. This paper provides evidence that abducing to causes and making assumptions as to what to predict from those assumptions [44, 46] is the right logical analogue of the independence in Bayesian networks (as described in section 4.2). One of the problems in causal reasoning that Bayesian networks overcome [39] is in preventing reasoning such as "if c 1 is a cause for a and c 2 is a cause for :a, then from c 1 we can infer :c 2 ". This is the problem that occurs, for example, in the Yale shooting problem [19]. <p> Bayesian networks as c 1 and c 2 must already be known to be disjoint. holds (alive,do (shoot,do (wait,do (load,0)))) holds (alive,do (wait,do (load,0))) holds (loaded,do (wait,do (load,0))) holds (alive,do (load,0)) holds (loaded,do (load,0)) holds (alive,0) The following is translation of the above diagram into a probabilistic Horn 5 Pearl <ref> [39] </ref> has a similar graphical representation, although it was not explicitly a Bayesian network. Here we have used a situation calculus type representation. <p> This has repercussions in biasing the most likely explanation to the first rule, which is more general than the others. This problem of the most likely diagnosis depending on the representation seems endemic to approaches that try to find the diagnosis (either explanation or interpretation) that is "most likely" <ref> [39, 52] </ref>. We avoid this problem by not placing importance in the most likely explanations, but only in how they contribute to the probability of propositions. 5.2 Causation Events When representing knowledge for abduction [45, 46], we have to be able to make sure that we can imply the observations.
Reference: [40] <author> Y. Peng and J. A. Reggia. </author> <title> Abductive Inference Models for Diagnostic Problem-Solving. Symbolic Computation - AI Series. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: Analysis of the combinatorial explosions would however tend to suggest that we need to take into account probabilities of the diagnoses <ref> [13, 40, 34] </ref>, and not even generate the unlikely diagnoses (i.e., those with a low posterior probability). In a different strand of research, Bayesian networks [39], have proven to be a good representation for the sort of probabilistic independence found in many domains. <p> To solve this problem we introduce another hypothesis that the cold caused the sneezing. In the other example, we have to hypothesise that the gate is producing a particular value. This idea is analogous to the notion of a "causation event" of Peng and Reggia <ref> [40] </ref>. The cold causing sneezing could be written as sneeze cold ^ cold caused sneeze Probabilistic Horn abduction and Bayesian networks 30 Following Peng and Reggia [40], one way to implement the causation events, is to use the relations has disease (D) to mean that the patient has disease D; actually <p> This idea is analogous to the notion of a "causation event" of Peng and Reggia <ref> [40] </ref>. The cold causing sneezing could be written as sneeze cold ^ cold caused sneeze Probabilistic Horn abduction and Bayesian networks 30 Following Peng and Reggia [40], one way to implement the causation events, is to use the relations has disease (D) to mean that the patient has disease D; actually causes (D; M ) to mean that disease D "actually caused" manifestation M ; and has manif estation (M ) to mean that the patient has <p> We can say that a manifestation is caused by the disease that actually causes it by: has manif estation (M ) has disease (D) ^actually causes (D; M ): The conjunction has disease (D) ^ actually causes (D; M ) corresponds to Peng and Reggia's <ref> [40] </ref> causation event M : D. <p> We have the disjoint declarations for each i; j: disjoint ([actually causes (d i ; m j ) : p ij ; didnt actually cause (d i ; m j ) : q ij ]) where p ij corresponds to the the "conditional causal probability" ("causal strength") of <ref> [40] </ref>, and q ij = 1 p ij . p ij can be seen as the fraction of the cases where d i is true that d i "actually causes" m j . <p> Essentially we have added probabilities to that scheme under certain assumptions about the knowledge base and independence. 6.2 Probability and diagnosis de Kleer and Williams [13, 14] and Peng and Reggia <ref> [40] </ref> both incorporate probabilistic knowledge to find the most likely diagnoses, but do not provide as flexible and simple a representation language as the one here. de Kleer and Williams [13, 14] have explored the idea of using probabilistic information in consistency-based diagnosis (see [43, 45] for comparisons between abductive and <p> This is the same as the diagnoses of Peng and Reggia Probabilistic Horn abduction and Bayesian networks 45 <ref> [40] </ref> and the composite beliefs of Pearl [37], but is different from the diagnoses of de Kleer, Mackworth and Reiter [12]. <p> We do not place such an importance on the explanations, but rather on using the explanations to compute probabilities (see [52] for some of the issues involved in considering what we want to compute the probability of). Peng and Reggia <ref> [40] </ref> also consider an abductive definition of diagnosis and incorporate probabilities, and best-first search. One difference is that they are trying to find probabilities of interpretations, but we are using explanations to find the probabilities of atoms. The main difference is in the underlying language.
Reference: [41] <author> J. L. Pollock. </author> <title> Defeasible reasoning. </title> <journal> Cognitive Science, </journal> <volume> 11 </volume> <pages> 481-518, </pages> <year> 1987. </year>
Reference-contexts: Other have viewed nonmonotonic reasoning in terms of arguments <ref> [42, 29, 31, 41] </ref>. The explanations that we use can be seen as premises for logical arguments. We determine the probability of some proposition by coming up with arguments for the proposition.
Reference: [42] <author> D. Poole. </author> <title> A logical framework for default reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 36(1) </volume> <pages> 27-47, </pages> <year> 1988. </year> <title> Probabilistic Horn abduction and Bayesian networks 59 </title>
Reference-contexts: Let F 0 be the set of ground instances of elements of F . H is a set of (possibly open) atoms, called the "assumables" or the "possible hypotheses". Let H 0 be the set of ground instances of elements of H. Definition 2.5 <ref> [51, 42] </ref> If g is a closed formula, an explanation of g from hF; Hi is a set D of elements of H 0 such that * F [ D j= g and * F [ D 6j= f alse. <p> Other have viewed nonmonotonic reasoning in terms of arguments <ref> [42, 29, 31, 41] </ref>. The explanations that we use can be seen as premises for logical arguments. We determine the probability of some proposition by coming up with arguments for the proposition. <p> There is a direct mapping between the knowledge in a Bayesian network and the knowledge in a probabilistic Horn abduction theory. This is also interesting because it provides a link to earlier work on the use of assumption-based reasoning for default reasoning <ref> [42, 44, 46] </ref>. One of the ways of viewing default reasoning is where an adversary chooses the assumptions. One way of viewing the probabilistic Horn abduction is as an instance of assumption-based reasoning, but where nature chooses the assumptions.
Reference: [43] <author> D. Poole. </author> <title> Representing knowledge for logic-based diagnosis. </title> <booktitle> In International Conference on Fifth Generation Computing Systems, </booktitle> <pages> pages 1282-1290, </pages> <address> Tokyo, Japan, </address> <month> November </month> <year> 1988. </year>
Reference-contexts: In Appendix A, we give Probabilistic Horn abduction and Bayesian networks 8 a model theoretic characterisation that incorporates our assumptions, and show the equivalence of the formulations. The formulation of abduction used is a simplified form [18] of Theorist <ref> [51, 43] </ref>. It is simplified in being restricted to Horn clauses. This can also be seen as a generalisation of an ATMS (with predefined nogoods) [59] to be non-propositional 1 . An abductive scheme is a pair hF; Hi where F is a set of Horn clauses. <p> It is a generalisation of the hierarchical constraint of Clark [8]. It implies that there are no infinite chains when backchaining from any ground goal. This does not restrict recursion, but does mean that all recursion must be well founded. These assumptions are made implicitly in <ref> [43] </ref>, are explicit in [9] (who make the hierarchical constraint rather than the acyclic constraint), but are relaxed in [24]. When using abduction we often assume that the explanations are covering. <p> This can be a valid assumption if we have anticipated all eventualities, and the observations are within the domain of the expected observations (usually if this assumption is violated there are no explanations). This is also supported by recent attempts at a completion semantics for abduction <ref> [43, 9, 24] </ref>. The results show how abduction can be considered as deduction on the "closure" of the knowledge base that includes statements that the given causes are the only causes. <p> In this case we need to be able to have different observations at different times, and use constants to denote different times. We first axiomatise how gates work. We must axiomatise how normal gates as well as faulty gates work <ref> [43, 45] </ref>. Each of the gates can be in one of four states (ok, stuck on, stuck off or unknown). When the gate is in the unknown u state it can produce either value with equal probability. <p> [13, 14] and Peng and Reggia [40] both incorporate probabilistic knowledge to find the most likely diagnoses, but do not provide as flexible and simple a representation language as the one here. de Kleer and Williams [13, 14] have explored the idea of using probabilistic information in consistency-based diagnosis (see <ref> [43, 45] </ref> for comparisons between abductive and consistency-based diagnoses). The major differences between their approach and the one presented in this paper is that they differ in what they want to find the probability of. de Kleer and Williams find the most likely interpretations (assignment of values to all hypotheses).
Reference: [44] <author> D. Poole. </author> <title> Explanation and prediction: an architecture for default and abductive reasoning. </title> <journal> Computational Intelligence, </journal> <volume> 5(2) </volume> <pages> 97-110, </pages> <year> 1989. </year>
Reference-contexts: Probabilistic Horn abduction and Bayesian networks 24 4.2 Abduction and Prediction When computing the prior probability of a hypothesis, we find the explanations for that hypothesis. This corresponds to the use of "abduction" <ref> [44] </ref>. <p> This corresponds to the combination of abducing to causes and default reasoning to predictions from these causes <ref> [44, 46, 62] </ref>. The results of this paper, give extra evidence that this forms the "right" characterisation of causal reasoning. <p> Abducing the causes and then assumption-based reasoning from causes to predicting what should follow, is the common feature of both Bayesian networks (see also, for example, Shachter and Heckerman [61]) and recent assumption-based logical schemes <ref> [44, 46, 62] </ref>. There is another close similarity between the abductive approaches and the network propagation scheme of Pearl [39]. Finding the explanations of some g conceptually corresponds to working "up" the Bayesian network from g. Given evidence fi, we first find expl (fi; T ). <p> There have been claims that Bayesian networks provide the right independencies for causation [39]. This paper provides evidence that abducing to causes and making assumptions as to what to predict from those assumptions <ref> [44, 46] </ref> is the right logical analogue of the independence in Bayesian networks (as described in section 4.2). <p> There is a direct mapping between the knowledge in a Bayesian network and the knowledge in a probabilistic Horn abduction theory. This is also interesting because it provides a link to earlier work on the use of assumption-based reasoning for default reasoning <ref> [42, 44, 46] </ref>. One of the ways of viewing default reasoning is where an adversary chooses the assumptions. One way of viewing the probabilistic Horn abduction is as an instance of assumption-based reasoning, but where nature chooses the assumptions.
Reference: [45] <author> D. Poole. </author> <title> Normality and faults in logic-based diagnosis. </title> <booktitle> In Proc. 11th International Joint Conf. on Artificial Intelligence, </booktitle> <pages> pages 1304-1310, </pages> <address> Detroit, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: It can be motivated in a number of different ways: Determining what is in a system from observations (diagnosis and recognition) is an important part of AI. There have been many logic-based proposals as to what is a diagnosis <ref> [17, 57, 13, 45, 12] </ref>. One problem with all of these proposals is that for any diagnostic problem of a reasonable size there are far too many logical possibilities to handle. <p> There have been many logic-based proposals as to what is a diagnosis [17, 57, 13, 45, 12]. One problem with all of these proposals is that for any diagnostic problem of a reasonable size there are far too many logical possibilities to handle. For example, when considering fault models <ref> [14, 45] </ref>, there is almost always an exponential number of logical possibilities (e.g., each component could be in one of its normal states or in the unknown state). For practical problems, many of the logically possible diagnoses are so unlikely that it is not worth considering them. <p> If we want our probabilities to be correct, we must ensure that the rules for an atom are disjoint and covering. If the rules for an atom a are not covering, we can invent another cause for the goal representing "all the other possible causes" of the atom <ref> [14, 45] </ref>, and add a a true for some other reason. and make a true for some other reason into a hypothesis. Although disjointedness of rules places a restriction on the knowledge base, it does not place a restriction on the sorts of knowledge that we can represent. <p> We avoid this problem by not placing importance in the most likely explanations, but only in how they contribute to the probability of propositions. 5.2 Causation Events When representing knowledge for abduction <ref> [45, 46] </ref>, we have to be able to make sure that we can imply the observations. In general a fault or disease doesn't imply a particular observation. For example, having a cold does not imply sneezing, but could cause sneezing. <p> I have argued elsewhere <ref> [45, 46] </ref> that there is much power obtainable and subtlety involved in parametrizing hypotheses appropriately. In this section we expand on previous analysis [46], and show how probabilities affect parametrization considerations when using causation events by considering some case studies. <p> Suppose we want to represent the gate being in an unknown state 7 (this is applicable whether or not we have fault models <ref> [14, 45] </ref>). Suppose we represent the proposition that gate G has output V at time T as val (G; V; T ). <p> Probabilistic Horn abduction and Bayesian networks 32 put. Knowing a gate is in an unknown state does not imply any value for the output. When there are no probabilities involved <ref> [46, 45] </ref> we parametrize the hypothesis by the values on which it depends. <p> In this case we need to be able to have different observations at different times, and use constants to denote different times. We first axiomatise how gates work. We must axiomatise how normal gates as well as faulty gates work <ref> [43, 45] </ref>. Each of the gates can be in one of four states (ok, stuck on, stuck off or unknown). When the gate is in the unknown u state it can produce either value with equal probability. <p> In order for us to be able to observe inputs and to be able to predict expected values from unknown inputs we can make the inputs to the gates to be random variables. (The alternative is to write as facts what the inputs to the gates are <ref> [45] </ref>). disjoint ([val (input (1; adder (N )); on; T ) : 0:5; val (input (1; adder (N )); of f; T ) : 0:5]): disjoint ([val (input (2; adder (N )); on; T ) : 0:5; val (input (2; adder (N )); of f; T ) : 0:5]): We can <p> [13, 14] and Peng and Reggia [40] both incorporate probabilistic knowledge to find the most likely diagnoses, but do not provide as flexible and simple a representation language as the one here. de Kleer and Williams [13, 14] have explored the idea of using probabilistic information in consistency-based diagnosis (see <ref> [43, 45] </ref> for comparisons between abductive and consistency-based diagnoses). The major differences between their approach and the one presented in this paper is that they differ in what they want to find the probability of. de Kleer and Williams find the most likely interpretations (assignment of values to all hypotheses). <p> One way of viewing the probabilistic Horn abduction is as an instance of assumption-based reasoning, but where nature chooses the assumptions. This paper also demonstrates the correspondence between the observations that need to be explained in abduction <ref> [45] </ref>, and what is conditioned on in Bayesian probability. Probabilistic Horn abduction and Bayesian networks 48 A Formal Semantics In this section we give the formal semantics for our language. As the language is very simple, the semantics will be correspondingly simple.
Reference: [46] <author> D. Poole. </author> <title> A methodology for using a default and abductive reasoning system. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 5(5) </volume> <pages> 521-548, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: This corresponds to the combination of abducing to causes and default reasoning to predictions from these causes <ref> [44, 46, 62] </ref>. The results of this paper, give extra evidence that this forms the "right" characterisation of causal reasoning. <p> Abducing the causes and then assumption-based reasoning from causes to predicting what should follow, is the common feature of both Bayesian networks (see also, for example, Shachter and Heckerman [61]) and recent assumption-based logical schemes <ref> [44, 46, 62] </ref>. There is another close similarity between the abductive approaches and the network propagation scheme of Pearl [39]. Finding the explanations of some g conceptually corresponds to working "up" the Bayesian network from g. Given evidence fi, we first find expl (fi; T ). <p> There have been claims that Bayesian networks provide the right independencies for causation [39]. This paper provides evidence that abducing to causes and making assumptions as to what to predict from those assumptions <ref> [44, 46] </ref> is the right logical analogue of the independence in Bayesian networks (as described in section 4.2). <p> If there were a number of wait operations, the unloading could have occurred at any of them. 5 Representational Methodology Once we have a tool, it is important to know how to use it. The problem of a representational methodology <ref> [46] </ref> is an important and much overlooked part of automated reasoning research. It may seem that the assumptions used in designing probabilistic Horn abduction were so restrictive that the system would be useless for real problems. In this section, I argue that this is not the case. <p> We avoid this problem by not placing importance in the most likely explanations, but only in how they contribute to the probability of propositions. 5.2 Causation Events When representing knowledge for abduction <ref> [45, 46] </ref>, we have to be able to make sure that we can imply the observations. In general a fault or disease doesn't imply a particular observation. For example, having a cold does not imply sneezing, but could cause sneezing. <p> I have argued elsewhere <ref> [45, 46] </ref> that there is much power obtainable and subtlety involved in parametrizing hypotheses appropriately. In this section we expand on previous analysis [46], and show how probabilities affect parametrization considerations when using causation events by considering some case studies. <p> I have argued elsewhere [45, 46] that there is much power obtainable and subtlety involved in parametrizing hypotheses appropriately. In this section we expand on previous analysis <ref> [46] </ref>, and show how probabilities affect parametrization considerations when using causation events by considering some case studies. As an example, suppose we have a gate G that takes two values as input, and outputs a value that can be in the range 1 to n. <p> Probabilistic Horn abduction and Bayesian networks 32 put. Knowing a gate is in an unknown state does not imply any value for the output. When there are no probabilities involved <ref> [46, 45] </ref> we parametrize the hypothesis by the values on which it depends. <p> Here we interpret simple line drawings of a map. These consist of lines and areas that depict roads, rivers, shores, lakes and land. Our axiomatisation is based on the abductive representation of <ref> [46] </ref>. <p> Given an image we conjecture scene elements that could have produced that image. The main difference between this axiomatisation and those of <ref> [60, 46] </ref> is that we have to make constructive derivations of the image. Rather than starting with all interpretations, and use consistency to prune those that are impossible, we make sure that we can only generate possible explanations. This follows the methodology given earlier in this section. <p> There is a direct mapping between the knowledge in a Bayesian network and the knowledge in a probabilistic Horn abduction theory. This is also interesting because it provides a link to earlier work on the use of assumption-based reasoning for default reasoning <ref> [42, 44, 46] </ref>. One of the ways of viewing default reasoning is where an adversary chooses the assumptions. One way of viewing the probabilistic Horn abduction is as an instance of assumption-based reasoning, but where nature chooses the assumptions.
Reference: [47] <author> D. Poole. </author> <title> Representing Bayesian networks within probabilistic Horn abduction. </title> <booktitle> In Proc. Seventh Conf. on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 271-278, </pages> <address> Los Angeles, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Probabilistic Horn Abduction <ref> [48, 47] </ref> is a framework for logic-based abduction that incorporates probabilities with assumptions. This is being used as a framework for diagnosis [48] that incorporates both pure Prolog [30] and Bayesian Networks [39] as special cases. This paper expands on [48, 47] and develops the formal underpinnings of probabilistic Horn abduction, <p> 1 Introduction Probabilistic Horn Abduction <ref> [48, 47] </ref> is a framework for logic-based abduction that incorporates probabilities with assumptions. This is being used as a framework for diagnosis [48] that incorporates both pure Prolog [30] and Bayesian Networks [39] as special cases. This paper expands on [48, 47] and develops the formal underpinnings of probabilistic Horn abduction, shows the strong relationships to other formalisms and argues that it is a good representation language in its own right. <p> This is in contrast to earlier versions <ref> [48, 47] </ref> where we allowed arbitrary integrity constraints. The more expressive language in [48, 47] allows us to represent what the current version allows, however it lets us represent what we cannot interpret probabilistically, and makes the proof procedures more complicated without providing visible advantage. <p> This is in contrast to earlier versions <ref> [48, 47] </ref> where we allowed arbitrary integrity constraints. The more expressive language in [48, 47] allows us to represent what the current version allows, however it lets us represent what we cannot interpret probabilistically, and makes the proof procedures more complicated without providing visible advantage.
Reference: [48] <author> D. Poole. </author> <title> Representing diagnostic knowledge for probabilistic Horn abduction. </title> <booktitle> In Proc. 12th International Joint Conf. on Artificial Intelligence, </booktitle> <pages> pages 1129-1135, </pages> <address> Sydney, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Probabilistic Horn Abduction <ref> [48, 47] </ref> is a framework for logic-based abduction that incorporates probabilities with assumptions. This is being used as a framework for diagnosis [48] that incorporates both pure Prolog [30] and Bayesian Networks [39] as special cases. This paper expands on [48, 47] and develops the formal underpinnings of probabilistic Horn abduction, <p> 1 Introduction Probabilistic Horn Abduction [48, 47] is a framework for logic-based abduction that incorporates probabilities with assumptions. This is being used as a framework for diagnosis <ref> [48] </ref> that incorporates both pure Prolog [30] and Bayesian Networks [39] as special cases. This paper expands on [48, 47] and develops the formal underpinnings of probabilistic Horn abduction, shows the strong relationships to other formalisms and argues that it is a good representation language in its own right. <p> 1 Introduction Probabilistic Horn Abduction <ref> [48, 47] </ref> is a framework for logic-based abduction that incorporates probabilities with assumptions. This is being used as a framework for diagnosis [48] that incorporates both pure Prolog [30] and Bayesian Networks [39] as special cases. This paper expands on [48, 47] and develops the formal underpinnings of probabilistic Horn abduction, shows the strong relationships to other formalisms and argues that it is a good representation language in its own right. <p> This is in contrast to earlier versions <ref> [48, 47] </ref> where we allowed arbitrary integrity constraints. The more expressive language in [48, 47] allows us to represent what the current version allows, however it lets us represent what we cannot interpret probabilistically, and makes the proof procedures more complicated without providing visible advantage. <p> This is in contrast to earlier versions <ref> [48, 47] </ref> where we allowed arbitrary integrity constraints. The more expressive language in [48, 47] allows us to represent what the current version allows, however it lets us represent what we cannot interpret probabilistically, and makes the proof procedures more complicated without providing visible advantage. <p> Thanks to Mark Wallace for showing me that the language in <ref> [48] </ref> was too strong. Thanks to Fahiem Bacchus for help with the semantics. This research was supported under NSERC grant OGPOO44121, and under Project B5 of the Institute for Robotics and Intelligent Systems.
Reference: [49] <author> D. Poole. </author> <title> Logic programming, abduction and probability. </title> <booktitle> In International Conference on Fifth Generation Computer Systems (FGCS-92), </booktitle> <pages> pages 530-538, </pages> <address> Tokyo, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Probabilistic Horn abduction and Bayesian networks 44 to compute posterior probabilities. There are many ways that could be used to compute posterior probabilities, we could use some form of stochastic simulation (e.g., [20]), search (e.g., <ref> [49, 50] </ref>), or even using the mapping to Bayesian networks to translate ground instances of the theory into some secondary structure for propagating evidence (e.g., [27, 23]).
Reference: [50] <author> D. Poole. </author> <title> Search for computing posterior probabilities in Bayesian networks. </title> <type> Technical Report 92-24, </type> <institution> Department of Computer Science, University of British Columbia, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: Probabilistic Horn abduction and Bayesian networks 44 to compute posterior probabilities. There are many ways that could be used to compute posterior probabilities, we could use some form of stochastic simulation (e.g., [20]), search (e.g., <ref> [49, 50] </ref>), or even using the mapping to Bayesian networks to translate ground instances of the theory into some secondary structure for propagating evidence (e.g., [27, 23]).
Reference: [51] <author> D. Poole, R. Goebel, and R. Aleliunas. </author> <title> Theorist: A logical reasoning system for defaults and diagnosis. </title> <editor> In N. Cercone and G. McCalla, editors, </editor> <booktitle> The Knowledge Frontier: Essays in the Representation of Knowledge, </booktitle> <pages> pages 331-352. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1987. </year>
Reference-contexts: In Appendix A, we give Probabilistic Horn abduction and Bayesian networks 8 a model theoretic characterisation that incorporates our assumptions, and show the equivalence of the formulations. The formulation of abduction used is a simplified form [18] of Theorist <ref> [51, 43] </ref>. It is simplified in being restricted to Horn clauses. This can also be seen as a generalisation of an ATMS (with predefined nogoods) [59] to be non-propositional 1 . An abductive scheme is a pair hF; Hi where F is a set of Horn clauses. <p> Let F 0 be the set of ground instances of elements of F . H is a set of (possibly open) atoms, called the "assumables" or the "possible hypotheses". Let H 0 be the set of ground instances of elements of H. Definition 2.5 <ref> [51, 42] </ref> If g is a closed formula, an explanation of g from hF; Hi is a set D of elements of H 0 such that * F [ D j= g and * F [ D 6j= f alse.
Reference: [52] <author> D. Poole and G. Provan. </author> <title> What is the most likely diagnosis? In P. </title> <editor> P. Bonissone, M. Henrion, L. N. Kanal and J. F. Lemmer, editor, </editor> <booktitle> Uncertainty in Artificial Intelligence 6, </booktitle> <pages> pages 89-105. </pages> <publisher> Elsevier Science Publishers B. V., </publisher> <year> 1991. </year> <title> Probabilistic Horn abduction and Bayesian networks 60 </title>
Reference-contexts: This has repercussions in biasing the most likely explanation to the first rule, which is more general than the others. This problem of the most likely diagnosis depending on the representation seems endemic to approaches that try to find the diagnosis (either explanation or interpretation) that is "most likely" <ref> [39, 52] </ref>. We avoid this problem by not placing importance in the most likely explanations, but only in how they contribute to the probability of propositions. 5.2 Causation Events When representing knowledge for abduction [45, 46], we have to be able to make sure that we can imply the observations. <p> In our system, hypotheses that are not part of an explanation are irrelevant and are ignored. We do not place such an importance on the explanations, but rather on using the explanations to compute probabilities (see <ref> [52] </ref> for some of the issues involved in considering what we want to compute the probability of). Peng and Reggia [40] also consider an abductive definition of diagnosis and incorporate probabilities, and best-first search.
Reference: [53] <author> H. E. Pople, Jr. </author> <booktitle> On the mechanization of abductive logic. In Proc. 3rd International Joint Conf. on Artificial Intelligence, </booktitle> <pages> pages 147-152, </pages> <address> Stanford, </address> <month> August </month> <year> 1973. </year>
Reference-contexts: We thus only compare the representation to other proposals, and not any implementations. 6.1 Other logic-based abductive schemes There are many other proposals for logic-based abduction schemes (e.g., <ref> [53, 10, 18] </ref>). These however consider that we have to find all of the diagnoses. In practice there are prohibitively many of these.
Reference: [54] <author> G. Provan. </author> <title> An analysis of ATMS-based techniques for computing Dempster-Shafer belief functions. </title> <booktitle> In Proc. 11th International Joint Conf. on Artificial Intelligence, </booktitle> <pages> pages 1115-1120, </pages> <address> Detroit, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: We would need another, meta-level, program to transform our Prolog rules into Bayesian networks for a traditional Bayesian network interpreter to solve. 6.4 Horn abduction and Dempster-Shafer This work is also closely related to recent embeddings of Dempster-Shafer theory in ATMS <ref> [26, 54] </ref>. One difference between our embedding of Bayesian networks and Dempster-Shafer is in the independence assumptions used. Dempster-Shafer theory assumes that different rules are independent. We assume they are exclusive.
Reference: [55] <author> H. Reichenbach. </author> <title> The Direction of Time. </title> <institution> University of California Press, Berkeley and Los Angeles, </institution> <year> 1956. </year>
Reference-contexts: Note that others have also noticed the universality of just having independent hypotheses. For example, consider Reichenbach's principle of the common cause: "If coincidences of two events A and B occur more frequently than their independent occurrence, ... then there exists a common cause for these events ..." <ref> [55, p. 163] </ref>. When there is a dependency amongst random variables, we invent a hypothesis to explain that dependence. Thus the assumption of independence, while it gives a restriction on the knowledge bases that are legal, really gives no restriction on the domains that can be represented.
Reference: [56] <author> R. Reiter. </author> <title> Equality and domain closure in first order data bases. </title> <journal> J. ACM, </journal> <volume> 27 </volume> <pages> 235-249, </pages> <year> 1980. </year>
Reference-contexts: Thus, we are assuming that t 1 6= t 2 for different terms t 1 and t 2 . This assumption is the unique names assumption <ref> [56] </ref>. Note that it is for the probabilistic calculation that we are making the unique names assumption.
Reference: [57] <author> R. Reiter. </author> <title> A theory of diagnosis from first principles. </title> <journal> Artificial Intelligence, </journal> <volume> 32(1) </volume> <pages> 57-95, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: It can be motivated in a number of different ways: Determining what is in a system from observations (diagnosis and recognition) is an important part of AI. There have been many logic-based proposals as to what is a diagnosis <ref> [17, 57, 13, 45, 12] </ref>. One problem with all of these proposals is that for any diagnostic problem of a reasonable size there are far too many logical possibilities to handle.
Reference: [58] <author> R. Reiter. </author> <title> The frame problem in the situation calculus: A simple solution (sometimes) and a completeness result for goal regression. </title> <editor> In V. Lifschitz, editor, </editor> <booktitle> Artificial Intelligence and the Mathematical Theory of Computation: Papers in Honor of John McCarthy, </booktitle> <pages> pages 359-380. </pages> <publisher> Academic Press, </publisher> <address> San Diego, California, </address> <year> 1991. </year>
Reference-contexts: network representation is very similar to logic programming solutions to the frame problem (see e.g., [62, 1]) using the equivalence of our negation to negation as failure for acyclic theories [4] and, considering the completion of the program, to the recent deductive solutions to the frame problem proposed by Reiter <ref> [58] </ref> and Elkan [16]. The probabilistic Horn abduction representation allows us to consistently add probability to the temporal representations.
Reference: [59] <author> R. Reiter and J. de Kleer. </author> <title> Foundations of assumption-based truth maintenance systems: preliminary report. </title> <booktitle> In Proc. 6th National Conference on Artificial Intelligence, </booktitle> <pages> pages 183-188, </pages> <address> Seattle, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: The formulation of abduction used is a simplified form [18] of Theorist [51, 43]. It is simplified in being restricted to Horn clauses. This can also be seen as a generalisation of an ATMS (with predefined nogoods) <ref> [59] </ref> to be non-propositional 1 . An abductive scheme is a pair hF; Hi where F is a set of Horn clauses. Variables in F are implicitly universally quanti fied. Let F 0 be the set of ground instances of elements of F .
Reference: [60] <author> R. Reiter and A. K. Mackworth. </author> <title> A logical framework for depiction and image interpretation. </title> <journal> Artificial Intelligence, </journal> <volume> 41(2) </volume> <pages> 125-155, </pages> <year> 1989. </year>
Reference-contexts: (s (1))); on; t1) ^ val (output (1; adder (1)); on; t1); ^ val (output (1; adder (s (1))); of f; t1) ^ val (output (2; adder (s (1))); of f; t1) Example 5.3 The second example is of the framework for depiction and image interpretation of Reiter and Mackworth <ref> [60] </ref>. Here we interpret simple line drawings of a map. These consist of lines and areas that depict roads, rivers, shores, lakes and land. Our axiomatisation is based on the abductive representation of [46]. <p> Given an image we conjecture scene elements that could have produced that image. The main difference between this axiomatisation and those of <ref> [60, 46] </ref> is that we have to make constructive derivations of the image. Rather than starting with all interpretations, and use consistency to prune those that are impossible, we make sure that we can only generate possible explanations. This follows the methodology given earlier in this section. <p> Rather than starting with all interpretations, and use consistency to prune those that are impossible, we make sure that we can only generate possible explanations. This follows the methodology given earlier in this section. Following Reiter and Mackworth <ref> [60] </ref>, for each image object I we assume a scene object (I) which it depicts. We first allow one to write the building blocks of explanations. area (S; land) means that the scene object S is land, given that it is a region.
Reference: [61] <author> R. D. Shachter and D. Heckerman. </author> <title> Thinking backwards for knowledge acquisition. </title> <journal> AI Magazine, </journal> <volume> 8 </volume> <pages> 55-62, </pages> <year> 1987. </year>
Reference-contexts: The results of this paper, give extra evidence that this forms the "right" characterisation of causal reasoning. Abducing the causes and then assumption-based reasoning from causes to predicting what should follow, is the common feature of both Bayesian networks (see also, for example, Shachter and Heckerman <ref> [61] </ref>) and recent assumption-based logical schemes [44, 46, 62]. There is another close similarity between the abductive approaches and the network propagation scheme of Pearl [39]. Finding the explanations of some g conceptually corresponds to working "up" the Bayesian network from g. <p> In this section, I argue that this is not the case. The general idea is to use definite clauses to write a simulation (in the "causal" direction <ref> [61] </ref>) based on different possible hypotheses. This axiomatisation must follow the assumptions about the rule base and about the independence of hypotheses, but we argue in this section that this is not too difficult.
Reference: [62] <author> M. Shanahan. </author> <title> Prediction is deduction, but explanation is abduction. </title> <booktitle> In Proc. 11th International Joint Conf. on Artificial Intelligence, </booktitle> <pages> pages 1055-1060, </pages> <address> Detroit, Mich., </address> <month> August </month> <year> 1989. </year>
Reference-contexts: This corresponds to the combination of abducing to causes and default reasoning to predictions from these causes <ref> [44, 46, 62] </ref>. The results of this paper, give extra evidence that this forms the "right" characterisation of causal reasoning. <p> Abducing the causes and then assumption-based reasoning from causes to predicting what should follow, is the common feature of both Bayesian networks (see also, for example, Shachter and Heckerman [61]) and recent assumption-based logical schemes <ref> [44, 46, 62] </ref>. There is another close similarity between the abductive approaches and the network propagation scheme of Pearl [39]. Finding the explanations of some g conceptually corresponds to working "up" the Bayesian network from g. Given evidence fi, we first find expl (fi; T ). <p> do (load; S)) holds (alive; S): holds (alive; 0): holds (loaded; 0): The following formula can be proved: holds (alive; do (shoot; do (wait; do (load; 0)))): The solution that is derived from the Bayesian network representation is very similar to logic programming solutions to the frame problem (see e.g., <ref> [62, 1] </ref>) using the equivalence of our negation to negation as failure for acyclic theories [4] and, considering the completion of the program, to the recent deductive solutions to the frame problem proposed by Reiter [58] and Elkan [16].
Reference: [63] <author> S. E. Shimony and E. Charniak. </author> <title> A new algorithm for finding MAP assignments to belief networks. </title> <booktitle> In Proc. Sixth Conf. on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 98-103, </pages> <address> Cambridge, Mass., </address> <month> July </month> <year> 1990. </year> <title> Probabilistic Horn abduction and Bayesian networks 61 </title>
Reference-contexts: These costs can be seen as -log probabilities [7]. One can view the current work as extending Hobbs et. al.'s to derive posterior probabilities in a consistent manner. 6.3 Logic and Bayesian networks The representation of Bayesian networks is related to the work by Charniak and Shimony <ref> [7, 63] </ref>. Instead of considering abduction, they consider models that consist of an assignment of values to each random variable. The label of [63] plays an analogous role to our hypotheses. They however, do not use their system for computing posterior probabilities. <p> Instead of considering abduction, they consider models that consist of an assignment of values to each random variable. The label of <ref> [63] </ref> plays an analogous role to our hypotheses. They however, do not use their system for computing posterior probabilities. It is also not so obvious how to extend their formalism to more powerful logics.
Reference: [64] <author> L. Sterling and E. Shapiro. </author> <title> The Art of Prolog. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: The initial language is translated into an abductive framework with a number of assumptions about the knowledge base. The appendix gives a more formal model-theoretic semantics and demonstrates the equivalence between the two. 2.1 The Probabilistic Horn abduction language Our language uses the Prolog conventions <ref> [64] </ref>: Definition 2.1 A term is either a variable (starting with an upper case letter), a constant (starting with a lower case letter) or is of the form f (t 1 ; ; t n ) where f is a function symbol (starting with a lower case letter) and each t <p> the alarm. p 2 = 1 p 1 . 6 Comparison with Other Systems Before comparing the work in this paper with other proposals, we should note that in this paper we have described a representation, and not a way 11 Here we use the Prolog syntactic sugar for lists <ref> [64] </ref>. [j] is just a binary function symbol, [] is a constant. We use the notational convention that [ffj [fi]] is written as [ff; fi] for any sequence of symbols ff and fi. Probabilistic Horn abduction and Bayesian networks 44 to compute posterior probabilities.
Reference: [65] <author> M. H. van Emden. </author> <title> Quantitative deduction and its fixpoint theory. </title> <journal> Journal of Logic Programming, </journal> <volume> 4(1) </volume> <pages> 37-53, </pages> <year> 1986. </year>
Reference-contexts: These have typically not considered probability, but other uncer Probabilistic Horn abduction and Bayesian networks 47 tainty calculi such as certainty factors <ref> [65] </ref>. Ng and Subrahmanian [35] have combined logic programming and probability by allowing us to axiomatise probability in logic, and then use Prolog-style rules to give the probabilistic information. The Prolog rules reason about the probability, at much more of a meta-level than that proposed here.
References-found: 65

