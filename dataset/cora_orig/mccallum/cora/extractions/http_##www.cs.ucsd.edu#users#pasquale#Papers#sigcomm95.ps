URL: http://www.cs.ucsd.edu/users/pasquale/Papers/sigcomm95.ps
Refering-URL: http://www.cs.ucsd.edu/users/pasquale/Pub.html
Root-URL: http://www.cs.ucsd.edu
Email: norival, pasquale-@cs.ucsd.edu  
Title: Leave-in-Time: A New Service Discipline for Real-Time Communications in a PacketSwitching Network  
Author: Norival R. Figueira and Joseph Pasquale 
Keyword: delay shifting  
Address: San Diego, CA 92093-0114  
Affiliation: Computer Systems Laboratory Department of Computer Science and Engineering University of California, San Diego  
Abstract: Leave-in-Time is a new rate-based service discipline for packetswitching nodes in a connection-oriented data network. Leave-in-Time provides sessions with upper bounds on end-to-end delay, delay jitter, buffer space requirements, and an upper bound on the probability distribution of end-to-end delay s. A Leave-in-Time session s guarantees are completely determined by the dynamic traf fic behavior of that session, without in uence from other sessions. This results in the desirable property that these guarantees are expressed as functions derivable simply from a single fixed-rate server (with rate equal to the sessions reserved rate) serving only that session. Leave-in-Time has a nonwork-conserving mode of operation for sessions desiring low end-to-end delay jitter. Finally, Leave-in-Time supports the notion of whereby the delay bounds of some sessions may be decreased at the expense of increasing those of other sessions. We present a set of admission control algorithms which support the ability to do delay shifting in a systematic way. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Clark, S. Shenker , and L. Zhang, </author> <title> Supporting Real-T ime Applications in an Integrated Services Packet Network: Architecture and Mechanism, </title> <booktitle> In Proceedings of ACM SIG-COMM 92 , pp. </booktitle> <pages> 14-26, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Providing an upper bound on delay has been a major point of concern for previously proposed service disciplines; however , even this is not enough. The delay distribution of packets is likely to be very useful for tolerant applications <ref> [ 1] </ref>. Tolerant applications permit some brief interruptions in service; the level of toler - ance might be defi ned as a maximum percentage of missing packets over some period of time. <p> New tokens are continuously fi lling up the bucket at rate . All tokens exceeding the maximum bucket capacity are discarded. A sessions traffic conforms to a token bucket fi lter ( ) (here we adopt a notation similar to the one used in <ref> [1] </ref>, adding an identifi er for the session with the subscript ) if, for every generated packet, tokens are removed from the bucket, where is the length of the packet, and the bucket size is never negative (i.e. there are always enough tokens to be removed when a packet is generated). <p> Leave-in-T imes performance bounds depend only on the dynamic traffic behavior of that session, and are not af fected by the behavior of other sessions being transported over the same links and servers. The bound on delay distribution is especially useful in supporting tolerant applications as defined in <ref> [1] </ref>. A special case of Leave-in-T imes operation reduces to that of VirtualClock. Since the performance bounds we have presented apply to the general case of Leave-in-T imes operation, they also apply to VirtualClock.
Reference: [2] <author> R. L. Cruz, </author> <title> A Calculus for Network Delay , Part I: Network Elements in Isolation, </title> <journal> In IEEE Transactions on Information Theory , Vol. </journal> <volume> 37, No. 1, </volume> <pages> pp. 114-131, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Thus, from (14), , which is competitive with the result of Stop-and-Go. The reader is referred to [25] which compares the delay distribution seen by sessions under FCFS multiplexing with the delay bound computed with Cruzs method <ref> [2, 3] </ref>, the delay bound using Stop-and-Go, and the delay bound using PGPS (presented later in this section). Hierarchical Round Robin (HRR) [ 13] also uses a framing strategy and is a nonwork-conserving service discipline. <p> The reader is referred to [12] for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a network setting <ref> [2, 3, 15, 24] </ref>. In [ 2, 3], Cruz uses a non-probabilistic approach to characterize each session entering the network - the burstiness constraint , which is in principle very similar to a token bucket filter. <p> The reader is referred to [12] for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a network setting [2, 3, 15, 24]. In <ref> [ 2, 3] </ref>, Cruz uses a non-probabilistic approach to characterize each session entering the network - the burstiness constraint , which is in principle very similar to a token bucket filter. Under this assumption, a methodology is proposed to calculate per-session upper bounds on delay and buffer requirements. <p> Kurose in [ 15], and Yaron and Sidi in [ 24] describe methods to calculate bounds on the distribution of delay and buffer occupancy when all sessions entering the network are stochastically bounded. The work in <ref> [2, 3, 15, 24] </ref> differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session , while the methodology in [2, 3, 15, 24] provides the upper bound on the delay distribution directly. <p> The work in <ref> [2, 3, 15, 24] </ref> differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session , while the methodology in [2, 3, 15, 24] provides the upper bound on the delay distribution directly. <p> provide this function for sessions with any kind of dynamic traffic behavior, and this function depends only on the session in question, i.e. the dynamic traf fic behavior of other sessions does not enter into consideration (i.e. the Leave-in-T ime service discipline provides isolation between sessions), while the methodology in <ref> [2, 3, 15, 24] </ref> is based on the traffic characterization of all sessions sharing network servers with the session in question, and the dynamic traffic behavior of all sessions enters in the calculation of the delay distribution. 5 Conclusions We have presented the Leave-in-T ime service discipline which provides sessions with
Reference: [3] <author> R. L. Cruz, </author> <title> A Calculus for Network Delay , Part II: Network Analysis, </title> <journal> In IEEE Transactions on Information Theor y , Vol. </journal> <volume> 37, No. 1, </volume> <pages> pp. 132-141, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Thus, from (14), , which is competitive with the result of Stop-and-Go. The reader is referred to [25] which compares the delay distribution seen by sessions under FCFS multiplexing with the delay bound computed with Cruzs method <ref> [2, 3] </ref>, the delay bound using Stop-and-Go, and the delay bound using PGPS (presented later in this section). Hierarchical Round Robin (HRR) [ 13] also uses a framing strategy and is a nonwork-conserving service discipline. <p> The reader is referred to [12] for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a network setting <ref> [2, 3, 15, 24] </ref>. In [ 2, 3], Cruz uses a non-probabilistic approach to characterize each session entering the network - the burstiness constraint , which is in principle very similar to a token bucket filter. <p> The reader is referred to [12] for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a network setting [2, 3, 15, 24]. In <ref> [ 2, 3] </ref>, Cruz uses a non-probabilistic approach to characterize each session entering the network - the burstiness constraint , which is in principle very similar to a token bucket filter. Under this assumption, a methodology is proposed to calculate per-session upper bounds on delay and buffer requirements. <p> Kurose in [ 15], and Yaron and Sidi in [ 24] describe methods to calculate bounds on the distribution of delay and buffer occupancy when all sessions entering the network are stochastically bounded. The work in <ref> [2, 3, 15, 24] </ref> differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session , while the methodology in [2, 3, 15, 24] provides the upper bound on the delay distribution directly. <p> The work in <ref> [2, 3, 15, 24] </ref> differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session , while the methodology in [2, 3, 15, 24] provides the upper bound on the delay distribution directly. <p> provide this function for sessions with any kind of dynamic traffic behavior, and this function depends only on the session in question, i.e. the dynamic traf fic behavior of other sessions does not enter into consideration (i.e. the Leave-in-T ime service discipline provides isolation between sessions), while the methodology in <ref> [2, 3, 15, 24] </ref> is based on the traffic characterization of all sessions sharing network servers with the session in question, and the dynamic traffic behavior of all sessions enters in the calculation of the delay distribution. 5 Conclusions We have presented the Leave-in-T ime service discipline which provides sessions with
Reference: [4] <author> A. Demers, S. Keshav, and S. Shenker, </author> <title> Analysis and Simulation of a Fair Queueing Algorithm, </title> <booktitle> In Proceedings of ACM SIGCOMM 89 , pp. </booktitle> <pages> 1-12, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: PGPS is Parekh and Gallag er s method for computing delay bounds under Weighted Fair Queueing <ref> [4] </ref>. An important problem we address is that, in general, an upper bound on delay will grow linearly with the connection length. <p> Leave-in-T ime uses an approximate sorted priority queue algorithm which runs in O (1) time with a small cost in emu lation error [6]. Weighted Fair Queueing (WFQ) is proposed in <ref> [ 4] </ref> and is a service discipline that tries to emulate the service provided by a bit-by-bit round robin server.
Reference: [5] <author> D. Ferrari and D. Verma, </author> <title> A Scheme for Real-T ime Channel Establishment in Wide-Area Networks, </title> <journal> In IEEE JSAC , Vol. </journal> <volume> 8, No. 4, </volume> <pages> pp. 368-379, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the finite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD <ref> [ 5] </ref>, Jitter -EDD [ 22], RCSP [ 26], VirtualClock [ 29], PGPS [17, 18, 19, 20], Stop-and-Go [ 9, 10, 11], and Hierarchical Round Robin [ 13]. <p> In exactly the same manner , upper bounds on the end-to-end delay distribution, end-to-end delay jitter, and buf fer space requirements are obtained. Except for the upper bound on end-to-end delay (presented in [ 7]), these results are new for the VirtualClock service discipline. In DelayEDD <ref> [ 5] </ref>, and its extension Jitter -EDD [ 22] (EDD stands for earliest-due-date), packets are assigned deadlines and transmitted in order of increasing deadline. The deadline of a packet is not directly coupled to the reserved bandwidth of its session as in the Leave-in-T ime scheme (see equation (11)). <p> The deadline of a packet is not directly coupled to the reserved bandwidth of its session as in the Leave-in-T ime scheme (see equation (11)). This leads to a schedulability test at connection establishment time <ref> [ 5] </ref> to avoid scheduling saturation, which can occur even if bandwidth is not overbooked [5, 28]. The schedulability test is then a compro mise on the looser coupling between reserved rate and delay bound. The Leave-in-T ime scheme needs an admission control procedure for the same reason. <p> This leads to a schedulability test at connection establishment time [ 5] to avoid scheduling saturation, which can occur even if bandwidth is not overbooked <ref> [5, 28] </ref>. The schedulability test is then a compro mise on the looser coupling between reserved rate and delay bound. The Leave-in-T ime scheme needs an admission control procedure for the same reason.
Reference: [6] <author> N. R. Figueira, </author> <title> A New Approach to the Control of Real-Time Traffic in Packet Switching Data Networks, </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science and Engineering, University of California, </institution> <address> San Diego, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: This delay is completely determined by the dynamic traf fic behavior of the session. See <ref> [ 6] </ref> for an upper bound on the buf fer space proba bility distribution The Admission Control Procedures In order for the Leave-in-T ime service discipline to provide sessions with service commitments that are independent of the traffic behavior of other sessions, sessions must satisfy some traffic requirements as verifi ed <p> Simulation Results We simulated the Leave-in-T ime service discipline to illus trate the various performance guarantees provided. Experiments using admission control procedures 1 and 2 are presented. For more detailed results, see <ref> [6] </ref>. Admission Control Procedure 1 with One Class We simulated Leave-in-T ime using admission control proce dure 1 with one class, i.e. with = 1536kbits/s. End-to-End Delay ON-OFF five-hop session (without delay jitter control) in the MIX traffic confi guration in a 5 minute run of the network. <p> Leave-in-T ime uses an approximate sorted priority queue algorithm which runs in O (1) time with a small cost in emu lation error <ref> [6] </ref>. Weighted Fair Queueing (WFQ) is proposed in [ 4] and is a service discipline that tries to emulate the service provided by a bit-by-bit round robin server.
Reference: [7] <author> N. R. Figueira and Joseph Pasquale, </author> <title> An Upper Bound on Delay for the VirtualClock Service Discipline, </title> <journal> IEEE/ACM Transactions on Networking , Vol. </journal> <volume> 3, No. 4, </volume> <month> August </month> <year> 1995, </year> <note> (in press). </note>
Reference-contexts: All of these service disciplines provide an upper bound on end-to-end delay (this includes VirtualClock for which an upper bound on end-to-end delay was unknown until recently proven in <ref> [ 7] </ref>). JitterEDD, RCSP, and Stop-and-Go also provide an upper bound on delay jitter. Providing an upper bound on delay has been a major point of concern for previously proposed service disciplines; however , even this is not enough. <p> of the session , is the finishing transmission time of packet in the reference server (i.e. the time the last bit of packet leaves the reference server), and is the delay of packet in the reference server , i.e. . is related to and by the following equation (proof in <ref> [7] </ref>): where . Queue Received Packets L i s , r s The Leave-in-Time Service Discipline We present the Leave-in-T ime service discipline as a con struction in three steps: a base server algorithm based on the refer - ence server, and two generalizations that result in the final version. <p> As discussed before, the term is part of the upper bound on delay of VirtualClock and PGPS. In Virtual-Clock, this term originates from the term of equation (2) (the upper bound on delay for VirtualClock is given in <ref> [ 7] </ref>). The second generalization replaces by which allows some reduction of the upper bound on delay , i.e. by allowing a smaller value than to be assigned to . Thus, this generalization allows control over the upper bounds on the end-to-end delays that sessions experience. <p> In exactly the same manner , upper bounds on the end-to-end delay distribution, end-to-end delay jitter, and buf fer space requirements are obtained. Except for the upper bound on end-to-end delay (presented in <ref> [ 7] </ref>), these results are new for the VirtualClock service discipline. In DelayEDD [ 5], and its extension Jitter -EDD [ 22] (EDD stands for earliest-due-date), packets are assigned deadlines and transmitted in order of increasing deadline.
Reference: [8] <author> N. R. Figueira and Joseph Pasquale, </author> <title> Leave-in-T ime: A Ser - vice Discipline for Real-T ime Communications in a Packet Switching Network, </title> <institution> Technical Report CSE95-426 , University of California, </institution> <address> San Diego, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: In Section 4, the Leave-in-T ime service discipline is compared with other service disciplines. Section 5 is a summary of the paper s contributions. All results are presented without proof to simplify exposition and due to lack of space. See <ref> [8] </ref> for all proofs. 2 The Leave-in-Time Service Discipline The base packet scheduling algorithm of Leave-in-Time emulates, for each session, the service provided by a fi xed-rate server. <p> As in Jitter -EDD [22], the holding time Session Traffic Input Session Traffic Output calculated at server node - 1 is transmitted in the packet s header to node . Note that is always positive, and that (both proven in <ref> [ 8] </ref>). Thus, the term in (9) tries to eliminate the delay jit ter caused by the variation in the fi nishing transmission times of packets at server node - 1. We will see later that Leave-in-T ime allows to vary according to the packet s length.
Reference: [9] <author> S. J. Golestani, </author> <title> A Stop-and-Go Queueing Framework for Congestion Management, </title> <booktitle> In Pr oceedings of ACM SIG-COMM 90 , pp. </booktitle> <pages> 8-18, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the finite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [ 5], Jitter -EDD [ 22], RCSP [ 26], VirtualClock [ 29], PGPS [17, 18, 19, 20], Stop-and-Go <ref> [ 9, 10, 11] </ref>, and Hierarchical Round Robin [ 13]. All of these service disciplines provide an upper bound on end-to-end delay (this includes VirtualClock for which an upper bound on end-to-end delay was unknown until recently proven in [ 7]). <p> The admission control of Stop-and-Go requires that during any time frame of size arrived packets collectively have no more than bits, where the bandwidth given to session . In <ref> [ 9] </ref>, a session is called ( smooth if it follows this traf fic constraint. This is more restrictive than a token bucket filter. The delay under Stop-and-Go is equal to , where is a constant in the interval [1, 2), and number of links traversed by a session.
Reference: [10] <author> S. J. Golestani, </author> <title> Congestion-Free Transmission of Real-Time Traffic in Packet Networks, </title> <booktitle> In Proceedings of IEEE INFO-COM 90 , pp. </booktitle> <pages> 527-536, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the finite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [ 5], Jitter -EDD [ 22], RCSP [ 26], VirtualClock [ 29], PGPS [17, 18, 19, 20], Stop-and-Go <ref> [ 9, 10, 11] </ref>, and Hierarchical Round Robin [ 13]. All of these service disciplines provide an upper bound on end-to-end delay (this includes VirtualClock for which an upper bound on end-to-end delay was unknown until recently proven in [ 7]).
Reference: [11] <author> S. J. Golestani, </author> <title> Duration-Limited Statistical Multiplexing of DelaySensitive Traffic in Packet Networks, </title> <booktitle> I n Proceedings of IEEE INFOCOM 91 , pp. </booktitle> <pages> 323-332, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the finite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [ 5], Jitter -EDD [ 22], RCSP [ 26], VirtualClock [ 29], PGPS [17, 18, 19, 20], Stop-and-Go <ref> [ 9, 10, 11] </ref>, and Hierarchical Round Robin [ 13]. All of these service disciplines provide an upper bound on end-to-end delay (this includes VirtualClock for which an upper bound on end-to-end delay was unknown until recently proven in [ 7]).
Reference: [12] <author> S. J. Golestani, </author> <title> A Self-Clocked Fair Queueing Scheme for Broadband Applications, </title> <journal> In Pr oceedings of IEEE INFO-COM 94 , pp. </journal> <pages> 636-646, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: However , the Leave-in-T ime service discipline does not conform to the notion of fairness attributed to PGPS. PGPS is called a fair queueing scheme because it closely emulates the service provided by a bit-by-bit round robin server . The reader is referred to <ref> [12] </ref> for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a network setting [2, 3, 15, 24].
Reference: [13] <author> C. Kalmanek, H. Kanakia, and S. </author> <title> Keshav , Rate Controlled Servers for Very HighSpeed Networks, </title> <booktitle> In Proceedings of IEEE GlobeCom 90 , pp. </booktitle> <address> 300.3.1-300.3.9, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: Several rate-based service disciplines have been proposed: DelayEDD [ 5], Jitter -EDD [ 22], RCSP [ 26], VirtualClock [ 29], PGPS [17, 18, 19, 20], Stop-and-Go [ 9, 10, 11], and Hierarchical Round Robin <ref> [ 13] </ref>. All of these service disciplines provide an upper bound on end-to-end delay (this includes VirtualClock for which an upper bound on end-to-end delay was unknown until recently proven in [ 7]). JitterEDD, RCSP, and Stop-and-Go also provide an upper bound on delay jitter. <p> The reader is referred to [25] which compares the delay distribution seen by sessions under FCFS multiplexing with the delay bound computed with Cruzs method [2, 3], the delay bound using Stop-and-Go, and the delay bound using PGPS (presented later in this section). Hierarchical Round Robin (HRR) <ref> [ 13] </ref> also uses a framing strategy and is a nonwork-conserving service discipline. It of fers the same upper bound on delay as Stop-and-Go, but does not guarantee a lower bound on delay . The same arguments in the discussion of Stop-and-Go also apply.
Reference: [14] <author> L. Kleinrock, </author> <title> Queueing Systems, V ol. </title> <address> 1 . New York: </address> <publisher> Wiley, </publisher> <year> 1975. </year>
Reference-contexts: This inequality is a function of the probability distribution of delays of packets of the session in its reference server , i.e. a fi xed rate server, which is wellstudied <ref> [14, 23] </ref>. This inequality says that an upper bound on the probability distribution of delays is obtained by shifting the probability distribution of end-to-end delays of the session in a fi xed-rate server to the right by the constant (see Figure 4).
Reference: [15] <author> J. Kurose, </author> <title> On Computing Per session Performance Bounds in HighSpeed Multi-hop Computer Networks, </title> <booktitle> In ACM Sig-metrics 92 , pp. </booktitle> <pages> 128-139, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The reader is referred to [12] for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a network setting <ref> [2, 3, 15, 24] </ref>. In [ 2, 3], Cruz uses a non-probabilistic approach to characterize each session entering the network - the burstiness constraint , which is in principle very similar to a token bucket filter. <p> Under this assumption, a methodology is proposed to calculate per-session upper bounds on delay and buffer requirements. Kurose in <ref> [ 15] </ref>, and Yaron and Sidi in [ 24] describe methods to calculate bounds on the distribution of delay and buffer occupancy when all sessions entering the network are stochastically bounded. <p> Kurose in [ 15], and Yaron and Sidi in [ 24] describe methods to calculate bounds on the distribution of delay and buffer occupancy when all sessions entering the network are stochastically bounded. The work in <ref> [2, 3, 15, 24] </ref> differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session , while the methodology in [2, 3, 15, 24] provides the upper bound on the delay distribution directly. <p> The work in <ref> [2, 3, 15, 24] </ref> differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session , while the methodology in [2, 3, 15, 24] provides the upper bound on the delay distribution directly. <p> provide this function for sessions with any kind of dynamic traffic behavior, and this function depends only on the session in question, i.e. the dynamic traf fic behavior of other sessions does not enter into consideration (i.e. the Leave-in-T ime service discipline provides isolation between sessions), while the methodology in <ref> [2, 3, 15, 24] </ref> is based on the traffic characterization of all sessions sharing network servers with the session in question, and the dynamic traffic behavior of all sessions enters in the calculation of the delay distribution. 5 Conclusions We have presented the Leave-in-T ime service discipline which provides sessions with
Reference: [16] <author> A. M. Lee, </author> <title> Applied Queueing Theor y . London: </title> <publisher> Macmillan, </publisher> <address> New York: St. </address> <publisher> Martins Press, </publisher> <year> 1966. </year>
Reference-contexts: For this calculation, we need to know the probability distribution of delays of the session in its reference server , which is equivalent to a M/D/1 system in these experiments. We calculated the probability distribution of delays in a M/D/1 system following the results presented in <ref> [16, 21] </ref>. We also show in Figures 9 to 11 the upper bound on the probability distribution which is obtained when we use inequality (16) with the results obtained with a simulation of a fi xed-rate server serving our traf fic.
Reference: [17] <author> A. K. Parekh, </author> <title> A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks, </title> <type> Ph.D. Dissertation, </type> <institution> Massachusetts Institute of Technology , LIDS-TH-2089, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the finite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [ 5], Jitter -EDD [ 22], RCSP [ 26], VirtualClock [ 29], PGPS <ref> [17, 18, 19, 20] </ref>, Stop-and-Go [ 9, 10, 11], and Hierarchical Round Robin [ 13]. All of these service disciplines provide an upper bound on end-to-end delay (this includes VirtualClock for which an upper bound on end-to-end delay was unknown until recently proven in [ 7]). <p> For the special case where Leave-in-Time operates like VirtualClock, we will show that the upper bound on delay for sessions conforming to a token bucket fi lter (also called leaky bucket constrained sessions) is the same as the upper bound on delay given by PGPS <ref> [17, 18, 19, 20] </ref>. PGPS is Parekh and Gallag er s method for computing delay bounds under Weighted Fair Queueing [4]. An important problem we address is that, in general, an upper bound on delay will grow linearly with the connection length. <p> This result is the same as that found using PGPS <ref> [ 17, 18, 19, 20] </ref> (see equation (4.36) in [17], or equation (23) in [19]) and for Leave-in-Time with admission control procedure 1 (which we defi ne later) with one class and , since in this case is zero and . <p> This result is the same as that found using PGPS [ 17, 18, 19, 20] (see equation (4.36) in <ref> [17] </ref>, or equation (23) in [19]) and for Leave-in-Time with admission control procedure 1 (which we defi ne later) with one class and , since in this case is zero and . <p> Weighted Fair Queueing (WFQ) is proposed in [ 4] and is a service discipline that tries to emulate the service provided by a bit-by-bit round robin server. Each packet is stamped with the fi n-ishing round number (or virtual time fi nishing time , as called by Parekh in <ref> [17] </ref>) at which the packet would have fi nished transmission, had the server been doing a bit-by-bit round robin. Packets are served in increasing order of fi nishing round number . <p> Packets are served in increasing order of fi nishing round number . Packet-by-Packet Generalized Processor Sharing (PGPS) is the name given in <ref> [17, 18, 19, 20] </ref> to a method for computing delay bounds 2. Propagation delay is not considered here since it increases the delay by the same amount for both disciplines.
Reference: [18] <author> A. K. Parekh, and G. </author> <title> Gallager , A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks The Single Node Case, </title> <booktitle> In Proceedings of IEEE INFOCOM 92 , Vol. </booktitle> <volume> 2, </volume> <pages> pp. 915-924, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the finite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [ 5], Jitter -EDD [ 22], RCSP [ 26], VirtualClock [ 29], PGPS <ref> [17, 18, 19, 20] </ref>, Stop-and-Go [ 9, 10, 11], and Hierarchical Round Robin [ 13]. All of these service disciplines provide an upper bound on end-to-end delay (this includes VirtualClock for which an upper bound on end-to-end delay was unknown until recently proven in [ 7]). <p> For the special case where Leave-in-Time operates like VirtualClock, we will show that the upper bound on delay for sessions conforming to a token bucket fi lter (also called leaky bucket constrained sessions) is the same as the upper bound on delay given by PGPS <ref> [17, 18, 19, 20] </ref>. PGPS is Parekh and Gallag er s method for computing delay bounds under Weighted Fair Queueing [4]. An important problem we address is that, in general, an upper bound on delay will grow linearly with the connection length. <p> This result is the same as that found using PGPS <ref> [ 17, 18, 19, 20] </ref> (see equation (4.36) in [17], or equation (23) in [19]) and for Leave-in-Time with admission control procedure 1 (which we defi ne later) with one class and , since in this case is zero and . <p> Packets are served in increasing order of fi nishing round number . Packet-by-Packet Generalized Processor Sharing (PGPS) is the name given in <ref> [17, 18, 19, 20] </ref> to a method for computing delay bounds 2. Propagation delay is not considered here since it increases the delay by the same amount for both disciplines.
Reference: [19] <author> A. K. Parekh, and G. </author> <title> Gallager , A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks The Multiple Node Case, </title> <booktitle> In Pr oceedings of IEEE INFOCOM 93 , Vol. </booktitle> <volume> 2, </volume> <pages> pp. 521-530, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the finite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [ 5], Jitter -EDD [ 22], RCSP [ 26], VirtualClock [ 29], PGPS <ref> [17, 18, 19, 20] </ref>, Stop-and-Go [ 9, 10, 11], and Hierarchical Round Robin [ 13]. All of these service disciplines provide an upper bound on end-to-end delay (this includes VirtualClock for which an upper bound on end-to-end delay was unknown until recently proven in [ 7]). <p> For the special case where Leave-in-Time operates like VirtualClock, we will show that the upper bound on delay for sessions conforming to a token bucket fi lter (also called leaky bucket constrained sessions) is the same as the upper bound on delay given by PGPS <ref> [17, 18, 19, 20] </ref>. PGPS is Parekh and Gallag er s method for computing delay bounds under Weighted Fair Queueing [4]. An important problem we address is that, in general, an upper bound on delay will grow linearly with the connection length. <p> This result is the same as that found using PGPS <ref> [ 17, 18, 19, 20] </ref> (see equation (4.36) in [17], or equation (23) in [19]) and for Leave-in-Time with admission control procedure 1 (which we defi ne later) with one class and , since in this case is zero and . <p> This result is the same as that found using PGPS [ 17, 18, 19, 20] (see equation (4.36) in [17], or equation (23) in <ref> [19] </ref>) and for Leave-in-Time with admission control procedure 1 (which we defi ne later) with one class and , since in this case is zero and . <p> Packets are served in increasing order of fi nishing round number . Packet-by-Packet Generalized Processor Sharing (PGPS) is the name given in <ref> [17, 18, 19, 20] </ref> to a method for computing delay bounds 2. Propagation delay is not considered here since it increases the delay by the same amount for both disciplines.
Reference: [20] <author> A. K. Parekh, and G. </author> <title> Gallager , A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks: The Single-Node Case, </title> <journal> In IEEE/ACM T ransac-tions on Networking , Vol. </journal> <volume> 1, No. 3, </volume> <pages> pp. 344-357, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the finite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [ 5], Jitter -EDD [ 22], RCSP [ 26], VirtualClock [ 29], PGPS <ref> [17, 18, 19, 20] </ref>, Stop-and-Go [ 9, 10, 11], and Hierarchical Round Robin [ 13]. All of these service disciplines provide an upper bound on end-to-end delay (this includes VirtualClock for which an upper bound on end-to-end delay was unknown until recently proven in [ 7]). <p> For the special case where Leave-in-Time operates like VirtualClock, we will show that the upper bound on delay for sessions conforming to a token bucket fi lter (also called leaky bucket constrained sessions) is the same as the upper bound on delay given by PGPS <ref> [17, 18, 19, 20] </ref>. PGPS is Parekh and Gallag er s method for computing delay bounds under Weighted Fair Queueing [4]. An important problem we address is that, in general, an upper bound on delay will grow linearly with the connection length. <p> This result is the same as that found using PGPS <ref> [ 17, 18, 19, 20] </ref> (see equation (4.36) in [17], or equation (23) in [19]) and for Leave-in-Time with admission control procedure 1 (which we defi ne later) with one class and , since in this case is zero and . <p> Packets are served in increasing order of fi nishing round number . Packet-by-Packet Generalized Processor Sharing (PGPS) is the name given in <ref> [17, 18, 19, 20] </ref> to a method for computing delay bounds 2. Propagation delay is not considered here since it increases the delay by the same amount for both disciplines.
Reference: [21] <author> J. R. Shelton, </author> <title> Solution Methods for Waiting Line Problems, </title> <journal> Journal of Industrial Engineering , pp. </journal> <pages> 293-303, </pages> <month> July-August </month> <year> 1960. </year>
Reference-contexts: For this calculation, we need to know the probability distribution of delays of the session in its reference server , which is equivalent to a M/D/1 system in these experiments. We calculated the probability distribution of delays in a M/D/1 system following the results presented in <ref> [16, 21] </ref>. We also show in Figures 9 to 11 the upper bound on the probability distribution which is obtained when we use inequality (16) with the results obtained with a simulation of a fi xed-rate server serving our traf fic.
Reference: [22] <author> D. Verma, H. Zhang, and D. Ferrari, </author> <title> Delay Jitter Control for Real-Time Communication in a Packet Switching Network, </title> <booktitle> In Proceedings of IEEE TriCom 91 , pp. </booktitle> <pages> 35-43, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the finite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [ 5], Jitter -EDD <ref> [ 22] </ref>, RCSP [ 26], VirtualClock [ 29], PGPS [17, 18, 19, 20], Stop-and-Go [ 9, 10, 11], and Hierarchical Round Robin [ 13]. <p> Thus, a session can know what its performance bounds will be based on how it and it alone behaves. Leave-in-Time builds on ideas found in VirtualClock [29] and JitterEDD <ref> [ 22] </ref>. The reader will see that Leave-in-T ime exploits the good properties of VirtualClock and Jitter -EDD while maintaining ef ficiency and exibility, and providing desirable perfor - mance bounds. <p> The nonwork-conserving service discipline has two components (see Figure 2): a set of delay regulators that hold packets until their eligibility times, and a server transmission queue. The use of delay regulators to shape the traf fic pattern to reduce delay jitter is based on Jitter -EDD <ref> [ 22] </ref>. A session desiring delay jitter control (i.e. delay jitter reduction) is assigned a delay regulator . A session not desiring delay jitter control has all of its packets sent directly to the server queue upon arrival, i.e. the eligibility time equals the arrival time. <p> As in Jitter -EDD <ref> [22] </ref>, the holding time Session Traffic Input Session Traffic Output calculated at server node - 1 is transmitted in the packet s header to node . Note that is always positive, and that (both proven in [ 8]). <p> Upper Bound on End-to-End Delay Jitter Define the end-to-end delay jitter of session traversing servers 1 to as the maximum dif ference between the delays experienced by any two packets from session (this is the same definition as the one used in <ref> [ 22] </ref>). This definition implies that must be finite (i.e. the session has an upper bound on end toend delay). <p> This problem does not occur in admission control procedure 1. 4 Comparing Leave-in-Time to Other Schemes Leave-in-Time is most related to VirtualClock [29] and Jitter-EDD <ref> [22] </ref>. In VirtualClock, each packet is assigned a transmission deadline and packets are served in increasing order of deadline. The transmission deadlines are calculated by an equation equivalent to equation (2). <p> Except for the upper bound on end-to-end delay (presented in [ 7]), these results are new for the VirtualClock service discipline. In DelayEDD [ 5], and its extension Jitter -EDD <ref> [ 22] </ref> (EDD stands for earliest-due-date), packets are assigned deadlines and transmitted in order of increasing deadline. The deadline of a packet is not directly coupled to the reserved bandwidth of its session as in the Leave-in-T ime scheme (see equation (11)).
Reference: [23] <author> R. W. Wolff, </author> <title> Stochastic Modelling and the Theory of Queues. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: This inequality is a function of the probability distribution of delays of packets of the session in its reference server , i.e. a fi xed rate server, which is wellstudied <ref> [14, 23] </ref>. This inequality says that an upper bound on the probability distribution of delays is obtained by shifting the probability distribution of end-to-end delays of the session in a fi xed-rate server to the right by the constant (see Figure 4).
Reference: [24] <author> O. Yaron and M. Sidi, </author> <title> Calculating Performance Bounds in Communication Networks, </title> <journal> In Pr oceedings of IEEE INFO-COM 93 , Vol. </journal> <volume> 2, </volume> <pages> pp. 539-545, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: The reader is referred to [12] for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a network setting <ref> [2, 3, 15, 24] </ref>. In [ 2, 3], Cruz uses a non-probabilistic approach to characterize each session entering the network - the burstiness constraint , which is in principle very similar to a token bucket filter. <p> Under this assumption, a methodology is proposed to calculate per-session upper bounds on delay and buffer requirements. Kurose in [ 15], and Yaron and Sidi in <ref> [ 24] </ref> describe methods to calculate bounds on the distribution of delay and buffer occupancy when all sessions entering the network are stochastically bounded. <p> Kurose in [ 15], and Yaron and Sidi in [ 24] describe methods to calculate bounds on the distribution of delay and buffer occupancy when all sessions entering the network are stochastically bounded. The work in <ref> [2, 3, 15, 24] </ref> differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session , while the methodology in [2, 3, 15, 24] provides the upper bound on the delay distribution directly. <p> The work in <ref> [2, 3, 15, 24] </ref> differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session , while the methodology in [2, 3, 15, 24] provides the upper bound on the delay distribution directly. <p> provide this function for sessions with any kind of dynamic traffic behavior, and this function depends only on the session in question, i.e. the dynamic traf fic behavior of other sessions does not enter into consideration (i.e. the Leave-in-T ime service discipline provides isolation between sessions), while the methodology in <ref> [2, 3, 15, 24] </ref> is based on the traffic characterization of all sessions sharing network servers with the session in question, and the dynamic traffic behavior of all sessions enters in the calculation of the delay distribution. 5 Conclusions We have presented the Leave-in-T ime service discipline which provides sessions with
Reference: [25] <author> D. Yates, J. Kurose, D. Towsley, and M. G. Hluchyj, </author> <title> On Per-session End-to-End Delay Distributions and The Call Admission Problem for Real-Time Applications with QOS Requirements, </title> <note> In Pr oceedings of ACM SIGCOMM 93 September 1993. </note>
Reference-contexts: Traffic Source Models In this work, we chose three kinds of traf fic sources to exemplify the performance guarantees of a Leave-in-T ime network: ON-OFF, Poisson, and Deterministic (i.e. fi xed packet rate source model) sources. ON-OFF sources have been used extensively in recent studies <ref> [ 25, 29] </ref>, since they can be used to model standard voice sources. Poisson sources are used in our simulations to examine the fi rewall property of Leave-in-T ime, i.e. that the ser - vice guarantees of a session are independent of the behavior of other sessions traversing the network. <p> These values are the same as the ones used in <ref> [ 25] </ref>. In our simulations, = 13.25ms, which implies that the generation rate is 32kbits/s in the ON state (since the packet length is 424bits). All ON-OFF ses sions reserve a rate of 32kbits/s in the network. <p> The delay jitter bound provided by the Leave-in-T ime scheme is (inequality (17)), while in Stop-and-Go it is 2 )-smooth session con forms to a token bucket filter ( ). Thus, from (14), , which is competitive with the result of Stop-and-Go. The reader is referred to <ref> [25] </ref> which compares the delay distribution seen by sessions under FCFS multiplexing with the delay bound computed with Cruzs method [2, 3], the delay bound using Stop-and-Go, and the delay bound using PGPS (presented later in this section).
Reference: [26] <author> H. Zhang and D. Ferrari, </author> <title> Rate-Controlled Static-Priority Queueing, </title> <booktitle> In Proceedings of IEEE INFOCOM 93 236, </booktitle> <month> March </month> <year> 1993. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the finite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [ 5], Jitter -EDD [ 22], RCSP <ref> [ 26] </ref>, VirtualClock [ 29], PGPS [17, 18, 19, 20], Stop-and-Go [ 9, 10, 11], and Hierarchical Round Robin [ 13]. <p> The traf fic characterization specifi es a minimum packet interar - rival time , a minimum average packet interarrival time over an averaging interval of time , and a maximum packet length . In <ref> [ 26] </ref>, bandwidth is reserved at the peak rate implied by This admission control is refi ned in [27], where both are taken into consideration. <p> It of fers the same upper bound on delay as Stop-and-Go, but does not guarantee a lower bound on delay . The same arguments in the discussion of Stop-and-Go also apply. Rate-Controlled Static-Priority Queueing (RCSP) <ref> [ 26] </ref> is a service discipline that avoids both framing strategies (as in Stop and-Go and HRR) and sorted priority queues (that are used in all the other service disciplines studied here), by the separation of rate-control and delay-control in the design of the server , which allows it to provide
Reference: [27] <author> H. Zhang and D. Ferrari, </author> <title> Improving Utilization for Deter - ministic Service in Multimedia Communication, </title> <booktitle> In Proceedings of the International Confer ence on Multimedia Computing and Systems , pp. </booktitle> <pages> 295-304, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: In [ 26], bandwidth is reserved at the peak rate implied by This admission control is refi ned in <ref> [27] </ref>, where both are taken into consideration.
Reference: [28] <author> H. Zhang and S. Keshav, </author> <title> Comparison of Rate-Based Service Disciplines, </title> <booktitle> In Pr oceedings of ACM SIGCOMM 91 113-121, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: First Generalization : The base algorithm is generalized by allowing it to work in a nonwork-conserving mode. Nonwork-conserving service disciplines can generally provide lower variance in delay (or delay jitter) than with work-conserving ones <ref> [28] </ref>. Thus, packets are not necessarily immediately available for transmission upon arrival, and thus arrived packets may be delayed before being queued for transmission. The time a packet joins the server transmission queue is called the eligibility time packet. <p> This leads to a schedulability test at connection establishment time [ 5] to avoid scheduling saturation, which can occur even if bandwidth is not overbooked <ref> [5, 28] </ref>. The schedulability test is then a compro mise on the looser coupling between reserved rate and delay bound. The Leave-in-T ime scheme needs an admission control procedure for the same reason.
Reference: [29] <author> L. Zhang, V irtualClock: </author> <title> A New Traffic Control Algorithm for Packet Switching Networks, </title> <journal> In ACM T ransactions on Computer Systems , Vol. </journal> <volume> 9, No. 2, </volume> <pages> pp. 101-124, </pages> <month> May </month> <year> 1991. </year> <note> Also in Proceedings of ACM SIGCOMM 90 , pp. 19-29, Sep-tember 1990. </note>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the finite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [ 5], Jitter -EDD [ 22], RCSP [ 26], VirtualClock <ref> [ 29] </ref>, PGPS [17, 18, 19, 20], Stop-and-Go [ 9, 10, 11], and Hierarchical Round Robin [ 13]. All of these service disciplines provide an upper bound on end-to-end delay (this includes VirtualClock for which an upper bound on end-to-end delay was unknown until recently proven in [ 7]). <p> Thus, a session can know what its performance bounds will be based on how it and it alone behaves. Leave-in-Time builds on ideas found in VirtualClock <ref> [29] </ref> and JitterEDD [ 22]. The reader will see that Leave-in-T ime exploits the good properties of VirtualClock and Jitter -EDD while maintaining ef ficiency and exibility, and providing desirable perfor - mance bounds. <p> Traffic Source Models In this work, we chose three kinds of traf fic sources to exemplify the performance guarantees of a Leave-in-T ime network: ON-OFF, Poisson, and Deterministic (i.e. fi xed packet rate source model) sources. ON-OFF sources have been used extensively in recent studies <ref> [ 25, 29] </ref>, since they can be used to model standard voice sources. Poisson sources are used in our simulations to examine the fi rewall property of Leave-in-T ime, i.e. that the ser - vice guarantees of a session are independent of the behavior of other sessions traversing the network. <p> This problem does not occur in admission control procedure 1. 4 Comparing Leave-in-Time to Other Schemes Leave-in-Time is most related to VirtualClock <ref> [29] </ref> and Jitter-EDD [22]. In VirtualClock, each packet is assigned a transmission deadline and packets are served in increasing order of deadline. The transmission deadlines are calculated by an equation equivalent to equation (2).
References-found: 29

