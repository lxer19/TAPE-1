URL: ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/craven.ijcai-wkshp95.ps
Refering-URL: http://www.cs.wisc.edu/~shavlik/abstracts/craven.ijcai-wkshp95.ps.abstract.html
Root-URL: 
Email: email: fcraven, shavlikg@cs.wisc.edu  
Phone: phone: +1 (608) 263-0475  
Title: Extracting Comprehensible Concept Representations from Trained Neural Networks  
Author: Mark W. Craven Jude W. Shavlik 
Address: 1210 West Dayton St. Madison, Wisconsin 53706 U.S.A.  
Affiliation: Computer Sciences Department University of Wisconsin  
Note: Appears in the working notes of the IJCAI '95 Workshop on Comprehensibility in Machine Learning.  
Abstract: Although they are applicable to a wide array of problems, and have demonstrated good performance on a number of difficult, real-world tasks, neural networks are not usually applied to problems in which comprehensibility of the acquired concepts is important. The concept representations formed by neural networks are hard to understand because they typically involve distributed, nonlinear relationships encoded by a large number of real-valued parameters. To address this limitation, we have been developing algorithms for extracting "symbolic" concept representations from trained neural networks. We first discuss why it is important to be able to understand the concept representations formed by neural networks. We then briefly describe our approach and discuss a number of issues pertaining to comprehensibility that have arisen in our work. Finally, we discuss choices that we have made in our research to date, and open research issues that we have not yet addressed. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Alexander, J. A. & Mozer, M. C. </author> <year> (1995). </year> <title> Template-based algorithms for connectionist rule extraction. </title> <editor> In Tesauro, G., Touretzky, D., & Leen, T., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 7). </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Atlas, L., Cole, R., Connor, J., El-Sharkawi, M., Marks II, R. J., Muthusamy, Y., & Barnard, E. </author> <year> (1989). </year> <title> Performance comparisons between backpropagation networks and classification trees on three real-world applications. </title> <editor> In Touretzky, D., editor, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 2), </booktitle> <pages> (pp. 622-629), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Blum, A., Furst, M., Jackson, J., Kearns, M., Mansour, Y., & Rudich, S. </author> <year> (1994). </year> <title> Weakly learning DNF and characterizing statistical query learning using fourier analysis. </title> <booktitle> In Proceedings of the Twenty-sixth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> (pp. 253-262), </pages> <address> Montreal, Canada. </address> <publisher> ACM Press. </publisher>
Reference-contexts: We are currently investigating the applicability of algorithms developed in the computational learning theory community to this task <ref> (Blum et al., 1994) </ref>. The potential benefit of using simple perceptrons to describe trained multi-layer networks is that they may, in some cases, be more comprehensible than their equivalent decision trees.
Reference: <author> Breiman, L., Friedman, J. H., Olshen, R. A., & Stone, C. J. </author> <year> (1984). </year> <title> Classification and Regression Trees. </title> <publisher> Wadsworth and Brooks, </publisher> <address> Monterey, CA. </address>
Reference-contexts: Trepan is similar to conventional decision-tree induction algorithms, such as CART <ref> (Breiman et al., 1984) </ref>, ID3 (Quinlan, 1986), C4.5 (Quinlan, 1993), and ID2-of-3 (Murphy & Pazzani, 1991), which learn directly from a training set. These algorithms build decision trees by recursively partitioning the input space.
Reference: <author> Buntine, W. & Niblett, T. </author> <year> (1992). </year> <title> A further comparison of splitting rules for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 8 </volume> <pages> 75-86. </pages>
Reference: <author> Calder, B., Grunwald, D., Lindsay, D., Martin, J., Mozer, M., & Zorn, B. </author> <year> (1995). </year> <title> Corpus-based static branch prediction. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> (pp. 18-21), </pages> <address> La Jolla, CA. </address>
Reference-contexts: We do not have the resources to conduct the large-scale psychological experiment that would 10 be needed to objectively measure the comprehensibility of our representations. However, we do plan to work with experts in some of our problem domains <ref> (e.g., branch prediction in compilers, Calder et al., 1995) </ref> in order to assess how comprehensible they find the representations produced by our algorithms. * Dialogue vs. one-shot processes: Some work has cast the explanation problem not as a "one-shot" process, but instead as a dialogue between system and user.
Reference: <author> Cleeremans, A., Servan-Schreiber, D., & McClelland, J. </author> <year> (1989). </year> <title> Finite state automata and simple recurrent networks. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 372-381. </pages>
Reference: <author> Craven, M. W. & Shavlik, J. W. </author> <year> (1992). </year> <title> Visualizing learning and computation in artificial neural networks. </title> <journal> International Journal on Artificial Intelligence Tools, </journal> <volume> 1(2) </volume> <pages> 399-425. </pages> <note> 12 Craven, </note> <author> M. W. & Shavlik, J. W. </author> <year> (1993a). </year> <title> Learning symbolic rules using artificial neural networks. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> (pp. 73-80), </pages> <address> Amherst, MA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: methods: the weights and magnitudes of a network's connections (Hinton, 1986; Wejchert & Tesauro, 1989; Craven & Shavlik, 1992); the decision boundaries formed by units in a network (Lang & Witbrock, 1988; Munro, 1991; Pratt et al., 1991); unit activations and the forward propagation of activation signals through the network <ref> (Craven & Shavlik, 1992) </ref>; the backward propagation of error signals during learning (Craven & Shavlik, 1992); and the trajectory of units in weight space during learning (Wejchert & Tesauro, 1989). <p> & Tesauro, 1989; Craven & Shavlik, 1992); the decision boundaries formed by units in a network (Lang & Witbrock, 1988; Munro, 1991; Pratt et al., 1991); unit activations and the forward propagation of activation signals through the network <ref> (Craven & Shavlik, 1992) </ref>; the backward propagation of error signals during learning (Craven & Shavlik, 1992); and the trajectory of units in weight space during learning (Wejchert & Tesauro, 1989). Although visualization methods can provide insight into the learning and prediction behavior of a network, they are not a substitute for extraction methods.
Reference: <author> Craven, M. W. & Shavlik, J. W. </author> <year> (1993b). </year> <title> Learning to predict reading frames in E. coli DNA sequences. </title> <booktitle> In Proceedings of the 26th Hawaii International Conference on System Sciences, </booktitle> <pages> (pp. 773-782), </pages> <address> Wailea, HI. </address> <publisher> IEEE Press. </publisher>
Reference-contexts: well they generalize. 6 Table 2: Test-set accuracy. domain method networks C4.5 ID2-of-3 Trepan voting 91.5% 89.2% 86.9 92.2% protein coding 93.7 88.7 91.1 91.7 promoters 90.6 84.4 83.8 86.5 We evaluate Trepan using three real world domains: Congressional voting (Schlimmer & Fisher, 1986), recognition of protein-coding regions in DNA <ref> (Craven & Shavlik, 1993b) </ref>, and recognition of promoters in DNA (Towell et al., 1990). The voting domain has 15 Boolean features and two output categories. Following Buntine and Niblett (1992), we remove the physician-fee-freeze feature to make the problem more difficult.
Reference: <author> Craven, M. W. & Shavlik, J. W. </author> <year> (1993c). </year> <title> Learning to represent codons: A challenge problem for constructive induction. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 1319-1324), </pages> <address> Chambery, France. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Craven, M. W. & Shavlik, J. W. </author> <year> (1994). </year> <title> Using sampling and queries to extract rules from trained neural networks. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> (pp. 37-45), </pages> <address> New Brunswick, NJ. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Craven, M. W. & Shavlik, J. W. </author> <year> (1995). </year> <title> Extracting tree-structured representations of trained networks. </title> <note> Submitted for publication. </note>
Reference: <author> Das, S. & Mozer, M. </author> <year> (1994). </year> <title> A unified gradient-descent/clustering architecture for finite state machine induction. </title> <editor> In Cowan, J., Tesauro, G., & Alspector, J., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 6). </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Elman, J. L. </author> <year> (1989). </year> <title> Representation and structure in connectionist models. </title> <type> Technical Report 8903, </type> <institution> Center for Research in Language, University of California, </institution> <address> San Diego. </address>
Reference: <author> Fisher, D. H. & McKusick, K. B. </author> <year> (1989). </year> <title> An empirical comparison of ID3 and back-propagation. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 788-793), </pages> <address> Detroit, MI. </address>
Reference: <author> Flann, N. S. & Dietterich, T. G. </author> <year> (1986). </year> <title> Selecting appropriate representations for learning from examples. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> (pp. 460-466), </pages> <address> Philadelphia, PA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Fu, L. </author> <year> (1991). </year> <title> Rule learning by searching on adapted nets. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> (pp. 590-595), </pages> <address> Anaheim, CA. </address> <publisher> AAAI/MIT Press. </publisher>
Reference: <author> Gallant, S. I. </author> <year> (1993). </year> <title> Neural Network Learning and Expert Systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: In some domains, it is not necessary to have a holistic description of the learning system's concept representation, but it is desirable to be able to explain classifications of individual input patterns <ref> (Gallant, 1993) </ref>. If the concept representation is understandable in such a domain, then explanations of classifications made on a particular cases can be garnered. * Improving generalization.
Reference: <author> Giles, C. L., Miller, C. B., Chen, D., Chen, H. H., Sun, G. Z., & Lee, Y. C. </author> <year> (1992). </year> <title> Learning and extracting finite state automata with second-order recurrent neural networks. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 393-405. </pages>
Reference: <author> Gorman, R. P. & Sejnowski, T. J. </author> <year> (1988). </year> <title> Analysis of hidden units in a layered network trained to classify sonar targets. </title> <booktitle> Neural Networks, </booktitle> <volume> 1 </volume> <pages> 75-89. </pages>
Reference-contexts: A number of statistical techniques have been used to characterize the activity of the hidden units in neural networks. These methods include: hierarchical clustering of hidden-unit activations (Sejnowski & Rosenberg, 1987; Elman, 1989; Hanson & Burr, 1990), contribution analysis (Sanger, 1989), and weight pattern analysis <ref> (Gorman & Sejnowski, 1988) </ref>. Like visualization techniques, these hidden-unit analysis methods are limited in that they do not provide complete descriptions of the concepts learned by networks.
Reference: <author> Hanson, S. J. & Burr, D. J. </author> <year> (1990). </year> <title> What connectionist models learn: Learning and representation in connectionist networks. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 13 </volume> <pages> 471-518. </pages>
Reference: <author> Hayashi, Y. </author> <year> (1990). </year> <title> A neural expert system with automated extraction of fuzzy if-then rules. </title> <booktitle> In Advances in Neural Information Processing Systems (volume 3), </booktitle> <pages> (pp. 578-584), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Hinton, G. E. </author> <year> (1986). </year> <title> Learning distributed representations of concepts. </title> <booktitle> In Proceedings of the Eighth Annual Conference of the Cognitive Science Society, </booktitle> <pages> (pp. 1-12), </pages> <address> Amherst, MA. </address> <publisher> Erlbaum. </publisher>
Reference-contexts: Moreover, in multi-layer networks, these parameters may represent nonlinear, nonmonotonic relationships between the input features and the output categories. Although hidden units in multi-layer networks can be thought of as representing "constructed" features, they are difficult to understand themselves because networks commonly learn distributed representations <ref> (Hinton, 1986) </ref>. In a distributed representation, each meaningful concept is encoded by the activations of many hidden units, and each hidden unit plays a part in representing many different concepts.
Reference: <author> Hunter, L. & Klein, T. </author> <year> (1993). </year> <title> Finding relevant biomolecular features. </title> <booktitle> In Proceedings of the First International Conference on Intelligent Systems for Molecular Biology, </booktitle> <pages> (pp. 190-197), </pages> <address> Bethesda, MD. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: A system may discover salient features and relationships in the input data whose importance was not previously recognized. If the representations formed by the learner are comprehensible, then these discoveries can be made accessible to human review <ref> (e.g., Hunter & Klein, 1993) </ref>. * Explanation. In some domains, it is not necessary to have a holistic description of the learning system's concept representation, but it is desirable to be able to explain classifications of individual input patterns (Gallant, 1993).
Reference: <author> Jordan, M. </author> <year> (1986). </year> <title> Serial order: A parallel distributed processing approach. </title> <type> Technical Report 8604, </type> <institution> University of California, Institute for Cognitive Science, </institution> <address> San Diego. </address>
Reference: <author> Kramer, A. H. & Sangiovanni-Vincentelli, A. </author> <year> (1989). </year> <title> Efficient parallel learning algorithms for neural networks. </title> <editor> In Touretzky, D., editor, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 1). </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: The number of hidden units used for each network is chosen using cross validation on the network's training set. For each training set, we perform cross-validation runs using 0, 5, 10, 20 and 40 hidden units. The networks are trained using a conjugate-gradient learning method <ref> (Kramer & Sangiovanni-Vincentelli, 1989) </ref>. Training continues until either (i) all of the training-set examples are correctly classified, (ii) a local minimum in the error surface is reached, or (iii) 100 search directions have been tried.
Reference: <author> Lang, K. J. & Witbrock, M. J. </author> <year> (1988). </year> <title> Learning to tell two spirals apart. </title> <booktitle> In Proceedings of the 1988 Connectionist Models Summer School, </booktitle> <pages> (pp. 52-59). </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> McMillan, C., Mozer, M. C., & Smolensky, P. </author> <year> (1992). </year> <title> Rule induction through integrated symbolic and subsymbolic processing. </title> <editor> In Moody, J., Hanson, S., & Lippmann, R., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 4). </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Medin, D. L., Wattenmaker, W. D., & Michalski, R. S. </author> <year> (1987). </year> <title> Constraints and preferences in inductive learning: An experimental study of human and machine performance. </title> <journal> Cognitive Science, </journal> <volume> 11 </volume> <pages> 299-339. </pages>
Reference: <author> Michalski, R. S. </author> <year> (1983). </year> <title> A theory and methodology of inductive learning. </title> <journal> Artificial Intelligence, </journal> <volume> 20 </volume> <pages> 111-161. </pages> <note> 13 Mitchell, </note> <author> T., Caruana, R., Freitag, D., McDermott, J., & Zabowski, D. </author> <year> (1994). </year> <title> Experience with a learning personal assistant. </title> <journal> Communications of the ACM, </journal> <volume> 37(7) </volume> <pages> 80-91. </pages>
Reference-contexts: for future investigation is to design an algorithm that is able to transform extracted concept descriptions into simpler, though perhaps less faithful and accurate, representations. * Numeric representations: As mentioned previously, our research has focused on producing concept descriptions like those formed by common symbolic learning algorithms such as AQ <ref> (Michalski, 1983) </ref> and C4.5 (Quinlan, 1993). However, we also plan to investigate the utility of concept representations that use numeric weights to represent the strength of relationships. Specifically, we plan to consider the representation of simple perceptrons that have attributes and combinations of attributes as inputs.
Reference: <author> Moore, J. D. & Swartout, W. R. </author> <year> (1989). </year> <title> A reactive approach to explanation. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 1504-1510), </pages> <address> Detroit, MI. </address>
Reference: <author> Munro, P. </author> <year> (1991). </year> <title> Visualizations of 2-D hidden unit space. </title> <type> Technical Report LIS035/IS91003, </type> <institution> School of Library and Information Science, University of Pittsburgh, </institution> <address> Pittsburgh, PA. </address>
Reference: <author> Murphy, P. M. & Pazzani, M. J. </author> <year> (1991). </year> <title> ID2-of-3: Constructive induction of M-of-N concepts for discriminators in decision trees. </title> <booktitle> In Proceedings of the Eighth International Machine Learning Workshop, </booktitle> <pages> (pp. 183-187), </pages> <address> Evanston, IL. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Trepan is similar to conventional decision-tree induction algorithms, such as CART (Breiman et al., 1984), ID3 (Quinlan, 1986), C4.5 (Quinlan, 1993), and ID2-of-3 <ref> (Murphy & Pazzani, 1991) </ref>, which learn directly from a training set. These algorithms build decision trees by recursively partitioning the input space. Each internal node in such a tree represents a partition of some part of the input space, and each leaf represents a predicted class. <p> The selected binary split serves as seed for the search process. The search uses information gain as its heuristic evaluation function, and uses the two following operators <ref> (Murphy & Pazzani, 1991) </ref>: * m-of-n+1 : Add a new value to the set, and hold the threshold constant. For example, 2-of-fa; bg =) 2-of-fa; b; cg. * m+1-of-n+1: Add a new value to the set, and increment the threshold.
Reference: <author> Musick, R., Catlett, J., & Russell, S. </author> <year> (1993). </year> <title> Decision theoretic subsampling for induction on large databases. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> (pp. 212-219), </pages> <address> Amherst, MA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Currently, our algorithm chooses a split after considering at least S min examples, where S min is a parameter of the algorithm. Although it is possible to use a statistical test for this decision <ref> (Musick et al., 1993) </ref>, it is not clear that the computation involved in estimating the relevant statistic is worth the effort, since each split-selection step is only a locally 5 optimal decision.
Reference: <author> Neisser, U. & Weene, P. </author> <year> (1962). </year> <title> Hierarchies in concept attainment. </title> <journal> Journal of Experimental Psychology, </journal> <volume> 64 </volume> <pages> 640-645. </pages>
Reference: <author> Ourston, D. & Mooney, R. </author> <year> (1994). </year> <title> Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66(2) </volume> <pages> 273-309. </pages>
Reference: <author> Paris, C. </author> <year> (1987). </year> <title> Combining discourse strategies to generate descriptions to users along a naive/expert spectrum. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 626-632), </pages> <address> Milan, Italy. </address>
Reference: <author> Pazzani, M. & Kibler, D. </author> <year> (1992). </year> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9(1) </volume> <pages> 57-94. </pages>
Reference: <author> Pineda, F. J. </author> <year> (1987). </year> <title> Generalization of back-propagation to recurrent neural networks. </title> <journal> Physical Review Letters, </journal> <volume> 59 </volume> <pages> 2229-2232. </pages>
Reference: <author> Pinker, S. </author> <year> (1979). </year> <title> Formal models of language learning. </title> <journal> Cognition, </journal> <volume> 7 </volume> <pages> 217-283. </pages>
Reference: <author> Pollack, J. </author> <year> (1991). </year> <title> The induction of dynamical recognizers. </title> <journal> Machine Learning, </journal> <volume> 7 </volume> <pages> 227-252. </pages>
Reference: <author> Pomerleau, D. A. </author> <year> (1991). </year> <title> Efficient training of artificial neural networks for autonomous navigation. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 88-97. </pages>
Reference: <author> Pratt, L. Y., Mostow, J., & Kamm, C. A. </author> <year> (1991). </year> <title> Direct transfer of learned information among neural networks. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> (pp. 584-589), </pages> <address> Anaheim, CA. </address> <publisher> AAAI/MIT Press. </publisher>
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106. </pages>
Reference-contexts: Trepan is similar to conventional decision-tree induction algorithms, such as CART (Breiman et al., 1984), ID3 <ref> (Quinlan, 1986) </ref>, C4.5 (Quinlan, 1993), and ID2-of-3 (Murphy & Pazzani, 1991), which learn directly from a training set. These algorithms build decision trees by recursively partitioning the input space. <p> Note that any example must satisfy these constraints in order to reach the current node. Like the ID2-of-3 algorithm, Trepan uses a heuristic search process to construct its M-of-N splits. The search process begins by first selecting the best binary split at the current node; Trepan uses information gain <ref> (Quinlan, 1986) </ref> to evaluate candidate splits. For two-valued features, a binary split separates examples according to their values for the feature. For features with more than two values, we consider binary splits based on each allowable value of the feature (e.g., color=red?, color=blue?, ...).
Reference: <author> Quinlan, J. R. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: Trepan is similar to conventional decision-tree induction algorithms, such as CART (Breiman et al., 1984), ID3 (Quinlan, 1986), C4.5 <ref> (Quinlan, 1993) </ref>, and ID2-of-3 (Murphy & Pazzani, 1991), which learn directly from a training set. These algorithms build decision trees by recursively partitioning the input space. Each internal node in such a tree represents a partition of some part of the input space, and each leaf represents a predicted class. <p> As baselines for comparison, we also run Quinlan's C4.5 algorithm <ref> (Quinlan, 1993) </ref>, and Murphy and Pazzani's ID2-of-3 algorithm (1991) on the same testbeds. Recall that ID2-of-3 is similar to C4.5, except that it learns trees that use M-of-N splits. C4.5 avoids overfitting by pruning decision trees after they have been grown. <p> to design an algorithm that is able to transform extracted concept descriptions into simpler, though perhaps less faithful and accurate, representations. * Numeric representations: As mentioned previously, our research has focused on producing concept descriptions like those formed by common symbolic learning algorithms such as AQ (Michalski, 1983) and C4.5 <ref> (Quinlan, 1993) </ref>. However, we also plan to investigate the utility of concept representations that use numeric weights to represent the strength of relationships. Specifically, we plan to consider the representation of simple perceptrons that have attributes and combinations of attributes as inputs.
Reference: <author> Rice, J. A. </author> <year> (1995). </year> <title> Mathematical Statistics and Data Analysis. </title> <publisher> Wadsworth, </publisher> <address> Belmont, CA. </address>
Reference-contexts: If necessary, the oracle is queried for additional examples until 8 i6=c [ prob (p c &lt; p i ) &lt; ffi ], where ffi is a parameter of the algorithm. The Bonferroni correction <ref> (Rice, 1995) </ref> is used for problems that involve more than two classes. 3.2 Empirical Evaluation of the TREPAN Algorithm In our experiments, we are interested in evaluating our algorithm according to three criteria: (i) the fidelity of the trees to the networks from which they were extracted; (ii) the comprehensibility of
Reference: <author> Saito, K. & Nakano, R. </author> <year> (1988). </year> <title> Medical diagnostic expert system based on PDP model. </title> <booktitle> In Proceedings of the IEEE International Conference on Neural Networks, </booktitle> <pages> (pp. 255-262), </pages> <address> San Diego, CA. </address> <publisher> IEEE Press. </publisher>
Reference: <author> Sanger, D. </author> <year> (1989). </year> <title> Contribution analysis: A technique for assigning responsibilities to hidden units in connectionist networks. </title> <journal> Connection Science, </journal> <volume> 1(2) </volume> <pages> 115-138. </pages>
Reference-contexts: A number of statistical techniques have been used to characterize the activity of the hidden units in neural networks. These methods include: hierarchical clustering of hidden-unit activations (Sejnowski & Rosenberg, 1987; Elman, 1989; Hanson & Burr, 1990), contribution analysis <ref> (Sanger, 1989) </ref>, and weight pattern analysis (Gorman & Sejnowski, 1988). Like visualization techniques, these hidden-unit analysis methods are limited in that they do not provide complete descriptions of the concepts learned by networks.
Reference: <author> Schlimmer, J. C. & Fisher, D. </author> <year> (1986). </year> <title> A case study of incremental concept induction. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> (pp. 496-501), </pages> <address> Philadelphia, PA. </address>
Reference-contexts: (iii) the accuracy of our extracted decision trees, i.e., how well they generalize. 6 Table 2: Test-set accuracy. domain method networks C4.5 ID2-of-3 Trepan voting 91.5% 89.2% 86.9 92.2% protein coding 93.7 88.7 91.1 91.7 promoters 90.6 84.4 83.8 86.5 We evaluate Trepan using three real world domains: Congressional voting <ref> (Schlimmer & Fisher, 1986) </ref>, recognition of protein-coding regions in DNA (Craven & Shavlik, 1993b), and recognition of promoters in DNA (Towell et al., 1990). The voting domain has 15 Boolean features and two output categories.
Reference: <author> Sejnowski, T. & Rosenberg, C. </author> <year> (1987). </year> <title> Parallel networks that learn to pronounce English text. </title> <journal> Complex Systems, </journal> <volume> 1 </volume> <pages> 145-168. </pages>
Reference: <author> Sethi, I. K., Yoo, J. H., & Brickman, C. M. </author> <year> (1993). </year> <title> Extraction of diagnostic rules using neural networks. </title> <booktitle> In Proceedings of the Sixth IEEE Symposium on Computer-Based Medical Systems, </booktitle> <pages> (pp. 217-222), </pages> <address> Ann Arbor, MI. </address> <publisher> IEEE Press. </publisher>
Reference: <author> Shavlik, J. W., Mooney, R. J., & Towell, G. G. </author> <year> (1991). </year> <title> Symbolic and neural net learning algorithms: An empirical comparison. </title> <journal> Machine Learning, </journal> <volume> 6 </volume> <pages> 111-143. </pages>
Reference: <author> Shortliffe, E. </author> <year> (1976). </year> <title> Computer-based medical consultations: MYCIN. </title> <publisher> American Elsevier, </publisher> <address> New York, NY. </address>
Reference: <author> Smyth, P. & Mellstrom, J. </author> <year> (1992). </year> <title> Fault diagnosis of antenna pointing systems using hybrid neural network and signal processing models. </title> <editor> In Moody, J., Hanson, S., & Lippmann, R., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 4), </booktitle> <pages> (pp. 667-674), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Spackman, K. A. </author> <year> (1988). </year> <title> Learning categorical decision criteria. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> (pp. 36-46), </pages> <address> Ann Arbor, MI. 14 Stormo, </address> <publisher> G. </publisher> <year> (1987). </year> <title> Identifying coding sequences. </title> <editor> In Bishop, M. J. & Rawlings, C. J., editors, </editor> <title> Nucleic Acid and Protein Sequence Analysis: A Practical Approach. </title> <publisher> IRL Press, Oxford, </publisher> <address> England. </address>
Reference-contexts: As evidence that M-of-N rules are readily understandable, we note that in the field of medicine, they are common representations for diagnostic decision criteria <ref> (Spackman, 1988) </ref>. * Syntactic complexity: A major premise of our work is that syntactic complexity is a good indicator of comprehensibility. For a given representation language, we contend that, other 9 things being equal, simpler descriptions are better than complex descriptions. <p> We contend that representations, such as simple perceptrons, in which there are relatively few real-valued parameters and in which each parameter describes a simple (i.e. linear) relationship, are comprehensible. As evidence for this position, consider that linear discriminant functions are commonly used to express decision criteria in medicine <ref> (Spackman, 1988) </ref>. They are also widely used in molecular biology to describe sequence characteristics of interest (Stormo, 1987).
Reference: <author> Swartout, W. </author> <year> (1983). </year> <title> XPLAIN: A system for creating and explaining expert consulting programs. </title> <journal> Artificial Intelligence, </journal> <volume> 21(3) </volume> <pages> 285-325. </pages>
Reference: <author> Tan, A.-H. </author> <year> (1994). </year> <title> Rule learning and extraction with self-organizing neural networks. </title> <booktitle> In Proceedings of the 1993 Connectionist Models Summer School. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> Tchoumatchenko, I. & Ganascia, J.-G. </author> <year> (1994). </year> <title> A Bayesian framework to integrate symbolic and neural learning. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> (pp. 302-308), </pages> <address> New Brunswick, NJ. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Tesauro, G. & Sejnowski, T. J. </author> <year> (1989). </year> <title> A parallel network that learns to play backgammon. </title> <journal> Artificial Intelligence, </journal> <volume> 39(3) </volume> <pages> 357-390. </pages>
Reference-contexts: a network (Lang & Witbrock, 1988; Munro, 1991; Pratt et al., 1991); unit activations and the forward propagation of activation signals through the network (Craven & Shavlik, 1992); the backward propagation of error signals during learning (Craven & Shavlik, 1992); and the trajectory of units in weight space during learning <ref> (Wejchert & Tesauro, 1989) </ref>. Although visualization methods can provide insight into the learning and prediction behavior of a network, they are not a substitute for extraction methods.
Reference: <author> Thrun, S. </author> <year> (1995). </year> <title> Extracting rules from artificial neural networks with distributed representations. </title> <editor> In Tesauro, G., Touretzky, D., & Leen, T., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 7). </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Towell, G. & Shavlik, J. </author> <year> (1993). </year> <title> Extracting refined rules from knowledge-based neural networks. </title> <journal> Machine Learning, </journal> <volume> 13(1) </volume> <pages> 71-101. </pages>
Reference-contexts: We have developed a number of algorithms for extracting symbolic descriptions of trained networks. In previous work, we first developed an algorithm for extracting inference rules from knowledge-based neural networks 1 <ref> (Towell & Shavlik, 1993) </ref>, and then generalized the this algorithm so that it could be applied to ordinary networks when a special training procedure was used (Craven & Shavlik, 1993a).
Reference: <author> Towell, G. & Shavlik, J. </author> <year> (1994). </year> <booktitle> Knowledge-based artificial neural networks. Artificial Intelligence, </booktitle> <address> 70(1-2):119-165. </address>
Reference: <author> Towell, G., Shavlik, J., & Noordewier, M. </author> <year> (1990). </year> <title> Refinement of approximate domain theories by knowledge-based neural networks. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> (pp. 861-866), </pages> <address> Boston, MA. </address> <publisher> AAAI/MIT Press. </publisher>
Reference-contexts: networks C4.5 ID2-of-3 Trepan voting 91.5% 89.2% 86.9 92.2% protein coding 93.7 88.7 91.1 91.7 promoters 90.6 84.4 83.8 86.5 We evaluate Trepan using three real world domains: Congressional voting (Schlimmer & Fisher, 1986), recognition of protein-coding regions in DNA (Craven & Shavlik, 1993b), and recognition of promoters in DNA <ref> (Towell et al., 1990) </ref>. The voting domain has 15 Boolean features and two output categories. Following Buntine and Niblett (1992), we remove the physician-fee-freeze feature to make the problem more difficult. The protein-coding domain has 64 Boolean features and two output classes. <p> The voting data set has 435 examples, the promoter set has 438 examples, and the protein-coding domain has 20,000 examples. Note that the promoter set we use is larger and more complex than the original data set <ref> (Towell et al., 1990) </ref>. We randomly partition the voting and the promoter data into 10 training and test sets. Because of certain domain-specific characteristics of the data, we use only four training and test sets for the protein-coding task.
Reference: <author> Watkins, C. </author> <year> (1989). </year> <title> Learning from delayed rewards. </title> <type> PhD thesis, </type> <institution> King's College, </institution> <address> Cambridge. </address>
Reference-contexts: Another reason for preferring neural networks over symbolic algorithms is that they can be applied to some problems for which symbolic learning algorithms are poorly suited. For example, the technique of Q-learning <ref> (Watkins, 1989) </ref> requires that the learning system represent concepts as continuous-valued functions, and that these concepts be updated after each training instance. Few symbolic learning algorithms are able to meet both of these requirements.
Reference: <author> Watrous, R. L. & Kuhn, G. M. </author> <year> (1992). </year> <title> Induction of finite state languages using second-order neural networks. </title> <editor> In Moody, J., Hanson, S., & Lippmann, R., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 4). </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Weiss, S. M. & Kapouleas, I. </author> <year> (1989). </year> <title> An empirical comparison of pattern recognition, neural nets, and machine learning classification methods. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 688-693), </pages> <address> Detroit, MI. </address>
Reference: <author> Wejchert, J. & Tesauro, G. </author> <year> (1989). </year> <title> Neural network visualization. </title> <editor> In Touretzky, D., editor, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 2), </booktitle> <pages> (pp. 465-472), </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: a network (Lang & Witbrock, 1988; Munro, 1991; Pratt et al., 1991); unit activations and the forward propagation of activation signals through the network (Craven & Shavlik, 1992); the backward propagation of error signals during learning (Craven & Shavlik, 1992); and the trajectory of units in weight space during learning <ref> (Wejchert & Tesauro, 1989) </ref>. Although visualization methods can provide insight into the learning and prediction behavior of a network, they are not a substitute for extraction methods.
Reference: <author> Wolberg, W. H., Street, W. N., & Mangasarian, O. L. </author> <year> (1994). </year> <title> Machine learning techniques to diagnose breast cancer from fine needle aspirates. </title> <journal> Cancer Letters, </journal> <volume> 77 </volume> <pages> 163-171. </pages>
Reference-contexts: If the designers and end-users of a learning system are to be confident in the performance of the system, they must understand how it arrives at its decisions. The ability to inspect a learned concept definition is important in many domains, such as medical diagnosis <ref> (e.g., Wolberg et al., 1994) </ref>. * Discovery. Learning systems may also play an important role in the process of scientific discovery. A system may discover salient features and relationships in the input data whose importance was not previously recognized.
Reference: <author> Zeng, Z., Goodman, R. M., & Smyth, P. </author> <year> (1993). </year> <title> Learning finite state machines with self-clustering recurrent networks. </title> <journal> Neural Computation, </journal> <volume> 5(6) </volume> <pages> 976-990. 15 </pages>
References-found: 69

