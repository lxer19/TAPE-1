URL: ftp://ftp.cs.umd.edu/pub/papers/papers/2420/2420.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Title: Eigenvalues of Graded Matrices and the Condition Numbers of a Multiple Eigenvalue  
Author: G. W. Stewart G. Zhang 
Address: College Park, MD  College Park, MD 20742.  
Affiliation: Department of Computer Science and Institute for Advanced Computer Studies, University of Maryland,  Institute for Advanced Computer Studies, University of Maryland,  
Date: 90-31 February 1990  2420  
Note: UMIACS TR  20742. This work was supported in part by the Air Force Office of Sponsored Research under Contract AFOSR-87-0188.  
Pubnum: CS TR  
Abstract: This paper concerns two closely related topics: the behavior of the eigenvalues of graded matrices and the perturbation of a nondefective multiple eigenvalue. We will show that the eigenvalues of a graded matrix tend to share the graded structure of the matrix and give precise conditions insuring that this tendency is realized. These results are then applied to show that the secants of the canonical angles between the left and right invariant subspaces of a multiple eigenvalue tend to characterize its behavior when its matrix is slightly perturbed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Barlow and J. </author> <title> Demmel (1988). "Computig Accurate Eigensystems of Scaled Diagonally Dominant Matrices." </title> <type> Technical Report 421, </type> <institution> Computer Science Department, Courant Institute. </institution> <note> Cited in [3]. To appear in SIAM Journal on Numerical Analysis. </note>
Reference-contexts: In x3, we explore the relation between eigenvalues of a graded 4 Eigenvalues of Graded Matrices matrix and those of its Schur complements. These results are closely related to results obtained by one of the authors [7], 2 and more distantly to results by Barlow and Demmel <ref> [1] </ref> and Demmel and Veselic [3] for graded symmetric matrices. Here it should be stressed that our goal is not so much to derive tight bounds on the eigenvalues as to make statements about their magnitudes | as befits our intended application. <p> The basic tool used to establish this result is Gerschgorin's theorem (see, e.g., [5, p. 341]). Related results may be found in <ref> [1] </ref>. The center of the Gerschgorin disk from the first row of A is ffi 2 1 fi 11 , and its radius is bounded by fi max ffi 1 (ffi 2 + + ffi n ).
Reference: [2] <author> J. </author> <title> Demmel (1987). "The Smallest Perturbation of a Submatrix which Lowers the Rank and Constrained Total Least Squares Problems." </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 24, </volume> <pages> 199-206. </pages>
Reference-contexts: n ): The other eigenvalues of A satisfy jj fi max ffi 2 (ffi 1 + + ffi n ) jff 11 j fi max ffi 1 (ffi 2 + + ffi n ) j max j: 2 Mention should also be made of two papers on low rank approximation <ref> [4, 2] </ref>, whose results can be regarded as limiting cases of block scaling. Eigenvalues of Graded Matrices 5 To gain more insight into the condition (2.1), suppose that A is uniformly graded in the sense that the ratios i are constant | say they are equal to .
Reference: [3] <author> J. Demmel and K. </author> <title> Veselic (1989). "Jacobi's Method is More Accurate Than QR." </title> <type> Technical Report 468, </type> <institution> Computer Science Department, New York University. </institution>
Reference-contexts: These results are closely related to results obtained by one of the authors [7], 2 and more distantly to results by Barlow and Demmel [1] and Demmel and Veselic <ref> [3] </ref> for graded symmetric matrices. Here it should be stressed that our goal is not so much to derive tight bounds on the eigenvalues as to make statements about their magnitudes | as befits our intended application.
Reference: [4] <author> G. Golub, A. Hoffman, and G. W. </author> <title> Stewart (1987). "A Generalization of the Eckart-Young Matrix Approximation Theorem." </title> <journal> Linear Algebra and Its Applications, </journal> <volume> 88/89, </volume> <pages> 317-327. </pages>
Reference-contexts: n ): The other eigenvalues of A satisfy jj fi max ffi 2 (ffi 1 + + ffi n ) jff 11 j fi max ffi 1 (ffi 2 + + ffi n ) j max j: 2 Mention should also be made of two papers on low rank approximation <ref> [4, 2] </ref>, whose results can be regarded as limiting cases of block scaling. Eigenvalues of Graded Matrices 5 To gain more insight into the condition (2.1), suppose that A is uniformly graded in the sense that the ratios i are constant | say they are equal to .
Reference: [5] <author> G. H. Golub and C. F. Van Loan (1989). </author> <title> Matrix Computations (2nd ed.). </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, Maryland. </address>
Reference-contexts: Specifically, if fi 11 is not too small compared to fi max , the graded matrix A has an eigenvalue that approximates ff 11 = ffi 2 1 fi 11 . The basic tool used to establish this result is Gerschgorin's theorem (see, e.g., <ref> [5, p. 341] </ref>). Related results may be found in [1]. The center of the Gerschgorin disk from the first row of A is ffi 2 1 fi 11 , and its radius is bounded by fi max ffi 1 (ffi 2 + + ffi n ).
Reference: [6] <author> G. W. </author> <title> Stewart (1973). "Error and Perturbation Bounds for Subspaces Associated with Certain Eigenvalue Problems." </title> <journal> SIAM Review, </journal> <volume> 15, </volume> <pages> 727-764. </pages>
Reference-contexts: It then follows that the eigenvalues of the matrix ~ A 22 = A 22 P A 12 (3:1) are the eigenvalues associated with the complementary invariant subspace; i.e., the n k smallest eigenvalues of A. For details see <ref> [6] </ref> or [8, Ch. V]. <p> simple induction k ^ P k k 1 (1 + 2 (1 + s k1 ) + 1 3 (1 + s k1 ) 2 ) = 1 (1 + s k ); (3:6) where s k satisfies the recursion s 0 = 0; 3 An alternative is to follow <ref> [6] </ref> and define ^ P k as the solution of ^ P k B 22 D 2 1 B 1 11 ^ P k1 B 12 D 2 1 B 1 This approach gives a slightly less stringent condition for convergence but a slightly larger bound. 8 Eigenvalues of Graded Matrices <p> In x1 we saw that a judicious choice of eigenvectors led to a graded eigenvalue problem. The existence of a suitable choice for the general case is stated in the following theorem <ref> [6] </ref>. Theorem 4.1. <p> The maximizing angles are called the canonical angles between X and Y. For more details see [8, xI.5]. We must now relate this choice of basis to the eigenvalues of a perturbation A + E of A. This is done in the following theorem <ref> [6] </ref>. Theorem 4.2. Let C = Y H EX: Then there is a matrix ^ C = C + O (kEk 2 ) whose eigenvalues are eigenvalues of A + E.
Reference: [7] <author> G. W. </author> <title> Stewart (1984). "On the Asymptotic Behavior of Scaled Singular Value and QR Decompostions." </title> <journal> Mathematics of Computation, </journal> <volume> 43, </volume> <pages> 483-489. </pages>
Reference-contexts: In x3, we explore the relation between eigenvalues of a graded 4 Eigenvalues of Graded Matrices matrix and those of its Schur complements. These results are closely related to results obtained by one of the authors <ref> [7] </ref>, 2 and more distantly to results by Barlow and Demmel [1] and Demmel and Veselic [3] for graded symmetric matrices.
Reference: [8] <author> G. W. Stewart and Ji guang Sun (1990). </author> <title> Matrix Perturbation Theory. </title> <publisher> Academic Press, </publisher> <address> Boston. </address> <note> In production. </note>
Reference-contexts: It then follows that the eigenvalues of the matrix ~ A 22 = A 22 P A 12 (3:1) are the eigenvalues associated with the complementary invariant subspace; i.e., the n k smallest eigenvalues of A. For details see [6] or <ref> [8, Ch. V] </ref>. <p> The maximizing angles are called the canonical angles between X and Y. For more details see <ref> [8, xI.5] </ref>. We must now relate this choice of basis to the eigenvalues of a perturbation A + E of A. This is done in the following theorem [6]. Theorem 4.2.
Reference: [9] <author> J.-G. </author> <title> Sun (1989). "A Note on Local Behavior of Multiple Eigenvalues." </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 10, </volume> <pages> 533-541. </pages>
Reference-contexts: For an entry into this literature, see <ref> [9] </ref>. 1 2 Eigenvalues of Graded Matrices As an illustration, consider the variation of the eigenvalues of the matrix A = * B @ 1 1 C where * is small. This matrix has a simple eigenvalue 3 and a double eigenvalue 0.
References-found: 9

