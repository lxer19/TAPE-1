URL: ftp://ftp.cs.man.ac.uk/pub/TR/UMCS-96-2-3.ps.Z
Refering-URL: http://www.cs.man.ac.uk/cstechrep/Abstracts/UMCS-96-2-3.html
Root-URL: http://www.cs.man.ac.uk
Title: Remote Control of Mobile Robot via Internet  
Author: Ulrich Nehmzow, Andreas B uhlmeier, Holger D urer and Manfred N olte 
Affiliation: Computer Science University of Manchester  
Pubnum: ISSN 1361 6161  
Abstract: Department of Computer Science University of Manchester Technical Report Series UMCS-96-2-3 
Abstract-found: 1
Intro-found: 1
Reference: [Liu et al. 93] <author> A. Liu and G. Tharp and L. French and S. Lai and L. Stark, </author> <title> Some of what one needs to know about using head-mounted displays to improve teleoperator performance, </title> <journal> IEEE Transactions on Robotics and automation, </journal> <volume> Vol 9, </volume> <year> 1993. </year>
Reference-contexts: Immersive sensor data visualization techniques ("virtual reality") become counter-productive and confusing to the user if delays greater than 0.3s are encountered, particularly if the operator's body is displayed as well, because the natural correspondence between body movement and image motions is lost <ref> [Liu et al. 93] </ref>. We conclude that immersive techniques are unsuitable for applications where long delays are encountered (like internet communications). However, graphical display methods giving a third party view can be used successfully, as our experiments show.
Reference: [Nehmzow 92] <author> U. Nehmzow, </author> <title> Experiments in Competence Acquisition for Autonomous Mobile Robots, </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <year> 1992. </year>
Reference-contexts: Experiments have already been conducted in which FortyTwo acquires sensor-motor competences through remote control, and uses these skills to move autonomously, with only occasional interference by the operator (see <ref> [Nehmzow 92, Nehmzow 95] </ref> regarding the controller used for these experiments). A second area of investigation is to add further sensor modalities to the telerobotics control system. In particular, we intend to use the robot's visual sensor for this purpose.
Reference: [Nehmzow 95] <author> U. Nehmzow, </author> <title> Flexible Control of Mobile Robots through Autonomous Competence Acquisition, </title> <booktitle> Measurement and Control, </booktitle> <volume> Vol 28, No 2, </volume> <year> 1995. </year>
Reference-contexts: Experiments have already been conducted in which FortyTwo acquires sensor-motor competences through remote control, and uses these skills to move autonomously, with only occasional interference by the operator (see <ref> [Nehmzow 92, Nehmzow 95] </ref> regarding the controller used for these experiments). A second area of investigation is to add further sensor modalities to the telerobotics control system. In particular, we intend to use the robot's visual sensor for this purpose.
Reference: [Nomad 93] <institution> Nomad 200 User's Guide, Nomadic Technologies, </institution> <month> December </month> <year> 1993. </year>
Reference: [Sheridan 93] <author> T. Sheridan, </author> <title> Space teleoperation through time delay: </title> <journal> review and prognosis, IEEE Transactions on Robotics and automation, </journal> <volume> Vol 9, </volume> <year> 1993. </year>
Reference-contexts: round trip delays are typically between 0.3s and 4s, as well as deep 9 sea applications, where round trip delays can be as long as 10 minutes (<ref> [Sheridan 93] </ref>) in the case of cable-controlled submersibles. Predictive control, local impedance control and wave transform techniques are ways to alleviate this problem [Sheridan 93]. Immersive sensor data visualization techniques ("virtual reality") become counter-productive and confusing to the user if delays greater than 0.3s are encountered, particularly if the operator's body is displayed as well, because the natural correspondence between body movement and image motions is lost [Liu et al. 93].
Reference: [Vertut & Coiffet 85] <author> J. Vertut and P. Coiffet, </author> <title> Teleoperation and Robotics Evolution and Development, Robot Technology, Vols 3A & B, Kogan Page, </title> <address> London 1985. </address>
Reference-contexts: or pneumatic connections (<ref> [Vertut & Coiffet 85] </ref>). Early interest in teleoperation concentrated solely on object manipulation (chiefly in the nuclear industry), and it was only in 1967 when remotely controlled mobile vehicles were used for exploration tasks (the Soviet Lunakod was used to explore the surface of the moon, see [Vertut & Coiffet 85]). In 1992 a remotely controlled legged robot explored Mount Erebus ([Wettergreen et al. 92]) and Mount Spur. Both these remotely controlled mobile robots used dedicated, high bandwidth communication links.
Reference: [Wettergreen et al. 92] <author> D. Wettergreen, C. Thorpe and R. Whittaker, </author> <title> Dante's Exploration of Mount Erebus, </title> <type> Technical report, </type> <institution> Robotics Institute, Carnegie Mellon University, </institution> <year> 1992. </year> <month> 10 </month>
References-found: 7

