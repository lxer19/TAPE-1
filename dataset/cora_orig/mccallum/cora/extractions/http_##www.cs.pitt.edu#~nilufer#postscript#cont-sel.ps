URL: http://www.cs.pitt.edu/~nilufer/postscript/cont-sel.ps
Refering-URL: http://www.cs.pitt.edu/~nilufer/paper-guide-nilufer.html
Root-URL: 
Email: nilufer@cs.pitt.edu  pollack@cs.pitt.edu  
Title: Contingency Selection in Plan Generation  
Author: Nilufer Onder Martha E. Pollack 
Address: Pittsburgh Pittsburgh, PA 15260  Pittsburgh Pittsburgh, PA 15260  
Affiliation: Department of Computer Science University of  Department of Computer Science and Intelligent Systems Program University of  
Abstract: A key question in conditional planning is: how many, and which of the possible execution failures should be planned for? One cannot, in general, plan for all the failures that can be anticipated: there are simply too many. But neither can one ignore all the possible failures, or one will fail to produce sufficiently flexible plans. We describe a planning system that attempts to identify the contingencies that contribute the most to a plan's overall value. Plan generation proceeds by extending the plan to include actions that will be taken in case the identified contingencies fail, iterating until either a given expected value threshold is reached or planning time is exhausted. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Dean, T.; Kaelbling, L. P.; Kirman, J.; and Nicholson, A. </author> <year> 1995. </year> <title> Planning under time constraints in stochastic domains. </title> <booktitle> Artificial Intelligence 76 </booktitle> <pages> 35-74. </pages>
Reference: <author> Draper, D.; Hanks, S.; and Weld, D. </author> <year> 1994. </year> <title> Probabilistic planning with information gathering and contingent execution. </title> <booktitle> In Proc. 2nd Int. C. on AI Planning S., </booktitle> <pages> 31-36. </pages>
Reference-contexts: The subjects and triggers are mutually exclusive and exhaustive. The subject and trigger propositions cannot be identical, although the subject and label propositions can be. This observation action representation is similar to C-BURIDAN's <ref> (Draper, Hanks, & Weld 1994) </ref>. However, C-BURIDAN labels are arbitrary strings that do not relate to propositions, and it does not distinguish the subject of the sensor reading. Contingencies An important issue in the generation of probabilistic plans is the identification of equivalent consequences.
Reference: <author> Etzioni, O.; Hanks, S.; Weld, D.; Draper, D.; Lesh, N.; and Williamson, M. </author> <year> 1992. </year> <title> An approach to planning with incomplete information. </title> <booktitle> In Proc. 3rd Int. C. on Principles of Knowledge Repr. and Reasoning, </booktitle> <pages> 115-125. </pages>
Reference: <author> Goldman, R. P., and Boddy, M. S. </author> <year> 1994. </year> <title> Epsilon-safe planning. </title> <booktitle> In Proc. 10th C. on Uncertainty in AI, </booktitle> <pages> 253-261. </pages>
Reference-contexts: In the process of doing this, C-BURIDAN does not reason about whether both those contingent outcomes are worth planning for. The PLINTH system skips certain contexts during the construction of probabilistic plans <ref> (Goldman & Boddy 1994) </ref>. Our approach differs from theirs in two aspects. First, we are focusing on partial-ordering, where they use a total-order approach. Second, we consider the impact of failure in addition to the probability of failure.
Reference: <author> Haddawy, P., and Hanks, S. </author> <year> 1993. </year> <title> Utility models for goal-directed decision-theoretic planners. </title> <type> Technical Report 93-06-04, </type> <institution> Department of Computer Science and Engineering, University of Washington. </institution>
Reference-contexts: the failure of a contingency c means constructing a plan that does not depend on the effects produced by c, i.e., a plan that will succeed even if c fails to occur. 2 The utility of one subgoal does not depend on the degree to which other goals are satisfied <ref> (Haddawy & Hanks 1993) </ref>. Action Representation To formalize these notions, we build on the representation for probabilistic actions that was developed for (Kushmerick, Hanks, & Weld 1995, p. 247). Causal actions are those that alter the state of the world.
Reference: <author> Haddawy, P., and Suwandi, M. </author> <year> 1994. </year> <title> Decision-theoretic refinement planning using inheritance abstraction. </title> <booktitle> In Proc. 2nd Int. C. on AI Planning S., </booktitle> <pages> 266-271. </pages>
Reference-contexts: Second, we consider the impact of failure in addition to the probability of failure. Other relevant work includes the recent decision-theoretic planning literature, e.g., the PYRRHUS system (Williamson & Hanks 1994) which prunes the search space by using domain-specific heuristic know ledge, and the DRIPS system <ref> (Haddawy & Suwandi 1994) </ref> which uses an abstraction hierarchy. Kambham-pati (1994) describes planning algorithms with multi-contributor causal links. Our algorithm maintains multiple contributors at the action outcome level in a probabilistic setting.
Reference: <author> Kambhampati, S. </author> <year> 1994. </year> <title> Multi-contributor causal structures for planning: a formalization and evaluation. </title> <booktitle> Artificial Intelligence 69 </booktitle> <pages> 235-278. </pages>
Reference: <author> Kushmerick, N.; Hanks, S.; and Weld, D. S. </author> <year> 1995. </year> <title> An algorithm for probabilistic planning. </title> <booktitle> Artificial Intelligence 76 </booktitle> <pages> 239-286. </pages>
Reference-contexts: Action Representation To formalize these notions, we build on the representation for probabilistic actions that was developed for <ref> (Kushmerick, Hanks, & Weld 1995, p. 247) </ref>. Causal actions are those that alter the state of the world.
Reference: <author> Peot, M. A., and Smith, D. E. </author> <year> 1992. </year> <title> Conditional nonlinear planning. </title> <booktitle> In Proc. 1st Int. C. on AI Planning S., </booktitle> <pages> 189-197. </pages>
Reference: <author> Pryor, L., and Collins, G. </author> <year> 1993. </year> <title> Cassandra: Planning for contingencies. </title> <type> Technical Report 41, </type> <institution> The Institute for the Learning Sciences, Northwestern University. </institution>
Reference: <author> Williamson, M., and Hanks, S. </author> <year> 1994. </year> <title> Optimal planning with a goal-directed utility model. </title> <booktitle> In Proc. 2nd Int. C. on AI Planning S., </booktitle> <pages> 176-181. </pages> <note> xxx. Reference omitted for blind review. </note>
Reference-contexts: Our approach differs from theirs in two aspects. First, we are focusing on partial-ordering, where they use a total-order approach. Second, we consider the impact of failure in addition to the probability of failure. Other relevant work includes the recent decision-theoretic planning literature, e.g., the PYRRHUS system <ref> (Williamson & Hanks 1994) </ref> which prunes the search space by using domain-specific heuristic know ledge, and the DRIPS system (Haddawy & Suwandi 1994) which uses an abstraction hierarchy. Kambham-pati (1994) describes planning algorithms with multi-contributor causal links.
References-found: 11

