URL: ftp://svr-ftp.eng.cam.ac.uk/pub/reports/freitas_tr307.ps.gz
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00427.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-mail: jfgf@eng.cam.ac.uk  
Title: HIERARCHICAL BAYESIAN-KALMAN MODELS FOR REGULARISATION AND ARD IN SEQUENTIAL LEARNING  
Author: JFG de Freitas, M Niranjan and AH Gee 
Address: Trumpington Street Cambridge CB2 1PZ England  
Affiliation: Cambridge University Engineering Department  
Date: May 22, 1998  
Pubnum: CUED/F-INFENG/TR 307  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> B D Anderson and J B Moore. </author> <title> Optimal Filtering. </title> <publisher> Prentice-Hall, </publisher> <address> New Jersey, </address> <year> 1979. </year>
Reference-contexts: The situation for linear-Gaussian state space models is vastly simpler. There the mean and covariance 7 are sufficient statistics for describing the Gaussian posterior density function. In addition, the state can be computed in an optimal fashion with the Kalman filter <ref> [1, 2, 12, 20] </ref>. This motivates an approach based on Gaussian approximations that employs linear approximations about the current estimates. These two approximations lead to the formulation of the well known extended Kalman filter (EKF). <p> Under the assumptions that the state space model noise processes are uncorrelated with each other and the initial estimates of the parameters w k and their covariance matrix P k , we can model the prior, evidence and likelihood functions as follows <ref> [1, 7, 15] </ref> (see also Appendix A): Prior = p (w k+1 jY k ; M j ; R k ; Q k ) ~ N ( ^ w k ; P k + Q k ) (9) Evidence = p (y k+1 jY k ; M j ; R k
Reference: [2] <author> Y Bar-Shalom and X R Li. </author> <title> Estimation and Tracking: </title> <booktitle> Principles, Techniques and Software. </booktitle> <address> Artech House, Boston, </address> <year> 1993. </year>
Reference-contexts: This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom <ref> [2, 27] </ref>, Lee Feldkamp [40, 41, 42], Andrew Jazwinski [19, 20, 21], David Mackay [28, 30], Gintaras Puskorius [40, 41, 42] and Richard Sutton [50, 51]. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. <p> The conditional probability density function of w k given Y k (p (w k jY k )) constitutes the complete solution of the estimation problem <ref> [2, 15, 20] </ref>. This is simply because p (w k jY k ) embodies all the statistical information about w k given the measurements Y k and the initial condition w 0 . <p> The functional integral difference equation governing the evolution of the posterior density function (equation (3)) is not suitable for practical implementation <ref> [2, 20] </ref>. It involves propagating a quantity (the posterior density function) that cannot be described by a finite number of parameters. Three alternative routes have been proposed to surmount this problem, namely sampling techniques [4, 8, 16], graphical Bayesian models [3, 13] and Gaussian approximations [2]. <p> It involves propagating a quantity (the posterior density function) that cannot be described by a finite number of parameters. Three alternative routes have been proposed to surmount this problem, namely sampling techniques [4, 8, 16], graphical Bayesian models [3, 13] and Gaussian approximations <ref> [2] </ref>. Sampling methods and graphical models require extensive computational resources and are often restricted to the smoothing problem. Gaussian approximations also suffer from several drawbacks, especially when the probability density function being approximated has a large number of modes. <p> The situation for linear-Gaussian state space models is vastly simpler. There the mean and covariance 7 are sufficient statistics for describing the Gaussian posterior density function. In addition, the state can be computed in an optimal fashion with the Kalman filter <ref> [1, 2, 12, 20] </ref>. This motivates an approach based on Gaussian approximations that employs linear approximations about the current estimates. These two approximations lead to the formulation of the well known extended Kalman filter (EKF). <p> P k+1 are given by: ^ w k+1 = ^ w k + K k+1 (y k+1 H k+1 ^ w k ) (13) where K k is known as the Kalman gain: K k+1 = k+1 k+1 Equations (13), (14) and (15) correspond exactly to the Kalman filter equations <ref> [2, 12, 15] </ref>. Alternatively, the Kalman filter equations may be derived by adopting the minimum variance approach. That is, by minimising the following cost functional [12]: J k = trace (P k ) (16) The Kalman filter algorithm may be easily implemented by computing K, ^ w and P recursively. <p> The extended Kalman filter (EKF) constitutes an attempt in this direction <ref> [2, 12] </ref>. The EKF is a minimum variance estimator based on a Taylor series expansion of the nonlinear function g (w) around the previous estimate. <p> It is also important to point 11 out that the EKF may diverge as a result of its inherent approximations. The consistency of the EKF may be evaluated by means of extensive Monte Carlo simulations <ref> [2] </ref>. The EKF provides a minimum variance Gaussian approximation to the posterior probability density function. In many cases, p (w k jY k ) is a multi-modal (several peaks) function. <p> In many cases, p (w k jY k ) is a multi-modal (several peaks) function. In this scenario, it is possible to use a committee of Kalman filters, where each individual filter approximates a particular mode, to produce a more accurate approximation <ref> [2, 5, 22, 23] </ref>. The parameter covariances of the individual estimators may be used to determine the contribution of each estimator to the committee. In addition, the parameter covariances serve the purpose of placing confidence intervals on the output prediction. <p> That is, more importance is placed on the most recent measurements. Consequently, it may be asserted that filters with adaptive process noise covariances exhibit adaptive memory. Additionally, as the Kalman gain increases, the bandwidth of the filter also increases <ref> [2] </ref>. Therefore, the filter becomes less immune to noise and outliers. The amount of oscillation in the model prediction clearly depends on the value of the process noise covariance. As a result, this covariance can be used as a regularisation mechanism to control the smoothness of the prediction. <p> However, the results of Figure 4 suggest that the prediction obtained with the conventional EKF training outperforms the predictions of the other methods. This may be attributed to the fact that for this particular problem, it is easy to choose the 26 adaptation algorithm with weight decay <ref> [2] </ref>, the EKF algorithm with P updated by back-propagation [3], the evidence maximisation algorithm with weight decay [4] and the evidence maximisation algorithm with sequentially updated priors [5]. 27 adaptation algorithm with weight decay [2], the EKF algorithm with P updated by back-propagation [3], the evidence maximisation algorithm with weight decay <p> for this particular problem, it is easy to choose the 26 adaptation algorithm with weight decay <ref> [2] </ref>, the EKF algorithm with P updated by back-propagation [3], the evidence maximisation algorithm with weight decay [4] and the evidence maximisation algorithm with sequentially updated priors [5]. 27 adaptation algorithm with weight decay [2], the EKF algorithm with P updated by back-propagation [3], the evidence maximisation algorithm with weight decay [4] and the evidence maximisation algorithm with sequentially updated priors [5]. 28 matrices R and Q. It is imperative to note that this is not the case in general.
Reference: [3] <author> J Binder, K Murphy, and S Russell. </author> <title> Space-efficient inference in dynamic probabilistic networks. </title> <booktitle> In Fifteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Japan, </address> <year> 1997. </year>
Reference-contexts: It involves propagating a quantity (the posterior density function) that cannot be described by a finite number of parameters. Three alternative routes have been proposed to surmount this problem, namely sampling techniques [4, 8, 16], graphical Bayesian models <ref> [3, 13] </ref> and Gaussian approximations [2]. Sampling methods and graphical models require extensive computational resources and are often restricted to the smoothing problem. Gaussian approximations also suffer from several drawbacks, especially when the probability density function being approximated has a large number of modes. <p> This may be attributed to the fact that for this particular problem, it is easy to choose the 26 adaptation algorithm with weight decay [2], the EKF algorithm with P updated by back-propagation <ref> [3] </ref>, the evidence maximisation algorithm with weight decay [4] and the evidence maximisation algorithm with sequentially updated priors [5]. 27 adaptation algorithm with weight decay [2], the EKF algorithm with P updated by back-propagation [3], the evidence maximisation algorithm with weight decay [4] and the evidence maximisation algorithm with sequentially updated <p> the 26 adaptation algorithm with weight decay [2], the EKF algorithm with P updated by back-propagation <ref> [3] </ref>, the evidence maximisation algorithm with weight decay [4] and the evidence maximisation algorithm with sequentially updated priors [5]. 27 adaptation algorithm with weight decay [2], the EKF algorithm with P updated by back-propagation [3], the evidence maximisation algorithm with weight decay [4] and the evidence maximisation algorithm with sequentially updated priors [5]. 28 matrices R and Q. It is imperative to note that this is not the case in general.
Reference: [4] <author> J V Black and C M Reed. </author> <title> A hybrid parametric, non-parametric approach to Bayesian target tracking. </title> <type> Technical report, </type> <institution> DRA, Malvern, UK, </institution> <year> 1996. </year>
Reference-contexts: It involves propagating a quantity (the posterior density function) that cannot be described by a finite number of parameters. Three alternative routes have been proposed to surmount this problem, namely sampling techniques <ref> [4, 8, 16] </ref>, graphical Bayesian models [3, 13] and Gaussian approximations [2]. Sampling methods and graphical models require extensive computational resources and are often restricted to the smoothing problem. Gaussian approximations also suffer from several drawbacks, especially when the probability density function being approximated has a large number of modes. <p> This may be attributed to the fact that for this particular problem, it is easy to choose the 26 adaptation algorithm with weight decay [2], the EKF algorithm with P updated by back-propagation [3], the evidence maximisation algorithm with weight decay <ref> [4] </ref> and the evidence maximisation algorithm with sequentially updated priors [5]. 27 adaptation algorithm with weight decay [2], the EKF algorithm with P updated by back-propagation [3], the evidence maximisation algorithm with weight decay [4] and the evidence maximisation algorithm with sequentially updated priors [5]. 28 matrices R and Q. <p> the EKF algorithm with P updated by back-propagation [3], the evidence maximisation algorithm with weight decay <ref> [4] </ref> and the evidence maximisation algorithm with sequentially updated priors [5]. 27 adaptation algorithm with weight decay [2], the EKF algorithm with P updated by back-propagation [3], the evidence maximisation algorithm with weight decay [4] and the evidence maximisation algorithm with sequentially updated priors [5]. 28 matrices R and Q. It is imperative to note that this is not the case in general.
Reference: [5] <author> H A P Blom and Y Bar-Shalom. </author> <title> The interacting multiple model algorithm for systems with Markovian switching coefficients. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> 33(8) </volume> <pages> 780-783, </pages> <year> 1988. </year>
Reference-contexts: In many cases, p (w k jY k ) is a multi-modal (several peaks) function. In this scenario, it is possible to use a committee of Kalman filters, where each individual filter approximates a particular mode, to produce a more accurate approximation <ref> [2, 5, 22, 23] </ref>. The parameter covariances of the individual estimators may be used to determine the contribution of each estimator to the committee. In addition, the parameter covariances serve the purpose of placing confidence intervals on the output prediction. <p> may be attributed to the fact that for this particular problem, it is easy to choose the 26 adaptation algorithm with weight decay [2], the EKF algorithm with P updated by back-propagation [3], the evidence maximisation algorithm with weight decay [4] and the evidence maximisation algorithm with sequentially updated priors <ref> [5] </ref>. 27 adaptation algorithm with weight decay [2], the EKF algorithm with P updated by back-propagation [3], the evidence maximisation algorithm with weight decay [4] and the evidence maximisation algorithm with sequentially updated priors [5]. 28 matrices R and Q. <p> evidence maximisation algorithm with weight decay [4] and the evidence maximisation algorithm with sequentially updated priors <ref> [5] </ref>. 27 adaptation algorithm with weight decay [2], the EKF algorithm with P updated by back-propagation [3], the evidence maximisation algorithm with weight decay [4] and the evidence maximisation algorithm with sequentially updated priors [5]. 28 matrices R and Q. It is imperative to note that this is not the case in general. Figures 4 and 5 also reveal that when the noise processes are estimated automatically, some of the optimal performance of the EKF may be lost.
Reference: [6] <author> W L Buntine and A S Weigend. </author> <title> Bayesian back-propagation. </title> <journal> Complex Systems, </journal> <volume> 5 </volume> <pages> 603-643, </pages> <year> 1991. </year>
Reference-contexts: The remaining weights have no contribution because their magnitudes are forced to zero by the weight decay prior. Instead of adopting Mackay's evidence framework, it is possible to max-imise the posterior density function by performing integrations over the hyper-parameters analytically <ref> [6, 30, 55, 57] </ref>. The latter approach is known as the MAP framework for ff and fi.
Reference: [7] <author> J V Candy. </author> <title> Signal Processing: The Model Based Approach. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Under the assumptions that the state space model noise processes are uncorrelated with each other and the initial estimates of the parameters w k and their covariance matrix P k , we can model the prior, evidence and likelihood functions as follows <ref> [1, 7, 15] </ref> (see also Appendix A): Prior = p (w k+1 jY k ; M j ; R k ; Q k ) ~ N ( ^ w k ; P k + Q k ) (9) Evidence = p (y k+1 jY k ; M j ; R k
Reference: [8] <author> C K Carter and R Kohn. </author> <title> On Gibbs sampling for state space models. </title> <journal> Biometrika, </journal> <volume> 81(3) </volume> <pages> 541-553, </pages> <year> 1994. </year>
Reference-contexts: It involves propagating a quantity (the posterior density function) that cannot be described by a finite number of parameters. Three alternative routes have been proposed to surmount this problem, namely sampling techniques <ref> [4, 8, 16] </ref>, graphical Bayesian models [3, 13] and Gaussian approximations [2]. Sampling methods and graphical models require extensive computational resources and are often restricted to the smoothing problem. Gaussian approximations also suffer from several drawbacks, especially when the probability density function being approximated has a large number of modes.
Reference: [9] <author> J F G de Freitas, A Gaylard, A L Stevens, J N Ridley, and C F Landy. </author> <title> Identification of vibrating structures and fault detection using neural networks. </title> <booktitle> In International Conference on Neural Networks, </booktitle> <address> Washington, </address> <year> 1996. </year>
Reference-contexts: For instance, in conventional neural network modelling of finite data sets, the weights in charge of scaling the irrelevant inputs do not usually tend to zero because of random correlations between the inputs and the output [31]. In addition, in many engineering and financial applications <ref> [9, 10, 38] </ref>, we often find that we know part of the equation governing a particular process. That is, we might have inferred that the relationship between two measurements x and y is given by: y = x 2 + g (x) where the function g (x) is unknown. <p> When choosing the initial basis functions, preference should be given to basis functions that appear frequently in physical laws, such as polynomials, exponentials, sinusoids, logarithms, etc. This strategy has been successfully employed in computing models for pneumatic control valves and structural vi bration in induction motors <ref> [9, 10] </ref>. It follows that this idea may also be applied to clustering algorithms to determine the relevance of each cluster. The problems of automatic relevance determination of inputs (ARDI) and of basis functions (ARDF) can be addressed with clarity and efficiency within a 24 Bayesian framework.
Reference: [10] <author> J F G de Freitas, I M Macleod, and J S Maltz. </author> <title> Neural networks for pneumatic actuator fault detection. </title> <note> Accepted for Publication by the Transactions of the South African IEE, </note> <year> 1996. </year>
Reference-contexts: For instance, in conventional neural network modelling of finite data sets, the weights in charge of scaling the irrelevant inputs do not usually tend to zero because of random correlations between the inputs and the output [31]. In addition, in many engineering and financial applications <ref> [9, 10, 38] </ref>, we often find that we know part of the equation governing a particular process. That is, we might have inferred that the relationship between two measurements x and y is given by: y = x 2 + g (x) where the function g (x) is unknown. <p> When choosing the initial basis functions, preference should be given to basis functions that appear frequently in physical laws, such as polynomials, exponentials, sinusoids, logarithms, etc. This strategy has been successfully employed in computing models for pneumatic control valves and structural vi bration in induction motors <ref> [9, 10] </ref>. It follows that this idea may also be applied to clustering algorithms to determine the relevance of each cluster. The problems of automatic relevance determination of inputs (ARDI) and of basis functions (ARDF) can be addressed with clarity and efficiency within a 24 Bayesian framework.
Reference: [11] <author> J F G de Freitas, M Niranjan, </author> <title> and A H Gee. The EM algorithm and neural networks for nonlinear state space estimation. </title> <type> Tr 313, </type> <institution> Cambridge University Engineering Department, </institution> <year> 1998. </year>
Reference-contexts: This way, we avoid the problem of having to estimate f k (w k ). We have proven that the drift function may be estimated via extended Kalman smoothing and the EM algorithm <ref> [11] </ref>. However, the approach is only applicable to stationary environments. In this paper, we favour the approach of estimating the noise co-variances because it will lead us to an elegant framework for regularisation and automatic relevance determination in sequential learning. <p> In addition, the Bayesian inference framework provides an elegant, unifying theory to the problem of sequential learning. Although we did not estimate the drift function in this paper, we have proved elsewhere that linear drift functions may be estimated via extended Kalman smoothing and the EM algorithm <ref> [11] </ref>. The method for estimating the linear drift functions with the EM algorithm is simple, stable and elegant but exhibits very slow convergence and is only applicable to stationary environments. We showed that distributed learning rates, adaptive noise parameters and adaptive smoothing regularisers are mathematically equivalent.
Reference: [12] <editor> A Gelb, editor. </editor> <title> Applied Optimal Estimation. </title> <publisher> MIT Press, </publisher> <year> 1984. </year>
Reference-contexts: The problem of estimating w k given Y t is called the smoothing problem if k &lt; t ; the filtering problem if k = t ; or the prediction problem if k &gt; t <ref> [12, 20] </ref>. In the filtering problem, the estimate ^ w k can be used to predict future values of the output. In non-stationary environments we should favour the filtering approach to generate models of the sequential process being studied. <p> In stationary environ 5 ments, the smoothing approach, with forward and backward filtering, produces better estimates than plain forward filtering. For optimality reasons, we want ^ w k to be an unbiased, minimum variance and consistent estimate <ref> [12] </ref>, where: * An unbiased estimate is one whose expected value is equal to the quantity being estimated. * A minimum variance (unbiased) estimate is one that has its variance less than or equal to that of any other unbiased estimator. * A consistent estimate is one that converges to the <p> The situation for linear-Gaussian state space models is vastly simpler. There the mean and covariance 7 are sufficient statistics for describing the Gaussian posterior density function. In addition, the state can be computed in an optimal fashion with the Kalman filter <ref> [1, 2, 12, 20] </ref>. This motivates an approach based on Gaussian approximations that employs linear approximations about the current estimates. These two approximations lead to the formulation of the well known extended Kalman filter (EKF). <p> P k+1 are given by: ^ w k+1 = ^ w k + K k+1 (y k+1 H k+1 ^ w k ) (13) where K k is known as the Kalman gain: K k+1 = k+1 k+1 Equations (13), (14) and (15) correspond exactly to the Kalman filter equations <ref> [2, 12, 15] </ref>. Alternatively, the Kalman filter equations may be derived by adopting the minimum variance approach. That is, by minimising the following cost functional [12]: J k = trace (P k ) (16) The Kalman filter algorithm may be easily implemented by computing K, ^ w and P recursively. <p> Alternatively, the Kalman filter equations may be derived by adopting the minimum variance approach. That is, by minimising the following cost functional <ref> [12] </ref>: J k = trace (P k ) (16) The Kalman filter algorithm may be easily implemented by computing K, ^ w and P recursively. <p> The extended Kalman filter (EKF) constitutes an attempt in this direction <ref> [2, 12] </ref>. The EKF is a minimum variance estimator based on a Taylor series expansion of the nonlinear function g (w) around the previous estimate. <p> Another important aspect of Sutton's algorithm is that it circumvents the problem of choosing the process noise covariance Q. To understand how this is done, we need to write the Kalman filter equations in the following format <ref> [12] </ref>: K k+1 = P k H T k+1 ] 1 P k+1 = P k + Q k K k+1 H k+1 P k In this format, only the parameters' covariance update equation depends on Q.
Reference: [13] <author> Z Ghahramani and M Jordan. </author> <title> Factorial Hidden Markov Models. </title> <type> Technical Report 9502, </type> <institution> MIT Artificial Intelligence Lab, </institution> <address> MA, </address> <year> 1995. </year>
Reference-contexts: It involves propagating a quantity (the posterior density function) that cannot be described by a finite number of parameters. Three alternative routes have been proposed to surmount this problem, namely sampling techniques [4, 8, 16], graphical Bayesian models <ref> [3, 13] </ref> and Gaussian approximations [2]. Sampling methods and graphical models require extensive computational resources and are often restricted to the smoothing problem. Gaussian approximations also suffer from several drawbacks, especially when the probability density function being approximated has a large number of modes.
Reference: [14] <author> F Girosi, M Jones, and T Poggio. </author> <title> Regularization theory and neural networks architectures. </title> <journal> Neural Computation, </journal> <volume> 7 </volume> <pages> 219-269, </pages> <year> 1995. </year> <month> 39 </month>
Reference-contexts: In 17 batch learning, the regularisation parameter is often obtained by cross-validation [48, 49, 53]. Several methods have been proposed for the design of the regularisation functional. In our work we shall focus on weight decay regularisers. As a matter of interest, Girosi, Jones and Poggio <ref> [14] </ref> have proposed and alternative regulari-sation approach using a functional that clearly shows the relationship between regularisation and smoothness: = &lt; d ~ H (s) where the tildes indicate Fourier transforms and 1= ~ H (s) is chosen to be a high-pass filter.
Reference: [15] <author> Y C Ho and R C K Lee. </author> <title> A Bayesian approach to problems in stochastic es-timation and control. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> AC-9:333-339, </volume> <year> 1964. </year>
Reference-contexts: The conditional probability density function of w k given Y k (p (w k jY k )) constitutes the complete solution of the estimation problem <ref> [2, 15, 20] </ref>. This is simply because p (w k jY k ) embodies all the statistical information about w k given the measurements Y k and the initial condition w 0 . <p> The criteria are illustrated in Figure 7. As discussed above, the minimum variance estimate is the quantity of interest in our approach. 6 model parameters. The Bayesian solution to the optimal estimation problem is given by <ref> [15] </ref>: p (w k+1 jY k+1 ) = p (y k+1 jY k ) R R R (3) where the integrals run over the parameter space. The functional integral difference equation governing the evolution of the posterior density function (equation (3)) is not suitable for practical implementation [2, 20]. <p> Under the assumptions that the state space model noise processes are uncorrelated with each other and the initial estimates of the parameters w k and their covariance matrix P k , we can model the prior, evidence and likelihood functions as follows <ref> [1, 7, 15] </ref> (see also Appendix A): Prior = p (w k+1 jY k ; M j ; R k ; Q k ) ~ N ( ^ w k ; P k + Q k ) (9) Evidence = p (y k+1 jY k ; M j ; R k <p> P k+1 are given by: ^ w k+1 = ^ w k + K k+1 (y k+1 H k+1 ^ w k ) (13) where K k is known as the Kalman gain: K k+1 = k+1 k+1 Equations (13), (14) and (15) correspond exactly to the Kalman filter equations <ref> [2, 12, 15] </ref>. Alternatively, the Kalman filter equations may be derived by adopting the minimum variance approach. That is, by minimising the following cost functional [12]: J k = trace (P k ) (16) The Kalman filter algorithm may be easily implemented by computing K, ^ w and P recursively.
Reference: [16] <author> M Isard and A Blake. </author> <title> Contour tracking by stochastic propagation of conditional density. </title> <booktitle> In European Conference on Computer Vision, </booktitle> <pages> pages 343-356, </pages> <address> Cambridge, UK, </address> <year> 1996. </year>
Reference-contexts: It involves propagating a quantity (the posterior density function) that cannot be described by a finite number of parameters. Three alternative routes have been proposed to surmount this problem, namely sampling techniques <ref> [4, 8, 16] </ref>, graphical Bayesian models [3, 13] and Gaussian approximations [2]. Sampling methods and graphical models require extensive computational resources and are often restricted to the smoothing problem. Gaussian approximations also suffer from several drawbacks, especially when the probability density function being approximated has a large number of modes.
Reference: [17] <author> R A Jacobs. </author> <title> Increased rates of convergence through learning rates adaptation. </title> <booktitle> Neural Networks, </booktitle> <volume> 1 </volume> <pages> 295-307, </pages> <year> 1988. </year>
Reference-contexts: In its simplest form, gradient descent updates are computed according to the following equation: ^w k+1 = ^w k + (y k ^y k )x k where represents a learning rate parameter. An obvious improvement on this algorithm is to adapt the learning rates for each weight <ref> [17, 50] </ref>. <p> Sutton eliminates the problem of choosing Q by updating P with a variation of the least-mean-square rule <ref> [17, 50] </ref>. More specifically, Sutton's technique involves approximating P with a diagonal matrix, whose i-th diagonal entry is given by: p ii = exp (fi i ) where fi i is updated by the least-mean-square rule modified such that the learning rates for each parameter are updated sequentially.
Reference: [18] <author> E T Jaynes. </author> <title> Bayesian methods: General background. </title> <editor> In J H Justice, editor, </editor> <booktitle> Maximum Entropy and Bayesian Methods in Applied Statistics, </booktitle> <pages> pages 1-25. </pages> <publisher> Cambridge University Press, </publisher> <year> 1986. </year>
Reference-contexts: That is, the unknown quantities are described by probability density functions, whose widths indicate the range of values that are consistent with the prior information and the new data <ref> [18] </ref>. The conditional probability density function of w k given Y k (p (w k jY k )) constitutes the complete solution of the estimation problem [2, 15, 20].
Reference: [19] <author> A H Jazwinski. </author> <title> Adaptive filtering. </title> <journal> Automatica, </journal> <volume> 5 </volume> <pages> 475-485, </pages> <year> 1969. </year>
Reference-contexts: This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom [2, 27], Lee Feldkamp [40, 41, 42], Andrew Jazwinski <ref> [19, 20, 21] </ref>, David Mackay [28, 30], Gintaras Puskorius [40, 41, 42] and Richard Sutton [50, 51]. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. <p> One of the main purposes of this report is to show several interesting mathematical correlations between the problems of adaptive filtering, regularised error functions and adaptive learning rates. In the late sixties, Jazwinski <ref> [19, 21] </ref> proposed an algorithm for adaptive Kalman filtering based on the maximisa-tion of the probability density function of the new data given all the past data (evidence probability density function). His algorithm employed adaptive noise parameters. <p> In addition, in environments where the noise statistics change with time, such an approach can lead to large estimation errors and even to a divergence of errors. Several researchers in the estimation, filtering and control fields have attempted to solve this problem <ref> [19, 27, 32, 33, 34, 37, 52] </ref>. Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic. <p> An underlying requirement for updating the noise covariances without degrading the performance of the parameter estimation algorithm, is that the convergence of the parameter estimator to an acceptable solution should be faster than the variation of the noise statistics <ref> [19, 27] </ref>. As mentioned in Section 3, for rapidly changing noise statistics mixtures of models 13 with different noise statistics should be employed. <p> This result reveals that maximising the evidence function corresponds to equating the covariance over time r 2 k+1 to the ensemble covariance E [r 2 k+1 ]. That is, maximising the evidence leads to a covariance matching method. Jazwinski <ref> [19, 21] </ref> devised an algorithm for updating q according to equation (35). <p> Section 7.2 discusses an experiment where this behaviour is illustrated. The estimator of equation (36) is based on a single residual and is therefore of little statistical significance. This difficulty is overcome by employing the sample 21 mean for N predicted residuals, instead of a single residual. Jazwinski <ref> [19] </ref> shows that for the following sample mean: m r = N l=1 R k+l we may proceed as above, by maximising p (m r ), to obtain the following estimator: q = &gt; &gt; &lt; m 2 r E [m 2 r jq=0] 0 Otherwise (37) where S = S
Reference: [20] <author> A H Jazwinski. </author> <title> Stochastic Processes and Filtering Theory. </title> <publisher> Academic Press, </publisher> <year> 1970. </year>
Reference-contexts: This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom [2, 27], Lee Feldkamp [40, 41, 42], Andrew Jazwinski <ref> [19, 20, 21] </ref>, David Mackay [28, 30], Gintaras Puskorius [40, 41, 42] and Richard Sutton [50, 51]. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. <p> The problem of estimating w k given Y t is called the smoothing problem if k &lt; t ; the filtering problem if k = t ; or the prediction problem if k &gt; t <ref> [12, 20] </ref>. In the filtering problem, the estimate ^ w k can be used to predict future values of the output. In non-stationary environments we should favour the filtering approach to generate models of the sequential process being studied. <p> The conditional probability density function of w k given Y k (p (w k jY k )) constitutes the complete solution of the estimation problem <ref> [2, 15, 20] </ref>. This is simply because p (w k jY k ) embodies all the statistical information about w k given the measurements Y k and the initial condition w 0 . <p> The functional integral difference equation governing the evolution of the posterior density function (equation (3)) is not suitable for practical implementation <ref> [2, 20] </ref>. It involves propagating a quantity (the posterior density function) that cannot be described by a finite number of parameters. Three alternative routes have been proposed to surmount this problem, namely sampling techniques [4, 8, 16], graphical Bayesian models [3, 13] and Gaussian approximations [2]. <p> The situation for linear-Gaussian state space models is vastly simpler. There the mean and covariance 7 are sufficient statistics for describing the Gaussian posterior density function. In addition, the state can be computed in an optimal fashion with the Kalman filter <ref> [1, 2, 12, 20] </ref>. This motivates an approach based on Gaussian approximations that employs linear approximations about the current estimates. These two approximations lead to the formulation of the well known extended Kalman filter (EKF). <p> In many applications, it is not straightforward to choose the right noise covariances <ref> [20] </ref>. In addition, in environments where the noise statistics change with time, such an approach can lead to large estimation errors and even to a divergence of errors. Several researchers in the estimation, filtering and control fields have attempted to solve this problem [19, 27, 32, 33, 34, 37, 52].
Reference: [21] <author> A H Jazwinski and A E Bailie. </author> <title> Adaptive filtering. </title> <type> Technical Report 67-6, </type> <institution> Analytical Mechanics Associates, Maryland, </institution> <month> March </month> <year> 1967. </year>
Reference-contexts: This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom [2, 27], Lee Feldkamp [40, 41, 42], Andrew Jazwinski <ref> [19, 20, 21] </ref>, David Mackay [28, 30], Gintaras Puskorius [40, 41, 42] and Richard Sutton [50, 51]. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. <p> One of the main purposes of this report is to show several interesting mathematical correlations between the problems of adaptive filtering, regularised error functions and adaptive learning rates. In the late sixties, Jazwinski <ref> [19, 21] </ref> proposed an algorithm for adaptive Kalman filtering based on the maximisa-tion of the probability density function of the new data given all the past data (evidence probability density function). His algorithm employed adaptive noise parameters. <p> of the model residuals that E [r k+1 ] = 0 E [r 2 k+1 + R k+1 In addition, it is not difficult to prove that E [r k r l ] = 0 That is, the residuals are uncorrelated, and assuming they are Gaussian, they are also independent <ref> [21] </ref>. <p> This result reveals that maximising the evidence function corresponds to equating the covariance over time r 2 k+1 to the ensemble covariance E [r 2 k+1 ]. That is, maximising the evidence leads to a covariance matching method. Jazwinski <ref> [19, 21] </ref> devised an algorithm for updating q according to equation (35).
Reference: [22] <author> V Kadirkamanathan and M Kadirkamanathan. </author> <title> Recursive estimation of dynamic modular RBF networks. </title> <editor> In D S Touretzky, M C Mozer, and M E Hasselmo, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 8, </booktitle> <pages> pages 239-245, </pages> <year> 1995. </year>
Reference-contexts: In many cases, p (w k jY k ) is a multi-modal (several peaks) function. In this scenario, it is possible to use a committee of Kalman filters, where each individual filter approximates a particular mode, to produce a more accurate approximation <ref> [2, 5, 22, 23] </ref>. The parameter covariances of the individual estimators may be used to determine the contribution of each estimator to the committee. In addition, the parameter covariances serve the purpose of placing confidence intervals on the output prediction.
Reference: [23] <author> V Kadirkamanathan and M Kadirkamanathan. </author> <title> Kalman filter based estimation of dynamic modular networks. </title> <editor> In S Usui, Y Tohkura, S Katagiri, and E Wilson, editors, </editor> <booktitle> Proceedings of the IEEE Workshop on Neural Networks for Signal Processing VI, </booktitle> <pages> pages 180-189, </pages> <year> 1996. </year>
Reference-contexts: In many cases, p (w k jY k ) is a multi-modal (several peaks) function. In this scenario, it is possible to use a committee of Kalman filters, where each individual filter approximates a particular mode, to produce a more accurate approximation <ref> [2, 5, 22, 23] </ref>. The parameter covariances of the individual estimators may be used to determine the contribution of each estimator to the committee. In addition, the parameter covariances serve the purpose of placing confidence intervals on the output prediction.
Reference: [24] <author> V Kadirkamanathan and M Niranjan. </author> <title> Application of an architecturally dynamic network for speech pattern classification. </title> <booktitle> In Proceedings of the Institute of Acoustics, </booktitle> <volume> volume 14, </volume> <pages> pages 343-350, </pages> <year> 1992. </year>
Reference-contexts: Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic. In our work we make use of these results, from the adaptive estimation field, to improve the existing algorithms for training neural networks with the EKF algorithm <ref> [24, 25, 40, 41, 42, 45, 47, 56] </ref>. We achieve this in a principled manner by adhering to a hierarchical Bayesian methodology. In doing so, we are able to place some of the heuristic algorithms in the estimation field within a proper theoretical framework.
Reference: [25] <author> V Kadirkamanathan and M Niranjan. </author> <title> A function estimation approach to sequential learning with neural networks. </title> <journal> Neural Computation, </journal> <volume> 5 </volume> <pages> 954-975, </pages> <year> 1993. </year>
Reference-contexts: Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic. In our work we make use of these results, from the adaptive estimation field, to improve the existing algorithms for training neural networks with the EKF algorithm <ref> [24, 25, 40, 41, 42, 45, 47, 56] </ref>. We achieve this in a principled manner by adhering to a hierarchical Bayesian methodology. In doing so, we are able to place some of the heuristic algorithms in the estimation field within a proper theoretical framework.
Reference: [26] <author> R E Kalman and R S Bucy. </author> <title> New results in linear filtering and prediction theory. </title> <journal> Transactions of the ASME (Jounal of Basic Engineering), </journal> <volume> 83D:95-108, </volume> <year> 1961. </year>
Reference-contexts: To initialise the weights and their covariances we make use of a maximum likelihood method (Levenberg-Marquardt optimisation [36]). This prior is subsequently improved with the EKF recurrent 12 algorithm. 5 Noise Estimation and Regularisation A well known limitation of the Kalman-Bucy filter <ref> [26] </ref> and the extended Kalman filter, is the assumption of known a priori statistics to describe the measurement and process noise. In many applications, it is not straightforward to choose the right noise covariances [20].
Reference: [27] <author> X R Li and Y Bar-Shalom. </author> <title> A recursive multiple model approach to noise identification. </title> <journal> IEEE Transactions on Aerospace and Electronic Systems, </journal> <volume> 30(3) </volume> <pages> 671-684, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom <ref> [2, 27] </ref>, Lee Feldkamp [40, 41, 42], Andrew Jazwinski [19, 20, 21], David Mackay [28, 30], Gintaras Puskorius [40, 41, 42] and Richard Sutton [50, 51]. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. <p> To overcome this difficulty, in Section 5, we present techniques for estimating these covariances in slowly changing non-stationary environments. In environments where the noise statistics change rapidly, we shall favour the implementation of dynamic mixtures of models with different noise covariances <ref> [27] </ref>. This remark brings us to the topic of model selection. Model selection can be formulated in two ways; dynamic model selection and static model selection. In static model selection, the model assumed to be valid throughout the entire process is one of r hypothesised models. <p> Dynamic mixtures of models are far more general than static mixtures of models. However, in stationary environments, static mixtures are obviously more adequate. Dynamic mixtures of models correspond to a generalised version of hidden Markov models <ref> [27] </ref>. Mixtures of models are to be covered in a forthcoming paper. 4 Parameter Estimation In this section, we tackle the problem of estimating the model parameters. We start with a Bayesian derivation of the Kalman filter in the linear-Gaussian case and extend the approach to the nonlinear-Gaussian scenario. <p> In addition, in environments where the noise statistics change with time, such an approach can lead to large estimation errors and even to a divergence of errors. Several researchers in the estimation, filtering and control fields have attempted to solve this problem <ref> [19, 27, 32, 33, 34, 37, 52] </ref>. Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic. <p> Several researchers in the estimation, filtering and control fields have attempted to solve this problem [19, 27, 32, 33, 34, 37, 52]. Mehra [34] and Li and Bar-Shalom <ref> [27] </ref> have written brief surveys on this topic. In our work we make use of these results, from the adaptive estimation field, to improve the existing algorithms for training neural networks with the EKF algorithm [24, 25, 40, 41, 42, 45, 47, 56]. <p> An underlying requirement for updating the noise covariances without degrading the performance of the parameter estimation algorithm, is that the convergence of the parameter estimator to an acceptable solution should be faster than the variation of the noise statistics <ref> [19, 27] </ref>. As mentioned in Section 3, for rapidly changing noise statistics mixtures of models 13 with different noise statistics should be employed.
Reference: [28] <author> D J C Mackay. </author> <title> Bayesian interpolation. </title> <journal> Neural Computation, </journal> <volume> 4(3) </volume> <pages> 415-447, </pages> <year> 1992. </year>
Reference-contexts: This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom [2, 27], Lee Feldkamp [40, 41, 42], Andrew Jazwinski [19, 20, 21], David Mackay <ref> [28, 30] </ref>, Gintaras Puskorius [40, 41, 42] and Richard Sutton [50, 51]. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. <p> In the early nineties, Sutton [50, 51] showed for linear networks that distributed adaptive learning rates can be used to improve conventional error 3 back-propagation. We extend Sutton's ideas to nonlinear neural networks and relate them to other learning paradigms. Also in the early nineties, Mackay <ref> [28] </ref> introduced a method for estimating multiple regularisation coefficients, previously known in the Bayesian literature, to the neural network field. His method was also based on maximising the evidence density function. <p> It is important to keep in mind that when designing algorithms for updating the noise covariances, we should beware of not degrading the performance of the parameter estimation algorithm. This problem is also encountered in Bayesian methods for inverse problems, for example image reconstruction [46] and neural networks <ref> [28, 30] </ref>, where the regularisation coefficients are computed automatically from batches of data. <p> This can be done by borrowing some ideas from the Bayesian estimation field. In particular, we shall attempt to link the work on Bayesian estimation for neural networks <ref> [28, 30] </ref> and inverse problems [46] with the EKF estimation framework. This theoretical link should serve to enhance both methods. To pave the way for linking these methods, we shall briefly discuss David Mackay's Bayesian estimation approach to neural networks.
Reference: [29] <author> D J C Mackay. </author> <title> Bayesian nonlinear modelling for the prediction competition. </title> <journal> In ASHRAE Transactions Pt. </journal> <volume> 2, volume 100, </volume> <pages> Atlanta, </pages> <address> Georgia, </address> <year> 1994. </year>
Reference-contexts: In this context, distributed priors are used to determine the relevance of the various inputs and basis functions. For example, while addressing the ARDI problem, Mackay <ref> [29, 31] </ref> has proposed the following modification to the prior of equation (22): p (wjff c ) = 1 c Z w (ff c ) X ff c E wc where E wc = i2c i and the regularisation coefficient ff c controls the weight decay rates for the parameters linked
Reference: [30] <author> D J C Mackay. Hyperparameters: </author> <title> Optimise or integrate out? In G Heid-breder, editor, Maximum Entropy and Bayesian Methods, </title> <year> 1994. </year>
Reference-contexts: This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom [2, 27], Lee Feldkamp [40, 41, 42], Andrew Jazwinski [19, 20, 21], David Mackay <ref> [28, 30] </ref>, Gintaras Puskorius [40, 41, 42] and Richard Sutton [50, 51]. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. <p> It is important to keep in mind that when designing algorithms for updating the noise covariances, we should beware of not degrading the performance of the parameter estimation algorithm. This problem is also encountered in Bayesian methods for inverse problems, for example image reconstruction [46] and neural networks <ref> [28, 30] </ref>, where the regularisation coefficients are computed automatically from batches of data. <p> This can be done by borrowing some ideas from the Bayesian estimation field. In particular, we shall attempt to link the work on Bayesian estimation for neural networks <ref> [28, 30] </ref> and inverse problems [46] with the EKF estimation framework. This theoretical link should serve to enhance both methods. To pave the way for linking these methods, we shall briefly discuss David Mackay's Bayesian estimation approach to neural networks. <p> The remaining weights have no contribution because their magnitudes are forced to zero by the weight decay prior. Instead of adopting Mackay's evidence framework, it is possible to max-imise the posterior density function by performing integrations over the hyper-parameters analytically <ref> [6, 30, 55, 57] </ref>. The latter approach is known as the MAP framework for ff and fi. <p> That is, ff and fi are updated according to: ff k+1 = P q i fi k+1 = P n Mackay <ref> [30] </ref> has argued in favour of the evidence framework by stating that fitting a Gaussian around the MAP estimate, that is the peak of the posterior density function, does not represent the best approximation to the posterior density function.
Reference: [31] <author> D J C Mackay. </author> <title> Probable networks and plausible predictions a review of practical Bayesian methods for supervised neural networks. </title> <booktitle> Network-Computation in Neural Systems, </booktitle> <volume> 6 </volume> <pages> 469-505, </pages> <year> 1995. </year>
Reference-contexts: Spurious input variables will invariably lead to deterioration in model performance. For instance, in conventional neural network modelling of finite data sets, the weights in charge of scaling the irrelevant inputs do not usually tend to zero because of random correlations between the inputs and the output <ref> [31] </ref>. In addition, in many engineering and financial applications [9, 10, 38], we often find that we know part of the equation governing a particular process. <p> In this context, distributed priors are used to determine the relevance of the various inputs and basis functions. For example, while addressing the ARDI problem, Mackay <ref> [29, 31] </ref> has proposed the following modification to the prior of equation (22): p (wjff c ) = 1 c Z w (ff c ) X ff c E wc where E wc = i2c i and the regularisation coefficient ff c controls the weight decay rates for the parameters linked
Reference: [32] <author> R K Mehra. </author> <title> On the identification of variances and adaptive Kalman filtering. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> AC-15(2):175-184, </volume> <month> April </month> <year> 1970. </year>
Reference-contexts: In addition, in environments where the noise statistics change with time, such an approach can lead to large estimation errors and even to a divergence of errors. Several researchers in the estimation, filtering and control fields have attempted to solve this problem <ref> [19, 27, 32, 33, 34, 37, 52] </ref>. Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic.
Reference: [33] <author> R K Mehra. </author> <title> On-line identification of linear dynamic systems with applications to Kalman filtering. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> AC-16(1):12-21, </volume> <month> February </month> <year> 1971. </year>
Reference-contexts: In addition, in environments where the noise statistics change with time, such an approach can lead to large estimation errors and even to a divergence of errors. Several researchers in the estimation, filtering and control fields have attempted to solve this problem <ref> [19, 27, 32, 33, 34, 37, 52] </ref>. Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic.
Reference: [34] <author> R K Mehra. </author> <title> Approaches to adaptive filtering. </title> <journal> IEEE Transactions on Automatic Control, </journal> <pages> pages 693-698, </pages> <month> October </month> <year> 1972. </year>
Reference-contexts: In addition, in environments where the noise statistics change with time, such an approach can lead to large estimation errors and even to a divergence of errors. Several researchers in the estimation, filtering and control fields have attempted to solve this problem <ref> [19, 27, 32, 33, 34, 37, 52] </ref>. Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic. <p> Several researchers in the estimation, filtering and control fields have attempted to solve this problem [19, 27, 32, 33, 34, 37, 52]. Mehra <ref> [34] </ref> and Li and Bar-Shalom [27] have written brief surveys on this topic. In our work we make use of these results, from the adaptive estimation field, to improve the existing algorithms for training neural networks with the EKF algorithm [24, 25, 40, 41, 42, 45, 47, 56].
Reference: [35] <author> J Moody. </author> <title> Neural networks for financial predictions. </title> <booktitle> Cambridge University Neural Networks Summer School, </booktitle> <year> 1997. </year>
Reference-contexts: It is a dilemma because we cannot ascertain, without a priori knowledge, whether the fluctuations in the data correspond to non-stationary behaviour or noise. This problem is typical of high frequency predictions in foreign exchange markets <ref> [35] </ref>. 5.3.2 Scalar measurement noise estimation By maximising the evidence function with respect to R k = rI m , as done in the previous section, one obtains the following estimator for r: r = &gt; &lt; r 2 k if r 0 0 Otherwise (38) The hyper-parameter r is not
Reference: [36] <author> J J More. </author> <title> The Levenberg-Marquardt algorithm: Implementation and theory. </title> <editor> In A Watson, editor, </editor> <booktitle> Numerical Analysis, </booktitle> <pages> pages 105-116. </pages> <booktitle> Lecture Notes in Mathematics 630, </booktitle> <publisher> Springer Verlag, </publisher> <year> 1977. </year>
Reference-contexts: In our work we place more emphasis on the problem of automatically estimating the noise covariances. To initialise the weights and their covariances we make use of a maximum likelihood method (Levenberg-Marquardt optimisation <ref> [36] </ref>). This prior is subsequently improved with the EKF recurrent 12 algorithm. 5 Noise Estimation and Regularisation A well known limitation of the Kalman-Bucy filter [26] and the extended Kalman filter, is the assumption of known a priori statistics to describe the measurement and process noise.
Reference: [37] <author> K A Myers and B D Tapley. </author> <title> Adaptive sequential estimation of unknown noise statistics. </title> <journal> IEEE Transactions on Automatic Control, </journal> <pages> pages 520-523, </pages> <month> August </month> <year> 1976. </year>
Reference-contexts: In addition, in environments where the noise statistics change with time, such an approach can lead to large estimation errors and even to a divergence of errors. Several researchers in the estimation, filtering and control fields have attempted to solve this problem <ref> [19, 27, 32, 33, 34, 37, 52] </ref>. Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic.
Reference: [38] <author> M Niranjan. </author> <title> Sequential tracking in pricing financial options using model based and neural network approaches. </title> <editor> In M C Mozer, M I Jordan, and T Petsche, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <pages> pages 960-966, </pages> <year> 1996. </year>
Reference-contexts: For instance, in conventional neural network modelling of finite data sets, the weights in charge of scaling the irrelevant inputs do not usually tend to zero because of random correlations between the inputs and the output [31]. In addition, in many engineering and financial applications <ref> [9, 10, 38] </ref>, we often find that we know part of the equation governing a particular process. That is, we might have inferred that the relationship between two measurements x and y is given by: y = x 2 + g (x) where the function g (x) is unknown.
Reference: [39] <author> M Niranjan, I J Cox, and S Hingorani. </author> <title> Recursive estimation of formants in speech. </title> <booktitle> In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, </booktitle> <year> 1994. </year> <month> 41 </month>
Reference-contexts: In addition, we assume no knowledge of the drift function f k (:), that is the parameters are generated by a first order Markov process w k+1 = w k + d k . In certain applications, such as image tracking [43] and speech enhancement <ref> [39] </ref>, we may know the equations governing the evolution of a subset of the states. In such scenarios, the drift function may be modelled for that particular subset of states, while the remaining states are assumed to obey a first order Markov process.
Reference: [40] <author> G V Puskorius and L A Feldkamp. </author> <title> Decoupled extended Kalman filter train-ing of feedforward layered networks. </title> <booktitle> In International Joint Conference on Neural Networks, </booktitle> <pages> pages 307-312, </pages> <address> Seattle, </address> <year> 1991. </year>
Reference-contexts: This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom [2, 27], Lee Feldkamp <ref> [40, 41, 42] </ref>, Andrew Jazwinski [19, 20, 21], David Mackay [28, 30], Gintaras Puskorius [40, 41, 42] and Richard Sutton [50, 51]. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. <p> This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom [2, 27], Lee Feldkamp <ref> [40, 41, 42] </ref>, Andrew Jazwinski [19, 20, 21], David Mackay [28, 30], Gintaras Puskorius [40, 41, 42] and Richard Sutton [50, 51]. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. <p> In this particular work we adopt the use of Gaussian approximations because they provide an elegant treatment of the problems of regularisation, sequential learning and model selection. In addition, several successful applications of Gaussian approximations for neural networks in the automotive industry have been registered <ref> [40, 42] </ref>. As mentioned above, the implementation of the optimal estimator involves a functional recursion and is therefore of limited feasibility. The situation for linear-Gaussian state space models is vastly simpler. There the mean and covariance 7 are sufficient statistics for describing the Gaussian posterior density function. <p> An example of how to do this for a simple MLP is presented in Appendix B. The algorithm proposed by Singhal and Wu requires a considerable computational effort. The complexity is of the order mq 2 multiplications per estimation step. Shah, Palmieri and Datum [45] and Puskorius and Feldkamp <ref> [40] </ref> have proposed strategies for decoupling the global EKF estimation algorithm into local EKF estimation sub-problems. For example, they suggest that the weights of each neuron could be updated independently. The assumption in the local updating strategies is that the weights are decoupled and, consequently, P is a block-diagonal matrix. <p> Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic. In our work we make use of these results, from the adaptive estimation field, to improve the existing algorithms for training neural networks with the EKF algorithm <ref> [24, 25, 40, 41, 42, 45, 47, 56] </ref>. We achieve this in a principled manner by adhering to a hierarchical Bayesian methodology. In doing so, we are able to place some of the heuristic algorithms in the estimation field within a proper theoretical framework.
Reference: [41] <author> G V Puskorius and L A Feldkamp. </author> <title> Neurocontrol of nonlinear dynamical systems with Kalman filter trained recurrent networks. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5(2) </volume> <pages> 279-297, </pages> <year> 1994. </year>
Reference-contexts: This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom [2, 27], Lee Feldkamp <ref> [40, 41, 42] </ref>, Andrew Jazwinski [19, 20, 21], David Mackay [28, 30], Gintaras Puskorius [40, 41, 42] and Richard Sutton [50, 51]. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. <p> This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom [2, 27], Lee Feldkamp <ref> [40, 41, 42] </ref>, Andrew Jazwinski [19, 20, 21], David Mackay [28, 30], Gintaras Puskorius [40, 41, 42] and Richard Sutton [50, 51]. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. <p> Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic. In our work we make use of these results, from the adaptive estimation field, to improve the existing algorithms for training neural networks with the EKF algorithm <ref> [24, 25, 40, 41, 42, 45, 47, 56] </ref>. We achieve this in a principled manner by adhering to a hierarchical Bayesian methodology. In doing so, we are able to place some of the heuristic algorithms in the estimation field within a proper theoretical framework.
Reference: [42] <author> G V Puskorius, L A Feldkamp, and L I Davis. </author> <title> Dynamic neural network methods applied to on-vehicle idle speed control. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 84(10) </volume> <pages> 1407-1420, </pages> <year> 1996. </year>
Reference-contexts: This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom [2, 27], Lee Feldkamp <ref> [40, 41, 42] </ref>, Andrew Jazwinski [19, 20, 21], David Mackay [28, 30], Gintaras Puskorius [40, 41, 42] and Richard Sutton [50, 51]. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. <p> This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom [2, 27], Lee Feldkamp <ref> [40, 41, 42] </ref>, Andrew Jazwinski [19, 20, 21], David Mackay [28, 30], Gintaras Puskorius [40, 41, 42] and Richard Sutton [50, 51]. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. <p> In this particular work we adopt the use of Gaussian approximations because they provide an elegant treatment of the problems of regularisation, sequential learning and model selection. In addition, several successful applications of Gaussian approximations for neural networks in the automotive industry have been registered <ref> [40, 42] </ref>. As mentioned above, the implementation of the optimal estimator involves a functional recursion and is therefore of limited feasibility. The situation for linear-Gaussian state space models is vastly simpler. There the mean and covariance 7 are sufficient statistics for describing the Gaussian posterior density function. <p> Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic. In our work we make use of these results, from the adaptive estimation field, to improve the existing algorithms for training neural networks with the EKF algorithm <ref> [24, 25, 40, 41, 42, 45, 47, 56] </ref>. We achieve this in a principled manner by adhering to a hierarchical Bayesian methodology. In doing so, we are able to place some of the heuristic algorithms in the estimation field within a proper theoretical framework.
Reference: [43] <author> D Reynard, A Wildenberg, A Blake, and J Marchant. </author> <title> Learning dynamics of complex motions from image sequences. </title> <booktitle> In European Conference on Computer Vision, </booktitle> <pages> pages 357-368, </pages> <address> Cambridge, UK, </address> <year> 1996. </year>
Reference-contexts: In addition, we assume no knowledge of the drift function f k (:), that is the parameters are generated by a first order Markov process w k+1 = w k + d k . In certain applications, such as image tracking <ref> [43] </ref> and speech enhancement [39], we may know the equations governing the evolution of a subset of the states. In such scenarios, the drift function may be modelled for that particular subset of states, while the remaining states are assumed to obey a first order Markov process.
Reference: [44] <author> D W Ruck, S K Rogers, M Kabrisky, P S Maybeck, and M E Oxley. </author> <title> Comparative analysis of backpropagation and the extended Kalman filter for training multilayer perceptrons. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(6) </volume> <pages> 686-690, </pages> <year> 1992. </year>
Reference-contexts: These statistics are essential for placing error bars on the predictions and for combining separate networks into committees of networks. As a matter of interest, it has been proven elsewhere that the back-propagation algorithm is simply a degenerate of the EKF algorithm <ref> [44] </ref>. However, the EKF algorithm for training MLPs suffers from serious difficulties, namely choosing the initial conditions (w 0 ; P 0 ) and the noise covariance matrices R and Q. In our work we place more emphasis on the problem of automatically estimating the noise covariances.
Reference: [45] <author> S Shah, F Palmieri, and M Datum. </author> <title> Optimal filtering algorithms for fast learning in feedforward neural networks. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 779-787, </pages> <year> 1992. </year>
Reference-contexts: An example of how to do this for a simple MLP is presented in Appendix B. The algorithm proposed by Singhal and Wu requires a considerable computational effort. The complexity is of the order mq 2 multiplications per estimation step. Shah, Palmieri and Datum <ref> [45] </ref> and Puskorius and Feldkamp [40] have proposed strategies for decoupling the global EKF estimation algorithm into local EKF estimation sub-problems. For example, they suggest that the weights of each neuron could be updated independently. <p> Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic. In our work we make use of these results, from the adaptive estimation field, to improve the existing algorithms for training neural networks with the EKF algorithm <ref> [24, 25, 40, 41, 42, 45, 47, 56] </ref>. We achieve this in a principled manner by adhering to a hierarchical Bayesian methodology. In doing so, we are able to place some of the heuristic algorithms in the estimation field within a proper theoretical framework.
Reference: [46] <author> S Sibisi. </author> <title> Regularization and inverse problems. </title> <booktitle> In Maximum Entropy and Bayesian Methods, </booktitle> <pages> pages 389-396. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1989. </year>
Reference-contexts: It is important to keep in mind that when designing algorithms for updating the noise covariances, we should beware of not degrading the performance of the parameter estimation algorithm. This problem is also encountered in Bayesian methods for inverse problems, for example image reconstruction <ref> [46] </ref> and neural networks [28, 30], where the regularisation coefficients are computed automatically from batches of data. <p> This can be done by borrowing some ideas from the Bayesian estimation field. In particular, we shall attempt to link the work on Bayesian estimation for neural networks [28, 30] and inverse problems <ref> [46] </ref> with the EKF estimation framework. This theoretical link should serve to enhance both methods. To pave the way for linking these methods, we shall briefly discuss David Mackay's Bayesian estimation approach to neural networks.
Reference: [47] <author> S Singhal and L Wu. </author> <title> Training multilayer perceptrons with the extended Kalman algorithm. </title> <editor> In D S Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 1, </volume> <pages> pages 133-140, </pages> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: The immediate availability of confidence intervals and of mixing coefficients, required to generate mixtures of models, has motivated us to train neural networks with the EKF algorithm. 4.3 Training MLPs with the EKF One of the earliest implementations of EKF trained MLPs is due to Singhal and Wu <ref> [47] </ref>. In their method, the network weights are grouped into a single vector w that is updated in accordance with the EKF equations. The entries of the Jacobian matrix are calculated by back-propagating the m output values fy 1 (t); y 2 (t); ; y m (t)g through the network. <p> Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic. In our work we make use of these results, from the adaptive estimation field, to improve the existing algorithms for training neural networks with the EKF algorithm <ref> [24, 25, 40, 41, 42, 45, 47, 56] </ref>. We achieve this in a principled manner by adhering to a hierarchical Bayesian methodology. In doing so, we are able to place some of the heuristic algorithms in the estimation field within a proper theoretical framework.
Reference: [48] <author> M Stone. </author> <title> Cross-validatory choice and assessment of statistical predictions. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> B 36(1) </volume> <pages> 111-147, </pages> <year> 1974. </year>
Reference-contexts: A large value of places more importance on the smoothness of the model, while a small value of places more emphasis on fitting the data. The functional penalises for excessive model complexity. In 17 batch learning, the regularisation parameter is often obtained by cross-validation <ref> [48, 49, 53] </ref>. Several methods have been proposed for the design of the regularisation functional. In our work we shall focus on weight decay regularisers.
Reference: [49] <author> M Stone. </author> <title> Cross-validation: A review. </title> <journal> Math. Operationsforsch. Statist. Ser. Statistics, </journal> <volume> 9(1) </volume> <pages> 127-139, </pages> <year> 1978. </year>
Reference-contexts: A large value of places more importance on the smoothness of the model, while a small value of places more emphasis on fitting the data. The functional penalises for excessive model complexity. In 17 batch learning, the regularisation parameter is often obtained by cross-validation <ref> [48, 49, 53] </ref>. Several methods have been proposed for the design of the regularisation functional. In our work we shall focus on weight decay regularisers.
Reference: [50] <author> R S Sutton. </author> <title> Adapting bias by gradient descent: An incremental version of delta-bar-delta. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 171-176. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom [2, 27], Lee Feldkamp [40, 41, 42], Andrew Jazwinski [19, 20, 21], David Mackay [28, 30], Gintaras Puskorius [40, 41, 42] and Richard Sutton <ref> [50, 51] </ref>. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. One of the main purposes of this report is to show several interesting mathematical correlations between the problems of adaptive filtering, regularised error functions and adaptive learning rates. <p> In the late sixties, Jazwinski [19, 21] proposed an algorithm for adaptive Kalman filtering based on the maximisa-tion of the probability density function of the new data given all the past data (evidence probability density function). His algorithm employed adaptive noise parameters. In the early nineties, Sutton <ref> [50, 51] </ref> showed for linear networks that distributed adaptive learning rates can be used to improve conventional error 3 back-propagation. We extend Sutton's ideas to nonlinear neural networks and relate them to other learning paradigms. <p> Finally, the sequential evidence maximisation with updated priors will be appropriate for illustrating various issues including the regularisation/tracking dilemma and automatic relevance determination of network inputs and basis functions. 5.1 Adaptive Distributed Learning Rates and Kalman Fil tering The work of Richard Sutton with linear networks <ref> [50, 51] </ref> sheds light on the relationship between adaptive distributed learning rates in gradient descent algorithms and adaptive Kalman filtering. To merely simplify the exposition, without loss of generality, we shall restrict our explanation of this topic to a linear network with a single neuron. <p> In its simplest form, gradient descent updates are computed according to the following equation: ^w k+1 = ^w k + (y k ^y k )x k where represents a learning rate parameter. An obvious improvement on this algorithm is to adapt the learning rates for each weight <ref> [17, 50] </ref>. <p> Sutton eliminates the problem of choosing Q by updating P with a variation of the least-mean-square rule <ref> [17, 50] </ref>. More specifically, Sutton's technique involves approximating P with a diagonal matrix, whose i-th diagonal entry is given by: p ii = exp (fi i ) where fi i is updated by the least-mean-square rule modified such that the learning rates for each parameter are updated sequentially. <p> That is, a different regularisation coefficient is assigned to each input. The decay rates for irrelevant inputs may, therefore, be automatically inferred to be large. Consequently, their harmful effect on the model is prevented. A similar technique based on multiple hyper-parameters for ARDI has been proposed by Sutton <ref> [50] </ref>. Sutton implements multiple learning rates to determine the relevance of various inputs to a linear network. The theory developed in Sections 5.1, 5.2 and 5.3 established the equivalence between multiple learning rates , regularisation coefficients ff c and process noise hyper-parameters q.
Reference: [51] <author> R S Sutton. </author> <booktitle> Gain adaptation beats least squares? In Proceedings of the Seventh Yale Workshop on Adaptive Learning Systems, </booktitle> <pages> pages 161-166, </pages> <year> 1992. </year>
Reference-contexts: This research endeavour has been motivated by the synergetic efforts of various outstanding researchers in the fields of tracking and machine learning, namely Yaakov Bar-shalom [2, 27], Lee Feldkamp [40, 41, 42], Andrew Jazwinski [19, 20, 21], David Mackay [28, 30], Gintaras Puskorius [40, 41, 42] and Richard Sutton <ref> [50, 51] </ref>. The work is unique in that it places the sequential training of neural networks within a rigorous hierarchical Bayesian framework. One of the main purposes of this report is to show several interesting mathematical correlations between the problems of adaptive filtering, regularised error functions and adaptive learning rates. <p> In the late sixties, Jazwinski [19, 21] proposed an algorithm for adaptive Kalman filtering based on the maximisa-tion of the probability density function of the new data given all the past data (evidence probability density function). His algorithm employed adaptive noise parameters. In the early nineties, Sutton <ref> [50, 51] </ref> showed for linear networks that distributed adaptive learning rates can be used to improve conventional error 3 back-propagation. We extend Sutton's ideas to nonlinear neural networks and relate them to other learning paradigms. <p> Finally, the sequential evidence maximisation with updated priors will be appropriate for illustrating various issues including the regularisation/tracking dilemma and automatic relevance determination of network inputs and basis functions. 5.1 Adaptive Distributed Learning Rates and Kalman Fil tering The work of Richard Sutton with linear networks <ref> [50, 51] </ref> sheds light on the relationship between adaptive distributed learning rates in gradient descent algorithms and adaptive Kalman filtering. To merely simplify the exposition, without loss of generality, we shall restrict our explanation of this topic to a linear network with a single neuron. <p> Sutton <ref> [51] </ref> has proposed a gradient descent approach for updating the Kalman filter equations. The aim of his method was to reduce the computational time at the expense of a small deterioration in the performance of the estimator.
Reference: [52] <author> R R Tenney, R S Hebbert, and N S Sandell. </author> <title> A tracking filter for maneuvering sources. </title> <journal> IEEE Transactions on Automatic Control, </journal> <pages> pages 246-251, </pages> <month> April </month> <year> 1977. </year>
Reference-contexts: In addition, in environments where the noise statistics change with time, such an approach can lead to large estimation errors and even to a divergence of errors. Several researchers in the estimation, filtering and control fields have attempted to solve this problem <ref> [19, 27, 32, 33, 34, 37, 52] </ref>. Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic.
Reference: [53] <author> G Wahba and S Wold. </author> <title> A completely automatic French curve: Fitting spline functions by cross-validation. </title> <journal> Communications on Statistics, Series A, </journal> <volume> 4(1) </volume> <pages> 1-17, </pages> <year> 1969. </year>
Reference-contexts: A large value of places more importance on the smoothness of the model, while a small value of places more emphasis on fitting the data. The functional penalises for excessive model complexity. In 17 batch learning, the regularisation parameter is often obtained by cross-validation <ref> [48, 49, 53] </ref>. Several methods have been proposed for the design of the regularisation functional. In our work we shall focus on weight decay regularisers.
Reference: [54] <editor> A S Weigend and N A Gershenfeld, editors. </editor> <title> Time Series Prediction Forecasting the Future and Understanding the Past. </title> <publisher> Addison Wesley, </publisher> <address> MA, </address> <year> 1994. </year>
Reference-contexts: Figure 7 shows a section of the one step ahead predictions with their corresponding error bars or confidence intervals. To test this noise adaptation framework on a real data set, we consider the well known Santa Fe chaotic laser time series <ref> [54] </ref>. Figure 8 shows the one step ahead and unbounded predictions obtained with a simple one hidden layer (10 neurons) network. It should be emphasised that our purpose here was not to try to improve the predictions obtained by other authors.
Reference: [55] <author> P M Williams. </author> <title> Bayesian regularization and pruning using a Laplace prior. </title> <journal> Neural Computation, </journal> <volume> 7(1) </volume> <pages> 117-143, </pages> <year> 1995. </year>
Reference-contexts: The remaining weights have no contribution because their magnitudes are forced to zero by the weight decay prior. Instead of adopting Mackay's evidence framework, it is possible to max-imise the posterior density function by performing integrations over the hyper-parameters analytically <ref> [6, 30, 55, 57] </ref>. The latter approach is known as the MAP framework for ff and fi.
Reference: [56] <author> R J Williams. </author> <title> Some observations on the use of the extended Kalman filter as a recurrent network learning algorithm. </title> <type> Technical Report NU-CCS-92-1, </type> <institution> College of Computer Science, Northeastern University, </institution> <address> Boston, </address> <year> 1992. </year>
Reference-contexts: Mehra [34] and Li and Bar-Shalom [27] have written brief surveys on this topic. In our work we make use of these results, from the adaptive estimation field, to improve the existing algorithms for training neural networks with the EKF algorithm <ref> [24, 25, 40, 41, 42, 45, 47, 56] </ref>. We achieve this in a principled manner by adhering to a hierarchical Bayesian methodology. In doing so, we are able to place some of the heuristic algorithms in the estimation field within a proper theoretical framework.
Reference: [57] <author> D H Wolpert. </author> <title> On the use of evidence in neural networks. </title> <editor> In S J Hanson, J D Cowan, and C L Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 5, </volume> <pages> pages 539-546, </pages> <address> San Mateo, CA, </address> <year> 1993. </year> <month> 43 </month>
Reference-contexts: The remaining weights have no contribution because their magnitudes are forced to zero by the weight decay prior. Instead of adopting Mackay's evidence framework, it is possible to max-imise the posterior density function by performing integrations over the hyper-parameters analytically <ref> [6, 30, 55, 57] </ref>. The latter approach is known as the MAP framework for ff and fi.
References-found: 57

