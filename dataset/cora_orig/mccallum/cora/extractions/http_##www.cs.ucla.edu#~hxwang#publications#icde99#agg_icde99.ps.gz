URL: http://www.cs.ucla.edu/~hxwang/publications/icde99/agg_icde99.ps.gz
Refering-URL: http://www.cs.ucla.edu/~hxwang/publications/index.html
Root-URL: http://www.cs.ucla.edu
Email: hxwang@cs.ucla.edu zaniolo@cs.ucla.edu  
Title: User-Defined Aggregates for Data Mining and other Advanced Database Applications  
Author: Haixun Wang and Carlo Zaniolo 
Address: Los Angeles Los Angeles, CA 90095  
Affiliation: Computer Science Department University of California at  
Note: ICDE'99 Submission Number: U059  
Abstract: In this paper, we extend SQL with user-defined aggregates, and show that this new capability greatly improves its ability to support advanced database applications, particularly data mining applications. We build on SQL3's proposal for user-defined aggregates, which we extend with an early-return mechanism, as needed to express on-line aggregation and a broad range of new aggregate-like functions. Complex data mining algorithms can now be succinctly expressed and efficiently supported in SQL with these extended aggregates. Then, we describe two simple implementations developed at UCLA|one in Oracle PL/SQL, the other in DB2 using scratch-pad functions|and discuss their performance implications. Finally, we use the definition and implementation of extended user-defined aggregates in LDL++, to identify classes of aggregate functions that are monotonic. Since monotonic aggregates can be used without restrictions in recursive queries, this discovery further enhances the power and flexibility of SQL with extended user-defined aggregates. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Rakesh Agrawal and Ramkrishnan Srikant. </author> <title> "Fast Algorithm for Mining Association Rules." </title> <booktitle> In Proceedings of the 20th VLDB Conference, </booktitle> <address> Santiago, Chile, </address> <year> 1994. </year>
Reference-contexts: This aggregate-based formulation is preferable 3 to the original formulation given in [21] since it ensures scalability and performance on large training sets. Count-like aggregates are also the linchpin of other classifiers, such as the one in <ref> [1] </ref> that will be discussed briefly in Section 4. 2.2 Discovering Associations by Meta Predicates Another application that relies on count-like aggregates aims at discovering associations. <p> For instance, market data analysis represents one of the best known applications of association rules. The Apriori algorithm which is at core of this application searches for frequent items sets: i.e., it counts items and combination of items that are above a given threshold <ref> [1, 3, 5] </ref>. While this computation can be expressed using the SQL count aggregate, ensuring the efficiency of these queries represents much more of a challenge [18]. The same is true for a related class of queries called iceberg queries [9]. <p> Thus the external tables created for these three aggregates carry the result from the last aggregate to the next. Our experience with iceberg queries illustrates the ability of combining database access with control of specialized data structures via user-defined aggregates. Many data mining algorithms, including the Apriori algorithm <ref> [1, 5] </ref>, use iceberg queries as their main building block. 12 The SPRINT/PUBLIC Decision Tree Builders A decision tree recursively partitions a training set on a selected value of a selected attribute until each partition consists entirely of one class of items [19].
Reference: [2] <author> R. Agrawal, K. Shim: </author> <title> "Developing Tightly-Coupled Data Mining Applications on a Relational Database System", </title> <booktitle> Proc. of the 2nd Int'l Conference on Knowledge Discovery in Databases and Data Mining, </booktitle> <address> Portland, Oregon, </address> <month> August, </month> <year> 1996. </year> <month> 16 </month>
Reference-contexts: As a result, most data mining algorithms are currently designed to either bypass completely the database system, or to operate in a loose coupling mode <ref> [2] </ref>: a better integration of data mining algorithms and database systems represents a critical research challenge [18]. 1 In this paper, we introduce the notion of extended user-defined aggregates, and show that they can be used to dovetail data mining algorithms into database systems; also, they can play an important role
Reference: [3] <author> R. Agrawal and J.C. Shafer, </author> <title> "Parallel Mining of Association Rules: Design, </title> <journal> Implemen--tation and Experience", IEEE Transactions on Knowledge and Data Engineering, Vol.8, </journal> <volume> No. 6, </volume> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: For instance, market data analysis represents one of the best known applications of association rules. The Apriori algorithm which is at core of this application searches for frequent items sets: i.e., it counts items and combination of items that are above a given threshold <ref> [1, 3, 5] </ref>. While this computation can be expressed using the SQL count aggregate, ensuring the efficiency of these queries represents much more of a challenge [18]. The same is true for a related class of queries called iceberg queries [9]. <p> first bear little resemblance to aggregates or other database operations. (For instance, our boosted Bayesian classifier in SQL is frequently a source of surprise or skepticism.) Seeking scalability and performance, several classification algorithms have now been recast into a more database-centric framework where they can be expressed using aggregate-like operations <ref> [3, 19] </ref>. Reinforcing this trend, this paper provide tools for defining aggregates capable of supporting better data mining applications in a database-centric environment. 3 User-Defined Aggregates in SQL3 SQL3 prescribes that iterative routines should be used to define user-defined aggregates in some external language.
Reference: [4] <author> Punit Bhargava, </author> <title> "User-Defined Aggregates in Database Languages," </title> <type> Master's Thesis, </type> <institution> UCLA CS Dept., </institution> <note> Winter 98, http://www.cs.ucla.edu/~czdemo/SQL-AG/ </note> . 
Reference-contexts: Although, the database-oriented environment and compatible data types of PL/SQL provided some additional convenience and flexibility, the performance edge was clearly with the DB2 implementation. Therefore, here we will focus on DB2-based implementation; details on the Oracle implementation can be found in <ref> [4] </ref>. In IBM's DB2, users can define their own UDFs in a host programming language. The option of calling user-defined functions in so-called UNFENCED mode makes UDFs in DB2 system even more desirable.
Reference: [5] <author> S. Brin, R. Motwani, J. Ullman, and S. Tsur, </author> <title> "Dynamic Itemset: Counting and Implication Rules for Market Basket Data, </title> <booktitle> Proceedings ACM-SIGMOD Int. Conf on Management of Data, </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: For instance, market data analysis represents one of the best known applications of association rules. The Apriori algorithm which is at core of this application searches for frequent items sets: i.e., it counts items and combination of items that are above a given threshold <ref> [1, 3, 5] </ref>. While this computation can be expressed using the SQL count aggregate, ensuring the efficiency of these queries represents much more of a challenge [18]. The same is true for a related class of queries called iceberg queries [9]. <p> 2 2 SELECT company, mw5avg (price) FROM stock closing GROUPBY company; This is compiled into the following DB2 statement: SELECT company, mw5avg (price) FROM stock closing WHERE mw5avg groupby (company,price) &gt; 0; To implement this user-defined aggregate, the user will supply the following functions. struct f int pos; float window <ref> [5] </ref>; g StateType; void single mw5avg (floatfl x, StateTypefl state) f state!window [0] = flx; state!pos = 1; g void multi mw5avg (floatfl x, StateTypefl state, SateTypefl next state) f state!pos++; state!window [state!pos % 5] = flx; next state = state; g int return mw5avg (floatfl x, StateTypefl state, floatfl result) <p> Thus the external tables created for these three aggregates carry the result from the last aggregate to the next. Our experience with iceberg queries illustrates the ability of combining database access with control of specialized data structures via user-defined aggregates. Many data mining algorithms, including the Apriori algorithm <ref> [1, 5] </ref>, use iceberg queries as their main building block. 12 The SPRINT/PUBLIC Decision Tree Builders A decision tree recursively partitions a training set on a selected value of a selected attribute until each partition consists entirely of one class of items [19].
Reference: [6] <author> C. X. Chen and C. Zaniolo, </author> <title> "Universal Temporal Extensions for Data Languages," </title> <note> submitted to ICDE 1999. </note>
Reference-contexts: The new version of LDL++ allowed us to prototype several data mining functions and other new applications [28]. It has also been used for other important applications, including the support of temporal constructs as of Datalog T <ref> [6] </ref>. UCLA's SQL-AG prototype (i) implements SQL3 specifications for user-defined aggregates and (ii) extends them to support early returns. <p> It also supports early returns. This simple extension is actually very powerful, since it can express on-line aggregation, and many other complex aggregates required by advanced applications. One important application area treated in a parallel paper <ref> [6] </ref> is that of temporal queries. In this paper, we have concentrated on data mining applications, and argued that user-defined aggregates with early returns provide a natural solution to the very difficult problem of integrating data mining applications into a database-centric environment.
Reference: [7] <author> D. Chimenti, R. Gamboa, R. Krishnamurthy, S. Naqvi, S. Tsur, C. Zaniolo: </author> <title> The LDL System Prototype. </title> <journal> IEEE Transactions on Knowledge and Data Engineering 2(1): </journal> <month> 76-90 </month> <year> (1990) </year>
Reference: [8] <author> Charles Elkan. </author> <title> "Boosting and Naive Bayesian Learning." </title> <type> Technical report no cs97-557, </type> <institution> Dept. of Computer Science and Engineering, UCSD, </institution> <month> September </month> <year> 1997. </year>
Reference-contexts: Say for instance, that we want to classify the value of PlayTennis as a `Yes' or a `No' given the following vector of attribute values Outlook, Temperature, Humidity, Wind. and a training set such as that shown in Table 1. The algorithm known as Boosted Bayesian Classifier <ref> [8] </ref> has proven to be the most effective at this task (in fact, it was the winner of the KDD'97 data mining competition). A Naive Bayesian [8] classifier makes probability-based predictions as follows. <p> The algorithm known as Boosted Bayesian Classifier <ref> [8] </ref> has proven to be the most effective at this task (in fact, it was the winner of the KDD'97 data mining competition). A Naive Bayesian [8] classifier makes probability-based predictions as follows. Let A 1 , A 2 , : : : , A k be attributes, with discrete values, used to predict a discrete class C. (For the example at hand, we have four prediction attributes, k = 4, and C = `PlayTennis').
Reference: [9] <author> M. Fang, N. Shivakumar, H. Garcia-Molina, R. Motawni, J. Ullman, </author> <title> "Computing Iceberg Queries Efficiently", </title> <booktitle> Proceedings of the 1998 VLDB Conference, </booktitle> <address> New York, NY, </address> <year> 1998. </year>
Reference-contexts: While this computation can be expressed using the SQL count aggregate, ensuring the efficiency of these queries represents much more of a challenge [18]. The same is true for a related class of queries called iceberg queries <ref> [9] </ref>. Also the classification algorithms discussed in [19] face similar problems|see discussion in Section 5. 2.3 On Line aggregation and Early Returns In general, aggregate-like computations used in data mining algorithms cannot be implemented conveniently and efficiently using built-in SQL2 aggregates, or even employing SQL3's user-defined aggregates. <p> These frequent items corresponding to the tip of the iceberg, are called "heavy" items in <ref> [9] </ref>. Answering this query involves making a pass through the database of this year sale transactions to compute the simple aggregates such as sum or count involved in the query. The sales database is normally very large and must be normally stored on disk. <p> The sales database is normally very large and must be normally stored on disk. However substantial gains in performance can be achieved if the table with the candidate heavy items can be kept in main memory during the counting. An approach described in <ref> [9] </ref> to achieve that uses a hash function to compress the original identifier for the item into a key such that a hash table for that key can fit in main memory. <p> Then, we can discard all the items where the count associated with their hash key is below the threshold (no false negatives). Now there remains the problem of finding which of the remaining items have an individual count above the threshold. One technique proposed in <ref> [9] </ref> uses multilevel hashing. A second pass through the database is taken using a secondary hash function orthogonal to the first one. Only items where both their hash functions are above the threshold count in both passes are now potentially heavy. <p> Only items where both their hash functions are above the threshold count in both passes are now potentially heavy. Our actual implementation was based on the multistage hashing algorithm, modified with the statistical sampling technique also discussed in <ref> [9] </ref>. The algorithm consists of three steps: 1. Sample the database and identify the potential heavy candidates; mark their hash slots. 2. Scan the database completely. Read each record and hash it to a counter; if the slot is not already marked in the first step increment the counter.
Reference: [10] <author> J. Gray, A. Bosworth, H. Pirahesh, A. Layman. </author> <title> "Data Cube: A Relational Aggregation Operator Generalizing Group-By, </title> <booktitle> Cross-Tab, and Sub-Total." International Conference on Data Engineering, </booktitle> <year> 1996. </year>
Reference: [11] <author> J. M. Hellerstein, P. J. Haas, and H. J. Wang. </author> <title> "Online Aggregation." </title> <booktitle> In Proceedings of ACM-SIGMOD Conference on Management of Data, </booktitle> <month> May </month> <year> 1997. </year> <title> [12] "Database Language SQL Part 2: </title> <address> SQL/Foundation.", </address> <month> July </month> <year> 1996. </year>
Reference-contexts: 432 256 1992 fall oct 13 ? ? ? 481 1992 fall oct 21 ? ? 597 116 1992 fall nov 11 2692 733 136 136 Table 2: Keeping track of Sales over time The recently proposed concept of online aggregation finds many applications in data mining and OLAP algorithms <ref> [11] </ref>. A typical use of on-line aggregation is for estimating averages.
Reference: [13] <author> I. Motakis and C. Zaniolo, </author> <title> "Temporal Aggregation in Active Database Rules." </title> <booktitle> ACM SIGMOD, </booktitle> <year> 1997. </year>
Reference-contexts: For instance, many different sorts of temporal aggregation, e.g., cumulative aggregation and moving-window aggregation, are needed to perform time series analysis <ref> [13] </ref>. Thus, a user might request the running sum of sales, i.e., the running sum of the sales from a given time. This computation is facilitated by the fact that the data is normally stored sorted by time, as in Table 2.
Reference: [14] <author> I. S. Mumick, H. Pirahesh, and R. Ramakrishan, </author> <title> "The magic of duplicates and aggregates," </title> <booktitle> VLDB 1990, </booktitle> <pages> pp. 264-277, </pages> <year> 1990. </year>
Reference: [15] <author> K. A. Ross and Yehoshua Sagiv, </author> <title> "Monotonic Aggregation in Deductive Database", </title> <type> JCSS 54(1), </type> <month> 79-97 </month> <year> (1997) </year>
Reference-contexts: However, database researchers have long known that aggregation used in certain ways can be monotonic, and thus usable without restrictions in recursion <ref> [15] </ref>. Unfortunately, syntactic criteria that are simple and general enough to identify monotonic recursion did not follow from the referenced works. DB2 now only supports recursive queries if these are stratified with respect to aggregates. <p> Since S 0 S we conclude that the rules with mcount define a monotone deterministic mapping. All aggregates inductively defined using TERMINATE NOP define monotonic mappings, although these mapping can be nondeterministic in general. The examples which follow are based on those in <ref> [15] </ref>, and show that, deterministic or otherwise, monotone aggregates provide a powerful and flexible tool for advanced applications. Join the Party Some people will come to the party no matter what, and their names are stored in a sure (Pname) relation. <p> Indeed, this paper only represents a first step in the right direction, and leaves many important issues for later research. However, one important problem not left for later research, is that of monotonic aggregation <ref> [15] </ref>, which has been brought to a (surprisingly) simple resolution. Very useful applications, such as least-cost graph traversals and BoM queries requiring sums in recursion, can now be succinctly expressed in SQL-AG and thus efficiently supported in DB2.
Reference: [16] <author> L. Rowe and M. Stonebraker. </author> <title> "The POSTGRES Data Model." </title> <booktitle> In Proceedings of VLDB Conference, </booktitle> <address> Brighton, England, </address> <month> September </month> <year> 1987. </year>
Reference-contexts: Similar limitations are presented by other advanced database languages. For instance, Postgres allows the user to specify aggregates in terms of state-transition functions <ref> [16, 25] </ref>. The state functions sfunc1 and sfunc2 compute the new state from the old state and the value of the new record. Moreover, initcond is used to define the initial state of the aggregate, while finalfunc defines the computation to be performed at the end.
Reference: [17] <author> D. Sacca and C. Zaniolo. </author> <title> Deterministic and non-deterministic stable models. </title> <journal> Journal of Logic and Computation, </journal> <volume> 7(5) </volume> <pages> 555-579, </pages> <month> October </month> <year> 1997. </year>
Reference: [18] <author> S. Sarawagi, S. Thomas, R. Agrawal, </author> <title> "Integrating Association Rule Mining with Relational Database Systems: Alternatives and Implications," </title> <booktitle> Proceedings ACM-SIGMOD Int. Conf on Management of Data, </booktitle> <address> pp.343-354, </address> <month> June </month> <year> 1998. </year>
Reference-contexts: As a result, most data mining algorithms are currently designed to either bypass completely the database system, or to operate in a loose coupling mode [2]: a better integration of data mining algorithms and database systems represents a critical research challenge <ref> [18] </ref>. 1 In this paper, we introduce the notion of extended user-defined aggregates, and show that they can be used to dovetail data mining algorithms into database systems; also, they can play an important role in many other advanced applications. <p> While this computation can be expressed using the SQL count aggregate, ensuring the efficiency of these queries represents much more of a challenge <ref> [18] </ref>. The same is true for a related class of queries called iceberg queries [9].
Reference: [19] <author> J. Shafer, R. Agrawal and M. Metha, "SPRINT: </author> <title> A scalable parallel classifier for data mining," </title> <address> VLDB-96, Bombay, India, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: While this computation can be expressed using the SQL count aggregate, ensuring the efficiency of these queries represents much more of a challenge [18]. The same is true for a related class of queries called iceberg queries [9]. Also the classification algorithms discussed in <ref> [19] </ref> face similar problems|see discussion in Section 5. 2.3 On Line aggregation and Early Returns In general, aggregate-like computations used in data mining algorithms cannot be implemented conveniently and efficiently using built-in SQL2 aggregates, or even employing SQL3's user-defined aggregates. <p> first bear little resemblance to aggregates or other database operations. (For instance, our boosted Bayesian classifier in SQL is frequently a source of surprise or skepticism.) Seeking scalability and performance, several classification algorithms have now been recast into a more database-centric framework where they can be expressed using aggregate-like operations <ref> [3, 19] </ref>. Reinforcing this trend, this paper provide tools for defining aggregates capable of supporting better data mining applications in a database-centric environment. 3 User-Defined Aggregates in SQL3 SQL3 prescribes that iterative routines should be used to define user-defined aggregates in some external language. <p> Many data mining algorithms, including the Apriori algorithm [1, 5], use iceberg queries as their main building block. 12 The SPRINT/PUBLIC Decision Tree Builders A decision tree recursively partitions a training set on a selected value of a selected attribute until each partition consists entirely of one class of items <ref> [19] </ref>. After several refinements in an AI context, the SPRINT algorithm was proposed to ensure scalability and parallelizability [19]. <p> 12 The SPRINT/PUBLIC Decision Tree Builders A decision tree recursively partitions a training set on a selected value of a selected attribute until each partition consists entirely of one class of items <ref> [19] </ref>. After several refinements in an AI context, the SPRINT algorithm was proposed to ensure scalability and parallelizability [19]. The basic step in the algorithm consists in evaluating alternative attribute/value splits and choosing the one that has the least value of the gini function that evaluates the information-theoretic performance of the split.
Reference: [20] <author> K. Shim and R. Rastogi, </author> <title> "PUBLIC: A Decision Tree Classifier that Integrates Building and Pruning" VLDB'98, </title> <address> New York City, N.Y., </address> <year> 1998 </year>
Reference-contexts: This problem has traditionally been solved by first generating a large tree and then applying a pruning algorithm that deletes nodes that might lead to higher error rate. The minimum description length principle is often used to decide whether a node should be pruned or not <ref> [20] </ref>. The principle basically states that the tree that costs the least to describe accurately is the best tree to achieve. While the tree-pruning phase has traditionally been applied after the tree-building one, the recently proposed PUBLIC algorithm combines the two stages together. <p> The idea is that, if we can predict ahead of time that a node will cost more after being split, we will avoid the waste of first splitting it, only to have to prune it later on. Various versions of the PUBLIC method have been evaluated in <ref> [20] </ref>, and the version known as PUBLIC (1) resulted to be the most cost-effective. We were able to implement the SPRINT/PUBLIC (1) in SQL-AG, with very little effort.
Reference: [21] <author> W. Shen, K.Ong, B. Mitbander and C. Zaniolo, </author> <title> Metaqueries for Data Mining, Chapter 15 of Advances in Knowledge Discovery and Data Mining, </title> <editor> U. M. Fayyad et al (eds.), </editor> <publisher> MIT Press, </publisher> <year> 1996. </year> <title> 17 [22] "Database Language SQL Part 2: </title> <address> SQL/Foundation.", </address> <month> July </month> <year> 1996. </year>
Reference-contexts: Then, the boosting step described in <ref> [21] </ref> can be implemented by simply increasing the weight of the misclassified tuples. In conclusion, this award-winning classification algorithm can be implemented well using the SQL count aggregate. This aggregate-based formulation is preferable 3 to the original formulation given in [21] since it ensures scalability and performance on large training sets. <p> Then, the boosting step described in <ref> [21] </ref> can be implemented by simply increasing the weight of the misclassified tuples. In conclusion, this award-winning classification algorithm can be implemented well using the SQL count aggregate. This aggregate-based formulation is preferable 3 to the original formulation given in [21] since it ensures scalability and performance on large training sets. <p> C f can be computed by SQL queries using count. In <ref> [21] </ref> we assume that we are given a database of relations and we describe a system to find implication rules, such as the one above, by searching for tables that satisfy some meta-level templates specified by the user. <p> Then the system finds all the triplets P , Q and R of database predicates for which C f exceeds a given threshold, say, C f &gt; 0:8. In <ref> [21] </ref>, we described a system that uses the meta-level predicates of LDL++ to perform this search. In summary, some interesting association and classification methods can be implemented directly using the standard SQL2 aggregates.
Reference: [23] <institution> Redbrick Corp., "Decision-Makers, Business Data and RISQL.", </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: Similar conclusions also hold for other advanced applications; however, data mining and decision support provide the best example of this general trend as demonstrated by (i) the many vendor-defined, special-purpose aggregates introduced for OLAP and ROLAP systems <ref> [23] </ref>, and (ii) the examples that follow. 2.1 Classification by Boosted Bayesian Classifiers As a first example, consider the data mining methods used for classification.
Reference: [24] <author> K. A. Ross and D. Srivastava, </author> <title> "Fast Computation of Sparse Datacubes." </title> <booktitle> In Proceedings of the 23rd VLDB Conference, </booktitle> <address> Athens, Greece, </address> <year> 1997. </year>
Reference: [25] <author> M. Stonebraker, L. Rowe, and M. Hirohama. </author> <title> "The Implementation of POSTGRES." </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: Similar limitations are presented by other advanced database languages. For instance, Postgres allows the user to specify aggregates in terms of state-transition functions <ref> [16, 25] </ref>. The state functions sfunc1 and sfunc2 compute the new state from the old state and the value of the new record. Moreover, initcond is used to define the initial state of the aggregate, while finalfunc defines the computation to be performed at the end.
Reference: [26] <author> Scott Urman. </author> <title> Oracle8 PL/SQL Programming. </title> <publisher> McGrawHill Publishing Company, </publisher> <year> 1997. </year>
Reference: [27] <author> A. Van Gelder. </author> <booktitle> Foundations of Aggregations in Deductive Databases In Proc. of the Int. Conf. On Deductive and Object-Oriented databases, </booktitle> <year> 1993. </year>
Reference: [28] <author> H. Wang, </author> <title> User-Defined Aggregates in LDL++ (web page and on line documentation), </title> <address> http://www.cs.ucla.edu/~hxwang/ldl/aggregate/. </address>
Reference-contexts: The compiler infers from these rules which aggregates are mononotonic and which are not. The new version of LDL++ allowed us to prototype several data mining functions and other new applications <ref> [28] </ref>. It has also been used for other important applications, including the support of temporal constructs as of Datalog T [6]. UCLA's SQL-AG prototype (i) implements SQL3 specifications for user-defined aggregates and (ii) extends them to support early returns.
Reference: [29] <author> Carlo Zaniolo. </author> <title> "Design and Implementation of a Logic Based Language for Data Intensive Applications." </title> <booktitle> In Proceeding of the International Conference on Logic Programming, </booktitle> <year> 1988. </year>
Reference: [30] <author> Carlo Zaniolo, N. Arni, and K. Ong. </author> <title> "Negation and Aggregates in Recursive Rules: the LDL++ Approach." </title> <booktitle> DOOD, </booktitle> <year> 1993. </year>
Reference: [31] <author> C. Zaniolo, S. Ceri et al. </author> <title> "Advanced Database Systems," </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1997. </year>
References-found: 29

