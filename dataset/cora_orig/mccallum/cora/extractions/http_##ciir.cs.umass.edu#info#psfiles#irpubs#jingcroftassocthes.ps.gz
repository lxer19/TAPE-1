URL: http://ciir.cs.umass.edu/info/psfiles/irpubs/jingcroftassocthes.ps.gz
Refering-URL: http://ciir.cs.umass.edu/info/psfiles/irpubs/irnew.html
Root-URL: 
Email: jing@cs.umass.edu, croft@cs.umass.edu  
Title: An Association Thesaurus for Information Retrieval  
Author: Yufeng Jing and W. Bruce Croft 
Address: Amherst, MA 01003.  
Affiliation: Department of Computer Science, University of Massachusetts at Amherst,  
Abstract: Although commonly used in both commercial and experimental information retrieval systems, thesauri have not demonstrated consistent benefits for retrieval performance, and it is difficult to construct a thesaurus automatically for large text databases. In this paper, an approach, called PhraseFinder, is proposed to construct collection-dependent association thesauri automatically using large full-text document collections. The association thesaurus can be accessed through natural language queries in INQUERY, an information retrieval system based on the probabilistic inference network. Experiments are conducted in IN-QUERY to evaluate different types of association thesauri, and thesauri constructed for a variety of collections.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> James P. Callan, and W. Bruce Croft, </author> <title> An Evaluation of Query Processing Strategies Using the TIPSTER Collection, </title> <address> SIGIR'93 347-355, </address> <year> 1993. </year>
Reference-contexts: Noun phrases are used as the main characteristic features instead of terms because there is evidence that they play an important role in characterizing the content of a text <ref> [3, 1] </ref>. PhraseFinder considers co-occurrences between phrases and terms as associations. As we will see later, phrases do not have to be noun phrases. They are defined by a set of rules.
Reference: [2] <author> Kenneth Church, </author> <title> A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text, </title> <booktitle> In Proc. of the 2nd Conf. on Applied Natural Language Processing, </booktitle> <address> 136-143,. </address> <year> 1988. </year>
Reference-contexts: The following basic text features are used in PhraseFinder: * Terms Any word except a stop word is a term. * Part of Speech Each word has a part of speech that was assigned by a part-of-speech tagger. So far, the Church tagger <ref> [2] </ref> has been used to tag texts. In addition, PhraseFinder recognizes phrases based on a set of simple phrase rules and the part of speech of terms. The following text composite features are used : * Paragraphs A paragraph consists of a set of sentences.
Reference: [3] <author> W.Bruce Croft, Howard R. Turtle, and David D. Lewis, </author> <title> The Use of Phrases and Structured Queries in Information Retrieval, </title> <address> SIGIR'91, </address> <year> 1991 </year>
Reference-contexts: Noun phrases are used as the main characteristic features instead of terms because there is evidence that they play an important role in characterizing the content of a text <ref> [3, 1] </ref>. PhraseFinder considers co-occurrences between phrases and terms as associations. As we will see later, phrases do not have to be noun phrases. They are defined by a set of rules.
Reference: [4] <author> Carolyn J. Crouch, </author> <title> An Approach to the Automatic Construction of Global Thesauri, IP&M, </title> <booktitle> Vol.26(5), </booktitle> <pages> 629-640, </pages> <year> 1990 </year>
Reference-contexts: The occurrence information of terms in relevant and non-relevant documents is used to estimate the probability of terms similar to queries. When full relevance judgments are not fully available, the retrieval performance under the model degraded badly [22]. Recently Crouch and Yang <ref> [4, 5] </ref> used Salton's approach to build a term-vs-term thesaurus whose classes are clustered in terms of discrimination values. Although such a thesaurus improved retrieval performance, to determine the best threshold value is difficult because such a value is determined assuming the availability of relevance judgements.
Reference: [5] <author> Carolyn J. Crouch and Bokyung Yang, </author> <title> Experiments in Automatic Statistical Thesaurus Construction, </title> <booktitle> SIGIR 92, </booktitle> <pages> 77-88, </pages> <year> 1992 </year>
Reference-contexts: The occurrence information of terms in relevant and non-relevant documents is used to estimate the probability of terms similar to queries. When full relevance judgments are not fully available, the retrieval performance under the model degraded badly [22]. Recently Crouch and Yang <ref> [4, 5] </ref> used Salton's approach to build a term-vs-term thesaurus whose classes are clustered in terms of discrimination values. Although such a thesaurus improved retrieval performance, to determine the best threshold value is difficult because such a value is determined assuming the availability of relevance judgements.
Reference: [6] <author> David A. Evans, Kimberly Ginther-Webster, Mary Hart, Robert G. Lefferts, and Ira A. Monarch, </author> <title> Automatic Indexing Using Selective NLP and First-Order Thesauri, </title> <booktitle> RIAO 91, </booktitle> <pages> 624-643, </pages> <year> 1991 </year>
Reference-contexts: Adding so many terms may not, however, be efficient for large information retrieval systems. It should be noted that their improved results on the NPL collection is still lower than the baselines used in this paper. In the CLARIT project <ref> [6] </ref>, NLP techniques are used to identify candidate noun phrases in full-text and map them into candidate terms, in a morphologically-normalized form, emphasizing modifier and head relations, and the candidate terms are matched against a first-order thesaurus of certified domain-specific terminology, which is a semiautomatically generated control vocabulary dictionary.
Reference: [7] <author> Donna Harman, </author> <title> Overview of the First Text REtrieval Conference, </title> <booktitle> SIGIR'93, </booktitle> <pages> 36-47, </pages> <year> 1993 </year>
Reference-contexts: To some extent, query expansion shows whether or not a thesaurus can provide useful phrases (or terms for term-based thesauri) for searchers. To measure the performance of PhraseFinder, we conducted experiments using thesauri built from the NPL and TIPSTER collections <ref> [7] </ref>: * NPL: Associations generated from 11,429 documents containing titles and/or abstracts in the area of physics. * TIPSAMP: Associations generated from a sample of the TIPSTER collection consisting of about 52,000 full-text documents from AP, ZIFF, and WSJ (87, 88, 89).
Reference: [8] <author> R. Krovetz, </author> <title> Viewing Morphology as an Inference Process, </title> <booktitle> SIGIR'93, </booktitle> <pages> 191-202, </pages> <year> 1993 </year>
Reference-contexts: Regular stemming (i.e. the Porter stemmer [12]) is used for terms. Because this stemmer is quite "aggressive" in terms of removing endings and does not produce real word forms as output, we used a more conservative approach for stemming phrases <ref> [8] </ref>. 3.1 Association Generation and Paragraph Limits Associations represent the co-occurrence between terms and phrases within texts. Before the generation of associations is described, an important question is what range should be used to generate associations.
Reference: [9] <author> Jack Minker, Gerald A. Wilson, and Barbara H. Zimmerman, </author> <title> An Evaluation of Query Expansion by the Addition of Clustered Terms for a Document Retrieval System, IP&M, </title> <booktitle> Vol.8, </booktitle> <pages> 329-348, </pages> <year> 1972 </year>
Reference-contexts: In those experiments, automatic term classification without relevance judgments or feedback information did not produce any significant improvements. Minker, Wilson, and Zimmer-man in <ref> [9] </ref> after an exhaustive investigation came to the same conclusion. Salton [14] showed that using the Harris synonym thesaurus with relevance judgements produces significant improvements. He proposed two approaches : term-document and term-property matrices, for automatic construction of thesauri based on relevance judgements.
Reference: [10] <author> C.J. Rijsbergen, D.J. Harper, and M.F. Porter, </author> <title> The Selection of Good Search Terms, IP&M, </title> <booktitle> Vol.17, </booktitle> <pages> 77-91, </pages> <year> 1981 </year>
Reference-contexts: Research related to automatic thesauri dates back to Spark-Jones's work on automatic term classification [18, 19], Salton's work on automatic thesaurus construction and query expansion [14, 16], and Van Rijsbergen's work on term co-occurrence <ref> [10] </ref>. In those experiments, automatic term classification without relevance judgments or feedback information did not produce any significant improvements. Minker, Wilson, and Zimmer-man in [9] after an exhaustive investigation came to the same conclusion. Salton [14] showed that using the Harris synonym thesaurus with relevance judgements produces significant improvements. <p> Yu's 2 study on clustering for information retrieval [23] showed that term dependence information improves the effectiveness of retrieval systems. In the non-binary independence model, he used hierarchical term relations. Rijsbergen and Smeaton in <ref> [10, 17] </ref> used a statistically-derived MST (maximum spanning tree) as a term dependence structure with relevance feedback to verify the following association hypothesis If an index term is good at discriminating relevant from non-relevant documents then any closely associated index term is also likely to be good at this.
Reference: [11] <author> Gerda Ruge, </author> <title> Experiments on Linguistically Based Term Associations, </title> <booktitle> RIAO 91, </booktitle> <pages> 528-545, </pages> <year> 1991 </year>
Reference-contexts: This indexing technique builds a mapping between terms within a candidate noun phrase and terms in the first-order thesaurus. As an indexing technique, the method used in CLARIT was compared with human indexers on the basis of ten documents. Ruge <ref> [11] </ref> uses the head/modifier relation to investigate the effect of term associations on the performance of IR systems in the hyperterm system REALIST.
Reference: [12] <author> Porter M, </author> <title> An Algorithm for Suffix Stripping, Program, </title> <booktitle> Vol.14(3), </booktitle> <pages> 130-137, </pages> <year> 1980 </year>
Reference-contexts: PhraseFinder does not allow a phrase to cross sentence boundaries. PhraseFinder, as its name implies, identifies the associations between phrases and terms so that associated phrases can be retrieved through natural language queries and used for expansion. Regular stemming (i.e. the Porter stemmer <ref> [12] </ref>) is used for terms.
Reference: [13] <author> Yonggang Qiu, </author> <title> H.P. Frei, Concept Based Query Expansion, </title> <booktitle> SIGIR'93, </booktitle> <pages> 160-169, </pages> <year> 1993 </year> <month> 14 </month>
Reference-contexts: The experiments using MST resulted in no positive results. In the recent work by Yonggang Qiu and H.P. Frei <ref> [13] </ref>, a term-vs-term similarity matrix was constructed based on how the terms of the collection are indexed. A probabilistic method is used to estimate the probability of a term similar to a given query in the vector space model.
Reference: [14] <author> G. Salton, </author> <title> Automatic Information Organization and Retrieval, </title> <publisher> McGraw-Hill Book Com--pany, </publisher> <year> 1968 </year>
Reference-contexts: Research related to automatic thesauri dates back to Spark-Jones's work on automatic term classification [18, 19], Salton's work on automatic thesaurus construction and query expansion <ref> [14, 16] </ref>, and Van Rijsbergen's work on term co-occurrence [10]. In those experiments, automatic term classification without relevance judgments or feedback information did not produce any significant improvements. Minker, Wilson, and Zimmer-man in [9] after an exhaustive investigation came to the same conclusion. <p> In those experiments, automatic term classification without relevance judgments or feedback information did not produce any significant improvements. Minker, Wilson, and Zimmer-man in [9] after an exhaustive investigation came to the same conclusion. Salton <ref> [14] </ref> showed that using the Harris synonym thesaurus with relevance judgements produces significant improvements. He proposed two approaches : term-document and term-property matrices, for automatic construction of thesauri based on relevance judgements. In [16, 15, 22] Salton, Yu, and Buckley further developed these methods into a formal term dependence model.
Reference: [15] <author> G. Salton, </author> <title> Automatic Term Class Construction Using Relevance A Summary of Word in Automatic Pseudoclassification, </title> <journal> IP&M, </journal> <volume> Vol.16 (1), </volume> <pages> 1-15, </pages> <year> 1980 </year>
Reference-contexts: Minker, Wilson, and Zimmer-man in [9] after an exhaustive investigation came to the same conclusion. Salton [14] showed that using the Harris synonym thesaurus with relevance judgements produces significant improvements. He proposed two approaches : term-document and term-property matrices, for automatic construction of thesauri based on relevance judgements. In <ref> [16, 15, 22] </ref> Salton, Yu, and Buckley further developed these methods into a formal term dependence model. But the serious drawback with the term dependence model is that it assumes the availability of relevance judgements.
Reference: [16] <author> G. Salton, C. Buckley, and C.T. Yu, </author> <title> An Evaluation of Term Dependence Models in Information Retrieval, </title> <publisher> LNCS 146, </publisher> <pages> 151-173, </pages> <year> 1983 </year>
Reference-contexts: Research related to automatic thesauri dates back to Spark-Jones's work on automatic term classification [18, 19], Salton's work on automatic thesaurus construction and query expansion <ref> [14, 16] </ref>, and Van Rijsbergen's work on term co-occurrence [10]. In those experiments, automatic term classification without relevance judgments or feedback information did not produce any significant improvements. Minker, Wilson, and Zimmer-man in [9] after an exhaustive investigation came to the same conclusion. <p> Minker, Wilson, and Zimmer-man in [9] after an exhaustive investigation came to the same conclusion. Salton [14] showed that using the Harris synonym thesaurus with relevance judgements produces significant improvements. He proposed two approaches : term-document and term-property matrices, for automatic construction of thesauri based on relevance judgements. In <ref> [16, 15, 22] </ref> Salton, Yu, and Buckley further developed these methods into a formal term dependence model. But the serious drawback with the term dependence model is that it assumes the availability of relevance judgements.
Reference: [17] <author> Alan F. Smeaton, </author> <title> The Retrieval Effects of Query Expansion on a Feedback Document Retrieval System, </title> <institution> TR-2, Dept. of Computer Science, University College Dublin, </institution> <year> 1982 </year>
Reference-contexts: Yu's 2 study on clustering for information retrieval [23] showed that term dependence information improves the effectiveness of retrieval systems. In the non-binary independence model, he used hierarchical term relations. Rijsbergen and Smeaton in <ref> [10, 17] </ref> used a statistically-derived MST (maximum spanning tree) as a term dependence structure with relevance feedback to verify the following association hypothesis If an index term is good at discriminating relevant from non-relevant documents then any closely associated index term is also likely to be good at this.
Reference: [18] <author> K. Spark Jones and R. M. Needham, </author> <title> Automatic Term Classification and Retrieval, </title> <journal> IP&M, </journal> <volume> Vol.4, </volume> <pages> 91-100, </pages> <year> 1968 </year>
Reference-contexts: Research related to automatic thesauri dates back to Spark-Jones's work on automatic term classification <ref> [18, 19] </ref>, Salton's work on automatic thesaurus construction and query expansion [14, 16], and Van Rijsbergen's work on term co-occurrence [10]. In those experiments, automatic term classification without relevance judgments or feedback information did not produce any significant improvements.
Reference: [19] <author> K. Spark Jones and D.M. Jackson, </author> <title> The Use of Automatically-Obtained Keyword Classifications for Information Retrieval, IP&M, </title> <booktitle> Vol.5, </booktitle> <pages> 175-201, </pages> <year> 1970 </year>
Reference-contexts: Research related to automatic thesauri dates back to Spark-Jones's work on automatic term classification <ref> [18, 19] </ref>, Salton's work on automatic thesaurus construction and query expansion [14, 16], and Van Rijsbergen's work on term co-occurrence [10]. In those experiments, automatic term classification without relevance judgments or feedback information did not produce any significant improvements.
Reference: [20] <author> K. Spark Jones, </author> <title> Automatic Keyword Classification for Information Retrieval, </title> <type> Butterworth, </type> <year> 1971. </year>
Reference: [21] <author> Howard R. </author> <title> Turtle, Inference Networks for Document Retrieval, </title> <type> Ph.D. Thesis, COINS Technical Report 90-92, </type> <institution> University of Massachusetts at Amherst, </institution> <year> 1990 </year>
Reference-contexts: Thesaurus access is a procedure that measures the closeness of thesaurus items in the context of a particular query. In this paper, we implement PhraseFinder access through INQUERY, an information retrieval system based on the probabilistic inference network <ref> [21] </ref>. To do this, an association thesaurus is converted into a form suitable for INQUERY. Specifically, thesaurus phrases are mapped into pseudo-INQUERY documents where the representation of a pseudo-document consists of all the associated terms.
Reference: [22] <author> C. T. Yu, C. Buckley, K. Lam, and G. Salton, </author> <title> A Generalized Term Dependence Model in Information Retrieval, </title> <booktitle> Information Technology: Research and Development, Vol.2, </booktitle> <pages> 129-154, </pages> <year> 1983 </year>
Reference-contexts: Minker, Wilson, and Zimmer-man in [9] after an exhaustive investigation came to the same conclusion. Salton [14] showed that using the Harris synonym thesaurus with relevance judgements produces significant improvements. He proposed two approaches : term-document and term-property matrices, for automatic construction of thesauri based on relevance judgements. In <ref> [16, 15, 22] </ref> Salton, Yu, and Buckley further developed these methods into a formal term dependence model. But the serious drawback with the term dependence model is that it assumes the availability of relevance judgements. <p> The occurrence information of terms in relevant and non-relevant documents is used to estimate the probability of terms similar to queries. When full relevance judgments are not fully available, the retrieval performance under the model degraded badly <ref> [22] </ref>. Recently Crouch and Yang [4, 5] used Salton's approach to build a term-vs-term thesaurus whose classes are clustered in terms of discrimination values.
Reference: [23] <author> C.T. Yu, W. Meng, and S. Park, </author> <title> A Framework for Effective Retrieval, </title> <journal> ACM Tran. on Database Systems, </journal> <volume> Vol.14,No.2, </volume> <pages> 147-167, </pages> <year> 1989 </year> <month> 15 </month>
Reference-contexts: Although such a thesaurus improved retrieval performance, to determine the best threshold value is difficult because such a value is determined assuming the availability of relevance judgements. Yu's 2 study on clustering for information retrieval <ref> [23] </ref> showed that term dependence information improves the effectiveness of retrieval systems. In the non-binary independence model, he used hierarchical term relations.
References-found: 23

