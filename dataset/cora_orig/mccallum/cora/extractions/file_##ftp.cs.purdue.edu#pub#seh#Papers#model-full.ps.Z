URL: file://ftp.cs.purdue.edu/pub/seh/Papers/model-full.ps.Z
Refering-URL: http://www.cs.purdue.edu/people/seh/
Root-URL: http://www.cs.purdue.edu
Email: seh@cs.purdue.edu  ashfaq@cs.purdue.edu  
Title: C 3 A parallel model for coarse-grained machines  
Author: Susanne E. Hambrusch Ashfaq A. Khokhar 
Keyword: conquer approaches for contour ranking on images. Keywords: Parallel processing, coarse-grained machines, communication operations, com  
Note: Symposium on Parallel and Distributed Processing,  
Date: February 7, 1995  October 1994.  
Address: West Lafayette, IN 47907, USA  West Lafayette, IN 47907, USA  
Affiliation: Department of Computer Sciences Purdue University  School of Electrical Engineering and Department of Computer Sciences Purdue University  
Abstract: In this paper, we propose a model for parallel computation, the C 3 -model. The C 3 - model evaluates, for a given parallel algorithm and target architecture, the complexity of computation, the pattern of communication, and the potential congestion arising during communication. A metric for estimating the effect of link and processor congestion on the performance of a communication operation is developed. This metric allows the evaluation of arbitrary communication operations without the user having to specify fine scheduling details. We describe how the C 3 -model can serve as a platform for the development of coarse-grained algorithms sensitive to the parameters of a parallel machine. The initial validation of the C 3 -model is discussed for the Intel Touchstone Delta. We compare predicted and actual performance of different solutions for communication operations and of various divide-and putation versus communication, divide-and-conquer. fl Research supported in part by ARPA under contract DABT63-92-C-0022ONR. The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing official policies, expressed or implied, of the U.S. government. A preliminary version of this paper appeared in the 6-th IEEE 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Bala, J. Bruck, R. Cypher, P. Elustondo, A. Ho, C.-T. Ho, S. Kipnis, and M. Snir, </author> <title> "CCL: A Portable and Tunable Collective Communication Library for Scalable Parallel Computers," </title> <booktitle> Proceedings of 8-th International Parallel Processing Symposium, </booktitle> <pages> pp. 835-844, </pages> <year> 1994. </year>
Reference-contexts: An algorithm then operates on independent submachines. The importance of being able to operate on independent submachines has been recognized. It has been incorporated into the Message Passing Interface (MPI) [8] and has been extended to arbitrary process groups <ref> [1] </ref>. When it is known that a superstep operates on independent submachines, we charge communication units based on the parameters of the associated submachines. 2.1 Computation Units The charging of computation units in a superstep is done as follows. <p> Our results also indicate that the performance of 12 an implementation is influenced by the relationship among parameters of the parallel machine, as well as by the relationship of the parameters to the amount of data involved. This agrees with other research done on the implementation of communication operations <ref> [1, 2, 4, 19] </ref>. The Intel Touchstone Delta is a coarse-grained multi-processor system with 512 nodes organized as a 16 fi 32 2-dimensional mesh. Each node is directly connected to its 4 nearest neighbors. The communication network uses wormhole routing.
Reference: [2] <author> M. Barnett, R. Littlefield, D. G. Payne, and R. van de Geijn, </author> <title> "Global Combine on Meshes Architecures with Wormhole Routing," </title> <booktitle> Proceedings of 7-th International Parallel Processing Symposium, </booktitle> <pages> pp. 156-162, </pages> <year> 1993. </year>
Reference-contexts: Our results also indicate that the performance of 12 an implementation is influenced by the relationship among parameters of the parallel machine, as well as by the relationship of the parameters to the amount of data involved. This agrees with other research done on the implementation of communication operations <ref> [1, 2, 4, 19] </ref>. The Intel Touchstone Delta is a coarse-grained multi-processor system with 512 nodes organized as a 16 fi 32 2-dimensional mesh. Each node is directly connected to its 4 nearest neighbors. The communication network uses wormhole routing.
Reference: [3] <author> A. Bar-Noy, S. Kipnis, </author> <title> "Designing Broadcasting Algorithms in the Postal Model for Message-Passing Systems," </title> <booktitle> Proceedings of 4-th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 13-22, </pages> <year> 1992. </year> <month> 33 </month>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 6, 10, 13, 17, 23, 24, 25] </ref>. In most of these models, including the BSP model [24], the postal model [3], and the LogP model [6], processors are assumed to communicate using a point-to-point message router. <p> Recently, a number of models with this goal have been proposed [3, 6, 10, 13, 17, 23, 24, 25]. In most of these models, including the BSP model [24], the postal model <ref> [3] </ref>, and the LogP model [6], processors are assumed to communicate using a point-to-point message router. Composing more involved communication operations by using the message router places a significant burden on application programmers.
Reference: [4] <author> S.H. Bokhari, </author> <title> "Multiphase Complete Exchange on a Circuit Switched Hypercube," </title> <booktitle> Pro--ceedings of 1991 International Conference on Parallel Processing, </booktitle> <pages> pp. 525-529, </pages> <year> 1991. </year>
Reference-contexts: Our results also indicate that the performance of 12 an implementation is influenced by the relationship among parameters of the parallel machine, as well as by the relationship of the parameters to the amount of data involved. This agrees with other research done on the implementation of communication operations <ref> [1, 2, 4, 19] </ref>. The Intel Touchstone Delta is a coarse-grained multi-processor system with 512 nodes organized as a 16 fi 32 2-dimensional mesh. Each node is directly connected to its 4 nearest neighbors. The communication network uses wormhole routing. <p> The approach used in the first one, Algorithm 2-lev-sq, is independent of the underlying architecture. The approach used in the second one, Algorithm 2-lev-r,c is tailored towards the mesh architecture. An idea similar to the one used in Algorithm 2-lev-sq is described in <ref> [4] </ref> and an implementation of Algorithm 2-lev-c,r has also been reported in [22]. In Algorithm 2-lev-sq, a p-processor machine is logically partitioned into p p submachines, S 0 ; : : :S p p1 . <p> The advantage of the 3-step algorithm is that it uses square meshes as submachines, whereas the 2-step one uses linear arrays. The approach in Algorithm logp-lev-bfly has consistently been judged as being expensive for large message sizes <ref> [4, 22] </ref>. Our metric and the observed performance on the Delta, confirms that as well. 5 Validation through Divide-and-Conquer Solutions On coarse-grained machines, divide-and-conquer strategies are natural and often result in efficient solutions.
Reference: [5] <author> L. T. Chen, L. S. Davis, and C. P. Kruskal, </author> <title> "Efficient parallel processing of image contours," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 15, no. 1, </volume> <pages> pp. 69-81, </pages> <year> 1993. </year>
Reference-contexts: Contour ranking can be viewed as performing list ranking in images. The problem arises when edge contours generated by edge operators in a 2-dimensional image plane are transformed into a linearized representation. Such representations are more compact for processing performed in subsequent mid- and high-level vision tasks <ref> [5, 16, 20] </ref>. Generating the linear representation is called contour ranking. The algorithms we describe use divide-and-conquer and merge information about subimages in order to compute the final values. The information needed about a subimage is proportional to the number of edge points on the boundary of the subimage.
Reference: [6] <author> D. Culler, R. Karp, D. Patterson, A. Sahay, K.E. Schauser, E. Santos, R. Subramonian, T. von Eicken, </author> <title> "LogP: Towards a Realistic Model of Parallel Computation," </title> <booktitle> Proceedings of 4-th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, </booktitle> <pages> pp. 1-12, </pages> <year> 1993. </year>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 6, 10, 13, 17, 23, 24, 25] </ref>. In most of these models, including the BSP model [24], the postal model [3], and the LogP model [6], processors are assumed to communicate using a point-to-point message router. <p> Recently, a number of models with this goal have been proposed [3, 6, 10, 13, 17, 23, 24, 25]. In most of these models, including the BSP model [24], the postal model [3], and the LogP model <ref> [6] </ref>, processors are assumed to communicate using a point-to-point message router. Composing more involved communication operations by using the message router places a significant burden on application programmers. Furthermore, the above models do not attempt to capture the effect of link or processor congestion on communication.
Reference: [7] <author> R. Cypher, E. Leu, </author> <title> "The Semantics of Blocking and Nonblocking Send and Receive Primitives," </title> <type> Technical Report, </type> <institution> IBM Almaden Research Division, </institution> <year> 1993. </year>
Reference-contexts: Nonblocking sends thus allow overlapping of communication and computation and pipelining of multiple send operations. Analogously, receive operations issued by the processors can also be blocking or nonblocking. For additional details on routing protocols we refer to <ref> [7, 14, 17] </ref>. Sending a single message from P i to P j We start the description of how communication units are determined by giving a cost estimation for sending a single message between two processors.
Reference: [8] <author> J.J. Dongarra, R. Hempel, A.J.G. Hey, D.W. Walker. </author> <title> "A Proposal for a User-level, Message Passing Interface in a Distributed Memory Environment", </title> <type> Technical Report TM 12231, </type> <institution> Oak Ridge National Laboratory, </institution> <year> 1993. </year>
Reference-contexts: An algorithm then operates on independent submachines. The importance of being able to operate on independent submachines has been recognized. It has been incorporated into the Message Passing Interface (MPI) <ref> [8] </ref> and has been extended to arbitrary process groups [1]. When it is known that a superstep operates on independent submachines, we charge communication units based on the parameters of the associated submachines. 2.1 Computation Units The charging of computation units in a superstep is done as follows. <p> One-to-all Routing In one-to-all routing, a source processor P t , sends p 1 distinct messages, each to a different destination. One-to-all is also refered to as scatter or personalized broadcast <ref> [8, 15] </ref>. We have n s (t) = p 1, n r (i) = 1 for i 6= t, and cong = p 1. The total send time experienced by the source processor P t dominates the number of communication units. <p> For a mesh, a scaled down version will be either a smaller mesh with the same aspect ratio or a linear array. This is a stronger requirement than the use of process groups as proposed by the MPI Message Passing Standard <ref> [8] </ref>. When determining communication units, we assume that communication within a submachine occurs without interference from other submachines. When describing our algorithms, we assume that the size of the message routed between any two processors is L.
Reference: [9] <author> C. Dwork, M. Herlihy, O. Waarts, </author> <title> "Contention in Shared Memory Algorithms", </title> <booktitle> Proc. of 25-th ACM STOC, </booktitle> <pages> pp. 174-183, </pages> <year> 1993. </year>
Reference-contexts: At the same time, congestion is difficult to evaluate. Congestion is a global phenomena and where it occurs depends on specifics of the architecture and the routing paths taken. A formal model to deal with congestion in a shared memory machine has recently been proposed in <ref> [9] </ref>. Congestion depends on the amount of data sent between processor pairs and is 8 independent of whether we use store-and-forward or wormhole routing.
Reference: [10] <author> P.B. Gibbons, </author> <title> "A More Practical PRAM Model," </title> <booktitle> Proceedings of 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 158-168, </pages> <year> 1989. </year>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 6, 10, 13, 17, 23, 24, 25] </ref>. In most of these models, including the BSP model [24], the postal model [3], and the LogP model [6], processors are assumed to communicate using a point-to-point message router.
Reference: [11] <author> S.E. Hambrusch, F. Hameed, and A. Khokhar, </author> <title> "A Study of Coarse-Grained Communication Operations on Mesh Architectures" Technical Report, </title> <institution> Purdue University, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: We considered machine sizes from 16 to 256 processors and message sizes from 16 bytes to 16 Kbytes. The corresponding experimental results for p = 256 are shown in Intel Delta, we refer to <ref> [11] </ref>. Figure 7 shows that expressing each algorithm in terms of communication and computation units gives an accurate prediction of their relative performance on the Intel Delta. Algorithm 1-lev-dir is indeed a reasonable choice for large message sizes (at least 4 Kbytes). <p> This also agrees with its predicted performance. Figure 8 gives detailed performance results in tabulated form. From Figure 8 is follows that Algorithm logp-lev-rec (0:75) performs quite well. Actually, logp-lev-rec (0:75) gives optimal or near optimal results for all machine and message sizes on Delta <ref> [11] </ref>. As already stated earlier, the metric of the C 3 -model evaluates logp-lev-rec (0:75) to 19 be no better than Algorithm logp-lev-sq. If Algorithm logp-lev-rec (0:75) were implemented with a barrier-style synchronization between supersteps, we would see no improvement. However, logp-lev-rec (0:75) was implemented with no such synchronization. <p> For all all-to-one algorithms, the receive times are the dominating terms in the communication units. From a practical point of view, the best one-to-all algorithms do not necessarily correspond to the best all-to-one algorithms. We refer to <ref> [11] </ref> for a complete discussion and only state 20 our main observations. On a 256-processor Intel Delta, Algorithm 1-lev-dir is no longer a reasonable choice for large message sizes. <p> Implementations of these approaches on different machines have shown exclusive-or permutations to be superior to linear permutations [19, 22]. Another interesting approach for partitioning all-to-all routings into permutations has been introduced in [21]. We call this approach partitioning into balanced permutations and refer to <ref> [11] </ref> for implementation details. Balanced permutations are relevant to the mesh architecture since they minimize the congestion over the links.
Reference: [12] <author> F. Hameed, S.E. Hambrusch, A. Khokhar, and J.Patel, </author> <title> Contour Ranking on Coarse-Grained Machines: A Case Study for Low-level Vision Computations, </title> <type> Technical Report, </type> <institution> Purdue University, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: In a backward phase, the final head and rank in image I of edge points on the boundary of subimages are used to determine head and rank information for the remaining edge points within the subimages. We refer to <ref> [12] </ref> for details on how the boundary is represented and for details of the merging. In brief, each one of our algorithms consists of the following three steps. 1. Processor P i;j performs contour ranking on subimage I i;j .
Reference: [13] <author> T. Heywood and S. Ranka, </author> <title> "A Practical Hierarchical Model of Parallel Computation: I. The Model," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 16, </volume> <pages> pp. 212-232, </pages> <year> 1992. </year>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 6, 10, 13, 17, 23, 24, 25] </ref>. In most of these models, including the BSP model [24], the postal model [3], and the LogP model [6], processors are assumed to communicate using a point-to-point message router.
Reference: [14] <author> K. Hwang, </author> <title> Advanced Computer Architecture with Parallel Programming, </title> <publisher> McGraw-Hill, </publisher> <year> 1993. </year>
Reference-contexts: In order to demonstrate broad applicability of our model, we describe the evaluation of communication units for different routing schemas and different send and receive primitives. The two routing schemas we consider are store-and-forward and wormhole routing. Both are common and they are conceptually quite different. We refer to <ref> [14] </ref> for details. Most existing machines support both blocking and nonblocking protocols for send and receive primitives. These protocols differ in implementation based on the synchronization methods used. For the sake of completeness, we describe these protocols. <p> Nonblocking sends thus allow overlapping of communication and computation and pipelining of multiple send operations. Analogously, receive operations issued by the processors can also be blocking or nonblocking. For additional details on routing protocols we refer to <ref> [7, 14, 17] </ref>. Sending a single message from P i to P j We start the description of how communication units are determined by giving a cost estimation for sending a single message between two processors.
Reference: [15] <author> S.L. Johnsson, C.-T. Ho, </author> <title> "Optimum Broadcasting and Personalized Communication in Hypercubes," </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 38, </volume> <pages> pp. 1249-1268, </pages> <year> 1989. </year>
Reference-contexts: One-to-all Routing In one-to-all routing, a source processor P t , sends p 1 distinct messages, each to a different destination. One-to-all is also refered to as scatter or personalized broadcast <ref> [8, 15] </ref>. We have n s (t) = p 1, n r (i) = 1 for i 6= t, and cong = p 1. The total send time experienced by the source processor P t dominates the number of communication units.
Reference: [16] <author> M.H. Kim, O.H. Ibarra, </author> <title> "Transformations Between Boundary Codes, Run Length Codes, and Linear Quadtrees," </title> <booktitle> Proceedings of the 8th International Parallel Processing Symposium, </booktitle> <pages> pp. 120-125, </pages> <year> 1994. </year>
Reference-contexts: Contour ranking can be viewed as performing list ranking in images. The problem arises when edge contours generated by edge operators in a 2-dimensional image plane are transformed into a linearized representation. Such representations are more compact for processing performed in subsequent mid- and high-level vision tasks <ref> [5, 16, 20] </ref>. Generating the linear representation is called contour ranking. The algorithms we describe use divide-and-conquer and merge information about subimages in order to compute the final values. The information needed about a subimage is proportional to the number of edge points on the boundary of the subimage.
Reference: [17] <author> P. Liu, W. Aiello, S. Bhatt, </author> <title> "An Atomic Model for Message Passing," </title> <booktitle> Proceedings of 5-th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 154-163, </pages> <year> 1993. </year> <month> 34 </month>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 6, 10, 13, 17, 23, 24, 25] </ref>. In most of these models, including the BSP model [24], the postal model [3], and the LogP model [6], processors are assumed to communicate using a point-to-point message router. <p> Nonblocking sends thus allow overlapping of communication and computation and pipelining of multiple send operations. Analogously, receive operations issued by the processors can also be blocking or nonblocking. For additional details on routing protocols we refer to <ref> [7, 14, 17] </ref>. Sending a single message from P i to P j We start the description of how communication units are determined by giving a cost estimation for sending a single message between two processors.
Reference: [18] <author> G. Papadopoulos, </author> <title> "Constant Factors Matter: Putting Communication on the Compu--tation Power Curve," </title> <booktitle> Proceedings of DIMACS Workshop on Model, Architectures, and Technologies for Parallel Computation, </booktitle> <year> 1993. </year>
Reference-contexts: These weights should be based on the ratio between the processor clock speed and the network clock speed as well as the ratio of the bandwidth of the network and the bandwidth of the processors <ref> [18] </ref>. In the high-level approach taken by our model, clock speeds and bandwidth parameters do not influence the design of an algorithm and they are thus not included.
Reference: [19] <author> R. Ponnusamy, A. Choudhary, G. Fox, </author> <title> "Communication Overhead on CM5: An Experimental Performance Evaluation," </title> <booktitle> Proceedings of 4-th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pp. 108-115, </pages> <year> 1992. </year>
Reference-contexts: Our results also indicate that the performance of 12 an implementation is influenced by the relationship among parameters of the parallel machine, as well as by the relationship of the parameters to the amount of data involved. This agrees with other research done on the implementation of communication operations <ref> [1, 2, 4, 19] </ref>. The Intel Touchstone Delta is a coarse-grained multi-processor system with 512 nodes organized as a 16 fi 32 2-dimensional mesh. Each node is directly connected to its 4 nearest neighbors. The communication network uses wormhole routing. <p> When partitioning into exclusive-or permutations, all-to-all is partitioned so that in the i-th permutation processor j sends a message to i j. Implementations of these approaches on different machines have shown exclusive-or permutations to be superior to linear permutations <ref> [19, 22] </ref>. Another interesting approach for partitioning all-to-all routings into permutations has been introduced in [21]. We call this approach partitioning into balanced permutations and refer to [11] for implementation details. Balanced permutations are relevant to the mesh architecture since they minimize the congestion over the links.
Reference: [20] <author> H. Samet, </author> <title> Applications of Spatial Data Structures, Computer Graphics, and Image Processing, </title> <publisher> Addison Wesley, </publisher> <year> 1990. </year>
Reference-contexts: Contour ranking can be viewed as performing list ranking in images. The problem arises when edge contours generated by edge operators in a 2-dimensional image plane are transformed into a linearized representation. Such representations are more compact for processing performed in subsequent mid- and high-level vision tasks <ref> [5, 16, 20] </ref>. Generating the linear representation is called contour ranking. The algorithms we describe use divide-and-conquer and merge information about subimages in order to compute the final values. The information needed about a subimage is proportional to the number of edge points on the boundary of the subimage.
Reference: [21] <author> D.S. Scott, </author> <title> "Efficient All-to-All Communication Patterns in Hypercube and Mesh Topologies," </title> <booktitle> Proceedings of 6-th Distributed Memory Computing Conference, </booktitle> <pages> pp. 398-403, </pages> <year> 1991. </year>
Reference-contexts: Implementations of these approaches on different machines have shown exclusive-or permutations to be superior to linear permutations [19, 22]. Another interesting approach for partitioning all-to-all routings into permutations has been introduced in <ref> [21] </ref>. We call this approach partitioning into balanced permutations and refer to [11] for implementation details. Balanced permutations are relevant to the mesh architecture since they minimize the congestion over the links.
Reference: [22] <author> R. Thakur, A. Choudhary, </author> <title> "All-to-all Communication on Meshes with Wormhole Routing," </title> <booktitle> Proceedings of 8-th International Parallel Processing Symposium, </booktitle> <pages> pp. 561-565, </pages> <year> 1994. </year>
Reference-contexts: When partitioning into exclusive-or permutations, all-to-all is partitioned so that in the i-th permutation processor j sends a message to i j. Implementations of these approaches on different machines have shown exclusive-or permutations to be superior to linear permutations <ref> [19, 22] </ref>. Another interesting approach for partitioning all-to-all routings into permutations has been introduced in [21]. We call this approach partitioning into balanced permutations and refer to [11] for implementation details. Balanced permutations are relevant to the mesh architecture since they minimize the congestion over the links. <p> The approach used in the second one, Algorithm 2-lev-r,c is tailored towards the mesh architecture. An idea similar to the one used in Algorithm 2-lev-sq is described in [4] and an implementation of Algorithm 2-lev-c,r has also been reported in <ref> [22] </ref>. In Algorithm 2-lev-sq, a p-processor machine is logically partitioned into p p submachines, S 0 ; : : :S p p1 . Submachine S i performs an all-to-all routing within S i sending long messages of length p p 1L. <p> The advantage of the 3-step algorithm is that it uses square meshes as submachines, whereas the 2-step one uses linear arrays. The approach in Algorithm logp-lev-bfly has consistently been judged as being expensive for large message sizes <ref> [4, 22] </ref>. Our metric and the observed performance on the Delta, confirms that as well. 5 Validation through Divide-and-Conquer Solutions On coarse-grained machines, divide-and-conquer strategies are natural and often result in efficient solutions.
Reference: [23] <author> P. de la Torre and C.P. Kruskal, </author> <title> "Towards a Single Model of Efficient Computation in Real Parallel Machines," </title> <journal> Future Generation Computer Systems, </journal> <volume> Vol. 8, </volume> <pages> pp. 395-408, </pages> <year> 1992. </year>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 6, 10, 13, 17, 23, 24, 25] </ref>. In most of these models, including the BSP model [24], the postal model [3], and the LogP model [6], processors are assumed to communicate using a point-to-point message router.
Reference: [24] <author> L.G. Valiant, </author> <title> "A Bridging Model for Parallel Computation," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 33, No. 8, </volume> <pages> pp. 103-111, </pages> <year> 1990. </year>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 6, 10, 13, 17, 23, 24, 25] </ref>. In most of these models, including the BSP model [24], the postal model [3], and the LogP model [6], processors are assumed to communicate using a point-to-point message router. <p> Recently, a number of models with this goal have been proposed [3, 6, 10, 13, 17, 23, 24, 25]. In most of these models, including the BSP model <ref> [24] </ref>, the postal model [3], and the LogP model [6], processors are assumed to communicate using a point-to-point message router. Composing more involved communication operations by using the message router places a significant burden on application programmers. <p> We compare predicted and actual performance for common communication operations, including one-to-all, all-to-one, and all-to-all routing, and for contour ranking algorithms based on different divide-and-conquer solutions. In our model, we assume that computation is synchronized by a barrier-style synchronization mechanism similar to the one described in <ref> [24] </ref>. More precisely, an algorithm can be partitioned into a sequence of supersteps, with each superstep corresponding to local computation followed 2 by sending and receiving messages. Synchronization occurs between supersteps.
Reference: [25] <author> D.S. Wills and W. Dally, </author> <title> "Pi: A Parallel Architecture Interface," </title> <booktitle> Proceedings of 4-th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pp. 345-352, </pages> <year> 1992. </year> <month> 35 </month>
Reference-contexts: In addition, such a model should provide a platform for algorithm development and allow accurate prediction of the preformance of an algorithm. Recently, a number of models with this goal have been proposed <ref> [3, 6, 10, 13, 17, 23, 24, 25] </ref>. In most of these models, including the BSP model [24], the postal model [3], and the LogP model [6], processors are assumed to communicate using a point-to-point message router.
References-found: 25

