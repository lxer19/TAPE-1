URL: ftp://ftp.idsia.ch/pub/techrep/IDSIA-03-99.ps.gz
Refering-URL: http://www.idsia.ch/techrep.html
Root-URL: http://www.idsia.ch/techrep.html
Email: ffred,felix,juergeng@idsia.ch  
Title: Automatic discrimination among languages based on prosody alone  
Author: Fred Cummins Felix Gers, Juergen Schmidhuber 
Date: February 3, 1999  
Address: Corso Elvezia 36 CH 6900 Lugano Switzerland  
Affiliation: Istituto Dalle Molle di Studie sull'Intelligenza Artificiale  
Pubnum: IDSIA Technical Report IDSIA-03-99  
Abstract: The development of methods for the automatic identification of languages is motivated both by speech-based applications intended for use in a multi-lingual environment, and by theoretical questions of cross-linguistic variation and similarity. We evaluate the potential utility of two prosodic variables, F 0 and amplitude envelope modulation, in a pairwise language discrimination task. Discrimination is done using a novel neural network which can successfully attend to temporal information at a range of timescales. Both variables are found to be useful in discriminating among languages, and confusion patterns, in general, reflect traditional intonational and rhythmic language classes. The methods employed allow empirical determination of prosodic similarity across languages. Die Entwicklung von Methoden zur automatischen Sprachidentifikation wird motiviert sowohl durch sprach-basierte Anwendungen, die zum Einsatz in einer mehrsprachigen Umgebung bestimmt sind, als auch durch theoretische Fragen der interlinguistischen Variation und Ahnlichkeit. Wir erproben die eventuelle Nutzbarkeit zweier prosodischer Vari-ablen, F 0 und die Modulation der Einhullenden der Amplitude, an einem Problem mit der Zielsetzung paarweiser Sprachdiskriminierung. Die Diskriminierung erfolgt mittels eines neuen neuronalen Netzwerkes das imstande ist Information, die uber meherere zeitliche Skalen verteilt ist, zu nutzen. Beide Variablen haben sich bei der Diskriminierung zwischen Sprachen als nutzlich erwiesen und die resultierenden Verwechslungsmuster spiegeln die traditionellen Sprachgruppierungen auf der basis von Intonation und Rhythmus wieder. Die angewandten Methoden ermoglichen die empirische Festellung der prosodischen Ahn lichkeit unterschiedlicher Sprachen. fl To whom correspondence should be addressed
Abstract-found: 1
Intro-found: 1
Reference: <author> Beckman, M. E. </author> <year> (1996). </year> <title> The parsing of prosody. </title> <booktitle> Language and Cognitive Processes, </booktitle> 11(1/2):17-67. 
Reference: <author> Cummins, F. </author> <year> (1997). </year> <title> Rhythmic Coordination in English Speech: An Experimental Study. </title> <type> PhD thesis, </type> <institution> Indiana University, Bloomington, </institution> <note> IN. Also Technical Report 198, </note> <institution> Indiana University Cognitive Science Program. </institution>
Reference: <author> Cummins, F. and Port, R. F. </author> <year> (1996). </year> <title> Rhythmic constraints on English stress timing. </title> <editor> In Bunell, H. T. and Idsardi, W., editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Spoken Language Processing, </booktitle> <pages> pages 2036-2039. </pages> <institution> Alfred duPont Institute, Wilmington, Delaware. </institution>
Reference: <author> Cummins, F. and Port, R. F. </author> <year> (1998). </year> <title> Rhythmic constraints on stress timing in English. </title> <journal> Journal of Phonetics, </journal> <volume> 26(2) </volume> <pages> 145-171. </pages>
Reference: <author> Dauer, R. M. </author> <year> (1983). </year> <journal> Stress-timing and syllable-timing reanalyzed. Journal of Phonetics, </journal> <volume> 11 </volume> <pages> 51-62. </pages>
Reference-contexts: A long-standing crude taxonomy which recognizes stress-timed, syllable-timed and mora-timed languages has repeatedly failed to find empirical support from acoustic measurements <ref> (Dauer, 1983) </ref>, but no credible model has yet emerged to replace it. Evidence for strong rhythmic constraints on speech production was presented by Cummins and Port (1996, 1998), within the confines of a phrase-repetition task.
Reference: <author> Hazen, T. J. and Zue, V. W. </author> <year> (1994). </year> <title> Automatic language identification using a segment-based approach. </title> <booktitle> In Proceedings of the 3rd European Conference on Speech Communication and Technology, </booktitle> <pages> pages 1307-1310. </pages>
Reference: <author> Hazen, T. J. and Zue, V. W. </author> <year> (1997). </year> <title> Segment-based automatic language identification. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 101(4) </volume> <pages> 2323-2331. </pages>
Reference-contexts: Several groups have published results based on this corpus, making comparison across systems feasible (Hazen and Zue, 1994; Zissman, 1995; Thyme-Gobbel and Hutchins, 1996). LID systems typically make use of several more or less independent sources of information which are extracted from the raw speech signal <ref> (Hazen and Zue, 1997) </ref>. By far the most important source of information for LID is the short-term spectrum (usually represented by Mel-scaled cepstral coefficients). This is used to identify phones or phonemes, e.g. using hidden Markov models (Kadambe and Hieronymus, 1994). <p> This is used to identify phones or phonemes, e.g. using hidden Markov models (Kadambe and Hieronymus, 1994). This segment-based information can be used to assess the likelihood of the observed acoustic realization of segments, as well as the probability of observed segmental distributions and combinations (phonotactics) <ref> (Hazen and Zue, 1997) </ref>. Apart from segment-based information, there is reason to believe that suprasegmental, or prosodic information is of potential value in discriminating among languages.
Reference: <author> Hochreiter, J. </author> <year> (1991). </year> <note> Untersuchungen to dynamischen neuronalen Netzen. Diploma thesis, </note> <institution> Technische Universitat Munchen. </institution> <note> 13 Hochreiter, </note> <author> S. and Schmidhuber, J. </author> <year> (1997). </year> <title> Long short-term memory. Neural Computation, </title> <publisher> 9(8):1735--1780. </publisher>
Reference: <author> Itahashi, S., Zhou, J. X., and Tanaka, K. </author> <year> (1994). </year> <title> Spoken language discrimination using speech fundamental frequency. </title> <booktitle> In Proceedings of the 1994 International Conference on Spoken Language Processing, </booktitle> <volume> volume 4, </volume> <pages> pages 1899-1902, </pages> <address> Yokohama, Japan. </address>
Reference: <author> Kadambe, S. and Hieronymus, J. L. </author> <year> (1994). </year> <title> Spontaneous speech language identification with a knowledge of linguistics. </title> <booktitle> In Proceedings of the 1994 International Conference on Spoken Language Processing, </booktitle> <pages> pages 1879-1882, </pages> <address> Yokohama, Japan. </address>
Reference-contexts: By far the most important source of information for LID is the short-term spectrum (usually represented by Mel-scaled cepstral coefficients). This is used to identify phones or phonemes, e.g. using hidden Markov models <ref> (Kadambe and Hieronymus, 1994) </ref>. This segment-based information can be used to assess the likelihood of the observed acoustic realization of segments, as well as the probability of observed segmental distributions and combinations (phonotactics) (Hazen and Zue, 1997).
Reference: <author> Mozer, M. C. and Smolensky, P. </author> <year> (1989). </year> <title> Skeletonization: A technique for trimming the fat from a network via relevance assessment. </title> <editor> In Touretzky, D. S., editor, </editor> <booktitle> Advances in Neural Information Processing Systems 1, </booktitle> <pages> pages 107-115. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This is one approach to the general goal in network training of ensuring that separate hidden units or elements attempt to solve separate parts of the problem <ref> (Mozer and Smolensky, 1989) </ref>. 7 2.4 Network training In each network trial, the network was trained on 200 speech files from each of two languages (or 180, when Japanese was one of the two). Speech data was input at the 100 Hz resolution described above.
Reference: <author> Muthusamy, Y. K., Cole, R. A., and Oshika, B. T. </author> <year> (1992). </year> <title> The OGI multi-language telephone speech corpus. </title> <booktitle> In Proceedings of the International Conference on Spoken Language Processing 1992, </booktitle> <address> Banff, Canada. </address>
Reference-contexts: Research on language identification (LID) has benefitted greatly from the recent availability of large multi-language corpora. Of particular note is the Oregon Graduate Institute Telephone Speech corpus (OGI TS) <ref> (Muthusamy et al., 1992) </ref>, which is available from the Linguistic Data Consortium. This database contains recordings of telephone conversations in which speakers responded in their native language to a series of prompts designed to elicit speech on a continuum from specific lexical items to unconstrained monologue. <p> This provides an empirical handle on the difficult task of establishing language typologies based on intonation and rhythm. 2 General Methods 2.1 Data We use a subset of the OGI Multi-Language Telephone Speech Corpus, which was specifically designed to support language identification research <ref> (Muthusamy et al., 1992) </ref>. We restrict our attention to the five languages English, Japanese, Spanish, Mandarin Chinese and German.
Reference: <author> Pierrehumbert, J. B. and Beckman, M. E. </author> <year> (1988). </year> <title> Japanese Tone Structure. Linguistic Inquiry Monographs. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Ma. </address>
Reference: <author> Scott, S. K. </author> <year> (1993). </year> <title> P-centers in Speech: An Acoustic Analysis. </title> <type> PhD thesis, </type> <institution> University College London. </institution>
Reference: <author> Tajima, K. </author> <year> (1998). </year> <title> Speech Rhythm in English and Japanese: Experiments in Speech Cycling. </title> <type> PhD thesis, </type> <institution> Indiana University, Bloomington, </institution> <note> IN. </note>
Reference-contexts: These beats were found to lie at points within the repetition cycle which were consistent with a simple rhythmic interpretation. Similar, though more complex results, have been obtained for Japanese, suggesting that here, too, language-dependent features are present <ref> (Tajima, 1998) </ref>. In this study, we use F 0 and amplitude envelope modulation for discriminating among languages. Our approach contrasts with that of Thyme-Gobbel and Hutchins (1996), in that we do not compute a featural representation of the speech signal in advance.
Reference: <author> Thyme-Gobbel, A. and Hutchins, S. E. </author> <year> (1996). </year> <title> On using prosodic cues in automatic language identification. </title> <booktitle> In Proceedings of the 1996 International Conference on Spoken Language Processing, </booktitle> <volume> volume 3, </volume> <pages> pages 1768-1771, </pages> <address> Philadelphia, PA. </address>
Reference: <author> Zissman, M. A. </author> <year> (1995). </year> <title> Language identification using phoneme recognition and phonotactic language modeling. </title> <booktitle> In Proceedings of the 1996 International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 3503-3506. 14 </pages>
References-found: 17

