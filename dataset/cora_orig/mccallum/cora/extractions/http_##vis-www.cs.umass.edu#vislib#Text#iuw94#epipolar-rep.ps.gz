URL: http://vis-www.cs.umass.edu/vislib/Text/iuw94/epipolar-rep.ps.gz
Refering-URL: http://vis-www.cs.umass.edu/vislib/Text/iuw94/files.html
Root-URL: 
Title: The Epipolar Parametrization  
Author: Richard S. Weiss 
Address: Amherst, MA 01003-4610  
Affiliation: Dept. of Computer Science University of Massachusetts,  
Abstract: The epipolar parametrization arises naturally in the reconstruction of surfaces from profiles with known camera motion. This is a special case of a local parametric representation which is a mesh. Local parametric representations can be combined into a global one by computing the transformation in parameter space on the overlap of the patches. This paper also discusses the applicability of this type of model to problems in grasp configuration determination and pose determination.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.Blake and R.Cipolla, </author> <title> `Robust estimation of surface curvature from deformations of apparent contours', </title> <booktitle> Image and Vision Computing 9 (1991), </booktitle> <pages> 107-112. </pages>
Reference-contexts: This can result in a mesh where the nodes are the intersections of the two families of curves. It is the `epipolar parametrization' of M which is used in <ref> [1, 2] </ref> to reconstruct c (0) to c (t). Also shown are the two corresponding critical sets 0 , t , a segment of epipolar curve (drawn heavily), viewlines (dashed) tangent to the epipolar curve, and a local coordinate grid of critical sets and epipolar curves.
Reference: [2] <author> R. Cipolla and A. Blake, </author> <title> `Surface shape from the deformation of apparent contours', </title> <editor> Inter-nat. J. </editor> <booktitle> of Computer Vision 9 (1992), </booktitle> <pages> 83-112. </pages>
Reference-contexts: This can result in a mesh where the nodes are the intersections of the two families of curves. It is the `epipolar parametrization' of M which is used in <ref> [1, 2] </ref> to reconstruct c (0) to c (t). Also shown are the two corresponding critical sets 0 , t , a segment of epipolar curve (drawn heavily), viewlines (dashed) tangent to the epipolar curve, and a local coordinate grid of critical sets and epipolar curves.
Reference: [3] <author> J.-L. Chen, G.C. Stockman, and K. Rao, </author> <title> "Recovering and Tracking Pose of curved 3D Objects from 2D IMages," </title> <journal> cvpr93 pp. </journal> <pages> 233-239. </pages>
Reference-contexts: The pose (i.e. position and orientation) of an object has six parameters: three rotational and three translational. Most pose algorithms take as input an initial "guess" of the approximate object pose and correspondences between a set of projected model features and 2D image features. Chen, Stockman, et al. <ref> [3] </ref> computed pose from profiles using curvature information. One would like to know how closely the profile of the generated view matches the actual view.
Reference: [4] <author> A. Blake and M. Taylor, </author> <title> "Planning planar grasps of smooth contours," </title> <booktitle> IEEE Proc. Int. Conf. on Robotics and Automation. </booktitle> <publisher> IEEE Computer Society Press: Los Alamitos. </publisher> <year> 1993, </year> <pages> pp. </pages> <month> II-834-839. </month>
Reference: [5] <author> O.D. Faugeras, </author> <title> Three Dimensional Computer Vision, </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: The epipolar plane is the plane spanned by this ray and the tangent to the curve c of centers. In practice the epipolar plane is computed from a visual ray to one camera center and the baseline connecting the two centers <ref> [5, p.170] </ref>. On the surface M an epipolar curve through r is defined as one whose tangent is along the visual ray as shown in Fig. 1. As c moves with time, the visual ray slips along the epipolar curve.
Reference: [6] <author> O.D. Faugeras. </author> <title> `On the motion of 3-D curves and its relation to optic flow,' </title> <booktitle> Proc 1st ECCV, </booktitle> <pages> pp 107-117, </pages> <publisher> Springer Verlag, </publisher> <month> April </month> <year> 1990. </year>
Reference: [7] <author> P.J. Giblin, J.E. Rycroft and F.E. </author> <title> Pollick `Recovery of an unknown axis of rotation from the profiles of a rotating surface', </title> <publisher> J.Optical Soc. America 1994 </publisher>
Reference: [8] <author> P.J.Giblin and R.S.Weiss, </author> <title> `Reconstruction of surface from profiles', </title> <booktitle> Proc. First Internat Conf. on Computer Vision, London, 1987, Computer Society of the IEEE, </booktitle> <pages> pp. 136-144. </pages>
Reference: [9] <author> P.J.Giblin and R.S.Weiss, </author> <title> `Epipolar fields on surfaces', </title> <booktitle> Proceedings of ECCV, Stockholm 1994, Springer Lecture Notes on Computer Science, </booktitle> <editor> Ed. J.-O.Eklundh, </editor> <month> 800 </month> <year> (1994) </year> <month> 14-23. </month>
Reference-contexts: The first type is called the frontier, where the epipo-lar plane becomes tangent to M: It is precisely at such points that the epipolar curve becomes singular, and the epipolar parametrization breaks down. To examine the situation at the frontier one can use the `spatio-temporal surface' as in <ref> [9, 10] </ref>. The second type of situation occurs in the case of occlusion. Occlusion may happen in two ways. First, the surface normal may turn away from the camera. This event is typically a cusp and is characterized by the fact that the epipolar curve and critical set become tangent. <p> Taken together, the frontier and the natural boundary, which is the set of points of occlusion, form the boundary of each epipolar patch. A more complete description will appear in [10], and some of the results have appeared in <ref> [9] </ref>. To summarize those results, the (local) epipolar parametrization of M has a boundary when any of the following occur: (i) The critical sets form an envelope on M (fron tier points). (ii) The critical set and epipolar curve on M are smooth and tangent to one another.
Reference: [10] <author> P.J.Giblin and R.S.Weiss, </author> <title> `Epipolar curves on surfaces', </title> <note> to appear in Image and Vision Computing. </note>
Reference-contexts: This leads to strategies that use a sequence of planar trajectories each of which may only produce a model of a small region on the surface. The boundaries of these patches, which depend on the camera trajectories, have been characterized in <ref> [10] </ref>. There are basically two types of situation which occur at the boundaries of an epipolar patch. The first type is called the frontier, where the epipo-lar plane becomes tangent to M: It is precisely at such points that the epipolar curve becomes singular, and the epipolar parametrization breaks down. <p> The first type is called the frontier, where the epipo-lar plane becomes tangent to M: It is precisely at such points that the epipolar curve becomes singular, and the epipolar parametrization breaks down. To examine the situation at the frontier one can use the `spatio-temporal surface' as in <ref> [9, 10] </ref>. The second type of situation occurs in the case of occlusion. Occlusion may happen in two ways. First, the surface normal may turn away from the camera. This event is typically a cusp and is characterized by the fact that the epipolar curve and critical set become tangent. <p> These points are characterized as the distal points of contact of bitangent viewing rays. Taken together, the frontier and the natural boundary, which is the set of points of occlusion, form the boundary of each epipolar patch. A more complete description will appear in <ref> [10] </ref>, and some of the results have appeared in [9].
Reference: [11] <author> R. Grupen and R. Weiss. </author> <title> "Force Domain Models for Multifingered Grasp Control." </title> <booktitle> In Proc. Int. Conf. on Robotics and Automation, </booktitle> <publisher> IEEE Computer Society Press: Los Alamitos. </publisher> <year> 1991. </year>
Reference: [12] <author> K. Higuchi, H. Delingette, M. Hebert, K. </author> <title> Ikeuchi, "Merging Multiple views using a spherical representation." </title> <booktitle> Proc. Second CAD-Based Vision Workshop. </booktitle> <publisher> IEEE Computer Society Press: Los Alamitos. </publisher> <year> 1994, </year> <pages> pp. 124-131. </pages>
Reference-contexts: I would postulate that a graph representation is suitable for any of the standard techniques for collecting 3D data. The simplex angle image, which can be used for recognition is a derivative of a degree three graph representation that satisfies certain regularity conditions <ref> [12] </ref>. In addition, sensor fusion is easily done with a graph representation because one needs to model uncertainty at the resolution of the data, otherwise fitting data to an implicit (inside-outside) function makes certain assumptions about the shape of the object and may weight data points inappropriately.
Reference: [13] <author> T. Joshi, N. Ahuja, J. Ponce, </author> <title> Structure and Motion Estimation from Dynamic Silhouttes, </title> <institution> University of Illinois Tech. Rpt. UIUC-BI-AI-RCV-94-01, </institution> <year> 1994. </year>
Reference: [14] <author> K.N.Kutulakos and C.R.Dyer, </author> <title> `Occluding contour detection using affine invariants and purposive viewpoint control', </title> <booktitle> IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <address> Seattle, Washington (1994) 323-330. </address>
Reference: [15] <author> K.N.Kutulakos and C.R.Dyer, </author> <title> `Global surface reconstruction by purposive control of observation motion', </title> <booktitle> IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <address> Seattle, Washington (1994), </address> <pages> 331-338. </pages>
Reference-contexts: It may happen that only part of the surface is observable, and even then it may require several trajectories by the camera to reconstruct that part. Ku-tulakos and Dyer <ref> [15] </ref> have developed strategies for moving the camera or the object so that a maximal subset of the surface is covered by such a set of patches. 2 Epipolar parametrization Given a smooth surface M and a curve c (t) of camera centers, we have, for each t, a critical set
Reference: [16] <author> J.R.Steenstrom and C.I.Connolly, </author> <title> `Constructing object models from multiple images', </title> <journal> Int. J. of Computer Vision, </journal> <volume> 9 (1992), </volume> <pages> 185-212. </pages>
Reference: [17] <author> J. Ponce, S. Sullivan, J.-D. Boissonat, and J.- P. Merlet, </author> <title> "On characterizing and computing three- and four-finger force closure grasps of polyhedral objects," </title> <booktitle> IEEE Proc. Int. Conf. on Robotics and Automation. </booktitle> <publisher> IEEE Computer Society Press: Los Alamitos. </publisher> <year> 1993, </year> <pages> pp. </pages> <month> II-821-827. </month>
Reference: [18] <author> S. Sullivan, L. Sandford, and J. Ponce, </author> <title> "On Using Geometric Distance Fits to Estimate 3D Object Shape, Pose, and Deformation from Range, CT, and Video Images," </title> <booktitle> Proc. IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> New York, </address> <month> June </month> <year> 1993, </year> <pages> pp. 110-115. </pages>
Reference-contexts: For example, when fitting a super-ellipsoid to data there are a number of issues. First, using the evaluation of the inside-outside function is different from using geometric distance. In general, one can approximate geometric distance based on the gradient of the inside-outside function <ref> [18, 21] </ref>, but even then different points will have different covariances which need to be taken into account.
Reference: [19] <author> R.Szeliski, </author> <title> `Rapid octree construction from image sequences,' CVGIP: </title> <booktitle> Image Understanding 58 (1993), </booktitle> <pages> 23-32. </pages>
Reference: [20] <author> R. Szeliski and R. Weiss, </author> <title> `Robust shape recovery from occluding contours using a linear smoother,' </title> <booktitle> Proc. IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> New York, </address> <month> June </month> <year> 1993, </year> <month> pp.666-7. </month>
Reference-contexts: M from its profiles, although b-splines were used to represent critical sets. In <ref> [20] </ref> it is shown that reconstruction from the epipolar parametrization is readily transformable into an optimal estimation problem. <p> Therefore, it is possible to keep track of parts of the surface that have not been observed. As for the accuracy of depth, the approach of Szeliski and Weiss <ref> [20] </ref> uses linear smoothing and explicitly models the covariance of the position and curvature at each point in the mesh. It is clear that local parametric surface patches can be easily produced from reconstruction from profiles. In addition, information about curvature is recovered.
Reference: [21] <author> G.Taubin, R. Bolle, and D.B. Cooper, </author> <title> "Representing and comparing shapes using shape polynomials," </title> <booktitle> Proc. IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <year> 1989. </year> <pages> pp. 510-516. </pages>
Reference-contexts: For example, when fitting a super-ellipsoid to data there are a number of issues. First, using the evaluation of the inside-outside function is different from using geometric distance. In general, one can approximate geometric distance based on the gradient of the inside-outside function <ref> [18, 21] </ref>, but even then different points will have different covariances which need to be taken into account.
Reference: [22] <author> R. Vaillant and O.D. Faugeras, </author> <title> `Using extremal boundaries for 3-D object modeling,' </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 14, No. 2, </volume> <year> 1992, </year> <pages> pp. 157-173. </pages>
References-found: 22

