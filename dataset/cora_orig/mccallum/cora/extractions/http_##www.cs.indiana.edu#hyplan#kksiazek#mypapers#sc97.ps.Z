URL: http://www.cs.indiana.edu/hyplan/kksiazek/mypapers/sc97.ps.Z
Refering-URL: http://www.cs.indiana.edu/hyplan/kksiazek/pardis.html
Root-URL: http://www.cs.indiana.edu
Email: fkksiazek, gannong@cs.indiana.edu  
Title: PARDIS: CORBA-based Architecture for Application-Level Parallel Distributed Computation  
Author: Katarzyna Keahey and Dennis Gannon 
Address: 215 Lindley Hall Bloomington, IN 47405  
Affiliation: Department of Computer Science Indiana University  
Abstract: Modern technology provides the infrastructure necessary to develop distributed applications capable of using the power of multiple supercomputing resources and exploiting their diversity. The performance potential offered by distributed supercomputing is enormous, but it is hard to realize due to the complexity of programming in such environments. In this paper we introduce PARDIS, a system designed to overcome this challenge, based on ideas underlying the Common Object Request Broker Architecture (CORBA), a successful industry standard. PARDIS is a distributed environment in which objects representing data-parallel computations, called SPMD objects, as well as non-parallel objects present in parallel programs, can interact with each other across platforms and software systems. Each of these objects represents a small encapsulated application and can be used as a building block in the construction of powerful distributed metaapplications. The objects interact through interfaces specified in the Interface Definition Language (IDL), which allows the programmer to integrate within one metaapplication components implemented using different software systems. Further, support for non-blocking interactions between objects allows PARDIS to build concurrent distributed scenarios. 
Abstract-found: 1
Intro-found: 1
Reference: [ABC + 95] <author> S. Atlas, S. Banerjee, J.C. Cummings, P. J. Hinker, M. Srikant, J. V. W. Reyn-ders, and M. Tholburn, POOMA: </author> <title> A High Performance Distributed Simulation Environment for Scientific Applications, </title> <booktitle> Supercomputing '95 Proceedings, </booktitle> <month> De-cember </month> <year> 1995. </year>
Reference-contexts: In order to accommodate the largest possible set of applications, the required run-time system functionality in current implementation is very basic. We will show how PARDIS can be used to interface directly parallel packages, based on different run-time system approaches. Specifically, we have developed interfaces to the POOMA library <ref> [ABC + 95] </ref> and High Performance C++ Parallel Standard Template Library (HPC++ PSTL) [GBJ + ar]. <p> So far we have implemented this interface in MPI [For95], the Tulip [BG96] run-time system and the communication abstraction of the POOMA library <ref> [ABC + 95] </ref> which allows PARDIS to interact with the the object-oriented packages built on top of those systems. Restricting the assumptions about run-time system to a small set limits 4 the functionality of distributed argument structures, but allows us to provide interoperability with many parallel applications. <p> This limits the "programmer convenience" factor of our system. To address this problem we explored the possibility of expressing PARDIS IDL definitions directly in terms of data structures native to concrete packages: the distributed vector in HPC++ PSTL [GBJ + ar] and the field in the POOMA library <ref> [ABC + 95] </ref>. In order to use this mapping the programmer needs to annotate the IDL definitions with pragma statements directing the compiler to generate stubs marshaling the data into existing structures rather than generating code for their PARDIS representations. An example of this interaction is shown in section 4.3. <p> Further, both the diffusion and the gradient unit pipeline the results of every completed time-step to a visualizing server as part of their computation. In our simulation we will use a diffusion implementation which is a part of the POOMA application suite <ref> [ABC + 95] </ref>, a gradient program implemented in HPC++ PSTL, and a simple program for viewing the result.
Reference: [BBG + 94] <author> F. Bodin, P. Beckman, D. Gannon, J. Gotwals, S. Narayana, S. Srinivas, and B. Winnicka, Sage++: </author> <title> An object-oriented toolkit and class library for building Fortran and C++ restructuring tools, </title> <booktitle> Proceedings of the Second Annual Object-Oriented Numerics Conference (OON-SKI) (Sunriver, </booktitle> <address> Oregon), </address> <year> 1994, </year> <pages> pp. 122-138. </pages>
Reference-contexts: This direct interoperability requires customizing the compiler for any given package. However, in our experience the interfacing code is relatively straightforward, which may make possible generation of the necessary compiler routines from user's directions. A similar technique has been employed in the new implementation of the Sage++ library <ref> [BBG + 94] </ref>. Our experiences with providing customized mappings to different systems have revealed that although PARDIS can easily marshal complex data structures, the interfaced packages themselves are frequently unable to handle dynamically-sized, nested data structures. The marshaling code generated by PARDIS is of course available to the package.
Reference: [BG96] <author> P. Beckman and D. Gannon, Tulip: </author> <title> A Portable Run-Time System for Object-Parallel Systems, </title> <booktitle> Proceedings of the 10th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1996, </year> <pages> pp. 532-536. </pages>
Reference-contexts: In order to avoid conflicts, we also require a way to distinguish between PARDIS messages and messages pertaining to computation in user code (for example through a set of reserved message tags). So far we have implemented this interface in MPI [For95], the Tulip <ref> [BG96] </ref> run-time system and the communication abstraction of the POOMA library [ABC + 95] which allows PARDIS to interact with the the object-oriented packages built on top of those systems.
Reference: [BWF + 96] <author> F. Berman, R. Wolski, S. Figueira, J. Schopf, and G. Shao, </author> <title> Application-Level Scheduling on Distributed Heterogeneous Networks, </title> <booktitle> Supercomputing '96 Proceedings, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: Metacomputing environments and metasystems such as Globus [FK97], Legion [GW96] and WWVM [DF96] provide tools for application development and management in distributed environments. Services provided by these environments include resource configuration and management, security, fault-tolerance and debugging. AppLeS <ref> [BWF + 96] </ref> provides tools for efficient scheduling of distributed supercomputing applications.
Reference: [CS92] <author> C. Catlett and L. </author> <title> Smarr, Metacomputing, </title> <journal> Communications of the ACM 35 (1992), </journal> <volume> no. 6, </volume> <pages> 45-52. </pages>
Reference-contexts: However, the performance potential that these metacomputing environments <ref> [CS92, FK97] </ref> offer is seldom realized due to the difficulty of combining different transport mechanisms, software packages and heterogeneous resources in one system.
Reference: [DF96] <author> K. Dincer and G. C. Fox, </author> <title> Building a World-Wide Virtual Machine Based on Web and HPCC Technologies, </title> <booktitle> Supercomputing '96 Proceedings, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: This section will outline a number of current approaches to the problem of distributed supercomputing. Metacomputing environments and metasystems such as Globus [FK97], Legion [GW96] and WWVM <ref> [DF96] </ref> provide tools for application development and management in distributed environments. Services provided by these environments include resource configuration and management, security, fault-tolerance and debugging. AppLeS [BWF + 96] provides tools for efficient scheduling of distributed supercomputing applications.
Reference: [DFP + 96] <author> T. DeFanti, I. Foster, M. Papka, R. Stevens, and T. Kuhfuss, </author> <title> Overview of the I-Way: Wide-Area Visual Supercomputing, </title> <booktitle> The International Journal of Supercomputer Applications and High Performance Computing 10 (1996), </booktitle> <volume> no. 2, </volume> <pages> 123-131. </pages>
Reference-contexts: Values shown are the average over a series of measurements taken at different times. 5 Related Work As high-performance distributed computation became more feasible and more widespread, the challenges involved in constructing distributed metasystems received increasingly more attention. During the I-WAY <ref> [DFP + 96] </ref> networking experiment many researchers presented systems and applications capable of exploiting the heterogeneity of geographically distributed resources, proving that metacomputing is no longer a thing of the future. This section will outline a number of current approaches to the problem of distributed supercomputing.
Reference: [FGKT96] <author> I. Foster, J. Geisler, C. Kesselman, and S. Tuecke, </author> <title> Multimethod Communication for High-Performance Metacomputing Applications, </title> <booktitle> Supercomputing '96 Proceedings, </booktitle> <month> November </month> <year> 1996. </year> <month> 16 </month>
Reference-contexts: Another interesting approach to distributed supercomputing is offered by multi-method run-time systems and communication libraries <ref> [FGKT96, vRBF + 95] </ref>. These systems integrate diverse transport mechanisms under the same interface, thus allowing the programmer to treat a set of supercomputers as one virtual metacomputer.
Reference: [FK97] <author> I. Foster and C. Kesselman, Globus: </author> <title> A metacomputing infrastructure toolkit, </title> <booktitle> The International Journal of Supercomputer Applications and High Performance Computing 11 (1997), </booktitle> <volume> no. 2, </volume> <pages> 115-128. </pages>
Reference-contexts: However, the performance potential that these metacomputing environments <ref> [CS92, FK97] </ref> offer is seldom realized due to the difficulty of combining different transport mechanisms, software packages and heterogeneous resources in one system. <p> This section will outline a number of current approaches to the problem of distributed supercomputing. Metacomputing environments and metasystems such as Globus <ref> [FK97] </ref>, Legion [GW96] and WWVM [DF96] provide tools for application development and management in distributed environments. Services provided by these environments include resource configuration and management, security, fault-tolerance and debugging. AppLeS [BWF + 96] provides tools for efficient scheduling of distributed supercomputing applications.
Reference: [FKOT94] <author> I. Foster, C. Kesselman, R. Olson, and S. Tuecke, </author> <title> Nexus: An Interoperability Layer for Parallel and Distributed Computer Systems, </title> <note> Technical Memorandum ANL/MCS-TM-189 (1994). </note>
Reference-contexts: The current version of PARDIS uses NexusLite, the single threaded implementation of Nexus <ref> [FKOT94] </ref>, for network transport. PARDIS has been tested with parallel clients and servers running on SGI multi-processor architectures, IBM SP/2, and over networks of Sun workstations. 3 Programming Support for Parallel Distributed Com putation This section will discuss the programmer's view of PARDIS.
Reference: [For95] <author> Message Passing Interface Forum, </author> <title> MPI: A Message-Passing Interface Standard, </title> <month> June </month> <year> 1995. </year>
Reference-contexts: In order to avoid conflicts, we also require a way to distinguish between PARDIS messages and messages pertaining to computation in user code (for example through a set of reserved message tags). So far we have implemented this interface in MPI <ref> [For95] </ref>, the Tulip [BG96] run-time system and the communication abstraction of the POOMA library [ABC + 95] which allows PARDIS to interact with the the object-oriented packages built on top of those systems.
Reference: [GBJ + ar] <author> D. Gannon, P. Beckman, E. Johnson, T. Green, and M. Levine, </author> <title> HPC++ and the HPC++Lib Toolkit, Languages, Compilation Techniques and Run Time Systems (Recent Advances and Future Perspectives) (1997 (To appear)). </title>
Reference-contexts: We will show how PARDIS can be used to interface directly parallel packages, based on different run-time system approaches. Specifically, we have developed interfaces to the POOMA library [ABC + 95] and High Performance C++ Parallel Standard Template Library (HPC++ PSTL) <ref> [GBJ + ar] </ref>. <p> This limits the "programmer convenience" factor of our system. To address this problem we explored the possibility of expressing PARDIS IDL definitions directly in terms of data structures native to concrete packages: the distributed vector in HPC++ PSTL <ref> [GBJ + ar] </ref> and the field in the POOMA library [ABC + 95]. In order to use this mapping the programmer needs to annotate the IDL definitions with pragma statements directing the compiler to generate stubs marshaling the data into existing structures rather than generating code for their PARDIS representations.
Reference: [GS97] <author> A. Gokhale and D. Schmidt, </author> <title> Evaluating CORBA Latency and Scalability Over High-Speed ATM Networks, </title> <booktitle> Proceedings of the 17th International Conference on Distributed Systems, </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: By addressing interoperability at a higher level our approach makes it possible to combine components which are developed independently, possibly using different run-time systems. The success of CORBA also stimulated research investigating its performance for high-speed networks <ref> [GS97] </ref> and suitability for real-time application [SGHP97].
Reference: [GW96] <author> A. S. Grimshaw and W. A. Wulf, </author> <title> Legion | A View From 50,000 Feet, </title> <booktitle> Proceedings of the 5th IEEE International Symposium on High Performance Distributed Computation, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: This section will outline a number of current approaches to the problem of distributed supercomputing. Metacomputing environments and metasystems such as Globus [FK97], Legion <ref> [GW96] </ref> and WWVM [DF96] provide tools for application development and management in distributed environments. Services provided by these environments include resource configuration and management, security, fault-tolerance and debugging. AppLeS [BWF + 96] provides tools for efficient scheduling of distributed supercomputing applications.
Reference: [KBJ + 96] <author> L. V. Kale, M. Bhandarkar, N. Jagathesan, S. Krishnan, and J. Yelon, </author> <title> Converse: An Interoperable Framework for Parallel Programming, </title> <booktitle> Proceedings of the 10th International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1996. </year>
Reference-contexts: The marshaling code generated by PARDIS is of course available to the package. Packages based on different run-time systems can interoperate only in distributed mode; for literature related to interoperability on the same server see <ref> [KBJ + 96] </ref>. 7 4 Examples In this section we will present three examples to demonstrate that PARDIS has potential for easy development of efficient distributed scenarios.
Reference: [KG97] <author> K. Keahey and D. Gannon, PARDIS: </author> <title> A Parallel Approach to CORBA, </title> <booktitle> Proceedings of the 6th IEEE International Symposium on High Performance Distributed Computation, </booktitle> <month> August </month> <year> 1997. </year>
Reference-contexts: This approach allows for a high level of component reusability and does not require existing components to be reimplemented. Further, it allows PARDIS to take advantage of application-level information such as distribution of data structures in a data-parallel program <ref> [KG97] </ref>. PARDIS builds on CORBA in that it allows the programmer to construct metaappli-cations without concern for component location, heterogeneity of component resources, or data translation and marshaling in communication between them. However, PARDIS extends the CORBA object model by introducing SPMD objects representing data-parallel computations. <p> The server can set the distribution of any of the "in" arguments to its operations prior to object registration; the client can set the distribution of the expected "out" arguments before making an invocation. Knowledge of distribution allows the ORB to efficiently transfer arguments between the client and server <ref> [KG97] </ref>. The sequence class overloads operator [] to provide access to its elements with location transparency. We would like to stress however, that the main purpose of a distributed sequence is to be used as a container for argument data, not to provide its management.
Reference: [NBB + 96] <author> M. L. Norman, P. Beckman, G. L. Bryan, J. Dubinski, D. Gannon, L. Hernquist, K. Keahey, J. P. Ostriker, J. Shalf, J. Welling, and S. Yang, </author> <title> Galaxies Collide on the I-WAY: An Example of Heterogeneous Wide-Area Collaborative Supercomputing, </title> <booktitle> The International Journal of Supercomputer Applications and High Performance Computing 10 (1996), </booktitle> <volume> no. 2, </volume> <pages> 132-144. </pages>
Reference-contexts: We will also demonstrate how to use PARDIS to set up a simple pipelining scenario; this kind of interaction appears in many distributed scientific applications <ref> [NBB + 96, THC + 96] </ref>. Consider a metaapplication consisting of two distributed units: an application computing a simplified simulation of 2-D diffusion based on a 9-point stencil operation, and an application which computes magnitude gradient of the diffusion field in order to identify areas of the most intensive changes.
Reference: [OEPW96] <author> W.G. O'Farrell, F. Ch. Eigler, S. D. Pullara, and G. V. Wilson, </author> <title> Parallel Programming Using C++, ch. ABC++, </title> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: A non-blocking invocation can involve multiple futures of distributed as well as non-distributed arguments; they will all be resolved at the same time when the server completes its computation. The PARDIS C++ mapping for futures draws on an analogous abstraction implemented in ABC++ <ref> [OEPW96] </ref>. The use of futures is demonstrated in sections 4.1 and 4.2. On the server's side, after all objects have been created, the programmer usually passes control to PARDIS by calling POA::impl is ready ().
Reference: [OMG95] <author> OMG, </author> <title> The Common Object Request Broker: Architecture and Specification. Revision 2.0, OMG Document, </title> <month> June </month> <year> 1995. </year>
Reference-contexts: In this paper we describe PARDIS, a system which employs the ideas of the Common Object Request Broker Architecture (CORBA) <ref> [OMG95] </ref> | interoperability through meta-language interfaces | to implement application-level interaction of heterogeneous, PARallel components in a DIStributed environment. Addressing interoperability at the level of applications allows the programmer to build metaapplications from independently developed and tested components. <p> Our experiences indicate that this fact is due to two reasons. First, although invocations of both the gradient and show operations were non-blocking, they were not "oneway" <ref> [OMG95] </ref> and as the time of send began to approach the execution time of this relatively lightweight application the advantages of parallel execution began to disappear.
Reference: [SGHP97] <author> D. Schmidt, A. Gokhale, T. Harrison, and G. Parulkar, </author> <title> A High-performance Endsystem Architecture for Real-time CORBA, </title> <journal> IEEE Communications Magazine 14 (1997), </journal> <volume> no. 2. </volume> <pages> 17 </pages>
Reference-contexts: By addressing interoperability at a higher level our approach makes it possible to combine components which are developed independently, possibly using different run-time systems. The success of CORBA also stimulated research investigating its performance for high-speed networks [GS97] and suitability for real-time application <ref> [SGHP97] </ref>.
Reference: [THC + 96] <author> V. E. Taylor, M. Huang, T. Canfield, R. Stevens, D. Reed, and S. </author> <title> Lamm, Per--formance Modeling of Interactive, Immersive Virtual Environments for Finite Element Simulations, </title> <booktitle> The International Journal of Supercomputer Applications and High Performance Computing 10 (1996), </booktitle> <volume> no. 2, </volume> <pages> 145-156. </pages>
Reference-contexts: We will also demonstrate how to use PARDIS to set up a simple pipelining scenario; this kind of interaction appears in many distributed scientific applications <ref> [NBB + 96, THC + 96] </ref>. Consider a metaapplication consisting of two distributed units: an application computing a simplified simulation of 2-D diffusion based on a 9-point stencil operation, and an application which computes magnitude gradient of the diffusion field in order to identify areas of the most intensive changes.
Reference: [vRBF + 95] <author> R. van Renesse, K. P. Birman, R. Friedman, M. Hayden, and D. A. Karr, </author> <title> A Framework for Protocol Composition in Horus, </title> <booktitle> Proceedings of Principles of Distributed Computing, </booktitle> <year> 1995. </year> <month> 18 </month>
Reference-contexts: Another interesting approach to distributed supercomputing is offered by multi-method run-time systems and communication libraries <ref> [FGKT96, vRBF + 95] </ref>. These systems integrate diverse transport mechanisms under the same interface, thus allowing the programmer to treat a set of supercomputers as one virtual metacomputer.
References-found: 22

