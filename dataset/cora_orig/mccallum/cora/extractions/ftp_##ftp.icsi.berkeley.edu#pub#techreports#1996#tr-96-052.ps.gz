URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1996/tr-96-052.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1996.html
Root-URL: http://www.icsi.berkeley.edu
Title: Optimal Trade-Offs Between Size and Slowdown for Universal Parallel Networks  
Author: Friedhelm Meyer auf der Heide yz Martin Storch Rolf Wanka 
Note: On leave from  
Address: I 1947 Center St. Suite 600 Berkeley, California 94704-1198  33095 Paderborn, Germany  1947 Center Street, Berkeley, CA 94704-1198, USA,  33095 Paderborn, Germany,  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  Heinz Nixdorf Institute and Dept. of Mathematics and Computer Science, Paderborn University,  International Computer Science Institute,  Heinz Nixdorf Institute and Dept. of Mathematics and Computer Science, Paderborn University,  
Pubnum: TR-96-052  
Email: email: fmadh@uni-paderborn.de.  email: wanka@icsi.berkeley.edu.  email: wanka@uni-paderborn.de.  
Phone: (510) 643-9153 FAX (510) 643-7684  
Date: December 1996  
Abstract: A parallel processor network is called n-universal with slowdown s, if it can simulate each computation of each constant-degree processor network with n processors with slowdown s. We prove the following lower bound trade-off: For each constant-degree n-universal network of size m with slowdown s, m s = (n log m) holds. Our tradeoff holds for a very general model of simulations. It covers all previously considered models and all known techniques for simulations among networks. For m n, this improves a previous lower bound by a factor of log log n, proved for a weaker simulation model. For m &lt; n, this is the first non-trivial lower bound for this problem. In this case, this lower bound is asymptotically tight. fl Supported by DFG-Sonderforschungsbereich 376 "Massive Parallelitat," by DFG Leibniz Grant Me 872/6-1, and by EU ESPRIT Long Term Research Project 20244 (ALCOM-IT). A preliminary version of this paper appeared in: Proc. 7th ACM Symposium on Parallel and Algorithms and Architectures (SPAA), pp. 119-128; 1995. The full version will appear in: Mathematical Systems Theory (MST). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alf-Christian Achilles. </author> <title> Optimal emulation of meshes on meshes of trees. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing (EURO-PAR), </booktitle> <pages> pages 193-204, </pages> <year> 1995. </year>
Reference-contexts: A model of this type was first considered by Meyer auf der Heide in [13]. For special simulations, there are several results indicating the strength of these simulations, see <ref> [9, 18, 7, 8, 1] </ref>. E. g., the p p n-mesh can be simulated on an n-processor butterfly network with constant slowdown [9], whereas an embedding has slowdown (log n), as shown in [4, 3].
Reference: [2] <author> M. Ajtai, J. Komlos, and E. Szemeredi. </author> <title> Sorting in clog n parallel steps. </title> <journal> Combinatorica, </journal> <volume> 3 </volume> <pages> 1-19, </pages> <year> 1983. </year>
Reference-contexts: There are several randomized routing algorithms known, e. g., for the butterfly network (see [11]). Efficient deterministic algorithms for the h-h routing problem are known, e. g., for the constant-degree network one obtains by applying Leighton's Columnsort approach [12] to the AKS sorting circuit <ref> [2] </ref> and using parallel sorting as routing mechanism. 3 Lower Bound 3.1 The Simulation Model The simulation of T steps of a guest network G 2 U 0 by T 0 steps on a host network M of size m is modeled by a pebble game.
Reference: [3] <author> Sandeep N. Bhatt, Fan R. K. Chung, Jia-Wei Hong, F. Thomson Leighton, Bojana Obrenic, Arnold L. Rosenberg, and Eric J. Schwabe. </author> <title> Optimal emulations by Butterfly-like networks. </title> <journal> Journal of the ACM, </journal> <volume> 43 </volume> <pages> 293-330, </pages> <year> 1996. </year>
Reference-contexts: For special simulations, there are several results indicating the strength of these simulations, see [9, 18, 7, 8, 1]. E. g., the p p n-mesh can be simulated on an n-processor butterfly network with constant slowdown [9], whereas an embedding has slowdown (log n), as shown in <ref> [4, 3] </ref>. A more drastic difference is known for universal networks: In [14], an n 1+" -processor universal network is presented which has constant slowdown only.
Reference: [4] <author> Sandeep N. Bhatt, Fan R. K. Chung, Jia-Wei Hong, F. Thomson Leighton, and Arnold L. Rosenberg. </author> <title> Optimal simulations by Butterfly networks. </title> <booktitle> In Proceedings of the 20th ACM Symposium on Theory of Computing (STOC), </booktitle> <pages> pages 192-204, </pages> <year> 1988. </year>
Reference-contexts: For special simulations, there are several results indicating the strength of these simulations, see [9, 18, 7, 8, 1]. E. g., the p p n-mesh can be simulated on an n-processor butterfly network with constant slowdown [9], whereas an embedding has slowdown (log n), as shown in <ref> [4, 3] </ref>. A more drastic difference is known for universal networks: In [14], an n 1+" -processor universal network is presented which has constant slowdown only.
Reference: [5] <author> Robert Cypher and C. Greg Plaxton. </author> <title> Deterministic sorting in nearly logarithmic time on the hypercube and related computers. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 47 </volume> <pages> 501-548, </pages> <year> 1993. </year>
Reference-contexts: E. g., this means that constant-degree networks like the shu*e-exchange network and the cube-connected cycles network, each of size n, are n-universal with slowdown O (log n (log log n) 2 ) using the algorithm presented in <ref> [5] </ref>. A more general approach is the concept of dynamic simulations (also sometimes called emulations with redundancy). Such simulations allow that single guest processors are simulated at several host processors, and that the set of simulating processors may vary during the simulation.
Reference: [6] <author> Zvi Galil and Wolfgang Paul. </author> <title> An efficient general-purpose parallel computer. </title> <journal> Journal of the ACM, </journal> <volume> 30 </volume> <pages> 360-387, </pages> <year> 1983. </year>
Reference-contexts: We refer to these as special simulations. As it is not feasible to tailor topologies of networks to specific process graphs or communication patterns of parallel programs, Galil and Paul <ref> [6] </ref> have asked for constant-degree universal networks that are able to simulate all constant-degree networks of size n without slowing down the computation time substantially. More specifically, let U be the class of all constant-degree networks with n processors. <p> Previous Work. One approach for special simulations is the concept of embeddings. The processors of the guest are statically mapped to the processors of the host. For this concept, many results are known. See [16] for an overview. With respect to universal parallel networks, Galil and Paul <ref> [6] </ref> show that each network M of size m that can sort n numbers in time sort (n; m) is n-universal with slowdown O (sort (n; m)).
Reference: [7] <author> Christos Kaklamanis, Danny Krizanc, and Satish Rao. </author> <title> New graph decompositions and fast emulations in hypercubes and butterflies. </title> <booktitle> In Proceedings of the 5th ACM Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <pages> pages 325-334, </pages> <year> 1993. </year> <month> 16 </month>
Reference-contexts: A model of this type was first considered by Meyer auf der Heide in [13]. For special simulations, there are several results indicating the strength of these simulations, see <ref> [9, 18, 7, 8, 1] </ref>. E. g., the p p n-mesh can be simulated on an n-processor butterfly network with constant slowdown [9], whereas an embedding has slowdown (log n), as shown in [4, 3].
Reference: [8] <author> Christos Kaklamanis, Danny Krizanc, and Satish Rao. </author> <title> Universal emulations with sublogarithmic slowdown. </title> <booktitle> In Proceeding of the 34th IEEE Symposium on Foundations of Computer Science (FOCS), </booktitle> <pages> pages 341-350, </pages> <year> 1993. </year>
Reference-contexts: A model of this type was first considered by Meyer auf der Heide in [13]. For special simulations, there are several results indicating the strength of these simulations, see <ref> [9, 18, 7, 8, 1] </ref>. E. g., the p p n-mesh can be simulated on an n-processor butterfly network with constant slowdown [9], whereas an embedding has slowdown (log n), as shown in [4, 3]. <p> In [13], a butterfly-like network of size n 1+" is presented that is n-universal 1 with slowdown O (log log n). A similar result is obtained in <ref> [8] </ref>. In [8], a network of size n is constructed that can simulate each planar network of size n with slowdown O (log log n). <p> In [13], a butterfly-like network of size n 1+" is presented that is n-universal 1 with slowdown O (log log n). A similar result is obtained in <ref> [8] </ref>. In [8], a network of size n is constructed that can simulate each planar network of size n with slowdown O (log log n).
Reference: [9] <author> Richard Koch, Tom Leighton, Bruce Maggs, Satish Rao, and Arnold Rosenberg. </author> <title> Work-preserving emulations of fixed-connection networks. </title> <booktitle> In Proceedings of the 21st ACM Symposium on Theory of Computing (STOC), </booktitle> <pages> pages 227-240, </pages> <year> 1989. </year>
Reference-contexts: A model of this type was first considered by Meyer auf der Heide in [13]. For special simulations, there are several results indicating the strength of these simulations, see <ref> [9, 18, 7, 8, 1] </ref>. E. g., the p p n-mesh can be simulated on an n-processor butterfly network with constant slowdown [9], whereas an embedding has slowdown (log n), as shown in [4, 3]. <p> For special simulations, there are several results indicating the strength of these simulations, see [9, 18, 7, 8, 1]. E. g., the p p n-mesh can be simulated on an n-processor butterfly network with constant slowdown <ref> [9] </ref>, whereas an embedding has slowdown (log n), as shown in [4, 3]. A more drastic difference is known for universal networks: In [14], an n 1+" -processor universal network is presented which has constant slowdown only. <p> Lower bounds for dynamic simulations between special networks are shown in <ref> [9] </ref>: If, e. g., an m-processor butterfly network simulates an expander network of size n, it has a slowdown of ( n m log log m ). <p> For m n, our result is easily shown to be asymptotically tight (Section 2). For our lower bound presented in Section 3, the underlying simulation model is some kind of pebble game <ref> [9] </ref>, the assumably most general simulation model currently known. The proof is a counting argument inspired by the lower bounds in [13]. It improves the previous results in the following ways: 2 1.
Reference: [10] <author> Clyde P. Kruskal and Kevin J. Rappoport. </author> <title> Bandwidth-based lower bounds on slowdown for efficient emulations of fixed-connection networks. </title> <booktitle> In Proceedings of the 6th ACM Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <pages> pages 132-139, </pages> <year> 1994. </year>
Reference-contexts: For proving these properties, congestion- and diameter-based arguments are used. Rappoport shows in [17] that a multi-butterfly network of size n cannot be simulated efficiently by a butterfly network of size O (n " ), " &gt; 0. Further lower bounds are shown in <ref> [10] </ref>, where the communication bandwidth of guest and host are investigated as criteria to exceed the load-induced bound on the slowdown. All these techniques are not strong enough to prove lower bounds for universal networks.
Reference: [11] <author> F. Thomson Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction The Problem. In the past few years, the model of parallel processor networks has received much attention for solving time-critical tasks <ref> [11] </ref>. In this model of computation, the processors P 1 ; : : : ; P n are interconnected via a fixed communication graph M = (fP 1 ; : : : ; P n g; E). The edges of the graph represent communication links. <p> Because the guest has con stant degree, the d n m e-d n m e routing problem that may arise can be solved by routing O ( n m ) permutations that depend on G only, and, therefore, are known in advance. For the necessary techniques, see <ref> [11, Section 3.2.2] </ref>. The off-line routing problem can be solved in time O (log m) ([19]). Note that because of the lower bound shown in Section 3, this slowdown is asymptotically optimal. 3 Theorem 2.1 is also true if the complete network is simulated. <p> In contrast to the above construction, we now need an online routing algorithm for the d n m e-d n m e relations, because they are no longer known in advance. There are several randomized routing algorithms known, e. g., for the butterfly network (see <ref> [11] </ref>).
Reference: [12] <author> Tom Leighton. </author> <title> Tight bounds on the complexity of parallel sorting. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 34 </volume> <pages> 344-354, </pages> <year> 1985. </year>
Reference-contexts: There are several randomized routing algorithms known, e. g., for the butterfly network (see [11]). Efficient deterministic algorithms for the h-h routing problem are known, e. g., for the constant-degree network one obtains by applying Leighton's Columnsort approach <ref> [12] </ref> to the AKS sorting circuit [2] and using parallel sorting as routing mechanism. 3 Lower Bound 3.1 The Simulation Model The simulation of T steps of a guest network G 2 U 0 by T 0 steps on a host network M of size m is modeled by a pebble
Reference: [13] <editor> Friedhelm Meyer auf der Heide. </editor> <title> Efficiency of universal parallel computers. </title> <journal> Acta Infor-matica, </journal> <volume> 19 </volume> <pages> 269-296, </pages> <year> 1983. </year>
Reference-contexts: Such simulations allow that single guest processors are simulated at several host processors, and that the set of simulating processors may vary during the simulation. A model of this type was first considered by Meyer auf der Heide in <ref> [13] </ref>. For special simulations, there are several results indicating the strength of these simulations, see [9, 18, 7, 8, 1]. E. g., the p p n-mesh can be simulated on an n-processor butterfly network with constant slowdown [9], whereas an embedding has slowdown (log n), as shown in [4, 3]. <p> On the other hand, if only embeddings are allowed, universal networks with constant slowdown have exponential size (upper and lower bound), as shown in <ref> [13] </ref>. In [13], a butterfly-like network of size n 1+" is presented that is n-universal 1 with slowdown O (log log n). A similar result is obtained in [8]. <p> On the other hand, if only embeddings are allowed, universal networks with constant slowdown have exponential size (upper and lower bound), as shown in <ref> [13] </ref>. In [13], a butterfly-like network of size n 1+" is presented that is n-universal 1 with slowdown O (log log n). A similar result is obtained in [8]. <p> All these techniques are not strong enough to prove lower bounds for universal networks. E. g., no non-trivial lower bound for simulating an explicit network is known in case of an expander host (which might be a good choice for a universal network). In <ref> [13] </ref>, a lower bound on the slowdown of a universal network of size m n is shown using a somewhat weaker model of simulation (which still captures all known simulations for the case that the host is not smaller than the guest). <p> For our lower bound presented in Section 3, the underlying simulation model is some kind of pebble game [9], the assumably most general simulation model currently known. The proof is a counting argument inspired by the lower bounds in <ref> [13] </ref>. It improves the previous results in the following ways: 2 1. The simulation model (see Section 3.1) is generalized: load &gt; 1 is allowed, and steps may be simulated asynchronously. 2. It extends the lower bound to small hosts (m n). 3. <p> The factor 1= log log n is removed from the lower bound in the more general type of simulation, making the bound optimal for m n. The result can be interpreted in the following ways: Improving the lower bound trade-off of <ref> [13] </ref>, we get for m n, m s = (n log n). Thus, the size of a universal network with slowdown O (1) is m = (n log n). <p> We have to determine the minimum k with D (k) = jU 0 j. Counting jU 0 j is simple. It has already been done in <ref> [13] </ref>. Bounding the number D (k) is a difficult task and will be done in the rest of this section. Our approach to computing D (k) is as follows: Consider a computation of length T on some network G 2 U 0 , and its k-inefficient simulation on M . <p> Combining Lemma 3.3 and the Main Lemma, part (3), we get: X i=1 jD i j 2 m 2 n 2 n m 2 fln c i 12 = c12 m 2 c12 2 This finishes the proof of Lemma 3.5. Proof: (of Theorem 3.1): In <ref> [13] </ref>, it is shown that there is a ffi &gt; 0 with jU [G 0 ]j n 2 n 2 ffin : In Lemma 3.5, we have upper bounded the number of graphs in U [G 0 ], for which a k inefficient simulation exists.
Reference: [14] <editor> Friedhelm Meyer auf der Heide. </editor> <title> Efficient simulations among several models of parallel computers. </title> <journal> SIAM Journal on Computing, </journal> <volume> 15 </volume> <pages> 106-119, </pages> <year> 1986. </year>
Reference-contexts: E. g., the p p n-mesh can be simulated on an n-processor butterfly network with constant slowdown [9], whereas an embedding has slowdown (log n), as shown in [4, 3]. A more drastic difference is known for universal networks: In <ref> [14] </ref>, an n 1+" -processor universal network is presented which has constant slowdown only. The same result holds when oblivious computations of the complete network of size n are simulated, instead of bounded degree networks, as also shown in [14]. <p> A more drastic difference is known for universal networks: In <ref> [14] </ref>, an n 1+" -processor universal network is presented which has constant slowdown only. The same result holds when oblivious computations of the complete network of size n are simulated, instead of bounded degree networks, as also shown in [14]. On the other hand, if only embeddings are allowed, universal networks with constant slowdown have exponential size (upper and lower bound), as shown in [13]. In [13], a butterfly-like network of size n 1+" is presented that is n-universal 1 with slowdown O (log log n). <p> It shows that slowdown s can only be achieved if m s = n log log n : In case of simulating non-oblivious computations of the complete network of size n, s = (log n) holds, independent of m <ref> [14] </ref>. With the techniques from [14], it is possible to show the following upper bound tradeoff: For each ` 1, there is a universal network of size n `, whose slowdown fulfills: s log ` = O (log n). <p> It shows that slowdown s can only be achieved if m s = n log log n : In case of simulating non-oblivious computations of the complete network of size n, s = (log n) holds, independent of m <ref> [14] </ref>. With the techniques from [14], it is possible to show the following upper bound tradeoff: For each ` 1, there is a universal network of size n `, whose slowdown fulfills: s log ` = O (log n). <p> Note that looking at too short computations is not sufficient, because the techniques from <ref> [14] </ref> easily imply that a constant-degree network of size 2 O (t) n (consisting of n constant-degree trees of depth t) suffices to simulate all length t computations of all networks from U with constant slowdown. For m n, our result is easily shown to be asymptotically tight (Section 2). <p> Also, as the matching upper bound in Section 2 is done by a static embedding, it shows that dynamic embeddings do not yield an increase in efficiency for universal networks if m n, in contrast to the fact that they do increase the efficiency, if m &gt; n (see <ref> [14] </ref>). 2 Upper Bound Before we focus on the lower bound, we show that networks that have good routing capabilities are also good small universal networks. We describe an easy, intuitive simulation. <p> For universal networks, some open questions still remain. In the case of m n, it is not known how many processors are needed for a simulation algorithm with slowdown O (1). This paper shows that m = (n log n) in this case; in <ref> [14] </ref>, it is shown that m = O (n 1+" ) for any " &gt; 0.
Reference: [15] <author> Friedhelm Meyer auf der Heide and Rolf Wanka. </author> <title> Time-optimal simulations of networks by universal parallel computers. </title> <booktitle> In Proceedings of the 6th Symposium on Theoretical Aspects of Computer Science (STACS), </booktitle> <pages> pages 120-131, </pages> <year> 1989. </year>
Reference-contexts: For restricted classes of bounded degree networks (those with polynomial spreading function, i. e., networks where the size of the t-neighborhood of each node is bounded by a polynomial in t), constant slowdown simulations even only need O (n polylog n) size universal networks <ref> [15] </ref>. Lower bounds for dynamic simulations between special networks are shown in [9]: If, e. g., an m-processor butterfly network simulates an expander network of size n, it has a slowdown of ( n m log log m ).
Reference: [16] <author> Burkhard Monien and Hal Sudborough. </author> <title> Embedding one interconnection network in another. </title> <journal> Computing, </journal> <volume> 7 </volume> <pages> 257-282, </pages> <year> 1990. </year>
Reference-contexts: Previous Work. One approach for special simulations is the concept of embeddings. The processors of the guest are statically mapped to the processors of the host. For this concept, many results are known. See <ref> [16] </ref> for an overview. With respect to universal parallel networks, Galil and Paul [6] show that each network M of size m that can sort n numbers in time sort (n; m) is n-universal with slowdown O (sort (n; m)).
Reference: [17] <author> Kevin J. Rappoport. </author> <title> On the slowdown of efficient simulations of multibutterflies on butterflies and butterfly-derived networks. </title> <booktitle> In Proceedings of the 8th ACM Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <pages> pages 176-182, </pages> <year> 1996. </year>
Reference-contexts: Further results show that meshes of size m are not able to simulate a variety of networks of size n with the load-induced slowdown of n m only. For proving these properties, congestion- and diameter-based arguments are used. Rappoport shows in <ref> [17] </ref> that a multi-butterfly network of size n cannot be simulated efficiently by a butterfly network of size O (n " ), " &gt; 0.
Reference: [18] <author> Eric J. Schwabe. </author> <title> On the computational equivalence of hypercube-derived networks. </title> <booktitle> In Proceedings of 2nd ACM Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <pages> pages 388-397, </pages> <year> 1990. </year>
Reference-contexts: A model of this type was first considered by Meyer auf der Heide in [13]. For special simulations, there are several results indicating the strength of these simulations, see <ref> [9, 18, 7, 8, 1] </ref>. E. g., the p p n-mesh can be simulated on an n-processor butterfly network with constant slowdown [9], whereas an embedding has slowdown (log n), as shown in [4, 3].
Reference: [19] <author> A. Waksman. </author> <title> A permuting network. </title> <journal> Journal of the ACM, </journal> <volume> 15 </volume> <pages> 159-163, </pages> <year> 1968. </year> <month> 17 </month>
References-found: 19

