URL: http://www.cs.washington.edu/homes/dlee/mypapers/isca98.ps
Refering-URL: http://memsys.cs.washington.edu/memsys/html/papers.html
Root-URL: 
Title: Execution Characteristics of Desktop Applications on Windows NT  
Author: Dennis C. Lee, Patrick J. Crowley, Jean-Loup Baer, Thomas E. Anderson, and Brian N. Bershad 
Abstract: This paper examines the performance of desktop applications running on the Microsoft Windows NT operating system on Intel x86 processors, and contrasts these applications to the programs in the integer SPEC95 benchmark suite. We present measurements of basic instruction set and program characteristics, and detailed simulation results of the way these programs use the memory system and processor branch architecture. We show that the desktop applications have similar characteristics to the integer SPEC95 benchmarks for many of these metrics. However, compared to the integer SPEC95 applications, desktop applications have larger instruction working sets, execute instructions in a greater number of unique functions, cross DLL boundaries frequently, and execute a greater number of indirect calls. 
Abstract-found: 1
Intro-found: 1
Reference: [Calder et al. 94] <author> Calder, B., Grunwald, D., and Zorn, B. </author> <title> Quantifying be-havioural differences between C and C++ programs. </title> <journal> Journal of Programming Languages, </journal> <volume> 2(4):313351, </volume> <month> December </month> <year> 1994. </year>
Reference-contexts: The increased number of indirect calls in desktop applications may imply that most of the desktop applications are written in an object oriented style. <ref> [Calder et al. 94] </ref> observed that on average, C++ programs tend to have more indirect calls because C++ programs tend to use dynamic dispatch (i.e., virtual function calls) to take the place of Application Branches Calls % % % % % % % acrord32 89.3 (58) 9.9 0.7 82.3 10.7 7.0 <p> For our benchmark programs, netscape, photoshp, and most of powerpnt are written in C++, while acrord32 is written in object-oriented style C. Winword is written mostly in C. However, <ref> [Calder et al. 94] </ref> also found that C++ programs tend to have smaller function sizes and longer basic block sizes. None of the desktop applications have particularly longer basic blocks and only powerpnt has significantly smaller functions.
Reference: [Chen & Leupen 97] <author> Chen, J. B. and Leupen, B. D. D. </author> <title> Improving instruction locality with just-in-time code layout. </title> <booktitle> In Proceedings of the USENIX Windows NT Workshop, </booktitle> <pages> pages 2532, </pages> <month> August </month> <year> 1997. </year>
Reference-contexts: This suggests that one may be able to optimize the memory footprint of these applications through techniques like Just-In-Time Code Layout <ref> [Chen & Leupen 97] </ref> which loads in DLLs one function at a time. However, further study is needed to validate this observation for most applications and most users. 3.3 Instruction Set and Function Call Characteristics Instruction set measurements give a high level approximation of the usage pattern of a program.
Reference: [Chen et al. 95] <author> Chen, J. B., Endo, Y., Chan, K., Mazieres, D., Dias, A., Seltzer, M., and Smith, M. </author> <title> The measured performance of personal computer operating systems. </title> <booktitle> In Proceedings of the 15th Symposium on Operating Systems Principles, </booktitle> <pages> pages 299313, </pages> <year> 1995. </year>
Reference-contexts: Moreover, most of these computers run personal productivity and entertainment applications rather than engineering or server workloads. Recently, there has been some progress in understanding applications running under the Windows NT operating system. <ref> [Chen et al. 95, Endo et al. 96] </ref> have looked at the characteristics of different operating systems running on top of the Intel x86 processors using performance counters. [Perl & Sites 96] have measured the memory performance of three Windows NT applications (a SPEC application, a compiler back-end and a database
Reference: [Driesen & Holzle 97] <author> Driesen, K. and Holzle, U. </author> <title> Limits of indirect branch prediction. </title> <type> Technical Report TRCS97-10, </type> <institution> University of California, Santa Barbara, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: For these applications, increasing the size of the branch target is insufficient: the branch prediction algorithm for the BTB needs to become more sophisticated <ref> [Driesen & Holzle 97] </ref>. 5 Summary We traced and measured several desktop applications running under Windows NT on the x86 processor, and compared these to several SPEC95 applications on the same platform.
Reference: [Eggers et al. 90] <author> Eggers, S., Keppel, D., Koldinger, E., and Levy, H. </author> <title> Techniques for efficient inline tracing on a shared-memory multiprocessor. </title> <booktitle> In Proceedings of ACM Sigmetrics Conf. on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 3747, </pages> <year> 1990. </year>
Reference-contexts: For a small application, the traced application runs about 85-100 times slower than the original. For most applications, running slower means that external events like user input, disk I/O, and screen refreshes appear to complete faster <ref> [Eggers et al. 90] </ref>. We cope with this time dilation effect in two ways. First, our scripts feed commands to the application based on the response from the application, so the effect on the rate of user input should be minimal.
Reference: [Endo et al. 96] <author> Endo, Y., Wang, Z., Chen, J. B., and Seltzer, M. I. </author> <title> Using latency to evaluate interactive system performance. </title> <booktitle> In Second USENIX Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 185199, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Moreover, most of these computers run personal productivity and entertainment applications rather than engineering or server workloads. Recently, there has been some progress in understanding applications running under the Windows NT operating system. <ref> [Chen et al. 95, Endo et al. 96] </ref> have looked at the characteristics of different operating systems running on top of the Intel x86 processors using performance counters. [Perl & Sites 96] have measured the memory performance of three Windows NT applications (a SPEC application, a compiler back-end and a database
Reference: [Intel Corporation 97] <author> Intel Corporation. VTune, </author> <title> performance tuning advisor for Intel architecture. </title> <booktitle> software, </booktitle> <year> 1997. </year> <note> version 2.4. </note>
Reference-contexts: Although Etch can instrument most NT binaries, it currently does not understand kernel drivers and occasionally fails to instrument some DLLs (These DLLs either have hand-coded assembly routines or communicate with other processes through well-known addresses). To quantify the extent of these limitations we used VTune <ref> [Intel Corporation 97] </ref>, a PC sampling tool from In-tel to determine if we were missing a significant fraction of the instructions from unetched modules.
Reference: [Larus & Ball 92] <author> Larus, J. R. and Ball, T. </author> <title> Rewriting executable files to measure program behavior. </title> <type> Technical Report 1083, </type> <institution> University of Wisconson-Madison, Madison, WI, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: The techniques used by Etch are very similar to those employed by other static instrumentation engines such as QPT <ref> [Larus & Ball 92] </ref>, EEL [Larus & Schnarr 95], and Atom [Srivastava & Eustace 94]. To ensure that we had consistent input to an application across all our metrics, we wrote a Visual Test [Rational Software Corporation 96] script for each desktop application.
Reference: [Larus & Schnarr 95] <author> Larus, J. and Schnarr, E. EEL: </author> <title> machine-independent executable editing. </title> <journal> In SIGPLAN Notices, </journal> <pages> pages 291300, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The techniques used by Etch are very similar to those employed by other static instrumentation engines such as QPT [Larus & Ball 92], EEL <ref> [Larus & Schnarr 95] </ref>, and Atom [Srivastava & Eustace 94]. To ensure that we had consistent input to an application across all our metrics, we wrote a Visual Test [Rational Software Corporation 96] script for each desktop application.
Reference: [Maynard et al. 94] <author> Maynard, A. M., Donnelly, C., and Olszewski, B. </author> <title> Contrasting characteristics and cache performance of technical and multi-user commercial workloads. </title> <booktitle> In Proceedings of the 6th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 145155, </pages> <year> 1994. </year>
Reference-contexts: It is clear that SPEC92 is already obsolete. Newer benchmark suites such as SPEC95 [SPEC 95] and Instruction Benchmark Suite [Uhlig et al. 95] for scientific and engineering applications, server and commercial applications <ref> [Maynard et al. 94] </ref>, and parallel applications [Woo et al. 95] have emerged to provide a rich set of insights about application performance characteristics from a UNIX-based batch application environment.
Reference: [McFarling 93] <author> McFarling, S. </author> <title> Combining branch predictors. </title> <type> Technical Report TN 36, </type> <institution> DEC-WRL, </institution> <year> 1993. </year>
Reference-contexts: The first predictor is a simple bimodal predictor that uses a two-bit saturating counter per branch. The second one is a gshare predictor that uses a global shared history of taken/not-taken decisions (patterns) xor'ed with the PC to obtain the index into a table of two-bit saturating counters <ref> [Yeh & Patt 92, McFarling 93] </ref>. Essentially, the gshare predictor is able to distinguish different paths through the execution stream of the program and make predictions based on the path rather than just relying on the branch PC.
Reference: [Patterson & Hennessy 96] <author> Patterson, D. A. and Hennessy, J. L. </author> <title> Computer Architecture, A Quantitative Approach. </title> <publisher> Morgan Kauf-mann Publishers, Inc., </publisher> <address> San Francisco, CA, </address> <note> second edition, </note> <year> 1996. </year>
Reference-contexts: These usage patterns paint a broad picture of the architecture characteristics of a program and point out areas where effort needs to be concentrated <ref> [Patterson & Hennessy 96] </ref>. <p> Line size is 32-bytes. Write policy is write-allocate/write-back. For the data and combined caches, we show the miss rates for data loads. We simulated the effects of stores on the cache state but do not report misses due to stores because, in general, processors do not block on stores <ref> [Patterson & Hennessy 96] </ref>.
Reference: [Perl & Sites 96] <author> Perl, S. and Sites, R. </author> <title> Studies of Windows NT performance using dynamic execution traces. </title> <booktitle> In Second USENIX Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 169183, </pages> <year> 1996. </year>
Reference-contexts: Recently, there has been some progress in understanding applications running under the Windows NT operating system. [Chen et al. 95, Endo et al. 96] have looked at the characteristics of different operating systems running on top of the Intel x86 processors using performance counters. <ref> [Perl & Sites 96] </ref> have measured the memory performance of three Windows NT applications (a SPEC application, a compiler back-end and a database application) running on the DEC Alpha platform.
Reference: [Pettis & Hansen 90] <author> Pettis, K. and Hansen, R. C. </author> <title> Profile guided code positioning. </title> <booktitle> In Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation (SIGPLAN '90), </booktitle> <pages> pages 1627, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: DLL calls are more expensive than calling statically linked functions: i) Unlike regular function calls, DLL calls are implemented as indirect function calls; ii) DLLs are shared between applications, so improving instruction locality through traditional reordering algorithms <ref> [Pettis & Hansen 90] </ref> is more difficult; and iii) the caller and callee must live in different pages in the address space (as DLLs are aligned on page boundaries).
Reference: [Rational Software Corporation 96] <institution> Rational Software Corporation. Rational Visual Test. software, </institution> <year> 1996. </year> <note> version 4.0r, http://www.rational.com. </note>
Reference-contexts: To ensure that we had consistent input to an application across all our metrics, we wrote a Visual Test <ref> [Rational Software Corporation 96] </ref> script for each desktop application. We then gathered traces on a single machine in order to eliminate the effects due to the differences between the states of different machines (e.g., the locations and versions of shared libraries).
Reference: [Romer et al. 97] <author> Romer, T., Voelker, G., Lee, D., Wolman, A., Wong, W., Levy, H., and Bershad, B. </author> <title> Instrumentation and optimization of Win32/Intel executables using Etch. </title> <booktitle> In Proceedings of the USENIX Windows NT Workshop, </booktitle> <pages> pages 18, </pages> <month> August </month> <year> 1997. </year>
Reference-contexts: Second, using these traces, it compares these desktop applications to the SPEC95 applications from the perspective of the processor architecture and memory system. Our traces were generated using Etch, a binary instrumentation engine developed for Windows NT on the x86 platform <ref> [Romer et al. 97] </ref>. There are some obvious qualitative differences between desktop applications and traditional benchmarks that intuitively suggest differences in hardware utilization and program behavior: * Desktop applications are interactive. <p> Section 3 describes the applications in our benchmark suite and considers their high level application characteristics. Section 4 presents measurements of these applications with traditional architecture metrics for cache and branch prediction behavior. Finally, Section 5 summarizes our findings. 2 Methodology 2.1 Etch We use Etch <ref> [Romer et al. 97] </ref>, a binary instrumentation engine for the x86-Windows NT platform, to gather user level traces. Etch allows a user-provided instrumentation module to insert arbitrary code at well-defined points in the binaries.
Reference: [SPEC 95] <institution> SPEC newsletter, </institution> <month> September </month> <year> 1995. </year> <note> Information about the SPEC95 benchmarks used in this study is available at http://www.spec.org/osg/cpu95/CINT95. </note>
Reference-contexts: 1 Introduction Progress in microarchitecture, memory hierarchy, and instruction-level parallelism quickly outpaces the benchmarks that are designed to assess the performance of modern computer systems. It is clear that SPEC92 is already obsolete. Newer benchmark suites such as SPEC95 <ref> [SPEC 95] </ref> and Instruction Benchmark Suite [Uhlig et al. 95] for scientific and engineering applications, server and commercial applications [Maynard et al. 94], and parallel applications [Woo et al. 95] have emerged to provide a rich set of insights about application performance characteristics from a UNIX-based batch application environment.
Reference: [Srivastava & Eustace 94] <author> Srivastava, A. and Eustace, A. </author> <title> ATOM: a system for building customized program analysis tools. </title> <booktitle> In Proceedings of the 1994 ACM Symposium on Programming Language Design and Implementation, </booktitle> <pages> pages 196 205, </pages> <year> 1994. </year>
Reference-contexts: The techniques used by Etch are very similar to those employed by other static instrumentation engines such as QPT [Larus & Ball 92], EEL [Larus & Schnarr 95], and Atom <ref> [Srivastava & Eustace 94] </ref>. To ensure that we had consistent input to an application across all our metrics, we wrote a Visual Test [Rational Software Corporation 96] script for each desktop application. <p> Running VTune on our benchmarks also show that we miss less than 1% of executed user-level instructions. Using software instrumentation to gather traces also presents a series of issues. First, software instrumentation tools insert code into the binary and thus change the addresses seen by the CPU <ref> [Srivastava & Eustace 94] </ref> (for our tracing tool, Etch expands the size of the code by a factor of 32). Etch compensates for this by sending the instruction addresses that came from the original unetched program to the tracer rather than the address of the etched binary.
Reference: [Uhlig et al. 95] <author> Uhlig, R., Nagle, D., Mudge, T., Sechrest, S., and Emer, J. </author> <title> Instruction fetching: Coping with code bloat. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 345356. </pages> <publisher> ACM Press, </publisher> <month> June 2224 </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Progress in microarchitecture, memory hierarchy, and instruction-level parallelism quickly outpaces the benchmarks that are designed to assess the performance of modern computer systems. It is clear that SPEC92 is already obsolete. Newer benchmark suites such as SPEC95 [SPEC 95] and Instruction Benchmark Suite <ref> [Uhlig et al. 95] </ref> for scientific and engineering applications, server and commercial applications [Maynard et al. 94], and parallel applications [Woo et al. 95] have emerged to provide a rich set of insights about application performance characteristics from a UNIX-based batch application environment.
Reference: [Ungar et al. 84] <author> Ungar, D., Blau, R., Foley, P., Samples, D., and Pat-terson, D. </author> <title> Architecture of SOAR: Smalltalk on a risc. </title> <booktitle> In Proceedings of the 11th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 188197, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: For netscape and powerpnt, small BTB's cannot predict the indirect branches because there are not enough entries to hold the branches. This suggests an opportunity to use software techniques such as caching the target addresses of indirect branches in the instruction stream to improve their performance <ref> [Ungar et al. 84] </ref>. As BTB's get larger, the simple BTB prediction algorithm (predict the last target of the indirect branch or call) becomes the barrier to better BTB performance.
Reference: [Woo et al. 95] <author> Woo, S. C., Ohara, M., Torrie, E., Singh, J. P., and Gupta, A. </author> <title> The SPLASH-2 programs: Characterization and methodological considerations. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 2436, </pages> <year> 1995. </year>
Reference-contexts: It is clear that SPEC92 is already obsolete. Newer benchmark suites such as SPEC95 [SPEC 95] and Instruction Benchmark Suite [Uhlig et al. 95] for scientific and engineering applications, server and commercial applications [Maynard et al. 94], and parallel applications <ref> [Woo et al. 95] </ref> have emerged to provide a rich set of insights about application performance characteristics from a UNIX-based batch application environment. However, The authors can be reached through the Department of Computer Science and Engineering, Box 352350, University of Washington, Seattle, WA 98195-2350, or through email at fdlee,pcrowley,baer,tom,bershadg@cs.washington.edu.
Reference: [Yeh & Patt 92] <author> Yeh, T.-H. and Patt, Y. </author> <title> Alternative implementations of two-level adaptive branch prediction. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 124134, </pages> <year> 1992. </year>
Reference-contexts: The first predictor is a simple bimodal predictor that uses a two-bit saturating counter per branch. The second one is a gshare predictor that uses a global shared history of taken/not-taken decisions (patterns) xor'ed with the PC to obtain the index into a table of two-bit saturating counters <ref> [Yeh & Patt 92, McFarling 93] </ref>. Essentially, the gshare predictor is able to distinguish different paths through the execution stream of the program and make predictions based on the path rather than just relying on the branch PC.
Reference: [Young et al. 95] <author> Young, C., Gloy, N., and Smith, M. D. </author> <title> A comparative analysis of schemes for correlated branch prediction. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 276286, </pages> <month> June 2224 </month> <year> 1995. </year> <month> 12 </month>
Reference-contexts: The gshare predictor is able to exploit bigger tables as it distributes different paths to different entries in the table. At smaller sizes, however, the aliasing of multiple paths into common entries increases the misprediction rate of these predictors <ref> [Young et al. 95] </ref>. As expected, the gshare predictor works better as the tables get bigger. For example, at 512 entries, winword has a misprediction rate of 20% for the gshare predictor and only 15% for the bimodal predictor.
References-found: 23

