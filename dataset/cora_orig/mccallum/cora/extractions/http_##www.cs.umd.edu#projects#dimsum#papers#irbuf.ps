URL: http://www.cs.umd.edu/projects/dimsum/papers/irbuf.ps
Refering-URL: http://www.cs.umd.edu/projects/dimsum/siumei/references.html
Root-URL: 
Email: bthj@cs.umd.edu  franklin@cs.umd.edu  divesh@research.att.com  
Title: Interaction of Query Evaluation and Buffer Management for Information Retrieval  
Author: Bj orn T. J onsson Michael J. Franklin Divesh Srivastava Bjorn T. Jonsson and Michael J. Franklin 
Note: The work of  was partially supported by the NSF under grant IRI-94-09575, by the Office of Naval Research under contract number N66001-97-C8539 (DARPA order number F475), by Bellcore, and by an IBM Shared University Research award.  
Address: Labs-Research  
Affiliation: University of Maryland  University of Maryland  AT&T  
Abstract: The proliferation of the World Wide Web has brought information retrieval (IR) techniques to the forefront of search technology. To the average computer user, "searching" now means using IR-based systems for finding information on the WWW or in other document collections. IR query evaluation methods and workloads differ significantly from those found in database systems. In this paper, we focus on three such differences. First, due to the inherent fuzziness of the natural language used in IR queries and documents, an additional degree of flexibility is permitted in evaluating queries. Second, IR query evaluation algorithms tend to have access patterns that cause problems for traditional buffer replacement policies. Third, IR search is often an iterative process, in which a query is repeatedly refined and resubmitted by the user. Based on these differences, we develop two complementary techniques to improve the efficiency of IR queries: 1) Buffer-aware query evaluation, which alters the query evaluation process based on the current contents of buffers; and 2) Ranking-aware buffer replacement, which incorporates knowledge of the query processing strategy into replacement decisions. In a detailed performance study we show that using either of these techniques yields significant performance benefits and that in many cases, combining them produces even further improvements. 
Abstract-found: 1
Intro-found: 1
Reference: [ABGM90] <author> R. Alonso, D. Barbara, and H. Garcia-Molina. </author> <title> Data caching issues in an information retrieval system. </title> <journal> ACM TODS, </journal> <volume> 15(3), </volume> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: Client data caching for generic information retrieval systems (where information is not restricted to documents) is studied in <ref> [SA87, ABGM90] </ref>. Physical index design, inverted index caching, and database scaling for shared-nothing distributed IR systems are studied in [TGM93a, TGM93b]. None of these studies address buffer replace ment. For database systems, however, there are many studies of buffer replacement policies.
Reference: [Bro95] <author> E.W. Brown. </author> <title> Fast evaluation of structured queries for information retrieval. </title> <booktitle> Proc. ACM SIGIR Conf., </booktitle> <address> Seattle, WA, </address> <year> 1995. </year>
Reference-contexts: Of course, efficiency is also a concern for IR systems, and there has been significant research on indexing techniques and query evaluation heuristics that improve the query response time while maintaining a constant level of effectiveness (e.g., see <ref> [Fal85, ZMSD92, WL93, Per94, Bro95, TF95] </ref>). This research, however, has not investigated the system mechanisms that underlie the indexing and querying approaches. Database systems developers have long realized that efficient access to data requires smart algorithms for disk allocation and disk scheduling, buffer management, and process scheduling. <p> For simplicity we have left such operators out of this work; adding support for them is one avenue for future work. and 100 terms per query (e.g., see <ref> [Bro95, Per94, VH97] </ref>). The rationale is that even when users provide fewer terms, the retrieval system will use techniques such as relevance feedback [SB90] or query augmentation with synonyms to improve retrieval effectiveness, resulting in larger queries. <p> The inverted index has one inverted list for each term t, where all (d; f d;t ) entries (required for calculating the ranking) are stored. Inverted lists are traditionally ordered by document identifiers, as many query evaluation algorithms use those identifiers (e.g., see <ref> [ZMSD92, MZ94, Bro95] </ref>). An alternative organization, used in this paper, is a frequency ordering of the inverted lists [WL93, Per94], where those documents in which the terms occur most frequently are stored first in the lists. <p> If it is too large to fit in memory, intermediate results must be written to disk, incurring additional I/O operations. If no precautions are taken, the candidate set frequently includes more than half of the documents in the collection <ref> [Bro95] </ref>. There are many unsafe optimizations reported in the IR literature (see [TF95] for a survey). Some achieve significant improvement in response time for individual queries, while maintaining acceptable retrieval effectiveness. <p> able to improve the performance significantly, as it overcomes this problem with LRU by first reading what is available in buffers, and then reading in what is missing. 14 Since algorithms that use inverted lists ordered by document identifiers can be expected to read most of the inverted list pages <ref> [Bro95] </ref>, those algorithms would perform significantly worse than DF here. ADD-ONLY-QUERY1 sequence, varying buffer size. ADD-ONLY-QUERY2 sequence, varying buffer size. Both the MRU and RAP policies also improve the performance substantially; for the ADD-ONLY case there is no clear winner among the two policies.
Reference: [Bro97] <author> K.P. Brown. </author> <title> DBGuide industrial presentation. </title> <booktitle> ACM SIGMOD Conf., </booktitle> <address> Tucson, AZ, </address> <year> 1997. </year>
Reference-contexts: Projects that may benefit from buffer-replacement strategies that are tuned to the semantics of the data and queries, include the SQL extensions to restrict answers to highest/lowest values for an attribute presented in [CK97], and the interface for fuzzy answers to queries of <ref> [Bro97] </ref>. Finally, a project that is looking into the architectural foundations of Web-search engines is the Ink-tomi project [Ink].
Reference: [CD85] <author> H.-T. Chou and D.J. DeWitt. </author> <title> An evaluation of buffer management strategies for relational database systems. </title> <booktitle> Proc. of the VLDB Conf., </booktitle> <address> Stock-holm, Sweden, </address> <year> 1985. </year>
Reference-contexts: This is evidenced by a long list of studies of buffer management techniques for database systems (e.g., see <ref> [EH84, CD85, NFS91, CR93, OOW93, JS94, DFJ + 96] </ref>). The IR community, on the other hand, has largely ignored buffer management issues so far. We have observed that query evaluation algorithms for IR have access patterns that cause problems for traditional buffer replacement policies. <p> As with the BAF algorithm, implementing the RAP replacement policy requires some modifications to the 7 One well known solution to the problem of repeated sequential reads is to assign segments of buffer space to different queries, and use MRU (Most-Recently-Used) within each segment <ref> [CD85] </ref>. As will be shown in our experiments, however, MRU faces some additional problems in query refinement workloads. Also, the newer LRU/k [OOW93] and 2Q [JS94] policies will fare no better than LRU in this case. <p> None of these studies address buffer replace ment. For database systems, however, there are many studies of buffer replacement policies. Some have focused on matching the access patterns of queries (e.g., see <ref> [CD85, NFS91, CR93] </ref>), while others contend that using access patterns is hard, due to the complexity of SQL, and propose more generic policies (e.g., see [OOW93, JS94]).
Reference: [CK97] <author> M.J. Carey and D. Kossmann. </author> <title> On saying "enough already!" in SQL. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Tucson, AZ, </address> <year> 1997. </year>
Reference-contexts: Projects that may benefit from buffer-replacement strategies that are tuned to the semantics of the data and queries, include the SQL extensions to restrict answers to highest/lowest values for an attribute presented in <ref> [CK97] </ref>, and the interface for fuzzy answers to queries of [Bro97]. Finally, a project that is looking into the architectural foundations of Web-search engines is the Ink-tomi project [Ink].
Reference: [CR93] <author> C.M. Chen and N. Roussopoulos. </author> <title> Adaptive database buffer allocation using query feedback. </title> <booktitle> Proc. of the VLDB Conf., </booktitle> <address> Dublin, Ireland, </address> <year> 1993. </year>
Reference-contexts: This is evidenced by a long list of studies of buffer management techniques for database systems (e.g., see <ref> [EH84, CD85, NFS91, CR93, OOW93, JS94, DFJ + 96] </ref>). The IR community, on the other hand, has largely ignored buffer management issues so far. We have observed that query evaluation algorithms for IR have access patterns that cause problems for traditional buffer replacement policies. <p> None of these studies address buffer replace ment. For database systems, however, there are many studies of buffer replacement policies. Some have focused on matching the access patterns of queries (e.g., see <ref> [CD85, NFS91, CR93] </ref>), while others contend that using access patterns is hard, due to the complexity of SQL, and propose more generic policies (e.g., see [OOW93, JS94]).
Reference: [DFJ + 96] <author> S. Dar, M. Franklin, B.T. Jonsson, D. Sri-vastava, and M. Tan. </author> <title> Semantic data caching and replacement. </title> <booktitle> Proc. of the VLDB Conf., </booktitle> <address> Bombay, India, </address> <year> 1996. </year>
Reference-contexts: This is evidenced by a long list of studies of buffer management techniques for database systems (e.g., see <ref> [EH84, CD85, NFS91, CR93, OOW93, JS94, DFJ + 96] </ref>). The IR community, on the other hand, has largely ignored buffer management issues so far. We have observed that query evaluation algorithms for IR have access patterns that cause problems for traditional buffer replacement policies. <p> We present a query evaluation algorithm that dynamically changes the query evaluation strategy based on buffer contents. The second technique, based on ideas from Semantic Caching <ref> [DFJ + 96] </ref>, is a cache replacement policy that makes use of the access patterns of the retrieval algorithm as well as the data on the data pages when making replacement decisions. 1 In this paper, we use performance to refer to retrieval efficiency. <p> Document Filtering is presented in Section 3.1, and our extension is discussed in Section 3.2. Ranking-aware buffer replacement is based on the idea of "semantic value functions" from <ref> [DFJ + 96] </ref>. We propose a replacement policy that bases the replacement value of data pages on the actual data on the pages, as well as on the previously posed query. <p> As will be shown in our experiments, LRU also renders the buffers useless when they cannot hold the inverted list data used by a query refinement workload. 7 The BAF algorithm goes a long way towards solving this problem, but having a better replacement policy is clearly desirable. In <ref> [DFJ + 96] </ref> we proposed using knowledge of query patterns and the data semantics to determine the replacement value of data in a client cache. Two quick examples demonstrate how that idea is applied to the document retrieval domain: 1. <p> the multi-user case, users may benefit from pages cached in buffers for other users as well. 4 Experimental Environment 4.1 The Document Retrieval Environment In order to study the relative performance improvements of the proposed techniques, we implemented the DF and BAF algorithms on top of the simulator used in <ref> [FJK96, DFJ + 96] </ref>. The buffer manager of the simulator was modified to use any of the LRU, MRU, or RAP policies. The main parameters used in the experiments are listed in Table 3, and described in the following. <p> In document retrieval systems, such as the one studied here, the access patterns are simple and uniform, while presenting serious problems for the policies of [OOW93, JS94]. The concept of using a replacement value function based on the data and the query pattern is presented in <ref> [DFJ + 96] </ref>, where it is applied to a relational database in a client caching context. While our techniques are also applicable to client caching, we have focused on server buffering.
Reference: [EH84] <author> W. Effelsberg and T. Haerder. </author> <title> Principles of database buffer management. </title> <journal> ACM TODS, </journal> <volume> 9(4), </volume> <month> Dec. </month> <year> 1984. </year>
Reference-contexts: This is evidenced by a long list of studies of buffer management techniques for database systems (e.g., see <ref> [EH84, CD85, NFS91, CR93, OOW93, JS94, DFJ + 96] </ref>). The IR community, on the other hand, has largely ignored buffer management issues so far. We have observed that query evaluation algorithms for IR have access patterns that cause problems for traditional buffer replacement policies.
Reference: [Fal85] <author> C. Faloutsos. </author> <title> Access methods for text. </title> <journal> ACM Computing Surveys, </journal> <volume> 17(1), </volume> <year> 1985. </year>
Reference-contexts: Of course, efficiency is also a concern for IR systems, and there has been significant research on indexing techniques and query evaluation heuristics that improve the query response time while maintaining a constant level of effectiveness (e.g., see <ref> [Fal85, ZMSD92, WL93, Per94, Bro95, TF95] </ref>). This research, however, has not investigated the system mechanisms that underlie the indexing and querying approaches. Database systems developers have long realized that efficient access to data requires smart algorithms for disk allocation and disk scheduling, buffer management, and process scheduling. <p> Most retrieval algorithms therefore rely on some index structure for efficiency; the index is typically compressed for disk savings [PZSD96]. The most commonly used index structure is the inverted index (see <ref> [Fal85] </ref> for a survey of access methods for text). The inverted index has one inverted list for each term t, where all (d; f d;t ) entries (required for calculating the ranking) are stored.
Reference: [Fid91] <author> R. </author> <title> Fidel. Searchers' selection of search keys: III. Searching styles. </title> <journal> Journal of the American Society of Information Science, </journal> <volume> 42(7), </volume> <year> 1991. </year>
Reference-contexts: Buffering becomes increasingly important in the presence of a common IR search behavior known as query refinement. Query refinement refers to a multiple-query search process where a user repeatedly modifies a query, by adding or removing terms, and resubmits it to the document retrieval system <ref> [Fid91, KQCB94] </ref>. The combination of bad replacement behavior and query refinement can obviously lead to serious performance 1 problems. Also, as stated above, the information retrieval context adds a new and interesting dimension to buffering. <p> While our workloads are based on such queries, we are most interested in query refinement, which is an important search behavior in IR systems <ref> [Fid91, KQCB94] </ref>. When a ranked list of documents does not match what the user had in mind, the user refines the query by adding or removing terms, and resubmits it. This may occur repeatedly, until the user is satisfied with the returned results. <p> the good savings is that the query has a large number of terms with medium or long inverted lists; for those inverted lists great savings are realized due to the low idf t . 5.1.2 Query Refinement Workloads Recall that query refinement is an important search behavior in IR systems <ref> [Fid91, KQCB94] </ref>, where a user repeatedly refines the query by adding or removing (dropping) terms, and then resubmits it. We use two types of query refinement workloads, consisting of refinement sequences constructed from single TREC queries. Each sequence in turn consists of a number of queries, called refinements.
Reference: [FJK96] <author> M.J. Franklin, B.T. Jonsson, and D. Koss-mann. </author> <title> Performance tradeoffs for client-server query processing. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Montreal, Canada, </address> <year> 1996. </year>
Reference-contexts: the multi-user case, users may benefit from pages cached in buffers for other users as well. 4 Experimental Environment 4.1 The Document Retrieval Environment In order to study the relative performance improvements of the proposed techniques, we implemented the DF and BAF algorithms on top of the simulator used in <ref> [FJK96, DFJ + 96] </ref>. The buffer manager of the simulator was modified to use any of the LRU, MRU, or RAP policies. The main parameters used in the experiments are listed in Table 3, and described in the following.
Reference: [Fox92] <author> C. Fox. </author> <title> Lexical analysis and stoplists. </title> <editor> In W.B. Frakes and R. Baeza-Yates, editors, </editor> <booktitle> Information Retrieval, Data Structures and Algorithms. </booktitle> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992. </year>
Reference-contexts: The WSJ collection contains articles that appeared in the Wall Street Journal during the years 1987-1992. The total size of the collection is roughly 530 MB in 173,252 documents. Two common techniques for improving performance are stop-word removal <ref> [Fox92] </ref> and word stemming [Fra92].
Reference: [Fra92] <author> W.B. Frakes. </author> <title> Stemming algorithms. </title> <editor> In W.B. Frakes and R. Baeza-Yates, editors, </editor> <booktitle> Information Retrieval, Data Structures and Algorithms. </booktitle> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992. </year>
Reference-contexts: The WSJ collection contains articles that appeared in the Wall Street Journal during the years 1987-1992. The total size of the collection is roughly 530 MB in 173,252 documents. Two common techniques for improving performance are stop-word removal [Fox92] and word stemming <ref> [Fra92] </ref>. <p> The inverted index was created as follows: First, all non-words (punctuation, numbers, etc.) and stop-words were removed from the documents. All remaining terms were transformed to lower case and stemmed using a Porter stemmer (described in <ref> [Fra92] </ref>). The occurrences of each term in each document were summed up to form (d; f d;t ) entries, which were grouped into inverted lists. Finally the inverted lists were sorted, using f d;t as the primary key, and d as the secondary key.
Reference: [Har96] <author> D. </author> <title> Harman. </title> <booktitle> Overview of the fourth Text REtrieval Conference (TREC-4). The fourth Text REtrieval Conference (TREC-4), </booktitle> <publisher> NIST, </publisher> <address> Gaithersburg, MD, </address> <year> 1996. </year>
Reference-contexts: As stated in the introduction, however, the problems addressed by the IR and database communities have differed substantially. A brief description of the TREC conference series <ref> [Har96, VH97] </ref>, which serves as the major bench-marking activity for IR systems, illustrates this difference. The TREC conference uses a standard document collection, which is made up of three parts: Documents There are currently roughly 4 GB of doc uments in a number of sub-collections. <p> This is one of the metrics used in the TREC conferences <ref> [Har96] </ref>. 11 We chose the 100 most common words (with highest f t ) as stop-words, as we felt that after 100 terms most of the terms had some value for distinguishing between documents.
Reference: [HHW97] <author> J.M. Hellerstein, P.J. Haas, and H.J. Wang. </author> <title> Online aggregation. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Tucson, AZ, </address> <year> 1997. </year>
Reference-contexts: This limits the extent to which they can modify the query evaluation plan. There are a number of current database research projects which can benefit from techniques similar to those presented here. Buffer-aware evaluation is applicable in projects such as on-line aggregate computation <ref> [HHW97] </ref>, where the emphasis is on producing approximate answers very quickly.
Reference: [Ink] <author> Inktomi. </author> <note> The Inktomi Technology Behind Hotbot. http://www.inktomi.com/Tech/CoupClustWhitePap.html. </note>
Reference-contexts: Finally, a project that is looking into the architectural foundations of Web-search engines is the Ink-tomi project <ref> [Ink] </ref>.
Reference: [JS94] <author> T. Johnson and D. Shasha. </author> <title> 2Q: A low overhead high performance buffer management replacement algorithm. </title> <booktitle> Proc. of the VLDB Conf., </booktitle> <address> Santiago, Chile, </address> <year> 1994. </year>
Reference-contexts: This is evidenced by a long list of studies of buffer management techniques for database systems (e.g., see <ref> [EH84, CD85, NFS91, CR93, OOW93, JS94, DFJ + 96] </ref>). The IR community, on the other hand, has largely ignored buffer management issues so far. We have observed that query evaluation algorithms for IR have access patterns that cause problems for traditional buffer replacement policies. <p> As will be shown in our experiments, however, MRU faces some additional problems in query refinement workloads. Also, the newer LRU/k [OOW93] and 2Q <ref> [JS94] </ref> policies will fare no better than LRU in this case. Parameter Description PageSize Number of (d; f d;t ) entries in a page BufferSize Size of server buffers (pages) c add Tuning constant for f add c ins Tuning constant for f ins Table 3: Experimental parameters. buffer manager. <p> For database systems, however, there are many studies of buffer replacement policies. Some have focused on matching the access patterns of queries (e.g., see [CD85, NFS91, CR93]), while others contend that using access patterns is hard, due to the complexity of SQL, and propose more generic policies (e.g., see <ref> [OOW93, JS94] </ref>). In document retrieval systems, such as the one studied here, the access patterns are simple and uniform, while presenting serious problems for the policies of [OOW93, JS94]. <p> CR93]), while others contend that using access patterns is hard, due to the complexity of SQL, and propose more generic policies (e.g., see <ref> [OOW93, JS94] </ref>). In document retrieval systems, such as the one studied here, the access patterns are simple and uniform, while presenting serious problems for the policies of [OOW93, JS94]. The concept of using a replacement value function based on the data and the query pattern is presented in [DFJ + 96], where it is applied to a relational database in a client caching context.
Reference: [KK94] <author> A. Kemper and D. Kossmann. </author> <title> Dual-buffering strategies in object bases. </title> <booktitle> Proc. of the VLDB Conf., </booktitle> <address> Santiago, Chile, </address> <year> 1994. </year>
Reference-contexts: As queries typically access very few of these terms, however, the likelihood that two of them would be in the same page is very small. In workloads where such terms are frequently accessed, techniques such as dual buffering <ref> [KK94] </ref> would be appropriate. tuning parameters of the filtering algorithms, c add and c ins , were set as in [Per94] (c add = 0:002; c ins = 0:07).
Reference: [KQCB94] <author> J. Koenemann, R. Quatrain, C. Cool, and N.J. Belkin. </author> <title> New tools and old habits: The interactive searching behavior of expert online searchers using INQUERY. </title> <booktitle> The Third Text REtrieval Conference (TREC-3), </booktitle> <publisher> NIST, </publisher> <address> Gaithersburg, MD, </address> <year> 1994. </year>
Reference-contexts: Buffering becomes increasingly important in the presence of a common IR search behavior known as query refinement. Query refinement refers to a multiple-query search process where a user repeatedly modifies a query, by adding or removing terms, and resubmits it to the document retrieval system <ref> [Fid91, KQCB94] </ref>. The combination of bad replacement behavior and query refinement can obviously lead to serious performance 1 problems. Also, as stated above, the information retrieval context adds a new and interesting dimension to buffering. <p> While our workloads are based on such queries, we are most interested in query refinement, which is an important search behavior in IR systems <ref> [Fid91, KQCB94] </ref>. When a ranked list of documents does not match what the user had in mind, the user refines the query by adding or removing terms, and resubmits it. This may occur repeatedly, until the user is satisfied with the returned results. <p> the good savings is that the query has a large number of terms with medium or long inverted lists; for those inverted lists great savings are realized due to the low idf t . 5.1.2 Query Refinement Workloads Recall that query refinement is an important search behavior in IR systems <ref> [Fid91, KQCB94] </ref>, where a user repeatedly refines the query by adding or removing (dropping) terms, and then resubmits it. We use two types of query refinement workloads, consisting of refinement sequences constructed from single TREC queries. Each sequence in turn consists of a number of queries, called refinements.
Reference: [MZ94] <author> A. Moffat and J. Zobel. </author> <title> Fast ranking in limited space. </title> <booktitle> Proc. IEEE Conf. on Data Engineering, </booktitle> <address> Houston, TX 1994. </address>
Reference-contexts: The inverted index has one inverted list for each term t, where all (d; f d;t ) entries (required for calculating the ranking) are stored. Inverted lists are traditionally ordered by document identifiers, as many query evaluation algorithms use those identifiers (e.g., see <ref> [ZMSD92, MZ94, Bro95] </ref>). An alternative organization, used in this paper, is a frequency ordering of the inverted lists [WL93, Per94], where those documents in which the terms occur most frequently are stored first in the lists.
Reference: [NFS91] <author> R. Ng, C. Faloutsos, and T. Sellis. </author> <title> Flexible buffer allocation based on marginal gains. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Denver, CO, </address> <year> 1991. </year>
Reference-contexts: This is evidenced by a long list of studies of buffer management techniques for database systems (e.g., see <ref> [EH84, CD85, NFS91, CR93, OOW93, JS94, DFJ + 96] </ref>). The IR community, on the other hand, has largely ignored buffer management issues so far. We have observed that query evaluation algorithms for IR have access patterns that cause problems for traditional buffer replacement policies. <p> None of these studies address buffer replace ment. For database systems, however, there are many studies of buffer replacement policies. Some have focused on matching the access patterns of queries (e.g., see <ref> [CD85, NFS91, CR93] </ref>), while others contend that using access patterns is hard, due to the complexity of SQL, and propose more generic policies (e.g., see [OOW93, JS94]).
Reference: [OOW93] <author> E.J. O'Neil, P.E. O'Neil, and G. Weikum. </author> <title> The LRU-K page replacement algorithm for database disk buffering. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Washington, DC, </address> <year> 1993. </year>
Reference-contexts: This is evidenced by a long list of studies of buffer management techniques for database systems (e.g., see <ref> [EH84, CD85, NFS91, CR93, OOW93, JS94, DFJ + 96] </ref>). The IR community, on the other hand, has largely ignored buffer management issues so far. We have observed that query evaluation algorithms for IR have access patterns that cause problems for traditional buffer replacement policies. <p> As will be shown in our experiments, however, MRU faces some additional problems in query refinement workloads. Also, the newer LRU/k <ref> [OOW93] </ref> and 2Q [JS94] policies will fare no better than LRU in this case. <p> For database systems, however, there are many studies of buffer replacement policies. Some have focused on matching the access patterns of queries (e.g., see [CD85, NFS91, CR93]), while others contend that using access patterns is hard, due to the complexity of SQL, and propose more generic policies (e.g., see <ref> [OOW93, JS94] </ref>). In document retrieval systems, such as the one studied here, the access patterns are simple and uniform, while presenting serious problems for the policies of [OOW93, JS94]. <p> CR93]), while others contend that using access patterns is hard, due to the complexity of SQL, and propose more generic policies (e.g., see <ref> [OOW93, JS94] </ref>). In document retrieval systems, such as the one studied here, the access patterns are simple and uniform, while presenting serious problems for the policies of [OOW93, JS94]. The concept of using a replacement value function based on the data and the query pattern is presented in [DFJ + 96], where it is applied to a relational database in a client caching context.
Reference: [Per94] <author> M. Persin. </author> <title> Document filtering for fast ranking. </title> <booktitle> Proc. ACM SIGIR Conf., </booktitle> <address> Dublin, Ireland, </address> <year> 1994. </year>
Reference-contexts: Of course, efficiency is also a concern for IR systems, and there has been significant research on indexing techniques and query evaluation heuristics that improve the query response time while maintaining a constant level of effectiveness (e.g., see <ref> [Fal85, ZMSD92, WL93, Per94, Bro95, TF95] </ref>). This research, however, has not investigated the system mechanisms that underlie the indexing and querying approaches. Database systems developers have long realized that efficient access to data requires smart algorithms for disk allocation and disk scheduling, buffer management, and process scheduling. <p> For simplicity we have left such operators out of this work; adding support for them is one avenue for future work. and 100 terms per query (e.g., see <ref> [Bro95, Per94, VH97] </ref>). The rationale is that even when users provide fewer terms, the retrieval system will use techniques such as relevance feedback [SB90] or query augmentation with synonyms to improve retrieval effectiveness, resulting in larger queries. <p> As in <ref> [Per94] </ref>, the weight of t in d is defined by: w d;t = f d;t idf t (3) where f d;t is the number of occurrences of t in d and idf t is the inverse document frequency of the term t. <p> Inverted lists are traditionally ordered by document identifiers, as many query evaluation algorithms use those identifiers (e.g., see [ZMSD92, MZ94, Bro95]). An alternative organization, used in this paper, is a frequency ordering of the inverted lists <ref> [WL93, Per94] </ref>, where those documents in which the terms occur most frequently are stored first in the lists. This organization has the advantage that documents found early in the inverted lists are likely to be highly ranked, and has been shown to give significant performance advantages [WL93, Per94]. 2.4 Query Evaluation <p> of the inverted lists <ref> [WL93, Per94] </ref>, where those documents in which the terms occur most frequently are stored first in the lists. This organization has the advantage that documents found early in the inverted lists are likely to be highly ranked, and has been shown to give significant performance advantages [WL93, Per94]. 2.4 Query Evaluation Query evaluation is the last aspect of document retrieval systems that influences our proposed techniques. In relational database systems a query has a single correct answer. Thus, query optimization cannot transform the query in a way that would cause it to return a different answer. <p> We have proposed two techniques, buffer-aware query evaluation and ranking-aware buffer replacement. For buffer-aware query evaluation, we have extended an existing algorithm, Document Filtering <ref> [Per94] </ref>, by altering its search strategy to first process buffer-resident data when possible. Document Filtering is presented in Section 3.1, and our extension is discussed in Section 3.2. Ranking-aware buffer replacement is based on the idea of "semantic value functions" from [DFJ + 96]. <p> We propose a replacement policy that bases the replacement value of data pages on the actual data on the pages, as well as on the previously posed query. This policy is introduced in Section 3.3. 3.1 The Document Filtering Algorithm Persin's Document Filtering (DF) algorithm <ref> [Per94] </ref> is based on the intuition that if there are documents with large similarity values, it is not profitable to consider small partial similarities (see Section 2.2), as they will not be able to substantially change the final rank of documents. <p> This provides a convenient baseline for gauging the performance of the unsafe optimization. The c ins and c add parameters must be tuned to the document collection, and the query workload that the algorithm must serve (see <ref> [Per94] </ref> for details of the effects of varying these parameters). When properly tuned, this algorithm significantly reduces the size of the candidate set, and the number of (d; f d;t ) pairs processed, with only negligible difference in retrieval effectiveness [Per94]. <p> and the query workload that the algorithm must serve (see <ref> [Per94] </ref> for details of the effects of varying these parameters). When properly tuned, this algorithm significantly reduces the size of the candidate set, and the number of (d; f d;t ) pairs processed, with only negligible difference in retrieval effectiveness [Per94]. In Section 5.1.1 we briefly discuss the performance of the DF algorithm on individual queries based on the TREC collection. 3.2 Buffer-Aware Query Evaluation We now turn to our first technique, buffer-aware query evaluation. <p> Let us examine what happens if we then refine the query by adding the term "invest" to it (the stem of "investment"), and run the resulting query 4 while the inverted 4 The tuning parameters reported in <ref> [Per94] </ref> are not suitable for queries with very few terms, as they do not yield any optimization for such queries. <p> For our performance experiments, however, we use the values from <ref> [Per94] </ref>. Term idf t Pages S max f ins f add Proc. <p> In workloads where such terms are frequently accessed, techniques such as dual buffering [KK94] would be appropriate. tuning parameters of the filtering algorithms, c add and c ins , were set as in <ref> [Per94] </ref> (c add = 0:002; c ins = 0:07). <p> In retrospect, using a standard stop-word list would have been preferable; however, in <ref> [Per94] </ref> it is shown that the performance (efficiency) of document filtering is relatively insensitive to the presence or absence of stop-words, since not much additional data in the inverted lists of stop-words is processed by document filtering. <p> Before presenting details of our results, we define the workloads. 5.1 Workloads We defined two different workloads, each consisting of a number of query refinement sequences. Each refinement sequence is based on a single TREC query; from the 100 queries studied in <ref> [Per94] </ref>, we obtained 100 refinement sequences for each workload. As average numbers can be hard to explain, however, we have chosen four representative refinement sequences to present in detail. <p> In this subsection we first investigate the four TREC queries behind those refinement sequences, and then describe the query refinement workloads. 5.1.1 TREC Queries We used the 100 TREC queries used in <ref> [Per94] </ref> (queries 51-150). The terms and term frequencies (f q;t ) of the queries were found using the same procedure as was used to construct the inverted index (see Section 4.2). <p> The x-axis shows the total number of disk pages in all the inverted lists 13 The results of <ref> [Per94] </ref> were obtained with stop-words included in the inverted index and queries. We also ran such experiments and obtained results identical to those of [Per94], namely about 90% savings in disk reads, and over 98% savings in accumulators. <p> The x-axis shows the total number of disk pages in all the inverted lists 13 The results of <ref> [Per94] </ref> were obtained with stop-words included in the inverted index and queries. We also ran such experiments and obtained results identical to those of [Per94], namely about 90% savings in disk reads, and over 98% savings in accumulators. <p> Overall we observe that as buffer size is increased performance improves, until adding more buffers has no effect and the performance remains unchanged. We also note that DF with the LRU policy (the combination used in <ref> [Per94] </ref>) performs relatively poorly across the range of buffer sizes. 14 By using either BAF or one of the other replacement policies significant improvements are obtained. Finally, in some cases (most notably in BAF along with one of the better replacement policies. <p> ADD-DROP-QUERY2 sequence, varying buffer size. policies. In summary, using DF with LRU (as is done in <ref> [Per94] </ref>) leads to bad performance with query refinement when buffer space is limited.
Reference: [PZSD96] <author> M. Persin, J. Zobel, and R. Sacks-Davis. </author> <title> Filtered document retrieval with frequency-sorted indexes. </title> <journal> Journal of the American Society of Information Science, </journal> <volume> 47(10), </volume> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: Most retrieval algorithms therefore rely on some index structure for efficiency; the index is typically compressed for disk savings <ref> [PZSD96] </ref>. The most commonly used index structure is the inverted index (see [Fal85] for a survey of access methods for text). The inverted index has one inverted list for each term t, where all (d; f d;t ) entries (required for calculating the ranking) are stored. <p> Using compression techniques, however, each such 6 byte entry is compressed down to 1 byte <ref> [PZSD96] </ref>. A page that is one tenth of a 4 KB page with reasonable overhead can hold 404 tuples (PageSize = 404). Table 4 breaks up the terms by the length of the inverted lists.
Reference: [SA87] <author> P. Simpson and R. Alonso. </author> <title> Data caching in information retrieval systems. </title> <booktitle> Proc. ACM SIGIR Conf., </booktitle> <address> New Orleans, LA, </address> <year> 1987. </year>
Reference-contexts: Client data caching for generic information retrieval systems (where information is not restricted to documents) is studied in <ref> [SA87, ABGM90] </ref>. Physical index design, inverted index caching, and database scaling for shared-nothing distributed IR systems are studied in [TGM93a, TGM93b]. None of these studies address buffer replace ment. For database systems, however, there are many studies of buffer replacement policies.
Reference: [SB88] <author> G. Salton and C. Buckley. </author> <title> Term-weighting approaches in automatic text retrieval. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 24(5), </volume> <year> 1988. </year>
Reference-contexts: This may occur repeatedly, until the user is satisfied with the returned results. As we shall see, this search behavior has a significant effect on the way queries should be processed. 2.2 Answers and Ranking Many systems accomplish the ranking of documents using cosine similarity (see <ref> [SB88] </ref> for details).
Reference: [SB90] <author> G. Salton and C. Buckley. </author> <title> Improving retrieval performance by relevance feedback. </title> <journal> Journal of the American Society of Information Science, </journal> <volume> 41(4), </volume> <year> 1990. </year>
Reference-contexts: The rationale is that even when users provide fewer terms, the retrieval system will use techniques such as relevance feedback <ref> [SB90] </ref> or query augmentation with synonyms to improve retrieval effectiveness, resulting in larger queries. While our workloads are based on such queries, we are most interested in query refinement, which is an important search behavior in IR systems [Fid91, KQCB94].
Reference: [SS96] <author> S. Sarawagi and M. Stonebraker. </author> <title> Reordering query execution in tertiary memory databases. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Montreal, Canada, </address> <year> 1996. </year>
Reference-contexts: While our techniques are also applicable to client caching, we have focused on server buffering. We have shown that the highly predictable access patterns of IR algorithms allow for a very efficient replacement value function. The work most related to our buffer-aware algorithm is that of Sarawagi and Stonebraker <ref> [SS96] </ref>, where access to database relation fragments is re-ordered based on the location of the fragments and the time it takes to access them. Experiments with tertiary storage, where multiple users access the same data in a staggered manner, show an order of magnitude decrease in response time.
Reference: [Sto81] <author> M. Stonebraker. </author> <title> Operating system support for database management. </title> <journal> CACM, </journal> <volume> 24(7), </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: This behavior is analogous to repeatedly reading a relation sequentially in a relational DBMS. It is a well known result that for such access patterns the LRU policy renders buffers useless unless they can hold the entire relation <ref> [Sto81] </ref>. As will be shown in our experiments, LRU also renders the buffers useless when they cannot hold the inverted list data used by a query refinement workload. 7 The BAF algorithm goes a long way towards solving this problem, but having a better replacement policy is clearly desirable.
Reference: [TF95] <author> H. Turtle and J. Flood. </author> <title> Query evaluation: Strategies and optimization. </title> <booktitle> Information Processing & Management, </booktitle> <month> Nov. </month> <year> 1995. </year>
Reference-contexts: Of course, efficiency is also a concern for IR systems, and there has been significant research on indexing techniques and query evaluation heuristics that improve the query response time while maintaining a constant level of effectiveness (e.g., see <ref> [Fal85, ZMSD92, WL93, Per94, Bro95, TF95] </ref>). This research, however, has not investigated the system mechanisms that underlie the indexing and querying approaches. Database systems developers have long realized that efficient access to data requires smart algorithms for disk allocation and disk scheduling, buffer management, and process scheduling. <p> Since document retrieval systems do not return a single correct answer, however, IR researchers have developed unsafe (or approximate) query evaluation algorithms, which improve the response time of the system at the cost of potential degradation in retrieval effectiveness <ref> [TF95] </ref>. There are three main factors that affect the response time of document retrieval algorithms: Disk reads, CPU cost and memory requirements. While many database systems are disk bound, Turtle and Flood [TF95] report that in natural language systems it is unclear whether disk or CPU cost is more important. <p> algorithms, which improve the response time of the system at the cost of potential degradation in retrieval effectiveness <ref> [TF95] </ref>. There are three main factors that affect the response time of document retrieval algorithms: Disk reads, CPU cost and memory requirements. While many database systems are disk bound, Turtle and Flood [TF95] report that in natural language systems it is unclear whether disk or CPU cost is more important. Most of the CPU cost, however, is due to decompression of index data and calculations of partial scores, and thus is directly proportional to the number of disk reads. <p> If no precautions are taken, the candidate set frequently includes more than half of the documents in the collection [Bro95]. There are many unsafe optimizations reported in the IR literature (see <ref> [TF95] </ref> for a survey). Some achieve significant improvement in response time for individual queries, while maintaining acceptable retrieval effectiveness. <p> After this procedure, there were 167,017 distinct terms (or inverted lists), containing approximately 31.5 million (d; f d;t ) entries. As the WSJ collection is relatively small (Turtle and Flood state that "it is now common for users to search single collections containing many tens of gigabytes of text" <ref> [TF95] </ref>) and we are interested in de 10 The metric we use to measure retrieval effectiveness is the non-interpolated average precision, which combines recall and precision into a single number.
Reference: [TGM93a] <author> A. Tomasic and H. Garcia-Molina. </author> <title> Caching and database scaling in distributed shared-nothing information retrieval systems. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Washington, DC, </address> <year> 1993. </year>
Reference-contexts: Client data caching for generic information retrieval systems (where information is not restricted to documents) is studied in [SA87, ABGM90]. Physical index design, inverted index caching, and database scaling for shared-nothing distributed IR systems are studied in <ref> [TGM93a, TGM93b] </ref>. None of these studies address buffer replace ment. For database systems, however, there are many studies of buffer replacement policies. <p> Finally, a project that is looking into the architectural foundations of Web-search engines is the Ink-tomi project [Ink]. Inktomi's search engine uses a network of workstations (NOW) to efficiently paral-lelize Web-searches (similar issues were investigated in <ref> [TGM93a, TGM93b] </ref>), enabling low-cost systems with extreme scalability and significant fault-tolerance. 7 Conclusions and Future Work The proliferation of the World Wide Web has brought IR techniques to the forefront of search technology.
Reference: [TGM93b] <author> A. Tomasic and H. Garcia-Molina. </author> <title> Performance of inverted indices in shared-nothing distributed text document information retrieval systems. </title> <booktitle> Proc. PDIS Conf., </booktitle> <address> San Diego, CA, </address> <year> 1993. </year>
Reference-contexts: Client data caching for generic information retrieval systems (where information is not restricted to documents) is studied in [SA87, ABGM90]. Physical index design, inverted index caching, and database scaling for shared-nothing distributed IR systems are studied in <ref> [TGM93a, TGM93b] </ref>. None of these studies address buffer replace ment. For database systems, however, there are many studies of buffer replacement policies. <p> Finally, a project that is looking into the architectural foundations of Web-search engines is the Ink-tomi project [Ink]. Inktomi's search engine uses a network of workstations (NOW) to efficiently paral-lelize Web-searches (similar issues were investigated in <ref> [TGM93a, TGM93b] </ref>), enabling low-cost systems with extreme scalability and significant fault-tolerance. 7 Conclusions and Future Work The proliferation of the World Wide Web has brought IR techniques to the forefront of search technology.
Reference: [Tra95] <institution> Transaction Processing Performance Council (TPC), </institution> <address> 777 N. First Street, Suite 600, San Jose, CA 95112, USA. </address> <booktitle> TPC Benchmark D (Decision Support), </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: As a result, database query processing work has been largely focused on improving the efficiency of data access and manipulation. This emphasis is demonstrated by database query processing benchmarks such as TPC-D <ref> [Tra95] </ref>, which measure only the response time and/or cost of query processing; it is assumed that all database systems will return the same answer set for each query. In contrast, the semantics of IR queries are much fuzzier.
Reference: [Tur94] <author> H. </author> <title> Turtle. Natural language vs. boolean query evaluation: A comparison of retrieval performance. </title> <booktitle> Proc. ACM SIGIR Conf., </booktitle> <address> Dublin, Ireland, </address> <year> 1994. </year>
Reference-contexts: Benchmarks and studies for IR query processing have therefore focused on improving retrieval effectiveness, which is a measure of user satisfaction with the returned answers (e.g., see <ref> [Tur94, VH97] </ref>). Of course, efficiency is also a concern for IR systems, and there has been significant research on indexing techniques and query evaluation heuristics that improve the query response time while maintaining a constant level of effectiveness (e.g., see [Fal85, ZMSD92, WL93, Per94, Bro95, TF95]). <p> The boolean query model is similar to the query model used by relational languages such as SQL. Formulating boolean queries that return result sets of manageable size has been shown to require significant expertise; as the size of the collection grows, formulating queries becomes even harder <ref> [Tur94] </ref>. Natural language (or vector space model) techniques were developed concurrently with the boolean query model, but have only recently been adopted by commercial IR systems [Tur94]. <p> result sets of manageable size has been shown to require significant expertise; as the size of the collection grows, formulating queries becomes even harder <ref> [Tur94] </ref>. Natural language (or vector space model) techniques were developed concurrently with the boolean query model, but have only recently been adopted by commercial IR systems [Tur94]. <p> Research has shown that natural language techniques give better query results than boolean techniques, regardless of the size of the document collection <ref> [Tur94] </ref>. For this reason, we use natural language queries in this paper. Studies comparing query evaluation algorithms for document retrieval have traditionally used between 35 2 In many systems, additional operators, such as proximity operators, which restrict the location of terms in the documents, are provided.
Reference: [VH97] <author> E.M. Voorhees and D. </author> <title> Harman. </title> <booktitle> Overview of the fifth Text REtrieval Conference (TREC-5). The fifth Text REtrieval Conference (TREC-5), </booktitle> <publisher> NIST, </publisher> <address> Gaithersburg, MD, </address> <year> 1997. </year>
Reference-contexts: Benchmarks and studies for IR query processing have therefore focused on improving retrieval effectiveness, which is a measure of user satisfaction with the returned answers (e.g., see <ref> [Tur94, VH97] </ref>). Of course, efficiency is also a concern for IR systems, and there has been significant research on indexing techniques and query evaluation heuristics that improve the query response time while maintaining a constant level of effectiveness (e.g., see [Fal85, ZMSD92, WL93, Per94, Bro95, TF95]). <p> As stated in the introduction, however, the problems addressed by the IR and database communities have differed substantially. A brief description of the TREC conference series <ref> [Har96, VH97] </ref>, which serves as the major bench-marking activity for IR systems, illustrates this difference. The TREC conference uses a standard document collection, which is made up of three parts: Documents There are currently roughly 4 GB of doc uments in a number of sub-collections. <p> For simplicity we have left such operators out of this work; adding support for them is one avenue for future work. and 100 terms per query (e.g., see <ref> [Bro95, Per94, VH97] </ref>). The rationale is that even when users provide fewer terms, the retrieval system will use techniques such as relevance feedback [SB90] or query augmentation with synonyms to improve retrieval effectiveness, resulting in larger queries. <p> We report these additional metrics when necessary. 4.2 The Inverted Index We have indexed the WSJ document collection from the TREC benchmark <ref> [VH97] </ref>. The WSJ collection contains articles that appeared in the Wall Street Journal during the years 1987-1992. The total size of the collection is roughly 530 MB in 173,252 documents. Two common techniques for improving performance are stop-word removal [Fox92] and word stemming [Fra92].
Reference: [WL93] <author> W.Y.P. Wong and D.L. Lee. </author> <title> Implementation of partial document ranking using inverted files. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 29(5), </volume> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: Of course, efficiency is also a concern for IR systems, and there has been significant research on indexing techniques and query evaluation heuristics that improve the query response time while maintaining a constant level of effectiveness (e.g., see <ref> [Fal85, ZMSD92, WL93, Per94, Bro95, TF95] </ref>). This research, however, has not investigated the system mechanisms that underlie the indexing and querying approaches. Database systems developers have long realized that efficient access to data requires smart algorithms for disk allocation and disk scheduling, buffer management, and process scheduling. <p> Inverted lists are traditionally ordered by document identifiers, as many query evaluation algorithms use those identifiers (e.g., see [ZMSD92, MZ94, Bro95]). An alternative organization, used in this paper, is a frequency ordering of the inverted lists <ref> [WL93, Per94] </ref>, where those documents in which the terms occur most frequently are stored first in the lists. This organization has the advantage that documents found early in the inverted lists are likely to be highly ranked, and has been shown to give significant performance advantages [WL93, Per94]. 2.4 Query Evaluation <p> of the inverted lists <ref> [WL93, Per94] </ref>, where those documents in which the terms occur most frequently are stored first in the lists. This organization has the advantage that documents found early in the inverted lists are likely to be highly ranked, and has been shown to give significant performance advantages [WL93, Per94]. 2.4 Query Evaluation Query evaluation is the last aspect of document retrieval systems that influences our proposed techniques. In relational database systems a query has a single correct answer. Thus, query optimization cannot transform the query in a way that would cause it to return a different answer.
Reference: [ZMSD92] <author> J. Zobel, A. Moffat, and R. Sacks-Davis. </author> <title> An efficient indexing technique for full-text database systems. </title> <booktitle> Proc. of the VLDB Conf., </booktitle> <address> Vancouver, Canada, </address> <year> 1992. </year>
Reference-contexts: Of course, efficiency is also a concern for IR systems, and there has been significant research on indexing techniques and query evaluation heuristics that improve the query response time while maintaining a constant level of effectiveness (e.g., see <ref> [Fal85, ZMSD92, WL93, Per94, Bro95, TF95] </ref>). This research, however, has not investigated the system mechanisms that underlie the indexing and querying approaches. Database systems developers have long realized that efficient access to data requires smart algorithms for disk allocation and disk scheduling, buffer management, and process scheduling. <p> The inverted index has one inverted list for each term t, where all (d; f d;t ) entries (required for calculating the ranking) are stored. Inverted lists are traditionally ordered by document identifiers, as many query evaluation algorithms use those identifiers (e.g., see <ref> [ZMSD92, MZ94, Bro95] </ref>). An alternative organization, used in this paper, is a frequency ordering of the inverted lists [WL93, Per94], where those documents in which the terms occur most frequently are stored first in the lists.
References-found: 37

