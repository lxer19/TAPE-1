URL: http://www.cs.caltech.edu/~eric/papers/early_stopping.ps
Refering-URL: http://www.cs.caltech.edu/~eric/papers/papers.html
Root-URL: http://www.cs.caltech.edu
Title: The Central Classifier Bound ANew Error Bound for the Classifier Chosen by Early Stopping Key
Author: Eric Bax Zehra Cataltepe, and Joe Sill Vapnik-Chervonenkis. 
Date: September 15, 1997  
Affiliation: California Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> E. Bax, </author> <title> Validation of voting committees, </title> <publisher> CalTech-CS-TR-97-13. </publisher>
Reference-contexts: The new rules may require different uses of central classifiers to develop error bounds and different methods to select the central classifiers. There is a technical report [2] on applying the central classifier bound to the full VC framework. For more advanced applications of bounding by inference, see <ref> [1] </ref>. Finally, for improved uniform bounds over the central classifiers, see [3]. 10 Acknowledgements We thank Dr. Yaser Abu-Mostafa and Dr. Joel Franklin for their teaching and advice.
Reference: [2] <author> E. Bax, </author> <title> Similar classifiers and VC error bounds, </title> <publisher> CalTech-CS-TR-97-14. </publisher>
Reference-contexts: The new rules may require different uses of central classifiers to develop error bounds and different methods to select the central classifiers. There is a technical report <ref> [2] </ref> on applying the central classifier bound to the full VC framework. For more advanced applications of bounding by inference, see [1]. Finally, for improved uniform bounds over the central classifiers, see [3]. 10 Acknowledgements We thank Dr. Yaser Abu-Mostafa and Dr. Joel Franklin for their teaching and advice.
Reference: [3] <author> E. Bax, </author> <title> Improved uniform test error bounds, </title> <publisher> CalTech-CS-TR-97-15. </publisher>
Reference-contexts: There is a technical report [2] on applying the central classifier bound to the full VC framework. For more advanced applications of bounding by inference, see [1]. Finally, for improved uniform bounds over the central classifiers, see <ref> [3] </ref>. 10 Acknowledgements We thank Dr. Yaser Abu-Mostafa and Dr. Joel Franklin for their teaching and advice.
Reference: [4] <author> E. Bax, </author> <title> Validation of average error rate over classifiers, </title> <publisher> CalTech-CS-TR-97-17. </publisher>
Reference-contexts: Also, a central classifier could be defined as the following process. For each example, choose a member at random from a set of snapshots and apply it. The error rate of this process can be validated with the same confidence as the validation of a single classifier <ref> [4] </ref>. The validation error is the average over set members.
Reference: [5] <author> W. Feller, </author> <title> An Introduction to Probability Theory and Its Applications, </title> <publisher> John Wiley and Sons, Inc. </publisher> <year> 1968. </year>
Reference-contexts: Each of these values is the mean of a Bernoulli process that takes value 1 if c s and g fl disagree and value 0 otherwise. By the central limit theorem <ref> [5] </ref>, the sample mean converges to p s almost surely.) Choose c fl to be the central classifier with minimium -s + p s . Let -+ be the validation error of c fl .
Reference: [6] <author> Hoeffding, W. </author> <year> (1963). </year> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association, </journal> <pages> 13-30. </pages>
Reference-contexts: To simplify the analysis, we use the Hoeffding bound <ref> [6] </ref> 2e 1 2 * 2 D , where D = min (d; d 0 ), in place of the partition-based bound B (*). (The Hoeffding bound is smooth, and it is often used in VC analysis [8].) For a chosen confidence level, compare the test error bounds produced by the
Reference: [7] <author> J. Sill and Y. Abu-Mostafa, </author> <title> Monotonicity hints, </title> <booktitle> to appear in Advances in Neural Information Processing Systems, </booktitle> <volume> 9. </volume> <year> 1997. </year>
Reference-contexts: The discrete-valued traits were removed, leaving the six continous-valued traits. Of the 690 examples in the original database, 24 examples had at least one trait missing. These examples were removed, leaving 666 examples. The data were cleaned by Joseph Sill. For further information, see <ref> [7] </ref>. There were 10 tests. In each test, the 666 examples were randomly partitioned into 444 training examples, d = 111 validation examples, and d 0 = 111 test examples. In each test, a classifier was trained, producing M = 1000 snapshots.
Reference: [8] <author> V. N. Vapnik, </author> <title> Estimation of Dependences Based on Empirical Data p.31, </title> <publisher> Springer-Verlag New York, Inc. </publisher> <year> 1982. </year> <month> 11 </month>
Reference-contexts: Deliver a minimum validation error classifier, g fl , as the result of training. The purpose of this paper is to develop a good probabilistic upper bound on the error rate of g fl over out-of-sample (test) data. First, we use a validation-oriented version of VC analysis <ref> [8, 9] </ref> to develop a bound. Because of the nature of VC analysis, this initial bound is based on worst-case assumptions about the rates of agreement among snapshots. In practice, though, successive snapshots are similar classifiers. We exploit this feature to develop a new bound. <p> To simplify the analysis, we use the Hoeffding bound [6] 2e 1 2 * 2 D , where D = min (d; d 0 ), in place of the partition-based bound B (*). (The Hoeffding bound is smooth, and it is often used in VC analysis <ref> [8] </ref>.) For a chosen confidence level, compare the test error bounds produced by the VC-type and central classifier methods.
Reference: [9] <author> V. N. Vapnik and A. Chervonenkis, </author> <title> On the uniform convergence of rel-ative frequencies of events to their probabilities, </title> <journal> Theory Prob. Appl., </journal> <volume> 16(1971) </volume> <pages> 264-280. </pages>
Reference-contexts: Deliver a minimum validation error classifier, g fl , as the result of training. The purpose of this paper is to develop a good probabilistic upper bound on the error rate of g fl over out-of-sample (test) data. First, we use a validation-oriented version of VC analysis <ref> [8, 9] </ref> to develop a bound. Because of the nature of VC analysis, this initial bound is based on worst-case assumptions about the rates of agreement among snapshots. In practice, though, successive snapshots are similar classifiers. We exploit this feature to develop a new bound.
References-found: 9

