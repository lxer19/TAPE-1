URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3606/3606.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Email: lanubile@cs.umd.edu  visaggio@seldi.uniba.it  
Title: Evaluating Predictive Quality Models Derived from Software Measures: Lessons Learned  
Author: Filippo Lanubile Giuseppe Visaggio 
Address: College Park, Maryland 20742  Via Orabona 4, 70126 Bari, Italy  
Affiliation: Computer Science Department University of Maryland Institute for Advanced Computer Studies  Dipartimento di Informatica University of Bari  
Date: January 1996  
Pubnum: CS-TR-3606  UMIACS-TR-96-14 ISERN-96-03  
Abstract: 1 This paper describes an empirical comparison of several modeling techniques for predicting the quality of software components early in the software life cycle. Using software product measures, we built models that classify components as high-risk, i.e., likely to contain faults, or low-risk, i.e., likely to be free of faults. The modeling techniques evaluated in this study include principal component analysis, discriminant analysis, logistic regression, logical classification models, layered neural networks, and holographic networks. These techniques provide a good coverage of the main problemsolving paradigms: statistical analysis, machine learning, and neural networks. Using the results of independent testing, we determined the absolute worth of the predictive models and compare their performance in terms of misclassification errors, achieved quality, and verification cost. Data came from 27 software systems, developed and tested during three years of project-intensive academic courses. A surprising result is that no model was able to effectively discriminate between components with faults and components without faults. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Agresti, A., </author> <title> Categorical Data Analysis, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: one, applying discriminant analysis directly on the original eleven product metrics, and the second one, using as input the three domain metrics obtained from the principal component analysis. 8 3.3 Logistic regression Logistic regression refers to an analysis that computes the probability of class membership according to the following equation <ref> [1] </ref>: log p 1 - 0 i n where p is the probability that a software component is high-risk, and x i are the predictor variables. The regression coefficients c i are computed through a maximum-likelihood estimation. <p> Since the networks input and output are bounded between 0 and 1, we reduced input data using a direct scaling. When testing the network, we increased the error tolerance to 0.5 so that low-risk components correspond to observations with an output value in the first half of <ref> [ 0, 1 ] </ref> and high-risk components to observations with an output value in the second half. 3.6 Holographic networks With holographic networks, information is encoded inside holographic neurons rather than in the connection weights between neurons [29]. A holographic neuron holds a correlation matrix that enables memorizing stimulus-response associations.
Reference: [2] <author> Boetticher, G., Srinivas, K., and Eichmann, D., </author> <title> A neural net-based approach to software metrics, </title> <booktitle> in Proc. 5th Int. Conf. </booktitle> <institution> Software Eng. and Knowledge Eng., </institution> <month> 271-274, </month> <year> 1993. </year>
Reference-contexts: Logical classification models have been used extensively to identify high-risk modules [3, 4, 20, 21, 27] and reusable software components [8]. Layered neural networks have already been applied to building reliability growth models [11, 12], to predicting the gross change [16], and the degree of reuse <ref> [2] </ref>. Holographic networks, a nonconnectionist type of neural network, have been proposed for predicting software quality [18]. Empirical investigations have not yet been performed in the software engineering field but have in other areas such as financing [28] and manufacturing [10].
Reference: [3] <author> Briand, L. C., Thomas, W. M., and Hetmanski, C. J., </author> <title> Modeling and managing risk early in software development, </title> <booktitle> in Proc. 15th Int. Conf. Sofware Eng., </booktitle> <pages> 55-65, </pages> <year> 1993. </year>
Reference-contexts: Multiple linear regression analysis has been used to predict the number of corrective changes [13, 14]. Discriminant analysis has been applied to detect fault-prone modules [16, 19]. Logistic regression has been used for modeling to identify high-risk components <ref> [3, 4] </ref>. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models [3, 4, 14]. Logical classification models have been used extensively to identify high-risk modules [3, 4, 20, 21, 27] and reusable software components [8]. <p> Discriminant analysis has been applied to detect fault-prone modules [16, 19]. Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models <ref> [3, 4, 14] </ref>. Logical classification models have been used extensively to identify high-risk modules [3, 4, 20, 21, 27] and reusable software components [8]. Layered neural networks have already been applied to building reliability growth models [11, 12], to predicting the gross change [16], and the degree of reuse [2]. <p> Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models [3, 4, 14]. Logical classification models have been used extensively to identify high-risk modules <ref> [3, 4, 20, 21, 27] </ref> and reusable software components [8]. Layered neural networks have already been applied to building reliability growth models [11, 12], to predicting the gross change [16], and the degree of reuse [2]. <p> So if all the high-risk components are properly classified, all defects will be removed by the extra verification, and perfect quality will be achieved. However, quality will be degraded with each high-risk component that is not identified. We measure the criterion of achieved quality using the completeness measure <ref> [3] </ref> which is the percentage of faulty components that have been actually classified as such by the model.
Reference: [4] <author> Briand, L. C., Basili, V. R., and Hetmanski, C. J., </author> <title> Developing interpretable models with optimized set reduction for identifying high-risk software components, </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 19 (11), </volume> <pages> 1028-1044, </pages> <month> November </month> <year> (1993). </year>
Reference-contexts: Multiple linear regression analysis has been used to predict the number of corrective changes [13, 14]. Discriminant analysis has been applied to detect fault-prone modules [16, 19]. Logistic regression has been used for modeling to identify high-risk components <ref> [3, 4] </ref>. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models [3, 4, 14]. Logical classification models have been used extensively to identify high-risk modules [3, 4, 20, 21, 27] and reusable software components [8]. <p> Discriminant analysis has been applied to detect fault-prone modules [16, 19]. Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models <ref> [3, 4, 14] </ref>. Logical classification models have been used extensively to identify high-risk modules [3, 4, 20, 21, 27] and reusable software components [8]. Layered neural networks have already been applied to building reliability growth models [11, 12], to predicting the gross change [16], and the degree of reuse [2]. <p> Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models [3, 4, 14]. Logical classification models have been used extensively to identify high-risk modules <ref> [3, 4, 20, 21, 27] </ref> and reusable software components [8]. Layered neural networks have already been applied to building reliability growth models [11, 12], to predicting the gross change [16], and the degree of reuse [2]. <p> None of the other models discovers even half of the high-risk components and waste nearly half or more of the verification effort. 6. Related Work Some empirical studies, relevant to this work, are summarized in the following. Briand et al. <ref> [4] </ref> presented an experiment for predicting high-risk components using two logical classification models (Optimized Set Reduction and classification tree) and two logistic regression models (with and without principal components). Design and code metrics were collected from 146 components of a 260 KLOC system.
Reference: [5] <author> Briand, L., El Eman, K., and Morasca, S., </author> <title> Theoretical and empirical validation of software product measures, </title> <journal> ISERN-95-03, International Software Engineering Research Network, </journal> <year> 1995. </year>
Reference-contexts: Whereas the research underlying the validation of software product measures as internal attributes of software quality is not novel, it is only within the past few years that researchers have begun to worry about a rigorous and local validation <ref> [5, 9, 17, 25] </ref>. Predictive models are very attractive to build but they can be a waste of time if we rely on false assumptions instead of building a local process for selecting valid predictors.
Reference: [6] <author> Conover, W. J., </author> <title> Practical Nonparametric Statistics, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1971. </year>
Reference-contexts: The alternative hypothesis is one of general association. A chisquare ( c 2 ) statistic <ref> [6] </ref> with a distribution of one degree of freedom is applied to test the null hypothesis. 4.2 Misclassification rate For our predictive models, which classify components as either low-risk or high-risk, two misclassification errors are possible.
Reference: [7] <author> Dillon, W. R., and Goldstein, M., </author> <title> Multivariate Analysis: Methods and Applications, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: In this case, principal component analysis is applied to reduce the dimensions of the metric space and obtain a smaller number of orthogonal domain metrics <ref> [7] </ref>. In our study, the principal component analysis applied on the eleven product metrics produced three distinct complexity domains, having eigenvalues greater than 0.9. In Table 2, each column shows the degree of relationship between the eleven metrics and the three orthogonal domains. <p> Rotated factor pattern 3.2 Discriminant analysis Discriminant analysis develops a discriminant function or classification criterion to place each observation into one of a set of mutually exclusive groups <ref> [7] </ref>. It requires that there exists a prior knowledge of the classes, in our case low-risk and high-risk components. To develop the classification criterion, we used a parametric method that uses a measure of generalized square distance and is based on a pooled covariance matrix.
Reference: [8] <author> Esteva, J. C., and Reynolds, R. G., </author> <title> Identifying reusable software components by induction, </title> <journal> Int. J. Software Eng. and Knowledge Eng., </journal> <volume> 1 (3), </volume> <month> 271-292 </month> <year> (1991). </year>
Reference-contexts: Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models [3, 4, 14]. Logical classification models have been used extensively to identify high-risk modules [3, 4, 20, 21, 27] and reusable software components <ref> [8] </ref>. Layered neural networks have already been applied to building reliability growth models [11, 12], to predicting the gross change [16], and the degree of reuse [2]. Holographic networks, a nonconnectionist type of neural network, have been proposed for predicting software quality [18].
Reference: [9] <author> Fenton, N. E., </author> <title> Software measurement: a necessary scientific basis, </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 20 (3), </volume> <pages> 199-206, </pages> <month> March </month> <year> (1994). </year>
Reference-contexts: Whereas the research underlying the validation of software product measures as internal attributes of software quality is not novel, it is only within the past few years that researchers have begun to worry about a rigorous and local validation <ref> [5, 9, 17, 25] </ref>. Predictive models are very attractive to build but they can be a waste of time if we rely on false assumptions instead of building a local process for selecting valid predictors.
Reference: [10] <author> Jensen, G., </author> <title> Quality control in manufacturing based on fuzzy classification, in Frontier Decision Support Concepts (V. </title> <editor> L. Plantamura, B. Soucek, G. Visaggio, eds.), </editor> <publisher> John Wiley & Sons, </publisher> <address> New York, 107-118, </address> <year> 1994. </year>
Reference-contexts: Holographic networks, a nonconnectionist type of neural network, have been proposed for predicting software quality [18]. Empirical investigations have not yet been performed in the software engineering field but have in other areas such as financing [28] and manufacturing <ref> [10] </ref>. Many of the past studies have focused on predicting the presence of faults early in the software life cycle.
Reference: [11] <author> Karunanithi, N., Whitley, D., and Malaiya, Y. K., </author> <title> Prediction of software reliability using connectionists models, </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 18 (7), </volume> <pages> 563-573, </pages> <month> July </month> <year> (1992). </year>
Reference-contexts: Logical classification models have been used extensively to identify high-risk modules [3, 4, 20, 21, 27] and reusable software components [8]. Layered neural networks have already been applied to building reliability growth models <ref> [11, 12] </ref>, to predicting the gross change [16], and the degree of reuse [2]. Holographic networks, a nonconnectionist type of neural network, have been proposed for predicting software quality [18].
Reference: [12] <author> Karunanithi, N., Whitley, D., and Malaiya, Y. K., </author> <title> Using neural networks in reliability prediction, </title> <journal> IEEE Software, </journal> <pages> 53-59, </pages> <month> July </month> <year> (1992). </year>
Reference-contexts: Logical classification models have been used extensively to identify high-risk modules [3, 4, 20, 21, 27] and reusable software components [8]. Layered neural networks have already been applied to building reliability growth models <ref> [11, 12] </ref>, to predicting the gross change [16], and the degree of reuse [2]. Holographic networks, a nonconnectionist type of neural network, have been proposed for predicting software quality [18].
Reference: [13] <author> Khoshgoftaar, T. M., Munson, J. C., Bhattacharya, B. B., and Richardson G. D., </author> <title> Predictive modeling techniques of software quality from software measures, </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 18 (11), </volume> <pages> 979-987, </pages> <month> November </month> <year> (1992). </year>
Reference-contexts: 1. Introduction The construction of predictive systems is one of the main purposes of software measurement. Predictive systems have been built from product metrics by applying different kinds of modeling techniques. Multiple linear regression analysis has been used to predict the number of corrective changes <ref> [13, 14] </ref>. Discriminant analysis has been applied to detect fault-prone modules [16, 19]. Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models [3, 4, 14].
Reference: [14] <author> Khoshgoftaar, T. M., Lanning, D. L., and Munson, J. C., </author> <title> A comparative study of predictive models for program changes during system testing and maintenance, </title> <booktitle> in Proc. Conf. Software Maintenance, </booktitle> <pages> 72-79, </pages> <year> 1993. </year>
Reference-contexts: 1. Introduction The construction of predictive systems is one of the main purposes of software measurement. Predictive systems have been built from product metrics by applying different kinds of modeling techniques. Multiple linear regression analysis has been used to predict the number of corrective changes <ref> [13, 14] </ref>. Discriminant analysis has been applied to detect fault-prone modules [16, 19]. Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models [3, 4, 14]. <p> Discriminant analysis has been applied to detect fault-prone modules [16, 19]. Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models <ref> [3, 4, 14] </ref>. Logical classification models have been used extensively to identify high-risk modules [3, 4, 20, 21, 27] and reusable software components [8]. Layered neural networks have already been applied to building reliability growth models [11, 12], to predicting the gross change [16], and the degree of reuse [2].
Reference: [15] <author> Khoshgoftaar, T. M., Allen, E. B., Kalaichelvan, K. S., and Goel, N., </author> <title> Early quality prediction: a case study in telecommunications, </title> <journal> IEEE Software, </journal> <pages> 65-71, </pages> <month> January </month> <year> (1996). </year>
Reference-contexts: Discriminant analysis has been applied to detect fault-prone modules [16, 19]. Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models <ref> [15, 19] </ref> or regression models [3, 4, 14]. Logical classification models have been used extensively to identify high-risk modules [3, 4, 20, 21, 27] and reusable software components [8]. <p> They collected 14 metrics, including Halsteads metrics together with other code metrics. Applying discriminant analysis with principal components resulted in correctly recognizing 79 percent of the modules with a total misclassification rate of 5 percent. Khoshgoftaar et al. <ref> [15] </ref> again applied principal component analysis and discriminant analysis to identify fault-prone modules (modules with five or more faults) in a large telecommunications system. They used 1980 modules consisting of 194 new, 917 reused but modified, and 869 reused without modification.
Reference: [16] <author> Khoshgoftaar, T. M., and Szabo, R. M., </author> <title> Improving code churn prediction during the system test and maintenance phases, </title> <booktitle> in Proc. of the Int. Conf. Software Maintenance, </booktitle> <pages> 58-67, </pages> <year> 1994. </year> <month> 18 </month>
Reference-contexts: Predictive systems have been built from product metrics by applying different kinds of modeling techniques. Multiple linear regression analysis has been used to predict the number of corrective changes [13, 14]. Discriminant analysis has been applied to detect fault-prone modules <ref> [16, 19] </ref>. Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models [3, 4, 14]. <p> Logical classification models have been used extensively to identify high-risk modules [3, 4, 20, 21, 27] and reusable software components [8]. Layered neural networks have already been applied to building reliability growth models [11, 12], to predicting the gross change <ref> [16] </ref>, and the degree of reuse [2]. Holographic networks, a nonconnectionist type of neural network, have been proposed for predicting software quality [18]. Empirical investigations have not yet been performed in the software engineering field but have in other areas such as financing [28] and manufacturing [10].
Reference: [17] <author> Kitchenham, B., Pfleeger, S. L., and Fenton, N., </author> <title> Towards a framework for software measurement validation, </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 21 (12), </volume> <pages> 929-943, </pages> <month> December </month> <year> (1995). </year>
Reference-contexts: Whereas the research underlying the validation of software product measures as internal attributes of software quality is not novel, it is only within the past few years that researchers have begun to worry about a rigorous and local validation <ref> [5, 9, 17, 25] </ref>. Predictive models are very attractive to build but they can be a waste of time if we rely on false assumptions instead of building a local process for selecting valid predictors.
Reference: [18] <author> Lanubile, F., and Visaggio, G., </author> <title> Quality evaluation on software reengineering based on fuzzy classification, in Frontier Decision Support Concepts (V. </title> <editor> L. Plantamura, B. Soucek, G. Visaggio, eds.), </editor> <publisher> John Wiley & Sons, </publisher> <address> New York, 119-134, </address> <year> 1994. </year>
Reference-contexts: Layered neural networks have already been applied to building reliability growth models [11, 12], to predicting the gross change [16], and the degree of reuse [2]. Holographic networks, a nonconnectionist type of neural network, have been proposed for predicting software quality <ref> [18] </ref>. Empirical investigations have not yet been performed in the software engineering field but have in other areas such as financing [28] and manufacturing [10]. Many of the past studies have focused on predicting the presence of faults early in the software life cycle.
Reference: [19] <author> Munson, J. C., and Khoshgoftaar, T. M., </author> <title> The detection of fault-prone programs, </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 18 (5), </volume> <pages> 423-433, </pages> <month> May </month> <year> (1992). </year>
Reference-contexts: Predictive systems have been built from product metrics by applying different kinds of modeling techniques. Multiple linear regression analysis has been used to predict the number of corrective changes [13, 14]. Discriminant analysis has been applied to detect fault-prone modules <ref> [16, 19] </ref>. Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models [3, 4, 14]. <p> Discriminant analysis has been applied to detect fault-prone modules [16, 19]. Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models <ref> [15, 19] </ref> or regression models [3, 4, 14]. Logical classification models have been used extensively to identify high-risk modules [3, 4, 20, 21, 27] and reusable software components [8]. <p> Most studies measure both design and code attributes but there is not a unique set of product metrics that all the studies 3 use. Our indirect metrics of software quality are essentially the same used by Munson and Khoshgoftaar <ref> [19] </ref> to construct their predictive models. Reduction of the prediction problem to a classification problem. <p> He measured the mean accuracy across all tree applications according to completeness (82 percent) and to the percentage of components whose target class membership is correctly identified (72 percent), that is the complement of the Proportion of Type 1 and Type 2 error. Munson and Khoshgoftaar <ref> [19] </ref> detected faulty components by applying principal component analysis and discriminant analysis to discriminate between programs with less than five faults and programs having five or more faults. The data set included 327 program modules from two 15 distinct Ada projects of a command and control communication system.
Reference: [20] <author> Porter, A. A., </author> <title> Developing and analyzing classification rules for predicting faulty software components, </title> <booktitle> in Proc. 5th Int. Conf. </booktitle> <institution> Software Eng. and Knowledge Eng., </institution> <month> 453-461, </month> <year> 1993. </year>
Reference-contexts: Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models [3, 4, 14]. Logical classification models have been used extensively to identify high-risk modules <ref> [3, 4, 20, 21, 27] </ref> and reusable software components [8]. Layered neural networks have already been applied to building reliability growth models [11, 12], to predicting the gross change [16], and the degree of reuse [2]. <p> The classification tree was more complete (82 percent) and correct (83 percent) than logistic regression models. The use of principal components improved the accuracy of logistic regression, from 67 to 71 percent completeness and from 77 to 80 percent correctness. Porter <ref> [20] </ref> presented an application of classification trees to data collected from 1400 components of six FORTRAN projects in a NASA environment. For each component, 19 attributes were measured, capturing information spanning from design specifications to implementation.
Reference: [21] <author> Porter, A. A., and Selby, R. W., </author> <title> Empirically guided software development using metric based classification trees, </title> <journal> IEEE Software, </journal> <pages> 46-54, </pages> <month> March </month> <year> (1990). </year>
Reference-contexts: Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models [3, 4, 14]. Logical classification models have been used extensively to identify high-risk modules <ref> [3, 4, 20, 21, 27] </ref> and reusable software components [8]. Layered neural networks have already been applied to building reliability growth models [11, 12], to predicting the gross change [16], and the degree of reuse [2].
Reference: [22] <author> Quinlan, J. R., </author> <title> Induction of decision trees, </title> <journal> Machine Learning, </journal> <volume> 1 (1), </volume> <month> 81-106 </month> <year> (1986). </year>
Reference-contexts: They are generated through a recursive algorithm that selects metrics that best discriminate between components within a target class and those outside it. To automatically build the classification model we used the C4.5 system [23], a variation on the ID3 system <ref> [22] </ref>. The C4.5 system partitions continuous attributes, in our case the indirect metrics of reliability, finding the best threshold among the set of training cases.
Reference: [23] <author> Quinlan, J. R., C4.5: </author> <title> Programs for Machine Learning, </title> <publisher> Morgan Kauffman Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: They are generated through a recursive algorithm that selects metrics that best discriminate between components within a target class and those outside it. To automatically build the classification model we used the C4.5 system <ref> [23] </ref>, a variation on the ID3 system [22]. The C4.5 system partitions continuous attributes, in our case the indirect metrics of reliability, finding the best threshold among the set of training cases.
Reference: [24] <author> Rumelhart, D., Hinton, G., and Williams, R., </author> <title> Learning internal representations by error propagation, </title> <booktitle> in Parallel Distribuited Processing, </booktitle> <address> vol.I, </address> <publisher> MIT Press, </publisher> <address> Cambridge, MA, 318-362, </address> <year> 1986. </year>
Reference-contexts: tree was transformed into a collection of rules, by removing the conditions that were not helpful for discriminating between classes and by excluding rules that did not contribute to the accuracy of the set of rules as a whole. 3.5 Layered neural networks We used a typical feed-forward neural network <ref> [24] </ref>, characterized in our experiment by one input layer of eleven neurons, each connected to a product metric, one output layer of only one neuron that provides the predicted risk, and one layer of fifty hidden neurons.
Reference: [25] <author> Schneidewind, N. F., </author> <title> Methodology for validating software metrics, </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 18 (5), </volume> <pages> 410-422, </pages> <month> May </month> <year> (1992). </year>
Reference-contexts: Whereas the research underlying the validation of software product measures as internal attributes of software quality is not novel, it is only within the past few years that researchers have begun to worry about a rigorous and local validation <ref> [5, 9, 17, 25] </ref>. Predictive models are very attractive to build but they can be a waste of time if we rely on false assumptions instead of building a local process for selecting valid predictors.
Reference: [26] <author> Schneidewind, N. F., </author> <title> Validating metrics for ensuring Space Shuttle Flight software quality, </title> <booktitle> Computer, </booktitle> <pages> 50-57, </pages> <month> August </month> <year> (1994). </year>
Reference-contexts: As a result of a Type 2 error, an actual low-risk component will receive more testing and inspection effort than needed. In the contingency table, the number of Type 1 and Type 2 errors is given, respectively, by n 21 12 . We use the following measures of misclassification <ref> [26] </ref>: Proportion of Type 1: P 1 21 Proportion of Type 2: P 2 12 Proportion of Type 1 + Type 2: P 12 21 12 4.3 Quality achieved We are interested in measuring how effective the predictive models are in terms of the quality achieved after the components classified as <p> Completeness: C = n 22 2 12 4.4 Verification cost Quality is achieved by increasing the cost of verification due to an extra effort in inspection and testing for the components that have been flagged as high-risk. We measure the verification cost by using two indicators. The former, inspection <ref> [26] </ref>, measures the overall cost by considering the percentage of components that should be verified. The latter, wasted inspection, is the percentage of components that do not contain faults but have been verified because they have been incorrectly classified.
Reference: [27] <author> Selby, R. W., and Porter, A. A., </author> <title> Learning from examples: generation and evaluation of decision trees for software resource analysis, </title> <journal> IEEE Trans. Software Eng., </journal> <volume> 14 (12), </volume> <pages> 1743-1757, </pages> <month> December </month> <year> (1988). </year>
Reference-contexts: Logistic regression has been used for modeling to identify high-risk components [3, 4]. Principal component analysis has often been used to improve the accuracy of discriminant models [15, 19] or regression models [3, 4, 14]. Logical classification models have been used extensively to identify high-risk modules <ref> [3, 4, 20, 21, 27] </ref> and reusable software components [8]. Layered neural networks have already been applied to building reliability growth models [11, 12], to predicting the gross change [16], and the degree of reuse [2].
Reference: [28] <author> Soucek, B., Sutherland, J., and Visaggio, G., </author> <title> Holographic decision support system: credit scoring based on quality metrics, in Frontier Decision Support Concepts (V. </title> <editor> L. Plantamura, B. Soucek, G. Visaggio, eds.), </editor> <publisher> John Wiley & Sons, </publisher> <address> New York, 171-182, </address> <year> 1994. </year>
Reference-contexts: Holographic networks, a nonconnectionist type of neural network, have been proposed for predicting software quality [18]. Empirical investigations have not yet been performed in the software engineering field but have in other areas such as financing <ref> [28] </ref> and manufacturing [10]. Many of the past studies have focused on predicting the presence of faults early in the software life cycle.
Reference: [29] <author> Sutherland, J., </author> <title> A holographic model of memory, learning and expression, </title> <journal> Int. J. Neural Syst., </journal> <volume> 1 (3), </volume> <month> 259-267 </month> <year> (1990). </year>
Reference-contexts: components correspond to observations with an output value in the first half of [ 0, 1 ] and high-risk components to observations with an output value in the second half. 3.6 Holographic networks With holographic networks, information is encoded inside holographic neurons rather than in the connection weights between neurons <ref> [29] </ref>. A holographic neuron holds a correlation matrix that enables memorizing stimulus-response associations. Individual associations are learned deterministically in one non-iterative transformation.
References-found: 29

