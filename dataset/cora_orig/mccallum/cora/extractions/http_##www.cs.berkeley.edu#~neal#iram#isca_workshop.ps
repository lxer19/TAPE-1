URL: http://www.cs.berkeley.edu/~neal/iram/isca_workshop.ps
Refering-URL: http://www.cs.berkeley.edu/~neal/iram/simIRAM.html
Root-URL: 
Email: fbowman,neal,kozyraki,cromer,helenjwg@cs.berkeley.edu  
Title: Evaluation of Existing Architectures in IRAM Systems  
Author: Ngeci Bowman, Neal Cardwell, Christoforos E. Kozyrakis, Cynthia Romer and Helen Wang 
Address: California-Berkeley  
Affiliation: Computer Science Division University of  
Abstract: Computer memory systems are increasingly a bottleneck limiting application performance. IRAM architectures, which integrate a CPU with DRAM main memory on a single chip, promise to remove this limitation by providing tremendous main memory bandwidth and significant reductions in memory latency. To determine whether existing microarchitectures can tap the potential performance advantages of IRAM systems, we examined both execution time analyses of existing microprocessors and system simulation of hypothetical processors. Our results indicate that, for current benchmarks, existing architectures, whether simple, superscalar or out-of-order, are unable to exploit IRAM's increased memory bandwidth and decreased memory latency to achieve significant performance benefits. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> SPEC CPU95 benchmarks. </institution> <address> http://www.specbench.org/ osg/cpu95/. </address>
Reference-contexts: SPEC 95 <ref> [1] </ref> is the current industry-accepted standard for uniprocessor performance evaluation. We used three of the floating point programs of the suite (tomcatv, su2cor, wave5) and all eight integer benchmarks. All SPEC 95 programs were compiled with base settings and run on the complete reference inputs.
Reference: [2] <author> BHANDARKAR, D., AND DING, J. </author> <title> Performance characterization of the Pentium Pro processor. </title> <booktitle> In Proceedings of the Third International Symposium on High-Performance Computer Architecture (February 1997). </booktitle>
Reference-contexts: This allowed us to compare the potential performance of the IRAM implementations to that of the originals. The two architectures examined in this study were the DEC Alpha 21064 [4] and the Intel Pentium Pro <ref> [2] </ref>. The Alpha 21064 uses a simple dual-issue, in-order execution organization with direct-mapped, blocking caches. By contrast, the Pentium Pro employs an aggressive triple-issue architecture, with out-of-order and speculative execution, a deeper pipeline, and 4-way set-associative, non-blocking caches. Table 2 summarizes the main characteristics of the two processors.
Reference: [3] <author> BOWMAN, N., CARDWELL, N., AND ROMER, C. </author> <title> The performance of Real Applications and Operating Systems on Simple IRAM Architectures. </title> <address> http://www.cs.berkeley.edu/~neal/iram/simIRAM.html. </address>
Reference-contexts: This is in part because the SPEC 95 applications fit well within the 2MByte L2 cache of the conventional machine, so that even the decreased memory latency of the IRAM implementations offers no significant advantage. A more complete discussion of the simulation results can be found at <ref> [3] </ref>. 6 Concluding Remarks Both the execution analysis and simulation approaches suggest that the potential performance benefits from using existing microarchitectures in IRAM systems are limited.
Reference: [4] <author> CVETANOVIC, Z., AND BHANDARKAR, D. </author> <title> Characterization of ALPHA AXP performance using TP and SPEC woarkloads. </title> <booktitle> In Proceedings of the 21st Annual International Symposium on Computer Architecture (April 1994), </booktitle> <pages> pp. 60-70. </pages>
Reference-contexts: This allowed us to compare the potential performance of the IRAM implementations to that of the originals. The two architectures examined in this study were the DEC Alpha 21064 <ref> [4] </ref> and the Intel Pentium Pro [2]. The Alpha 21064 uses a simple dual-issue, in-order execution organization with direct-mapped, blocking caches. By contrast, the Pentium Pro employs an aggressive triple-issue architecture, with out-of-order and speculative execution, a deeper pipeline, and 4-way set-associative, non-blocking caches. <p> The on-chip programmable hardware counters available in both processors were used to perform detailed profiling and measurements without affecting the program behavior <ref> [4] </ref>. The measurements included processor and memory hierarchy events like issue and stall cycles, branch mispredictions, TLB misses, and memory references and miss rates at each level of the memory hierarchy.
Reference: [5] <author> FROMM, R., ET AL. </author> <title> The Energy Efficiency of IRAM Architectures. </title> <booktitle> In the Proceedings of the 24th International Symposium on Computer Architecture (June 1997). </booktitle>
Reference-contexts: Second, since these access times for the on-chip main memory [8] can be comparable to that of SRAM L2 caches today, using die area for an L2 cache provides little performance improvement. This area can instead be used for on-chip DRAM, which is more than 10 times as dense <ref> [5] </ref>. Consequently, the IRAM systems we consider in this study have no L2 caches. Third, because main memory will be integrated on-chip, IRAM systems can be designed with memory busses as wide as desired. <p> Existing DRAM technology has been optimized for density and yield, so logic transistors and gates in DRAM processes are slower than those in corresponding logic processes. This can translate to a processor clock frequency up to 1.5 times slower than that of similar architectures implemented with conventional logic processes <ref> [5] </ref> [10]. Fortunately, highspeed logic in DRAM processes has already been demonstrated in prototype systems, so it is expected that within a few years logic in DRAM chips will be as fast as microprocessor logic. 3 Benchmarks and Applications Table 1 describes the benchmarks and applications used for this evaluation. <p> Our conventional machine uses the remaining on-chip area for a 2 MByte L2 SRAM cache, whereas an IRAM includes 24 MBytes of DRAM, which is treated as main memory. Since DRAM is approximately 16 to 32 times more dense than SRAM embedded on a microprocessor <ref> [5] </ref>, these areas should be roughly equal, again assuming a 256Mbit DRAM 0.25 m CMOS process. 5.1 Simulation Models Table 3 lists the parameters for the architectural models used in the simulations. <p> Still, using simple conventional architectures in IRAM systems has some advantages that are very important in certain areas. Simple, energy-efficient RISC processor cores combined with IRAM memory systems can be very energy-efficient <ref> [5] </ref>, which translates to longer battery life for portable systems. In addition, significant cost reduction derives from the higher integration level and smaller overall system area (system-on-a-chip).
Reference: [6] <author> HENNESSY, J., AND PATTERSON, D. </author> <title> Computer Archi--tecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, Inc, </publisher> <address> San Francisco, CA, </address> <year> 1996. </year>
Reference-contexts: Such evolutionary IRAM implementations will range from equally fast for CPU intensive applications up to two times faster in the best case for some memory-intensive applications. For comparison it is useful to note that conventional processors double in speed every 18 months <ref> [6] </ref>, so that similar speedups can be reached with conventional architecture and process technology improvements in less than two years, without requiring the modification to current integrated circuits fabrication and processing techniques that IRAM will entail.
Reference: [7] <author> HERROD, S., ET AL. </author> <title> The SimOS simulation environment. </title> <address> http://www-flash.stanford.edu/SimOS, Sept. </address> <year> 1996. </year>
Reference-contexts: latency advantages of IRAM we chose two values for IRAM main memory access latency, an optimistic one (21 ns) and a pessimistic one (33 ns). 5.2 Methodology To simulate these conventional and IRAM architectures we extended the 1.0 release of SimOS, a complete computer system simulation tool developed at Stanford <ref> [7] </ref> [11]. The standard version of SimOS 1.0 simulates a Silicon Graphics uniprocessor or multiprocessor workstation, including MIPS processors, two levels of cache, multiprocessor memory busses, memory, disk drives, consoles, and Ethernet devices, in enough detail to boot and run a slightly modified version of IRIX 5.3.
Reference: [8] <author> KOIKE, H., ET AL. </author> <title> A 30ns 64Mb DRAM with built-in self-test and repair function. </title> <booktitle> In Digest of Technical Papers, 1996 IEEE International SolidState Circuits Conference (San Francisco, </booktitle> <address> CA, </address> <month> Feb. </month> <year> 1996), </year> <pages> pp. 150-151, 270. </pages>
Reference-contexts: This is up to ten times faster than the main memory access times of current conventional systems. Second, since these access times for the on-chip main memory <ref> [8] </ref> can be comparable to that of SRAM L2 caches today, using die area for an L2 cache provides little performance improvement. This area can instead be used for on-chip DRAM, which is more than 10 times as dense [5].
Reference: [9] <author> KOZYRAKIS, C., AND WANG, H. </author> <title> Evaluation and Comparison of Existing Cache Designs Implemented as an IRAM. </title> <address> http://www.cs.berkeley.edu/~kozyraki/project/252/. </address>
Reference-contexts: Therefore, since most of the L1 cache misses for these programs are served by the Pentium Pro's L2 cache, the performance of IRAM implementations is lower than that of the conventional. A detailed description of this analysis and its results is presented at <ref> [9] </ref>. 5 Evaluating IRAM through Simulation In addition to evaluating IRAM implementations of two existing microarchitectures using performance measurements and analytic models, we simulated several simple IRAM systems to verify these results.
Reference: [10] <author> PATTERSON, D., ET AL. </author> <title> A Case for Intelligent RAM. </title> <booktitle> IEEE MICRO 17, </booktitle> <month> 2 (April </month> <year> 1997), </year> <pages> 34-44. </pages>
Reference-contexts: 1 Introduction One proposed solution to the growing gap between microprocessor performance and main memory latency is to integrate a processor and DRAM on the same die, an organization we refer to as Intelligent RAM (IRAM) <ref> [10] </ref>. Because all memory accesses remain on-chip and the memory bus width is no longer influenced by pin constraints, IRAM should improve main memory bandwidth by two orders of magnitude and main memory latency by one order of magnitude. <p> While this may not be sufficient by itself for high-end workstations, it is enough for low-end PCs and portable computers. The memory access time for such a system could can be as low as 21ns, since off-chip communication over high-capacity busses has been eliminated <ref> [10] </ref>. This is up to ten times faster than the main memory access times of current conventional systems. Second, since these access times for the on-chip main memory [8] can be comparable to that of SRAM L2 caches today, using die area for an L2 cache provides little performance improvement. <p> This can translate to a processor clock frequency up to 1.5 times slower than that of similar architectures implemented with conventional logic processes [5] <ref> [10] </ref>. Fortunately, highspeed logic in DRAM processes has already been demonstrated in prototype systems, so it is expected that within a few years logic in DRAM chips will be as fast as microprocessor logic. 3 Benchmarks and Applications Table 1 describes the benchmarks and applications used for this evaluation. <p> The fundamental reason for this limitation is the inability of today's conventional microarchitectures to take advantage of the phenomenal main memory bandwidth that becomes available on-chip in IRAM systems <ref> [10] </ref>. Current architectures have been developed under the implicit assumption that the connection with main memory has both high latency and low for the 500MHz conventional model with 116 ns main memory latency. Larger bars are better.
Reference: [11] <author> ROSENBLUM, M., ET AL. </author> <title> Complete computer system simulation: The SimOS approach. </title> <booktitle> In IEEE Parallel and Distributed Technology: Systems and Applications (Winter 1995), </booktitle> <volume> vol. 3, </volume> <pages> pp. 34-43. </pages>
Reference-contexts: advantages of IRAM we chose two values for IRAM main memory access latency, an optimistic one (21 ns) and a pessimistic one (33 ns). 5.2 Methodology To simulate these conventional and IRAM architectures we extended the 1.0 release of SimOS, a complete computer system simulation tool developed at Stanford [7] <ref> [11] </ref>. The standard version of SimOS 1.0 simulates a Silicon Graphics uniprocessor or multiprocessor workstation, including MIPS processors, two levels of cache, multiprocessor memory busses, memory, disk drives, consoles, and Ethernet devices, in enough detail to boot and run a slightly modified version of IRIX 5.3.
Reference: [12] <author> SAEKI, T., ET AL. </author> <title> A 2.5ns clock access 250MHz 256Mb SDRAM with a synchronous mirror delay. </title> <booktitle> In Digest of Technical Papers, 1996 IEEE International Solid-State Circuits Conference (San Francisco, </booktitle> <address> CA, </address> <month> Feb. </month> <year> 1996), </year> <pages> pp. 374-375. </pages>
Reference-contexts: For example the DEC Alpha 21164 processor, with 16KBytes of first level caches and 96KBytes of L2 cache, occupies 299mm 2 in a 0:5m CMOS process. In a 256Mbit DRAM 0:25m CMOS process <ref> [12] </ref>, this would take up approximately 75mm 2 , or one fourth of the die area. This allows up to 24MBytes of on-chip DRAM memory in the remaining area. While this may not be sufficient by itself for high-end workstations, it is enough for low-end PCs and portable computers.
References-found: 12

