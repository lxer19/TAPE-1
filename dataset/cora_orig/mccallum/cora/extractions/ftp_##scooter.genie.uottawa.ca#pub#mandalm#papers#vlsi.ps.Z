URL: ftp://scooter.genie.uottawa.ca/pub/mandalm/papers/vlsi.ps.Z
Refering-URL: http://www.mathsoft.com/wavelets.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: VLSI Implementation of Discrete Wavelet Transform  
Author: A. Grzeszczak, M. K. Mandal, S. Panchanathan, Member, IEEE, and T. Yeap, Member, IEEE 
Address: Ottawa, Ottawa, Canada K1N 6N5  
Affiliation: Visual Computing and Communications Laboratory Department of Electrical Engineering University of  
Note: IEEE Transactions on VLSI Systems Vol. 4, No. 4, pp.  N 10 samples/sec corresponding to a clock speed of N MHz.  
Email: email: tet@elg.uottawa.ca  
Phone: Tel. (613) 562-5800 .6219, Fax (613) 562-5175  
Date: 421-433, Dec 1996  
Abstract: This paper presents a VLSI implementation of discrete wavelet transform (DWT). The architecture is simple, modular, and cascadable for computation of one, or multidimensional DWT. It comprises of four basic units: input delay, filter, register bank, and control unit. The proposed architecture is systolic in nature and performs both high-pass and low-pass coefficient calculations with only one set of multipliers. In addition, it requires a small on-chip interface circuitry for interconnection to a standard communication bus. A detailed analysis of the effect of finite precision of data and wavelet filter coefficients on the accuracy of the DWT coefficients is presented. The architecture has been simulated in VLSI and has a hardware utilization efficiency of 87.5%. Being systolic in nature, the architecture can compute DWT at a data rate of 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> I. Daubechies, </author> <title> Orthonormal bases of compactly supported wavelets, </title> <journal> Comm. Pure Appl. Math, </journal> <volume> Vol. 41, </volume> <pages> pp. 906-966, </pages> <year> 1988 </year>
Reference: [2] <author> S. G. Mallat, </author> <title> A theory of multiresolution signal decomposition: the wavelet representation, </title> <journal> IEEE Trans. on Pattern Recognition and Machine Intelligence , Vol. </journal> <volume> 11, No. 7, </volume> <month> July </month> <year> 1989. </year>
Reference-contexts: The DWT coefficients can be obtained by taking the inner product between the input signal and the wavelet functions. Since, the basis functions are translated and dilated versions of each other, a simpler algorithm, known as Mallats tree algorithm or pyramid algorithm, has been proposed in <ref> [2] </ref>. <p> The entries in column 2, 3, and 5 provide the filter coefficients with the minimum phase, whereas entries in column 4 and 6 provide the filter coefficients with the least asymmetric phase. The 2-D DWT is usually calculated using a separable approach <ref> [2] </ref>. To start with, the 1-D DWT computation is performed on each row. This is followed by a matrix transposition operation [28]. Next, the DWT operation is executed on each row of the 2-D data.
Reference: [3] <author> M. Vetterli and C. Harley, </author> <title> Wavelets and filter banks: theory and design, </title> <journal> IEEE Transactions on Signal processing, </journal> <volume> Vol. 40, No. 9, </volume> <pages> pp. 2207-2232, </pages> <year> 1992 </year> . 
Reference: [4] <author> R. A. Gopinath, </author> <title> Wavelets and Filter Banks - New Results and Applications, </title> <type> Ph.D Dissertation, </type> <institution> Rice University, Houston, Texas, </institution> <year> 1993. </year>
Reference: [5] <author> Y. Meyer, </author> <title> Wavelets: Algorithms and Applications, </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1993. </year>
Reference: [6] <author> A. N. Akansu and R. A. Haddad, </author> <title> Multiresolution Signal Decomposition: Transform, Subbands and Wavelets, </title> <publisher> Academic Press Inc., </publisher> <year> 1992. </year>
Reference-contexts: One of the main contributions of wavelet theory is to relate the discrete time filterbank with the theory of continuous time function space. Typical applications of wavelets include signal processing <ref> [6] </ref>, [7], image processing [8]-[10], numerical analysis [11], statistics [12], biomedicine [13], etc. Wavelet transform offers a wide variety of useful features, in contrast to other transforms, such as Fourier transform or cosine transform. <p> Compactly supported wavelets are generally used in various applications. Table 1 lists a few orthonormal wavelet filter coefficients ( h n ( ) ) popular in compression applications <ref> [6] </ref>. These wavelets have the property of having the maximum number of vanishing moments for a given order, and are known as Daubechies wavelets.
Reference: [7] <author> O. Rioul and M. Vetterli, </author> <title> Wavelets and signal processing, </title> <journal> IEEE Signal processing Magazine, </journal> <pages> pp. 14-38, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: One of the main contributions of wavelet theory is to relate the discrete time filterbank with the theory of continuous time function space. Typical applications of wavelets include signal processing [6], <ref> [7] </ref>, image processing [8]-[10], numerical analysis [11], statistics [12], biomedicine [13], etc. Wavelet transform offers a wide variety of useful features, in contrast to other transforms, such as Fourier transform or cosine transform.
Reference: [8] <author> R. A. Devore, B. Jawerth and B. J. Lucier, </author> <title> Image compression through wavelet coding, </title> <journal> IEEE Trans. on Information Theory, </journal> <volume> Vol. 38, No. 2, </volume> <pages> pp. 719-746, </pages> <month> March </month> <year> 1992 </year> . 
Reference: [9] <author> M. Unser, </author> <title> Texture classification and segmentation using wavelet frames, </title> <journal> IEEE Trans. on Image processing, </journal> <volume> Vol. 4, No. 11, </volume> <pages> pp. 1549-1560, </pages> <month> Nov. </month> <year> 1995. </year> <month> 10 </month>
Reference: [10] <author> S. G. Mallat, </author> <title> "Multifrequency channel decompositions of images and wavelet models", </title> <journal> IEEE Trans. on Acoustics, Speech and Signal Processing, </journal> <volume> Vol. 37, No. 12, </volume> <pages> pp. 2091-2110, </pages> <month> Sept. </month> <year> 1989. </year>
Reference: [11] <author> G. Beylkin, R. R. Coifman and V. Rokhlin, </author> <booktitle> Wavelets in Numerical Analysis; in Wavelets and Their Applications, </booktitle> <pages> pp. 181-210, </pages> <publisher> Jones and bartlett, </publisher> <year> 1992. </year>
Reference-contexts: One of the main contributions of wavelet theory is to relate the discrete time filterbank with the theory of continuous time function space. Typical applications of wavelets include signal processing [6], [7], image processing [8]-[10], numerical analysis <ref> [11] </ref>, statistics [12], biomedicine [13], etc. Wavelet transform offers a wide variety of useful features, in contrast to other transforms, such as Fourier transform or cosine transform.
Reference: [12] <author> M. A. Stoksik, R. G. Lane and D. T. Nguyen, </author> <title> Accurate synthesis of fractional Brownian motion using wavelets, </title> <journal> Electronics Letters, </journal> <volume> Vol. 30, No. 5, </volume> <pages> pp. 383-384, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: One of the main contributions of wavelet theory is to relate the discrete time filterbank with the theory of continuous time function space. Typical applications of wavelets include signal processing [6], [7], image processing [8]-[10], numerical analysis [11], statistics <ref> [12] </ref>, biomedicine [13], etc. Wavelet transform offers a wide variety of useful features, in contrast to other transforms, such as Fourier transform or cosine transform.
Reference: [13] <author> L. Senhadji, G. Carrault, and J. J. Bellanger, </author> <title> Interictal EEG spike detection: A new framework based on wavelet transform, </title> <booktitle> Proc. of the IEEE-SP International Symposium on Time-Frequency and TimeScale Analysis, </booktitle> <pages> pp. 548-551, </pages> <address> Philadelphia, </address> <month> Oct </month> <year> 1994. </year>
Reference-contexts: One of the main contributions of wavelet theory is to relate the discrete time filterbank with the theory of continuous time function space. Typical applications of wavelets include signal processing [6], [7], image processing [8]-[10], numerical analysis [11], statistics [12], biomedicine <ref> [13] </ref>, etc. Wavelet transform offers a wide variety of useful features, in contrast to other transforms, such as Fourier transform or cosine transform.
Reference: [14] <author> O. Rioul and P. Duhamel, </author> <title> Fast algorithms for discrete and continuous wavelet transforms, </title> <journal> IEEE Trans. on Information Theory, </journal> <volume> Vol. 38, No. 2, </volume> <month> March </month> <year> 1992. </year>
Reference-contexts: We note that a simple polyphase decomposition has been assumed in the above calculation. The complexity can be further reduced using more sophisticated algorithms, such as FFT, first running FIR filtering <ref> [14] </ref>. However, these algorithms need complex control circuitry for hardware implementation and has hence not been considered in the proposed architecture. In many applications, a regular tree, instead of a dyadic tree, might be more appropriate. The computational complexity at each stage of a regular tree is 2 NL FLOP.
Reference: [15] <author> K. K. Parhi and T. Nishitani, </author> <title> VLSI architectures for discrete wavelet transforms, </title> <journal> IEEE Trans. on VLSI Systems, </journal> <pages> pp. 191-202, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: We note that in the 2-D case more stages (row and column) of DWT are involved, resulting in a decrease in the SNR (compared to 1-D case). 4. The Proposed Systolic Array Architecture A digit serial wavelet architecture using the pyramid algorithm was outlined in <ref> [15] </ref>. The proposed systolic array (DWT-SA) architecture is an improvement over the above architecture. Here, only one set of multipliers and adders has been employed, in contrast to two parallel computational hardware employed in [15]. <p> Proposed Systolic Array Architecture A digit serial wavelet architecture using the pyramid algorithm was outlined in <ref> [15] </ref>. The proposed systolic array (DWT-SA) architecture is an improvement over the above architecture. Here, only one set of multipliers and adders has been employed, in contrast to two parallel computational hardware employed in [15]. The multiplier and adder set performs all necessary computations to generate all highpass and lowpass coefficients. The DWT-SA architecture does not use any external or internal memory modules to store the intermediate results and therefore avoids the delays caused by memory access and memory refresh timing.
Reference: [16] <institution> Aware Wavelet Transform Processor (WTP) Preliminary, Aware Inc., </institution> <address> Cambridge, MA. </address>
Reference-contexts: The solutions include parallel filter architecture, SIMD linear array architecture, SIMD multigrid architecture [17], [19], 2-D block based architecture [20], and the AWARE's wavelet transform processor (WTP) <ref> [16] </ref>. The first three architectures, namely the parallel filter architecture, SIMD linear array architecture and the SIMD multigrid architecture, are special purpose parallel processors that implement the high level abstraction of the pyramid algorithm.
Reference: [17] <author> M. Vishwanath, </author> <title> Discrete wavelet transform in VLSI, </title> <booktitle> Proc. IEEE Int. Conf. Appl. Specific Array Processors. </booktitle> <pages> pp. 218-229, </pages> <year> 1992. </year>
Reference-contexts: The solutions include parallel filter architecture, SIMD linear array architecture, SIMD multigrid architecture <ref> [17] </ref>, [19], 2-D block based architecture [20], and the AWARE's wavelet transform processor (WTP) [16]. The first three architectures, namely the parallel filter architecture, SIMD linear array architecture and the SIMD multigrid architecture, are special purpose parallel processors that implement the high level abstraction of the pyramid algorithm.
Reference: [18] <author> K. K. Parhi, </author> <title> "Video data format converters using minimum number of registers", </title> <journal> IEEE Trans. on Circuits and Systems for Video Tech., </journal> <volume> vol. 38, </volume> <pages> pp. 255-267, </pages> <month> June </month> <year> 1992. </year>
Reference: [19] <author> C. Chakrabarti, M. Vishwanath and R. M. Owens, </author> <title> "Architectures for wavelet transforms", </title> <booktitle> Proc. IEEE VLSI Signal Processing Workshop. </booktitle> <pages> pp. 507-515, </pages> <year> 1993. </year>
Reference-contexts: The solutions include parallel filter architecture, SIMD linear array architecture, SIMD multigrid architecture [17], <ref> [19] </ref>, 2-D block based architecture [20], and the AWARE's wavelet transform processor (WTP) [16]. The first three architectures, namely the parallel filter architecture, SIMD linear array architecture and the SIMD multigrid architecture, are special purpose parallel processors that implement the high level abstraction of the pyramid algorithm.
Reference: [20] <author> Y. Kang, </author> <title> "Low-power design of wavelet processors", </title> <booktitle> Proc. of SPIE, </booktitle> <volume> vol. 2308, </volume> <pages> pp. 1800-1806, </pages> <year> 1993. </year>
Reference-contexts: Efficient VLSI implementation Since DWT requires intensive computations, several architectural solutions using special purpose parallel processor have been proposed [15]-<ref> [20] </ref> in order to meet the real time requirement in many applications. The solutions include parallel filter architecture, SIMD linear array architecture, SIMD multigrid architecture [17], [19], 2-D block based architecture [20], and the AWARE's wavelet transform processor (WTP) [16]. The first three architectures, namely the parallel filter architecture, SIMD linear array architecture and the SIMD multigrid architecture, are special purpose parallel processors that implement the high level abstraction of the pyramid algorithm.
Reference: [21] <author> A. Grzeszczak, </author> <title> VLSI Architecture for Discrete Wavelet Transform, M.A.Sc. </title> <type> thesis, </type> <institution> Department of Electrical Engineering, University of Ottawa, Canada, </institution> <year> 1995. </year>
Reference-contexts: Here, the user is required to input only the data stream and the high-pass and low-pass filter coefficients. 2 This paper presents a design and VLSI implementation of an efficient systolic array architecture for computing DWT <ref> [21] </ref>. The proposed VLSI architecture computes both highpass and lowpass frequency coefficients in the same clock cycle and thus has an efficient hardware utilization. The design is simple, modular, and cascadable for computation of 1-D or 2-D data streams of fairly arbitrary size. <p> The details of the schematic and the design of the transposer can be found in <ref> [21] </ref>, [28]. We note that the proposed architecture is a complete setup for computing forward DWT. <p> Subsequent coefficients are available at the output the pipeline every 8 clock cycles. The DWT coefficients are output from the final filter stage. 9 4.6 Simulation Results The proposed DWT-SA architecture, has been fully simulated in order to validate its functionality <ref> [21] </ref>. First, analog simulations on each small cell, and later digital simulations on the larger block and the final chip have been performed. The analog simulations were executed using the Hspice simulation tool, running under the Opus 4.2 design platform.
Reference: [22] <author> G. Knowles, </author> <title> "VLSI architecture for the discrete wavelet transform," </title> <journal> Electronics Letters, </journal> <volume> Vol. 26, No. 15, </volume> <pages> pp. 1184-1185, </pages> <month> Jul. </month> <year> 1990. </year>
Reference: [23] <author> M. Vishwanath, </author> <title> The recursive pyramid algorithm for the discrete wavelet transform, </title> <journal> IEEE Trans. on Signal Processing, </journal> <month> March </month> <year> 1994. </year>
Reference: [24] <author> A. D. Booth, </author> <title> "A signed binary multiplication technique", </title> <journal> Quarterly Journal of Mechanics and Applied Mathematics, </journal> <volume> Vol. 4, </volume> <pages> pp. 236-240, </pages> <year> 1951. </year>
Reference-contexts: In order to meet the real time requirements of applications such as video compression, a fast multiplier design is required. For this purpose, a high speed Booth multiplier <ref> [24] </ref> is used in the filter cell. The Booth multiplier uses a powerful algorithm for signed-number multiplication which treats both positive and negative numbers uniformly and is significantly faster than an array multiplier due to the reduced number of add stages required [24], [25]. <p> For this purpose, a high speed Booth multiplier <ref> [24] </ref> is used in the filter cell. The Booth multiplier uses a powerful algorithm for signed-number multiplication which treats both positive and negative numbers uniformly and is significantly faster than an array multiplier due to the reduced number of add stages required [24], [25]. The additional speedup is a result of using only half the number of adder stages The full adders and half adders employed inside the multiplier are variants of those described in [26].
Reference: [25] <author> G. J. Hekstra, </author> <title> Multiplier Architectures for VLSI Implementation, </title> <type> Technical Report No. 90-104, </type> <institution> Delft University of Technology, Netherlands, </institution> <month> Nov. </month> <year> 1990. </year>
Reference-contexts: The Booth multiplier uses a powerful algorithm for signed-number multiplication which treats both positive and negative numbers uniformly and is significantly faster than an array multiplier due to the reduced number of add stages required [24], <ref> [25] </ref>. The additional speedup is a result of using only half the number of adder stages The full adders and half adders employed inside the multiplier are variants of those described in [26].
Reference: [26] <author> N. Weste and K. Eshragian, </author> <title> Principles of CMOS VLSI Design, </title> <publisher> Addison-Wesley, </publisher> <month> June </month> <year> 1988. </year>
Reference-contexts: The additional speedup is a result of using only half the number of adder stages The full adders and half adders employed inside the multiplier are variants of those described in <ref> [26] </ref>. Both designs have been modified to reduce the carry out delay which is critical in achieving the fastest possible multiplication. 4.3 Storage Units Two storage units are used in the proposed architecture: Input Delay and Register Bank. <p> The data registers used in these storage units have been constructed from standard MasterSlave, Edge Triggered, D-type flip-flops <ref> [26] </ref>, [27]. The following presents the structure of each storage unit.
Reference: [27] <author> J. Cavanagh, </author> <title> Digital Computer Arithmetic, </title> <publisher> McGraw-Hill, </publisher> <year> 1984. </year>
Reference-contexts: The data registers used in these storage units have been constructed from standard MasterSlave, Edge Triggered, D-type flip-flops [26], <ref> [27] </ref>. The following presents the structure of each storage unit.

References-found: 27

