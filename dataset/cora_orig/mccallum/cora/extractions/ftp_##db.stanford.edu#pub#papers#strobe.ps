URL: ftp://db.stanford.edu/pub/papers/strobe.ps
Refering-URL: http://www.cs.toronto.edu/~mendel/dwbib.html
Root-URL: 
Email: fzhuge,hector,wienerg@cs.stanford.edu  
Title: The Strobe Algorithms for Multi-Source Warehouse Consistency  
Author: Yue Zhuge, Hector Garcia-Molina, and Janet L. Wiener 
Web: http://db.stanford.edu/warehouse  
Address: Stanford, CA 94305-2140, USA  
Affiliation: Computer Science Department Stanford University  
Abstract: A warehouse is a data repository containing integrated information for efficient querying and analysis. Maintaining the consistency of warehouse data is challenging, especially if the data sources are autonomous and views of the data at the warehouse span multiple sources. Transactions containing multiple updates at one or more sources, e.g., batch updates, complicate the consistency problem. In this paper we identify and discuss three fundamental transaction processing scenarios for data warehousing. We define four levels of consistency for warehouse data and present a new family of algorithms, the Strobe family, that maintain consistency as the warehouse is updated, under the various warehousing scenarios. All of the algorithms are incremental and can handle a continuous and overlapping stream of updates from the sources. Our implementation shows that the algorithms are practical and realistic choices for a wide variety of update scenarios. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Baralis, S. Ceri, and S. Paraboschi. </author> <title> Conservative timestamp revised for materialized view maintenance in a data warehouse. </title> <booktitle> In The Workshop on Materialized Views, </booktitle> <pages> pages 1-9, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: We consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; <ref> [1; 2] </ref>). Using a conventional incremental view maintenance algorithm [2], the following events may occur at the WH. 1. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . <p> It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. <p> The WH receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. Since the current view is empty, no action is taken for this deletion. 4. The WH receives A 2 1 = [1; 2; 3; 4] from source z, which is the final answer for Q 1 . <p> The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. The WH receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. <p> The WH receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. This final view is incorrect. 2 In this example, the interleaving of query Q 1 with updates arriving from the sources causes the incorrect view. <p> The first way is to store copies of all relations at the warehouse. In our example, Q 1 could then be atomically evaluated at the warehouse, causing tuple <ref> [1; 2; 3; 4] </ref> to be added to M V . When U 2 arrives, the tuple is deleted from M V , yielding a correct final warehouse state. While this solution may be adequate for some applications, we believe it has several disadvantages. <p> In our example, the warehouse notes that deletion U 2 arrived at the warehouse while it was processing query Q 1 . Therefore, answer A 1 may contain some tuples that reflect the deleted r 1 tuple. Indeed, A 1 contains <ref> [1; 2; 3; 4] </ref>, which should not exist after [1; 2] was deleted from r 1 . Thus, the warehouse removes this tuple, leaving an empty answer. The materialized view is then left empty, which is the correct state after both updates take place. <p> Therefore, answer A 1 may contain some tuples that reflect the deleted r 1 tuple. Indeed, A 1 contains [1; 2; 3; 4], which should not exist after <ref> [1; 2] </ref> was deleted from r 1 . Thus, the warehouse removes this tuple, leaving an empty answer. The materialized view is then left empty, which is the correct state after both updates take place. <p> We compare our definition of consistency with theirs in Section 4. Another recent paper by Baralis, et al. <ref> [1] </ref> also uses timestamps to maintain materialized views at a warehouse. However, they assume that the warehouse never needs to query the sources for more data, hence circumventing all of the consistency problems that we address. A warehouse often processes updates (from one or more transactions) in batch mode. <p> Initially, the relations are A B B C C D The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; <ref> [1; 2] </ref>), and apply the Strobe algorithm. 1. AL = h i. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . <p> It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> The WH receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. It first adds U 2 to pending (Q 1 ) and then adds key delete (M V; U 2 ) to AL. The re sulting AL = hkey delete (M V; U 2 )i. 4. <p> It first adds U 2 to pending (Q 1 ) and then adds key delete (M V; U 2 ) to AL. The re sulting AL = hkey delete (M V; U 2 )i. 4. The WH receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z. Since pending (Q) is not empty, the WH applies key delete (A 2 1 ; U 2 ) and the resulting answer A 2 = ;. Therefore, nothing is added to AL. <p> Assume attribute A is the key of relation r 1 . Originally, the relation is: r 1 = A B . Initially M V = (<ref> [1; 2] </ref>). We consider one source transaction: T 1 = hdelete (r 1 ; [1; 2]); insert (r 1 ; [3; 4])i. When the Strobe algorithm is applied to this scenario, the warehouse firsts adds the deletion to AL. <p> Initially, the relations are r 1 : 1 2 r 2 : - r 3 : 3 4 The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; <ref> [1; 2] </ref>), and apply the C-Strobe algorithm. There are two possible orderings of events at the warehouse. Here we consider one, and in the next example we discuss the other. 1. Delta = ;. The WH receives from source y U 1 = insert (r 2 ; [2; 3]). <p> It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1;1;0 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 4. <p> To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1;1;0 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 4. <p> The WH receives A 1 1;1;0 = [1; 2; 3] from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. It saves this update in a queue. 4. The WH receives A 1;1;0 = A 2 1;1;0 = ([1; 2; 3; 4]) from source z, which is the final answer to Q 1;1;0 . <p> Since U 2 was received between Q 1;1;0 and A 1;1;0 and it is a deletion, the WH generates a query Q 1;2;1 = <ref> [1; 2] </ref> ./ [2; 3] ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta, so Delta = ([1; 2; 3; 4]). 5. The WH receives A 1;2;1 = ([1; 2; 3; 4]) and tries to add it to Delta. <p> It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. It saves this update in a queue. 3. The WH receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. <p> It saves this update in a queue. 3. The WH receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. Since U 2 was received between Q 1;1;0 and A 1;1;0 , the WH generates the compensating query Q 1;2;1 = <ref> [1; 2] </ref> ./ [2; 3] ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta and Delta is still empty. 4. The WH receives A 1;2;1 = ([1; 2; 3; 4]) and adds it to Delta. Delta = ([1; 2; 3; 4]). 5.
Reference: [2] <author> J. Blakeley, P.-A. Larson, and F. Tompa. </author> <title> Efficiently updating materialized views. </title> <booktitle> In SIGMOD, </booktitle> <pages> pages 61-71, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: Initially, the relations are r 1 : 1 2 r 2 : - r 3 : 3 4 The materialized view at the warehouse is M V = ;. We consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]). Using a conventional incremental view maintenance algorithm [2], the following events may occur at the WH. 1. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. <p> We consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; <ref> [1; 2] </ref>). Using a conventional incremental view maintenance algorithm [2], the following events may occur at the WH. 1. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . <p> We consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; [1; 2]). Using a conventional incremental view maintenance algorithm <ref> [2] </ref>, the following events may occur at the WH. 1. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . <p> consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]). Using a conventional incremental view maintenance algorithm [2], the following events may occur at the WH. 1. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. <p> Using a conventional incremental view maintenance algorithm [2], the following events may occur at the WH. 1. The WH receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = [1; 2; 3] from source x. <p> The WH receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. <p> It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. <p> The WH receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. Since the current view is empty, no action is taken for this deletion. 4. The WH receives A 2 1 = [1; 2; 3; 4] from source z, which is the final answer for Q 1 . <p> The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. The WH receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. <p> The WH receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. This final view is incorrect. 2 In this example, the interleaving of query Q 1 with updates arriving from the sources causes the incorrect view. <p> The first way is to store copies of all relations at the warehouse. In our example, Q 1 could then be atomically evaluated at the warehouse, causing tuple <ref> [1; 2; 3; 4] </ref> to be added to M V . When U 2 arrives, the tuple is deleted from M V , yielding a correct final warehouse state. While this solution may be adequate for some applications, we believe it has several disadvantages. <p> In our example, the warehouse notes that deletion U 2 arrived at the warehouse while it was processing query Q 1 . Therefore, answer A 1 may contain some tuples that reflect the deleted r 1 tuple. Indeed, A 1 contains <ref> [1; 2; 3; 4] </ref>, which should not exist after [1; 2] was deleted from r 1 . Thus, the warehouse removes this tuple, leaving an empty answer. The materialized view is then left empty, which is the correct state after both updates take place. <p> Therefore, answer A 1 may contain some tuples that reflect the deleted r 1 tuple. Indeed, A 1 contains [1; 2; 3; 4], which should not exist after <ref> [1; 2] </ref> was deleted from r 1 . Thus, the warehouse removes this tuple, leaving an empty answer. The materialized view is then left empty, which is the correct state after both updates take place. <p> Furthermore, they offer a variety of consistency levels that are useful in the context of warehousing. Many incremental view maintenance algorithms have been developed for centralized database systems, e.g., <ref> [2, 9, 5] </ref> and a good overview of materialized views and their maintenance can be found in [8]. <p> As we showed in Example 1, when a centralized algorithm is applied to the warehouse, the warehouse user may see inconsistent views of the source data. These inconsistent views arise regardless of whether the centralized algorithm computes changes using the old base relations, as in <ref> [2] </ref>, or using the new base relations, as in [5]. The crux of the warehouse problem is that the exact state of the base relations (old or new) when the incremental changes are computed at the sources is unknown, and our algorithms filter out or add in recent modifications dynamically. <p> Initially, the relations are A B B C C D The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the Strobe algorithm. 1. AL = h i. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 <p> Initially, the relations are A B B C C D The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; <ref> [1; 2] </ref>), and apply the Strobe algorithm. 1. AL = h i. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . <p> We again consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the Strobe algorithm. 1. AL = h i. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. <p> insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the Strobe algorithm. 1. AL = h i. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = [1; 2; 3] from source x. <p> The WH receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. <p> It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> The WH receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. It first adds U 2 to pending (Q 1 ) and then adds key delete (M V; U 2 ) to AL. The re sulting AL = hkey delete (M V; U 2 )i. 4. <p> It first adds U 2 to pending (Q 1 ) and then adds key delete (M V; U 2 ) to AL. The re sulting AL = hkey delete (M V; U 2 )i. 4. The WH receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z. Since pending (Q) is not empty, the WH applies key delete (A 2 1 ; U 2 ) and the resulting answer A 2 = ;. Therefore, nothing is added to AL. <p> Assume attribute A is the key of relation r 1 . Originally, the relation is: r 1 = A B . Initially M V = (<ref> [1; 2] </ref>). We consider one source transaction: T 1 = hdelete (r 1 ; [1; 2]); insert (r 1 ; [3; 4])i. When the Strobe algorithm is applied to this scenario, the warehouse firsts adds the deletion to AL. <p> Initially, the relations are r 1 : 1 2 r 2 : - r 3 : 3 4 The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the C-Strobe algorithm. There are two possible orderings of events at the warehouse. Here we consider one, and in the next example we discuss the other. 1. Delta = ;. <p> Initially, the relations are r 1 : 1 2 r 2 : - r 3 : 3 4 The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; [2; 3]) and U 2 = delete (r 1 ; <ref> [1; 2] </ref>), and apply the C-Strobe algorithm. There are two possible orderings of events at the warehouse. Here we consider one, and in the next example we discuss the other. 1. Delta = ;. The WH receives from source y U 1 = insert (r 2 ; [2; 3]). <p> There are two possible orderings of events at the warehouse. Here we consider one, and in the next example we discuss the other. 1. Delta = ;. The WH receives from source y U 1 = insert (r 2 ; <ref> [2; 3] </ref>). It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. <p> Here we consider one, and in the next example we discuss the other. 1. Delta = ;. The WH receives from source y U 1 = insert (r 2 ; <ref> [2; 3] </ref>). It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1;1;0 = [1; 2; 3] from source x. <p> The WH receives from source y U 1 = insert (r 2 ; <ref> [2; 3] </ref>). It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1;1;0 = [1; 2; 3] from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. <p> It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1;1;0 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 4. <p> To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1;1;0 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 4. <p> The WH receives A 1 1;1;0 = [1; 2; 3] from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. It saves this update in a queue. 4. The WH receives A 1;1;0 = A 2 1;1;0 = ([1; 2; 3; 4]) from source z, which is the final answer to Q 1;1;0 . <p> Since U 2 was received between Q 1;1;0 and A 1;1;0 and it is a deletion, the WH generates a query Q 1;2;1 = <ref> [1; 2] </ref> ./ [2; 3] ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta, so Delta = ([1; 2; 3; 4]). 5. The WH receives A 1;2;1 = ([1; 2; 3; 4]) and tries to add it to Delta. <p> Since U 2 was received between Q 1;1;0 and A 1;1;0 and it is a deletion, the WH generates a query Q 1;2;1 = [1; 2] ./ <ref> [2; 3] </ref> ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta, so Delta = ([1; 2; 3; 4]). 5. The WH receives A 1;2;1 = ([1; 2; 3; 4]) and tries to add it to Delta. <p> We now consider a different set of events at the WH. 1. Delta = ;. The WH receives from source y U 1 = insert (r 2 ; <ref> [2; 3] </ref>). It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. <p> We now consider a different set of events at the WH. 1. Delta = ;. The WH receives from source y U 1 = insert (r 2 ; <ref> [2; 3] </ref>). It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> The WH receives from source y U 1 = insert (r 2 ; <ref> [2; 3] </ref>). It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 3. The WH receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. <p> It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives U 2 = delete (r 1 ; <ref> [1; 2] </ref>) from source x. It saves this update in a queue. 3. The WH receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. <p> It saves this update in a queue. 3. The WH receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. Since U 2 was received between Q 1;1;0 and A 1;1;0 , the WH generates the compensating query Q 1;2;1 = <ref> [1; 2] </ref> ./ [2; 3] ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta and Delta is still empty. 4. The WH receives A 1;2;1 = ([1; 2; 3; 4]) and adds it to Delta. Delta = ([1; 2; 3; 4]). 5. <p> The WH receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. Since U 2 was received between Q 1;1;0 and A 1;1;0 , the WH generates the compensating query Q 1;2;1 = [1; 2] ./ <ref> [2; 3] </ref> ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta and Delta is still empty. 4. The WH receives A 1;2;1 = ([1; 2; 3; 4]) and adds it to Delta. Delta = ([1; 2; 3; 4]). 5. <p> Given these costs, users can now determine what is best for them, given their consistency requirements and their transactional scenario. Third, when updates arrive infrequently at the warehouse, or only in periodic batches with large gaps in between, the Strobe algorithms are as efficient as conventional algorithms such as <ref> [2] </ref>. They only introduce extra complexity when updates must be processed while other updates are arriving at the warehouse, which is when conventional algorithms cannot guarantee a consistent view.
Reference: [3] <author> Y. Breitbart, H. Garcia-Molina, and A. Silber-schatz. </author> <title> Overview of multidatabase transaction management. </title> <journal> VLDB Journal, </journal> <volume> 1(2) </volume> <pages> 181-239, </pages> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: Initially, the relations are r 1 : 1 2 r 2 : - r 3 : 3 4 The materialized view at the warehouse is M V = ;. We consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]). Using a conventional incremental view maintenance algorithm [2], the following events may occur at the WH. 1. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. <p> consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]). Using a conventional incremental view maintenance algorithm [2], the following events may occur at the WH. 1. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. <p> Using a conventional incremental view maintenance algorithm [2], the following events may occur at the WH. 1. The WH receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = [1; 2; 3] from source x. <p> The WH receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. <p> It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. <p> The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. The WH receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. <p> The WH receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. This final view is incorrect. 2 In this example, the interleaving of query Q 1 with updates arriving from the sources causes the incorrect view. <p> The first way is to store copies of all relations at the warehouse. In our example, Q 1 could then be atomically evaluated at the warehouse, causing tuple <ref> [1; 2; 3; 4] </ref> to be added to M V . When U 2 arrives, the tuple is deleted from M V , yielding a correct final warehouse state. While this solution may be adequate for some applications, we believe it has several disadvantages. <p> In our example, the warehouse notes that deletion U 2 arrived at the warehouse while it was processing query Q 1 . Therefore, answer A 1 may contain some tuples that reflect the deleted r 1 tuple. Indeed, A 1 contains <ref> [1; 2; 3; 4] </ref>, which should not exist after [1; 2] was deleted from r 1 . Thus, the warehouse removes this tuple, leaving an empty answer. The materialized view is then left empty, which is the correct state after both updates take place. <p> A warehouse holds a copy of the source data, so essentially we have a distributed database system with replicated data. However, because of the autonomy of the sources, traditional concurrency mechanisms are often not applicable <ref> [3] </ref>. A variety of concurrency control schemes have been suggested over the years for such environments. They either provide weaker notions of consistency, e.g., [6], or exploit the semantics of applications. <p> Initially, the relations are A B B C C D The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the Strobe algorithm. 1. AL = h i. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 <p> We again consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the Strobe algorithm. 1. AL = h i. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. <p> insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the Strobe algorithm. 1. AL = h i. The WH receives U 1 = insert (r 2 ; [2; 3]) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = [1; 2; 3] from source x. <p> The WH receives U 1 = insert (r 2 ; <ref> [2; 3] </ref>) from source y. It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = [1; 2; 3] from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. <p> It generates query Q 1 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> To evaluate Q 1 , the WH first sends query Q 1 1 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> It first adds U 2 to pending (Q 1 ) and then adds key delete (M V; U 2 ) to AL. The re sulting AL = hkey delete (M V; U 2 )i. 4. The WH receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z. Since pending (Q) is not empty, the WH applies key delete (A 2 1 ; U 2 ) and the resulting answer A 2 = ;. Therefore, nothing is added to AL. <p> Assume attribute A is the key of relation r 1 . Originally, the relation is: r 1 = A B . Initially M V = ([1; 2]). We consider one source transaction: T 1 = hdelete (r 1 ; [1; 2]); insert (r 1 ; <ref> [3; 4] </ref>)i. When the Strobe algorithm is applied to this scenario, the warehouse firsts adds the deletion to AL. <p> Initially, the relations are r 1 : 1 2 r 2 : - r 3 : 3 4 The materialized view M V = ;. We again consider two source updates: U 1 = insert (r 2 ; <ref> [2; 3] </ref>) and U 2 = delete (r 1 ; [1; 2]), and apply the C-Strobe algorithm. There are two possible orderings of events at the warehouse. Here we consider one, and in the next example we discuss the other. 1. Delta = ;. <p> There are two possible orderings of events at the warehouse. Here we consider one, and in the next example we discuss the other. 1. Delta = ;. The WH receives from source y U 1 = insert (r 2 ; <ref> [2; 3] </ref>). It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. <p> Here we consider one, and in the next example we discuss the other. 1. Delta = ;. The WH receives from source y U 1 = insert (r 2 ; <ref> [2; 3] </ref>). It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1;1;0 = [1; 2; 3] from source x. <p> The WH receives from source y U 1 = insert (r 2 ; <ref> [2; 3] </ref>). It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1;1;0 = [1; 2; 3] from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. <p> It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1;1;0 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 4. <p> To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives A 1 1;1;0 = <ref> [1; 2; 3] </ref> from source x. Query Q 2 1;1;0 = [1; 2; 3] ./ r 3 is sent to source z for evaluation. 3. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 4. <p> Since U 2 was received between Q 1;1;0 and A 1;1;0 and it is a deletion, the WH generates a query Q 1;2;1 = [1; 2] ./ <ref> [2; 3] </ref> ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta, so Delta = ([1; 2; 3; 4]). 5. The WH receives A 1;2;1 = ([1; 2; 3; 4]) and tries to add it to Delta. <p> We now consider a different set of events at the WH. 1. Delta = ;. The WH receives from source y U 1 = insert (r 2 ; <ref> [2; 3] </ref>). It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. <p> We now consider a different set of events at the WH. 1. Delta = ;. The WH receives from source y U 1 = insert (r 2 ; <ref> [2; 3] </ref>). It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. <p> The WH receives from source y U 1 = insert (r 2 ; <ref> [2; 3] </ref>). It generates query Q 1;1;0 = r 1 ./ [2; 3] ./ r 3 . To evaluate Q 1;1;0 , the WH first sends query Q 1 1;1;0 = r 1 ./ [2; 3] to source x. 2. The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. It saves this update in a queue. 3. The WH receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. <p> The WH receives A 1 1;1;0 = ; from source x. This implies that A 1;1;0 = ;. Since U 2 was received between Q 1;1;0 and A 1;1;0 , the WH generates the compensating query Q 1;2;1 = [1; 2] ./ <ref> [2; 3] </ref> ./ r 3 and sends it to source z. Also, it adds A 1;1;0 to Delta and Delta is still empty. 4. The WH receives A 1;2;1 = ([1; 2; 3; 4]) and adds it to Delta. Delta = ([1; 2; 3; 4]). 5.
Reference: [4] <author> M. Cochinwala and J. Bradley. </author> <title> A multidatabase system for tracking and retrieval of financial data. </title> <booktitle> In VLDB, </booktitle> <pages> pages 714-721, </pages> <year> 1994. </year>
Reference-contexts: The WH receives U 2 = delete (r 1 ; [1; 2]) from source x. Since the current view is empty, no action is taken for this deletion. 4. The WH receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. <p> The WH receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z, which is the final answer for Q 1 . Since there are no pending queries or updates, the answer is inserted into M V and M V = [1; 2; 3; 4]. This final view is incorrect. 2 In this example, the interleaving of query Q 1 with updates arriving from the sources causes the incorrect view. <p> The first way is to store copies of all relations at the warehouse. In our example, Q 1 could then be atomically evaluated at the warehouse, causing tuple <ref> [1; 2; 3; 4] </ref> to be added to M V . When U 2 arrives, the tuple is deleted from M V , yielding a correct final warehouse state. While this solution may be adequate for some applications, we believe it has several disadvantages. <p> In our company example, we would need to update the stock prices of all companies, as the prices change. This can represent a very high update load <ref> [4] </ref>, much of it to data we may never need. Third, due to cost, copyright, or security, storing copies of all of the source data may not be feasible. For example, the source access charges may be proportional to the amount of data we track at the warehouse. <p> In our example, the warehouse notes that deletion U 2 arrived at the warehouse while it was processing query Q 1 . Therefore, answer A 1 may contain some tuples that reflect the deleted r 1 tuple. Indeed, A 1 contains <ref> [1; 2; 3; 4] </ref>, which should not exist after [1; 2] was deleted from r 1 . Thus, the warehouse removes this tuple, leaving an empty answer. The materialized view is then left empty, which is the correct state after both updates take place. <p> It first adds U 2 to pending (Q 1 ) and then adds key delete (M V; U 2 ) to AL. The re sulting AL = hkey delete (M V; U 2 )i. 4. The WH receives A 2 1 = <ref> [1; 2; 3; 4] </ref> from source z. Since pending (Q) is not empty, the WH applies key delete (A 2 1 ; U 2 ) and the resulting answer A 2 = ;. Therefore, nothing is added to AL. <p> Assume attribute A is the key of relation r 1 . Originally, the relation is: r 1 = A B . Initially M V = ([1; 2]). We consider one source transaction: T 1 = hdelete (r 1 ; [1; 2]); insert (r 1 ; <ref> [3; 4] </ref>)i. When the Strobe algorithm is applied to this scenario, the warehouse firsts adds the deletion to AL.
Reference: [5] <author> L. Colby, T. Griffin, L. Libkin, I. Mumick, and H. Trickey. </author> <title> Algorithms for deferred view maintenance. </title> <booktitle> In SIGMOD, </booktitle> <pages> pages 469-480, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Furthermore, they offer a variety of consistency levels that are useful in the context of warehousing. Many incremental view maintenance algorithms have been developed for centralized database systems, e.g., <ref> [2, 9, 5] </ref> and a good overview of materialized views and their maintenance can be found in [8]. <p> These inconsistent views arise regardless of whether the centralized algorithm computes changes using the old base relations, as in [2], or using the new base relations, as in <ref> [5] </ref>. The crux of the warehouse problem is that the exact state of the base relations (old or new) when the incremental changes are computed at the sources is unknown, and our algorithms filter out or add in recent modifications dynamically.
Reference: [6] <author> R. Gallersdorfer and M. Nicola. </author> <title> Improving performance in replicated databases through relaxed coherency. </title> <booktitle> In VLDB, </booktitle> <pages> pages 445-456, </pages> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: However, because of the autonomy of the sources, traditional concurrency mechanisms are often not applicable [3]. A variety of concurrency control schemes have been suggested over the years for such environments. They either provide weaker notions of consistency, e.g., <ref> [6] </ref>, or exploit the semantics of applications. The algorithms we present in this paper exploit the semantics of materialized view maintenance to obtain consistency without traditional distributed concurrency control. Furthermore, they offer a variety of consistency levels that are useful in the context of warehousing.
Reference: [7] <author> R. Goldring and B. Hamel, </author> <month> Jan. </month> <year> 1996. </year> <title> Personal correspondence about IBM's data warehouse customer needs. </title>
Reference-contexts: Furthermore, as more and more updates occur, the down time window may no longer be sufficient to process all of the updates <ref> [7] </ref>. Thus, there is substantial interest in warehouses that can absorb incoming updates and incrementally modify the materialized views at the warehouse, without halting query processing. In this paper we focus on this process and on how to ensure that queries see consistent data. <p> Note that as concurrent query and update processing at warehouses becomes more common, and as warehouse applications grow beyond "statistical analysis," there will be more concern from users about the consistency of the data they are accessing <ref> [7] </ref>. Thus, we believe it is important to offer customers a variety of consistency options and ways to enforce them. 3. We develop the Strobe family of algorithms to provide consistency for each of the transaction scenarios.
Reference: [8] <author> A. Gupta and I. Mumick. </author> <title> Maintenance of materialized views: Problems, techniques, </title> <journal> and applications. IEEE Data Engineering Bulletin, </journal> <volume> 18(2) </volume> <pages> 3-18, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Furthermore, they offer a variety of consistency levels that are useful in the context of warehousing. Many incremental view maintenance algorithms have been developed for centralized database systems, e.g., [2, 9, 5] and a good overview of materialized views and their maintenance can be found in <ref> [8] </ref>. Most of these solutions assume that a single system controls all of the base relations and understands the views and hence can intelligently monitor activities and compute all of the information that is needed for updating the views. <p> Further discussion of how to treat a modification as an insert and a delete may be found in <ref> [8] </ref>. 5.2 Strobe The Strobe algorithm processes updates as they arrive, sending queries to the sources when necessary. However, the updates are not performed immediately on the materialized view M V ; instead, we generate a list of actions AL to be performed on the view.
Reference: [9] <author> A. Gupta, I. Mumick, and V. Subrahmanian. </author> <title> Maintaining views incrementally. </title> <booktitle> In SIGMOD, </booktitle> <pages> pages 157-166, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Furthermore, they offer a variety of consistency levels that are useful in the context of warehousing. Many incremental view maintenance algorithms have been developed for centralized database systems, e.g., <ref> [2, 9, 5] </ref> and a good overview of materialized views and their maintenance can be found in [8].
Reference: [10] <author> R. Hull and G. Zhou. </author> <title> A framework for supporting data integration using the materialized and virtual approaches. </title> <booktitle> In SIGMOD, </booktitle> <pages> pages 481-492, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Previous distributed algorithms for view maintenance, such as those in [14, 12], rely on timestamping the updated tuples. For a warehousing environment, sources can be legacy systems so we cannot assume that they will help by transmitting all necessary data or by attaching timestamps. Hull and Zhou <ref> [10] </ref> provide a framework for supporting distributed data integration using materialized views. However, their approach first materializes each base relation (or relevant portion), then computes the view from the materialized copies; on the other hand, we propose algorithms to maintain joined views directly, without storing any auxiliary data. <p> That is, there is a complete order-preserving mapping between the states of the view and the states of the sources. Hull and Zhou's definition of consistency for replicated data <ref> [10] </ref> is similar to our strong consistency, except that they also require global timestamps across sources, which we do not. Also, our strong consis-tency is less restrictive than theirs in that we do not require any fixed order between two non-conflicting actions. Our definition is compatible with standard serializability theory.
Reference: [11] <author> W. Inmon and C. Kelley. Rdb/VMS: </author> <title> Developing the Data Warehouse. </title> <publisher> QED Publishing Group, </publisher> <address> Boston, Massachusetts, </address> <year> 1993. </year>
Reference-contexts: We discuss each in turn. Data warehouses are large repositories for analytical data, and have recently generated tremendous interest in industry. A general description of the data warehousing idea may be found in <ref> [11] </ref>. Companies such as Red Brick and Prism have built specialized data warehousing software, while almost all other database vendors, such as Sybase, Oracle and IBM, are targeting their existing products to data warehousing applications.
Reference: [12] <author> B. Lindsay, L. Haas, C. Mohan, H. Pirahesh, and P. Wilms. </author> <title> A snapshot differential refresh algorithm. </title> <booktitle> In SIGMOD, </booktitle> <month> May </month> <year> 1986. </year>
Reference-contexts: Previous distributed algorithms for view maintenance, such as those in <ref> [14, 12] </ref>, rely on timestamping the updated tuples. For a warehousing environment, sources can be legacy systems so we cannot assume that they will help by transmitting all necessary data or by attaching timestamps. Hull and Zhou [10] provide a framework for supporting distributed data integration using materialized views.
Reference: [13] <author> D. Lomet and J. Widom, </author> <title> editors. Special Issue on Materialized Views and Data Warehousing, </title> <journal> IEEE Data Engineering Bulletin 18(2), </journal> <month> June </month> <year> 1995. </year>
Reference-contexts: At the warehouse, the integrator receives the source data, performs any necessary data integration or translation, adds any extra desired information, such as timestamps for historical analysis, and tells the warehouse to store the data. In effect, the warehouse caches a materialized view of the source data <ref> [13] </ref>. The data is then readily available to user applications for querying and analysis. Most current commercial warehousing systems (e.g., Prism, Redbrick) focus on storing the data for efficient access, and on providing extensive querying facilities at the warehouse.
Reference: [14] <author> A. Segev and J. Park. </author> <title> Updating distributed materialized views. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 1(2) </volume> <pages> 173-184, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Previous distributed algorithms for view maintenance, such as those in <ref> [14, 12] </ref>, rely on timestamping the updated tuples. For a warehousing environment, sources can be legacy systems so we cannot assume that they will help by transmitting all necessary data or by attaching timestamps. Hull and Zhou [10] provide a framework for supporting distributed data integration using materialized views.
Reference: [15] <institution> Sybase, Inc. </institution> <note> Command Reference Manual, release 4.9 edition, </note> <year> 1992. </year>
Reference-contexts: We assume that each single update transaction and source-local transaction is reported in one message, at the time that the transaction commits. For example, a relational database source might trigger sending a message on transaction commit <ref> [15] </ref>. However, batching multiple transactions into the same message does not affect the algorithms of Section 5. For global transactions, updates can be delivered in a variety of ways.
Reference: [16] <author> J. Wiener, H. Gupta, W. Labio, Y. Zhuge, H. Garcia-Molina, and J. Widom. </author> <title> A system prototype for warehouse view maintenance. </title> <booktitle> In The Workshop on Materialized Views, </booktitle> <pages> pages 26-33, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Thus, we believe it is important to offer customers a variety of consistency options and ways to enforce them. 3. We develop the Strobe family of algorithms to provide consistency for each of the transaction scenarios. We have implemented each of the Strobe algorithms in our warehouse prototype <ref> [16] </ref>, demonstrating that the algorithms are prac tical and efficient. 4. We map out the space of warehouse maintenance algorithms (Figure 2). The algorithms we present in this paper provide a wide number of options for this consistency and distribution space. The remainder of the paper is organized as follows. <p> Fourth, the Strobe algorithms are relatively inexpensive to implement, and we have incorporated them into the Whips (WareHousing Information Prototype at Stanford) prototype <ref> [16] </ref>. In our implementation, the Strobe algorithm is only 50 more lines of C++ code than the conventional view maintenance algorithm, and C-strobe is only another 50 lines of code. The core of each of the algorithms is about 400 lines of C++ code (not including evaluating each query).
Reference: [17] <author> Y. Zhuge, H. Garcia-Molina, J. Hammer, and J. Widom. </author> <title> View maintenance in a warehousing environment. </title> <booktitle> In SIGMOD, </booktitle> <pages> pages 316-327, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: They are substantially more complex than the ones presented here | another reason for including keys in the view.) In our previous work <ref> [17] </ref> we considered a very restricted scenario: all warehouse data arrived from a single source. Even in that simple case, there are consistency problems, and we developed algorithms for solving them. <p> Even in that simple case, there are consistency problems, and we developed algorithms for solving them. However, in the more realistic multi-source scenario, it becomes significantly more complex to maintain consistent views. (For instance, the ECA and ECA-Key algorithms of <ref> [17] </ref> do not provide consistency in Example 1; they lead to the same incorrect execution shown.) In particular, the complexities not covered in our earlier work are as follows. * An update from one source may need to be integrated with data from several other sources. <p> In this paper we present view maintenance algorithms that address these problems. Finally, as we mentioned in Section 1, in <ref> [17] </ref> we showed how to provide consistency in a restricted single-source environment. Here we study the more general case of multiple sources and transactions that may span sources. 3 Warehouse transaction environment The complexity of designing consistent warehouse algorithms is closely related to the scope of transactions at the sources. <p> We define four levels of consistency for warehouse views. Each level subsumes all prior levels. These definitions are a generalization of the ones in <ref> [17] </ref> for a multi-source warehouse environment. 1. Convergence: For all finite executions, V (ws f ) = V (ss q ). That is, after the last update and after all activity has ceased, the view is con sistent with the source data. 2. <p> Figure 2 summarizes the algorithms we discussed in this paper and their correctness. In the figure, "Conventional" refers to a conventional centralized view maintenance algo rithm, while "ECA" and "ECA-Key" are algorithms from <ref> [17] </ref>. Conv entional Single Update Local Trans.
Reference: [18] <author> Y. Zhuge, H. Garcia-Molina, and J. Wiener. </author> <title> The Strobe algorithms for multi-source warehouse consistency. </title> <type> Technical report, </type> <institution> Stan-ford University, </institution> <month> Sept. </month> <year> 1996. </year> <note> Available via anonymous ftp from host db.stanford.edu as pub/zhuge/1996/strobe-full.ps. </note>
Reference-contexts: For example, evaluating a query at a source and sending the answer back to the warehouse is considered one event. We assume events are atomic, and are ordered by the sequence of the corresponding actions. (In <ref> [18] </ref> we discuss what to do when this assumption does not hold.) We also assume that any two messages sent from one source to the warehouse are delivered in the same order as they were sent. (This can be enforced by numbering messages.) We place no restrictions on the order in <p> Our definition is compatible with standard serializability theory. In fact, our consistency definition can be rephrased in terms of serializability theory, by treating the warehouse view evaluation as a read only transaction at the sources <ref> [18] </ref>. Although completeness is a nice property since it states that the view "tracks" the base data exactly, we believe it may be too strong a requirement and unnecessary in most practical warehousing scenarios. <p> The Strobe algorithm provides strong consistency for all single-update transaction environments. A correctness proof is given in <ref> [18] </ref>. The intuition is that each time M V is modified, updates have quiesced and the view contents can be obtained by evaluating the view expression at the current source states. <p> On single-update transactions, T-Strobe reduces to the Strobe algorithm. 5.4 Global-strobe While the T-Strobe algorithm is strongly consistent for source-local transactions, it is only weakly consistent if global transactions are present. In <ref> [18] </ref> we present an example that illustrates this and develop a new algorithm, Global-Strobe (G-Strobe), that guarantees strong consistency for global transactions. <p> C-Strobe is complete because M V is updated once after each update, and the resulting warehouse state corresponds to the source state after the same update. We prove the correctness of C-Strobe in <ref> [18] </ref>.
References-found: 18

