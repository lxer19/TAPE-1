URL: http://www.apl.jhu.edu/~hall/text/Papers/Monterrey-Memoization.ps
Refering-URL: http://www.apl.jhu.edu/~hall/lisp.html
Root-URL: 
Email: hall@aplcenmp.apl.jhu.edu mayfield@cs.umbc.edu  
Phone: (410) 792-6000 x3440 (410) 455-3099  
Title: Improving the Performance of AI Software: Payoffs and Pitfalls in Using Automatic Memoization LISP code
Author: Marty Hall James Mayfield (gethash Args Hash-Table) 
Note: As a typographical convention throughout the paper,  (if Found?  This  
Address: PO Box 126 5401 Wilkens Ave. Hunt Valley, MD 21030 Baltimore, MD 21228  
Affiliation: Artificial Intelligence Laboratory Computer Science Department AAI Corporation University of Maryland Baltimore County  
Abstract: Many functions perform redundant calculations. Within a single function invocation, several sub-functions may be invoked with exactly the same arguments, or, over the course of time in a system run, a function may be invoked by different users or routines with the same or similar inputs. This observation leads to the obvious conclusion that in some cases it is beneficial to store the previously calculated values and only perform a calculation in situations that have not been seen previously. This technique is called memoization, and the manual version of this generally involves building lookup tables. This however, is often a tedious and time-consuming process, and requires significant modification and debugging of existing code. This is frequently inappropriate in the dynamic, rapid-prototyping context of AI software development. An automatic memoization facility is one in which existing functions can be programmatically changed to cache previously-seen results in a hash table. These results will then be returned when the functions are invoked with arguments they have seen previously. This can be done without changing the code, thus providing a simple, modular, and transparent way to dramatically accelerate certain types of functions. This paper presents an overview of automatic memoization and discusses the types of applications that benefit from it, illustrated with experiences on the ARPA Submarine Signature Management System, a large LISP-based decision aiding system. ming [6], which was in turn inspired by [1]. It takes a function as input and returns an equivalent function that performs lookup from a hash table. When called, this new function compares the argument to ones that it has recorded previously. If the argument has been seen before, the corresponding value in the hash table is returned. If it has not been seen previously, the original function is called with that argument, the return value is stored in the hash table with the argument as key, and then that value is returned. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Abelson, Harold, Sussman, Gerald Jay, and Sussman, Julie, </author> <title> Structure and Interpretation of Computer Programs, </title> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference: [2] <author> Cheney, Ward, and Kincaid, David, </author> <title> Numerical Mathematics and Computing, </title> <address> Brooks/Cole, </address> <year> 1980. </year>
Reference-contexts: By means of illustration, consider the following definition of Divided-Difference, which may be used to determine coefficients of interpolated polynomials. The algorithm is a standard one in numerical methods, taken directly from Numerical Mathematics and Computing <ref> [2] </ref>. The application is not particularly important; the point is that the recursive calls form a graph, not a tree, and calculations are repeated.
Reference: [3] <author> Cormen, Thomas, Leiserson, Charles, and Rivest, Ronald, </author> <title> Introduction to Algorithms, </title> <publisher> McGraw Hill and MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Given this, memoization can be viewed as a general and straightforward technique for automatic dynamic programming. Rather than tackling the difficult task of determining the proper order in which to build up sub-pieces, a simple solution can be memoized to get the same performance <ref> [3] </ref>. The question, then, becomes which approach is better: memoizing a less efficient algorithm or changing to an implementation that either uses a different algorithm or maintains special-purpose data structures? Clearly, automatic memoization is not meant to be a substitute for finding the proper algorithm for the task.
Reference: [4] <author> Knuth, Donald E., </author> <booktitle> The Art of Computer Programming, </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1969. </year>
Reference-contexts: Subsequent invocations take near-constant time. This type of repetition is common and is normally addressed by either determining a better calling sequence or building a special purpose data structure to store intermediate results. For instance, in Volume 2 (Seminumerical Algorithms) of The Art of Computer Programming <ref> [4] </ref>, Knuth presents a straightforward method for building up the divided differences in the proper order to get the same performance as the first invocation of the memoized version.
Reference: [5] <author> Michie, Donald, </author> <title> Memo Functions and Machine Learning, </title> <journal> Nature, </journal> <volume> 218 No. 1, </volume> <month> April </month> <year> 1968, </year> <pages> pp. 19-22. </pages>
Reference-contexts: Anonymous FTP is available from ftp.cs.umbc.edu (130.85.100.53), in /pub/Memoization. Requests for the sources can also be mailed to the author at hall@aplcenmp.apl.jhu.edu. 2. What is Automatic Memoization? The term memoization was first coined by Donald Michie <ref> [5] </ref> and refers to the process of tabulating results in order to prevent wasted calculations. Automatic memoization refers to a method by which an existing function can be changed into one that memoiz-es.
Reference: [6] <author> Norvig, Peter, </author> <title> Paradigms of AI Programming: Case Studies in Common LISP, </title> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference: [7] <author> Norvig, Peter, </author> <title> Techniques for Automatic Memoization with Applications to Context-Free Parsing, </title> <booktitle> Computational Linguistics, </booktitle> <year> 1991. </year>
Reference-contexts: Similarly, Peter Nor-vig shows that the performance of chart parsing or 1 2 3 N+ + + + Earleys algorithm can be obtained for parsing context--free languages by memoizing a simple recursive backtracking parser <ref> [7] </ref>. Given this, memoization can be viewed as a general and straightforward technique for automatic dynamic programming. Rather than tackling the difficult task of determining the proper order in which to build up sub-pieces, a simple solution can be memoized to get the same performance [3].
Reference: [8] <author> [Warrren, David S., </author> <title> Memoing for Logic Programs, </title> <journal> Communications of the ACM, </journal> <volume> 35 No 3, </volume> <month> March </month> <year> 1992, </year> <pages> pp. 93-111. </pages>
References-found: 8

