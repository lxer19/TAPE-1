URL: http://www.cs.ucsb.edu/oocsb/papers/oopsla93.ps
Refering-URL: http://www.csd.uu.se/~thomasl/wpo/oo-compilation-papers.html
Root-URL: 
Email: kjdriese@vnet3.vub.ac.be  
Title: Selector Table Indexing Sparse Arrays  
Author: Karel Driesen 
Address: Pleinlaan 2 B-1050 Brussels  
Affiliation: Programming Technology Lab Faculty of Sciences Vrije Universiteit Brussel  
Abstract: 0. Abstract 
Abstract-found: 1
Intro-found: 1
Reference: [ALB88] <author> M. O. Albertson, J. P. Hutchinson. </author> <title> Discrete Mathematics with Algorithms John Wiley & Sons (1988) </title>
Reference: [AND92] <author> P. Andr, J. C. Royer. </author> <title> Optimizing Method Search with Lookup Caches and Incremental Coloring, </title> <booktitle> OOPSLA'92 Proceedings p.110-126 </booktitle>
Reference-contexts: For our example, this gives 8.540, as opposed to the 295.414 entries of the masterarray. In terms of time, one reference indirection is added to the method lookup. 3.3. Selector coloring Selector coloring, first proposed in [DIX 89], and expanded for dynamically typed languages in <ref> [AND92] </ref>, offers a different way to optimize the selector table size. <p> The fill rate, given by the average number of understood messages per class, divided by K, was found to be 57%, comparable to our scheme, and consistent with the results given in <ref> [AND92] </ref>. 3.3.1 Resolving aliasing in selector coloring An issue not addressed in [AND92], but touched upon in [DIX 89], is the problem of aliasing of selectors. <p> The fill rate, given by the average number of understood messages per class, divided by K, was found to be 57%, comparable to our scheme, and consistent with the results given in <ref> [AND92] </ref>. 3.3.1 Resolving aliasing in selector coloring An issue not addressed in [AND92], but touched upon in [DIX 89], is the problem of aliasing of selectors. <p> When examining the performance of the two methods on special cases of inheritance, differences are blown up. On a tree structure (as in the Smalltalk example), both approaches behave similarly. Figure 7 lists other examples (terminology adopted from <ref> [AND92] </ref>). the Object hierarchy, when compared to simple selector table indexing . B b C c Branch A a Comb E e Apple A a The 'branch' case has no overhead for SA.
Reference: [AOE92] <author> J. I. Aoe, K. Morimoto, T. Sato. </author> <title> A n Efficient Implementation of Trie Structures Software-Practice and Experience, </title> <address> Vol.22(9), </address> <month> 695-721 (September </month> <year> 1992) </year>
Reference: [BRA90] <author> G. Bracha, W. Cook. </author> <booktitle> Mixin-based inheritance ECOOP/OOPSLA'90 Proceedings, p. </booktitle> <pages> 303-311 </pages>
Reference: [COD91] <author> W . C o d e n i e , P . S t e y a e r t , M . VanLimberghen AGORA, </author> <title> a short introduction, PROG internal report 1991 </title>
Reference-contexts: Whether this is still profitable is an open question. 5. Future and related work The work described in this paper is support for the Agora language, a prototype-based, object - oriented language employing mixin-based inheritance [STE93] <ref> [COD91] </ref>. A runtime version of selector table indexing with sparse arrays will be implemented in the near future for an experimental Agora to Scheme compiler [DHO93]. Runtime aspects of the technique, such as the performance of inline caching, combined with SA, will then be more thoroughly investigated.
Reference: [COX87] <author> B . J . C o x . Object Oriented Programming: </author> <title> An Evolutionary Approach, </title> <publisher> Addison-Wesley 1987 </publisher>
Reference: [DIX 89] <author> T. Dixon, M. Vaughan, P. Sweizer. </author> <title> A fast Method Dispatcher for Compiled Languages with Multiple Inheritance, </title> <booktitle> OOPSLA'89 Proceedings p.221-214 </booktitle>
Reference-contexts: For our example, this gives 8.540, as opposed to the 295.414 entries of the masterarray. In terms of time, one reference indirection is added to the method lookup. 3.3. Selector coloring Selector coloring, first proposed in <ref> [DIX 89] </ref>, and expanded for dynamically typed languages in [AND92], offers a different way to optimize the selector table size. <p> The fill rate, given by the average number of understood messages per class, divided by K, was found to be 57%, comparable to our scheme, and consistent with the results given in [AND92]. 3.3.1 Resolving aliasing in selector coloring An issue not addressed in [AND92], but touched upon in <ref> [DIX 89] </ref>, is the problem of aliasing of selectors. Since most color numbers are used by more than one selector, for each class there will exist selectors that are not understood by the class, but that have the same colornumber as a selector that is understood. <p> Without checking, a send of a selector s to a class C, with s not understood by C, can result in the execution of the method implementing selector r, understood by C, if color (s) = color (r). A solution suggested in <ref> [DIX 89] </ref> is to keep in each method a copy of the selectorcode to which it responds (as in 3.2.2), and to keep at each message send not only the colornumber of the selector, but also the selectorcode itself.
Reference: [DHO93] <author> T. D'Hondt, P. </author> <title> Steyaert The Design and Implementation of the Agora Environment PROG internal report 1993 </title>
Reference-contexts: A runtime version of selector table indexing with sparse arrays will be implemented in the near future for an experimental Agora to Scheme compiler <ref> [DHO93] </ref>. Runtime aspects of the technique, such as the performance of inline caching, combined with SA, will then be more thoroughly investigated. A formal treatment of the mentioned heuristics for table packing is being studied.
Reference: [DRI 87] <author> K. Driesen. </author> <note> Typesystemen in Smalltalk-80 Thesis 1987, </note> <institution> Faculty of Sciences, Vrije Universiteit Brussel </institution>
Reference: [DEU 84] <author> P. Deutch, A. Schiffman. </author> <title> E f f i c i e n t Implementation of the Smalltalk-80 System POPL Proceedings 1984 p. </title> <type> 297-302 </type>
Reference-contexts: from STI are also known as static caching, since a message is entered in the cache when it is defined, rather than when it is called (compile-time versus runtime). 5 We again assume that the implementation of a method table is such that memory comsumption is minimal. 6 Inline caching <ref> [DEU 84] </ref> can be considered a special form of caching in which the cache is distributed over the code. 3. Reducing the memory overhead of STI In this section, we will preserve the basic idea of STI, while reducing the memory cost. <p> Comparing sparse array STI & dynamic caching In the absence of hard performance data, an assesment of the expected efficiency of our technique is in order. The currently most used strategy to speed up method lookup in dynamically typed, object-oriented languages, is inline caching <ref> [DEU 84] </ref>, [UNG 87]. In this technique, a call to the method lookup routine is replaced (inline) by a direct call to the method which was called last time at that particular point.
Reference: [ELL 90] <author> M. A. Ellis, B. </author> <title> Stroustrup The Annotated C++ Reference Manual Addison-Wesley 1990 </title>
Reference: [GOL 83] <author> A. Goldberg, D. </author> <title> Robson Smalltalk-80: The Language and its Implementation Addison-Wesley 1983 </title>
Reference: [JOH 87] <author> R. </author> <booktitle> Johnson Workshop on Compiling and Optimizing ObjectOriented Programming Languages OOPSLA'87 Addendum to the Proceedings p. </booktitle> <pages> 57-66 </pages>
Reference-contexts: The next time the same pair is encountered, a lookup in the cache dictionary is performed. If the method is still resident, it is immediately executed. If not, a superclass-chain lookup is done. Hit rates as high as 95% have been obtained, rendering a substantial speedup in message calling <ref> [JOH 87] </ref>. However, due to the statistical nature of the speedup, this cannot be guaranteed in all possible cases. The memory overhead of this technique is equal to the size of the cache.
Reference: [KRA 83] <author> G. </author> <title> Krasner Smalltalk-80: Bits of History, Words of Advice Addison-Wesley 1983 </title>
Reference-contexts: The association of a class-selector pair to the implementing method amounts to indexing in an array, a constant-time operation. The memory requirements are enormous, however. If C is the number of classes, C*S is the memory used. Dynamic caching <ref> [KRA 83] </ref> is an effort to join the best of both worlds. Superclass-chain lookup is used the first time a message is sent at run time. The association of the class/selector pair and the acquired method is then entered in a dictionary, implemented for fast retrieval 6 (the cache).
Reference: [STE93] <author> P. Steyaert, W. Codenie, T. D'Hondt, K. De Hondt, C. Lucas, M. </author> <note> VanLimberghen Nested Mixin-Methods in Agora to be presented at ECOOP93 </note>
Reference-contexts: Whether this is still profitable is an open question. 5. Future and related work The work described in this paper is support for the Agora language, a prototype-based, object - oriented language employing mixin-based inheritance <ref> [STE93] </ref> [COD91]. A runtime version of selector table indexing with sparse arrays will be implemented in the near future for an experimental Agora to Scheme compiler [DHO93]. Runtime aspects of the technique, such as the performance of inline caching, combined with SA, will then be more thoroughly investigated.
Reference: [UNG 87] <author> D. M. </author> <title> Ungar The Design and Evaluation of a High Performance Smalltalk System An ACM Distinguished Dissertation 1986, </title> <publisher> MIT Press 1987 </publisher>
Reference-contexts: Comparing sparse array STI & dynamic caching In the absence of hard performance data, an assesment of the expected efficiency of our technique is in order. The currently most used strategy to speed up method lookup in dynamically typed, object-oriented languages, is inline caching [DEU 84], <ref> [UNG 87] </ref>. In this technique, a call to the method lookup routine is replaced (inline) by a direct call to the method which was called last time at that particular point. <p> On a hit, this scheme takes only three to four machine instructions, coming very close to the efficiency of procedure calling. SA takes six to seven instructions with the double masterarray. In <ref> [UNG 87] </ref>, the SOAR Smaltalk system spends 11% of its time in (inline) cache probes and another 12% handling misses. Since SA, by construction, does not have the latter overhead, we can tentatively assume that the runtime efficiency will approach that of inline caching.
References-found: 16

