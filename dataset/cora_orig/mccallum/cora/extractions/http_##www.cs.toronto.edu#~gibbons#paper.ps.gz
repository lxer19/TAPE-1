URL: http://www.cs.toronto.edu/~gibbons/paper.ps.gz
Refering-URL: http://www.cs.toronto.edu/~gibbons/
Root-URL: 
Email: gibbons@cs.ubc.ca  
Title: A Historical Application Profiler for Use by Parallel Schedulers  
Author: Richard Gibbons 
Address: 201-2366 Main Mall, Vancouver, B.C., Canada V6T 1Z4  
Affiliation: University of British Columbia  
Abstract: Scheduling algorithms that use application and system knowledge have been shown to be more effective at scheduling parallel jobs on a multiprocessor than algorithms that do not. This paper focuses on obtaining such information for use by a scheduler in a network of workstations environment. The log files from three parallel systems are examined to determine both how to categorize parallel jobs for storage in a job database and what job information would be useful to a scheduler. A Historical Profiler is proposed that stores information about programs and users, and manipulates this information to provide schedulers with execution time predictions. Several preemptive and non-preemptive versions of the FCFS, EASY and Least Work First scheduling algorithms are compared to evaluate the utility of the profiler. It is found that both preemption and the use of application execution time predictions obtained from the Histori cal Profiler lead to improved performance.
Abstract-found: 1
Intro-found: 1
Reference: [Amd67] <author> G. </author> <title> Amdahl. Validity of the single-processor approach to achieving large-scale computing capabilities. </title> <booktitle> In Proceedings of the 1967 AFIPS Conference, </booktitle> <volume> volume 30, </volume> <publisher> AFIPS Press, </publisher> <pages> pages 483-485, </pages> <year> 1967. </year>
Reference-contexts: These applications execute for a period of time that depends on a pseudo-random total work parameter, W , Amdahl's fraction sequential parameter, D <ref> [Amd67] </ref>, and the number of processors on which the application is running, p: t = W (D + p For any job, p, W , and D are determined as follows. The number of processors p is selected randomly between 2 and 16 inclusive according to a Uniform distribution.
Reference: [AS97] <author> S.V. Anastasiadis and K.C. Sevcik. </author> <title> Parallel application scheduling on networks of workstations. </title> <note> To appear in: Journal of Parallel and Distributed Computing, </note> <month> June </month> <year> 1997. </year>
Reference-contexts: 1 Introduction Many theoretical and modeling-based studies indicate that knowledge of the characteristics of parallel applications can improve the performance of scheduling algorithms <ref> [MEB90, PD89, GST91, MEB91, Wu93, PS95, AS97, BG96, PS96] </ref>. However, much less research has focused on practical ways of obtaining such application knowledge. Sevcik [Sev94] proposes simply having the user provide estimates of application characteristics. However, this is inconvenient for users and the accuracy of data is not assured.
Reference: [BG96] <author> T.B. Brecht and K. Guha. </author> <title> Using parallel program characteristics in dynamic processor allocation policies. Performance Evaluation, </title> <booktitle> 27(8) </booktitle> <pages> 519-539, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Many theoretical and modeling-based studies indicate that knowledge of the characteristics of parallel applications can improve the performance of scheduling algorithms <ref> [MEB90, PD89, GST91, MEB91, Wu93, PS95, AS97, BG96, PS96] </ref>. However, much less research has focused on practical ways of obtaining such application knowledge. Sevcik [Sev94] proposes simply having the user provide estimates of application characteristics. However, this is inconvenient for users and the accuracy of data is not assured.
Reference: [CS85] <author> M. Calzarossa and G. </author> <title> Serazzi. A characterization of the variation in time of workload arrival patterns. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34(2):156-162, </volume> <month> February </month> <year> 1985. </year>
Reference-contexts: The lower the CV, the more accurate the estimates are likely to be. We will focus on choosing what attributes to use to classify jobs. There have been only a few detailed workload characterization studies of parallel systems <ref> [CS85, PBK91] </ref>. Furthermore, the studies that do exist do not focus on different ways of classifying jobs, with the exception of Feitelson and Nitzberg's [FN95] analysis of the workload of the 128-node NASA Ames iPSC/860 hypercube.
Reference: [DAC96] <author> A.C. Dusseau, R.H. Arpaci, and D.E. Culler. </author> <title> Effective distributed scheduling of parallel workloads. </title> <booktitle> In Proceedings of the 1996 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 25-36, </pages> <year> 1996. </year>
Reference-contexts: However, the tool he proposes requires special versions of applications to be created and run to determine application characteristics. This is a great inconvenience for users. Another approach is to measure application characteristics at run time. Dusseau, Arpaci and Culler <ref> [DAC96] </ref> use this method with their implicit scheduling technique for distributed time-shared workloads. Local schedulers use the communication and synchronization events implicit in parallel applications to estimate load imbalances.
Reference: [Dow88] <author> L. W. Dowdy. </author> <title> On the partitioning of multiprocessor systems. </title> <type> Technical Report Technical Report 88-06, </type> <institution> Vanderbilt University, </institution> <month> March </month> <year> 1988. </year>
Reference-contexts: Thus, the latter classification will be used. 3 The Historical Profiler The first step in the design of the Historical Profiler is defining the information that the Historical Profiler should provide to the scheduler. In the literature <ref> [MEB90, Dow88, PD89, GST91, Wu93, Sev94, PS96] </ref> scheduling algorithms that use the execution time of jobs have been frequently examined.
Reference: [DS81] <author> N.R. Draper and H. Smith. </author> <title> Applied Regression Analysis, 2nd ed. </title> <publisher> John Wiley and Sons, </publisher> <address> Toronto, </address> <year> 1981. </year>
Reference-contexts: This problem is dealt with by estimating the execution time function based on the available information. For any p &gt; 0, the execution time function T (p) represents the execution time of the job executing on p processors. Using weighted least squares <ref> [DS81] </ref>, a standard method of approximating functions using several point estimates of varying accuracy, the Historical Profiler finds a quadratic approximation of T (p) .
Reference: [FN95] <author> D.G. Feitelson and B. Nitzberg. </author> <title> Job characteristics of a production parallel scientific workload on the NASA Ames iPSC/ 860. </title> <booktitle> In Proceedings of IPPS '95 Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <pages> pages 215-227, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: The database could then deduce the resource usage of future jobs from the past usage. Despite results of workload characterization studies that seem to indicate that this approach holds some potential <ref> [PBK91, FN95, Hot96, HSO96] </ref>, up to now, nobody has implemented this strategy. This paper addresses this issue by creating a Historical Profiler. Through the examination of several production parallel systems, Section 2 justifies the use of and provides insight into an appropriate design of a Historical Profiler. <p> We will focus on choosing what attributes to use to classify jobs. There have been only a few detailed workload characterization studies of parallel systems [CS85, PBK91]. Furthermore, the studies that do exist do not focus on different ways of classifying jobs, with the exception of Feitelson and Nitzberg's <ref> [FN95] </ref> analysis of the workload of the 128-node NASA Ames iPSC/860 hypercube.
Reference: [Gib97] <author> R.B. Gibbons. </author> <title> A historical profiler for use by parallel schedulers. M. Sc. </title> <type> thesis, </type> <institution> University of Toronto, Toronto, </institution> <address> Ontario, Canada, </address> <year> 1997. </year>
Reference-contexts: However, if insufficient processors are available to service the next job in the queue, but a different job in the queue requiring fewer processors can run, that job will be run. 6 A more detailed description of the use of weighted least squares in this context is given discussed elsewhere <ref> [Gib97] </ref>. 7. Least Estimated Remaining Work First (LERWF): LEWF with the addition of preemption. Jobs are run in strict least estimated work first order.
Reference: [GST91] <author> D. Ghosal, G. Serazzi, and S. K. Tripathi. </author> <title> The processor working set and its use in scheduling multiprocessor systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(5) </volume> <pages> 443-453, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Many theoretical and modeling-based studies indicate that knowledge of the characteristics of parallel applications can improve the performance of scheduling algorithms <ref> [MEB90, PD89, GST91, MEB91, Wu93, PS95, AS97, BG96, PS96] </ref>. However, much less research has focused on practical ways of obtaining such application knowledge. Sevcik [Sev94] proposes simply having the user provide estimates of application characteristics. However, this is inconvenient for users and the accuracy of data is not assured. <p> Furthermore, it finds that in many cases, the performance of algorithms using the Historical Profiler is relatively close to the performance of the same algorithms using perfect information. Finally, Section 6 summarizes the findings and discusses future research. 2 Workload Characterization Previous results <ref> [MEB90, Sev89, PD89, GST91, MEB91, Sev94] </ref> have indicated that knowledge of job characteristics can improve the performance of parallel schedulers. <p> Thus, the latter classification will be used. 3 The Historical Profiler The first step in the design of the Historical Profiler is defining the information that the Historical Profiler should provide to the scheduler. In the literature <ref> [MEB90, Dow88, PD89, GST91, Wu93, Sev94, PS96] </ref> scheduling algorithms that use the execution time of jobs have been frequently examined.
Reference: [Hot96] <author> S. Hotovy. </author> <title> Workload evolution on the Cornell Theory Center IBM SP2. </title> <booktitle> In Proceedings of IPPS '96 Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <pages> pages 15-22, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: The database could then deduce the resource usage of future jobs from the past usage. Despite results of workload characterization studies that seem to indicate that this approach holds some potential <ref> [PBK91, FN95, Hot96, HSO96] </ref>, up to now, nobody has implemented this strategy. This paper addresses this issue by creating a Historical Profiler. Through the examination of several production parallel systems, Section 2 justifies the use of and provides insight into an appropriate design of a Historical Profiler. <p> To confirm that these results hold for other systems, we examine the Cornell Theory Center (CTC) IBM SP2 and network of workstations (NOW) sites at NASA Lewis and an anonymous university (which we shall refer to as Univer-sity1). Hotovy, et al. <ref> [Hot96, HSO96] </ref> have already done much analysis of the workload on the CTC IBM SP2. They have examined it in terms of utilization and user-node time. They find that the average utilization is only 60% 2 .
Reference: [HSO96] <author> S. Hotovy, D. Scheider, and T. O'Donnell. </author> <title> Analysis of the early workload on the Cornell Theory Center IBM SP2. </title> <booktitle> In Proceedings of the 1996 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 272-273, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: The database could then deduce the resource usage of future jobs from the past usage. Despite results of workload characterization studies that seem to indicate that this approach holds some potential <ref> [PBK91, FN95, Hot96, HSO96] </ref>, up to now, nobody has implemented this strategy. This paper addresses this issue by creating a Historical Profiler. Through the examination of several production parallel systems, Section 2 justifies the use of and provides insight into an appropriate design of a Historical Profiler. <p> To confirm that these results hold for other systems, we examine the Cornell Theory Center (CTC) IBM SP2 and network of workstations (NOW) sites at NASA Lewis and an anonymous university (which we shall refer to as Univer-sity1). Hotovy, et al. <ref> [Hot96, HSO96] </ref> have already done much analysis of the workload on the CTC IBM SP2. They have examined it in terms of utilization and user-node time. They find that the average utilization is only 60% 2 .
Reference: [Kum88] <author> M. Kumar. </author> <title> Measuring parallelism in computation-intensive scientific/engineering applications. </title> <journal> IEEE Transactions on Computing, </journal> <volume> 37(9) </volume> <pages> 1088-1098, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Sevcik [Sev94] proposes simply having the user provide estimates of application characteristics. However, this is inconvenient for users and the accuracy of data is not assured. As a result, more technical solutions may be warranted. Kumar <ref> [Kum88] </ref> proposes a tool that measures application parallelism by inserting statements into application code. However, the tool he proposes requires special versions of applications to be created and run to determine application characteristics. This is a great inconvenience for users. Another approach is to measure application characteristics at run time.
Reference: [Lif95] <author> D.A. Lifka. </author> <title> The ANL/IBM SP scheduling system. </title> <booktitle> In Proceedings of IPPS '95 Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <pages> pages 187-191, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: However, if insufficient processors are available to service the next job in the queue, but a different job in the queue that requires fewer processors can run, that job will be run. Jobs are never preempted. 3. EASY-kill: Lifka's EASY algorithm <ref> [Lif95] </ref>. Estimates of each job's duration are used. If any job exceeds its estimate, it is killed. Jobs are serviced in FCFS order.
Reference: [LSF96] <institution> LSF Users's Guide. Platform Computing Corporation, </institution> <address> 5001 Yonge St, Suite 1401, North York, ONT, Canada M2N 6P6, </address> <year> 1996. </year>
Reference-contexts: The development of a Historical Profiler and scheduling algorithms for parallel jobs in this environment requires system support in several areas such as job management, host management, and the remote execution of parallel jobs. The commercial Load Sharing Facility (LSF) <ref> [LSF96, ZZWD93] </ref> supports many of these requirements. LSF does job, host, and queue management, supports access to all the job information required, and allows an external scheduler to control jobs to specify when and on which processors each job will be started.
Reference: [MEB90] <author> S. Majumdar, D.L. Eager, and R.B. Bunt. </author> <title> Scheduling in multiprogrammed parallel systems. </title> <booktitle> In Proceedings of the 1988 ACM SIGMETRICS Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 104-113, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Many theoretical and modeling-based studies indicate that knowledge of the characteristics of parallel applications can improve the performance of scheduling algorithms <ref> [MEB90, PD89, GST91, MEB91, Wu93, PS95, AS97, BG96, PS96] </ref>. However, much less research has focused on practical ways of obtaining such application knowledge. Sevcik [Sev94] proposes simply having the user provide estimates of application characteristics. However, this is inconvenient for users and the accuracy of data is not assured. <p> Furthermore, it finds that in many cases, the performance of algorithms using the Historical Profiler is relatively close to the performance of the same algorithms using perfect information. Finally, Section 6 summarizes the findings and discusses future research. 2 Workload Characterization Previous results <ref> [MEB90, Sev89, PD89, GST91, MEB91, Sev94] </ref> have indicated that knowledge of job characteristics can improve the performance of parallel schedulers. <p> Thus, the latter classification will be used. 3 The Historical Profiler The first step in the design of the Historical Profiler is defining the information that the Historical Profiler should provide to the scheduler. In the literature <ref> [MEB90, Dow88, PD89, GST91, Wu93, Sev94, PS96] </ref> scheduling algorithms that use the execution time of jobs have been frequently examined.
Reference: [MEB91] <author> S. Majumdar, D.L. Eager, and R.B. Bunt. </author> <title> Characterization of programs for scheduling in multiprogrammed parallel systems. Performance Evaluation, </title> <booktitle> 13(2) </booktitle> <pages> 109-130, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Many theoretical and modeling-based studies indicate that knowledge of the characteristics of parallel applications can improve the performance of scheduling algorithms <ref> [MEB90, PD89, GST91, MEB91, Wu93, PS95, AS97, BG96, PS96] </ref>. However, much less research has focused on practical ways of obtaining such application knowledge. Sevcik [Sev94] proposes simply having the user provide estimates of application characteristics. However, this is inconvenient for users and the accuracy of data is not assured. <p> Furthermore, it finds that in many cases, the performance of algorithms using the Historical Profiler is relatively close to the performance of the same algorithms using perfect information. Finally, Section 6 summarizes the findings and discusses future research. 2 Workload Characterization Previous results <ref> [MEB90, Sev89, PD89, GST91, MEB91, Sev94] </ref> have indicated that knowledge of job characteristics can improve the performance of parallel schedulers.
Reference: [NVZ96a] <author> T.D. Nguyen, R. Vaswani, and J. Zahorjan. </author> <title> Parallel application characterization for multiprocessor scheduling policy design. </title> <booktitle> In Proceedings of IPPS '96 Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <pages> pages 105-118, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: The local schedulers are able to determine from this data when to schedule parallel applications so that multiple processes of a job have a high probability of being scheduled simultaneously. Nguyen, Vaswani and Zahorjan <ref> [NVZ96b, NVZ96a] </ref> use a combination of code instrumentation and hardware monitors to determine run time characteristics of iterative applications. By varying the processor allocations over several iterations of a loop, the scheduler can determine application characteristics.
Reference: [NVZ96b] <author> T.D. Nguyen, R. Vaswani, and J. Zahorjan. </author> <title> Using runtime measured workload characteristics in parallel processor scheduling. </title> <booktitle> In Proceedings of IPPS '96 Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <pages> pages 93-104, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: The local schedulers are able to determine from this data when to schedule parallel applications so that multiple processes of a job have a high probability of being scheduled simultaneously. Nguyen, Vaswani and Zahorjan <ref> [NVZ96b, NVZ96a] </ref> use a combination of code instrumentation and hardware monitors to determine run time characteristics of iterative applications. By varying the processor allocations over several iterations of a loop, the scheduler can determine application characteristics.
Reference: [Par97] <author> E.W. Parsons. </author> <title> Using Resource Requirements in Multiprogrammed Multipro--cessor Scheduling. </title> <type> Ph. D. thesis, </type> <institution> University of Toronto, Toronto, </institution> <address> Ontario, Canada, </address> <year> 1997. </year>
Reference-contexts: It also allows access to system information through the LSF Application Programming Interface (API). Unfortunately, every call to the LSF API requires crossing address spaces. For efficiency, another layer is required, the Job and System Information Cache (JSIC). The JSIC, developed by Parsons <ref> [Par97] </ref> with help from the author, stores the data required by the profiler and the scheduler in the same address space. The information in the JSIC is periodically updated by polling LSF. The use of these two layers has several advantages.
Reference: [PBK91] <author> J. Pasquale, B. Bittel, and D. Kraiman. </author> <title> A static and dynamic workload characterization study of the San Diego Supercomputer Center Cray X-MP. </title> <booktitle> In Proceedings of the 1991 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 218-219, </pages> <year> 1991. </year>
Reference-contexts: The database could then deduce the resource usage of future jobs from the past usage. Despite results of workload characterization studies that seem to indicate that this approach holds some potential <ref> [PBK91, FN95, Hot96, HSO96] </ref>, up to now, nobody has implemented this strategy. This paper addresses this issue by creating a Historical Profiler. Through the examination of several production parallel systems, Section 2 justifies the use of and provides insight into an appropriate design of a Historical Profiler. <p> The lower the CV, the more accurate the estimates are likely to be. We will focus on choosing what attributes to use to classify jobs. There have been only a few detailed workload characterization studies of parallel systems <ref> [CS85, PBK91] </ref>. Furthermore, the studies that do exist do not focus on different ways of classifying jobs, with the exception of Feitelson and Nitzberg's [FN95] analysis of the workload of the 128-node NASA Ames iPSC/860 hypercube.
Reference: [PD89] <author> K.H. Park and L.W. Dowdy. </author> <title> Dynamic partitioning of multiprocessor systems. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 18(2) </volume> <pages> 91-120, </pages> <month> Febru-ary </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Many theoretical and modeling-based studies indicate that knowledge of the characteristics of parallel applications can improve the performance of scheduling algorithms <ref> [MEB90, PD89, GST91, MEB91, Wu93, PS95, AS97, BG96, PS96] </ref>. However, much less research has focused on practical ways of obtaining such application knowledge. Sevcik [Sev94] proposes simply having the user provide estimates of application characteristics. However, this is inconvenient for users and the accuracy of data is not assured. <p> Furthermore, it finds that in many cases, the performance of algorithms using the Historical Profiler is relatively close to the performance of the same algorithms using perfect information. Finally, Section 6 summarizes the findings and discusses future research. 2 Workload Characterization Previous results <ref> [MEB90, Sev89, PD89, GST91, MEB91, Sev94] </ref> have indicated that knowledge of job characteristics can improve the performance of parallel schedulers. <p> Thus, the latter classification will be used. 3 The Historical Profiler The first step in the design of the Historical Profiler is defining the information that the Historical Profiler should provide to the scheduler. In the literature <ref> [MEB90, Dow88, PD89, GST91, Wu93, Sev94, PS96] </ref> scheduling algorithms that use the execution time of jobs have been frequently examined.
Reference: [PS95] <author> E.W. Parsons and K.C. Sevcik. </author> <title> Multiprocessor scheduling for high-variability service time distributions. </title> <booktitle> In Proceedings of IPPS '95 Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <pages> pages 76-88, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Many theoretical and modeling-based studies indicate that knowledge of the characteristics of parallel applications can improve the performance of scheduling algorithms <ref> [MEB90, PD89, GST91, MEB91, Wu93, PS95, AS97, BG96, PS96] </ref>. However, much less research has focused on practical ways of obtaining such application knowledge. Sevcik [Sev94] proposes simply having the user provide estimates of application characteristics. However, this is inconvenient for users and the accuracy of data is not assured.
Reference: [PS96] <author> E.W. Parsons and K.C. Sevcik. </author> <title> Benefits of speedup knowledge in memory-constrained multiprocessor scheduling. Performance Evaluation, </title> <booktitle> 27(8) </booktitle> <pages> 253-272, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Many theoretical and modeling-based studies indicate that knowledge of the characteristics of parallel applications can improve the performance of scheduling algorithms <ref> [MEB90, PD89, GST91, MEB91, Wu93, PS95, AS97, BG96, PS96] </ref>. However, much less research has focused on practical ways of obtaining such application knowledge. Sevcik [Sev94] proposes simply having the user provide estimates of application characteristics. However, this is inconvenient for users and the accuracy of data is not assured. <p> Thus, the latter classification will be used. 3 The Historical Profiler The first step in the design of the Historical Profiler is defining the information that the Historical Profiler should provide to the scheduler. In the literature <ref> [MEB90, Dow88, PD89, GST91, Wu93, Sev94, PS96] </ref> scheduling algorithms that use the execution time of jobs have been frequently examined.
Reference: [Sev89] <author> K.C. Sevcik. </author> <title> Characterizations of parallelism in applications and their use in scheduling. </title> <booktitle> In Proceedings of the 1989 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 171-180, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Furthermore, it finds that in many cases, the performance of algorithms using the Historical Profiler is relatively close to the performance of the same algorithms using perfect information. Finally, Section 6 summarizes the findings and discusses future research. 2 Workload Characterization Previous results <ref> [MEB90, Sev89, PD89, GST91, MEB91, Sev94] </ref> have indicated that knowledge of job characteristics can improve the performance of parallel schedulers.
Reference: [Sev94] <author> K. C. Sevcik. </author> <title> Application scheduling and processor allocation in multipro-grammed parallel processing systems. Performance Evaluation, </title> <booktitle> 19 </booktitle> <pages> 107-140, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction Many theoretical and modeling-based studies indicate that knowledge of the characteristics of parallel applications can improve the performance of scheduling algorithms [MEB90, PD89, GST91, MEB91, Wu93, PS95, AS97, BG96, PS96]. However, much less research has focused on practical ways of obtaining such application knowledge. Sevcik <ref> [Sev94] </ref> proposes simply having the user provide estimates of application characteristics. However, this is inconvenient for users and the accuracy of data is not assured. As a result, more technical solutions may be warranted. Kumar [Kum88] proposes a tool that measures application parallelism by inserting statements into application code. <p> Furthermore, it finds that in many cases, the performance of algorithms using the Historical Profiler is relatively close to the performance of the same algorithms using perfect information. Finally, Section 6 summarizes the findings and discusses future research. 2 Workload Characterization Previous results <ref> [MEB90, Sev89, PD89, GST91, MEB91, Sev94] </ref> have indicated that knowledge of job characteristics can improve the performance of parallel schedulers. <p> Thus, the latter classification will be used. 3 The Historical Profiler The first step in the design of the Historical Profiler is defining the information that the Historical Profiler should provide to the scheduler. In the literature <ref> [MEB90, Dow88, PD89, GST91, Wu93, Sev94, PS96] </ref> scheduling algorithms that use the execution time of jobs have been frequently examined.
Reference: [Wu93] <author> C.S. Wu. </author> <title> Processor scheduling in multiprogrammed shared memory numa multiprocessors. M. Sc. </title> <type> thesis, </type> <institution> Department of Computer Science, University of Toronto, Toronto, </institution> <address> Ontario, Canada, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Many theoretical and modeling-based studies indicate that knowledge of the characteristics of parallel applications can improve the performance of scheduling algorithms <ref> [MEB90, PD89, GST91, MEB91, Wu93, PS95, AS97, BG96, PS96] </ref>. However, much less research has focused on practical ways of obtaining such application knowledge. Sevcik [Sev94] proposes simply having the user provide estimates of application characteristics. However, this is inconvenient for users and the accuracy of data is not assured. <p> Thus, the latter classification will be used. 3 The Historical Profiler The first step in the design of the Historical Profiler is defining the information that the Historical Profiler should provide to the scheduler. In the literature <ref> [MEB90, Dow88, PD89, GST91, Wu93, Sev94, PS96] </ref> scheduling algorithms that use the execution time of jobs have been frequently examined.
Reference: [ZZWD93] <author> S. Zhou, X. Zheng, J. Wang, and P. Delisle. </author> <title> Utopia: a load sharing facility for large, </title> <journal> heterogenous distributed computer systems. Software: Practice And Experience, </journal> <volume> 23(12) </volume> <pages> 1305-1336, </pages> <month> December </month> <year> 1993. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: The development of a Historical Profiler and scheduling algorithms for parallel jobs in this environment requires system support in several areas such as job management, host management, and the remote execution of parallel jobs. The commercial Load Sharing Facility (LSF) <ref> [LSF96, ZZWD93] </ref> supports many of these requirements. LSF does job, host, and queue management, supports access to all the job information required, and allows an external scheduler to control jobs to specify when and on which processors each job will be started.
References-found: 28

