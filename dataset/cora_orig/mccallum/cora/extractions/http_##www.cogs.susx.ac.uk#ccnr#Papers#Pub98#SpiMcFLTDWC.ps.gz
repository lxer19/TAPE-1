URL: http://www.cogs.susx.ac.uk/ccnr/Papers/Pub98/SpiMcFLTDWC.ps.gz
Refering-URL: http://www.cogs.susx.ac.uk/ccnr/Papers/pub98.html
Root-URL: http://www.cogs.susx.ac.uk/ccnr/Papers/pub98.html
Email: emmet@cogs.sussex.ac.uk  david.mcfarland@balliol.ox.ac.uk  
Title: Learning To Do Without Cognition  
Author: Emmet Spier David McFarland 
Address: Brighton BN1 9SB, UK  Oxford University, South Parks Road, Oxford OX1 3PS, UK  
Affiliation: Centre for Computational Neuroscience and Robotics Sussex University, Innovation Centre,  Animal Robotics Laboratory, Department of Zoology  
Abstract: In this paper we show that a phenomenon in animal learning theory (the outcome devaluation effect) for which there is dispute over whether explicit representations and symbolic reasoning is required for its performance, does not require such things. This is done using a reactive motivational model, previously inspired from ethological thought, to which some simple reinforcement learning rules are attached. An instan-tation of the model is used as the control system of an animat in a spatial computer simulation and it succeeds in learning the necessary parameters to allow the behaviour sequencing system to exhibit the phenomenon. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Adams, C.D. and Dickinson, A. </author> <year> (1981). </year> <title> Instrumental Responding Following Reinforcer Devaluation. </title> <journal> Quarterly Journal of Experimental Psychology, </journal> <volume> 33B, </volume> <pages> pp. 109-121. </pages>
Reference-contexts: After recovery, the rats are then tested (without reinforcement) in the Skinner box to see if they will lever press or chain pull. Half of a four group balanced experimental design <ref> (this one following Adams and Dickinson, 1981) </ref> can be summarised as : CP ! R 2 R 1 ! LiCl LP v CP ? LP ! R 1 R 2 ! LiCl LP v CP ? with the other two groups being those that receive the opposite instrumental contingencies (LP stands
Reference: <author> Barto, A., Sutton, R. and Anderson, C. </author> <year> (1983). </year> <title> Neu-ronlike Adaptive Elements that can Solve Difficult Learning Control Problems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> SMC-13, </volume> <pages> 834-846. </pages>
Reference-contexts: As such, we will, for r, use a simple delta learning rule whose learning rate will be modified by the reinforcers temporal distance (its `eligibility' <ref> (Barto, Sutton and Anderson, 1983) </ref> - captured in a time decaying `eligibility trace' r 0 ); and for k we will, additionally, take advantage of the decaying eligibility (k 0 ) to capture, in k, the time constraint that manipulating the operant controls places upon the agent (since the action, say
Reference: <author> Blumberg, B., Todd, P. and Maes, P. </author> <year> (1996). </year> <note> No bad dogs: Ethological lessions for learning in Hamster-dam. In From Animals to Animats 4: Proceedings of SAB96. </note> <editor> (ed. Maes, P., Mataric, M., Meyer, J.-A., Pollack, J. and Wilson, S. </editor> <publisher> W.), </publisher> <pages> pp. 295-304. </pages> <address> Cam-bridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Colwill, R.M. and Rescorla, R.A. </author> <year> (1985). </year> <title> Postcondition-ing Devaluation of a Reinforcer Affects Instrumental Responding. </title> <journal> Journal of Experimental Psychology: Animal Behavior Processes, </journal> <volume> 11, </volume> <pages> pp. 120-132. </pages>
Reference: <author> Dickinson, A. </author> <year> (1980). </year> <title> Contemporary Animal Learning Theory. </title> <publisher> Cambridge, Cambridge University Press. </publisher>
Reference: <author> Dickinson, A. </author> <year> (1985). </year> <title> Actions and Habits the Development Of Behavioral Autonomy. </title> <journal> Philosophical Transactions Of the Royal Society Of London Series B- Biological Sciences, </journal> <volume> 308, </volume> <pages> pp. 67-78. </pages>
Reference: <author> Dickinson, A. and Dawson, G. </author> <year> (1989). </year> <title> Incentive learning and the motivational control of instrumental performance. </title> <journal> Quarterly journal of experimental psychology, </journal> <volume> 41B, </volume> <pages> pp. 99-112. </pages>
Reference: <editor> Garcia, J., Kimelforf, D.G. and Koelling, </editor> <address> P.A. </address> <year> (1955). </year> <title> Conditioned aversion to saccharine resulting from exposure to gamma radiation. </title> <journal> Science, </journal> <volume> 122, </volume> <pages> pp. 157-158. </pages>
Reference: <author> Holland, P. and Straub, K. </author> <year> (1979). </year> <title> Differential Effects of two ways of devaluing the unconditioned stimulus after Pavlovian appetitive conditioning. </title> <journal> Journal of Experimental Psychology: Animal Behavior Processes, </journal> <volume> 5, </volume> <pages> pp. 65-78. </pages>
Reference: <author> Hull, C.L. </author> <year> (1943). </year> <booktitle> Principles of behavior. </booktitle> <address> New York, Ap-pleton. </address>
Reference: <author> Humphrys, M. </author> <year> (1996). </year> <title> Action Selection methods using Reinforcement Learning. </title> <note> In From Animals to Ani-mats 4: Proceedings SAB96. </note> <editor> (ed. Maes, P., Mataric, M., Meyer, J.-A., Pollack, J. and Wilson, S. W.). </editor> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Krieckhaus, E. and Wolf, G. </author> <year> (1968). </year> <title> Acquisition of sodium by rats: Interaction of innate mechanisms and latent learning. </title> <journal> Journal of comparative and Physiological Psychology, </journal> <volume> 65, </volume> <pages> pp. 197-201. </pages>
Reference: <author> McFarland, D. and Spier, E. </author> <year> (1997). </year> <title> Basic cycles, utility and opportunism in self-sufficient robots. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 20, </volume> <pages> pp. 179-190. </pages>
Reference-contexts: Such a model is amenable to implementation on real robots <ref> (McFarland and Spier, 1997) </ref>. In section 2 there is an overview of the outcome devaluation effect, the phenomenon in question, and a discussion of previously offered explanations and their implications. <p> This section describes a computer simulation experiment that set out to see if the mathematical description can actually generate its expected behaviour when placed in a less homogeneous environment than a mathematical model <ref> (Spier and McFarland, 1997) </ref>. 6.1 Environment The simulation environment consisted of a continuous rectangular surface of 2000fi2000 units within which resided the agent, the operant controls (manipulanda), a food hopper and two types of reinforcer.
Reference: <author> McFarland, D. and Bosser, T. </author> <year> (1993). </year> <booktitle> Intelligent Be-haviour in Animals and Robots. </booktitle> <address> Cambridge, MA, </address> <publisher> MIT Press. </publisher>
Reference: <author> McFarland, D. and Sibly, R. </author> <year> (1975). </year> <title> The Behavioural Final Common Path. </title> <journal> Philosophical Transactions of the Royal Society (Series B), </journal> <volume> 270, </volume> <pages> pp. 265-293. </pages>
Reference-contexts: The subsequent body of this paper demonstrates that by the incorporation of simple learning rules into an already established procedural model (Spier and McFarland, 1996) outcome devaluation-like phenomena can be exhibited. 1 Presumably one would have to postulate a common currency into which `sickness' and `glucose-solution' could be translated <ref> (c.f. McFarland and Sibly, 1975) </ref>. 3 The drk model Previous work discussed at this conference (Spier and McFarland, 1996) developed a motivational model for behavioural sequencing that would not only respond to consumatory cues but could also respond to appetitive or instrumental ones.
Reference: <author> Rescorla, R.A. and Wagner, A.R. </author> <year> (1972). </year> <title> A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement. In Classical conditioning II: current theory and research. </title> <editor> (ed. Black, A. H. and Prokasy, W. </editor> <publisher> F.), </publisher> <pages> pp. 64-99. </pages> <address> NY: Appleton-Century-Crofts. </address>
Reference: <author> Shanks, D. </author> <year> (1995). </year> <title> The Psychology of Associative Learning. </title> <publisher> Cambridge, CUP. </publisher>
Reference: <author> Shipley, B.E. and Colwill, R.M. </author> <year> (1996). </year> <title> Direct effects on instrumental performance of outcome revalua-tion by drive shifts. Animal Learning and Behavior, </title> <booktitle> 24, </booktitle> <pages> pp. 57-67. </pages>
Reference: <author> Skinner, B.F. </author> <year> (1938). </year> <title> The behavior of organisms. </title> <address> New York, Appleton. </address>
Reference: <author> Spier, E. </author> <year> (1997). </year> <title> From reactive behaviour to adaptive behaviour: Motivational models for behaviour in animals and robots. D.Phil. </title> <type> thesis, </type> <institution> Department of Zoology, Oxford University. </institution> <note> Also available at http://www.cogs.sussex.ac.uk/users/emmet </note> . 
Reference-contexts: Such a model is amenable to implementation on real robots <ref> (McFarland and Spier, 1997) </ref>. In section 2 there is an overview of the outcome devaluation effect, the phenomenon in question, and a discussion of previously offered explanations and their implications. <p> The r and k values are modulated by sensed (Pavlovian) cues to their presence, as elaborated later. 2 Although only a two-dimensional physiological state space is used here, the model can be naturally extended to n dimensions <ref> (Spier, 1997) </ref>. k PC k SL k SI L I d d t r P r S d +d h Ph + Output of motivational tendency drk Input of Pavlovian cues to the tools Input of Pavlovian cues to the resources Input of deficits in physiological state metaphor. <p> This section describes a computer simulation experiment that set out to see if the mathematical description can actually generate its expected behaviour when placed in a less homogeneous environment than a mathematical model <ref> (Spier and McFarland, 1997) </ref>. 6.1 Environment The simulation environment consisted of a continuous rectangular surface of 2000fi2000 units within which resided the agent, the operant controls (manipulanda), a food hopper and two types of reinforcer.
Reference: <author> Spier, E. and McFarland, D. </author> <year> (1996). </year> <title> A Finer-Grained Motivational Model of Behaviour Sequencing. </title> <booktitle> In From Animals to Animats 4: Proceedings of SAB96. </booktitle> <editor> (ed. Maes, P., Mataric, M., Meyer, J.-A., Pollack, J. and Wilson, S. </editor> <publisher> W.), </publisher> <pages> pp. 255-263. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: It extends a reactive motivational model called the drk model <ref> (Spier and McFarland, 1996) </ref> with some simple reinforcement learning rules and uses an instantation of this model as the control system of an animat in a computer simulation of a Skinner box. Such a model is amenable to implementation on real robots (McFarland and Spier, 1997). <p> The subsequent body of this paper demonstrates that by the incorporation of simple learning rules into an already established procedural model <ref> (Spier and McFarland, 1996) </ref> outcome devaluation-like phenomena can be exhibited. 1 Presumably one would have to postulate a common currency into which `sickness' and `glucose-solution' could be translated (c.f. McFarland and Sibly, 1975). 3 The drk model Previous work discussed at this conference (Spier and McFarland, 1996) developed a motivational model <p> rules into an already established procedural model <ref> (Spier and McFarland, 1996) </ref> outcome devaluation-like phenomena can be exhibited. 1 Presumably one would have to postulate a common currency into which `sickness' and `glucose-solution' could be translated (c.f. McFarland and Sibly, 1975). 3 The drk model Previous work discussed at this conference (Spier and McFarland, 1996) developed a motivational model for behavioural sequencing that would not only respond to consumatory cues but could also respond to appetitive or instrumental ones. Figure 1 depicts the architecture of the model which is more concisely expressed in matrix notation. <p> Even so it seems a perfectly reasonable assumption in this context and additionally has the already established benefit of allowing trading-off and opportunism in behaviour <ref> (Spier and Mc-Farland, 1996) </ref>. The second is that associations with the reinforcer are incorporated twice into the model: firstly as the r component of the drk product; and secondly in the k matrix elements as is always highlighted by the nomenclature k reinforcer tool .
Reference: <author> Spier, E. and McFarland, D. </author> <year> (1997). </year> <title> Possibly Optimal Decision Making under Self-sufficiency and Autonomy. </title> <journal> Journal of theoretical biology, </journal> <volume> 189, </volume> <pages> pp. 317-331. </pages>
Reference-contexts: Such a model is amenable to implementation on real robots <ref> (McFarland and Spier, 1997) </ref>. In section 2 there is an overview of the outcome devaluation effect, the phenomenon in question, and a discussion of previously offered explanations and their implications. <p> The r and k values are modulated by sensed (Pavlovian) cues to their presence, as elaborated later. 2 Although only a two-dimensional physiological state space is used here, the model can be naturally extended to n dimensions <ref> (Spier, 1997) </ref>. k PC k SL k SI L I d d t r P r S d +d h Ph + Output of motivational tendency drk Input of Pavlovian cues to the tools Input of Pavlovian cues to the resources Input of deficits in physiological state metaphor. <p> This section describes a computer simulation experiment that set out to see if the mathematical description can actually generate its expected behaviour when placed in a less homogeneous environment than a mathematical model <ref> (Spier and McFarland, 1997) </ref>. 6.1 Environment The simulation environment consisted of a continuous rectangular surface of 2000fi2000 units within which resided the agent, the operant controls (manipulanda), a food hopper and two types of reinforcer.
Reference: <author> Sutton, R. and Barto, A. </author> <year> (1981a). </year> <title> An Adaptive Network that constructs and uses an internal model of its world. </title> <journal> Cognition and Brain Theory, </journal> <volume> 4, </volume> <pages> pp. 217-246. </pages>
Reference: <author> Sutton, R. and Barto, A. </author> <year> (1981b). </year> <title> Toward a modern theory of adaptive networks: Expectation and prediction. </title> <journal> Psychological Review, </journal> <volume> 88, </volume> <pages> pp. 135-170. </pages>
Reference: <author> Tolman, </author> <title> E.C. </title> <booktitle> (1932). Purposive behavior in animals and men. </booktitle> <address> New York, Appleton-Century-Crofts. </address>
Reference: <author> Touretzky, D. and Saksida, L. </author> <year> (1996). </year> <note> Skinnerbots. In From Animals to Animats 4: </note> <editor> SAB96. (ed. Maes, P., Mataric, M., Meyer, J.-A., Pollack, J. and Wilson, S. W.). </editor> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Watson, J.B. </author> <year> (1919). </year> <title> Psychology from the standpoint of a behaviourist. </title> <address> Philadelphia, Lippincott. </address>
Reference: <author> Widrow, B. and Hoff, M.E. </author> <year> (1960). </year> <title> Adaptive switching circuits. </title> <booktitle> In 1960 IRE WESCON Convention Record (pt. </booktitle> <volume> 4), </volume> <pages> pp. 96-104. </pages>
References-found: 28

