URL: http://www.ri.cmu.edu/afs/cs/project/sensor-9/ftp/papers/ssbh_phd.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs/project/sensor-9/ftp/papers/
Root-URL: 
Title: STEREOSCOPIC IMAGE SEQUENCE COMPRESSION USING MULTIRESOLUTION AND QUADTREE DECOMPOSITION BASED DISPARITY- AND MOTION-ADAPTIVE SEGMENTATION  
Author: SRIRAM SETHURAMAN 
Degree: A DISSERTATION SUBMITTED TO THE GRADUATE SCHOOL IN PARTIAL FULFILLMENT OF THE REQUIREMENTS for the degree of DOCTOR OF PHILOSOPHY in ELECTRICAL ENGINEERING by  
Date: July, 1996  
Affiliation: CARNEGIE MELLON UNIVERSITY  Pittsburgh, Pennsylvania  
Abstract-found: 0
Intro-found: 1
Reference: <institution> Books/compilations: </institution>
Reference: [1] <author> Majid Rabbani and Paul W. Jones, </author> <title> Digital image compression techniques, </title> <publisher> SPIE Optical Engineering Press, Bellingham, </publisher> <address> WA, </address> <year> 1991. </year>
Reference-contexts: Some widely used waveform coding methods are differential pulse code modulation (DPCM), transform coding, sub-band coding, vector quantization (VQ) and fractal image coding. DPCM based coders employ an M-th order Markov model based causal predictor <ref> [1] </ref>. Suitable static or adaptive predictive coefficients are derived based on the model; the residuals (deviation of the predicted values from the actual values) are coded based on the entropy of the residual symbols 3 . A lossy coding can be carried out by quantizing 4 the residuals 5 . <p> An optimal scalar quantizer (SQ) that minimizes the quantization error and the entropy of the quantizer output symbols for such a pdf has been shown to be a uniform quantizer (equal width between the different levels of the quantizer) <ref> [1] </ref>. Figure 2.3 shows a schematic of a DPCM based lossy coder. Since quantization and coding are done at a pixel-by-pixel level, the average bits per pixel (bpp) cannot be made less than 1. A noncausal predictive coding method is presented in [46]. <p> These methods enable irrelevancy reduction better than DPCM methods. For example, the human contrast sensitivity is low at high spatial frequencies 3 . This fact is exploited by quantizing the different frequency coefficients according to the respective contrast sensitivity thresholds (CST) at those frequencies <ref> [1] </ref>. The nonzero values after quantization are scanned in a zig-zag manner (to increase the number of zero values in a row) and are runlength encoded. A typical DCT based encoder is shown in Fig. 2.4. Several computationally efficient implementations of DCT are available [47,111]. <p> Several computationally efficient VQ methods (such as tree structured VQ) that reduce the search complexity when finding the best approximating code vector and several different variants have been proposed [5]. VQ-based coding can be used for direct image coding <ref> [1, 5] </ref>, residual coding [1, 45], or sub-band coding [48]. Fractal image coding [50] relies on the fact that typical images have self similar structures embedded in them. A set of domain blocks with different basic features in them such as simple edges, complex edges and texture are created. <p> Several computationally efficient VQ methods (such as tree structured VQ) that reduce the search complexity when finding the best approximating code vector and several different variants have been proposed [5]. VQ-based coding can be used for direct image coding [1, 5], residual coding <ref> [1, 45] </ref>, or sub-band coding [48]. Fractal image coding [50] relies on the fact that typical images have self similar structures embedded in them. A set of domain blocks with different basic features in them such as simple edges, complex edges and texture are created. <p> The typical filters we use are of orders n=1 and n=2 (specifically, <ref> [-1, 0, 1] </ref> and [-1, -2, 0, 2, 1]). A larger n provides a more reliable edge location by smoothing out local variations, but reduces the number of candidate partitioning locations due to edge effects. This procedure is illustrated for a test image in Fig. 3.4. <p> The typical filters we use are of orders n=1 and n=2 (specifically, [-1, 0, 1] and <ref> [-1, -2, 0, 2, 1] </ref>). A larger n provides a more reliable edge location by smoothing out local variations, but reduces the number of candidate partitioning locations due to edge effects. This procedure is illustrated for a test image in Fig. 3.4. <p> To enable easy comparison in terms of excess bandwidth, the rate is shown in terms of excess bandwidth on the R-D plots. Some of the observations from these plots are: <ref> [1] </ref> DBS-1 outperforms FBS-1 at all the quality settings and for all the sequences. The decrease in the bit-rate for the DBS-1 scheme compared to the FBS-1 scheme, for a given quality, is primarily due to the reduction arising from the segmentation. <p> In Fig. 4.12 we compare the performance of the RDBS joint-coding scheme against the performances of other configuration-1 schemes, namely, FBS-1 and DBS-1. The observations are: <ref> [1] </ref> RDBS performs better than FBS-1 for all cases. [2] Except for the booksale and crowd sequences, RDBS performs as well as or better than DBS-1 for the auxiliary sequence. The improvement in performance is because the segmentation coding overhead is shared by the main and auxiliary sequences. <p> The improvements are tabulated in Table 4.2. stream R-D values are given alongside the plots and are tabulated for comparison in Table 4.2. The observations are: <ref> [1] </ref> The R-D performances of ST-1 and DBS-1 for the main sequence are more or less similar, except for the aqua sequence. The aqua sequence has a very high spatial detail.
Reference: [2] <author> Arun N. Netravali and Barry G. </author> <title> Haskell, Digital pictures: representation and compression, </title> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: carried out at a pixel-by-pixel level; (2) digital transmission can be made more robust than analog transmission; (3) digital copying does not degrade the quality of the copy; and, (4) finer trade-off between perceived quality and transmission bandwidth becomes possible. 2.2.1 Need for compression of digital video A nominal NTSC <ref> [2] </ref> video signal has 480 active scan lines per frame and each scan line is typically digitized to 720 pixels. <p> Coding methods that exploit this redundancy that exists between temporally adjacent frames are known as interframe coding methods. Motion compensated prediction (MCP) is the most widely employed interframe coding method. Even spatio-temporal extensions of transform and sub-band coding methods <ref> [2, 61] </ref> include a motion compensation stage. In a typical image sequence, motion from frame-to-frame is a composite of the individual object motions and the motion of the camera in the 3-D space, projected on the image plane. <p> The typical filters we use are of orders n=1 and n=2 (specifically, [-1, 0, 1] and <ref> [-1, -2, 0, 2, 1] </ref>). A larger n provides a more reliable edge location by smoothing out local variations, but reduces the number of candidate partitioning locations due to edge effects. This procedure is illustrated for a test image in Fig. 3.4. <p> As such, the savings in bpp remains more or less constant across the different quality levels. In other words, the percentage savings in bit-rate is higher at low bit-rates. <ref> [2] </ref> DBS-2 outperforms FBS-2 at all quality settings and for all the test sequences. Again, the bit rate reduction at a given quality is only due to the gains from segmentation, as all other factors are maintained the same. In addition, DBS-2 also consistently outperforms DBS-1 and FBS-1. <p> In Fig. 4.12 we compare the performance of the RDBS joint-coding scheme against the performances of other configuration-1 schemes, namely, FBS-1 and DBS-1. The observations are: [1] RDBS performs better than FBS-1 for all cases. <ref> [2] </ref> Except for the booksale and crowd sequences, RDBS performs as well as or better than DBS-1 for the auxiliary sequence. The improvement in performance is because the segmentation coding overhead is shared by the main and auxiliary sequences. <p> The aqua sequence has a very high spatial detail. The increase in bit-rate may be due to the need to maintain a high quality for the main sequence. <ref> [2] </ref> For the auxiliary stream, the R-D performance is very close to that of DBS-1 in most cases. Since the segmentation overhead is shared by several frames in the ST-1 case, the performance at low bit-rates is very close to or better than the performance of the DBS-1 scheme.
Reference: [3] <author> Arun N. Netravali and Birendra Prasada, </author> <title> Editors, Visual communication systems, </title> <publisher> IEEE Press, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: -0.041 -0.08 +0.094 -0.40 Piano 720 x 576 25 0.475 4.925 34.77 0.430 -0.045 -0.16 -0.016 -0.57 Train 720 x 576 25 0.554 5.744 33.72 0.500 -0.054 +0.01 +0.007 -0.37 Tunnel 720 x 576 25 0.378 3.919 33.34 0.354 -0.024 -0.11 +0.046 -0.38 77 configuration, intermediate views cannot be synthesized. <ref> [3] </ref> The bit-rate using FBS methods cannot be reduced below a certain minimum bit-rate (which depends on the average number of motion or disparity coding bits per blocks). <p> Erroneous predictions for exposed regions using the scan-line based prediction method described in Section 4.5.2, can be a reason for the reduction in R-D performance, as this method assumes that the disparity has only a horizontal component. <ref> [3] </ref> Since the main sequence in RDBS is coded based on segmentation, a slight improvement in the rate-distortion performance for the main sequence over FBS-based coding can be seen.
Reference: [4] <author> Russell Hsing and Andrew G. Tescher, </author> <title> Editors, Selected papers on visual communication: technology and applications, </title> <publisher> SPIE Optical Engineering Press, Bellingham, </publisher> <address> MA, </address> <year> 1990. </year>
Reference-contexts: This implies that the differential predictive coding of motion and disparity is not useful beyond a certain point, due to the presence of spurious matches. On the other hand, by varying the segmentation parameters, arbitrarily low bit-rates for the segmentation schemes can be achieved. <ref> [4] </ref> The PSNR shown for the mixed-resolution based coding case is at the lower resolution. This curve has been shown to emphasize the fact that by trading off resolution, we can improve the quality of residual coding compared to what is achieved at the original resolution.
Reference: [5] <author> Allen Gersho and Robert M. Gray, </author> <title> Vector quantization and signal compression, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1992. </year>
Reference-contexts: Several computationally efficient VQ methods (such as tree structured VQ) that reduce the search complexity when finding the best approximating code vector and several different variants have been proposed <ref> [5] </ref>. VQ-based coding can be used for direct image coding [1, 5], residual coding [1, 45], or sub-band coding [48]. Fractal image coding [50] relies on the fact that typical images have self similar structures embedded in them. <p> Several computationally efficient VQ methods (such as tree structured VQ) that reduce the search complexity when finding the best approximating code vector and several different variants have been proposed [5]. VQ-based coding can be used for direct image coding <ref> [1, 5] </ref>, residual coding [1, 45], or sub-band coding [48]. Fractal image coding [50] relies on the fact that typical images have self similar structures embedded in them. A set of domain blocks with different basic features in them such as simple edges, complex edges and texture are created. <p> The bit-rate savings is higher at higher quality settings indicating that more bits are being spent in the DBS-2 case to encode the residuals at the edges, which are not present at the lower resolution. Psychophysically, suppression of artifacts might outweigh loss of resolution. <ref> [5] </ref> The excess bandwidth is anomalously high for the aqua sequence in all cases, as its main sequence is coded at a low bit-rate owing to the very slight motion between frames.
Reference: [6] <author> P. Anandan, et al., </author> <title> Hierarchical model-based motion estimation, in Motion Analysis and Image sequence processing, </title> <editor> Ibrahim Sezan and Reginald Lagendijk, Editors, </editor> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: Since motion estimation of vertices may be unreliable, an alternate approach is to iteratively refine the motion model estimates using gradient descent or Gauss-Newton search methods, over the set of pixels within a patch <ref> [6] </ref>. 2.2.6 Model-based coding These are coding methods that have emerged recently and are a result of the synergy between the three fields namely, image coding, image understanding (scene analysis) and computer graphics (image synthesis). <p> An alternative is to maintain the block size constant at all resolutions. Thus a block in level-l will correspond to four blocks in level-(l-1). as in (2.4). Hierarchical extension to any general motion estimation model is presented in <ref> [6] </ref>. 2.3.6 Other applications of multirate filters in video coding The interoperability of video encoders and decoders requires handling of a wide variety of display formats. The different television standards such as NTSC, PAL and SECAM that are used in different parts of the world have different display sizes. <p> By relaxing the 109 translation of planar patch parallel to the image sensor assumption for motion and disparity and considering affine or perspective transformation based models <ref> [6] </ref> (see Section 2.2.5), the compensation can be further improved. The segmentation boundaries in our method are computed based only on the luminance components. By suitably exploiting the chrominance components also, the segmentation can be improved in regions of near iso-luminance.
Reference: [7] <author> K. R. Rao and P. Yip, </author> <title> Discrete cosine transform: algorithms, advantages, applications, </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: The discrete cosine transform (DCT) has been found to have the most energy packing efficiency for typical natural images <ref> [7] </ref>. These methods enable irrelevancy reduction better than DPCM methods. For example, the human contrast sensitivity is low at high spatial frequencies 3 . This fact is exploited by quantizing the different frequency coefficients according to the respective contrast sensitivity thresholds (CST) at those frequencies [1].
Reference: [8] <author> R. J. Clarke, </author> <title> Transform coding of images, </title> <publisher> Academic Press, </publisher> <address> Orlando, </address> <year> 1985. </year>
Reference-contexts: Figure 2.3 shows a schematic of a DPCM based lossy coder. Since quantization and coding are done at a pixel-by-pixel level, the average bits per pixel (bpp) cannot be made less than 1. A noncausal predictive coding method is presented in [46]. Orthogonal transform based coding methods <ref> [8] </ref> achieve decorrelation by packing most of the energy 2 present in a signal to be coded into the least possible number of coefficients.
Reference: [9] <author> Anil K. Jain, </author> <title> Fundamentals of digital image processing, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1989. </year>
Reference-contexts: Arising from the concept of area under the power spectrum of a signal, the energy of a video signal can be defined as the sum of the squares of the intensities of pixels over a region of interest, using Parsevals relation <ref> [9] </ref>. 3. Human contrast sensitivity function has a bandpass characteristic. <p> Region growing methods, the early segmentation methods, employ a combination of edge and texture discrimination techniques to obtain homogeneously textured areas [62, 75]. Recently, mathematical morphology has been used to segment images [63, 64]. Contour coding is the coding of arbitrary shapes over the discrete grid. Chain coding <ref> [9] </ref>, the simplest known way of exactly coding a contour, is typically not bit efficient. The contours can be approximately coded by picking a set of control vertices and by defining a polygon or fitting a spline curve through these vertices.
Reference: [10] <author> Bernd Jahne, </author> <title> Digital Image Processing: Concepts, algorithms and scientific applications, </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference: [11] <author> P. P. Vaidyanathan, </author> <title> Multirate systems and filter banks, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1993. </year>
Reference-contexts: - Ihh1 (low - low) - Ihg1 (low - high) - Igh1 (high - low) - Igg1 (high - high) (a) w 1 w 2 24 filters are mirror images of each other w.r.t to the quadrature frequency 2p/4; hence the filters are referred to as quadrature mirror filters (QMF) <ref> [11] </ref>.
Reference: [12] <author> Bela Julesz, </author> <title> Foundations of Cyclopean perception, </title> <publisher> Univ. of Chicago Press, </publisher> <address> Chicago, </address> <year> 1971. </year>
Reference-contexts: This restricts the number of bits that can be allocated for residual coding. The significant residuals that are left uncoded can result in visually distracting artifacts. The noticeable artifacts can be suppressed by trading off resolution and coding the auxiliary stream frames at a reduced resolution. Psychophysical studies <ref> [12, 30, 89, 107] </ref> have shown that satisfactory stereoscopic perception is achieved even when one of the stereoscopic sequences is presented to a viewer at a Auxiliary stream stream Main I B P P MDBS Track MCP 1 1 1 P A I A 1 1 2 2 Track Track Track <p> The holes are then filled in. MCP - MCP w.r.t to reference frames (for under-compensated blocks). MCP - MCP of the segments MDBS MDBS FIG. 4.7: Segment tracking scheme ST-1 - configuration 1 71 reduced resolution. Based on psychophysical experiments with random-dot stereograms, Julesz <ref> [12] </ref> has reported that stereopsis can occur even if spatial similarities exist only in a particular frequency band. <p> Based on an experiment where a sharp image was presented to the right eye and a significantly blurred image was present to the other eye, he reports <ref> [12, page 96] </ref> that the stereoscopic image pair is easy to fuse, and the binocular percept appears not only in depth but seems as detailed as the sharper image.
Reference: [13] <author> David Marr, </author> <title> Vision: a computational investigation into the human representation and processing of visual information, </title> <publisher> W.H.Freeman and Co., </publisher> <address> San Francisco, </address> <year> 1982. </year> <month> 119 </month>
Reference: [14] <author> Lenny Lipton, </author> <title> Foundations of the stereoscopic cinema: a study in depth, </title> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, </address> <year> 1982. </year>
Reference: [15] <author> V. M. Bove, </author> <title> Scalable (extensible, interoperable) digital video representation, Chapter 3, </title> <editor> Andrew B. Watson, Editor, </editor> <title> Digital images and human vision, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: Since the filters are non-ideal and the high frequency components are lost, the reconstruction can contain aliased high frequency components (if the original image had significant energy at the high frequencies). A Wiener filter for reducing such aliasing-noise has been used in <ref> [15] </ref>. The decoder complexity increases because of the need for filtering, upsampling and downsampling. However, as we mentioned in Section 2.3.6, to achieve spatial and temporal scalability multi-rate filter banks are in general desirable in decoders. The hardware resource available for this purpose can be used for mixed-resolution coding.
Reference: [16] <author> John E. W. Mayhew and John P. </author> <title> Frisby, Editors, 3D model recognition from stereoscopic cues, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: (which are the perpendicular lines to the imaging planes passing through the respective centers of projection) are coplanar, the corresponding points are constrained by the geometry to lie on epipolar lines, defined by the respective intersections of the two image planes with the plane defined by (P, L, and R) <ref> [16] </ref>. Thus, the search for the corresponding point P L in the left image, for the point P R , is restricted to one dimension. In the particular case of the optical axes being parallel (Fig. 2.2), the epipolar lines become the corresponding horizontal scan lines.
Reference: [17] <editor> A. Rosenfeld, Editor, </editor> <title> Multiresolution image processing and analysis, </title> <publisher> Springer-Verlag, </publisher> <address> New York 1984. </address>
Reference: [18] <author> R. O.Duda and P. E. Hart, </author> <title> Pattern classification and scene analysis, </title> <publisher> Wiley, </publisher> <address> NewYork, </address> <year> 1973. </year>
Reference-contexts: In this regard, fractal image coding is similar to vector quantization with a codebook containing all possible combinations of the transformations applied to the domain blocks. 1. The LBG algorithm is the same as the k-means clustering method used in pattern recognition <ref> [18] </ref>. block DCT Quantizer zig-zag scan Runlength code Entropy code bits Forward FIG. 2.4: Typical DCT-based encoder 15 2.2.4 Second generation coding methods The second generation coding methods are adaptations of waveform coding methods, which however attempt to partition the images into homogeneous regions of arbitrary shapes and sizes depending on
Reference: [19] <author> H. Samet, </author> <title> Design and analysis of spatial data structures, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: The other option to avoiding arbitrarily shaped regions is commonly known as variable block size (VBS) based segmentation. Quadtrees are a well known example of such segmentation <ref> [19] </ref>. Quadtrees are constructed either in a top-down or bottom-up fashion or as a combination of both. Top-down construction requires recursively splitting a block (called a node of the quadtree) into four sub-blocks depending on a splitting criterion.
Reference: [20] <author> G. Wolberg, </author> <title> Digital image warping, </title> <publisher> IEEE Computer Society, </publisher> <address> Washington, </address> <year> 1990. </year>
Reference-contexts: Typically the composite local motion is estimated using an approximation to the actual underlying 3D motion model. The region used for motion estimation is typically considered a planar patch that is undergoing motion and a suitable projective transformation is used to model the projection onto the image plane <ref> [51, 20] </ref>. Translation-only motion parallel to the image plane is the most widely used approximation. This simple model requires only two parameters, namely the horizontal and vertical components of translation. <p> Hierarchical block matching (HBM) is also logarithmically efficient, but it does not make the monotonicity assumption. HBM will be elaborated later in Section 2.3.5. Once the best match in full-pixel displacements is obtained, the estimate can be interpolated to sub-pixel accuracies. The commonly used bilinear interpolation <ref> [20] </ref> uses a linear combination of the four nearest pixels to produce the subpixel value. The horizontal and vertical translatory components together for a block is called a motion vector. The motion vectors are usually DPCM encoded to exploit the smoothness of the motion field over the image.
Reference: [21] <author> D. F. McAllister, </author> <title> Stereo computer graphics and other true 3D technologies, </title> <publisher> Princeton University Press, </publisher> <address> Princeton NJ, October 1993.. </address> <publisher> Standards: </publisher>
Reference: [22] <institution> Video codec for audiovisual services at px64 kbits/s, CCITT Recommendation H.261, </institution> <month> Dec. </month> <year> 1989. </year>
Reference-contexts: In two-way communications, as in videoconferencing, the coder-decoder pair at each end (referred to as a codec) has to operate in real-time. The available bandwidth for transmission is also usually limited. The H.261 standard makes recommendations for coding video for such applications <ref> [22] </ref>. Reduced resolution picture sizes 1 at variable frame rates are adopted to tackle the real-time and bandwidth constraints. The basic unit for processing is a macroblock (MB) of size (16 pixels) x (16 pixels) 2 .
Reference: [23] <institution> Description of Reference Model 8 (RM8), CCITT Doc. </institution> <month> 525, June </month> <year> 1989. </year>
Reference: [24] <institution> Coding of moving pictures and associated audio for digital storage media at up to about 1.5 Mbits/s, </institution> <note> ISO 11172 (MPEG-1), Draft International Standard, </note> <month> November </month> <year> 1992. </year>
Reference-contexts: This is done to minimize the objectionable blocking artifacts common at low bit-rates. For more general video coding where there are no real-time encoding constraints, a different standard known widely as the MPEG-1 (Motion Picture Experts Group) standards evolved <ref> [24] </ref>. This standard focussed on compression for storage media and the target video bit-rate was fixed at 1.2 Mbps (to be within the CD-ROM bit-rate of 1.5 Mbps). Correspondingly a source input format (SIF) of 240 x 352 size frames at 30 fps in 4:2:0 format was chosen.
Reference: [25] <author> ISO/IEC JTC1/SC29/WG11, </author> <title> Information technology - generic coding of moving pictures and associated audio, Recommendation H.262, </title> <note> ISO/IEC 13818-2 (MPEG-2), Draft International Standard, </note> <month> March </month> <year> 1994. </year>
Reference-contexts: The maximum permissible search range is quite high as compared to the real-time codecs. DCT-based coding is used to code the error image after motion compensation. To handle interlaced video and higher bit-rate video (as in HDTVs) efficiently, a downward compatible standard referred to as MPEG-2 standards evolved <ref> [25] </ref>. This standard offers different coding modes such as frame-picture-coding and field-picture-coding modes to handle interlaced frames. The motion compensation methods are also suitably modified to have field and frame prediction. Currently, different proposals for a new draft standard called MPEG-4 [28] for very-low bit-rate video coding are being considered. <p> However, because of the high entropy of the residuals, even their lossy coding typically constitutes a significant fraction of the overall bit budget. The MPEG standard recommends a discrete cosine transform based residual coder <ref> [25] </ref>. However, the residuals contain no special structure in the transform domain which can be exploited to code them efficiently. <p> VQ (1x1) -scalar quantize (a) Stages involved in coding a typical non-intra coded frame (b) Residual coding methods at the different levels of a macroblock quadtree 64 after the zig-zag scan <ref> [25] </ref>. Hierarchical block matching as described in Section 2.3.5 and Fig. 2.9 is employed for MCP and DCP. Since it is hard to achieve a perfectly parallel camera configuration, a small search range is allowed in the vertical direction during disparity compensation. <p> The bit-rate (R) and distortion (D) measures used to compare the different schemes are the average bpp and the average PSNR (defined in Figure 2.2.8) respectively. The rate-distortion (R-D) curves for the FBS-1, DBS-1, FBS-2, DBS-2 and mixed-1. The MPEG-2 standard uses field prediction and dual-prime <ref> [25] </ref> prediction modes in addition to frame prediction, in order to exploit the redundancy between adjacent fields in an interlaced sequence. For simplicity, we employ only frame prediction and treat each field as a frame.
Reference: [26] <author> ISO/IEC JTC1/SC29/WG11, </author> <title> Test model editing committee, MPEG-2 Video Test Model 5, </title> <journal> Doc. </journal> <volume> No. 400, </volume> <month> April </month> <year> 1993. </year>
Reference-contexts: The disparity vectors are coded by differential prediction followed by entropy coding (similar to motion vector encoding in MPEG-2 Test Model <ref> [26] </ref>). It can be seen that the DBS algorithm results in a bpp which is 45-75% of the bpp required for a FBS algorithm. The PSNRs for the DBS case are slightly less than the PSNRs for the FBS case. <p> to the cameras; due to the non-unity angular magnification during viewing, the views with the nominal interocular separation are hard to fuse. 117 Appendix B Motion and disparity vector coding The motion and disparity vectors in the experiments were coded in a manner similar to the MPEG-2 test-model 5 (TM5) <ref> [26] </ref>. For the fixed block-size case, the block motion/disparity vectors are scanned left to right and from top to bottom. The horizontal and vertical components are coded separately. The first motion/disparity vector is coded by itself.
Reference: [27] <institution> Video coding for low bitrate communications, </institution> <type> Draft ITU-T Recommendation H. 263, </type> <month> December </month> <year> 1995. </year>
Reference-contexts: Thresholding is used to avoid coding small errors after compensation. To take advantage of the progress in the video coding field, and the advancements in the VLSI technology, a new videoconferencing standard that is targeted at low bit-rates is currently emerging. This standard-to-be (called H.263 <ref> [27] </ref>) has several advanced prediction modes. The most significant of these is the overlapped block motion compensation (OBMC) algorithm. The OBMC algorithm permits a different motion vector for each pixel, obtained by interpolating neighboring block motion vectors. This is done to minimize the objectionable blocking artifacts common at low bit-rates. <p> If the disparity or motion compensation can be improved, the residual coding overhead can be considerably reduced. We have considered only simple block matching. As a first step to improve compensation, overlapped block motion compensation <ref> [27] </ref> can be applied to obtain interpolated motion and disparity estimates for each pixel within a block.
Reference: [28] <author> ISO/IEC JTC1/SC29/WG11, </author> <title> MPEG4 proposal package description, no. 937, Test/ evaluation procedures document, no. 938, Requirements for the MPEG4 SDL, no. 939, Call for proposals, </title> <journal> no. </journal> <volume> 943, </volume> <month> March </month> <year> 1995. </year> <note> 120 Journal/Transactions papers: </note>
Reference-contexts: This standard offers different coding modes such as frame-picture-coding and field-picture-coding modes to handle interlaced frames. The motion compensation methods are also suitably modified to have field and frame prediction. Currently, different proposals for a new draft standard called MPEG-4 <ref> [28] </ref> for very-low bit-rate video coding are being considered. This standard is expected to be based on advanced motion compensation techniques and hybrid model-based coders.
Reference: [29] <author> F.Chassaing et.al, </author> <title> A stereoscopic television system and compatible transmission on a MAC channel, Signal Processing: </title> <journal> Image Communication, </journal> <volume> no. 4, </volume> <pages> pp., </pages> <year> 1991. </year>
Reference: [30] <author> Michael G. Perkins, </author> <title> Data compression of stereopairs, </title> <journal> IEEE Trans. on Communications, vol.40, </journal> <volume> no. 4, </volume> <pages> pp. 684-696, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Several DC-based methods have followed. Perkins <ref> [30] </ref> formalized DC-based coding as a conditional coding approach that is optimal for lossless coding and sub-optimal for lossy coding. He was also one of the first advocates of mixed resolution coding, wherein one of the views is presented at a lower resolution. <p> Other DC-based algorithms in the literature use simple fixed block-size (FBS) based disparity estimation <ref> [30, 87, 96, 34] </ref>, which can be supported by the current technology. However, the bit allocation in these schemes is not commensurate with the local disparity or motion detail present within a multi-view sequence. <p> Also, perspective-induced occlusions are not coded efficiently by these methods. While most of the coding advantages in video compression have been achieved by exploiting the tolerances of the human visual system, only few researchers <ref> [30, 87, 101] </ref> have exploited special stereoscopic masking effects to achieve large stereoscopic compression gains. <p> A brief overview of the important works was presented in Section 1.2. Here, we describe some of these methods and point out their shortcomings in light of the objectives set forth in Section 1.3. In <ref> [30] </ref>, a stereoscopic image sequence is modeled as a stationary and ergodic discrete stochastic process that issues two integers from a finite set of integers that represent the set of all possible images (for a given frame size and number of intensity levels). <p> This restricts the number of bits that can be allocated for residual coding. The significant residuals that are left uncoded can result in visually distracting artifacts. The noticeable artifacts can be suppressed by trading off resolution and coding the auxiliary stream frames at a reduced resolution. Psychophysical studies <ref> [12, 30, 89, 107] </ref> have shown that satisfactory stereoscopic perception is achieved even when one of the stereoscopic sequences is presented to a viewer at a Auxiliary stream stream Main I B P P MDBS Track MCP 1 1 1 P A I A 1 1 2 2 Track Track Track <p> Mixed-resolution based stereoscopic image coding was first described by Perkins in <ref> [30] </ref>, where each 4x4 block in one view is averaged to obtain one pixel at the reduced resolution. During display, a bilinear interpolation is applied to expand the size. The subsampling and upsampling are thus done in an adhoc fashion, without any consideration about aliasing or the reconstruction quality. <p> Mixed Resolution Sacrifices resolution to achieve lower bit-rates - psychophysically motivated - fits well within the multiresolution framework 86 difference in perceived stereoscopic quality (as demonstrated through psychophysical experiments in <ref> [30, 89] </ref>). Our reported results are based only on the PSNR quality metric.
Reference: [31] <author> A. Tamtaoui and C. Labit, </author> <title> Constrained disparity and motion estimators for 3DTV image sequence coding, Signal Processing: </title> <journal> Image Commun., </journal> <volume> vol. 4, </volume> <pages> pp. 45-54, </pages> <year> 1991. </year>
Reference-contexts: He was also one of the first advocates of mixed resolution coding, wherein one of the views is presented at a lower resolution. A similar solution was also suggested by Dinstein [89]. Tamtaoui and Labit <ref> [31, 88] </ref> presented a constrained motion and disparity estimation scheme based on a calibrated pair of converged cameras. They also provided a coherence equation to verify the motion and disparity components between two stereo pairs of frames. <p> The DC-based 4 algorithms that have their origins in the computer vision field <ref> [33, 31] </ref> are primarily targeted at scene analysis and understanding and hence are computationally intensive and do not lend themselves well to coding. <p> As was discussed in Section 2.2.7, international video coding standards adopt FBS-BMA for motion estimation because of its implementation simplicity. Hence a majority of researchers have applied it for DCP also <ref> [31, 87, 89, 91, 97] </ref>. However, these methods have certain inherent shortcomings which are 1. Physically, this implies a planar patch that lies parallel to the image sensors at a fixed depth. <p> Since the same segment is tracked, the motion estimates from the segmentation with proper scaling can be used as initial estimates for block matching. The auxiliary stream frames can be estimated in two ways by using the following coherence equation <ref> [31] </ref>: (EQ 4.3) where v m is the main stream motion vector of a segment between the frames at instants t and (t+k), v a is the auxiliary stream motion vector between the frames at instants t and (t+k), d t is the left-right disparity at instant t, and d t+k
Reference: [32] <author> R. Skerjanc and J.Liu, </author> <title> A three camera approach for calculating disparity and synthesizing intermediate pictures, Signal Processing: </title> <journal> Image Commun., Vol.4, No.1, </journal> <volume> pp.55-64, </volume> <year> 1991. </year>
Reference-contexts: The disparity is computed on triangular patches using an affine model. The encoding procedure is computationally intensive even for simple scenes. However, good compression and interpolation results on two simple scenes are reported. A three camera based view interpolation using dynamic programming based disparity estimation is presented in <ref> [32] </ref>. Occlusions are minimized in this case by the triangular camera setup with two horizontally separated cameras and one vertically offset camera in between and above the other two cameras. <p> Based on this disparity representation and the texture information of each triangular patch, intermediate views are synthesized. Though the method yields high compression ratios for simple scenes, it does not scale well with complex scenes. A triangular 3-camera setup has been used in <ref> [32] </ref> to minimize occlusions typically incurred with a horizontally separated 2-camera setup. In that paper, the disparity is estimated using dynamic programming techniques for intensity edges; this sparse disparity is interpolated to obtain a dense disparity map which is used to synthesize intermediate views. <p> In addition, if regions occluded in the extreme views are visible in the intermediate views, an additional intensity image and a disparity map are coded. The disparities are estimated using a dynamic programming approach constrained by the parallel axes camera geometry. As in <ref> [32] </ref>, this paper does not discuss the coding of the dense disparity maps.
Reference: [33] <author> J. Liu and R. Skerjanc, </author> <title> Stereo and motion correspondence in a sequence of stereo images, Signal Processing: </title> <journal> Image Commun., </journal> <volume> Vol. 5, </volume> <pages> pp. 305-318, </pages> <year> 1993. </year>
Reference-contexts: Tamtaoui and Labit [31, 88] presented a constrained motion and disparity estimation scheme based on a calibrated pair of converged cameras. They also provided a coherence equation to verify the motion and disparity components between two stereo pairs of frames. Liu and Skerjanc <ref> [33] </ref> presented a dynamic programming based disparity estimation approach for establishing correspondence between edges. Tzovaras et al. [34] provided a hierarchical block matching method for disparity estimation. They were also the first to propose a bidirectional motion/disparity compensation which they called fused estimation. <p> The DC-based 4 algorithms that have their origins in the computer vision field <ref> [33, 31] </ref> are primarily targeted at scene analysis and understanding and hence are computationally intensive and do not lend themselves well to coding. <p> However, this method is iterative, and no compression results are presented. 3.1.3 Second generation and model-based disparity estimation methods Several edge-based methods for solving the correspondence problem have been proposed in the machine vision literature [see 118] and some of these methods have been extended for use in coding applications <ref> [33] </ref>. These methods typically detect intensity edges by convolving the image with a Laplacian-of-Gaussian operator and extracting the zero crossings. The extracted edges are approximated by straight line segments and labelled. <p> The extracted edges are approximated by straight line segments and labelled. Correspondence is established for an edge in one view by searching for an edge with similar orientation and length in the other view using a suitable optimization method. Dynamic programming methods have been proposed to establish such correspondences <ref> [33, 83] </ref>. The correspondences at the edges need to be propagated to other pixels. In general, the contour or edge-based disparity estimation schemes are computationally intensive, and are not efficient from the coding point of view.
Reference: [34] <author> D. Tzovaras, M. G. Strintzis, and H. Sahinoglou, </author> <title> Evaluation of multiresolution block matching techniques for motion and disparity estimation, Signal Processing: </title> <journal> Image Commun., </journal> <volume> vol. 6, no. 1, </volume> <pages> pp. 59-67, </pages> <year> 1994. </year>
Reference-contexts: They also provided a coherence equation to verify the motion and disparity components between two stereo pairs of frames. Liu and Skerjanc [33] presented a dynamic programming based disparity estimation approach for establishing correspondence between edges. Tzovaras et al. <ref> [34] </ref> provided a hierarchical block matching method for disparity estimation. They were also the first to propose a bidirectional motion/disparity compensation which they called fused estimation. A genetic algorithm based disparity estimation solution was presented by Franich [91]. This work also introduced a smoothness measure to evaluate the disparity map. <p> Other DC-based algorithms in the literature use simple fixed block-size (FBS) based disparity estimation <ref> [30, 87, 96, 34] </ref>, which can be supported by the current technology. However, the bit allocation in these schemes is not commensurate with the local disparity or motion detail present within a multi-view sequence. <p> Satisfying such arbitrary bit-rate constraints can result in inadequate residual coding. This can give rise to objectionable artifacts that can cause confusion to the viewer when the resulting sequences are viewed stereoscopically. Except for <ref> [34, 96] </ref>, most other methods consider only disparity compensation for coding multi-view sequences. This results in poor performance when a still image pair compression problem is extended to a sequence compression problem. Also, perspective-induced occlusions are not coded efficiently by these methods.
Reference: [35] <author> B. Kost and S. Pastoor, </author> <title> Visibility thresholds for disparity quantization errors in stereoscopic displays, </title> <booktitle> Proc. of SID, </booktitle> <volume> vol. 32, </volume> <pages> no.2, pp. 165-170, </pages> <year> 1991. </year>
Reference-contexts: Also, as the intra-coded frame typically discards most high frequency components, the loss of information as compared to full resolution coding can be expected to be small. However, the reduction in the horizontal resolution can result in a reduction in depth plane resolution or stereo-acuity <ref> [35] </ref>. To avoid this, we employ a sub-pixel-accurate disparity estimation at the reduced resolution that is equivalent to a half-pixel accurate disparity estimation at the original resolution.
Reference: [36] <author> Stephane G. Mallat, </author> <title> A theory for multiresolution signal decomposition: The wavelet representation, </title> <journal> IEEE Trans. on PAMI, </journal> <volume> vol. 11, no. 7, </volume> <pages> pp. 674-693, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Columns level-1 level-2 level-3 Ihh1 Rows Columns Rows Columns Ihh2 Ihh3 fl 2 fl 2 H H FIG. 2.8: 3-level multiresolution decomposition (and the resolution pyramid) Ihh3 - M/8 x N/8 Ihh1 - M/2 x N/2 I - M x N (Level-0) (Level-1) (Level-2) (Level-3) 25 decomposition theory of Mallat <ref> [36] </ref>. Filtering equivalences to wavelet decomposition can be found in [36, 72]. The close relationship between the MRFB and wavelet theory provides a rich variety of filter families to choose from, depending on specific requirements. <p> Filtering equivalences to wavelet decomposition can be found in <ref> [36, 72] </ref>. The close relationship between the MRFB and wavelet theory provides a rich variety of filter families to choose from, depending on specific requirements. The most commonly used class of wavelet-based filters are the compactly supported orthonormal wavelets of Daubechies [38].
Reference: [37] <author> S. G. Mallat, </author> <title> Multifrequency channel decompositions of image and wavelet models, </title> <journal> IEEE Trans, on ASSP, </journal> <volume> Vol. 37, no. 12, </volume> <month> Dec. </month> <year> 1989. </year>
Reference-contexts: Also, early refinements can be made at a global level, unaffected by local spatial details. Experiments in human visual physiology and psychophysics have shown that the HVS is spatial-frequency selective and that the bandwidth of these spatial filters is likely to be one octave <ref> [37] </ref>. In other words, the different frequency bands have approximately the same width on a logarithmic scale; this suggests the possibility that the HVS itself employs a multiresolution representation.
Reference: [38] <author> Ingrid Daubechies, </author> <title> Orthonormal bases of compactly supported wavelets, </title> <journal> Communications of Pure and Applied Mathematics, </journal> <volume> vol. 41, </volume> <pages> pp. 909-996, </pages> <year> 1988. </year>
Reference-contexts: The close relationship between the MRFB and wavelet theory provides a rich variety of filter families to choose from, depending on specific requirements. The most commonly used class of wavelet-based filters are the compactly supported orthonormal wavelets of Daubechies <ref> [38] </ref>. As the name suggests, these filters have a compact support (desirable for computational efficiency) while maintaining a reasonable half-band filter characteristic (needed for minimizing aliasing). <p> The estimation accuracy does not depend much on the choice of the analysis filters. We have chosen Daubechies compactly supported 6-tap filter as it offers a reasonable half band frequency response with a small number of coefficients <ref> [38] </ref>. The filter coefficients are given below. 3.2.2 Generalized quadtree decomposition Quadtree decomposition of an image is a structured recursive partitioning of an image into rectangular blocks based on a splitting criterion. Figure 3.2 illustrates a typical quadtree.
Reference: [39] <author> M. Waldowski, </author> <title> A new segmentation algorithm for videophone applications based on stereoscopic image pairs, </title> <journal> IEEE Trans. on Communications, </journal> <volume> Vol. 39, no. 12, </volume> <pages> pp. 1856-1868, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: We maintain that a representation optimal for disparity coding can be obtained by segmenting the stereoscopic image pair based on the disparity. Some earlier attempts at segmenting an image into foreground and background areas for videophone applications using a stereo camera setup are described in <ref> [39, 74] </ref>. In this subsection, we formalize the need for a such an approach. Let us assume that a suitable model can be formulated to map a set of pixels in one view of the stereo pair to a corresponding set of pixels in the other view. <p> For example, depth-adaptive bit allocation can be carried out if the depth range of interest in the scene is known. This has been used to detect background in typical head and shoulders type videophone sequences in <ref> [39] </ref>. The segmented background region is coded at a lower quality. Similar extensions for more general scenes deserve further consideration. A significant number of bits are wasted filling-in the uncovered regions in the segment tracking case.
Reference: [40] <author> I. Grammalidis, et al., </author> <title> stereoscopic image sequence coding based on three dimensional motion estimation and compensation, Signal Processing: </title> <journal> Image Commun., </journal> <volume> vol. 7, no. 2, </volume> <pages> pp. 129-145, </pages> <year> 1995. </year>
Reference-contexts: The DC-based 4 algorithms that have their origins in the computer vision field [33, 31] are primarily targeted at scene analysis and understanding and hence are computationally intensive and do not lend themselves well to coding. Advanced model-based coding methods <ref> [40, 100, 99] </ref>, which use object-oriented 3D models, do not scale well with multiple objects in the scene; they are also computationally more complex than what the current technology can support in real-time.
Reference: [41] <author> X. Wu and Y. Fang, </author> <title> A segmentation-based predictive multiresolution image coder, </title> <journal> IEEE Trans. on Image Processing, </journal> <volume> vol. 4, </volume> <pages> pp. 34-47, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: Some extensions to tree-based segmentation that reduce the number of subblocks by allowing diagonal partitions, in addition to horizontal and vertical partitions, are described in <ref> [41] </ref>. The most commonly used criterion for homogeneity is the intensity variance. <p> The intensity within each segment is usually modeled as a planar (or) quadratic surface, and the parameters of these surfaces are computed by solving the system of equations obtained by applying the model to each pixel in the region <ref> [109, 41] </ref>. The residuals after fitting the model are coded using conventional methods. 16 2.2.5 Interframe coding Image sequences have considerable temporal redundancy as objects in the scene and the camera typically undergo only small displacements between successive frames. <p> Hence the overhead needed to represent the tree structure, referred to as the segmentation overhead, is very minimal. However, as the partitioning location is obtained independent of the features within the image, the regular decomposition typically results in a larger number of blocks. Spatial homogeneity of a block, e.g. <ref> [41, 109] </ref>, and block motion, e.g. [42], have been used as h (1) = 0.23523360389202 h (2) = 0.57055845791566 h (3) = 0.32518250026277 leaf node (not divided) (bit 0) non-leaf node (bit 1) 1 3 4 5 6 9 14 15 FIG. 3.2: Illustration of regular quadtree decomposition 1010100000001100000010000 - Encoded <p> Since the dominant edge within a block can have an arbitrary orientation, this restriction results in an increase in the leaf nodes. A variance-based segmentation technique that uses diagonal partitions in addition to the horizontal and vertical partitions is described in <ref> [41] </ref>. Since computations based only on the intensity values within each segment are needed in this case, a reasonable complexity is maintained. However, if we use such partitions for DCP, we will need to estimate disparity over triangles and irregular quadrilaterals.
Reference: [42] <author> X.Zhang, M. C. Cavenor and J. F. Arnold, </author> <title> Adaptive quadtree coding of motion compensated image sequences for use on the broadband ISDN, </title> <journal> IEEE Trans. on Circuits and Systems for Video Technology, vol.3, </journal> <volume> no.3, </volume> <pages> pp. 222-229, </pages> <month> June </month> <year> 1993. </year> <month> 121 </month>
Reference-contexts: However, as the partitioning location is obtained independent of the features within the image, the regular decomposition typically results in a larger number of blocks. Spatial homogeneity of a block, e.g. [41, 109], and block motion, e.g. <ref> [42] </ref>, have been used as h (1) = 0.23523360389202 h (2) = 0.57055845791566 h (3) = 0.32518250026277 leaf node (not divided) (bit 0) non-leaf node (bit 1) 1 3 4 5 6 9 14 15 FIG. 3.2: Illustration of regular quadtree decomposition 1010100000001100000010000 - Encoded tree structure (depth-first tree traversal) 1
Reference: [43] <author> Y. Linde, A. Buzo, R. Gray, </author> <title> An algorithm for vector quantization design, </title> <journal> IEEE Trans. on Communications, COM-28, </journal> <volume> no. 1, </volume> <pages> pp. 84-95, </pages> <month> January </month> <year> 1980. </year>
Reference-contexts: The most common method for constructing a codebook is the LBG algorithm 1 , which iteratively builds the optimal codebook given the number of code vectors <ref> [43] </ref>. Several computationally efficient VQ methods (such as tree structured VQ) that reduce the search complexity when finding the best approximating code vector and several different variants have been proposed [5]. VQ-based coding can be used for direct image coding [1, 5], residual coding [1, 45], or sub-band coding [48]. <p> Also, for typical images, a larger block size has a higher likelihood of containing significant errors. The quadtree based VQ/SQ residual coding algorithm for each MB is summarized in Table 4.1. The codebooks are generated using the LBG algorithm <ref> [43] </ref>. The 16-dimensional vector codebook is obtained by training over a set of residual code vectors derived from typical sequences.
Reference: [44] <author> Stuart P. Lloyd, </author> <title> Least squares quantization in PCM, </title> <journal> IEEE Trans. on Information Theory, </journal> <volume> Vol. IT-28, No. 2, </volume> <pages> pp. 129-134, </pages> <month> March </month> <year> 1982. </year>
Reference-contexts: The 4-dimensional vector codebook is obtained in a similar manner with a larger range for the residuals. The scalar quantizer levels are designed for the Laplacian distribution of the errors <ref> [44] </ref> obtained from actual runs of the residual coder incorporating the above two VQs. The quadtree structure coding overhead (1 bit per node) and the VLCs from the VQ and SQ stages constitute the residual coding overhead for a macroblock.
Reference: [45] <author> A. Asif and J. M. F. Moura, </author> <title> Image codec by noncausal prediction, residual mean removal, and cascaded VQ, </title> <journal> IEEE Trans. on Circuits and Systems for Video Tech., </journal> <volume> Vol. 6, No. 1, </volume> <pages> pp. 42-55, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: Several computationally efficient VQ methods (such as tree structured VQ) that reduce the search complexity when finding the best approximating code vector and several different variants have been proposed [5]. VQ-based coding can be used for direct image coding [1, 5], residual coding <ref> [1, 45] </ref>, or sub-band coding [48]. Fractal image coding [50] relies on the fact that typical images have self similar structures embedded in them. A set of domain blocks with different basic features in them such as simple edges, complex edges and texture are created.
Reference: [46] <author> N. Balram and J. M. F. Moura, </author> <title> Noncausal predictive image codec, </title> <journal> IEEE Trans. on Image Proc., </journal> <volume> Vol. </volume> <pages> 5, </pages> <address> no.8, TBD, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: Figure 2.3 shows a schematic of a DPCM based lossy coder. Since quantization and coding are done at a pixel-by-pixel level, the average bits per pixel (bpp) cannot be made less than 1. A noncausal predictive coding method is presented in <ref> [46] </ref>. Orthogonal transform based coding methods [8] achieve decorrelation by packing most of the energy 2 present in a signal to be coded into the least possible number of coefficients.
Reference: [47] <author> B. G. Lee, </author> <title> A new algorithm to compute the discrete cosine transform, </title> <journal> IEEE Trans. on ASSP, </journal> <volume> ASSP-32 (6), </volume> <pages> pp. 1243-1245, </pages> <year> 1984. </year>
Reference: [48] <author> J. W. Woods and S. D. ONeil, </author> <title> Subband coding of images, </title> <journal> IEEE Trans. on ASSP, ASSP 34(5), </journal> <volume> pp.1278-1288, </volume> <year> 1986. </year>
Reference-contexts: The nonzero values after quantization are scanned in a zig-zag manner (to increase the number of zero values in a row) and are runlength encoded. A typical DCT based encoder is shown in Fig. 2.4. Several computationally efficient implementations of DCT are available [47,111]. Sub-band coding methods <ref> [48] </ref> are yet another class of waveform coding methods that exploit the non-uniform distribution of energy across the different frequency bands. These methods partition the image into different sub-bands, each of which is coded independently according to 4. <p> Several computationally efficient VQ methods (such as tree structured VQ) that reduce the search complexity when finding the best approximating code vector and several different variants have been proposed [5]. VQ-based coding can be used for direct image coding [1, 5], residual coding [1, 45], or sub-band coding <ref> [48] </ref>. Fractal image coding [50] relies on the fact that typical images have self similar structures embedded in them. A set of domain blocks with different basic features in them such as simple edges, complex edges and texture are created. <p> Methods for independent vector and scalar quantization of the sub-bands are suggested in [68, 69, 70]. The correlation across the sub-bands can be exploited by vector quantizing the vectors formed by the corresponding coefficients in the different sub-bands as in <ref> [48] </ref>. A zero-tree and successive-approximation based coding of the sub-bands that takes advantage of the predominantly zero regions in the high frequency sub-bands and the correlation across different sub-bands is described in [71].
Reference: [49] <author> H. S. Malvar and D. H. Staelin, </author> <title> The LOT: transform coding without blocking effects, </title> <journal> IEEE Trans. </journal> <volume> on ASSP-37 (4), </volume> <pages> pp. 553-559, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Sub-band coding has been shown to be equivalent to coding using an extension of (non-overlapping) block transform called the overlapped or lapped orthogonal transform (LOT) <ref> [49] </ref>. Further details about sub-band decomposition are presented in Section 2.3. Vector quantization based coding is an extension of SQ principles to overcome the 1 bpp barrier associated with SQ. Neighboring source pixels are grouped into vectors.
Reference: [50] <author> A. E. Jacquin, </author> <title> Fractal image coding - a review, </title> <booktitle> Proceeding of the IEEE, </booktitle> <address> vol.81, no.10, </address> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: VQ-based coding can be used for direct image coding [1, 5], residual coding [1, 45], or sub-band coding [48]. Fractal image coding <ref> [50] </ref> relies on the fact that typical images have self similar structures embedded in them. A set of domain blocks with different basic features in them such as simple edges, complex edges and texture are created.
Reference: [51] <author> H. Li, et al., </author> <title> Image sequence coding at very low bitrates: A review, </title> <journal> IEEE Trans. on image processing, Vol.3, </journal> <volume> no. 5, </volume> <pages> pp. 589-609, </pages> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: Typically the composite local motion is estimated using an approximation to the actual underlying 3D motion model. The region used for motion estimation is typically considered a planar patch that is undergoing motion and a suitable projective transformation is used to model the projection onto the image plane <ref> [51, 20] </ref>. Translation-only motion parallel to the image plane is the most widely used approximation. This simple model requires only two parameters, namely the horizontal and vertical components of translation.
Reference: [52] <author> J. R. Jain and A. K. Jain, </author> <title> Displacement measurement and its application in interframe image coding, </title> <journal> IEEE Trans. on Commun., vol.29, </journal> <volume> pp.1799-1806, </volume> <month> Dec. </month> <year> 1981. </year>
Reference-contexts: Motion estimation (ME) is typically performed for a group of pixels that are likely to have the same motion parameters. ME with a rectangular block of pixels and with the translation-only model is commonly known as block matching (BM) <ref> [52, 53] </ref>; it corresponds to finding a block in the reference frame that best matches (in some minimum distortion sense) the block to be predicted. The distortion function is evaluated over a search range centered around the location of zero translation.
Reference: [53] <editor> H. G. Musmann, et al., </editor> <booktitle> Advances in picture coding, Proc. of the IEEE, </booktitle> <volume> Vol. 73, no. 4, </volume> <pages> pp. 523-548, </pages> <month> Apr. </month> <year> 1985. </year>
Reference-contexts: Motion estimation (ME) is typically performed for a group of pixels that are likely to have the same motion parameters. ME with a rectangular block of pixels and with the translation-only model is commonly known as block matching (BM) <ref> [52, 53] </ref>; it corresponds to finding a block in the reference frame that best matches (in some minimum distortion sense) the block to be predicted. The distortion function is evaluated over a search range centered around the location of zero translation. <p> Several search reduction strategies have been suggested in the literature, based on the assumption that the distortion function is monotonic in the search range. The most notable of these are the logarithmic search, 3-step search and conjugate direction search <ref> [53] </ref>. Hierarchical block matching (HBM) is also logarithmically efficient, but it does not make the monotonicity assumption. HBM will be elaborated later in Section 2.3.5. Once the best match in full-pixel displacements is obtained, the estimate can be interpolated to sub-pixel accuracies.
Reference: [54] <author> B.Liu and A.Zaccarin, </author> <title> `New fast algorithms for the estimation of block motion vectors, </title> <journal> IEEE Trans. on Circuits and Systems, Vol.3, No.2, </journal> <pages> pp. 148-157, </pages> <month> April </month> <year> 1993. </year>
Reference: [55] <author> H. G. Musmann, et al., </author> <title> Object-oriented analysis synthesis coding of moving images, Signal Processing: </title> <journal> Image Commun., </journal> <volume> Vol. 1, no. 2, pp.117-138, </volume> <month> October </month> <year> 1989. </year>
Reference-contexts: Typically model-based coding methods track the objects over time, as opposed to predicting the frame-to-be-coded from a reference frame. The typical modules of such coding schemes are modeling, image analysis according to the models, model parameter coding, model failure handling, and image synthesis from the models <ref> [55, 56, 57] </ref>. The analysis stage typically consists of a segmentation 1 stage to obtain the different homogeneous regions in the scene. If the nature of the object is known a priori, as in the videoconferencing situation, suitable 3D surface or volumetric models can be used [60].
Reference: [56] <author> M. Hotter, </author> <title> Object-oriented analysis-synthesis coding based on moving two dimensional objects, Signal Processing: </title> <journal> Image Commun., </journal> <volume> vol. 2, no. 4, </volume> <pages> pp. 409-428, </pages> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: A genetic algorithm based disparity estimation solution was presented by Franich [91]. This work also introduced a smoothness measure to evaluate the disparity map. Ziegler and Panis [100] describe an object oriented coder for stereoscopic video coding along the lines of Hotters <ref> [56] </ref> analysis-synthesis based coder. However, this method is useful only when there is no camera motion and when there are not many objects in the scene. <p> Typically model-based coding methods track the objects over time, as opposed to predicting the frame-to-be-coded from a reference frame. The typical modules of such coding schemes are modeling, image analysis according to the models, model parameter coding, model failure handling, and image synthesis from the models <ref> [55, 56, 57] </ref>. The analysis stage typically consists of a segmentation 1 stage to obtain the different homogeneous regions in the scene. If the nature of the object is known a priori, as in the videoconferencing situation, suitable 3D surface or volumetric models can be used [60].
Reference: [57] <author> M. Hotter, </author> <title> Optimization and efficiency of an object-oriented analysis-synthesis coder, </title> <journal> IEEE Trans. on circuits and systems for video tech., </journal> <volume> Vol. 4, </volume> <pages> no.2, pp. 181-194, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Typically model-based coding methods track the objects over time, as opposed to predicting the frame-to-be-coded from a reference frame. The typical modules of such coding schemes are modeling, image analysis according to the models, model parameter coding, model failure handling, and image synthesis from the models <ref> [55, 56, 57] </ref>. The analysis stage typically consists of a segmentation 1 stage to obtain the different homogeneous regions in the scene. If the nature of the object is known a priori, as in the videoconferencing situation, suitable 3D surface or volumetric models can be used [60]. <p> If the nature of the object is known a priori, as in the videoconferencing situation, suitable 3D surface or volumetric models can be used [60]. Model failure (MF) corresponds to regions that cannot be modeled correctly (such as uncovered background). These regions are usually handled by waveform coding methods <ref> [57] </ref>. By assuming the objects to be non-rigid and using motion models for exible objects, the MF regions are considerably reduced.
Reference: [58] <author> K. M. Uz, M. Vetterli, D. J. LeGall, </author> <title> Interpolative multiresolution coding of advanced television with compatible subchannels, </title> <journal> IEEE Trans. on circuits and systems for video 122 tech., Vol.1, </journal> <volume> No.1, </volume> <pages> pp. 86-99, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: Hence the sub-band decomposition is usually preferred over pyramid decomposition for coding purposes. However, Laplacian pyramid coding has the advantage that quantization errors in the higher levels of the pyramid can be included in the lower level detail images, thus avoiding accumulation of errors <ref> [58] </ref>. Only the quantization errors while coding the level-0 detail image remain. Such quantization error feedback is not possible in sub-band coding, and the quantization errors can also lead to aliasing during reconstruction. On the other hand, sub-band coding can exploit the orientation sensitivity of the HVS. <p> The frame rate difference between different video sources (60 Hz and 50 Hz field repetition rates in TVs and 24 frames per second in movies) can also be handled if the multiresolution concept is extended in the temporal dimension. One such scheme is presented in <ref> [58] </ref>. Block size is fixed at all levels. Each block in level- (j+1) corresponds to 4 blocks in level-j. The initial estimate for the disparity vector of a block in level-j is twice that of the corresponding disparity vector in level-(j+1).
Reference: [59] <author> M. F. Chowdhury, et al., </author> <title> A switched model-based coder for video signals, </title> <journal> IEEE Trans. on circuits and systems for video tech., </journal> <volume> Vol. 4, no. 3, </volume> <pages> pp. 216-227, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Some researchers have proposed a switched hybrid coder, that uses model-based coding for coding objects complying to the model and waveform-based coding for coding the model failure regions <ref> [59] </ref>, to encode more complex scenes. 1.
Reference: [60] <author> C. S. Choi, et al., </author> <title> Analysis and synthesis of facial image sequences in model-based image coding, </title> <journal> IEEE Trans. on circuits and systems for video tech., </journal> <volume> Vol. 4, no. 3, </volume> <pages> pp. 257-275, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: The analysis stage typically consists of a segmentation 1 stage to obtain the different homogeneous regions in the scene. If the nature of the object is known a priori, as in the videoconferencing situation, suitable 3D surface or volumetric models can be used <ref> [60] </ref>. Model failure (MF) corresponds to regions that cannot be modeled correctly (such as uncovered background). These regions are usually handled by waveform coding methods [57]. By assuming the objects to be non-rigid and using motion models for exible objects, the MF regions are considerably reduced.
Reference: [61] <author> D. Taubman and A. Zakhor, </author> <title> Multirate 3D subband coding of video, </title> <journal> IEEE Trans. on image processing, </journal> <volume> vol. 3, no. 5, </volume> <pages> pp. 572-588, </pages> <month> Sep. </month> <year> 1994. </year>
Reference-contexts: Coding methods that exploit this redundancy that exists between temporally adjacent frames are known as interframe coding methods. Motion compensated prediction (MCP) is the most widely employed interframe coding method. Even spatio-temporal extensions of transform and sub-band coding methods <ref> [2, 61] </ref> include a motion compensation stage. In a typical image sequence, motion from frame-to-frame is a composite of the individual object motions and the motion of the camera in the 3-D space, projected on the image plane.
Reference: [62] <author> M. Kunt, et al., </author> <title> Second generation image coding techniques, </title> <journal> Proc. IEEE, </journal> <volume> vol. 73, </volume> <pages> pp. 549 574, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: For each segment, the shape, location and the parameters modeling the intensity and color distribution within that segment, need to be coded. Region growing methods, the early segmentation methods, employ a combination of edge and texture discrimination techniques to obtain homogeneously textured areas <ref> [62, 75] </ref>. Recently, mathematical morphology has been used to segment images [63, 64]. Contour coding is the coding of arbitrary shapes over the discrete grid. Chain coding [9], the simplest known way of exactly coding a contour, is typically not bit efficient.
Reference: [63] <author> F. Meyer and S. Beucher, </author> <title> Morphological segmentation, </title> <journal> J. Visual Commun. & Image representation, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 21-46, </pages> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: Region growing methods, the early segmentation methods, employ a combination of edge and texture discrimination techniques to obtain homogeneously textured areas [62, 75]. Recently, mathematical morphology has been used to segment images <ref> [63, 64] </ref>. Contour coding is the coding of arbitrary shapes over the discrete grid. Chain coding [9], the simplest known way of exactly coding a contour, is typically not bit efficient.
Reference: [64] <author> P. Salembier and M. Pardas, </author> <title> Hierarchical morphological segmentation for image sequence coding, </title> <journal> IEEE Trans. on image processing, </journal> <volume> vol. 3, no. 5, </volume> <pages> pp. 639-651, </pages> <month> Sep. </month> <year> 1994. </year>
Reference-contexts: Region growing methods, the early segmentation methods, employ a combination of edge and texture discrimination techniques to obtain homogeneously textured areas [62, 75]. Recently, mathematical morphology has been used to segment images <ref> [63, 64] </ref>. Contour coding is the coding of arbitrary shapes over the discrete grid. Chain coding [9], the simplest known way of exactly coding a contour, is typically not bit efficient.
Reference: [65] <author> C-L. Huang and C-Y Hsu, </author> <title> A new motion compensation method for image sequence coding using hierarchical grid interpolation, </title> <journal> IEEE Trans. on circuits and systems for video tech., </journal> <volume> vol. 4, no. 1, </volume> <pages> pp. 42-52, </pages> <month> Feb. </month> <year> 1994. </year>
Reference: [66] <author> T. R. Fischer, </author> <title> A pyramid vector quantizer, </title> <journal> IEEE Trans. on Inform. theory, </journal> <volume> vol. 32, no. 4, </volume> <pages> pp. 568-583, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: In some cases, vectors in a lattice structure with certain desirable properties are chosen as codevectors, thus obviating the need to transmit the codebook <ref> [66, 67, 113] </ref>. The most common method for constructing a codebook is the LBG algorithm 1 , which iteratively builds the optimal codebook given the number of code vectors [43].
Reference: [67] <author> H. S. Wang and N. Moayeri, </author> <title> Trellis coded vector quantization, </title> <journal> IEEE Trans. on Commun., </journal> <volume> vol. 40, no. 8, </volume> <pages> pp. 1273-1276, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: In some cases, vectors in a lattice structure with certain desirable properties are chosen as codevectors, thus obviating the need to transmit the codebook <ref> [66, 67, 113] </ref>. The most common method for constructing a codebook is the LBG algorithm 1 , which iteratively builds the optimal codebook given the number of code vectors [43].
Reference: [68] <author> M. Antonini, et al., </author> <title> Image coding using wavelet transform, </title> <journal> IEEE Trans. on Image Proc., </journal> <volume> vol. 1, no. 2, </volume> <pages> pp. 205-220, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Such quantization error feedback is not possible in sub-band coding, and the quantization errors can also lead to aliasing during reconstruction. On the other hand, sub-band coding can exploit the orientation sensitivity of the HVS. Methods for independent vector and scalar quantization of the sub-bands are suggested in <ref> [68, 69, 70] </ref>. The correlation across the sub-bands can be exploited by vector quantizing the vectors formed by the corresponding coefficients in the different sub-bands as in [48].
Reference: [69] <author> M. Barlaud, et al., </author> <title> Pyramidal lattice vector quantization for multiscale image coding, </title> <journal> IEEE Trans. on Image Proc., </journal> <volume> vol. 3, no. 4, </volume> <pages> pp. 367-381, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: Such quantization error feedback is not possible in sub-band coding, and the quantization errors can also lead to aliasing during reconstruction. On the other hand, sub-band coding can exploit the orientation sensitivity of the HVS. Methods for independent vector and scalar quantization of the sub-bands are suggested in <ref> [68, 69, 70] </ref>. The correlation across the sub-bands can be exploited by vector quantizing the vectors formed by the corresponding coefficients in the different sub-bands as in [48].
Reference: [70] <author> P. C. Cosman, et al., </author> <title> Vector quantization of image subbands: a survey, </title> <journal> IEEE Trans. on Image Proc., </journal> <volume> vol. 5, no. 2. </volume> <pages> pp. 202-225, </pages> <month> Feb. </month> <year> 1996. </year>
Reference-contexts: Such quantization error feedback is not possible in sub-band coding, and the quantization errors can also lead to aliasing during reconstruction. On the other hand, sub-band coding can exploit the orientation sensitivity of the HVS. Methods for independent vector and scalar quantization of the sub-bands are suggested in <ref> [68, 69, 70] </ref>. The correlation across the sub-bands can be exploited by vector quantizing the vectors formed by the corresponding coefficients in the different sub-bands as in [48].
Reference: [71] <author> J. M. Shapiro, </author> <title> An embedded hierarchical image coder using zerotrees of wavelet coefficients, </title> <booktitle> Proc. of Data Compression Conf., </booktitle> <year> 1993, </year> <pages> pp. 214-223. </pages>
Reference-contexts: A zero-tree and successive-approximation based coding of the sub-bands that takes advantage of the predominantly zero regions in the high frequency sub-bands and the correlation across different sub-bands is described in <ref> [71] </ref>. Both 26 representations offer progressive transmission capability in which the coarser resolution subimages are transmitted first and the detail images are progressively added.
Reference: [72] <author> M. Vetterli and C. Herley, </author> <title> Wavelets and filter banks: Theory and design, </title> <journal> IEEE Trans. on Signal Proc., </journal> <volume> vol. 40, no. 9, </volume> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: Filtering equivalences to wavelet decomposition can be found in <ref> [36, 72] </ref>. The close relationship between the MRFB and wavelet theory provides a rich variety of filter families to choose from, depending on specific requirements. The most commonly used class of wavelet-based filters are the compactly supported orthonormal wavelets of Daubechies [38].
Reference: [73] <author> S. L. Horowitz and T. Pavlidis, </author> <title> Picture segmentation by a tree traversal algorithm, </title> <journal> J. Assoc. Computing Mach., </journal> <volume> vol. 23, </volume> <pages> pp. 368-388, </pages> <year> 1976. </year> <month> 123 </month>
Reference-contexts: Though the splitting criteria in step 6 of the DBS algorithm in Section 3.2.5 ensures that a node is split only if its child nodes have different disparities, there can be spatially adjacent leaf nodes that share the same disparity value. The motivation of split and merge methods <ref> [73] </ref> is to merge these regions to obtain homogeneous (but arbitrarily shaped) areas, which can be used in applications such as pattern recognition. However, from the coding point of view, a label has to be assigned to each group of spatially adjacent leaf nodes that share the same depth.
Reference: [74] <author> T. Aach and A. Kaup, </author> <title> Disparity-based segmentation of stereoscopic foreground/ background image sequences, </title> <journal> IEEE Trans. on Commun., </journal> <volume> vol. 42, </volume> <pages> no.2, pp. 673-679, </pages> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: We maintain that a representation optimal for disparity coding can be obtained by segmenting the stereoscopic image pair based on the disparity. Some earlier attempts at segmenting an image into foreground and background areas for videophone applications using a stereo camera setup are described in <ref> [39, 74] </ref>. In this subsection, we formalize the need for a such an approach. Let us assume that a suitable model can be formulated to map a set of pixels in one view of the stereo pair to a corresponding set of pixels in the other view.
Reference: [75] <author> R. M. Haralick and L. G. Shapiro, </author> <title> Survey: Image segmentation techniques, </title> <journal> J. Computer vision, graphics and image proc., </journal> <volume> vol. 29, </volume> <pages> pp. 100-132, </pages> <year> 1985. </year>
Reference-contexts: For each segment, the shape, location and the parameters modeling the intensity and color distribution within that segment, need to be coded. Region growing methods, the early segmentation methods, employ a combination of edge and texture discrimination techniques to obtain homogeneously textured areas <ref> [62, 75] </ref>. Recently, mathematical morphology has been used to segment images [63, 64]. Contour coding is the coding of arbitrary shapes over the discrete grid. Chain coding [9], the simplest known way of exactly coding a contour, is typically not bit efficient.
Reference: [76] <author> P.J.Burt and E.H.Adelson, </author> <title> The Laplacian Pyramid as a compact image code', </title> <journal> IEEE Trans. on Commun., </journal> <volume> Vol. 31, No. 4, </volume> <pages> pp. </pages> , <month> April </month> <year> 1983. </year>
Reference-contexts: A decomposition that employs octave-bandwidth filters (followed by subsampling by a factor of 2) to obtain the MR subimages is known as a dyadic decomposition. Since a filter with a gaussian shape has compact support in both the spatial and frequency domains, the first proposed MR decomposition <ref> [76] </ref> used such a filter. However, such a filter does not have unity gain in the entire passband, and hence results in excessive smoothing. The collection of progressively lower resolution sub-images is called a Gaussian pyramid and will be used for progressive refinement. <p> The collection of the detail images at the different resolution levels is called a Laplacian pyramid, as the difference of the Gaussian filtered images corresponds to directly applying a Laplacian operator <ref> [76] </ref>. Figure 2.6 illustrates the construction of the Gaussian and Laplacian pyramids. The coarsest level sub-image of the Laplacian pyramid is the same as the coarsest level sub-image of the Gaussian pyramid. Since the detail images are typically sparse, they can be compressed efficiently.
Reference: [77] <author> T. Okoshi, </author> <title> Three-dimensional displays, </title> <journal> Proc. of the IEEE, </journal> <volume> vol. 68, no. 5, </volume> <month> May </month> <year> 1980. </year>
Reference: [78] <author> L. Lipton, </author> <title> The evolution of electronic stereoscopy, </title> <journal> SMPTE Journal, </journal> <volume> vol. 100, no. 5, </volume> <pages> pp. 332-336, </pages> <month> May </month> <year> 1991. </year>
Reference: [79] <author> D. J. Le Gall, </author> <title> MPEG: A video compression standard for multimedia applications, </title> <journal> Commun. of the ACM, </journal> <volume> vol. 34, no. 4, </volume> <pages> pp. </pages> <month> 47-58,April </month> <year> 1991. </year>
Reference: [80] <author> M. Liou, </author> <title> Overview of the px64 kbits/s video coding standard, </title> <journal> Commun. of the ACM, </journal> <volume> vol. 34, no. 4, </volume> <pages> pp. </pages> <month> 60-63,,April </month> <year> 1991. </year>
Reference: [81] <author> M. Irani, et al., </author> <title> Video compression using mosaic representations, Signal Processing: </title> <journal> Image Commun., </journal> <volume> vol. </volume> <pages> 7, </pages> <address> no.4-6, pp.529-552, </address> <month> Nov. </month> <year> 1995. </year>
Reference-contexts: Similar extensions for more general scenes deserve further consideration. A significant number of bits are wasted filling-in the uncovered regions in the segment tracking case. If the background region over a group of frames can be extracted (for e.g. using mosaic-based coding techniques <ref> [81, 115] </ref>) and coded as a single image, then the foreground region can be overlaid. This can give rise to perceptually pleasing images even at low bit-rates.
Reference: [82] <author> J. Y. A. Wang and E. H. Adelson, </author> <title> Representing moving images with layers, </title> <journal> IEEE Trans. on Image Proc., </journal> <volume> vol. 3, no. 5, </volume> <pages> pp. 625-638, </pages> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: For sequences in which the camera motion is such that it is dominant over object motions and is likely to cover spatially adjacent locations over a long period of time, a new class of methods known as mosaic-based coding methods have evolved <ref> [82, 115] </ref>. These methods register the frames over time using appropriate warping techniques to account for the camera motion and obtain a composite panoramic mosaic image. Thus the temporal redundancies are eliminated. The mosaic is coded using standard intracoding methods. <p> The coded mosaic and registration parameters are sufficient to reconstruct the sequence. Regions with local motion are handled through cut and paste operations in [115]. A similar coding scheme that peels foreground objects and codes the sequence as a set of layered (depth-wise) constructs is presented in <ref> [82] </ref>. It should be noted that, because of the a priori knowledge used, a model based coder designed for a particular type of scene is not optimal for coding a different type of scene.
Reference: [83] <author> Y. Ohta and T. Kanade, </author> <title> Stereo by intra- and inter scanline search using dynamic programming, </title> <journal> IEEE Trans. PAMI, </journal> <volume> Vol. 7, no. 2, </volume> <pages> pp. 139-154, </pages> <month> March </month> <year> 1985. </year>
Reference-contexts: The extracted edges are approximated by straight line segments and labelled. Correspondence is established for an edge in one view by searching for an edge with similar orientation and length in the other view using a suitable optimization method. Dynamic programming methods have been proposed to establish such correspondences <ref> [33, 83] </ref>. The correspondences at the edges need to be propagated to other pixels. In general, the contour or edge-based disparity estimation schemes are computationally intensive, and are not efficient from the coding point of view.
Reference: [84] <author> C. E. Shannon, </author> <title> Coding theorems for a discrete source with a fidelity criterion, </title> <booktitle> in IRE Nat. Conv. Rec., </booktitle> <address> part4, pp.142-163, </address> <year> 1959. </year>
Reference-contexts: Such redundancy removal leads to lossless compression methods. However, lossless compression can typically achieve only very low compression factors 2 . Source coding with respect to a fidelity criterion <ref> [84] </ref> can be used to increase the compression ratio while restricting the distortions introduced to be below certain permissible limit. Quantization of source symbols with respect to the mean squared error fidelity criterion is a commonly employed source coding method.
Reference: [85] <author> H. H. Baker and R. C. Bolles, </author> <title> Generalizing epipolar-plane image analysis on the spatiotemporal surface, </title> <journal> Intl. J. of Computer Vision, </journal> <volume> Vol. 3, pp.33-49, </volume> <year> 1989. </year> <note> Conference/Workshop papers: </note>
Reference-contexts: In that paper, one view is coded separately and all the other views are predicted from the independently coded view. An analysis of epipolar plane images (EPIs), which are a set of multiple views very closely spaced, is presented in <ref> [85] </ref>. The analysis is used for obtaining a compact representation of the unambiguous depth information over a viewing range. However, the acquisition, processing and compression of these very large number of views may not be practical for transmission purposes.
Reference: [86] <author> Michael E. Lukacs, </author> <title> Predictive coding of multi-viewpoint image sets, </title> <booktitle> in Proc. of ICASSP, </booktitle> <year> 1986, </year> <pages> pp. 521-524. </pages>
Reference-contexts: However, typically, these methods are computationally intensive and are not directly suited for coding applications. The 1. Analog transmission methods also exploit some of these factors to achieve bandwidth reduction. 3 paper by Lukacs <ref> [86] </ref> constitutes one of the earliest attempts at multi-view coding in which the concept of disparity compensation (DC) (- establishing correspondence between similar areas in two images using the binocular disparity relationship - discussed in detail in Chapter 3) is used to predict the rest of the views from an independently <p> We also consider an adaptation of the multiple-baseline disparity estimation method, which can reduce ambiguous matches, for coding multi-view images. 5.2 PRIOR WORK Multi-view coding and synthesis of intermediate views has been studied by several researchers. A pel-recursive disparity compensation based coding of the multiple views was presented in <ref> [86] </ref>. In that paper, one view is coded separately and all the other views are predicted from the independently coded view. An analysis of epipolar plane images (EPIs), which are a set of multiple views very closely spaced, is presented in [85].
Reference: [87] <author> A.Schertz, </author> <title> Source coding of stereoscopic television pictures, </title> <booktitle> Third intl. conf. on image proc. and its applications, IEE Conf. Pub. </booktitle> <volume> no. 307, </volume> <year> 1989, </year> <month> pp.462-464. </month>
Reference-contexts: Other DC-based algorithms in the literature use simple fixed block-size (FBS) based disparity estimation <ref> [30, 87, 96, 34] </ref>, which can be supported by the current technology. However, the bit allocation in these schemes is not commensurate with the local disparity or motion detail present within a multi-view sequence. <p> Also, perspective-induced occlusions are not coded efficiently by these methods. While most of the coding advantages in video compression have been achieved by exploiting the tolerances of the human visual system, only few researchers <ref> [30, 87, 101] </ref> have exploited special stereoscopic masking effects to achieve large stereoscopic compression gains. <p> As was discussed in Section 2.2.7, international video coding standards adopt FBS-BMA for motion estimation because of its implementation simplicity. Hence a majority of researchers have applied it for DCP also <ref> [31, 87, 89, 91, 97] </ref>. However, these methods have certain inherent shortcomings which are 1. Physically, this implies a planar patch that lies parallel to the image sensors at a fixed depth.
Reference: [88] <author> A. Tamtaoui and C. Labit, </author> <title> Coherent disparity and motion compensation in 3DTV image sequence coding schemes, </title> <booktitle> in Proc. of ICASSP, </booktitle> <year> 1991, </year> <pages> pp. 2845-2848. </pages>
Reference-contexts: He was also one of the first advocates of mixed resolution coding, wherein one of the views is presented at a lower resolution. A similar solution was also suggested by Dinstein [89]. Tamtaoui and Labit <ref> [31, 88] </ref> presented a constrained motion and disparity estimation scheme based on a calibrated pair of converged cameras. They also provided a coherence equation to verify the motion and disparity components between two stereo pairs of frames.
Reference: [89] <author> I. Dinstein, et al., </author> <title> Compression of stereoscopic images and the evaluation of its effects on 124 3D perception, </title> <booktitle> in SPIE Conf. Applications of Digital Image Processing XII, 1989, </booktitle> <volume> Vol. 1153, </volume> <pages> pp. 522-530. </pages>
Reference-contexts: He was also one of the first advocates of mixed resolution coding, wherein one of the views is presented at a lower resolution. A similar solution was also suggested by Dinstein <ref> [89] </ref>. Tamtaoui and Labit [31, 88] presented a constrained motion and disparity estimation scheme based on a calibrated pair of converged cameras. They also provided a coherence equation to verify the motion and disparity components between two stereo pairs of frames. <p> As was discussed in Section 2.2.7, international video coding standards adopt FBS-BMA for motion estimation because of its implementation simplicity. Hence a majority of researchers have applied it for DCP also <ref> [31, 87, 89, 91, 97] </ref>. However, these methods have certain inherent shortcomings which are 1. Physically, this implies a planar patch that lies parallel to the image sensors at a fixed depth. <p> This restricts the number of bits that can be allocated for residual coding. The significant residuals that are left uncoded can result in visually distracting artifacts. The noticeable artifacts can be suppressed by trading off resolution and coding the auxiliary stream frames at a reduced resolution. Psychophysical studies <ref> [12, 30, 89, 107] </ref> have shown that satisfactory stereoscopic perception is achieved even when one of the stereoscopic sequences is presented to a viewer at a Auxiliary stream stream Main I B P P MDBS Track MCP 1 1 1 P A I A 1 1 2 2 Track Track Track <p> During display, a bilinear interpolation is applied to expand the size. The subsampling and upsampling are thus done in an adhoc fashion, without any consideration about aliasing or the reconstruction quality. A Gaussian pyramid (see Section 2.3.1) based subsampling and upsampling is used for reduced resolution coding in <ref> [89] </ref>. Since we employ a multiresolution framework for segmentation and motion/disparity estimation, the mixed-resolution based coding automatically fits into our framework. <p> Mixed Resolution Sacrifices resolution to achieve lower bit-rates - psychophysically motivated - fits well within the multiresolution framework 86 difference in perceived stereoscopic quality (as demonstrated through psychophysical experiments in <ref> [30, 89] </ref>). Our reported results are based only on the PSNR quality metric.
Reference: [90] <author> J. Liu and R. Skerjanc, </author> <title> Construction of intermediate pictures for a multiview 3D system, </title> <booktitle> SPIE/IS&T Symp. on Electronic imaging, </booktitle> <volume> Vol. 1669, </volume> <month> Feb. </month> <year> 1992, </year> <pages> pp. 10-19. </pages>
Reference: [91] <author> R. E. H. Franich, R. L. Lagendijk, and J. Biemond, </author> <title> Stereo-enhanced displacement estimation by genetic block matching, </title> <booktitle> in SPIE Conf. Visual Commun. Image Processing, 1993, </booktitle> <volume> Vol. </volume> <year> 2094, </year> <pages> pp. 362-371. </pages>
Reference-contexts: Tzovaras et al. [34] provided a hierarchical block matching method for disparity estimation. They were also the first to propose a bidirectional motion/disparity compensation which they called fused estimation. A genetic algorithm based disparity estimation solution was presented by Franich <ref> [91] </ref>. This work also introduced a smoothness measure to evaluate the disparity map. Ziegler and Panis [100] describe an object oriented coder for stereoscopic video coding along the lines of Hotters [56] analysis-synthesis based coder. <p> As was discussed in Section 2.2.7, international video coding standards adopt FBS-BMA for motion estimation because of its implementation simplicity. Hence a majority of researchers have applied it for DCP also <ref> [31, 87, 89, 91, 97] </ref>. However, these methods have certain inherent shortcomings which are 1. Physically, this implies a planar patch that lies parallel to the image sensors at a fixed depth. <p> HBM for disparity compensation is considered by us in [103]. A very closely related method is described in [99]. These methods improve the smoothness of the disparity map to a certain extent. A genetic algorithm based block matching scheme is described in <ref> [91] </ref>, which specifically tries to achieve a smoother disparity map.
Reference: [92] <author> T. Ozkan and E. Salari, </author> <title> Coding of stereoscopic images, </title> <booktitle> SPIE/IS&T Symp. on Electronic imaging, </booktitle> <volume> Vol. </volume> <year> 1903, </year> <month> Feb. </month> <year> 1993, </year> <pages> pp. 228-235. </pages>
Reference: [93] <author> T.Fujii and H.Harashima, </author> <title> Data compression of an autostereoscopic 3-D Image, </title> <booktitle> IST/SPIE Symp. on Electronic Imaging, Stereoscopic Displays and applications, </booktitle> <address> Vol.2177, </address> <year> 1994, </year> <pages> pp. 108-118. </pages>
Reference-contexts: A perceptually adaptive quantization scheme for such a compatible coder is presented in [101]. Some new algorithms have been reported in the area of multi-view coding and intermediate view synthesis (IVS) as well. Fujii et al. <ref> [93] </ref> describe a disparity estimation based multi-view coding and interpolation scheme. The encoding procedure extracts the 3D structure and texture of the scene. The disparity is computed on triangular patches using an affine model. The encoding procedure is computationally intensive even for simple scenes. <p> However, the acquisition, processing and compression of these very large number of views may not be practical for transmission purposes. Recently, a variation of the EPI analysis method was presented for compression purposes in <ref> [93] </ref>. The multi-view images are stacked up in what they call the multi-view image space. The disparity between adjacent views is represented in a normalized object space. A triangular mesh for the scene is chosen based on intensity variance. Using affine 1.
Reference: [94] <author> B. L. Tseng and D.Anastassiou, </author> <title> A theoretical study on accurate reconstruction of multiview images based on the Viterbi algorithm, </title> <booktitle> Proc. of Intl. Conf. on Image Processing, </booktitle> <address> Washington D.C, </address> <booktitle> 1995, </booktitle> <volume> Vol. 2, </volume> <pages> pp. 378-381. </pages>
Reference: [95] <author> H. Aydinoglu and M. H. Hayes, </author> <title> Compression of multi-view images, </title> <booktitle> Proc. of Intl. Conf. on Image Processing, </booktitle> <address> Austin, TX, </address> <booktitle> 1994, </booktitle> <volume> Vol. 2, </volume> <pages> pp. 385-388. </pages>
Reference-contexts: Good synthesis capability has been reported for simple scenes. However, the paper does not discuss the coding approach used to code the disparities. A coding scheme is reported in <ref> [95] </ref>, where two extreme view images are coded along with two disparity maps that specify the disparity for each pixel in these extreme views. In addition, if regions occluded in the extreme views are visible in the intermediate views, an additional intensity image and a disparity map are coded.
Reference: [96] <author> A. Puri, R. V. Kollarits and B. G. </author> <title> Haskell, Stereoscopic video compression using temporal scalability, </title> <booktitle> in SPIE Conf. Visual Commun. Image Processing, 1995, </booktitle> <volume> Vol. 2501, </volume> <pages> pp. 745-756. </pages>
Reference-contexts: However, no conclusive results are shown to indicate general applicability of such a coder. Puri et al. <ref> [96] </ref> present results of MPEG-2 compatible coding. One of the views is coded in the base layer and the other vie w is coded within the enhancement layer of the temporal scalability model of the MPEG-2 standard. <p> Other DC-based algorithms in the literature use simple fixed block-size (FBS) based disparity estimation <ref> [30, 87, 96, 34] </ref>, which can be supported by the current technology. However, the bit allocation in these schemes is not commensurate with the local disparity or motion detail present within a multi-view sequence. <p> Satisfying such arbitrary bit-rate constraints can result in inadequate residual coding. This can give rise to objectionable artifacts that can cause confusion to the viewer when the resulting sequences are viewed stereoscopically. Except for <ref> [34, 96] </ref>, most other methods consider only disparity compensation for coding multi-view sequences. This results in poor performance when a still image pair compression problem is extended to a sequence compression problem. Also, perspective-induced occlusions are not coded efficiently by these methods. <p> Though reduced quality coding of auxiliary frames has been considered in the literature <ref> [96] </ref>, the excess bandwidth is arbitrarily chosen. Also the impact of the reference frame quality has not been addressed by other researchers. <p> This configuration thus has the capability to choose adaptively between DCP and MCP. However, the decoder no longer has the complete disparity map and hence synthesis of intermediate views is not possible. The second configuration is similar to the configuration-2 described in <ref> [96] </ref>, in which an MPEG-2 compatible stereoscopic sequence coding scheme by using MPEG-2s temporal scalability model is considered. Our two basic configurations are illustrated in Fig. 4.2. 4.2 RESIDUAL CODER Before considering the SSC schemes, we briey describe the residual coder that we employ.
Reference: [97] <author> A. Puri et al., </author> <title> Compression of stereoscopic video using MPEG-2, </title> <booktitle> Proc. SPIE Vol. </booktitle> <month> CR60, </month> <title> Standards and common interfaces for video information systems, </title> <editor> K. R. </editor> <publisher> Rao (Ed.), </publisher> <pages> pp. 309-334. </pages>
Reference-contexts: As was discussed in Section 2.2.7, international video coding standards adopt FBS-BMA for motion estimation because of its implementation simplicity. Hence a majority of researchers have applied it for DCP also <ref> [31, 87, 89, 91, 97] </ref>. However, these methods have certain inherent shortcomings which are 1. Physically, this implies a planar patch that lies parallel to the image sensors at a fixed depth.
Reference: [98] <author> S. Malassiotis and M. G. Strintzis, </author> <title> Joint motion/disparity estimation for stereoscopic image sequences, </title> <booktitle> in SPIE Conf. Visual Commun. Image Processing, 1994, </booktitle> <volume> Vol. 2308, </volume> <pages> pp. 614-625. </pages>
Reference: [99] <author> D. Tzovaras, N. Grammalidis, and M. G. Strintzis, </author> <title> Object-based coding of stereoscopic image sequences using joint 3D motion/disparity segmentation, </title> <booktitle> in SPIE Conf. Visual Commun. Image Processing, 1995, </booktitle> <volume> Vol. 2501, </volume> <pages> pp. 1678-1689. </pages>
Reference-contexts: Ziegler and Panis [100] describe an object oriented coder for stereoscopic video coding along the lines of Hotters [56] analysis-synthesis based coder. However, this method is useful only when there is no camera motion and when there are not many objects in the scene. Tzovaras et al. <ref> [99] </ref> have also recently proposed an object oriented coder that extracts the 3D motion model of objects based on the depth computed from the disparity map, and segments the frames based on depth and motion. However, no conclusive results are shown to indicate general applicability of such a coder. <p> The DC-based 4 algorithms that have their origins in the computer vision field [33, 31] are primarily targeted at scene analysis and understanding and hence are computationally intensive and do not lend themselves well to coding. Advanced model-based coding methods <ref> [40, 100, 99] </ref>, which use object-oriented 3D models, do not scale well with multiple objects in the scene; they are also computationally more complex than what the current technology can support in real-time. <p> The number of spurious matches can be reduced by resorting to hierarchical block matching described in Section 2.3.5. HBM for disparity compensation is considered by us in [103]. A very closely related method is described in <ref> [99] </ref>. These methods improve the smoothness of the disparity map to a certain extent. A genetic algorithm based block matching scheme is described in [91], which specifically tries to achieve a smoother disparity map. <p> The correspondences at the edges need to be propagated to other pixels. In general, the contour or edge-based disparity estimation schemes are computationally intensive, and are not efficient from the coding point of view. Recently, model-based image coding methods <ref> [100, 99] </ref> have been applied to make the disparity compensation adaptive to the actual objects present in the scene. As was explained in Section 2.2.6, these model-based coding methods are well suited only for restricted applications.
Reference: [100] <author> M. Ziegler and S. Panis, </author> <title> An object-based stereoscopic coder, </title> <booktitle> in Intl. workshop on Stereoscopic and Three Dimensional Imaging, </booktitle> <year> 1995, </year> <pages> pp. 40-45. </pages>
Reference-contexts: They were also the first to propose a bidirectional motion/disparity compensation which they called fused estimation. A genetic algorithm based disparity estimation solution was presented by Franich [91]. This work also introduced a smoothness measure to evaluate the disparity map. Ziegler and Panis <ref> [100] </ref> describe an object oriented coder for stereoscopic video coding along the lines of Hotters [56] analysis-synthesis based coder. However, this method is useful only when there is no camera motion and when there are not many objects in the scene. <p> The DC-based 4 algorithms that have their origins in the computer vision field [33, 31] are primarily targeted at scene analysis and understanding and hence are computationally intensive and do not lend themselves well to coding. Advanced model-based coding methods <ref> [40, 100, 99] </ref>, which use object-oriented 3D models, do not scale well with multiple objects in the scene; they are also computationally more complex than what the current technology can support in real-time. <p> The correspondences at the edges need to be propagated to other pixels. In general, the contour or edge-based disparity estimation schemes are computationally intensive, and are not efficient from the coding point of view. Recently, model-based image coding methods <ref> [100, 99] </ref> have been applied to make the disparity compensation adaptive to the actual objects present in the scene. As was explained in Section 2.2.6, these model-based coding methods are well suited only for restricted applications.
Reference: [101] <author> B. L. Tseng and D. Anastassiou, </author> <title> Perceptual adaptive quantization of stereoscopic video coding using MPEG-2s temporal scalability structure, </title> <booktitle> in Intl. workshop on Stereoscopic and Three Dimensional Imaging, </booktitle> <year> 1995, </year> <pages> pp. 52-57. 125 </pages>
Reference-contexts: One of the views is coded in the base layer and the other vie w is coded within the enhancement layer of the temporal scalability model of the MPEG-2 standard. A perceptually adaptive quantization scheme for such a compatible coder is presented in <ref> [101] </ref>. Some new algorithms have been reported in the area of multi-view coding and intermediate view synthesis (IVS) as well. Fujii et al. [93] describe a disparity estimation based multi-view coding and interpolation scheme. The encoding procedure extracts the 3D structure and texture of the scene. <p> Also, perspective-induced occlusions are not coded efficiently by these methods. While most of the coding advantages in video compression have been achieved by exploiting the tolerances of the human visual system, only few researchers <ref> [30, 87, 101] </ref> have exploited special stereoscopic masking effects to achieve large stereoscopic compression gains. <p> A perceptually adaptive residual coding scheme that takes into account stereoscopic masking effects, such as suppression of artifacts in a coarsely quantized view when the corresponding regions in the other view are coded at a higher quality, is presented in <ref> [101] </ref>. A similar extension within our framework can lead to further reduction in the excess bandwidth without affecting the perceived stereoscopic quality. The extension of the framework to multiple views also requires further consideration.
Reference: [102] <author> M. W. Siegel, et al., </author> <title> Compression of stereoscopic image pairs and streams, </title> <booktitle> in SPIE Conf. Stereoscopic Displays and Virtual Reality Systems, 1994, </booktitle> <volume> Vol. 2177, </volume> <pages> pp. 258-268. </pages>
Reference: [103] <author> S. Sethuraman, M. W. Siegel, and A. G. Jordan, </author> <title> Multiresolution based hierarchical disparity estimation for stereoscopic image pair compression, </title> <booktitle> in Symposium on Applications of subbands and wavelets, </booktitle> <month> March </month> <year> 1993. </year>
Reference-contexts: Further, the intermediate views, synthesized based on a disparity map with spurious and incorrect matches, are highly inaccurate. The number of spurious matches can be reduced by resorting to hierarchical block matching described in Section 2.3.5. HBM for disparity compensation is considered by us in <ref> [103] </ref>. A very closely related method is described in [99]. These methods improve the smoothness of the disparity map to a certain extent. A genetic algorithm based block matching scheme is described in [91], which specifically tries to achieve a smoother disparity map.
Reference: [104] <author> S. Sethuraman, M. W. Siegel, and A. G. Jordan, </author> <title> A multiresolution framework for stereoscopic image sequence compression, </title> <booktitle> in Proc. of ICIP, 1994, </booktitle> <volume> Vol. 2, </volume> <pages> pp. 361-365. </pages>
Reference: [105] <author> S. Sethuraman, M. W. Siegel, and A. G. Jordan, </author> <title> A multiresolutional region based segmentation scheme for stereoscopic image compression, </title> <booktitle> in SPIE Conf. on Digital Video Compression: Algorithms and Technologies 1995, </booktitle> <pages> pp. 265-275. </pages>
Reference: [106] <author> S. Sethuraman, M. W. Siegel and A. G. Jordan, </author> <title> Segmentation based coding of stereoscopic image sequences, </title> <booktitle> in SPIE Conf. on Digital Video Compression: Algorithms and Technologies 1996, </booktitle> <volume> Vol. 2668, </volume> <pages> pp. 420-429. </pages>
Reference: [107] <author> Tetsuo Mitsuhashi, </author> <title> Subjective image position in stereoscopic TV systems - considerations on comfortable stereoscopic images, </title> <booktitle> in SPIE Conf. Human Vision, Visual Processing and Digital Display V, 1994, </booktitle> <volume> Vol. 2179, </volume> <month> pp.259-266. </month>
Reference-contexts: This restricts the number of bits that can be allocated for residual coding. The significant residuals that are left uncoded can result in visually distracting artifacts. The noticeable artifacts can be suppressed by trading off resolution and coding the auxiliary stream frames at a reduced resolution. Psychophysical studies <ref> [12, 30, 89, 107] </ref> have shown that satisfactory stereoscopic perception is achieved even when one of the stereoscopic sequences is presented to a viewer at a Auxiliary stream stream Main I B P P MDBS Track MCP 1 1 1 P A I A 1 1 2 2 Track Track Track
Reference: [108] <author> V. Grinberg, G. Podnar, and M. W. Siegel, </author> <title> Geometry of binocular imaging, </title> <booktitle> in SPIE Conf. Stereoscopic Displays and Virtual Reality systems, 1994, </booktitle> <volume> Vol. 2177, </volume> <pages> pp. 56-65. </pages>
Reference-contexts: When the same display screen is used for displaying both views, the geometry places additional restrictions on how to position the image sensor planes relative to the lenses <ref> [108] </ref>. 1. A pin-hole approximation is the model that the imaging element is an infinitesimally small hole and that the image of a point P in the real world, on the image plane, is given by the intersection of the image plane and the line joining P and the pinhole.
Reference: [109] <author> P. Strobach, </author> <title> Image coding based on quadtree-structured recursive least squares approximation, </title> <booktitle> Proc. of ICASSP 1989, </booktitle> <volume> vol. 4, </volume> <year> 1989, </year> <pages> pp. 1961-1964. </pages>
Reference-contexts: The intensity within each segment is usually modeled as a planar (or) quadratic surface, and the parameters of these surfaces are computed by solving the system of equations obtained by applying the model to each pixel in the region <ref> [109, 41] </ref>. The residuals after fitting the model are coded using conventional methods. 16 2.2.5 Interframe coding Image sequences have considerable temporal redundancy as objects in the scene and the camera typically undergo only small displacements between successive frames. <p> Hence the overhead needed to represent the tree structure, referred to as the segmentation overhead, is very minimal. However, as the partitioning location is obtained independent of the features within the image, the regular decomposition typically results in a larger number of blocks. Spatial homogeneity of a block, e.g. <ref> [41, 109] </ref>, and block motion, e.g. [42], have been used as h (1) = 0.23523360389202 h (2) = 0.57055845791566 h (3) = 0.32518250026277 leaf node (not divided) (bit 0) non-leaf node (bit 1) 1 3 4 5 6 9 14 15 FIG. 3.2: Illustration of regular quadtree decomposition 1010100000001100000010000 - Encoded
Reference: [110] <author> S. T. Barnard and M. A. Fischler, </author> <title> Computational and biological theories of stereo, </title> <booktitle> Proc. of the DARPA Image Understanding workshop, </booktitle> <month> September </month> <year> 1990, </year> <pages> pp. 439-448. </pages>
Reference-contexts: The problem of finding all pairs (P L ,P R ), given the left and right view images, is known as the correspondence or disparity estimation problem <ref> [110] </ref>. The search for P L for a given P R is in general two-dimensional.
Reference: [111] <author> E. Feig, </author> <title> A fast scaled-DCT algorithm, </title> <booktitle> in Proc. SPIE Image processing algorithms and techniques, </booktitle> <volume> Vol. 1244, </volume> <year> 1990, </year> <pages> pp. 2-13. </pages>
Reference: [112] <author> M. Bierling, </author> <title> Displacement estimation by hierarchical block matching, Visual Commun. and Image processing, </title> <journal> Nov. 1988, </journal> <volume> Vol. 1001, </volume> <pages> pp. 942-951. </pages>
Reference: [113] <author> D. G. Jeong and J. D. Gibson, </author> <title> Lattice vector quantization for image coding, </title> <booktitle> Proc. of ICASSP-89, </booktitle> <month> May </month> <year> 1989, </year> <pages> pp. 1743-1746. </pages>
Reference-contexts: In some cases, vectors in a lattice structure with certain desirable properties are chosen as codevectors, thus obviating the need to transmit the codebook <ref> [66, 67, 113] </ref>. The most common method for constructing a codebook is the LBG algorithm 1 , which iteratively builds the optimal codebook given the number of code vectors [43].
Reference: [114] <author> T. Aach, et al., </author> <title> Combined displacement estimation and segmentation of stereo image pairs based on Gibbs random fields, </title> <booktitle> Proc. of ICASSP, </booktitle> <year> 1990, </year> <pages> pp. 2301-2304. </pages>
Reference: [115] <author> R. S. Jasinschi and J. M. F. Moura, </author> <title> Content-based video sequence representation, </title> <booktitle> Proc. of Intl. Conf. on Image Proc., Oct. 1995, </booktitle> <volume> Vol. 2, </volume> <pages> pp. 229-232. </pages>
Reference-contexts: For sequences in which the camera motion is such that it is dominant over object motions and is likely to cover spatially adjacent locations over a long period of time, a new class of methods known as mosaic-based coding methods have evolved <ref> [82, 115] </ref>. These methods register the frames over time using appropriate warping techniques to account for the camera motion and obtain a composite panoramic mosaic image. Thus the temporal redundancies are eliminated. The mosaic is coded using standard intracoding methods. <p> Thus the temporal redundancies are eliminated. The mosaic is coded using standard intracoding methods. The coded mosaic and registration parameters are sufficient to reconstruct the sequence. Regions with local motion are handled through cut and paste operations in <ref> [115] </ref>. A similar coding scheme that peels foreground objects and codes the sequence as a set of layered (depth-wise) constructs is presented in [82]. <p> Similar extensions for more general scenes deserve further consideration. A significant number of bits are wasted filling-in the uncovered regions in the segment tracking case. If the background region over a group of frames can be extracted (for e.g. using mosaic-based coding techniques <ref> [81, 115] </ref>) and coded as a single image, then the foreground region can be overlaid. This can give rise to perceptually pleasing images even at low bit-rates.
Reference: [116] <author> S. M. Faris, </author> <title> Micro-polarizer arrays applied to a new class of stereoscopic imaging, </title> <booktitle> SID 91 126 digest, </booktitle> <pages> pp. 840, </pages> <year> 1991. </year> <note> Technical Reports: </note>
Reference: [117] <author> A. Cohen, I. Daubechies and J. C. Feauveau, </author> <title> Biorthogonal bases of compactly supported wavelets, </title> <journal> AT&T Bell Laboratories, </journal> <volume> TR no. </volume> <month> 11217-900529-07. </month>
Reference-contexts: This phase distortion gives rise to varying spatial offsets over the image which may not be acceptable in certain applications that require precise position extraction. A class of symmetric filters with an odd number of coefficients, known as biorthogonal filters, have been designed <ref> [117] </ref> to overcome this drawback. In this case, the low and high pass filters have different lengths. 2.3.4 Laplacian pyramid vs. sub-band decomposition for coding Though the pyramid and sub-band decompositions are similar in principle, they offer two different representations of the original image.
Reference: [118] <author> H. H. Baker, </author> <title> Depth from edge and intensity based stereo, </title> <type> TR, </type> <institution> Dept. of Computer Sciece, Stanford University, </institution> <year> 1982. </year>
Reference: [119] <author> M. Okutomi and T. Kanade, A multiple-baseline stereo, CMU-CS-90-189, </author> <month> November </month> <year> 1990. </year>
Reference-contexts: Thus, the RDBS scheme can also be extended directly to multi-view prediction if the reliability of the disparity map can be improved by utilizing the information from the different views. Multiple-baseline stereo matching Multiple-baseline stereo matching is a well-known computer vision algorithm <ref> [119, 120] </ref> in which knowledge of the camera separations for a given multi-view set is used to obtain unambiguous disparity estimates. The principle behind the algorithm is as follows.
Reference: [120] <author> T. Nakahara and T. Kanade, </author> <title> Experiments in multiple-baseline stereo, </title> <address> CMU-CS-93-102, </address> <month> August </month> <year> 1992. </year> <pages> Others: </pages>
Reference-contexts: Thus, the RDBS scheme can also be extended directly to multi-view prediction if the reliability of the disparity map can be improved by utilizing the information from the different views. Multiple-baseline stereo matching Multiple-baseline stereo matching is a well-known computer vision algorithm <ref> [119, 120] </ref> in which knowledge of the camera separations for a given multi-view set is used to obtain unambiguous disparity estimates. The principle behind the algorithm is as follows.
Reference: [121] <author> DISTIMA sequences, </author> <title> generated and distributed under the RACE-DISTIMA European project, </title> <month> October </month> <year> 1994. </year>
Reference: [122] <author> J. S. McVeigh, </author> <title> Efficient compression of arbitrary multi-view signals, </title> <type> Ph.D Thesis, </type> <institution> Dept. of Electrical and Computer Engineering, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: An approach for adaptively selecting optimal reference frames for predicting multi-view images (in the sense of maximizing the correlation or minimizing the occlusion) along with a robust intermediate view synthesis method that refines the disparity maps obtained from block disparities at the decoder is presented in <ref> [122] </ref>. 5.3 INTERMEDIATE VIEW SYNTHESIS (IVS) In this section we present an algorithm for synthesizing intermediate views, given two views and a unidirectional disparity map between the two views. Let L and R be the two views given.
References-found: 123

