URL: http://www.sls.lcs.mit.edu/sree/paper.ps
Refering-URL: http://www.sls.lcs.mit.edu/sree/publications.html
Root-URL: 
Email: fsree,zueg@sls.lcs.mit.edu  
Title: A SEGMENT-BASED SPEAKER VERIFICATION SYSTEM USING SUMMIT  
Author: Sridevi V. Sarma and Victor W. Zue 
Address: Cambridge, Massachusetts 02139 USA  
Affiliation: Spoken Language Systems Group Laboratory for Computer Science Massachusetts Institute of Technology  
Abstract: The main goal of this work is to develop a competitive segment-based speaker verification system that is computationally efficient. To achieve our goal, we modified SUMMIT [12] to suit our needs. The speech signal was first transformed into a hierarchical segment network using frame-based measurements. Next, acoustic models for 168 speakers were developed for a set of 6 broad phoneme classes. The models represented feature statistics with diagonal Gaussians, preceded by principle component analysis. The feature vector included segment-averaged MFCCs, plus three prosodic measurements: energy, fundamental frequency (F0), and duration. The size and content of the feature vector were determined through a greedy algorithm while optimizing overall speaker verification performance. We were able to achieve a performance of 2.74% equal error rate (EER) using cohorts during testing; and 1.59% EER using all speakers during testing. We reduced computation significantly through the use of a small number of features, a small number of phonetic models per speaker, few model parameters, and few competing speakers during testing (when cohorts are used). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bennani, Y., </author> <title> Speaker Identification Through Modular Connectionist Architecture: Evaluation on the TIMIT database, </title> <booktitle> Proceedings of ICSLP: </booktitle> <pages> 607-610, </pages> <year> 1992. </year>
Reference-contexts: Performance Comparison Below, we compare our system with two other state-of-the-art systems that also use the TIMIT corpus. One system implements HMMs to represent speakers [6], while the other uses neural networks <ref> [1] </ref>. Both systems, if tested using the same decision algorithm as ours, reach the ideal performance of 0% error. Unlike the HMM and neural network (NN) system, our system does not achieve perfect performance. However, performance degradation is somewhat compensated by computational efficiency.
Reference: [2] <author> Cormen, T., Leiserson, C., Rivest, R., </author> <title> Introduction to Algorithms, </title> <publisher> The M.I.T. Press : 1990 </publisher>
Reference-contexts: Finally, computation increases as the number of features increases, which may become prohibitive if all 17 measurements are used in the system. To find a (sub)-optimal subset of the 17 features, we conducted a greedy search <ref> [2] </ref>. At every decision point in a greedy algorithm, the best choice, based on an optimality criterion, is selected. Our criterion is the speaker verification performance of each proposed feature set.
Reference: [3] <author> Doddington, G., Secrest, B., </author> <title> An integrated pitch tracking algorithm for speech systems, </title> <booktitle> Proceedings of ICASSP: </booktitle> <pages> 1352-1355, </pages> <year> 1983. </year>
Reference-contexts: Two-dimensional feature sets are grouped in this fashion, and are each used to test the speakers. The best 2-dimensional feature vector, in terms of speaker verification performance, is then used 2 To estimate F0, we used the ESPS tracker, in particular the FORMANT function <ref> [3] </ref>. Although the tracker estimates probabilities of voicing for each frame, we retained F0 information for every frame, regardless of whether the underlying sounds were voiced or unvoiced. for the next stage of the search.
Reference: [4] <author> Garofolo, J. et al, </author> <title> DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus CD-ROM, </title> <institution> National Institute of Standards and Technology: </institution> <year> 1990. </year>
Reference-contexts: SYSTEM DESCRIPTION 2.1. Corpus The TIMIT <ref> [4] </ref> corpus was used in our experiments. TIMIT consists of 630 speakers, 70% male and 30% female, representing 8 major dialect regions of the United States.
Reference: [5] <author> Glass, J., Chang, J., McCandless, M., </author> <title> A Probabilistic Framework for Feature-Based Speech Recognition, </title> <booktitle> Proceedings of the ICSLP: </booktitle> <year> 1996 </year>
Reference-contexts: Finally, we reduce computation during testing by using only a set of speaker models similar to the purported speaker's model, as opposed to using all the speaker models in the system. 3 SUMMIT's recent modification and improvement is discussed in <ref> [5] </ref>. Computation, in terms of the number of training parameters, is approximated on the order of 10 6 for the HMM system and on the order of 10 4 for the SUMMIT speaker verification system.
Reference: [6] <author> Lamel, L., Gauvain, J., </author> <title> A Phone-based Approach to Nonlinguistic Speech Feature Identification, </title> <booktitle> Computer Speech and Language: </booktitle> <pages> 87-103, </pages> <year> 1995. </year>
Reference-contexts: Signal Representation Past observations have shown that the Mel-frequency-based cepstral coefficients (MFCCs) and prosodic features are useful for speaker verification <ref> [6, 11] </ref>. Thus, the initial set of features used consisted of MFCCs and several prosodic measurements. Specifically, 14 MFCCs, the logarithm of energy, duration and fundamental frequency (FO) were computed 2 . The features were averaged across speech segments, which were proposed by a segmentation algorithm implemented in SUMMIT. 2.3. <p> Consequently, when performance using all speakers during testing is poor (&gt;10% EER), normalized cohort approximations are inaccurate. 4.4. Performance Comparison Below, we compare our system with two other state-of-the-art systems that also use the TIMIT corpus. One system implements HMMs to represent speakers <ref> [6] </ref>, while the other uses neural networks [1]. Both systems, if tested using the same decision algorithm as ours, reach the ideal performance of 0% error. Unlike the HMM and neural network (NN) system, our system does not achieve perfect performance. However, performance degradation is somewhat compensated by computational efficiency. <p> In the process, we significantly reduced computation in many ways. We believe that by considering the speech signal as a concatenation of phone-sized units, we capitalized on measurements for such units more readily. Future work includes representing acoustic features with more complex distributions, adapting speaker models <ref> [6] </ref>, and conducting feature searches on NTIMIT and CTIMIT to find robust features for the telephone and cellular telephone domains, respectively.
Reference: [7] <author> Naik, J., </author> <title> Speaker Verification: A Tutorial, </title> <journal> IEEE Communications Magazine: </journal> <pages> 42-47, </pages> <year> 1990. </year>
Reference-contexts: Many details are left out of the block diagram, such as the type of text the system prompts, the features the system extracts, and the speaker models and classifiers the system implements. For a detailed tutorial on speaker verification, refer to <ref> [7] </ref>. In this paper, we describe how we developed a speaker verification system that extracts acoustic features from speech segments. Our investigation is motivated by past observations that speaker-specific cues may manifest themselves differently depending on the manner of articulation of the phonemes [10].
Reference: [8] <author> Reynolds, D., </author> <title> Speaker identification and verification using Gaussian mixture speaker models, </title> <journal> Speech Communication: </journal> <pages> 91-108, </pages> <year> 1995. </year>
Reference-contexts: First, we selected cohorts using the Mahalanobis distance, whereas during testing we compared speakers using forced-paths scores. Second, the cohorts were not selected in a manner that maximized a spread around each speaker as they were in <ref> [8] </ref>. A spread prevents impostors that are far from the purported speaker, but even further from the purported speaker's cohorts, to be falsely accepted.
Reference: [9] <author> Sarma, S., </author> <title> A Segment Based Speaker Verification System Using SUMMIT, M.I.T. </title> <type> SM Thesis, </type> <institution> Department of Electrical Engineering and Computer Science: </institution> <year> 1997. </year>
Reference-contexts: For each feature set and speaker, we found 14 nearest neighbors using the Mahalanobis distance metric. To accept or reject a speaker, we compute forced alignment scores, described in <ref> [9] </ref>, for the purported speaker's two test utterances. The scores are computed using 15 models, the speaker's model and his/her 14 cohort models. These scores are then sorted, and the speaker is accepted if the score using his/her model is in the top N scores of the 15 results.
Reference: [10] <author> Wolf, J., </author> <title> Acoustic Measurements for Speaker Recognition, </title> <type> M.I.T PhD Thesis, </type> <institution> Department of Electrical Engineering and Computer Science : 1969. </institution>
Reference-contexts: In this paper, we describe how we developed a speaker verification system that extracts acoustic features from speech segments. Our investigation is motivated by past observations that speaker-specific cues may manifest themselves differently depending on the manner of articulation of the phonemes <ref> [10] </ref>. By treating the speech signal as a concatenation of phone-sized units (segments), one may be able to capitalize on measurements for such units more readily.
Reference: [11] <author> Yegnanarayana, B., Wagh, S., Rajendra, S., </author> <title> A speaker verification system using prosodic features, </title> <booktitle> Proceedings of ICASSP: </booktitle> <pages> 1867-1870, </pages> <year> 1994, </year>
Reference-contexts: Signal Representation Past observations have shown that the Mel-frequency-based cepstral coefficients (MFCCs) and prosodic features are useful for speaker verification <ref> [6, 11] </ref>. Thus, the initial set of features used consisted of MFCCs and several prosodic measurements. Specifically, 14 MFCCs, the logarithm of energy, duration and fundamental frequency (FO) were computed 2 . The features were averaged across speech segments, which were proposed by a segmentation algorithm implemented in SUMMIT. 2.3.
Reference: [12] <author> Zue, V., Glass, J., Phillips, M., Seneff, S. </author> <title> The SUMMIT Speech Recognition System: Phonological Modeling and Lexical Access, </title> <booktitle> Proceedings of ICASSP: </booktitle> <pages> 49-52, </pages> <year> 1990. </year>
References-found: 12

