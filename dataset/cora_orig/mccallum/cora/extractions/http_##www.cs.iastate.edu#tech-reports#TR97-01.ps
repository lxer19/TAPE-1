URL: http://www.cs.iastate.edu/tech-reports/TR97-01.ps
Refering-URL: http://www.cs.iastate.edu/tech-reports/catalog.html
Root-URL: http://www.cs.iastate.edu
Email: balakris@cs.iastate.edu, honavar@cs.iastate.edu  
Title: Spatial Memory Structures for Sensor-Guided Robot Navigation  
Author: Karthik Balakrishnan and Vasant Honavar 
Date: (515)-294-1098  
Address: Ames, IA 50011, USA  
Affiliation: Artificial Intelligence Research Group Department of Computer Science Iowa State University,  
Abstract: Although evolutionary algorithms offer an attractive and versatile approach to the automated design of behavior and control structures for mobile robots, they cannot anticipate the detailed structure of specific environments that the robot might have to deal with. Robots must thus possess mechanisms to adapt to the environments they encounter. In particular, mobile robots need stuctures for building and using spatial maps to aid in the successful exploration and navigation of a-priori unknown environments. This paper proposes a biologically inspired computational model for the acquisition and use of spatial memory structures for mobile robot navigation. Preliminary experimental results indicate that the proposed mechanisms can be effectively exploited by evolution in the design of high-performance robots. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Balakrishnan and V. Honavar. </author> <title> Analysis of neurocontrollers designed by simulated evolution. </title> <type> Technical Report CS TR 95-25, </type> <institution> Department of Computer Science, Iowa State University, Ames, </institution> <address> IA - 50011, </address> <year> 1995. </year>
Reference-contexts: Task environments that robots typically deal with offer particular challenges to learning in terms of the form and amount of information that is available <ref> [11, 1] </ref>. Reinforcement learning, which only requires scalar feedback, has found use in learning policy or action functions (the right set of actions to perform in each sensory state) for robots [11, 8, 10]. <p> The remaining 400 population members are produced by choosing parents based on fitness proportionate selection and applying uniform crossover with probability 0.5 and mutation with probability 0.01 per gene. For details, refer to <ref> [1] </ref>. For each experiment, we made 10 evolutionary runs, each starting with a different random initial population. Since the robots are evaluated over different random environments in each of the runs, it is difficult to directly compare the robots produced by each of the runs. <p> All the units compute the bipolar threshold function and the action to be performed by the robot is determined by the output unit that is the winner, i.e., the one that has the highest input activation (refer to <ref> [1] </ref> for details). The sensors are tuned to detect specific classes of objects located at specific distances from the robot.
Reference: [2] <author> K. Balakrishnan and V. Honavar. </author> <title> Analysis of neurocontrollers designed by simulated evolution. </title> <booktitle> In Proceedings of IEEE International Conference on Neural Networks ICNN'96, </booktitle> <year> 1996. </year>
Reference-contexts: At the end of its simulation trial each box against a wall earns one fitness point and every box pushed into a corner fetches an extra fitness point. In our earlier work we have successfully evolved neurocontrollers for such a robot <ref> [2] </ref>. In addition to the neurocontroller design, we have also been able to evolve minimal numbers of sensors and their efficient placement [4], leading to interesting designs even in the presence of sensor noise [5].
Reference: [3] <author> K. Balakrishnan and V. Honavar. </author> <title> A neurobiologically inspired model of spatial navigation in robots. </title> <type> Technical Report CS TR 96-19, </type> <institution> Department of Computer Science, Iowa State University, Ames, </institution> <address> IA - 50011, </address> <month> December </month> <year> 1996. </year>
Reference-contexts: In this process, it navigates by a tactile sensor placed just ahead of it (which is not used otherwise), avoiding obstacles (boxes, walls, and other unlocated power sources) by a random sequence of movements <ref> [3] </ref>. Once at the goal, the robot charges up until its battery level reaches the HBT. Since in one time step the robot can only charge by 50 units, it might have to spend some amount of time in order to charge to HBT.
Reference: [4] <author> K. Balakrishnan and V. Honavar. </author> <title> On sensor evolution in robotics. </title> <booktitle> In Proceedings of Genetic Programming Conference - GP-96, </booktitle> <year> 1996. </year>
Reference-contexts: In our earlier work we have successfully evolved neurocontrollers for such a robot [2]. In addition to the neurocontroller design, we have also been able to evolve minimal numbers of sensors and their efficient placement <ref> [4] </ref>, leading to interesting designs even in the presence of sensor noise [5]. <p> This was a slight variation of the representation used in <ref> [4] </ref>. We created random populations of 500 genotypes. Each genotype was evaluated by decoding it into a robot architecture and placing the robot at a random position in a 10 fi 10 grid-world with 10 boxes and 2 power sources located randomly. <p> We thus take the best robot at the end of each of the evolutionary runs and reevaluate them on a predetermined set of 500 environments. We refer to this fitness as the corrected fitness of the robot <ref> [4] </ref>. The robots could use upto 5 hidden units in the neurocontroller and upto 10 sensors. Further, the neurocontroller units were constrained to have a maximum of 15 input synapses.
Reference: [5] <author> K. Balakrishnan and V. Honavar. </author> <title> Some experiments in the evolutionary synthesis of robotic neurocontrollers. </title> <booktitle> In WCNN'96: Proceedings of the World Congress on Neural Networks, </booktitle> <address> San Diego, </address> <pages> pages 1035-1040, </pages> <year> 1996. </year>
Reference-contexts: In our earlier work we have successfully evolved neurocontrollers for such a robot [2]. In addition to the neurocontroller design, we have also been able to evolve minimal numbers of sensors and their efficient placement [4], leading to interesting designs even in the presence of sensor noise <ref> [5] </ref>. The task here differs from our earlier work in a few significant ways. * The robot environment is much larger here, which coupled with the limited sensory abilities of the robot, makes the task of finding and pushing boxes much harder than before.
Reference: [6] <author> K. Bayse, T. Dean, and J. Vitter. </author> <title> Coping with uncertainty in map learning. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <year> 1989. </year>
Reference-contexts: In addition, topological maps represent space very compactly since they only represent distinctive places and not the whole world. Many variations of such topological maps exist <ref> [6, 17, 20, 16, 12, 30] </ref>. However, the significant issues of what corresponds to a distinctive place, and how the map is to be represented and used, still remain open research problems.
Reference: [7] <author> R. Brooks. </author> <title> Visual map making for a mobile robot. </title> <booktitle> In Proceedings of the IEEE Conference on Robotics and Automation, </booktitle> <year> 1985. </year>
Reference-contexts: For instance, a robot might learn a spatial map of obstacles in its environment and use it to navigate to specific goal locations efficiently. A number of researchers have argued for the use of such spatial maps in mobile robot navigation. Brooks <ref> [7] </ref> argued for the use of topological maps, which represent the world as an abstract network of nodes and arcs. The nodes fl Submitted to GP-97 y This research is partially supported by the National Science Foundation (through grants IRI-9409580 and IRI-9643299) and the John Deere Foundation.
Reference: [8] <author> R. Brooks and M. Mataric. </author> <title> Real robots, real learning problems. </title> <editor> In J. Connell and S. Mahadevan, editors, </editor> <title> Robot Learning, </title> <booktitle> chapter 8, </booktitle> <pages> pages 193-213. </pages> <publisher> Kluwer Academic Publishers, </publisher> <address> MA, </address> <year> 1993. </year>
Reference-contexts: Reinforcement learning, which only requires scalar feedback, has found use in learning policy or action functions (the right set of actions to perform in each sensory state) for robots <ref> [11, 8, 10] </ref>. Availability of an internal model of the environment often simplifies the learning of action functions [11, 18]. Robots that have to navigate and manipulate objects in space can benefit from structures for acquiring and using internal models or spatial maps of their environments.
Reference: [9] <author> N. Burgess, M. Recce, and J. O'Keefe. </author> <title> A model of hippocampal function. </title> <booktitle> Neural Networks, </booktitle> 7(6/7):1065-1081, 1994. 
Reference-contexts: These suggest that the motor system input is somehow a critical determinant of place cell firing. Some or all of these facts have been used to suggest hippocampus-aided navigation models for animals <ref> [9, 22, 26] </ref>. However, none of these models explain the neurophysiological and behavioral data in their entirety. For instance, the model of Burgess et al. [9] aims to explain the hippocampal place cell data (including their relationship to EEG -rhythms) and head-direction cells. <p> Some or all of these facts have been used to suggest hippocampus-aided navigation models for animals [9, 22, 26]. However, none of these models explain the neurophysiological and behavioral data in their entirety. For instance, the model of Burgess et al. <ref> [9] </ref> aims to explain the hippocampal place cell data (including their relationship to EEG -rhythms) and head-direction cells. However, it falls short of demonstrating dead reckoning related behavior, including the ability of animals to navigate in darkness in familiar environments.
Reference: [10] <author> M. Colombetti and M. Dorigo. </author> <title> Learning to control an autonomous robot by distributed genetic algorithms. </title> <editor> In J-A. Meyer, H. Roitblat, and S. Wilson, editors, </editor> <booktitle> From Animals to Animats 2: Proceedings of the Second International Conference on Simulation of Adaptive Behavior, </booktitle> <address> Cambridge, MA, 1992. </address> <publisher> MIT Press-Bradford Books. </publisher>
Reference-contexts: Reinforcement learning, which only requires scalar feedback, has found use in learning policy or action functions (the right set of actions to perform in each sensory state) for robots <ref> [11, 8, 10] </ref>. Availability of an internal model of the environment often simplifies the learning of action functions [11, 18]. Robots that have to navigate and manipulate objects in space can benefit from structures for acquiring and using internal models or spatial maps of their environments.
Reference: [11] <author> J. Connell and S. Mahadevan, </author> <title> editors. Robot Learning. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> MA, </address> <year> 1993. </year> <month> 8 </month>
Reference-contexts: Task environments that robots typically deal with offer particular challenges to learning in terms of the form and amount of information that is available <ref> [11, 1] </ref>. Reinforcement learning, which only requires scalar feedback, has found use in learning policy or action functions (the right set of actions to perform in each sensory state) for robots [11, 8, 10]. <p> Reinforcement learning, which only requires scalar feedback, has found use in learning policy or action functions (the right set of actions to perform in each sensory state) for robots <ref> [11, 8, 10] </ref>. Availability of an internal model of the environment often simplifies the learning of action functions [11, 18]. Robots that have to navigate and manipulate objects in space can benefit from structures for acquiring and using internal models or spatial maps of their environments. <p> Reinforcement learning, which only requires scalar feedback, has found use in learning policy or action functions (the right set of actions to perform in each sensory state) for robots [11, 8, 10]. Availability of an internal model of the environment often simplifies the learning of action functions <ref> [11, 18] </ref>. Robots that have to navigate and manipulate objects in space can benefit from structures for acquiring and using internal models or spatial maps of their environments.
Reference: [12] <author> S. Engelson. </author> <title> Passive Map Learning and Visual Place Recognition. </title> <type> PhD thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <year> 1994. </year>
Reference-contexts: In addition, topological maps represent space very compactly since they only represent distinctive places and not the whole world. Many variations of such topological maps exist <ref> [6, 17, 20, 16, 12, 30] </ref>. However, the significant issues of what corresponds to a distinctive place, and how the map is to be represented and used, still remain open research problems.
Reference: [13] <author> H. Everett. </author> <title> Sensors for Mobile Robots: Theory and Application. </title> <editor> A. K. </editor> <publisher> Peters Ltd, </publisher> <address> Wellesley, MA, </address> <year> 1995. </year>
Reference-contexts: For instance, accurate laser rangefinders have been developed, and a variety of devices for sensing anything from light intensities, to acceleration, to the slightest degree of movement have been invented <ref> [13] </ref>.
Reference: [14] <author> C. Gallistel. </author> <title> The Organization of Learning. </title> <publisher> Bradford-MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: For instance, ants, bees, rodents, doves, etc., demonstrate a suprising sense of space, and are capable of locating their homes even after pseudo-random movements in search of food or their young <ref> [21, 14] </ref>. In the cognitive and neuroscience communities, it is stongly believed that these animals construct and use some form of a cognitive map to aid their spatial navigation needs. <p> There is considerable evidence that this process plays a fundamental role in navigation in animals from ants to humans <ref> [14] </ref>. For instance the desert ant, Cataglyphis bicolor, follows a tortuous path in search of food and wanders as far away as 100 meters from its nest. During this exploratory search, its turning velocity attains rates of 4000 degrees per second. <p> During this exploratory search, its turning velocity attains rates of 4000 degrees per second. In spite of these, upon finding food, the ant turns and heads directly for home at a brisk 15 meters per minute, successfully locating the 1 mm nest opening in the featureless desert <ref> [14] </ref>. Studies with rats and gerbils have also confirmed the dead reckoning ability of rodents [14]. In the neuroscience community, the hippocampal formation and adjacent cortical regions of the medial temporal lobe have long been associated with spatial learning and memory. <p> In spite of these, upon finding food, the ant turns and heads directly for home at a brisk 15 meters per minute, successfully locating the 1 mm nest opening in the featureless desert <ref> [14] </ref>. Studies with rats and gerbils have also confirmed the dead reckoning ability of rodents [14]. In the neuroscience community, the hippocampal formation and adjacent cortical regions of the medial temporal lobe have long been associated with spatial learning and memory. Hippocampal lesions have been known to impair spatial learning skills in humans and animals.
Reference: [15] <author> D. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: In addition, the sensor types and their placements were also subject to evolution. We wanted to study the effect of incorporating the spatial module mechanism in our robot architecture. 5 Simulation Details and Results We used genetic algorithms <ref> [15] </ref> in our experiments with a genetic representation (genotype) of the robot architectures that included the types and placements of the sensors and the input connectivities of the neurocontroller units. This was a slight variation of the representation used in [4]. We created random populations of 500 genotypes.
Reference: [16] <author> D. Kortenkamp. </author> <title> Cognitive Maps for Mobile Robots: A Representation for Mapping and Navigation. </title> <type> PhD thesis, </type> <institution> University of Michigan, Electrical Engineering and Computer Science Department, </institution> <year> 1993. </year>
Reference-contexts: In addition, topological maps represent space very compactly since they only represent distinctive places and not the whole world. Many variations of such topological maps exist <ref> [6, 17, 20, 16, 12, 30] </ref>. However, the significant issues of what corresponds to a distinctive place, and how the map is to be represented and used, still remain open research problems.
Reference: [17] <author> B. Kuipers and Y-T. Byun. </author> <title> A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 8, </volume> <year> 1991. </year>
Reference-contexts: In addition, topological maps represent space very compactly since they only represent distinctive places and not the whole world. Many variations of such topological maps exist <ref> [6, 17, 20, 16, 12, 30] </ref>. However, the significant issues of what corresponds to a distinctive place, and how the map is to be represented and used, still remain open research problems.
Reference: [18] <author> L. Kuvayev and R. Sutton. </author> <title> Model-based reinforcement learning with an approximate, learned model. </title> <booktitle> In Proceedings of the Ninth Yale Workshop on Adaptive and Learning Systems, </booktitle> <pages> pages 101-105, </pages> <address> New Haven, CT, </address> <year> 1996. </year> <institution> Yale University. </institution>
Reference-contexts: Reinforcement learning, which only requires scalar feedback, has found use in learning policy or action functions (the right set of actions to perform in each sensory state) for robots [11, 8, 10]. Availability of an internal model of the environment often simplifies the learning of action functions <ref> [11, 18] </ref>. Robots that have to navigate and manipulate objects in space can benefit from structures for acquiring and using internal models or spatial maps of their environments.
Reference: [19] <author> B. Leonard and B. McNaughton. </author> <title> Spatial representation in the rat: Conceptual, behavioral, and neurophysiological perspectives. </title> <editor> In R. Kesner and D. Olton, editors, </editor> <title> Neurobiology of Comparative Cognition. </title> <publisher> Lawrence Earlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1990. </year>
Reference-contexts: Hippocampal lesions have been known to impair spatial learning skills in humans and animals. Further, evidence from single-unit recordings and lesion studies in nonprimate mammals, mostly rodents, have also pointed to the significant involvement of the hippocampal formation in spatial learning and reasoning tasks <ref> [19] </ref>. It is believed that in such cases the hippocampus represents spatial information in the form of cognitive maps [25] which are then used for efficient, purposeful, goal-directed navigation.
Reference: [20] <author> M. Mataric. </author> <title> Integration of representation into goal-driven behavior-based robots. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 8(3), </volume> <year> 1992. </year>
Reference-contexts: In addition, topological maps represent space very compactly since they only represent distinctive places and not the whole world. Many variations of such topological maps exist <ref> [6, 17, 20, 16, 12, 30] </ref>. However, the significant issues of what corresponds to a distinctive place, and how the map is to be represented and used, still remain open research problems.
Reference: [21] <author> D. McFarland. </author> <title> Animal Behavior. </title> <publisher> Longman Scientific and Technical, Essex, </publisher> <address> England, </address> <year> 1993. </year>
Reference-contexts: For instance, ants, bees, rodents, doves, etc., demonstrate a suprising sense of space, and are capable of locating their homes even after pseudo-random movements in search of food or their young <ref> [21, 14] </ref>. In the cognitive and neuroscience communities, it is stongly believed that these animals construct and use some form of a cognitive map to aid their spatial navigation needs.
Reference: [22] <author> B. McNaughton, J. Knierim, and M. Wilson. </author> <title> Vector encoding and the vestibular foundations of spatial cognition: A neurophysiological and computational hypothesis. </title> <editor> In M. Gazzaniga, editor, </editor> <booktitle> The Cognitive Neurosciences, chapter 37. </booktitle> <publisher> Boston:MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: These suggest that the motor system input is somehow a critical determinant of place cell firing. Some or all of these facts have been used to suggest hippocampus-aided navigation models for animals <ref> [9, 22, 26] </ref>. However, none of these models explain the neurophysiological and behavioral data in their entirety. For instance, the model of Burgess et al. [9] aims to explain the hippocampal place cell data (including their relationship to EEG -rhythms) and head-direction cells. <p> However, it falls short of demonstrating dead reckoning related behavior, including the ability of animals to navigate in darkness in familiar environments. The model of McNaughton et al. <ref> [22] </ref> is strongly influenced by the dead reckoning behavior of animals and the presence of head-direction cells. In their model, place cells encode landmarks in the form of a vector representation. However, they do not have an implementation of this theory.
Reference: [23] <author> B. McNaughton and L. </author> <title> Nadel. Hebb-marr networks and the neurobiological representation of action in space. </title> <editor> In M. Gluck and D. Rumelhart, editors, </editor> <booktitle> Neuroscience and Connectionist Theory, </booktitle> <pages> pages 1-63. </pages> <publisher> Lawrence Earlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1990. </year>
Reference-contexts: This enables the animal to determine the egocentric (with respect to the animal) headings of visible landmarks. 2 3. Behavioral experiments suggest that the motor system plays a very important role in the formation of cognitive maps in rats <ref> [23] </ref>. For instance, when rats were wrapped in a towel, restraining their motor activity entirely, almost all hippocampal neuronal activity ceased. Neuronal activity did not resume even when the rats were passively moved through the environment to regions that resulted in place cell firing earlier.
Reference: [24] <author> J. O'Keefe and J. Dostrovsky. </author> <title> The hippocampus as a spatial map: Preliminary evidence from unit activity in the freely moving rat. </title> <journal> Brain Research, </journal> <volume> 34 </volume> <pages> 171-175, </pages> <year> 1971. </year>
Reference-contexts: Advances in the neurosciences have uncovered several key pieces of information regarding biological information processing. 1. Pyramidal cells in the regions CA1 and CA3 of the rat hippocampus are mostly place cells, that is they fire only when the rat is in a particular portion of its environment <ref> [24, 25] </ref>. Thus, place cells represent an ensemble code for the region of the environment [29]. However, the exact nature of the code is still open to debate. 2. Head-direction cells have been found in several regions of the brain, including the dorsal presubiculum and the posterior neocortex [27, 28].
Reference: [25] <author> J. O'Keefe and L. </author> <title> Nadel. The Hippocampus as a Cognitive Map. </title> <publisher> Oxford:Clarendon Press, </publisher> <year> 1978. </year>
Reference-contexts: The hippocampal formation has been known to play a crucial role in the spatial learning ability of animals and has a suspected involvement in the acquisition and representation of ,the cognitive map <ref> [25] </ref>. However, even after decades of research, the exact nature of the spatial information encoded and the representation and use of the cognitive map remains unanswered in its entirety. <p> Further, evidence from single-unit recordings and lesion studies in nonprimate mammals, mostly rodents, have also pointed to the significant involvement of the hippocampal formation in spatial learning and reasoning tasks [19]. It is believed that in such cases the hippocampus represents spatial information in the form of cognitive maps <ref> [25] </ref> which are then used for efficient, purposeful, goal-directed navigation. However, in spite of these insights and the many models of hippocampal function that have been proposed, the precise nature of the hippocampal code and the nature and use of cognitive maps remains to be fully understood. <p> Advances in the neurosciences have uncovered several key pieces of information regarding biological information processing. 1. Pyramidal cells in the regions CA1 and CA3 of the rat hippocampus are mostly place cells, that is they fire only when the rat is in a particular portion of its environment <ref> [24, 25] </ref>. Thus, place cells represent an ensemble code for the region of the environment [29]. However, the exact nature of the code is still open to debate. 2. Head-direction cells have been found in several regions of the brain, including the dorsal presubiculum and the posterior neocortex [27, 28].
Reference: [26] <author> D. Redish and D. Touretzky. </author> <title> Navigating with landmarks: Computing goal locations from place codes. </title> <editor> In K. Ikeuchi and M. Veloso, editors, </editor> <title> Symbolic Visual Learning. </title> <publisher> Oxford University Press, </publisher> <year> 1996. </year>
Reference-contexts: These suggest that the motor system input is somehow a critical determinant of place cell firing. Some or all of these facts have been used to suggest hippocampus-aided navigation models for animals <ref> [9, 22, 26] </ref>. However, none of these models explain the neurophysiological and behavioral data in their entirety. For instance, the model of Burgess et al. [9] aims to explain the hippocampal place cell data (including their relationship to EEG -rhythms) and head-direction cells. <p> Further, in order to determine a path to the goal location, this model assumes the existence of a landmark that is visible from the current location as well as the goal. Redish and Touretzky <ref> [26] </ref> have a theory of rodent navigation that is consistent with a number of neurophysiological and behavioral data. Their place cell theory is very much like ours (ref. section 3.1).
Reference: [27] <author> J. Taube, R. Muller, and J. Ranck. </author> <title> Head direction cells recorded from the postsubiculum in freely moving rats: I. description and quantitative analysis. </title> <journal> Journal of Neuroscience, </journal> <volume> 10 </volume> <pages> 420-435, </pages> <year> 1990. </year>
Reference-contexts: Thus, place cells represent an ensemble code for the region of the environment [29]. However, the exact nature of the code is still open to debate. 2. Head-direction cells have been found in several regions of the brain, including the dorsal presubiculum and the posterior neocortex <ref> [27, 28] </ref>. These cells appear to fire preferentially based on the current orientation of the head. This enables the animal to determine the egocentric (with respect to the animal) headings of visible landmarks. 2 3.
Reference: [28] <author> J. Taube, R. Muller, and J. Ranck. </author> <title> Head direction cells recorded from the postsubiculum in freely moving rats: Ii. effects of environmental manipulations. </title> <journal> Journal of Neuroscience, </journal> <volume> 10 </volume> <pages> 436-447, </pages> <year> 1990. </year>
Reference-contexts: Thus, place cells represent an ensemble code for the region of the environment [29]. However, the exact nature of the code is still open to debate. 2. Head-direction cells have been found in several regions of the brain, including the dorsal presubiculum and the posterior neocortex <ref> [27, 28] </ref>. These cells appear to fire preferentially based on the current orientation of the head. This enables the animal to determine the egocentric (with respect to the animal) headings of visible landmarks. 2 3.
Reference: [29] <author> M. Wilson and B. McNaughton. </author> <title> Dynamics of the hippocampal ensemble code for space. </title> <journal> Science, </journal> <volume> 261 </volume> <pages> 1055-1058, </pages> <year> 1993. </year>
Reference-contexts: Pyramidal cells in the regions CA1 and CA3 of the rat hippocampus are mostly place cells, that is they fire only when the rat is in a particular portion of its environment [24, 25]. Thus, place cells represent an ensemble code for the region of the environment <ref> [29] </ref>. However, the exact nature of the code is still open to debate. 2. Head-direction cells have been found in several regions of the brain, including the dorsal presubiculum and the posterior neocortex [27, 28]. These cells appear to fire preferentially based on the current orientation of the head. <p> We are also in the process of making the simulation environment more realistic by adding more realistic models of sensing and action. The place cell representation could also be improved. There is evidence that ensembles of place cells code for space <ref> [29] </ref>, rather than single cells as our model has assumed. This is an extension worth pursuing. Instead of X-Y routing, other navigation algorithms capable of operating in non-grid environments would also need to be incorporated. Importantly, the goal-identification module in our experiments, is programmed by the user.
Reference: [30] <author> B. Yamauchi and R. Beer. </author> <title> Spatial learning for navigation in dynamic environments. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics Part B, Special Issue on Robot Learning, </journal> <volume> 26, </volume> <year> 1996. </year> <month> 9 </month>
Reference-contexts: In addition, topological maps represent space very compactly since they only represent distinctive places and not the whole world. Many variations of such topological maps exist <ref> [6, 17, 20, 16, 12, 30] </ref>. However, the significant issues of what corresponds to a distinctive place, and how the map is to be represented and used, still remain open research problems.
References-found: 30

