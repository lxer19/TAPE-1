URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/fgcozman/www/Research/QuasiBayesian/UAI97/uai97.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/fgcozman/www/Research/QuasiBayesian/UAI97/cozmanf.html
Root-URL: 
Email: fgcozman@cs.cmu.edu,  
Title: Robustness analysis of Bayesian networks with local convex sets of distributions  
Author: Fabio Cozman 
Web: http://www.cs.cmu.edu/~fgcozman  
Date: August 1-3, 1997  
Address: Providence, Rhode Island,  
Affiliation: Artificial Intelligence,  Robotics Institute, School of Computer Science, Carnegie Mellon University  
Note: In Proceedings of the Thirteenth Annual Conference on Uncertainty in  
Abstract: Robust Bayesian inference is the calculation of posterior probability bounds given perturbations in a probabilistic model. This paper focuses on perturbations that can be expressed locally in Bayesian networks through convex sets of distributions. Two approaches for combination of local models are considered. The first approach takes the largest set of joint distributions that is compatible with the local sets of distributions; we show how to reduce this type of robust inference to a linear programming problem. The second approach takes the convex hull of joint distributions generated from the local sets of distributions; we demonstrate how to apply interior-point optimization methods to generate posterior bounds and how to generate approximations that are guaranteed to converge to correct posterior bounds. We also discuss calculation of bounds for expected utilities and variances, and global perturbation mod els.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. </author> <title> Avriel. </title> <booktitle> Advances in Geometric Programming. </booktitle> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: Suppose there are M constraints for each node; there are M s constraints in the linear program. This asymmetry suggests a resort to the dual linear program, in which there will be M s variables and m s constraints <ref> [1] </ref>. <p> We describe two different approaches to this numerical problem. The first approach investigates interior-point methods for its solution (subsection 4.2). The second approach uses Lavine's algorithm to reduce robust in ference to signomial programming <ref> [1] </ref> (subsection 4.3). 4.2 INTERIOR-POINT ALGORITHMS In this subsection we recast the robust inference problem as a parameter estimation problem. Consider a transformed Bayesian network with transparent variables fz 0 i g. Each transparent variable has values f1; 2; : : :; j ^ z 0 i jg. <p> The idea is to settle for deciding whether or not p (x q = a) is larger than a given value k. When we obtain this result, we can construct an algorithm by bracketing the interval <ref> [0; 1] </ref> with k. This algorithm is convergent and improves monotonically. Notice that p (x q = a) = min (p (x q = a; e)=p (e)) is larger than k if and only if min (p (x q = a; e) kp (e)) is larger than zero.
Reference: [2] <author> M. Avriel. </author> <title> Nonlinear Programming: Analysis and Methods. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, </address> <year> 1980. </year>
Reference-contexts: This type of problem is termed a signomial program, for which there are algorithms that can determine the global minimum <ref> [2] </ref>. The combination of Lavine's algorithm and signomial programming leads to an algo rithm that surely converges to the correct lower bound of the posterior distribution. 5 EXPECTED UTILITY AND VARIANCE This paper has so far concentrated on algorithms for posterior marginals.
Reference: [3] <author> J. O. Berger. </author> <title> Robust bayesian analysis: Sensitivity to the prior. </title> <journal> Journal of Statistical Planning and Inference, </journal> <volume> 25 </volume> <pages> 303-328, </pages> <year> 1990. </year>
Reference-contexts: 1 INTRODUCTION Robust Bayesian inference is the calculation of posterior probability bounds given perturbations in a probabilistic model <ref> [3, 22, 38] </ref>. This paper presents robust inference algorithms when local perturbations to Bayesian networks are modeled by polytope-like convex sets of distributions. <p> Consider a variable x with values ^x, and a specification of probabilities masses for non-overlapping subsets of ^x. This procedure characterizes a sub-class of the belief function class, called a sub-sigma class <ref> [3, 24, 28] </ref>. The density bounded class A density bounded class is the set of all distributions p (x) so that l (x) p (x) u (x), where l () and u () are arbitrary non-negative measures so that P P 1 [25, 26].
Reference: [4] <author> J. S. Breese and K. W. Fertig. </author> <title> Decision making with interval influence diagrams. </title> <booktitle> UAI 6, </booktitle> <pages> pages 467-478. </pages> <publisher> Elsevier Science, North-Holland, </publisher> <year> 1991. </year> <booktitle> In Proceedings of the Thirteenth Annual Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Providence, Rhode Island, </address> <month> August 1-3, </month> <year> 1997 </year>
Reference-contexts: Several other theories use similar representations: inner/outer measures [17, 19, 30, 36], lower probability theory <ref> [4, 8, 15, 35] </ref>), convex Bayesianism [23], Dempster-Shafer theory [34], probability/utility sets [33]. The convex set of distributions maintained by an agent is called the credal set, and its existence is postulated on the grounds of axioms about preferences [16]. <p> Also, this class is the set of all distributions p (x) so that p (x) l (x) for an arbitrary non-negative measure l () [10]; there are approximations (without error bounds) for inferences with this formulation <ref> [4] </ref>. Belief function and sub-sigma classes Consider a discrete variable x with a finite set of values ^x. Suppose we impose a probability distribution m (A) into subsets of ^x.
Reference: [5] <author> A. Cano, J. E. Cano, and S. Moral. </author> <title> Convex sets of probabilities propagation by simulated annealing. </title> <booktitle> Fifth Int. Conference IPMU, </booktitle> <pages> pages 4-8, </pages> <year> 1994. </year>
Reference-contexts: The second approach takes the convex hull of all combinations of vertices in the local convex sets. We discuss exact algorithms for this problem using the Cano/Cano/Moral (CCM) transform <ref> [5] </ref>. Due to the complexity of exact algorithms, we develop two classes of approximation algorithms. <p> This technique forms the largest joint credal set whose vertices respect the independence relations displayed in the network [37]. The axiomatic underpinnings and algorithmic properties of this method for Bayesian networks have been studied previously <ref> [5, 6] </ref>. The method of the first approach is referred to as a natural extension and the result of the second method is referred to as a type-1 combination, to use terms proposed by Walley in a similar setting [37, pp. 453, 455]. <p> We begin with the exact solution for this problem using the Cano/Cano/Moral (CCM) transform <ref> [5] </ref>. 4.1 EXACT ROBUST INFERENCES Consider a Quasi-Bayesian network where variables z i are associated to polytopic credal sets with has vertices p i;j . <p> De fine the distribution of z 00 i to be: p (z 00 i )) = (p i;j (z i jpa (z i )) when z 0 i = j). The variables z 0 i are called transparent variables <ref> [5] </ref>. Note that each vertex in the original credal set can be obtained by properly adjusting the transparent variables. <p> Maximization and minimization with respect to the transparent variables produces the required bounds. These algorithms have been hinted in the analysis of the CCM transform <ref> [5] </ref>. Exact algorithms may be practical in cases where a few credal sets are under consideration, but their complexity grows too fast. If the network has s credal sets, each credal set represented by m i vertices, there are i=1 m i independent Bayesian inference runs to be performed. <p> To tackle large problems, we must use approximations. Cano, Cano and Moral have looked at approximations that treat the selection of transparent variable values as an integer programming problem; they use probabilistic techniques such as simulated annealing and genetic algorithms to handle such problems <ref> [5] </ref>. We describe two different approaches to this numerical problem. The first approach investigates interior-point methods for its solution (subsection 4.2). <p> This sampling approach offers a contrast between the interior-point methods advanced here and combinatorial optimization methods that search for the best combination of transparent variable values <ref> [5] </ref>. In combinatorial approaches, each iteration of the sampling procedure demands a complete cycle of standard Bayesian inference. <p> Instead, by searching in the interior space of distributions, we can use the simulated annealing and Gibbs sampling simultaneously; the convergence of this process is a particular benefit of the probabilistic structure of graphical models [39] which is not exploited by purely combinatorial approaches <ref> [5] </ref>. 4.3 LAVINE'S BRACKETING ALGORITHM The previous numerical approaches produced algorithms that converge to optimizers of the posterior distribution, without guarantees about global optimality. In this subsection we sketch an approach to obtain convergence to the global minimum of the posterior distribution. <p> We expect our results to bring robustness analysis to the forefront of tools that are used in a daily basis by Bayesian analysts. However, several issues remain to be addressed. It is necessary to evaluate which algorithms work best with empirical data; a comparison of integer programming methods <ref> [5] </ref> with interior-point methods is particularly important. Finally, and perhaps most importantly, methods to elicit information about credal sets from experts should be created and evaluated; for example, there must be guidance on how to select between natural extension/type-1 combinations.
Reference: [6] <author> J. Cano, M. Delgado, and S. Moral. </author> <title> An axiomatic framework for propagating uncertainty in directed acyclic networks. </title> <journal> Int. Journal of Approximate Reasoning, </journal> <volume> 8 </volume> <pages> 253-280, </pages> <year> 1993. </year>
Reference-contexts: This technique forms the largest joint credal set whose vertices respect the independence relations displayed in the network [37]. The axiomatic underpinnings and algorithmic properties of this method for Bayesian networks have been studied previously <ref> [5, 6] </ref>. The method of the first approach is referred to as a natural extension and the result of the second method is referred to as a type-1 combination, to use terms proposed by Walley in a similar setting [37, pp. 453, 455].
Reference: [7] <author> L. Chrisman. </author> <title> Independence with lower and upper probabilities. </title> <booktitle> UAI 12, </booktitle> <pages> pages 169-177, </pages> <year> 1996. </year>
Reference-contexts: Second, we may deal with a group of disagreeing experts, each specifying a particular distribution [27]. Third, we may be interested in abstracting away parts of a model and assessing the effects of this abstraction <ref> [7, 18] </ref>. For example, in the model of Figure 1, an agent may want to assess the impact of the link between variables A and B, or the impact of merging variables C and D into a single variable.
Reference: [8] <author> L. Chrisman. </author> <title> Propagation of 2-monotone lower probabilities on an undirected graph. </title> <booktitle> UAI 12, </booktitle> <pages> pages 178-186, </pages> <year> 1996. </year>
Reference-contexts: Several other theories use similar representations: inner/outer measures [17, 19, 30, 36], lower probability theory <ref> [4, 8, 15, 35] </ref>), convex Bayesianism [23], Dempster-Shafer theory [34], probability/utility sets [33]. The convex set of distributions maintained by an agent is called the credal set, and its existence is postulated on the grounds of axioms about preferences [16].
Reference: [9] <author> K. L. Clarkson, K. Mehlhorn, and R. Seidel. </author> <title> Four results on randomized incremental constructions. </title> <booktitle> In STACS, </booktitle> <pages> pages 463-474. </pages> <publisher> Springer, </publisher> <year> 1992. </year>
Reference-contexts: This asymmetry suggests a resort to the dual linear program, in which there will be M s variables and m s constraints [1]. Even though the complexity is still the same for exact solutions, now we can use recent results in the field of linear programming <ref> [9] </ref>, which indicate that problems with large numbers of constraints (compared to the number of variables) can be efficiently solved by In Proceedings of the Thirteenth Annual Conference on Uncertainty in Artificial Intelligence, Providence, Rhode Island, August 1-3, 1997 discarding many redundant constraints.
Reference: [10] <author> F. Cozman. </author> <title> Robust analysis of bayesian networks with finitely generated convex sets of distributions. </title> <institution> CMU-RI-TR96-41, Carnegie Mel-lon University, </institution> <note> December 1996 (available at http://www.cs.cmu.edu/~fgcozman/home.html). </note>
Reference-contexts: Proceedings of the Thirteenth Annual Conference on Uncertainty in Artificial Intelligence, Providence, Rhode Island, August 1-3, 1997 4.2.1 Gradient-based techniques The gradient of L (fi) is obtained by computing, for each ij : @L (fi) = @ ij @ log p (e) : This expression (derivation can be found in <ref> [10] </ref>) is: @L (fi) = i = jjx q = a; e) i = jje) ; (3) which can be obtained through standard Bayesian network algorithms using local computations. <p> The first step of the QEM algorithm is to obtain the expected value of the log-likelihood given the evidence and assuming fi 0 is correct <ref> [10] </ref>: Q (fijfi k ) = E [log (p (x q = a; e)) log (p (e))] = ijk ijk The second step of the QEM algorithm is to maximize Q (fijfi k ) for fi. <p> Now set fi k+1 to the maximizing value and go to the next iteration. The following theorem provides the justification for the QEM algorithm (proof can be found in <ref> [10] </ref>): Theorem 1 The QEM algorithm produces a sequence that converges globally to a local maximum of L (fi). 4.2.3 Sampling-based techniques Once we recast the robust inference problem as the estimation of parameters fi, we can also assume the parameters fi to be assigned uniform priors. <p> Most algorithms presented in this paper extend readily to expected utility by simple inclusion of the utility functions <ref> [10] </ref>. Calculation of lower and upper variances is more complex than expected utility because variances are nonlinear functionals of the distributions. We must reduce calculation of variances to an iterative calculation of expected utilities [37, Theorem G2] in order to solve this problem (the method is presented in [10]). 6 LOCAL <p> utility functions <ref> [10] </ref>. Calculation of lower and upper variances is more complex than expected utility because variances are nonlinear functionals of the distributions. We must reduce calculation of variances to an iterative calculation of expected utilities [37, Theorem G2] in order to solve this problem (the method is presented in [10]). 6 LOCAL ROBUSTNESS ANALYSIS IN JavaBayes In this section we describe an implementation of lo cal robust analysis for Quasi-Bayesian networks and present an example to illustrate the methods. Local robust analysis is available in the JavaBayes system, a portable and freely distributed inference engine for graphical models. <p> We also thank the reviewers, who suggested many improvements and brought important related work to our attention. A Classes of polytopic credal sets This section demonstrates the generality of our results by placing the most common models of robust Statistics into our framework <ref> [10] </ref>. *-contaminated and lower density bounded classes An *-contaminated class is characterized by a distribution p () and a real number * 2 (0; 1): r (x) = (1 *)p (x) + *q (x): (5) An *-contaminated class is the convex hull of the functions (1 *)p (x) + *ffi a <p> Also, this class is the set of all distributions p (x) so that p (x) l (x) for an arbitrary non-negative measure l () <ref> [10] </ref>; there are approximations (without error bounds) for inferences with this formulation [4]. Belief function and sub-sigma classes Consider a discrete variable x with a finite set of values ^x. Suppose we impose a probability distribution m (A) into subsets of ^x.
Reference: [11] <author> F. Cozman. </author> <title> Robustness analysis of bayesian networks with global neighborhoods. </title> <institution> CMU-RI-TR96-42, Carnegie Mellon University, </institution> <note> December 1996 (available at http://www.cs.cmu.edu/~fgcozman/home.html). </note>
Reference-contexts: The *-contaminated, constant density ratio, constant density bounded and total variation classes lead to robust inferences whose complexity is identical to the complexity of standard Bayesian inferences (the algorithms are presented in <ref> [11] </ref>). Future work will reveal whether such global models are useful for practical robustness analysis.
Reference: [12] <author> R. Dechter. </author> <title> Bucket elimination: A unifying framework for probabilistic inference. </title> <booktitle> UAI 12, </booktitle> <pages> pages 211-219, </pages> <year> 1996. </year>
Reference-contexts: Suppose a set of variables is fixed as evidence e; p e () is a distribution where variables e are fixed. Our algorithms assume efficient computation of posterior marginals in a Bayesian network <ref> [12, 21, 40] </ref>. 2.2 QUASI-BAYESIAN THEORY AND POLYTOPIC CREDAL SETS Quasi-Bayesian theory uses convex sets of distributions to represent beliefs and to evaluate decisions [16].
Reference: [13] <author> A. P. Dempster, N. M. Laird, and D. B. Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal Royal Statistical Society B, </journal> <volume> 44 </volume> <pages> 1-38, </pages> <year> 1977. </year>
Reference-contexts: A conjugate gradient descent can be constructed by selecting an initial value for fi and, at each step, normalizing the values of fi to ensure they represent proper distributions [31]. 4.2.2 The QEM algorithm In this subsection we show how the original Expectation-Maximization algorithm <ref> [13] </ref> can be extended to a Quasi-Bayesian Expectation-Maximization (QEM) algorithm with the same convergence properties. We must maximize the posterior log-likelihood L (fi) defined previously. The algorithm begins by assuming that the transparent variables are actual random quantities with distributions specified by fi.
Reference: [14] <author> L. DeRobertis and J. A. Hartigan. </author> <title> Bayesian inference using intervals of measures. </title> <journal> The Annals of Statistics, </journal> <volume> 9(2) </volume> <pages> 235-244, </pages> <year> 1981. </year>
Reference-contexts: The density ratio class A density ratio class con sists of distributions p (A) so that for any event A <ref> [14] </ref>: (l 0 (A)=l 00 (B)) (p (A)=p (B)) (l 00 (A)=l 0 (B)): where l 0 (A) and l 00 (A) are arbitrary positive measures such that l 0 () l 00 ().
Reference: [15] <author> T. L. </author> <title> Fine. Lower probability models for uncertainty and nondeterministic processes. </title> <journal> Journal of Statistical Planning and Inference, </journal> <volume> 20 </volume> <pages> 389-411, </pages> <year> 1988. </year>
Reference-contexts: Several other theories use similar representations: inner/outer measures [17, 19, 30, 36], lower probability theory <ref> [4, 8, 15, 35] </ref>), convex Bayesianism [23], Dempster-Shafer theory [34], probability/utility sets [33]. The convex set of distributions maintained by an agent is called the credal set, and its existence is postulated on the grounds of axioms about preferences [16].
Reference: [16] <author> F. J. Giron and S. Rios. </author> <title> Quasi-bayesian behaviour: A more realistic approach to decision making? Bayesian Statistics, </title> <address> pages 17-38. </address> <publisher> University Press, </publisher> <address> Valencia, Spain, </address> <year> 1980. </year>
Reference-contexts: The goal of robustness analysis is to study the impact of such perturbations to posterior values; this is done by analyzing bounds of posterior probabilities. We use the term Quasi-Bayesian theory, as suggested by Giron and Rios <ref> [16] </ref>, to refer to the theory of convex sets of distributions. In this theory there is no commitment to a underlying "true" distribution; a rational decision maker is expected to represent beliefs and preferences through convex sets of distributions which can have more than one element. <p> Our algorithms assume efficient computation of posterior marginals in a Bayesian network [12, 21, 40]. 2.2 QUASI-BAYESIAN THEORY AND POLYTOPIC CREDAL SETS Quasi-Bayesian theory uses convex sets of distributions to represent beliefs and to evaluate decisions <ref> [16] </ref>. Several other theories use similar representations: inner/outer measures [17, 19, 30, 36], lower probability theory [4, 8, 15, 35]), convex Bayesianism [23], Dempster-Shafer theory [34], probability/utility sets [33]. <p> The convex set of distributions maintained by an agent is called the credal set, and its existence is postulated on the grounds of axioms about preferences <ref> [16] </ref>. To simplify terminology, we use the term credal set only when it refers to a set of distributions containing more than one element. Convex sets of conditional distributions are used to represent conditional beliefs. <p> We use two well-known results about posterior credal sets in this paper. First, to obtain a posterior credal set, one has to apply Bayes rule only to the vertices of a prior credal set and take the convex hull of the resulting distributions <ref> [16] </ref>. Second, to obtain maximum and minimum values of posterior probabilities, we must look only at the vertices of the posterior credal sets [37].
Reference: [17] <author> I. J. </author> <title> Good. Good Thinking. </title> <publisher> University of Minnesota Press, </publisher> <address> Minneapolis, </address> <year> 1983. </year>
Reference-contexts: Our algorithms assume efficient computation of posterior marginals in a Bayesian network [12, 21, 40]. 2.2 QUASI-BAYESIAN THEORY AND POLYTOPIC CREDAL SETS Quasi-Bayesian theory uses convex sets of distributions to represent beliefs and to evaluate decisions [16]. Several other theories use similar representations: inner/outer measures <ref> [17, 19, 30, 36] </ref>, lower probability theory [4, 8, 15, 35]), convex Bayesianism [23], Dempster-Shafer theory [34], probability/utility sets [33]. The convex set of distributions maintained by an agent is called the credal set, and its existence is postulated on the grounds of axioms about preferences [16].
Reference: [18] <author> V. Ha and P. Haddawy. </author> <title> Theoretical foundations for abstraction-based probabilistic planning. </title> <booktitle> UAI 12, </booktitle> <pages> pages 291-298, </pages> <year> 1996. </year>
Reference-contexts: Second, we may deal with a group of disagreeing experts, each specifying a particular distribution [27]. Third, we may be interested in abstracting away parts of a model and assessing the effects of this abstraction <ref> [7, 18] </ref>. For example, in the model of Figure 1, an agent may want to assess the impact of the link between variables A and B, or the impact of merging variables C and D into a single variable.
Reference: [19] <author> J. Y. Halpern and R. Fagin. </author> <title> Two views of belief: Belief as generalized probability and belief as evidence. </title> <journal> Artificial Intelligence, </journal> <volume> 54 </volume> <pages> 275-317, </pages> <year> 1992. </year>
Reference-contexts: Our algorithms assume efficient computation of posterior marginals in a Bayesian network [12, 21, 40]. 2.2 QUASI-BAYESIAN THEORY AND POLYTOPIC CREDAL SETS Quasi-Bayesian theory uses convex sets of distributions to represent beliefs and to evaluate decisions [16]. Several other theories use similar representations: inner/outer measures <ref> [17, 19, 30, 36] </ref>, lower probability theory [4, 8, 15, 35]), convex Bayesianism [23], Dempster-Shafer theory [34], probability/utility sets [33]. The convex set of distributions maintained by an agent is called the credal set, and its existence is postulated on the grounds of axioms about preferences [16].
Reference: [20] <author> D. Heckerman, J. Breese, and K. Rommelse. </author> <title> Decision theoretic troubleshooting. </title> <journal> Communications of the ACM, </journal> <volume> 38 </volume> <pages> 49-57, </pages> <year> 1995. </year>
Reference-contexts: Documentation, code and examples for JavaBayes can be downloaded from http://www.cs.cmu.edu/~fgcoz-man/Research/JavaBayes/Home. As an example, consider a troubleshooting problem where the objective is to analyze the state of a car <ref> [20] </ref>, which contains 17 variables and several deterministic and stochastic relationships. Suppose there is some imprecision in the probability values for two variables. First, take the variable BatteryAge, which has two values, Old and New.
Reference: [21] <author> F. V. Jensen. </author> <title> An Introduction to Bayesian Networks. </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: Suppose a set of variables is fixed as evidence e; p e () is a distribution where variables e are fixed. Our algorithms assume efficient computation of posterior marginals in a Bayesian network <ref> [12, 21, 40] </ref>. 2.2 QUASI-BAYESIAN THEORY AND POLYTOPIC CREDAL SETS Quasi-Bayesian theory uses convex sets of distributions to represent beliefs and to evaluate decisions [16]. <p> In this space, the minimization problem is a linear fractional program: the minimization of the ratio of two linear functions subject to linear constraints [32]. To write down the program, we must run a cluster-type of Bayesian inference in the network <ref> [21] </ref>, leaving all nodes associated with credal sets in a single cluster. The probability values in this cluster will be the coefficients in the linear fractional program.
Reference: [22] <author> J. B. Kadane. </author> <title> Robustness of Bayesian Analysis, volume 4 of Studies in Bayesian econometrics. </title> <publisher> Elsevier Science Pub. Co., </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: 1 INTRODUCTION Robust Bayesian inference is the calculation of posterior probability bounds given perturbations in a probabilistic model <ref> [3, 22, 38] </ref>. This paper presents robust inference algorithms when local perturbations to Bayesian networks are modeled by polytope-like convex sets of distributions.
Reference: [23] <author> H. E. Kyburg Jr. </author> <title> Bayesian and non-Bayesian evidential updating. </title> <journal> Artificial Intelligence, </journal> <volume> 31 </volume> <pages> 271-293, </pages> <year> 1987. </year>
Reference-contexts: Several other theories use similar representations: inner/outer measures [17, 19, 30, 36], lower probability theory [4, 8, 15, 35]), convex Bayesianism <ref> [23] </ref>, Dempster-Shafer theory [34], probability/utility sets [33]. The convex set of distributions maintained by an agent is called the credal set, and its existence is postulated on the grounds of axioms about preferences [16].
Reference: [24] <author> D. Lambert and G. T. Duncan. </author> <title> Single-parameter inference based on partial prior information. </title> <journal> The Cana-dian Journal of Statistics, </journal> <volume> 14(4) </volume> <pages> 297-305, </pages> <year> 1986. </year>
Reference-contexts: Consider a variable x with values ^x, and a specification of probabilities masses for non-overlapping subsets of ^x. This procedure characterizes a sub-class of the belief function class, called a sub-sigma class <ref> [3, 24, 28] </ref>. The density bounded class A density bounded class is the set of all distributions p (x) so that l (x) p (x) u (x), where l () and u () are arbitrary non-negative measures so that P P 1 [25, 26].
Reference: [25] <author> M. Lavine. </author> <title> Sensitivity in bayesian statistics, the prior and the likelihood. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 86(414) </volume> <pages> 396-399, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: The density bounded class A density bounded class is the set of all distributions p (x) so that l (x) p (x) u (x), where l () and u () are arbitrary non-negative measures so that P P 1 <ref> [25, 26] </ref>. Since finitely many linear inequalities gen erate this class, it is a polytopic credal set.
Reference: [26] <editor> J. F. Lemmer and H. E. Kyburg Jr. </editor> <title> Conditions for the existence of belief functions corresponding to intervals of belief. </title> <booktitle> Proc. 9th National Conference on Artificial Intelligence, </booktitle> <pages> pages 488-493, </pages> <year> 1991. </year>
Reference-contexts: The density bounded class A density bounded class is the set of all distributions p (x) so that l (x) p (x) u (x), where l () and u () are arbitrary non-negative measures so that P P 1 <ref> [25, 26] </ref>. Since finitely many linear inequalities gen erate this class, it is a polytopic credal set.
Reference: [27] <author> I. Levi. </author> <title> The Enterprise of Knowledge. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1980. </year>
Reference-contexts: Second, we may deal with a group of disagreeing experts, each specifying a particular distribution <ref> [27] </ref>. Third, we may be interested in abstracting away parts of a model and assessing the effects of this abstraction [7, 18].
Reference: [28] <author> C. F. Manski. </author> <title> Learning and decision making when subjective probabilities have subjective domains. </title> <journal> The Annals of Statistics, </journal> <volume> 9(1) </volume> <pages> 59-65, </pages> <year> 1981. </year>
Reference-contexts: Consider a variable x with values ^x, and a specification of probabilities masses for non-overlapping subsets of ^x. This procedure characterizes a sub-class of the belief function class, called a sub-sigma class <ref> [3, 24, 28] </ref>. The density bounded class A density bounded class is the set of all distributions p (x) so that l (x) p (x) u (x), where l () and u () are arbitrary non-negative measures so that P P 1 [25, 26].
Reference: [29] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kauff-man, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: A Bayesian network defines a unique joint probability distribution <ref> [29] </ref>: p (~x) = i We use the abbreviation p i for p (x i jpa (x i )); expression (1) can be written as p (~x) = Q i p i . <p> As we assume that polytopic credal sets are specified over local (presumably small) structures, we assume that representations of polytopic credal sets in terms of vertices and inequalities can be used interchangeably. 2.3 COMBINING LOCAL INFORMATION Given a Bayesian network, there is a unique way to obtain a joint distribution <ref> [29] </ref>. This property does not generalize to Quasi-Bayesian models: given a Quasi-Bayesian network, there are several ways to combine the local conditional credal sets into a joint credal set. This paper focuses on two approaches to combination of local credal sets.
Reference: [30] <author> E. H. Ruspini. </author> <title> The logical foundations of evidential reasoning. </title> <type> Technical Report SRIN408, </type> <institution> SRI International, </institution> <year> 1987. </year>
Reference-contexts: Our algorithms assume efficient computation of posterior marginals in a Bayesian network [12, 21, 40]. 2.2 QUASI-BAYESIAN THEORY AND POLYTOPIC CREDAL SETS Quasi-Bayesian theory uses convex sets of distributions to represent beliefs and to evaluate decisions [16]. Several other theories use similar representations: inner/outer measures <ref> [17, 19, 30, 36] </ref>, lower probability theory [4, 8, 15, 35]), convex Bayesianism [23], Dempster-Shafer theory [34], probability/utility sets [33]. The convex set of distributions maintained by an agent is called the credal set, and its existence is postulated on the grounds of axioms about preferences [16].
Reference: [31] <author> S. Russell, J. Binder, D. Koller, and K. </author> <title> Kanazawa. Local learning in probabilistic networks with hidden variables. </title> <booktitle> Proc. Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <year> 1995. </year>
Reference-contexts: A conjugate gradient descent can be constructed by selecting an initial value for fi and, at each step, normalizing the values of fi to ensure they represent proper distributions <ref> [31] </ref>. 4.2.2 The QEM algorithm In this subsection we show how the original Expectation-Maximization algorithm [13] can be extended to a Quasi-Bayesian Expectation-Maximization (QEM) algorithm with the same convergence properties. We must maximize the posterior log-likelihood L (fi) defined previously.
Reference: [32] <author> S. Schaible. </author> <title> A survey of fractional programming. </title> <booktitle> Generalized Concavity in Optimization and Economics, </booktitle> <pages> pages 417-440. </pages> <publisher> Academic Press, </publisher> <year> 1981. </year>
Reference-contexts: In this space, the minimization problem is a linear fractional program: the minimization of the ratio of two linear functions subject to linear constraints <ref> [32] </ref>. To write down the program, we must run a cluster-type of Bayesian inference in the network [21], leaving all nodes associated with credal sets in a single cluster. The probability values in this cluster will be the coefficients in the linear fractional program. <p> The probability values in this cluster will be the coefficients in the linear fractional program. The advantage of approaching natural extension from this point of view is that any linear fractional program can be converted to a linear program through a simple transformation <ref> [32] </ref>, for which standard algorithms exist. We are able to produce an exact robust inference through this approach. The disadvantage of this approach is that the generation of coefficients in the cluster-based network propagation step may be impractical for Quasi-Bayesian networks with a large number of credal sets.
Reference: [33] <author> T. Seidenfeld. </author> <title> Outline of a theory of partially ordered preferences. </title> <booktitle> Philosophical Topics, </booktitle> <volume> 21(1) </volume> <pages> 173-188, </pages> <month> Spring </month> <year> 1993. </year>
Reference-contexts: Several other theories use similar representations: inner/outer measures [17, 19, 30, 36], lower probability theory [4, 8, 15, 35]), convex Bayesianism [23], Dempster-Shafer theory [34], probability/utility sets <ref> [33] </ref>. The convex set of distributions maintained by an agent is called the credal set, and its existence is postulated on the grounds of axioms about preferences [16].
Reference: [34] <author> G. Shafer. </author> <title> A mathematical theory of evidence. </title> <publisher> Prince-ton University Press, </publisher> <year> 1976. </year>
Reference-contexts: Several other theories use similar representations: inner/outer measures [17, 19, 30, 36], lower probability theory [4, 8, 15, 35]), convex Bayesianism [23], Dempster-Shafer theory <ref> [34] </ref>, probability/utility sets [33]. The convex set of distributions maintained by an agent is called the credal set, and its existence is postulated on the grounds of axioms about preferences [16]. <p> Belief function and sub-sigma classes Consider a discrete variable x with a finite set of values ^x. Suppose we impose a probability distribution m (A) into subsets of ^x. A belief function can be defined from the basic mass assignment as Bel (A) = P <ref> [34] </ref>; the belief function is the convex set of distributions such that p (A) Bel (A) for all A. To generate the finitely many vertices of the credal set, we must concentrate the non-zero basic mass assignments into each one of their subsets, one at a time.
Reference: [35] <author> C. A. B. Smith. </author> <title> Consistency in statistical inference and decision. </title> <journal> Journal Royal Statistical Society B, </journal> <volume> 23 </volume> <pages> 1-25, </pages> <year> 1961. </year>
Reference-contexts: Several other theories use similar representations: inner/outer measures [17, 19, 30, 36], lower probability theory <ref> [4, 8, 15, 35] </ref>), convex Bayesianism [23], Dempster-Shafer theory [34], probability/utility sets [33]. The convex set of distributions maintained by an agent is called the credal set, and its existence is postulated on the grounds of axioms about preferences [16].
Reference: [36] <author> P. Suppes. </author> <title> The measurement of belief. </title> <journal> Journal Royal Statistical Society B, </journal> <volume> 2 </volume> <pages> 160-191, </pages> <year> 1974. </year>
Reference-contexts: Our algorithms assume efficient computation of posterior marginals in a Bayesian network [12, 21, 40]. 2.2 QUASI-BAYESIAN THEORY AND POLYTOPIC CREDAL SETS Quasi-Bayesian theory uses convex sets of distributions to represent beliefs and to evaluate decisions [16]. Several other theories use similar representations: inner/outer measures <ref> [17, 19, 30, 36] </ref>, lower probability theory [4, 8, 15, 35]), convex Bayesianism [23], Dempster-Shafer theory [34], probability/utility sets [33]. The convex set of distributions maintained by an agent is called the credal set, and its existence is postulated on the grounds of axioms about preferences [16].
Reference: [37] <author> P. Walley. </author> <title> Statistical Reasoning with Imprecise Probabilities. </title> <publisher> Chapman and Hall, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: Second, to obtain maximum and minimum values of posterior probabilities, we must look only at the vertices of the posterior credal sets <ref> [37] </ref>. <p> for a function u (x) are defined as: E [u] = inf E p [u] E [u] = sup E p [u]: A credal set always creates lower and upper bounds of probability, but a set of lower and upper bounds of probability does not define a unique credal set <ref> [37, section 2.7] </ref>. The Quasi-Bayesian approach sidesteps this difficulty by taking convex sets as basic entities. <p> To produce a joint credal set, take the convex hull of the distributions Q j and k. This technique forms the largest joint credal set whose vertices respect the independence relations displayed in the network <ref> [37] </ref>. The axiomatic underpinnings and algorithmic properties of this method for Bayesian networks have been studied previously [5, 6]. <p> The method of the first approach is referred to as a natural extension and the result of the second method is referred to as a type-1 combination, to use terms proposed by Walley in a similar setting <ref> [37, pp. 453, 455] </ref>. <p> Calculation of lower and upper variances is more complex than expected utility because variances are nonlinear functionals of the distributions. We must reduce calculation of variances to an iterative calculation of expected utilities <ref> [37, Theorem G2] </ref> in order to solve this problem (the method is presented in [10]). 6 LOCAL ROBUSTNESS ANALYSIS IN JavaBayes In this section we describe an implementation of lo cal robust analysis for Quasi-Bayesian networks and present an example to illustrate the methods.
Reference: [38] <author> L. Wasserman. </author> <title> Recent methodological advances in robust bayesian inference. </title> <booktitle> Bayesian Statistics 4, </booktitle> <pages> pages 483-502. </pages> <publisher> Oxford University Press, </publisher> <year> 1992. </year>
Reference-contexts: 1 INTRODUCTION Robust Bayesian inference is the calculation of posterior probability bounds given perturbations in a probabilistic model <ref> [3, 22, 38] </ref>. This paper presents robust inference algorithms when local perturbations to Bayesian networks are modeled by polytope-like convex sets of distributions. <p> Since finitely many linear inequalities gen erate this class, it is a polytopic credal set. The total variation class The total variation class is the set of distributions p (x) so that <ref> [38] </ref>: jp (A) r (A)j * for any event A, where r (x) is a given probability distribution (a finite number of in equalities is generated this way).
Reference: [39] <author> J. York. </author> <title> Use of the gibbs sampler in expert systems. </title> <journal> Artificial Intelligence, </journal> <volume> 56 </volume> <pages> 115-130, </pages> <year> 1992. </year>
Reference-contexts: With this maneuver, we can use Bayesian learning methods to produce robust inferences. Sampling algorithms for calculation of posterior maxima have been studied in connection with Bayesian inference in general <ref> [39] </ref>. The reasoning in the previous paragraph demonstrates that they can be applied directly to Quasi-Bayesian inferences as well. Simulated annealing can guide a Gibbs sampler in generating samples of the posterior distribution; the sample with the highest probability defines the maximum [39]. <p> studied in connection with Bayesian inference in general <ref> [39] </ref>. The reasoning in the previous paragraph demonstrates that they can be applied directly to Quasi-Bayesian inferences as well. Simulated annealing can guide a Gibbs sampler in generating samples of the posterior distribution; the sample with the highest probability defines the maximum [39]. This sampling approach offers a contrast between the interior-point methods advanced here and combinatorial optimization methods that search for the best combination of transparent variable values [5]. In combinatorial approaches, each iteration of the sampling procedure demands a complete cycle of standard Bayesian inference. <p> Instead, by searching in the interior space of distributions, we can use the simulated annealing and Gibbs sampling simultaneously; the convergence of this process is a particular benefit of the probabilistic structure of graphical models <ref> [39] </ref> which is not exploited by purely combinatorial approaches [5]. 4.3 LAVINE'S BRACKETING ALGORITHM The previous numerical approaches produced algorithms that converge to optimizers of the posterior distribution, without guarantees about global optimality.
Reference: [40] <author> N. L. Zhang and D. Poole. </author> <title> Exploiting causal independence in Bayesian network inference. </title> <journal> Journal of Artificial Intelligence Research, </journal> <pages> pages 301-328, </pages> <year> 1996. </year>
Reference-contexts: Suppose a set of variables is fixed as evidence e; p e () is a distribution where variables e are fixed. Our algorithms assume efficient computation of posterior marginals in a Bayesian network <ref> [12, 21, 40] </ref>. 2.2 QUASI-BAYESIAN THEORY AND POLYTOPIC CREDAL SETS Quasi-Bayesian theory uses convex sets of distributions to represent beliefs and to evaluate decisions [16].
References-found: 40

