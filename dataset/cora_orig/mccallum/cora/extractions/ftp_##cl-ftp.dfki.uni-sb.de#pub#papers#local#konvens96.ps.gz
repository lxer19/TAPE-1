URL: ftp://cl-ftp.dfki.uni-sb.de/pub/papers/local/konvens96.ps.gz
Refering-URL: http://cl-www.dfki.uni-sb.de/cl/papers/cl-abstracts.html
Root-URL: 
Title: From Word Hypotheses to Logical Form: An Efficient Interleaved Approach ist, eine plausible semantische Interpretation
Author: Walter Kasper Hans-Ulrich Krieger Jorg Spilker Hans Weber Papier betrachten wir auf neue Weise Wortgraphenparsing, dessen Aufgabe es 
Keyword: Dialoge eingesetzt wird.  
Note: In diesem  
Abstract: This paper revisits word lattice parsing whose task is to find a plausible semantic interpretation for a given utterance. Our approach of interleaved search and analysis is designed to break the frontier of "toy" applications. The framework is implemented in two interacting modules, running in parallel. Instead of simply parsing a word lattice, we rather do tree decoding with a probabilistic approximation of a given grammar, employing a beam search strategy. Logical form is build up in tandem according to the decoded derivation histories, using a codescriptive HPSG grammar for dialog turns. Auerung zu finden. Unser Ansatz von uberlagerter Suche und Analyse ist mit dem Ziel entwickelt worden, die Grenzen von "Spielapplikationen" zu durch-brechen. Das System ist in zwei interagierenden, parallel arbeitenden Mo-dulen implementiert. Anstatt einen Wortgraphen direkt zu parsen, dekodieren wir Baume mit einer probabilistischen Approximation einer gegebene Gram-matik unter Verwendung einer Strahlensuche. Logische Form wird gema den Ableitungshistorien gleichzeitig mit aufgebaut, wobei eine HPSG Grammatik fur 
Abstract-found: 1
Intro-found: 1
Reference: <author> Amtrup, J. W. </author> <year> 1995. </year> <title> ICE|INTARC Communication Environment. Users Guide and Reference Manual. </title> <note> Version 1.4. Technical Document 14, Verbmobil, December. 11 Diagne, </note> <author> A. K., W. Kasper, and H.-U. Krieger. </author> <year> 1995. </year> <title> Distributed Parsing With HPSG Grammars. </title> <booktitle> In Proceedings of the 4th International Workshop on Parsing Technologies, IWPT-95, </booktitle> <pages> 79-86. </pages> <note> Also available as DFKI Research Report RR-95-19. </note>
Reference-contexts: The first parser operates on word lattices, getting its input from the speech recognition module. The second parser embodies the constraint solver, primarily interested in building up logical form. Communication between the parsers is established through the INTARC Communication Environment ICE <ref> (cf. Amtrup 1995) </ref>. ICE is based on PVM, the Parallel Virtual Machine, a system for communication between many processes in a heterogeneous network. ICE itself implements an interface layer on top of PVM, abstracting from communication channels, as it is known from Occam.
Reference: <author> Fujisaki, T., F. Jelinek, J. Cocke, E. Black, and T. Nishino. </author> <year> 1991. </year> <title> A Probabilistic Parsing Method for Sentence Disambiguation. In Current Issues in Parsing Technology, </title> <editor> ed. M. </editor> <booktitle> Tomita, </booktitle> <pages> 139-148. </pages> <address> Norvell, Mass. </address> <publisher> Kluver Akademic Publishers. </publisher>
Reference: <author> Hanrieder, G. </author> <year> 1995. </year> <title> Inkrementelles Parsing gesprochener Sprache mit einer linksas-soziativen Unifikationsgrammatik. </title> <type> PhD thesis, </type> <institution> Friedrich-Alexander Universitat, Erlangen-Nurnberg. </institution> <note> In German. </note>
Reference-contexts: How this can be achieved is described in Section 8. 5 4 Context-Sensitive Grammar Models The original unification grammar would be to expensive when directly applied to word lattices. Such approaches only assume read speech input which is an order of magnitude easier to decode than spontaneous speech <ref> (e.g., Hanrieder 1995 or Weber 1994) </ref>. Connected word graphs used there only contain 200 or less word hypotheses (instead of 30,000). The crucial point here is that parsing of unification grammar is basicly NP-complete while a context-free approximation can be parsed in (less than) cubic time.
Reference: <author> Hauenstein, A., and H. Weber. </author> <year> 1994. </year> <title> An Investigation of Tightly Coupled Time Synchronous Speech Language Interfaces Using a Unification Grammar. </title> <booktitle> In Proceedings of the Workshop on Integration of Natural Language and Speech Processing at AAAI 94, </booktitle> <editor> ed. P. </editor> <booktitle> McKevitt, </booktitle> <pages> 42-49. </pages> <month> August. </month>
Reference: <author> Kay, M., J. M. Gawron, and P. Norvig. </author> <year> 1994. </year> <title> Verbmobil: A Translation System for Face-to-Face Dialog. CSLI Lecture Notes, Number 33. Stanford: Center for the Study of Language and Information. </title>
Reference: <author> Krieger, H.-U. </author> <year> 1995. </year> <title> Classification and Representation of Types in TDL. </title> <booktitle> In Proceedings of the International KRUSE Symposium, Knowledge Retrieval, Use, and Storage for Efficiency, </booktitle> <pages> 74-85. </pages> <note> Also available as DFKI Research Report RR-95-17. </note>
Reference-contexts: In Intarc, this task is undertaken by the sophisticated typed feature formalisms TDL. Since the HPSG grammar for dialog turns (cf. Section 3) is strictly typed, a good deal of feature structure unifications simply reduce to type unifications which are implemented very efficiently through bit vectors and hash tables <ref> (cf. Krieger 1995) </ref>. It is worth noting that all rules of the grammar obey a certain locality requirement, meaning that they do not constrain daughters of daughters (neither through coreference requirements, nor through values).
Reference: <author> Krieger, H.-U., and U. Schafer. </author> <year> 1994. </year> <title> TDL|A Type Description Language for Constraint-Based Grammars. </title> <booktitle> In Proceedings of the 15th International Conference on Computational Linguistics, COLING-94, </booktitle> <pages> 893-899. </pages> <note> A enlarged version of this paper is available as DFKI Research Report RR-94-37. </note>
Reference-contexts: For the analysis of dialog turns, we use an HPSG-inspired grammar (Pollard and Sag 1987, Pollard and Sag 1994). The grammar consists of 65 rules, written in the typed feature formalism TDL <ref> (cf. Krieger and Schafer 1994 and Krieger and Schafer 1995) </ref>. It is a codescriptive grammar specifying simultaneously syntax and semantics. In order to deal with turns consisting of several segments, the HPSG approach had to be extended, primarily to deal with the semantic composition of turn segments.
Reference: <author> Krieger, H.-U., and U. Schafer. </author> <year> 1995. </year> <title> Efficient Parameterizable Type Expansion for Typed Feature Formalisms. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence, IJCAI-95, </booktitle> <pages> 1428-1434. </pages> <note> Also available as DFKI Research Report RR-95-18. </note>
Reference-contexts: In Intarc, this task is undertaken by the sophisticated typed feature formalisms TDL. Since the HPSG grammar for dialog turns (cf. Section 3) is strictly typed, a good deal of feature structure unifications simply reduce to type unifications which are implemented very efficiently through bit vectors and hash tables <ref> (cf. Krieger 1995) </ref>. It is worth noting that all rules of the grammar obey a certain locality requirement, meaning that they do not constrain daughters of daughters (neither through coreference requirements, nor through values).
Reference: <author> Magerman, D. M. </author> <year> 1994. </year> <title> Natural Language Parsing as Statistical Pattern Recognition. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> February. </month>
Reference-contexts: The probabilities actually used were distributions on rule applications given the mother rule and its daughter number as context K. We would have wished to extend the context K to larger portions of a tree in the sense of a history-based grammar model <ref> (see Magerman 1994) </ref>, but would have been running in sparse data problems then. Since the original tree bank was produced by a HPSG-style unification grammar (where no structure sharing can be used in a tree bank), we could not use an inside-outside algorithm to estimate our distributions.
Reference: <author> Ney, H. </author> <year> 1995. </year> <title> Architecture and Search Strategies for Large-Vocabulary Continuous-Speech Recognition. 59-84. </title> <booktitle> NATO ASI Series. </booktitle> <address> Berlin: </address> <publisher> Springer. </publisher> <editor> In: </editor> <title> Speech Recognition and Coding, </title> <editor> A.J. Rubio Ayuso and J.M. Lopez Soler, </editor> <publisher> editors. </publisher>
Reference: <author> Petzold, A. </author> <year> 1995. </year> <title> Strategies for Focal Accent Detection in Spontanous Speech. </title> <booktitle> In Proceedings of the 13th ICPhS, </booktitle> <pages> 672-675. </pages>
Reference: <author> Pollard, C., and I. A. Sag. </author> <year> 1987. </year> <title> Information-Based Syntax and Semantics. Vol. I: Fundamentals. CSLI Lecture Notes, Number 13. Stanford: Center for the Study of Language and Information. </title>
Reference-contexts: For the analysis of dialog turns, we use an HPSG-inspired grammar <ref> (Pollard and Sag 1987, Pollard and Sag 1994) </ref>. The grammar consists of 65 rules, written in the typed feature formalism TDL (cf. Krieger and Schafer 1994 and Krieger and Schafer 1995). It is a codescriptive grammar specifying simultaneously syntax and semantics.
Reference: <author> Pollard, C., and I. A. Sag. </author> <year> 1994. </year> <title> Head-Driven Phrase Structure Grammar. </title> <booktitle> Studies in Contemporary Linguistics. </booktitle> <address> Chicago: </address> <publisher> University of Chicago Press. </publisher>
Reference: <author> Strom, V. </author> <year> 1995. </year> <title> Detection of Accents, Phrase Boundaries and Sentence Modality in German with Prosodic Features. </title> <booktitle> In Eurospeech 95, </booktitle> <pages> 2039-2041. </pages>
Reference-contexts: This is important to further reduce the set of emitted hypotheses, as explained in Section 7. The word-lattice parser as well as the sem-parser additionally receives hypotheses from two prosodic components (see Section 8). The one simply termed "prosody" is a detector for phrase boundaries and sentence modalities <ref> (cf. Strom 1995) </ref>. The other one is a detector for focus (cf.
Reference: <author> Wahlster, W. </author> <year> 1993. </year> <note> VERBMOBIL|Translation of Face-to-Face Dialogs. Research Report RR-93-34, German Research Center for Artificial Intelligence (DFKI), Saarbrucken, Germany. Also in Proc. </note> <institution> MT Summit IV, </institution> <address> 127-135, Kobe, Japan, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: The domain of Verbmobil consists of a collection of negotiation dialogs, where only a minor part consists of "sentences" in a linguistic sense <ref> (cf. Wahlster 1993 and Kay et al. 1994) </ref>. A large amount of the dialog steps are long turns made of sequences of fragments, sentences and interjections. Well-trained bigram models for these dialogs show a perplexity of more than 100.
Reference: <author> Weber, H. </author> <year> 1994. </year> <title> Time-Synchronous Chart Parsing of Speech Integrating Unification Grammars with Statistics. </title> <booktitle> Proceedings of Twente Workshop on Speech and Language Engeneering 107-120. </booktitle>
Reference: <author> Weber, H. </author> <year> 1995. </year> <institution> LR-inkrementelles, probabilistisches Chartparsing von Worthypothe-senmengen mit Unifikationsgrammatiken: Eine enge Kopplung von Suche und Analyse. </institution> <type> PhD thesis, </type> <institution> Universitat Hamburg, Department of Computer Science. </institution> <note> In German. 13 </note>
Reference-contexts: How this can be achieved is described in Section 8. 5 4 Context-Sensitive Grammar Models The original unification grammar would be to expensive when directly applied to word lattices. Such approaches only assume read speech input which is an order of magnitude easier to decode than spontaneous speech <ref> (e.g., Hanrieder 1995 or Weber 1994) </ref>. Connected word graphs used there only contain 200 or less word hypotheses (instead of 30,000). The crucial point here is that parsing of unification grammar is basicly NP-complete while a context-free approximation can be parsed in (less than) cubic time. <p> Instead, we extended a PCFG reestimation procedure from Fujisaki et al. 1991 to arbitrary contexts K. 5 Lattice Parsing as Tree Decoding The lattice parsing module is a variant of an LR-incremental active chart parser, where all empty edge introduction operations are precompiled into an LR table <ref> (cf. Weber 1995 and Weber 1994) </ref>.
References-found: 17

