URL: http://www.cs.arizona.edu/people/debray/papers/retval_placement.ps
Refering-URL: http://www.cs.arizona.edu/jc/
Root-URL: http://www.cs.arizona.edu
Email: E-mail: debray@cs.arizona.edu  
Title: RETURN VALUE PLACEMENT AND TAIL CALL OPTIMIZATION IN HIGH LEVEL LANGUAGES  
Author: PETER A. BIGOT AND SAUMYA DEBRAY Saumya K. Debray, 
Address: Tucson, AZ 85721, USA.  655 Avenue of the Americas, New York, NY 10010 0743-1066/93/$3.50  
Affiliation: Department of Computer Science, University of Arizona,  
Note: J. LOGIC PROGRAMMING 1993:12:1-199 1  Address correspondence to  THE JOURNAL OF LOGIC PROGRAMMING c flElsevier Science Publishing Co., Inc., 1993  
Abstract: fl This paper discusses the interaction between tail call optimization and the placement of output values in functional and logic programming languages. Implementations of such languages typically rely on fixed placement policies: most functional language implementations return output values in registers, while most logic programming systems return outputs via memory. Such fixed placement policies incur unnecessary overheads in many commonly encountered situations: the former are unable to implement many intuitively iterative computations in a truly iterative manner, while the latter incur a performance penalty due to additional memory references. We describe an approach that determines, based on a low-level cost model for an implementation together with an estimated execution profile for a program, whether or not the output of a procedure should be returned in registers or in memory. This can be seen as realizing a restricted form of inter-procedural register allocation, and avoids the disadvantages associated with the fixed register and fixed memory output placement policies. Experimental results indicate that it provides good performance improvements compared to existing approaches. fl This work was supported in part by the National Science Foundation under grant number CCR-9123520. The first author was also supported by graduate fellowships from the U.S. Office of Naval Research and AT&T Bell Laboratories. A preliminary version of this paper appeared in Proc. Eleventh International Conference on Logic Programming, Santa Margherita Ligure, Italy, June 1994. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> A. W. Appel, </author> <title> Compiling with Continuations, </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: A similar situation arises in systems such as Standard ML of New Jersey <ref> [1] </ref> that use continuation passing style, and which pass arguments to "known" functions in registers: since functions in continuation passing style do not actually return any values to their caller, but pass them instead as arguments to a continuation, the placement of these "return values" is determined by the scheme used <p> The second problem, namely, register shu*ing, can be addressed to some extent by techniques such as register targeting <ref> [1, 2, 11] </ref>, but these do not address the additional space overheads that can be incurred by such schemes. It is interesting to contrast such register-return models, commonly used in functional programming systems, with implementations of logic programming languages such as Prolog. <p> the merit that, in the absence of recursive data structure construction and multiple return values, a call that appears syntactically in a tail call position can be guaranteed to be implementable as a tail call (as illustrated in Example 3.2, this is not true of schemes such as register targeting <ref> [1, 2, 11] </ref>, which relax the fixed positional association between return values and registers in order to reduce the shu*ing of data between registers). Unfortunately, it suffers from two disadvantages. <p> The second of these problems can be avoided using flexible register return policies, where the positional association between values and registers is relaxed. This can be accomplished, for example, using register targeting techniques <ref> [1, 2, 11] </ref> or inter-procedural register allocation [15]. However, flexible register returns exacerbate the problem with tail call deoptimization due to mismatches in return register choices.
Reference: 2. <author> A. W. Appel and Z. Shao, </author> <title> "Callee-save Registers in Continuation-passing Style", </title> <booktitle> Lisp and Symbolic Computation (5) 191-221, </booktitle> <year> 1992. </year>
Reference-contexts: The second problem, namely, register shu*ing, can be addressed to some extent by techniques such as register targeting <ref> [1, 2, 11] </ref>, but these do not address the additional space overheads that can be incurred by such schemes. It is interesting to contrast such register-return models, commonly used in functional programming systems, with implementations of logic programming languages such as Prolog. <p> the merit that, in the absence of recursive data structure construction and multiple return values, a call that appears syntactically in a tail call position can be guaranteed to be implementable as a tail call (as illustrated in Example 3.2, this is not true of schemes such as register targeting <ref> [1, 2, 11] </ref>, which relax the fixed positional association between return values and registers in order to reduce the shu*ing of data between registers). Unfortunately, it suffers from two disadvantages. <p> The second of these problems can be avoided using flexible register return policies, where the positional association between values and registers is relaxed. This can be accomplished, for example, using register targeting techniques <ref> [1, 2, 11] </ref> or inter-procedural register allocation [15]. However, flexible register returns exacerbate the problem with tail call deoptimization due to mismatches in return register choices.
Reference: 3. <author> J. M. Ashley and R. K. Dybvig, </author> <title> "An Efficient Implementation of Multiple Return Values in Scheme", </title> <booktitle> Proc. ACM Conference on Lisp and Functional Programming, </booktitle> <year> 1994, </year> <pages> pp. 140-149. </pages>
Reference-contexts: sequence to the register in which that value is passed: the first argument to a function is passed in register 1, the second argument in register 2, etc.; the first return value is returned in register 1, the second return value in register 2, and so on (see, for example, <ref> [3, 8, 11] </ref>; the S-1 Common Lisp compiler uses this approach for numerical return values [6]). <p> For example, we may use a convention similar to that used for the input arguments, with the first return value being placed in register 1, the second in register 2, and so on. The simplicity of this approach makes it the method of choice in many functional language implementations <ref> [3, 6, 8, 11] </ref>. 2 In reality, implementations have only a bounded number of registers available to them. Because of this, a system that would otherwise pass a value in a register may be forced, due to an inadequate number of available registers, to pass it in memory.
Reference: 4. <author> J. Beer, </author> <title> "The Occur-Check Problem Revisited", </title> <journal> J. Logic Programming vol. </journal> <volume> 5 no. 3, </volume> <month> Sept. </month> <year> 1988, </year> <pages> pp. 243-261. 30 </pages>
Reference-contexts: All these costs, for both registers and memory, are scaled by the frequency with which the clause is executed. 3 Such initialization may not be necessary if the uninitialized memory cells can be recognized as such, e.g., by using a special tag on pointers to such cells <ref> [4] </ref>.
Reference: 5. <author> P. A. Bigot, D. Gudeman, and S. K. Debray, </author> <title> "Output Value Placement in Moded Logic Programs", </title> <type> Technical Report 94-03, </type> <institution> Department of Computer Science, The University of Arizona, Tucson, </institution> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: The second pass processes procedures in decreasing order of execution frequency (obtained either using heuristics based on program structure <ref> [5, 20] </ref> or using execution profiles generated from "training runs" of the program) and does a greedy bottom-up assignment of output locations. A high-level overview of the method appears in the features of the various contexts in which values are defined and used. 4.1. <p> Performance Results: Simple Loops this paper correspond to gcc 2.6.3 invoked with -O2 -fomit-frame-pointer) to compile the resulting program to executable code (the current system uses heuristics based on the structure of the program to estimate execution frequencies [20]: a detailed discussion of the heuristics used appears in <ref> [5] </ref>; in principle, this information could also be obtained using profile information obtained from "training runs" of the programs, but we have not implemented this yet).
Reference: 6. <author> R. A. Brooks, R. P. Gabriel, and G. L. Steele, Jr., </author> <title> "S-1 Common Lisp Implementation", </title> <booktitle> Proc. ACM Symp. on Lisp and Functional Programming, </booktitle> <address> Pittsburgh, PA, </address> <month> Aug. </month> <year> 1982, </year> <pages> pp. 108-113. </pages>
Reference-contexts: function is passed in register 1, the second argument in register 2, etc.; the first return value is returned in register 1, the second return value in register 2, and so on (see, for example, [3, 8, 11]; the S-1 Common Lisp compiler uses this approach for numerical return values <ref> [6] </ref>). <p> For example, we may use a convention similar to that used for the input arguments, with the first return value being placed in register 1, the second in register 2, and so on. The simplicity of this approach makes it the method of choice in many functional language implementations <ref> [3, 6, 8, 11] </ref>. 2 In reality, implementations have only a bounded number of registers available to them. Because of this, a system that would otherwise pass a value in a register may be forced, due to an inadequate number of available registers, to pass it in memory.
Reference: 7. <author> P. Cheng and C. Okasaki, </author> <title> "Destination-Passing Style and Generational Garbage Collection", </title> <type> unpublished manuscript, </type> <institution> School of Computer Science, Carnegie Mellon University, Pittsburgh, </institution> <month> Nov. </month> <year> 1996. </year>
Reference-contexts: Fortunately, this turns out not to be a problem in practice, since the issue can be addressed using a technique developed by Cheng and Okasaki <ref> [7] </ref>, who maintain a list of pointers into data structures that have survived 5 In the case of ties between different placements, our implementation chooses memory over registers of the same cost, because memory will less often destroy a tail call opportunity.
Reference: 8. <author> W. D. Clinger and L. T. Hansen, </author> <title> "Lambda, the Ultimate Label, or A Simple Optimizing Compiler for Scheme", </title> <booktitle> Proc. ACM Conference on Lisp and Functional Programming, </booktitle> <year> 1994, </year> <pages> pp. 128-139. </pages>
Reference-contexts: sequence to the register in which that value is passed: the first argument to a function is passed in register 1, the second argument in register 2, etc.; the first return value is returned in register 1, the second return value in register 2, and so on (see, for example, <ref> [3, 8, 11] </ref>; the S-1 Common Lisp compiler uses this approach for numerical return values [6]). <p> For example, we may use a convention similar to that used for the input arguments, with the first return value being placed in register 1, the second in register 2, and so on. The simplicity of this approach makes it the method of choice in many functional language implementations <ref> [3, 6, 8, 11] </ref>. 2 In reality, implementations have only a bounded number of registers available to them. Because of this, a system that would otherwise pass a value in a register may be forced, due to an inadequate number of available registers, to pass it in memory.
Reference: 9. <author> S. K. Debray, D. Gudeman and P. A. Bigot, </author> <title> "Detection and Optimization of Suspension-free Logic Programs", </title> <journal> Journal of Logic Programming (Special Issue on High Performance Implementations), </journal> <volume> vol. 29 nos. </volume> <pages> 1-3, </pages> <month> Nov. </month> <year> 1996, </year> <pages> pp. 171-194. </pages>
Reference-contexts: This section describes an algorithm we have developed that has these characteristics and that has been incorporated into a compiler that we have implemented for Janus, a committed-choice logic programming language [10]. The compiler uses inter-procedural dataflow analyses <ref> [9] </ref> to determine the input and output arguments of each procedure, and identify procedures and variables that must use the default output placement policy (e.g., procedures whose execution can suspend and subsequently be resumed, and variables that may be used as logical variables, i.e., "used" before they are defined).
Reference: 10. <author> D. Gudeman, K. De Bosschere, and S.K. Debray, </author> <title> "jc: An Efficient and Portable Sequential Implementation of Janus", </title> <booktitle> Proc. Joint International Conference and Symposium on Logic Programming, </booktitle> <address> Washington DC, </address> <month> Nov. </month> <year> 1992, </year> <pages> pp. 399-413. </pages> <publisher> MIT Press. </publisher>
Reference-contexts: This section describes an algorithm we have developed that has these characteristics and that has been incorporated into a compiler that we have implemented for Janus, a committed-choice logic programming language <ref> [10] </ref>. <p> An early version of the system is described in <ref> [10] </ref>, and a prototype of the system as well as the code for the benchmarks is available by anonymous FTP from ftp.cs.arizona.edu.
Reference: 11. <author> D. Krantz, </author> <title> ORBIT: An Optimizing Compiler for Scheme, </title> <type> Ph.D. Dissertation, </type> <institution> Yale University, </institution> <year> 1988. </year> <note> (Also available as Technical Report YALEU/DCS/RR-632, </note> <institution> Dept. of Computer Science, Yale University, </institution> <month> Feb. </month> <year> 1988.) </year>
Reference-contexts: sequence to the register in which that value is passed: the first argument to a function is passed in register 1, the second argument in register 2, etc.; the first return value is returned in register 1, the second return value in register 2, and so on (see, for example, <ref> [3, 8, 11] </ref>; the S-1 Common Lisp compiler uses this approach for numerical return values [6]). <p> The second problem, namely, register shu*ing, can be addressed to some extent by techniques such as register targeting <ref> [1, 2, 11] </ref>, but these do not address the additional space overheads that can be incurred by such schemes. It is interesting to contrast such register-return models, commonly used in functional programming systems, with implementations of logic programming languages such as Prolog. <p> For example, we may use a convention similar to that used for the input arguments, with the first return value being placed in register 1, the second in register 2, and so on. The simplicity of this approach makes it the method of choice in many functional language implementations <ref> [3, 6, 8, 11] </ref>. 2 In reality, implementations have only a bounded number of registers available to them. Because of this, a system that would otherwise pass a value in a register may be forced, due to an inadequate number of available registers, to pass it in memory. <p> the merit that, in the absence of recursive data structure construction and multiple return values, a call that appears syntactically in a tail call position can be guaranteed to be implementable as a tail call (as illustrated in Example 3.2, this is not true of schemes such as register targeting <ref> [1, 2, 11] </ref>, which relax the fixed positional association between return values and registers in order to reduce the shu*ing of data between registers). Unfortunately, it suffers from two disadvantages. <p> The second of these problems can be avoided using flexible register return policies, where the positional association between values and registers is relaxed. This can be accomplished, for example, using register targeting techniques <ref> [1, 2, 11] </ref> or inter-procedural register allocation [15]. However, flexible register returns exacerbate the problem with tail call deoptimization due to mismatches in return register choices.
Reference: 12. <author> J. R. Larus, </author> <title> Restructuring Symbolic Programs for Concurrent Execution on Multiprocessors, </title> <type> Ph.D. Dissertation, </type> <institution> University of California, Berkeley, </institution> <year> 1989. </year> <note> Also available as Technical Report UCB/CSD 89/502, </note> <institution> Computer Science Division (EECS), University of California, Berkeley, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: RELATED WORK The work most closely related to this is the output placement algorithm described by Van Roy [18] and used in the Aquarius Prolog compiler, and the "destination passing style" described by Larus <ref> [12] </ref>. Van Roy's scheme is heterogeneous, i.e., can choose between register and memory placements. When register returns are chosen, it uses a fixed positional mapping to determine which register an output value should be returned in.
Reference: 13. <author> W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery, </author> <title> Numerical Recipes in C, </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: Performance Results: Structure Computations - mandelbrot computes the Mandelbrot set on a 17 fi 17 grid on an area of the complex plane from (1:5; 1:5) to (1:5; 1:5); - mcint uses Monte Carlo integration to estimate the mass of a body of irreg ular shape, adapted from <ref> [13] </ref>; - tak, from the Gabriel benchmarks, is a heavily recursive program involving integer addition and subtraction; zeta computes the Euler-Riemann zeta function, defined by the series zeta (x) = 1 + 2 x + 3 x + (where x is real-valued), at x = 2:0; In this case, a homogeneous <p> The benchmarks used were the following: - bsort is a bubble sort program on a list of 100 integers; - disj converts a propositional formula to disjunctive normal form; - fft is an iterative one-dimensional fast Fourier transform, adapted from <ref> [13] </ref>.
Reference: 14. <author> N. Rojemo, </author> <title> "Generational Garbage Collection for Lazy Functional Languages with Temporary Space Leaks", </title> <booktitle> Proc. International Workshop on Memory Management, 1995. </booktitle> <publisher> Springer Verlag. </publisher>
Reference-contexts: A similar interaction with generational garbage collection also arises in lazy functional languages because of the way closures are updated with values once they get evaluated; techniques proposed to address this problem for lazy languages may be applicable to our optimization as well (see, for example, <ref> [14] </ref>). 4.4.
Reference: 15. <author> P. A. Steenkiste and J. L. Hennessy, </author> <title> "A Simple Interprocedural Register Allocation Algorithm and its Effectiveness for Lisp", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> vol. 11 no. 1, </volume> <month> Jan. </month> <year> 1989, </year> <pages> pp. 1-32. </pages>
Reference-contexts: The second of these problems can be avoided using flexible register return policies, where the positional association between values and registers is relaxed. This can be accomplished, for example, using register targeting techniques [1, 2, 11] or inter-procedural register allocation <ref> [15] </ref>. However, flexible register returns exacerbate the problem with tail call deoptimization due to mismatches in return register choices. In particular, unlike the fixed register return case, tail call optimization can be blocked even in the absence of multiple return values and data structures constructed on the heap.
Reference: 16. <author> D. Tarditi, G. Morrisett, P. Cheng, C. Stone, R. Harper, and P. Lee, </author> <title> "TIL: A type-directed optimizing compiler for ML", </title> <booktitle> Proc. SIGPLAN '96 Conference on Programming Language Design and Implementation. ACM, </booktitle> <address> New York, </address> <pages> pp. 181-192. </pages>
Reference-contexts: Using an implementation based on TIL <ref> [16] </ref>, an optimizing compiler for Standard ML, Cheng and Okasaki show that using an approach similar to that proposed here can lead to significant improvements in running time, both when garbage collection time is included in the measurements, and when it is not; they also show that in many cases, such
Reference: 17. <author> E. Tick, </author> <title> Parallel Logic Programming, </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Performance Results: Scalar Computations - nand is an electrical circuit design program, taken from <ref> [17] </ref>; pi computes the value of to a precision of 10 3 using the expansion 4 = 3 + 1 7 + ; sum adds the integers from 1 to 10,000|it is essentially similar to a tail recursive factorial computation, except that it can perform a much greater number of iterations
Reference: 18. <author> P. Van Roy. </author> <title> Can Logic Programming Execute as Fast as Imperative Programming? PhD thesis, </title> <institution> University of California at Berkeley, </institution> <year> 1990. </year>
Reference-contexts: RELATED WORK The work most closely related to this is the output placement algorithm described by Van Roy <ref> [18] </ref> and used in the Aquarius Prolog compiler, and the "destination passing style" described by Larus [12]. Van Roy's scheme is heterogeneous, i.e., can choose between register and memory placements.
Reference: 19. <author> P. Wadler, </author> <title> "Listlessness is Better than Laziness: Lazy evaluation and garbage collection at compile-time", </title> <booktitle> Proc. ACM Symposium on Lisp and Functional Programming, </booktitle> <year> 1984, </year> <pages> pp. 45-52. 31 </pages>
Reference-contexts: An idea similar to destination passing style, though motivated by different concerns|namely, the elimination of intermediate lists in applicative programs|and somewhat more restricted in scope, is described by Wadler, who refers to it as tail recursion modulo cons <ref> [19] </ref>. 8. CONCLUSIONS Most implementations of functional and logic programming languages take a fixed approach to how values computed by procedures are returned: return values are usually placed either always in registers, or always in memory.
Reference: 20. <author> D. W. Wall, </author> <title> "Predicting Program Behavior Using Real or Estimated Profiles", </title> <booktitle> Proc. SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991, </year> <pages> pp. 59-70. </pages>
Reference-contexts: The second pass processes procedures in decreasing order of execution frequency (obtained either using heuristics based on program structure <ref> [5, 20] </ref> or using execution profiles generated from "training runs" of the program) and does a greedy bottom-up assignment of output locations. A high-level overview of the method appears in the features of the various contexts in which values are defined and used. 4.1. <p> Performance Results: Simple Loops this paper correspond to gcc 2.6.3 invoked with -O2 -fomit-frame-pointer) to compile the resulting program to executable code (the current system uses heuristics based on the structure of the program to estimate execution frequencies <ref> [20] </ref>: a detailed discussion of the heuristics used appears in [5]; in principle, this information could also be obtained using profile information obtained from "training runs" of the programs, but we have not implemented this yet).
Reference: 21. <author> D. H. D. Warren, </author> <title> "An Abstract Prolog Instruction Set", </title> <type> Technical Note 309, </type> <institution> SRI International, </institution> <address> Menlo Park, CA, </address> <month> Oct. </month> <year> 1983. </year>
Reference-contexts: Memory Returns Unlike functional language systems, implementations of logic programming languages have typically returned output values in memory. A commonly used policy, 9 originating in the Warren Abstract Machine <ref> [21] </ref>, is to pass the ith argument in register i: if the ith argument happens to be a variable (which typically corresponds to an output argument), the value passed is a pointer to the location of the variable (which may be either on the stack or on the heap).
References-found: 21

