URL: http://www.ececs.uc.edu/~sweaver/postscript/cdc.ps
Refering-URL: http://www.ececs.uc.edu/~sweaver/
Root-URL: 
Title: Adaptive Wavelet Control of Nonlinear Systems  
Author: Marios M. Polycarpou Mark J. Mears ; and Scott E. Weaver ; 
Keyword: wavelets, neural networks, adaptive nonlinear control, Lyapunov stability theory, localization.  
Note: 2 Wright-Patterson Air Force Base, WL/FIGC, WPAFB,  3 Wright-Patterson Air Force Base, WL/AACF, WPAFB,  
Address: OH 45221-0030, USA  OH 45433-7531, USA  OH 45433-7318, USA  
Affiliation: 1 Dept. ECECS, University of Cincinnati, Cincinnati,  
Abstract: This paper considers the design and analysis of adaptive wavelet control algorithms for uncertain nonlinear dynamical systems. The Lyapunov synthesis approach is used to develop a state-feedback adaptive control scheme based on nonlinearly parametrized wavelet network models. Semi-global stability results are obtained under the key assumption that the system uncertainty satisfies a "matching" condition. The localization properties of adaptive networks are discussed and formal definitions of interference and localization measures are proposed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R.M. Sanner and J.-J.E. Slotine, </author> <title> "Gaussian networks for direct adaptive control," </title> <journal> IEEE Trans. on Neural Networks, </journal> <volume> vol. 3, no. 6, </volume> <pages> pp. 837-863, </pages> <month> Nov. </month> <year> 1992. </year>
Reference: [2] <author> M. Polycarpou and P. Ioannou, </author> <title> "Modeling, identification and stable adaptive control of continuous-time nonlinear dynamical systems using neural networks," </title> <booktitle> Proc. 1992 Amer. Control Conf., </booktitle> <pages> pp. 36-40, </pages> <month> June </month> <year> 1992. </year>
Reference: [3] <author> F.-C. Chen and H.K. Khalil, </author> <title> "Adaptive control of a class of nonlinear discrete-time systems using neural networks," </title> <journal> IEEE Trans. Autom. Control, </journal> <volume> vol. 40, no. 5, </volume> <pages> pp. 791-801, </pages> <month> May </month> <year> 1995. </year>
Reference: [4] <author> F.L. Lewis, K. Liu, and A. Yesildirek, </author> <title> "Neural net robot controller with guaranteed tracking performance," </title> <journal> IEEE Trans. on Neural Networks, </journal> <volume> vol. 6, no. 3, </volume> <pages> pp. 703-715, </pages> <month> May </month> <year> 1995. </year>
Reference: [5] <author> J.T Spooner, R. Ordonez, K.M. Passino, </author> <title> "Stable Direct Adaptive Control of a class of discrete-time nonlinear systems," </title> <booktitle> Proc. 13th World Congress of IFAC, vol. K, </booktitle> <pages> pp. 343-348, </pages> <month> July </month> <year> 1996. </year>
Reference: [6] <editor> M.M. Polycarpou, </editor> <title> "Stable adaptive neural control scheme for nonlinear systems," </title> <journal> IEEE Trans. Au-tom. Control, </journal> <volume> vol. 41, no. 3, </volume> <pages> pp. 447-451, </pages> <month> March </month> <year> 1996. </year>
Reference: [7] <author> H.K. Khalil, </author> <title> Nonlinear Systems, </title> <booktitle> 2nd Edit., </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1996. </year>
Reference-contexts: According to the above formulation, the modeling uncertainty, , and disturbances, d, are assumed to be in the range space of the matrix G fl ; this is known as a matching condition <ref> [7] </ref>. Several systems of practical in terest satisfy such a matching condition. <p> continuously differentiable Lyapunov function V N (x) that satisfies the inequalities ff 1 (kxk) V N ff 2 (kxk) (4) @x where ff 1 , ff 2 , ff 3 are class K 1 functions; i.e., they are strictly increasing, ff i (0) = 0, and they are radially unbounded <ref> [7] </ref>. The control objective is to design an augmented control law such that the overall controller u = ff + causes the system to be feedback stabilizable in the presence of modeling uncertainties and disturbances.
Reference: [8] <author> J. Park and I.W. Sandberg, </author> <title> "Universal approximation using radial-basis-function networks," </title> <journal> Neural Computation, </journal> <volume> vol. 3, </volume> <pages> pp. 246-257, </pages> <year> 1991. </year>
Reference-contexts: In general, increasing the number of adjustable weights (denoted by q) reduces the network reconstruction error. Universal approximation results for various adaptive network architectures indicate that if q is sufficiently large then ffi can be made arbitrarily small uniformly on a compact region <ref> [8, 9] </ref>. The optimal weight vector is an "artificial" quantity required only for analytical purposes.
Reference: [9] <author> A. Barron, </author> <title> "Universal approximation bounds for superpositions of a sigmoidal function," </title> <journal> IEEE Trans. Information Theory, </journal> <volume> vol. 39, </volume> <pages> pp. 930-945, </pages> <year> 1993. </year>
Reference-contexts: In general, increasing the number of adjustable weights (denoted by q) reduces the network reconstruction error. Universal approximation results for various adaptive network architectures indicate that if q is sufficiently large then ffi can be made arbitrarily small uniformly on a compact region <ref> [8, 9] </ref>. The optimal weight vector is an "artificial" quantity required only for analytical purposes.
Reference: [10] <author> I. Daubechies, </author> <title> Ten Lectures on Wavelets, </title> <publisher> SIAM, </publisher> <year> 1992. </year>
Reference-contexts: Wavelets have been studied as a mathematical tool <ref> [10] </ref>, been investigated for their information theoretic value [11], been applied to signal processing [12], and control and estimation [13, 14]. A wavelet is a function which can be shifted along the independent axis (translation) and re-scaled so that it appears squashed or expanded along the independent axis (dilation).
Reference: [11] <author> S. Mallat and W. L. Hwang, </author> <title> "Singularity detection and processing with wavelets," </title> <journal> IEEE Trans. on Inform. Theory, </journal> <pages> pp. 617-643, </pages> <year> 1992. </year>
Reference-contexts: Wavelets have been studied as a mathematical tool [10], been investigated for their information theoretic value <ref> [11] </ref>, been applied to signal processing [12], and control and estimation [13, 14]. A wavelet is a function which can be shifted along the independent axis (translation) and re-scaled so that it appears squashed or expanded along the independent axis (dilation).
Reference: [12] <author> S. Mallat, </author> <title> Wavelet Signal Processing,, </title> <publisher> Acedemic Press, </publisher> <year> 1995. </year>
Reference-contexts: Wavelets have been studied as a mathematical tool [10], been investigated for their information theoretic value [11], been applied to signal processing <ref> [12] </ref>, and control and estimation [13, 14]. A wavelet is a function which can be shifted along the independent axis (translation) and re-scaled so that it appears squashed or expanded along the independent axis (dilation).
Reference: [13] <author> Q. Zhang and A. Beneveniste, </author> <title> "Wavelet networks," </title> <journal> IEEE Trans on Neural Networks, </journal> <volume> vol. 3, no. 6, </volume> <pages> pp. 889-898, </pages> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: Wavelets have been studied as a mathematical tool [10], been investigated for their information theoretic value [11], been applied to signal processing [12], and control and estimation <ref> [13, 14] </ref>. A wavelet is a function which can be shifted along the independent axis (translation) and re-scaled so that it appears squashed or expanded along the independent axis (dilation).
Reference: [14] <author> M.R. Cannon and J.-J.E. Slotine, </author> <title> "Space-frequency localized basis function networks for nonlinear system estimation and control," </title> <journal> Neurocomputing, </journal> <volume> vol. 9, no. 3, </volume> <year> 1995. </year>
Reference-contexts: Wavelets have been studied as a mathematical tool [10], been investigated for their information theoretic value [11], been applied to signal processing [12], and control and estimation <ref> [13, 14] </ref>. A wavelet is a function which can be shifted along the independent axis (translation) and re-scaled so that it appears squashed or expanded along the independent axis (dilation). <p> Elements on the same tier have the same width of support. Elements on high-level tiers having large support and large frequency resolvability and lower-level tiers having smaller support and greater space domain resolvability. In <ref> [14] </ref>, the authors utilize results from multi-resolution approximation theory to develop an algorithm which adjusts on-line not only the weights of the network but also the structure of the network. 4 Adaptive Wavelet Control Design In this section we consider the design of an adaptive wavelet controller based on the problem
Reference: [15] <author> J.D. Depree and C.W. Swartz, </author> <title> Introduction to Real Analysis, </title> <publisher> Wiley, </publisher> <year> 1988. </year>
Reference-contexts: Using the mean-value theorem and Taylor's theorem it can be shown that j (x; ^ )j r (x; ^ )j ~ j, where lim ^ ! r (x; ^ ) = 0 for all x <ref> [15] </ref>. The higher-order term encapsulates the nonlinear parametriza tion structure of the network. For example, in the special case of a linearly parametrized networks (such as the case of fixed dilation and translation coefficients), ^ (x; ^ ) = (x) T ^ and therefore is identically equal to zero.
Reference: [16] <author> P.A. Ioannou and J. Sun, </author> <title> Stable and Robust Adaptive Control, </title> <publisher> Prentice-Hall, </publisher> <year> 1995. </year>
Reference-contexts: If " 6= 0, then in order to guarantee uniform bound-edness of the parameter estimates ^ (t) and ^ 0 (t), the adaptive laws (12), (13) have to be modified because of parameter drift. In the robust adaptive control literature <ref> [16] </ref> there are various modifications to "ideal" adaptive laws for preventing parameter drift. A straightforward approach is the projection algorithm, where the parameter estimates are restricted to a preselected region via a projection modification, which activates in the case the estimates reach the boundary of the region. <p> In general, the projection algorithm requires known upper bounds on the unknown parameters to be estimated. Another approach for addressing the parameter drift problem is the -modification <ref> [16] </ref>, which employs a "leakage term" (of the form ^ ) in the adaptive law.
Reference: [17] <author> J.A. Farrell, </author> <title> "Approximators characteristics and their effect on training misbehavior in passive learning control," </title> <booktitle> IEEE Symposium on Intelligent Control, </booktitle> <pages> pp. 181-187, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: As discussed and illustrated (via a simple example) by Farrell <ref> [17] </ref>, the instantaneous approximation error is only an indicator of the function approxi p. 4 mator's fidelity at the current place in state space, and reducing this instantaneous error may not result in a useful system. <p> Sometimes, the designer may be free to drive the process into regions where data is desired or needed, or to selectively chose data for training and thus implicitly choose the probability density function; this is referred to as active learning <ref> [19, 17] </ref>. In many applications (especially in control applications), however, the system is not free to explore the domain of interest. Cases where the probability density function of the data is defined by an external mechanism, are referred to as passive learning.
Reference: [18] <author> S.E. Weaver, L. Baird and M.M. Polycarpou, </author> <title> "An analytical framework for local feedforward networks," </title> <booktitle> Proc. 1996 IEEE Inter. Symp. on Intelligent Control, </booktitle> <pages> pp. 450-455, </pages> <note> September 1996 (also submitted to IEEE Trans. on Neural Networks). </note>
Reference-contexts: Using local networks, however, also has some disadvantages, such as requiring more memory. To investigate more rigorously the issues of localization and interference, a more formal measure of these quantities is required. Such a theoretical framework has been initiated in <ref> [18] </ref> for case of static supervised learning systems with discrete-time weight update rules. In this section we extend these descriptions of interference and localization to continuous adaptive laws in a dynamic system framework.
Reference: [19] <author> J. A. Farrell and T. Berger, </author> <title> "On the effects of the training sample density in passive learning control," </title> <booktitle> American Control Conference, </booktitle> <pages> pp. 872-876, </pages> <month> June </month> <year> 1995. </year> <note> p. 6 </note>
Reference-contexts: Sometimes, the designer may be free to drive the process into regions where data is desired or needed, or to selectively chose data for training and thus implicitly choose the probability density function; this is referred to as active learning <ref> [19, 17] </ref>. In many applications (especially in control applications), however, the system is not free to explore the domain of interest. Cases where the probability density function of the data is defined by an external mechanism, are referred to as passive learning.
References-found: 19

