URL: ftp://ftp.cs.virginia.edu/pub/dissertations/9402.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/dissertations/README.html
Root-URL: http://www.cs.virginia.edu
Title: A Dissertation  The Design and Analysis of Scheduling Algorithms for Real-Time and Fault-Tolerant Computer Systems  
Author: Yingfeng Oh 
Degree: Presented to the Faculty of the  In Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy (Computer Science)  
Date: May 1994  
Note: by  
Affiliation: School of Engineering and Applied Science University of Virginia  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> N.C. Audsley, </author> <title> Deadline Monotonic Scheduling, </title> <type> Ph.D. Thesis, </type> <institution> Dept. Computer Science, University of York, </institution> <year> 1990. </year>
Reference-contexts: Then 2.2833 2.33. Proof: Similar to what we have done in Section 3.3 for the RM-FF algorithm, we use the same weighting function to map the utilization of a task into the real interval <ref> [0, 1] </ref>. Note that all the relevant lemmas in Section 3.3 hold for those processors of Type (II) in the RM-BF schedule. Let S = - be a set of m tasks, with their utilizations respectively, and v = . <p> u n 1+ 1 2 1 2 2 1 2 1 u n 1+ 2 1 2 3 2 + 2 2 1 FT RM FF 134 In order to prove the above bound, we define a weighting function that maps the uti lization of tasks into the real interval <ref> [0, 1] </ref> as follows: , where a = . Lemma 4.3: If a processor is assigned a number of tasks with uti lizations , then , where a = . This lemma is true according to Lemma 3.1 Lemma 4.4: In the completed FT-RM-FF schedule. <p> Since a bin can be filled to a level from zero to one, we instead divide the bins into groups according to the regions their levels fall into. A total number of seven regions is defined: (0, 1/2], (1/2, 2/3], (2/3, 2/3 + 1/18), <ref> [2/3 + 1/18, 3/4), [3/4, 4/5), [4/5, 5/6), and [5/6, 1] </ref>. For each region, the result is stated in a lemma. The proof of the theorem is given at the end. Lemma 5.3: Let a bin be filled with items b 1 b 2 b m . <p> Since a bin can be filled to a level from zero to one, we instead divide the bins into groups according to the regions their levels fall into. A total number of seven regions is defined: (0, 1/2], (1/2, 2/3], (2/3, 2/3 + 1/18), [2/3 + 1/18, 3/4), <ref> [3/4, 4/5), [4/5, 5/6), and [5/6, 1] </ref>. For each region, the result is stated in a lemma. The proof of the theorem is given at the end. Lemma 5.3: Let a bin be filled with items b 1 b 2 b m . <p> A total number of seven regions is defined: (0, 1/2], (1/2, 2/3], (2/3, 2/3 + 1/18), [2/3 + 1/18, 3/4), [3/4, 4/5), <ref> [4/5, 5/6), and [5/6, 1] </ref>. For each region, the result is stated in a lemma. The proof of the theorem is given at the end. Lemma 5.3: Let a bin be filled with items b 1 b 2 b m . <p> A total number of seven regions is defined: (0, 1/2], (1/2, 2/3], (2/3, 2/3 + 1/18), [2/3 + 1/18, 3/4), [3/4, 4/5), [4/5, 5/6), and <ref> [5/6, 1] </ref>. For each region, the result is stated in a lemma. The proof of the theorem is given at the end. Lemma 5.3: Let a bin be filled with items b 1 b 2 b m . <p> Proof: For any task T j S - S i with j <ref> [1, 2, , m - 1] </ref>, it starts on time zero in both schedules LPT (S, m) and LPT (S - S i , m - 1).
Reference: [2] <author> A. Avizienis, </author> <title> The N-version Approach to Fault-Tolerant Software, </title> <journal> IEEE Transactions on Software Engineering 11, </journal> <year> 1985, </year> <pages> 1491-1501. </pages>
Reference-contexts: To tolerate hardware failures or software errors, hardware and software redundancy techniques can be used. Examples of redundancy techniques are N-Modular-Redundancy (NMR) [29], Data-Diversity [35], Recovery Block [66], and N-version Programming (N-VP) <ref> [2] </ref>. At the level of task scheduling, hardware and software are abstracted as processors and tasks. In general, to tolerate processor failures, redundant processors are used to execute the same software and the final results are obtained through voting on the multiple results. <p> Furthermore, they have shown that a set of periodic tasks may not be schedulable non-preemptively on a single processor, even if its total Table 1.1: Worst Case Performance of Existing Scheduling Algorithms Algorithm A Complexity Type RMNF [20] [2.4, 2.67] Off-line RMFF [20] <ref> [2, 2.23?] </ref> Off-line NF-M [16] S M fi 2.2837 On-line FFDUF [17] 2.0 Off-line FFDUF O n nlog ( ) O n ( ) O n nlog ( ) 17 utilization is very small, i.e., close to zero. <p> Recall that the worst case utilization bound of can be achieved by the following set of n tasks: C i = ( ), T i = , for i = 0, 1, , n - 1. These n tasks totally utilize the processor in the time period of <ref> [0, 2] </ref>. The total utilization of the n tasks is therefore given by U = n ( ). Next, we want to decide the number of tasks needed to have a total utilization of close to but no greater than 1/2 for each of the n tasks above. <p> The copies or versions of a task are executed on different processors in order to tolerate processor failures. Multiple versions of a task are executed so that possible task errors can be tolerated if they are not the same <ref> [2] </ref>. <p> Assumptions (A) and (B) make a rather general statement about the redundancy schemes used by each task. The term version has been used in N-version programming <ref> [2] </ref> to denote multiple implementations of a task. However, for the sake of convenience, it 126 is used here to denote both true versions of a task and mere copies of a single task version. <p> Proof: For any task T j S - S i with j <ref> [1, 2, , m - 1] </ref>, it starts on time zero in both schedules LPT (S, m) and LPT (S - S i , m - 1).
Reference: [3] <author> B.S. Baker, </author> <title> A New Proof for the First Fit Decreasing Bin Packing Algorithm, </title> <editor> J. </editor> <booktitle> Algorithms 6, </booktitle> <year> 1985, </year> <pages> 49-70. </pages>
Reference-contexts: This difference makes the analysis of the worst case performance of the scheduling heuristics considerably more complicated than that of bin-packing heuristics. Note that the analysis of bin-packing heuristics is quite complex even when the sizes of bins are unitary <ref> [3, 14, 15, 30, 31, 32, 33, 38, 44, 83] </ref>.
Reference: [4] <author> S. Balaji et al, </author> <title> Workload Redistribution for Fault-Tolerance in a Hard Real-Time Distributed Computing System, </title> <address> FTCS-19, Chicago, Illinois, </address> <month> June </month> <year> 1989, </year> <pages> 366-373. </pages>
Reference-contexts: The optimal result can be generalized to include conditions in which tasks are related by = k , where k is an integer. Though there have been several works in the literature <ref> [4, 5, 36, 45] </ref> which deal with allocation algorithms for fault-tolerant systems, they are developed under vastly different assumptions and are only remotely related to our work. Here we mention several. <p> Though there have been several works in the literature [4, 5, 36, 45] which deal with allocation algorithms for fault-tolerant systems, they are developed under vastly different assumptions and are only remotely related to our work. Here we mention several. In order to tolerate processor failures, Balaji et al <ref> [4] </ref> presented an algorithm to dynamically distribute the workload of a failed processor to other operating processors. The tolerance of some processor failures is achieved under the condition that the task set is fixed, and enough processing power is available to execute it.
Reference: [5] <author> J.A. Bannister and K. S. Trivedi, </author> <title> Task Allocation in Fault-Tolerant Distributed Systems, </title> <publisher> Acta Informatica 20, Springer-Verlag, </publisher> <year> 1983, </year> <pages> 261-281. </pages>
Reference-contexts: The optimal result can be generalized to include conditions in which tasks are related by = k , where k is an integer. Though there have been several works in the literature <ref> [4, 5, 36, 45] </ref> which deal with allocation algorithms for fault-tolerant systems, they are developed under vastly different assumptions and are only remotely related to our work. Here we mention several. <p> Unfortunately, their algorithm has the severe drawback that it is premised on the solution to two NP-complete problems. Perhaps the most closely related work to ours is that of Bannister and Trivedi <ref> [5] </ref>. They considered the allocation of a set of periodic tasks to a number of processors so that a certain number of processor failures can be sustained. All the tasks have the same number of clones, and for each task, all its clones have the same computation time requirement. <p> Hence, . n From the derivation of the bounds we can see that the performance of RMGT-M is sensitive to the choice of M, the number of classes in a task set. In practice, it is sufficient for M to assume a value in the range of <ref> [5, 100] </ref>. The worst case bounds improve for large values of M. However, M also determines the number of current processors, which may not be fully utilized. Next we consider the problem of optimally selecting the value of M such that the worst case bounds are lowest. <p> The Design and Analysis of FT-Rate-Monotonic-First-Fit Since the result of by Bannister and Trivedi <ref> [5] </ref> is very attractive in view of workload distribution among the processors, it is quite tempting to expect that based on their algorithm, a good heuristic could be developed to solve the FT-RMMS problem. Even though no schedulability test is introduced in their algorithm, it can be added.
Reference: [6] <author> A. Burchard, J. Liebeherr, Y. Oh, and S.H. Son, </author> <title> Assigning Real-Time Tasks to Homogeneous Multiprocessor Systems, </title> <note> submitted to IEEE Transactions on Computers, </note> <month> January </month> <year> 1994. </year>
Reference: [7] <author> A. Burchard, Y. Oh, J. Liebeherr, and S. H. Son, </author> <title> A Linear Time On-line Task Assignment Scheme for Multiprocessor Systems, </title> <booktitle> IEEE 11th Workshop on Real-Time Operating Systems and Software, </booktitle> <address> Seattle, Washington, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: It took about 15 years until 1988 when RM scheduling was used as a scheduling algorithm for a real-time operating system. Now the RM algorithm has been used in a number of applications <ref> [7] </ref>. The first result on RM scheduling heuristic for multiprocessor was derived in 1978 and was presented in Dhall and Lius 1978 paper. Interests in task scheduling on multiprocessors have rapidly increased only recently, because of the inevitable employment of multiprocessors in many real-time systems.
Reference: [8] <author> R.W. Butler, </author> <title> An Assessment of the Real-Time Application Capabilities of the SIFT Computer System, </title> <type> NASA Technical Memorandum 84432, </type> <month> April </month> <year> 1982. </year>
Reference-contexts: This basic model may not be of much practical relevance if it cannot be extended to accommodate other requirements. Recently this model has been adapted and extended in many aspects by researchers in solving practical problems <ref> [8, 69, 72] </ref>.
Reference: [9] <author> S. Cheng, J.A. Stankovic, and K. Ramamritham, </author> <title> Scheduling Algorithms for Hard Real-Time Systems: A Brief Survey, Tutorial: Hard Real-Time Systems, </title> <publisher> EFF Press, </publisher> <year> 1988, </year> <pages> 150-173. </pages>
Reference-contexts: Besides, we should be aware of how our problems relate to other problems that have been studied. To achieve these two goals, we offer a top-down description of the problems and their relationship to other scheduling problems. A complete description of the general scheduling problem under various constraints <ref> [9, 12, 26] </ref>, though desirable, is beyond the scope of this thesis. Generally, a scheduling problem is defined by four parameters: (1) the machine environment, (2) the task characteristics, (3) the scheduling environment, and (4) the scheduling objectives. The machine environment specifies the types of the processors and their quantity.
Reference: [10] <author> H. Chetto and M. Chetto, </author> <title> Some Results of the Earliest Deadline Scheduling Algorithm, </title> <journal> IEEE Transactions on Software Engineering 15(10), </journal> <year> 1989, </year> <pages> 466-473. </pages>
Reference: [11] <author> R.W. Conway, W.L. Maxwell, and L.W. Miller, </author> <title> Theory of Scheduling, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1967. </year>
Reference-contexts: Overview Scheduling problems occur in a variety of situations in which a set of resources is to be used to perform a set of tasks. The general problem of scheduling <ref> [11, 12] </ref> is to allocate resources for the performance of a set of tasks such that specified objectives are achieved.
Reference: [12] <author> E.G. Coffman, Jr. (ed.), </author> <title> Computer and Job Shop Scheduling Theory, </title> <address> New York: </address> <publisher> 192 Wiley, </publisher> <year> 1975. </year>
Reference-contexts: Overview Scheduling problems occur in a variety of situations in which a set of resources is to be used to perform a set of tasks. The general problem of scheduling <ref> [11, 12] </ref> is to allocate resources for the performance of a set of tasks such that specified objectives are achieved. <p> Besides, we should be aware of how our problems relate to other problems that have been studied. To achieve these two goals, we offer a top-down description of the problems and their relationship to other scheduling problems. A complete description of the general scheduling problem under various constraints <ref> [9, 12, 26] </ref>, though desirable, is beyond the scope of this thesis. Generally, a scheduling problem is defined by four parameters: (1) the machine environment, (2) the task characteristics, (3) the scheduling environment, and (4) the scheduling objectives. The machine environment specifies the types of the processors and their quantity.
Reference: [13] <author> E.G. Coffman, Jr. and R. Sethi, </author> <title> A Generalized Bound on LPT Sequencing, </title> <journal> Revue Francaise dAutomatique Informatique Recherche Operationelle 10 (5), 1976, </journal> <volume> Suppl., </volume> <pages> 17-25. </pages>
Reference-contexts: However, that bound is only achievable by a pathological example, where, with the exception of one processor, the number of tasks scheduled on each processor is only two. Coffman and Sethi <ref> [13] </ref> later generalized Grahams bound to be (k + 1)/k - 1/(km), where m is the number of processors, and k is the least number of tasks on any processor, or k is the number of tasks on a processor whose last task terminates the schedule. <p> Since OV first schedules the primary copies using 181 LPT and then the backup copies using ALPT, the worst case performance bound is therefore expected to be around 1 + 1/k for k &gt; m according to the result by Coffman and Sethi <ref> [13] </ref>. This is due to the observation that for k &gt; m, all the backup copies of the tasks are scheduled immediately after the primary schedule on each processor. In the following, we show that our heuristic A has an upper bound which is similar to that for LPT.
Reference: [14] <author> E.G. Coffman, Jr., M.R. Garey, and D.S. Johnson, </author> <title> An Application of Bin-Packing to Multiprocessor Scheduling, </title> <journal> SIAM J. Computing 7, </journal> <year> 1978, </year> <pages> 1-17. </pages>
Reference-contexts: This difference makes the analysis of the worst case performance of the scheduling heuristics considerably more complicated than that of bin-packing heuristics. Note that the analysis of bin-packing heuristics is quite complex even when the sizes of bins are unitary <ref> [3, 14, 15, 30, 31, 32, 33, 38, 44, 83] </ref>. <p> Since the scheduling to minimize the makespan of a schedule is NP-complete, several scheduling heuristics have been developed, among which LPT [25] and MULTIFIT <ref> [14] </ref> are notable ones. <p> The conclusion is based on the result by Coffman, Garey, and Johnson <ref> [14] </ref>. Let L and denote the schedule lengths obtained by NOV_1 and the optimal algorithm, respectively. Let N and denote the schedule lengths obtained by LPT and the optimal algorithm, respectively. = . The relationship among these parameters is given in Figure 6.9.
Reference: [15] <author> E.G. Coffman, Jr., M.R. Garey, and D.S. Johnson, </author> <title> Approximate Algorithms for Bin Packing - An Updated Survey, In Algorithm Design for Computer System Design, 49-106, </title> <editor> G. Ausiello, M. Lucertinit, and P. Serafini (eds), </editor> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Since d becomes insignificant when is large, we let = c, and use to denote the worst case performance bound for convenience. In the literature, the measurement = is used frequently to evaluate the performance of heuristics <ref> [15, 23] </ref>. It is used because there are situations where the maximum value of is achieved under some pathological cases, mostly when the size of the input data is small. <p> This difference makes the analysis of the worst case performance of the scheduling heuristics considerably more complicated than that of bin-packing heuristics. Note that the analysis of bin-packing heuristics is quite complex even when the sizes of bins are unitary <ref> [3, 14, 15, 30, 31, 32, 33, 38, 44, 83] </ref>. <p> In order to overcome these likely disadvantages, a new algorithm is designed as follows, which is based on the Best-Fit bin-packing algorithm. It is a well-known fact that the Best-Fit heuristic has the same worst case performance bound as the First-Fit in bin-packing <ref> [15] </ref>. Yet we cannot automatically conclude from the bin-packing results that RM-FF and RM-BF will have the same worst case performance bound, since the RMMS problem differs from the bin-packing problem (i.e., the classical one-dimensional bin-packing). <p> C ij j 1= T i i 1= n max 1 i n - k i - 2 2 1 2 2 1 2 2 1 2 2 1 129 Bin-packing algorithms <ref> [15] </ref> are a class of well-studied heuristic algorithms, which perform well for the assignment of variable-size items into fixed-size bins. However, bin-packing heuristics cannot be directly applied to solving the FT-RMMS problem, since there are two major differences involved.
Reference: [16] <author> S. Davari and S.K. Dhall, </author> <title> An On Line Algorithm for Real-Time Tasks Allocation, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1986, </year> <pages> 194-200. </pages>
Reference-contexts: Given the intractability, any practical solution to the problem of scheduling periodic tasks on multiprocessor systems presents a trade-off between computational complexity and performance. Several 6 efforts have been devoted to the development of heuristic algorithms for the scheduling problem <ref> [16, 17, 19, 20] </ref>. However, due to the difficulty involved in showing the effectiveness of the algorithms, few results have been obtained. In short, the progress in establishing a firm theoretical foundation for rate-monotonic scheduling on a multiprocessor has been slow. <p> Since the problem of scheduling a set of periodic tasks on a multiprocessor system, using either fixed priority assignment or dynamic priority assignment, is NP-complete, heuristic algorithms have been sought to solve it. The approach taken by a number of researchers <ref> [16, 17, 19, 20, 60] </ref> is to partition a given set of tasks into different groups, such that the tasks in each group can be feasibly scheduled on a single processor by a given algo n 2 1 15 rithm. <p> Furthermore, their RMFF and RMNF are off-line, since they require that tasks must be assigned in the order of increasing period. Davari and Dhall later considered two other algorithms called First-Fit-Decreasing-Utilization-Factor (FFDUF) and NEXT-FIT-M (NF-M) <ref> [16, 17] </ref>. The FFDUF algorithm sorts the set of tasks in non-increasing order of task utilization and assigns tasks to processors in that order. The NEXT-FIT-M algorithm classified tasks into M classes with respect to their utilizations. <p> Furthermore, they have shown that a set of periodic tasks may not be schedulable non-preemptively on a single processor, even if its total Table 1.1: Worst Case Performance of Existing Scheduling Algorithms Algorithm A Complexity Type RMNF [20] [2.4, 2.67] Off-line RMFF [20] [2, 2.23?] Off-line NF-M <ref> [16] </ref> S M fi 2.2837 On-line FFDUF [17] 2.0 Off-line FFDUF O n nlog ( ) O n ( ) O n nlog ( ) 17 utilization is very small, i.e., close to zero. <p> The performance metric in all experiments is the number of processors required to execute a given task set. We first compare the performance of the max i C i T i ( ) 111 following on-line algorithms: RMNF [20] NF-M <ref> [16] </ref> RMGT-M (Section 3.6) RM-FF (Section 3.3) RM-FFF-IFF (Section 3.8) Since an optimal schedule cannot be calculated for large task sets, we use the total utilization (or load) U = of a task set as the lower bound for the number of processors required.
Reference: [17] <author> S. Davari and S.K. Dhall, </author> <title> On a Periodic Real-Time Task Allocation Problem, </title> <booktitle> Proc. of 19th Annual International Conference on System Sciences, </booktitle> <year> 1986, </year> <pages> 133-141. </pages>
Reference-contexts: Given the intractability, any practical solution to the problem of scheduling periodic tasks on multiprocessor systems presents a trade-off between computational complexity and performance. Several 6 efforts have been devoted to the development of heuristic algorithms for the scheduling problem <ref> [16, 17, 19, 20] </ref>. However, due to the difficulty involved in showing the effectiveness of the algorithms, few results have been obtained. In short, the progress in establishing a firm theoretical foundation for rate-monotonic scheduling on a multiprocessor has been slow. <p> Since the problem of scheduling a set of periodic tasks on a multiprocessor system, using either fixed priority assignment or dynamic priority assignment, is NP-complete, heuristic algorithms have been sought to solve it. The approach taken by a number of researchers <ref> [16, 17, 19, 20, 60] </ref> is to partition a given set of tasks into different groups, such that the tasks in each group can be feasibly scheduled on a single processor by a given algo n 2 1 15 rithm. <p> Furthermore, their RMFF and RMNF are off-line, since they require that tasks must be assigned in the order of increasing period. Davari and Dhall later considered two other algorithms called First-Fit-Decreasing-Utilization-Factor (FFDUF) and NEXT-FIT-M (NF-M) <ref> [16, 17] </ref>. The FFDUF algorithm sorts the set of tasks in non-increasing order of task utilization and assigns tasks to processors in that order. The NEXT-FIT-M algorithm classified tasks into M classes with respect to their utilizations. <p> that a set of periodic tasks may not be schedulable non-preemptively on a single processor, even if its total Table 1.1: Worst Case Performance of Existing Scheduling Algorithms Algorithm A Complexity Type RMNF [20] [2.4, 2.67] Off-line RMFF [20] [2, 2.23?] Off-line NF-M [16] S M fi 2.2837 On-line FFDUF <ref> [17] </ref> 2.0 Off-line FFDUF O n nlog ( ) O n ( ) O n nlog ( ) 17 utilization is very small, i.e., close to zero. <p> We compare the performance of the following algorithms: RMFF [20] 2 1 115 FFDUF <ref> [17] </ref> RMST (Section 3.6) 116 RMGT (Section 3.6) RM-FFDU (Section 3.7) RM-FFDU-IFF (Section 3.8) The same task sets as used in the previous experiments are run through these offline algorithms.
Reference: [18] <author> R.I. Davis, K.W. Tindell, and A. Burns, </author> <title> Scheduling Slack Time in Fixed Priority Preemptive Systems, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <pages> 1993222-231. </pages>
Reference-contexts: Assumption (1) requires that each request of a task must arrive in the system at fixed interval. This precludes some tasks that need aperiodic processing. Recently, several techniques have been developed to schedule aperiodic tasks together with periodic tasks in a single processor system <ref> [18, 65, 79] </ref>. The essence of these techniques is either to reserve processor utilization for aperiodic tasks by approximating aperiodic task execution with periodic task execution, or to utilize unused time of periodic tasks for aperiodic task processing.
Reference: [19] <author> S.K. Dhall, </author> <title> Scheduling Periodic-Time-Critical Jobs on Single Processor and Multiprocessor Computing Systems, </title> <type> Ph.D. Thesis, </type> <institution> University of Illinois, Urbana, </institution> <year> 1977. </year>
Reference-contexts: Given the intractability, any practical solution to the problem of scheduling periodic tasks on multiprocessor systems presents a trade-off between computational complexity and performance. Several 6 efforts have been devoted to the development of heuristic algorithms for the scheduling problem <ref> [16, 17, 19, 20] </ref>. However, due to the difficulty involved in showing the effectiveness of the algorithms, few results have been obtained. In short, the progress in establishing a firm theoretical foundation for rate-monotonic scheduling on a multiprocessor has been slow. <p> Since the problem of scheduling a set of periodic tasks on a multiprocessor system, using either fixed priority assignment or dynamic priority assignment, is NP-complete, heuristic algorithms have been sought to solve it. The approach taken by a number of researchers <ref> [16, 17, 19, 20, 60] </ref> is to partition a given set of tasks into different groups, such that the tasks in each group can be feasibly scheduled on a single processor by a given algo n 2 1 15 rithm. <p> Some of the task sets that cannot be scheduled by using the WC condition can be scheduled by using this condition, since this condition takes advantage of the fact that tasks are ordered against non-decreasing periods. Dhall <ref> [19] </ref> also proved the following results: Theorem 2.2: Let be a set of n tasks with and . <p> This question is answered in the following two theorems. The first theorem, first outlined and partially proven by Dhall in his thesis <ref> [19] </ref>, is the key to the proof of the second theorem. The proof of these two theorems relies heavily on Theorem 3.1.
Reference: [20] <author> S.K. Dhall and C.L. Liu, </author> <title> On a Real-Time Scheduling Problem, </title> <note> Operations Research 26, </note> <year> 1978, </year> <pages> 127-140. </pages>
Reference-contexts: Given the intractability, any practical solution to the problem of scheduling periodic tasks on multiprocessor systems presents a trade-off between computational complexity and performance. Several 6 efforts have been devoted to the development of heuristic algorithms for the scheduling problem <ref> [16, 17, 19, 20] </ref>. However, due to the difficulty involved in showing the effectiveness of the algorithms, few results have been obtained. In short, the progress in establishing a firm theoretical foundation for rate-monotonic scheduling on a multiprocessor has been slow. <p> The utilization of a task is defined as the ratio between its computation time and its period, and the total utilization of a set of tasks is the sum of the utilizations of all tasks in the set. Three other schedulability conditions were later developed by Dhall and Liu <ref> [20] </ref> in developing heuristic scheduling algorithms for multiprocessor systems. All these conditions are sufficient conditions. Lehoczky, Sha, and Ding recently discovered a schedulabil-ity condition that is both necessary and sufficient [40]. <p> Since the problem of scheduling a set of periodic tasks on a multiprocessor system, using either fixed priority assignment or dynamic priority assignment, is NP-complete, heuristic algorithms have been sought to solve it. The approach taken by a number of researchers <ref> [16, 17, 19, 20, 60] </ref> is to partition a given set of tasks into different groups, such that the tasks in each group can be feasibly scheduled on a single processor by a given algo n 2 1 15 rithm. <p> The measure denotes the computation time complexity for scheduling a set of n tasks. Dhall and Liu were the first to propose two heuristic algorithms for the scheduling problem <ref> [20] </ref>. The algorithms, Rate-Monotonic-Next-Fit (RMNF) and Rate-Monotonic-First-Fit (RMFF), were shown to have worst case performance bounds of 2.4 2.67, and 2 (4 (2 )/(1 + 2 ) 2.23. <p> Furthermore, they have shown that a set of periodic tasks may not be schedulable non-preemptively on a single processor, even if its total Table 1.1: Worst Case Performance of Existing Scheduling Algorithms Algorithm A Complexity Type RMNF <ref> [20] </ref> [2.4, 2.67] Off-line RMFF [20] [2, 2.23?] Off-line NF-M [16] S M fi 2.2837 On-line FFDUF [17] 2.0 Off-line FFDUF O n nlog ( ) O n ( ) O n nlog ( ) 17 utilization is very small, i.e., close to zero. <p> Furthermore, they have shown that a set of periodic tasks may not be schedulable non-preemptively on a single processor, even if its total Table 1.1: Worst Case Performance of Existing Scheduling Algorithms Algorithm A Complexity Type RMNF <ref> [20] </ref> [2.4, 2.67] Off-line RMFF [20] [2, 2.23?] Off-line NF-M [16] S M fi 2.2837 On-line FFDUF [17] 2.0 Off-line FFDUF O n nlog ( ) O n ( ) O n nlog ( ) 17 utilization is very small, i.e., close to zero. <p> Another schedulability condition, which is called IP (Increasing Period), was given by Dhall and Liu <ref> [20] </ref> in studying the performance of their multiprocessor scheduling heu ristics, RMNF and RMFF. Condition IP: Let be a set of n tasks with and u = . If u and C n / T n , then the task set can be feasibly scheduled by the RM algorithm. <p> This theorem also serves as a counter example for the claim that Dhall and Lius RMFF is upper bounded by 2.23 in <ref> [20] </ref>. Since the tasks in each group has the same utilization and to show the incorrectness of the upper bound for RMFF in [20], we use the condition, C n / T n 2 - 1, instead of the condition C n / T n 2/ , without affecting the final <p> This theorem also serves as a counter example for the claim that Dhall and Lius RMFF is upper bounded by 2.23 in <ref> [20] </ref>. Since the tasks in each group has the same utilization and to show the incorrectness of the upper bound for RMFF in [20], we use the condition, C n / T n 2 - 1, instead of the condition C n / T n 2/ , without affecting the final result. <p> The performance metric in all experiments is the number of processors required to execute a given task set. We first compare the performance of the max i C i T i ( ) 111 following on-line algorithms: RMNF <ref> [20] </ref> NF-M [16] RMGT-M (Section 3.6) RM-FF (Section 3.3) RM-FFF-IFF (Section 3.8) Since an optimal schedule cannot be calculated for large task sets, we use the total utilization (or load) U = of a task set as the lower bound for the number of processors required. <p> Performance Comparison of New and Existing Off-line Algorithms Just as we have done for the on-line algorithms in the previous sub-section, we simulate the performance of the new and existing off-line algorithms following the same strat egy. We compare the performance of the following algorithms: RMFF <ref> [20] </ref> 2 1 115 FFDUF [17] RMST (Section 3.6) 116 RMGT (Section 3.6) RM-FFDU (Section 3.7) RM-FFDU-IFF (Section 3.8) The same task sets as used in the previous experiments are run through these offline algorithms. <p> Another question remains where for some task systems, the mapping of tasks to processors is not arbitrary because of access to peripheral devices. 189 Appendix A In this appendix, we show that some errors exist in the proof for the upper bound of RMFF by Dhall and Liu in <ref> [20] </ref>. Their RMFF is almost the same as our RM-FF except that in their RMFF, the IP condition is used with the tasks being sorted in the order of increasing period.
Reference: [21] <author> B.L. Di Vito and R.W. Butler, </author> <title> Provable Transient Recovery for Frame-Based, Fault-Tolerant Computing Systems, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1992, </year> <pages> 275-279. </pages>
Reference-contexts: The bound is also shown to be nearly tight. The average case behavior of the heuristic is studied through simulation. Experimental data show that the heuristic performs surprisingly well on the average. There are two general approaches to achieve fault-tolerance under RM Scheduling (RMS). The first approach <ref> [21] </ref> considers processor failures only; a set of periodic tasks is assigned to a processor such that their deadlines are met with the assumption that the processor is fault-tolerant.
Reference: [22] <author> J.D. Gafford, </author> <title> Rate-Monotonic Scheduling, </title> <booktitle> IEEE Micro, </booktitle> <month> June </month> <year> 1991, </year> <pages> 34-39. </pages>
Reference-contexts: Recently, the RM algorithm has been used in a number of applications. For example, it has been specified for use with software on board the Space Station as the means for scheduling multiple independent task execution <ref> [22] </ref>. The RM algorithm will be built into the on-board operating system, and is directly supported by the Ada compiler in use.
Reference: [23] <author> M.R. Garey and D.S. Johnson, </author> <title> Computers and Intractability: A Guide to the The 193 ory of NP-completeness, W.H. </title> <publisher> Freeman and Company, </publisher> <address> NY, </address> <year> 1978. </year>
Reference-contexts: Our goal is to find algorithms that can provide better performance, i.e., lower worst case performance bounds. In the following, we give a formal definition of the worst case performance bound (ratio). For more details on formal description of such performance criteria, please refer to <ref> [23] </ref>. Let P be a scheduling problem and I be any given set of tasks for problem P. We define = . <p> Since d becomes insignificant when is large, we let = c, and use to denote the worst case performance bound for convenience. In the literature, the measurement = is used frequently to evaluate the performance of heuristics <ref> [15, 23] </ref>. It is used because there are situations where the maximum value of is achieved under some pathological cases, mostly when the size of the input data is small. <p> Proof: It is sufficient to prove that this scheduling problem is NP-complete even in the case of m = 3. It is easy to verify that this problem is in NP. We next transform the PAR TITION problem, an NP-complete problem, to the scheduling problem. The PARTITION problem <ref> [23] </ref> is stated as follows: given a finite set A and a size m 3 t S + r Z D Z s 159 for each , is there a subset such that = ? Given an instance of A = of the PARTITION problem, we construct a task set S <p> Theorem 6.5: The Task Sequencing Problem is NP-complete. Proof: It is easy to verify that the scheduling problem belongs to NP. We now transform the PARTITION problem <ref> [23] </ref> to the scheduling problem when the number of proces sors is 3, i.e., m = 3. t i i 1= m 3 t S + r Z D Z l t ( ) s 172 Given an instance of A = of the PARTITION problem, we construct a task set
Reference: [24] <author> M.J. Gonzalez and J.W. Soh, </author> <title> Periodic Job Scheduling in a Distributed Processor System, </title> <journal> IEEE Transactions on Aerospace and Electronic Systems 12(5), </journal> <month> Septem-ber </month> <year> 1976, </year> <pages> 530-535. </pages>
Reference-contexts: When the release times of all tasks are the same and the task periods obey a binary distribution, Gonzales and Soh <ref> [24] </ref> showed that an optimal algorithm exists for it. Let denote the period of the ith task. Then by a binary distribution of task periods, they mean that if the tasks are ordered in terms of increasing period, then = 2 .
Reference: [25] <author> R. L. Graham, </author> <title> Bounds on Multiprocessing Timing Anomalies, </title> <journal> SIAM J. Appl. Math. </journal> <volume> 17, </volume> <year> 1969, </year> <pages> 416-429. </pages>
Reference-contexts: This scheduling problem, at a first glance, seems very much to resemble the scheduling problem of minimizing the makespan of a schedule in a multiprocessor system. Since the scheduling to minimize the makespan of a schedule is NP-complete, several scheduling heuristics have been developed, among which LPT <ref> [25] </ref> and MULTIFIT [14] are notable ones. <p> Thus it is concluded that the performance of the algorithm is near-optimal. The performance of NOV may seem surprisingly good at the first glance. However, it is not surprising at all if we take a closer look at the performance of the heuristic. Graham <ref> [25] </ref> proved that the worst case performance of LPT was tightly bounded by 4/3 - 1/3m, where m is the number of processors. <p> Since W L /L * &lt; 1, we have N/ &gt; 7/3 - 1/(3m) - W L /L * &gt; 4/3 - 1/(3m), which contradicts the result that N/ 4/3 - 1/(3m) by Graham <ref> [25] </ref>. Case 2: &gt; L * . Since = 2L * , we have L/ = L/(2L * ), i.e, L/L * &gt; 7/3 - 1/(3m). Since L = N + W L , L/L * = N/L * + W L /L * . <p> For example, if the given period D is twice as long as the optimal schedule length, then according to the results by Graham <ref> [25] </ref>, any algorithm, as long as it does not leave any processor idle when there are tasks ready for execution, can generate a feasible schedule.
Reference: [26] <editor> R.L. Graham et al. </editor> <title> Optimization and Approximation in Deterministic Sequencing and Scheduling: A Survey, </title> <journal> Annals of Discrete Mathematics 5, </journal> <year> 1979, </year> <pages> 287-326. </pages>
Reference-contexts: Besides, we should be aware of how our problems relate to other problems that have been studied. To achieve these two goals, we offer a top-down description of the problems and their relationship to other scheduling problems. A complete description of the general scheduling problem under various constraints <ref> [9, 12, 26] </ref>, though desirable, is beyond the scope of this thesis. Generally, a scheduling problem is defined by four parameters: (1) the machine environment, (2) the task characteristics, (3) the scheduling environment, and (4) the scheduling objectives. The machine environment specifies the types of the processors and their quantity.
Reference: [27] <author> A.L. Hopkins et al, </author> <title> FTMP-A Highly Reliable Fault-Tolerant Multiprocessor for Aircraft, </title> <booktitle> Proc. of the IEEE 66 (10), </booktitle> <month> October, </month> <year> 1978. </year>
Reference: [28] <author> K. Jeffay, D.F. Stanat, and C.U. Martel, </author> <title> On non-preemptive scheduling of periodic and sporadic tasks, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1991, </year> <pages> 129-139. </pages>
Reference-contexts: For non-preemptive scheduling, the problem of minimizing the number of processors is more difficult. Jeffay, Stanat, and Martel <ref> [28] </ref> have shown that the problem of determining whether a set of non-preemptive, periodic tasks with different release times is schedulable is NP-hard in the strong sense. <p> The scheduling problem is formulated in the similar manner as its preemptive counterpart. However, the problem of non-preemptively scheduling a set of periodic tasks on a multiprocessor is a much difficult one. Jeffay, Stanat and Martel <ref> [28] </ref> have shown that a set of periodic tasks may not be schedulable non-preemptively on a single processor, even if its total CPU utilization is very small, i.e., close to zero.
Reference: [29] <author> B.W. Johnson, </author> <title> Design and Analysis of Fault Tolerant Digital Systems, </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: In a hard real-time system, a late answer is a wrong answer. In a soft real-time system, a late answer may have some diminishing value. Dependability is the quality of service that a particular system provides, which encompasses such concepts as reliability, availability, safety, maintainability, and perform-ability <ref> [29] </ref>. One type of computer systems that support dependability is the fault-tolerant system. A fault-tolerant system can continue to correctly perform its specified tasks even in the presence of hardware failures and software errors [29]. The timeliness of a real-time system is ensured through scheduling algorithms. <p> that a particular system provides, which encompasses such concepts as reliability, availability, safety, maintainability, and perform-ability <ref> [29] </ref>. One type of computer systems that support dependability is the fault-tolerant system. A fault-tolerant system can continue to correctly perform its specified tasks even in the presence of hardware failures and software errors [29]. The timeliness of a real-time system is ensured through scheduling algorithms. <p> To tolerate hardware failures or software errors, hardware and software redundancy techniques can be used. Examples of redundancy techniques are N-Modular-Redundancy (NMR) <ref> [29] </ref>, Data-Diversity [35], Recovery Block [66], and N-version Programming (N-VP) [2]. At the level of task scheduling, hardware and software are abstracted as processors and tasks.
Reference: [30] <author> D.S. Johnson, </author> <title> Near-Optimal Bin Packing Algorithms, </title> <type> Ph.D. Thesis, </type> <institution> MIT, </institution> <year> 1973. </year>
Reference-contexts: This difference makes the analysis of the worst case performance of the scheduling heuristics considerably more complicated than that of bin-packing heuristics. Note that the analysis of bin-packing heuristics is quite complex even when the sizes of bins are unitary <ref> [3, 14, 15, 30, 31, 32, 33, 38, 44, 83] </ref>. <p> Lemma 5.2: Let a bin be filled with items b 1 , b 2 , , b m . Then 1.7. This lemma was proven by Johnson in <ref> [30] </ref>. <p> When k = 1, the problem becomes the well-known classical bin-packing problem. Since the ratio 1.7 is not affected by the value of k, our result therefore subsumes the previous known result <ref> [30] </ref>. Also, when k = 1, examples that achieve the bound of 1.7 has been given in [30]. Since the term 2.19k is a constant, it disappears when the optimal number of bins L * approaches infinity. Therefore, we conclude that the bound is asymptotically tight. 5.2. <p> When k = 1, the problem becomes the well-known classical bin-packing problem. Since the ratio 1.7 is not affected by the value of k, our result therefore subsumes the previous known result <ref> [30] </ref>. Also, when k = 1, examples that achieve the bound of 1.7 has been given in [30]. Since the term 2.19k is a constant, it disappears when the optimal number of bins L * approaches infinity. Therefore, we conclude that the bound is asymptotically tight. 5.2.
Reference: [31] <author> D.S. Johnson, A. Bemers, J.D. Ullman, M.R. Garey, and R.L. Graham, </author> <title> Worst-Case Performance Bounds for Simple One-dimensional Packing Algorithms, </title> <journal> SIAM J. Comput. </journal> <volume> 3, </volume> <year> 1974, </year> <pages> 299-326. </pages>
Reference-contexts: This difference makes the analysis of the worst case performance of the scheduling heuristics considerably more complicated than that of bin-packing heuristics. Note that the analysis of bin-packing heuristics is quite complex even when the sizes of bins are unitary <ref> [3, 14, 15, 30, 31, 32, 33, 38, 44, 83] </ref>.
Reference: [32] <author> D.S. Johnson, </author> <title> Fast Algorithms for Bin Packing, </title> <journal> J. Comput. Syst. Sci. </journal> <volume> 8, </volume> <year> 1974, </year> <pages> 272-314. </pages>
Reference-contexts: This difference makes the analysis of the worst case performance of the scheduling heuristics considerably more complicated than that of bin-packing heuristics. Note that the analysis of bin-packing heuristics is quite complex even when the sizes of bins are unitary <ref> [3, 14, 15, 30, 31, 32, 33, 38, 44, 83] </ref>.
Reference: [33] <author> D.S. Johnson, </author> <title> and M.R. Garey, A 71/60 Theorem for Bin Packing, </title> <journal> J. </journal> <volume> Complexity 1, </volume> <year> 1985, </year> <pages> 65-106. </pages>
Reference-contexts: This difference makes the analysis of the worst case performance of the scheduling heuristics considerably more complicated than that of bin-packing heuristics. Note that the analysis of bin-packing heuristics is quite complex even when the sizes of bins are unitary <ref> [3, 14, 15, 30, 31, 32, 33, 38, 44, 83] </ref>.
Reference: [34] <author> R.M. Kieckhafer, C.J. Walter, </author> <title> A.M. Finn, and P.M. Thambidurai, The MAFT Architecture for Distributed Fault Tolerance, </title> <journal> IEEE Transactions on Computers 37 (4), </journal> <month> April </month> <year> 1988, </year> <pages> 398-405. </pages>
Reference: [35] <author> J.C. Knight and P.E. Ammann, </author> <title> Design Fault Tolerance, Reliability Engineering and System Safety 32, </title> <booktitle> 1991, </booktitle> <pages> 25-49. 194 </pages>
Reference-contexts: To tolerate hardware failures or software errors, hardware and software redundancy techniques can be used. Examples of redundancy techniques are N-Modular-Redundancy (NMR) [29], Data-Diversity <ref> [35] </ref>, Recovery Block [66], and N-version Programming (N-VP) [2]. At the level of task scheduling, hardware and software are abstracted as processors and tasks.
Reference: [36] <author> C.M. Krishna and K.C Shin, </author> <title> On Scheduling Tasks with a Quick Recovery from Failure, </title> <journal> IEEE Transactions on Computers 35(5), </journal> <month> May </month> <year> 1986, </year> <pages> 448-454. </pages>
Reference-contexts: The optimal result can be generalized to include conditions in which tasks are related by = k , where k is an integer. Though there have been several works in the literature <ref> [4, 5, 36, 45] </ref> which deal with allocation algorithms for fault-tolerant systems, they are developed under vastly different assumptions and are only remotely related to our work. Here we mention several. <p> The tolerance of some processor failures is achieved under the condition that the task set is fixed, and enough processing power is available to execute it. Krishna and Shin <ref> [36] </ref> proposed a dynamic programming algorithm that ensures that backup, or contingency, schedules can be efficiently embedded within the original, primary schedule to ensure that hard deadlines continue to be met even in the face of processor failures.
Reference: [37] <author> J. Labetoulle, E.L. Lawler, J.K. Lenstra, and A.H.G. Rinnooy Kan. </author> <title> Preemptive Scheduling of Uniform Machines Subject to Release Dates, </title> <type> Report BW 99, </type> <institution> Mathe-matisch Centrum, </institution> <address> Amsterdam, </address> <year> 1979. </year>
Reference: [38] <author> C.C. Lee and D.T. Lee, </author> <title> A Simple On-line Bin-Packing Algorithm, </title> <type> JACM 32 (3), </type> <month> July </month> <year> 1985, </year> <pages> 562-572. </pages>
Reference-contexts: This difference makes the analysis of the worst case performance of the scheduling heuristics considerably more complicated than that of bin-packing heuristics. Note that the analysis of bin-packing heuristics is quite complex even when the sizes of bins are unitary <ref> [3, 14, 15, 30, 31, 32, 33, 38, 44, 83] </ref>.
Reference: [39] <author> J.P. Lehoczky, L. Sha, and J.K. Strosnider, </author> <title> Enhanced Aperiodic Responsiveness in Hard Real-time Environments, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1987, </year> <pages> 261-270. </pages>
Reference: [40] <author> J.P. Lehoczky, L. Sha, and Y. Ding, </author> <title> The Rate Monotonic Scheduling Algorithm: Exact Characterization and Average Case Behavior, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1989, </year> <pages> 166-171. </pages>
Reference-contexts: Three other schedulability conditions were later developed by Dhall and Liu [20] in developing heuristic scheduling algorithms for multiprocessor systems. All these conditions are sufficient conditions. Lehoczky, Sha, and Ding recently discovered a schedulabil-ity condition that is both necessary and sufficient <ref> [40] </ref>. For dynamic priority assignment, the EDF algorithm is optimal in the sense that no other dynamic priority assignment algorithm can schedule a task set which cannot be scheduled by the EDF algorithm. The request of a task is assigned the highest priority if its deadline is the closest. <p> If u and C n / T n , then the given set of n tasks can be feasibly scheduled by the RM algorithm. Lehoczky et al recently obtained the following result, which contains a condition that is both necessary and sufficient <ref> [40] </ref>. This condition, which is called the IFF condition, takes into account of both the computation time and period of a task. Condition IFF: Let S = be a set of n tasks with . can be feasibly scheduled by the RM algorithm if and only if = 1. <p> Note that Lemma 1 is true if their RMFF used instead the necessary and sufficient condition given by Lehoczky et al in their 1989 paper <ref> [40] </ref> for m &gt; 2, and our new result as stated in Theorem 3.3. It may be the case that Dhall and Liu indeed considered the problem of scheduling a set of n tasks on n processors (with one task on each processor), and obtained the result in Lemma I.
Reference: [41] <author> J.P. Lehoczky, </author> <title> Fixed Priority Scheduling of Periodic Task Sets with Arbitrary Deadlines, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1990, </year> <pages> 201-209. </pages>
Reference-contexts: Assumption (2) requires that the deadline of a request coincides with the arrival of the next request. This assumption can be relaxed for uniprocessor scheduling <ref> [41] </ref>. Assumption (4) basically assumes that all processors are identical. It follows from the task model that a task is completely defined by two numbers, the run-time of the requests and the request period.
Reference: [42] <author> J.P. Lehoczky and S. Ramos-Thuel, </author> <title> An Optimal Algorithm for Scheduling Soft-Aperiodic Tasks in Fixed-Priority Preemptive Systems, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1992, </year> <pages> 110-123. </pages>
Reference: [43] <author> J.Y.T. Leung and J. Whitehead, </author> <title> On the Complexity of Fixed-Priority Scheduling of Periodic, Real-Time Tasks, Performance Evaluation 2, </title> <booktitle> 1982, </booktitle> <pages> 237-250. </pages>
Reference-contexts: In fact, the problem of optimally scheduling a set of periodic tasks on a multiprocessor system using either fixed priority or dynamic priority assignment is known to be NP-complete <ref> [43] </ref>. An optimal algorithm is the one that uses the minimum number of processors to schedule any task set. Given the intractability, any practical solution to the problem of scheduling periodic tasks on multiprocessor systems presents a trade-off between computational complexity and performance. <p> In fact, the minimization problem has been proven to be NP-complete even in the case where each task has only one copy <ref> [43] </ref>. However, this fact does not make the problem go away; rather it requires that heuristic algorithms must be developed to solve it. In the following, we propose a simple scheduling algorithm to solve the 125 problem.
Reference: [44] <author> M.F. Liang, </author> <title> A Lower Bound for On-line Bin Packing, </title> <note> Information Processing Letters 10 (2), </note> <month> March </month> <year> 1982, </year> <pages> 76-79 </pages>
Reference-contexts: Among the many heuristics, Next-Fit (NF) has a tight bound of 2. First-Fit (FF) and Best-Fit (BF) have a tight bound of 1.7. First-Fit-Decreasing (FFD) has a tight bound of 11/9. Any on-line heuristic cannot have a worst case bound lower than 1.5333 <ref> [44] </ref>. The existing heuristic algorithms that schedule a set of periodic tasks on a multiprocessor using fixed priority assignment are summarized in Table 1.1. The measure denotes the computation time complexity for scheduling a set of n tasks. <p> This difference makes the analysis of the worst case performance of the scheduling heuristics considerably more complicated than that of bin-packing heuristics. Note that the analysis of bin-packing heuristics is quite complex even when the sizes of bins are unitary <ref> [3, 14, 15, 30, 31, 32, 33, 38, 44, 83] </ref>. <p> What are the tight bounds for the RM-FF-IFF and RM-FFDU-IFF algorithms? What is the low bound for any on-line algorithm for the RMMS problem? For bin-packing, it is proven that the low bound for any optimal on-line algorithm cannot be smaller than 1.533... <ref> [44] </ref>.
Reference: [45] <author> A.L. Liestman and R.H. Campbell, </author> <title> A Fault Tolerant Scheduling Problem, </title> <journal> IEEE Transactions on Software Engineering 12(11), </journal> <month> November </month> <year> 1986, </year> <pages> 1089-1095. </pages>
Reference-contexts: The optimal result can be generalized to include conditions in which tasks are related by = k , where k is an integer. Though there have been several works in the literature <ref> [4, 5, 36, 45] </ref> which deal with allocation algorithms for fault-tolerant systems, they are developed under vastly different assumptions and are only remotely related to our work. Here we mention several.
Reference: [46] <author> C.L. Liu and J. Layland, </author> <title> Scheduling Algorithms for Multiprogramming in a Hard Real-Time Environment, </title> <type> JACM 10(1), </type> <year> 1973, </year> <pages> 174-189. </pages>
Reference-contexts: The RM algorithm is optimal for fixed priority assignment for scheduling a set of periodic tasks on a uniprocessor system, while the EDF algorithm is optimal for dynamic priority assignment. First discovered by Liu and Layland <ref> [46] </ref> and Serlin [68], the RM and EDF algorithms have been proven to be viable scheduling techniques for real-time systems. <p> If a set of tasks can be scheduled such that all task deadlines can be met by some 14 algorithms, then we say that the task set is feasible. If a set of periodic tasks can be feasibly scheduled on a single processor, then the Rate-Monotonic (RM) <ref> [46] </ref> or Intelligent Fixed Priority algorithm [68] is optimal for fixed priority assignment, in the sense that no other fixed priority assignment algorithm can schedule a task set which cannot be scheduled by the RM algorithm. <p> Assumption (4) basically assumes that all processors are identical. It follows from the task model that a task is completely defined by two numbers, the run-time of the requests and the request period. The release time of each task does not affect the schedulability of a set of tasks <ref> [46] </ref>. We shall denote a task by the ordered pair ( , ), where is the computation time and is the period of the requests. The ratio / , which is denoted as , is called the utilization (or load) of the task . <p> In the following, we offer a brief review on the RM algorithm. For more details, please refer to the original paper written by Liu and Layland <ref> [46] </ref>. We define the response time of a request for a certain task to be the time span t i C i T i u i t i 26 between the request and the end of the response to that request. <p> A critical instant for a task is defined to be an instant at which a request for that task will have the largest response time. Then we have the following theorem <ref> [46] </ref>: Theorem 2.1: A critical instant for any task occurs whenever the task is requested simultaneously with requests for all higher priority tasks. <p> Therefore, intuitively, assigning a higher priority to a task with a shorter period (which is what RM does) yields more feasible schedules. The optimality of such priority assignment can be in fact established as Liu and Layland did in <ref> [46] </ref>. The following condition, which was given by Liu and Layland [46] and Serlin [68] and is hereafter referred to as WC (Worst-Case) condition, ensures that a task set can be scheduled to meet their deadlines by the RM algorithm if the total utilization of the tasks is less than or <p> The optimality of such priority assignment can be in fact established as Liu and Layland did in <ref> [46] </ref>. The following condition, which was given by Liu and Layland [46] and Serlin [68] and is hereafter referred to as WC (Worst-Case) condition, ensures that a task set can be scheduled to meet their deadlines by the RM algorithm if the total utilization of the tasks is less than or equal to , where n is the number of tasks in <p> An optimal algorithm is the one that always uses the minimum number of processors to execute any given task set. According to Assumption (D), the deadline of each task coincides with its next arrival. For periodic task scheduling, it has been proven <ref> [46] </ref> that the release times of tasks do not affect the schedulability of the tasks. <p> each task are executed on different processors and all the task deadlines are met by EDF? Liu and Layland prove that a set of periodic tasks S = with the deadline of each task coinciding with its next arrival can be feasibly scheduled by EDF if and only if 1 <ref> [46] </ref>. Note that the release time of each task, R i , does not affect the schedulability of a set of periodic tasks. Therefore, R i and D i can be safely omitted in scheduling tasks to processors.
Reference: [47] <author> J.W.S. Liu, K.-J. Lin, and S. Natarajan, </author> <title> Scheduling Real-time, Periodic Jobs Using 195 Imprecise Results, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1987, </year> <pages> 252-260. </pages>
Reference: [48] <author> J.W.S. Liu, K.-J. Lin, W.K. Shih, A.C. Yu, J.Y. Chung and W. Zhao, </author> <title> Algorithms for Scheduling Imprecise Computations, </title> <booktitle> Computer, </booktitle> <month> May </month> <year> 1989, </year> <pages> 58-68. </pages>
Reference: [49] <author> A.K. Mok, </author> <title> Fundamental Design Problems of Distributed Systems for the Hard Real-Time Environment, </title> <type> Ph.D. Thesis, </type> <institution> M.I.T., </institution> <year> 1993. </year>
Reference: [50] <author> Y. Oh and S.H. Son, </author> <title> Multiprocessor Support for Real-Time Fault-Tolerant Scheduling, </title> <booktitle> IEEE Workshop on Architectural Aspects of Real-Time Systems, </booktitle> <address> San Anto-nio, Texas, </address> <month> December </month> <year> 1991, </year> <pages> 76-80. </pages>
Reference: [51] <author> Y. Oh and S.H. Son, </author> <title> An Algorithm for Real-Time Fault-Tolerant Scheduling in Multiprocessor Systems, </title> <booktitle> 4th Euromicro Workshop on Real-Time Systems, </booktitle> <address> Athens, Greece, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: This process is repeated until that either correct results are produced or all the backup copies are exhausted. Here we consider a special case of the primary-backup copy approach where each task has one backup copy only. The following Lemmas <ref> [51] </ref> guarantee that having one backup copy for each task is sufficient for the tolerance of one arbitrary processor failure.
Reference: [52] <author> Y. Oh and S.H. Son, </author> <title> Preemptive Scheduling of Periodic Tasks on Multiprocessor: Dynamic Algorithms and Their Performance, </title> <institution> TR-CS-93-26, Department of Computer Science, University of Virginia, </institution> <month> May </month> <year> 1993. </year>
Reference: [53] <author> Y. Oh and S.H. Son, </author> <title> Allocating Fixed-Priority Periodic Tasks on Multiprocessor Systems, re-submitted to Real-Time Systems Journal, </title> <month> February </month> <year> 1994. </year>
Reference: [54] <author> Y. Oh and S. H. Son, </author> <title> Rate-Monotonic Scheduling on Multiprocessor Systems, </title> <note> submitted to Informatica, </note> <month> February </month> <year> 1994. </year>
Reference: [55] <author> Y. Oh and S.H. Son, </author> <title> Scheduling Hard Real-Time Tasks with Tolerance of Multiple Processor Failures, </title> <journal> Euromicro Journal, </journal> <note> Special Issue on Parallel Processing in Embedded Real-Time Systems, 1994, to appear. </note>
Reference: [56] <author> Y. Oh and S. H. Son, </author> <title> Enhancing Fault-Tolerance in Rate-Monotonic Scheduling, </title> <journal> Real-Time Systems Journal, Special Issue on Responsive Computer Systems, </journal> <month> May </month> <year> 1994, </year> <note> to appear. </note>
Reference: [57] <author> Y. Oh and S.H. Son, </author> <title> Task Allocation Algorithms for Fault-tolerance in Hard Real-time Systems, </title> <note> submitted to IEEE Trans. on Parallel and Distributed Systems, Feb-ruary 1994. 196 </note>
Reference: [58] <author> Y. Oh and S.H. Son, </author> <title> Scheduling Hard Real-Time Tasks with Reliability Constraint, </title> <note> revised and re-submitted to Journal of Operational Research Society, </note> <month> May </month> <year> 1994. </year>
Reference: [59] <author> D.K. Pradhan, </author> <title> Fault-Tolerant Computing -- Theory and Techniques, Volumes I and II, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1986. </year>
Reference: [60] <author> R. Rajkumar, </author> <title> Task Synchronization in Real-Time Systems, </title> <type> Ph.D. Thesis, </type> <institution> Carnegie-Melon University, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: First discovered by Liu and Layland [46] and Serlin [68], the RM and EDF algorithms have been proven to be viable scheduling techniques for real-time systems. Researchers have successfully applied these techniques to tackle a number of practical problems, such as task synchronization <ref> [60] </ref>, bus scheduling [69], joint scheduling of periodic and aperiodic tasks [77, 79], mode change [70, 81], and transient overload [63]. In each of these areas, conventional RM and EDF algorithms have been adapted and extended to produce effective algorithms. <p> Since the problem of scheduling a set of periodic tasks on a multiprocessor system, using either fixed priority assignment or dynamic priority assignment, is NP-complete, heuristic algorithms have been sought to solve it. The approach taken by a number of researchers <ref> [16, 17, 19, 20, 60] </ref> is to partition a given set of tasks into different groups, such that the tasks in each group can be feasibly scheduled on a single processor by a given algo n 2 1 15 rithm.
Reference: [61] <author> K. Ramamritham, </author> <title> Allocation and Scheduling of Complex Periodic Tasks, </title> <booktitle> International Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1990. </year>
Reference: [62] <author> K. Ramamritham and J.A. Stankovic, </author> <title> Scheduling Strategies Adopted in Spring: A Overview, a chapter in Foundations of Real-Time Computing: Scheduling and Resource Allocation (ed.) by A.M. </title> <editor> van Tilborg and G.M. Koob, </editor> <year> 1991, </year> <pages> 277-307. </pages>
Reference: [63] <author> S. Ramos-Thuel and J.K. Strosnider, </author> <title> The Transient Server Approach to Scheduling Time-Critical Recovery Operations, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1991, </year> <pages> 286-295. </pages>
Reference-contexts: Researchers have successfully applied these techniques to tackle a number of practical problems, such as task synchronization [60], bus scheduling [69], joint scheduling of periodic and aperiodic tasks [77, 79], mode change [70, 81], and transient overload <ref> [63] </ref>. In each of these areas, conventional RM and EDF algorithms have been adapted and extended to produce effective algorithms. Recently, the RM algorithm has been used in a number of applications.
Reference: [64] <author> S. Ramos-Thuel, </author> <title> Enhancing Fault Tolerance of Real-Time Systems through Time Redundancy, </title> <type> Ph.D. Thesis, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1993. </year>
Reference: [65] <author> S. Ramos-Thuel and J.P. Lehoczky, </author> <title> On-line Scheduling of Hard Deadline Aperiodic Tasks in Fixed-Priority Systems, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1993, </year> <pages> 160-171. </pages>
Reference-contexts: Assumption (1) requires that each request of a task must arrive in the system at fixed interval. This precludes some tasks that need aperiodic processing. Recently, several techniques have been developed to schedule aperiodic tasks together with periodic tasks in a single processor system <ref> [18, 65, 79] </ref>. The essence of these techniques is either to reserve processor utilization for aperiodic tasks by approximating aperiodic task execution with periodic task execution, or to utilize unused time of periodic tasks for aperiodic task processing.
Reference: [66] <author> B. Randell, </author> <title> System Structure for Software Fault Tolerance, </title> <journal> IEEE Transactions on Software Engineering 1, </journal> <year> 1975, </year> <pages> 220-232. </pages>
Reference-contexts: To tolerate hardware failures or software errors, hardware and software redundancy techniques can be used. Examples of redundancy techniques are N-Modular-Redundancy (NMR) [29], Data-Diversity [35], Recovery Block <ref> [66] </ref>, and N-version Programming (N-VP) [2]. At the level of task scheduling, hardware and software are abstracted as processors and tasks. In general, to tolerate processor failures, redundant processors are used to execute the same software and the final results are obtained through voting on the multiple results. <p> Dont find fault, find a remedy. -- Henry Ford, 1863-1947 157 The task redundancy scheme specified in the above case actually corresponds to the primary-backup copy approach or recovery block approach. Primary-backup copy approach requires the multiple implementation of a specification <ref> [66] </ref>. The first implementation is called the primary copy, and the other implementations are called the backup copies. The primary and if necessary, the backup copies, execute in series. If the primary copy fails, one of the backup copies is switched in to perform the computation again.
Reference: [67] <author> K. Schwan and H. Zhou, </author> <title> Dynamic Scheduling of Hard Real-time Tasks and Real-time Threads, </title> <journal> IEEE Transactions on Software Engineering 18(8), </journal> <year> 1992, </year> <pages> 736-748. </pages>
Reference: [68] <author> P. </author> <title> Serlin, Scheduling of Time Critical Processes, </title> <booktitle> Proc. of the Spring Joint Computers Conference 40, </booktitle> <year> 1972, </year> <pages> 925-932. </pages>
Reference-contexts: The RM algorithm is optimal for fixed priority assignment for scheduling a set of periodic tasks on a uniprocessor system, while the EDF algorithm is optimal for dynamic priority assignment. First discovered by Liu and Layland [46] and Serlin <ref> [68] </ref>, the RM and EDF algorithms have been proven to be viable scheduling techniques for real-time systems. <p> If a set of periodic tasks can be feasibly scheduled on a single processor, then the Rate-Monotonic (RM) [46] or Intelligent Fixed Priority algorithm <ref> [68] </ref> is optimal for fixed priority assignment, in the sense that no other fixed priority assignment algorithm can schedule a task set which cannot be scheduled by the RM algorithm. <p> The optimality of such priority assignment can be in fact established as Liu and Layland did in [46]. The following condition, which was given by Liu and Layland [46] and Serlin <ref> [68] </ref> and is hereafter referred to as WC (Worst-Case) condition, ensures that a task set can be scheduled to meet their deadlines by the RM algorithm if the total utilization of the tasks is less than or equal to , where n is the number of tasks in the set. t
Reference: [69] <author> L. Sha, J.P. Lehoczky, and R. Rajkumar, </author> <title> Solutions for Some Practical Problems in Prioritized Preemptive Scheduling, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1986, </year> <month> 197 </month>
Reference-contexts: First discovered by Liu and Layland [46] and Serlin [68], the RM and EDF algorithms have been proven to be viable scheduling techniques for real-time systems. Researchers have successfully applied these techniques to tackle a number of practical problems, such as task synchronization [60], bus scheduling <ref> [69] </ref>, joint scheduling of periodic and aperiodic tasks [77, 79], mode change [70, 81], and transient overload [63]. In each of these areas, conventional RM and EDF algorithms have been adapted and extended to produce effective algorithms. Recently, the RM algorithm has been used in a number of applications. <p> This basic model may not be of much practical relevance if it cannot be extended to accommodate other requirements. Recently this model has been adapted and extended in many aspects by researchers in solving practical problems <ref> [8, 69, 72] </ref>.
Reference: [70] <author> L. Sha, R. Rajkumar, J.P. Lehoczky, and K. Ramamritham, </author> <title> Mode Change Protocols for Priority-Driven Preemptive Scheduling, Journal of Real-Time Systems 1(3), </title> <booktitle> 1989, </booktitle> <pages> 244-264. </pages>
Reference-contexts: Researchers have successfully applied these techniques to tackle a number of practical problems, such as task synchronization [60], bus scheduling [69], joint scheduling of periodic and aperiodic tasks [77, 79], mode change <ref> [70, 81] </ref>, and transient overload [63]. In each of these areas, conventional RM and EDF algorithms have been adapted and extended to produce effective algorithms. Recently, the RM algorithm has been used in a number of applications.
Reference: [71] <author> L. Sha, R. Rajkumar, and J.P. Lehoczky, </author> <title> Priority Inheritance Protocols: An Approach to Real-Time Synchronization, </title> <journal> IEEE Transactions on Computers 39(9), </journal> <year> 1990, </year> <pages> 1175-1185. </pages>
Reference: [72] <author> L. Sha and J.B. Goodenough, </author> <title> Real-Time Scheduling Theory and Ada, </title> <booktitle> Computer, </booktitle> <month> April </month> <year> 1990, </year> <pages> 53-65. </pages>
Reference-contexts: This basic model may not be of much practical relevance if it cannot be extended to accommodate other requirements. Recently this model has been adapted and extended in many aspects by researchers in solving practical problems <ref> [8, 69, 72] </ref>.
Reference: [73] <author> W-K. Shih, J.W.S. Liu, and J-Y Chung, </author> <title> Fast Algorithms for Scheduling Imprecise Computations, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1989, </year> <pages> 12-19. </pages>
Reference: [74] <author> K.G. Shin, G. Koob, and F. Jahanian, </author> <title> Fault-Tolerance in Real-Time Systems, </title> <booktitle> IEEE Real-Time Systems Newsletter 7 (3), </booktitle> <year> 1991, </year> <pages> 28-34. </pages>
Reference: [75] <author> T.B. Smith, </author> <title> Fault-Tolerant Processor Concepts and Operation, </title> <booktitle> Proc. of 14th IEE Fault-Tolerant Computing Symposium, </booktitle> <month> June </month> <year> 1984. </year>
Reference: [76] <author> A. Spector and D. Gifford, </author> <title> The Space Shuttle Primary Computer System, </title> <journal> CACM, </journal> <month> September </month> <year> 1984, </year> <pages> 874-900. </pages>
Reference: [77] <author> B. Sprunt, J.P. Lehoczky, and L. Sha, </author> <title> Exploiting Unused Periodic Time for Aperiodic Service Using the Extended Priority Exchange Algorithm, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1988, </year> <pages> 251-258. </pages>
Reference-contexts: Researchers have successfully applied these techniques to tackle a number of practical problems, such as task synchronization [60], bus scheduling [69], joint scheduling of periodic and aperiodic tasks <ref> [77, 79] </ref>, mode change [70, 81], and transient overload [63]. In each of these areas, conventional RM and EDF algorithms have been adapted and extended to produce effective algorithms. Recently, the RM algorithm has been used in a number of applications.
Reference: [78] <author> B. Sprunt, L. Sha, and J.P. Lehoczky, </author> <title> Aperiodic Task Scheduling for Hard Real-time Systems, Journal of Real-Time Systems 1, </title> <booktitle> 1989, </booktitle> <pages> 27-60. </pages>
Reference: [79] <author> B. Sprunt, </author> <title> Aperiodic Task Scheduling for Real-Time Systems, </title> <type> Ph.D. Thesis, </type> <institution> Carn-egie Melon University, </institution> <year> 1990. </year>
Reference-contexts: Researchers have successfully applied these techniques to tackle a number of practical problems, such as task synchronization [60], bus scheduling [69], joint scheduling of periodic and aperiodic tasks <ref> [77, 79] </ref>, mode change [70, 81], and transient overload [63]. In each of these areas, conventional RM and EDF algorithms have been adapted and extended to produce effective algorithms. Recently, the RM algorithm has been used in a number of applications. <p> Assumption (1) requires that each request of a task must arrive in the system at fixed interval. This precludes some tasks that need aperiodic processing. Recently, several techniques have been developed to schedule aperiodic tasks together with periodic tasks in a single processor system <ref> [18, 65, 79] </ref>. The essence of these techniques is either to reserve processor utilization for aperiodic tasks by approximating aperiodic task execution with periodic task execution, or to utilize unused time of periodic tasks for aperiodic task processing.
Reference: [80] <author> J.A. Stankovic, </author> <booktitle> Misconception of Real-Time Computing, IEEE Computer 21 (10), </booktitle> <year> 1988, </year> <pages> 10-19. </pages>
Reference: [81] <author> K.W. Tindell, A. Burns, and A.J. Wellings, </author> <title> Mode Change in Priority Pre-emp 198 tively Scheduled Systems, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <year> 1992, </year> <pages> 100-109. </pages>
Reference-contexts: Researchers have successfully applied these techniques to tackle a number of practical problems, such as task synchronization [60], bus scheduling [69], joint scheduling of periodic and aperiodic tasks [77, 79], mode change <ref> [70, 81] </ref>, and transient overload [63]. In each of these areas, conventional RM and EDF algorithms have been adapted and extended to produce effective algorithms. Recently, the RM algorithm has been used in a number of applications.
Reference: [82] <author> J.H. Wensley et.al, SIFT: </author> <title> Design and Analysis of a Fault-Tolerant Computer for Aircraft Control, </title> <booktitle> Proc. of the IEEE 66 (10), </booktitle> <month> October </month> <year> 1978, </year> <pages> 1240-1255. </pages>
Reference: [83] <author> A. C. Yao, </author> <title> New Algorithms for Bin Packing, </title> <type> JACM 27, </type> <year> 1980, </year> <pages> 207-227. </pages>
Reference-contexts: This difference makes the analysis of the worst case performance of the scheduling heuristics considerably more complicated than that of bin-packing heuristics. Note that the analysis of bin-packing heuristics is quite complex even when the sizes of bins are unitary <ref> [3, 14, 15, 30, 31, 32, 33, 38, 44, 83] </ref>.
References-found: 83

