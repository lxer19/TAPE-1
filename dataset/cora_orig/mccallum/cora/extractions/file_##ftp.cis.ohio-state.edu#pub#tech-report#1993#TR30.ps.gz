URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1993/TR30.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Title: Online Hard Real-Time Scheduling for Hypercube Multiprocessors  
Author: Davender Babbar and Phillip Krueger 
Date: September 29, 1993  
Address: Columbus, OH 43210  
Affiliation: Department of Computer and Information Science The Ohio State University  
Abstract: Scheduling sporadic tasks is a formidable problem in hard real-time systems, particularly multiprocessor systems. Until now little research has addressed this problem for hypercube multiprocessors. In this paper we study two online scheduling algorithms - Buddy/RT and Stacking, for hard real-time environments which provide guarantees at the time of arrival of a task. Buddy/RT is a straight-forward extension of the well-known Buddy strategy to the real-time environment, while Stacking is a more sophisticated algorithm based on the lessons learned from Buddy/RT. The underlying concept behind the Stacking algorithm is to reduce fragmentation by `stacking' equal-sized jobs in the time dimension. The performance of the two algorithms is compared through simulation studies. We find that the Stacking algorithm performs significantly better than Buddy/RT over a wide range of workloads, with no increase in complexity.
Abstract-found: 1
Intro-found: 1
Reference: [Chen86] <author> M. S. Chen and K. G. Shin, </author> <title> Embedment of Interacting Task Modules into a Hypercube Multiprocessor, </title> <booktitle> Proc. of the Second Hypercube Conference, </booktitle> <pages> pp. 121-129, </pages> <month> Oct. </month> <year> 1986 </year>
Reference: [Chen87] <author> M. S. Chen and K. G. Shin, </author> <title> Processor Allocation in an N-Cube Multiprocessor Using Gray Codes, </title> <journal> IEEE Trans. on Computers C-36, </journal> <volume> 12, </volume> <pages> pp. 1396-1407, </pages> <month> Dec. </month> <year> 1987 </year>
Reference-contexts: Job scheduling determines the order in which jobs are considered for processor allocation. Several strategies for processor allocation have been proposed that vary widely in complexity, including Buddy [Pete77], Single and Multiple Gray Code <ref> [Chen87] </ref>, and MSS [Dutt91]. In spite of its poor subcube recognition properties, the Buddy strategy has been shown to perform well in hypercube systems under general-purpose workloads [Krue91]. The Multiple Gray Code and MSS algorithms allow for perfect subcube recognition, but carry much 3 greater overhead than Buddy.
Reference: [Chen88] <author> G. I. Chen and T. H. Lai, </author> <title> Preemptive Scheduling of Independent Jobs On A Hypercube, </title> <journal> Information Processing Letters 28, </journal> <pages> pp. 201-206, </pages> <year> 1988 </year>
Reference: [Chen91] <author> G. I. Chen and T. H. Lai, </author> <title> Scheduling Independent Jobs On Partitionable Hy-percubes, </title> <journal> Journal of Parallel and Distributed Computing 12, </journal> <pages> pp. 74-78, </pages> <year> 1991 </year>
Reference: [Chua92] <author> P. J. Chuang and N. F. Tzeng, </author> <title> A Fast Recognition -Complete Processor Allocation Strategy for Hypercube Computers, </title> <journal> IEEE Trans. on Computers 41, </journal> <volume> 4, </volume> <pages> pp. 467-479, </pages> <month> April, </month> <year> 1992 </year>
Reference: [Coll86] <author> S. Colley and J. Palmer, </author> <title> A Microprocessor-based Hypercube Supercomputer, </title> <booktitle> IEEE Micro, </booktitle> <pages> pp. 6-17, </pages> <month> Oct. </month> <year> 1986 </year>
Reference: [Dert74] <author> M. L. Dertouzos, </author> <title> Control Robotics: The Procedural Control of Physical Prcoess, </title> <booktitle> Proc. IFIP Congress, </booktitle> <year> 1974 </year> <month> 20 </month>
Reference-contexts: Consequently, we must rely on scheduling algorithms based on heuristics. Job scheduling algorithms based on simple heuristics such as Earliest Deadline First (EDF) and Minimum Laxity First (MLF) are often used in uniprocessor systems [Hong89]. Dertouzos points out <ref> [Dert74] </ref> that for uniprocessor systems with independent preemptable tasks, EDF is optimal. Mok and Dertouzos [Mok78] show that MLF is also optimal for that same system. Under EDF, jobs are scheduled in ascending according to their deadlines. The job with the earliest deadline gets the highest priority.
Reference: [Doug91] <author> F. Douglis and J. Ousterhout, </author> <title> Transparent Process Migration: Design Alterna--tives and the Sprite Implementation, </title> <journal> Software Practice and Experience 21, </journal> <volume> 8, </volume> <pages> pp. 757-785, </pages> <month> Aug. </month> <year> 1991 </year>
Reference: [Dutt91] <author> S. Dutt and J. P. Hayes, </author> <title> Subcube Allocation in Hypercube Computers, </title> <journal> IEEE Trans. on Computers C-40, </journal> <volume> 3, </volume> <pages> pp. 341-352, </pages> <month> Mar. </month> <year> 1991 </year>
Reference-contexts: Job scheduling determines the order in which jobs are considered for processor allocation. Several strategies for processor allocation have been proposed that vary widely in complexity, including Buddy [Pete77], Single and Multiple Gray Code [Chen87], and MSS <ref> [Dutt91] </ref>. In spite of its poor subcube recognition properties, the Buddy strategy has been shown to perform well in hypercube systems under general-purpose workloads [Krue91]. The Multiple Gray Code and MSS algorithms allow for perfect subcube recognition, but carry much 3 greater overhead than Buddy.
Reference: [Gare79] <author> M. R. Garey and D. S. Johnson, </author> <title> Computers and Intractability, A Guide to the Theory of NP-Completeness. </title> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference-contexts: If the hypercube scheduling problem is simplified so that each job requires only a single processor, then it becomes the classical identical processors scheduling problem as studied by Graham [Grah69]. Since this problem is known to be NP-hard <ref> [Gare79] </ref>, the hypercube scheduling problem is also NP-hard. Consequently, we must rely on scheduling algorithms based on heuristics. Job scheduling algorithms based on simple heuristics such as Earliest Deadline First (EDF) and Minimum Laxity First (MLF) are often used in uniprocessor systems [Hong89].
Reference: [Grah69] <author> R. L. Graham, </author> <title> Bounds on Multiprocessing Timing Anomalies, </title> <journal> SIAM Journal of Applied Mathematics, </journal> <volume> 17, 2, </volume> <month> March </month> <year> 1969, </year> <pages> pp. 416-429. </pages>
Reference-contexts: If the hypercube scheduling problem is simplified so that each job requires only a single processor, then it becomes the classical identical processors scheduling problem as studied by Graham <ref> [Grah69] </ref>. Since this problem is known to be NP-hard [Gare79], the hypercube scheduling problem is also NP-hard. Consequently, we must rely on scheduling algorithms based on heuristics.
Reference: [Haye86] <author> J. P. Hayes, T. Mudge and Q. F. Stout, </author> <title> A Microprocessor-based Hypercube Supercomputer, </title> <booktitle> IEEE Micro, </booktitle> <month> Oct. </month> <year> 1986. </year>
Reference-contexts: The communication structures used in the Fast Fourier Transform (FFT) and bitonic sort algorithm can be embedded similarly in the hypercube <ref> [Haye86] </ref>. The nodes of a hypercube can be imagined to lie at the vertices of an n-dimensional cube, linked by communication channels that lie along the edges of the cube. Each node is linked to n-neighboring processors and the entire hypercube system contains N = 2 n processors.
Reference: [Hong89] <author> J. Hong, X. Tan and D. Towsley, </author> <title> A Performance Analysis of Minimum Laxity and Earliest Deadline Scheduling in a Real-Time System, </title> <journal> IEEE Trans. on Computers, </journal> <month> Dec. </month> <year> 1989. </year>
Reference-contexts: Consequently, we must rely on scheduling algorithms based on heuristics. Job scheduling algorithms based on simple heuristics such as Earliest Deadline First (EDF) and Minimum Laxity First (MLF) are often used in uniprocessor systems <ref> [Hong89] </ref>. Dertouzos points out [Dert74] that for uniprocessor systems with independent preemptable tasks, EDF is optimal. Mok and Dertouzos [Mok78] show that MLF is also optimal for that same system. Under EDF, jobs are scheduled in ascending according to their deadlines.
Reference: [Hong92] <author> K. S. Hong and J. Y-T. Leung, </author> <title> On-line Scheduling of Real-Time Tasks, </title> <journal> IEEE Trans. on Computers, </journal> <month> Oct. </month> <year> 1992. </year>
Reference: [Kim91] <author> J. Kim, C. R. Das and W. Lin, </author> <title> A Top-Down Processor Allocation Scheme for Hypercube Computers, </title> <journal> IEEE Trans. on Parallel and Distributed Systems 2, </journal> <volume> 1, </volume> <pages> pp. 20-30, </pages> <month> Jan. </month> <year> 1991 </year>
Reference: [Klei75] <author> L. Kleinrock, </author> <title> Queueing Systems: </title> <booktitle> Volume 1, Theory, </booktitle> <address> New York: </address> <publisher> John Wiley & Sons, </publisher> <year> 1976. </year>
Reference-contexts: The method of independent replication [Lave83] was used to achieve this level of accuracy. In this study, a Poisson job arrival process is assumed. The Poisson process has been found to model natural physical and organic processes realistically <ref> [Klei75] </ref>, and is commonly used to model random, independent arrivals of jobs to computer systems from an external population.
Reference: [Klei75B] <author> L. Kleinrock, </author> <title> Queueing Systems: </title> <booktitle> Volume 2, Computer Applications, </booktitle> <address> New York: </address> <publisher> John Wiley & Sons, </publisher> <year> 1976. </year>
Reference: [Know65] <author> K. C. Knowlton, </author> <title> A Fast Storage Allocator, </title> <journal> Comm. of ACM 8, </journal> <volume> 10, </volume> <pages> pp. 623-625, </pages> <month> Oct. </month> <year> 1965. </year>
Reference-contexts: Incorporating the lessons learned from studying this simple algorithm, we continue with a more sophisticated algorithm, which we refer to as the `Stacking' algorithm. 2.1 Extension of Buddy for Real-Time Environments The Buddy Strategy, originally proposed for storage allocation <ref> [Know65] </ref>, has since been applied to processor allocation on hypercube systems.
Reference: [Krue91] <author> P. Krueger, T. H. Lai, and V. A. Radiya, </author> <title> Processor Allocation vs. Job Scheduling on Hypercube Computers, </title> <booktitle> Proc. 11th Int. Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 394-401, </pages> <month> May </month> <year> 1991 </year>
Reference-contexts: Several strategies for processor allocation have been proposed that vary widely in complexity, including Buddy [Pete77], Single and Multiple Gray Code [Chen87], and MSS [Dutt91]. In spite of its poor subcube recognition properties, the Buddy strategy has been shown to perform well in hypercube systems under general-purpose workloads <ref> [Krue91] </ref>. The Multiple Gray Code and MSS algorithms allow for perfect subcube recognition, but carry much 3 greater overhead than Buddy. For this reason we focus on strategies related to the Buddy strategy in this study.
Reference: [Lave83] <author> S. S. Lavenberg, </author> <title> Computer Performance Modeling Handbook, </title> <publisher> Academic Press, </publisher> <year> 1983. </year>
Reference-contexts: The method of independent replication <ref> [Lave83] </ref> was used to achieve this level of accuracy. In this study, a Poisson job arrival process is assumed.
Reference: [Leut90] <author> S. T. Leutenegger and M. K. Vernon, </author> <title> The Performance of Multiprogrammed Multiprocessor Scheduling Policies, </title> <booktitle> Proc. of the 1990 ACM SIGMETRICS Conf. on Measurement & Modeling of Computer Systems, </booktitle> <pages> pp. 226-236, </pages> <month> May </month> <year> 1990 </year> <month> 21 </month>
Reference: [Maju88] <author> S. Majumdar, D. L. Eager, and R. B. Bunt, </author> <title> Scheduling in Multiprogrammed Parallel Systems, </title> <booktitle> Proc. of ACM SIGMETRICS 1988, </booktitle> <pages> pp. 104-113, </pages> <month> May </month> <year> 1988 </year>
Reference: [Mok78] <author> A. K. Mok and M. L. Dertouzos, </author> <title> Multiprocessor Scheduling in a Hard Real-Time Environment, </title> <booktitle> Proc. Seventh Texas Conf. Compt. Syst., </booktitle> <month> Nov. </month> <year> 1978. </year>
Reference-contexts: Job scheduling algorithms based on simple heuristics such as Earliest Deadline First (EDF) and Minimum Laxity First (MLF) are often used in uniprocessor systems [Hong89]. Dertouzos points out [Dert74] that for uniprocessor systems with independent preemptable tasks, EDF is optimal. Mok and Dertouzos <ref> [Mok78] </ref> show that MLF is also optimal for that same system. Under EDF, jobs are scheduled in ascending according to their deadlines. The job with the earliest deadline gets the highest priority.
Reference: [Shiv91] <author> N. G. Shivaratri and M. Singhal, </author> <title> A Transfer Policy for Global Scheduling Algorithms to Schedule Tasks With Deadlines, </title> <booktitle> Proc. of Int. Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 248-255, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: In this study, a Poisson job arrival process is assumed. The Poisson process has been found to model natural physical and organic processes realistically [Klei75], and is commonly used to model random, independent arrivals of jobs to computer systems from an external population. Similar to Shivratri and Singhal <ref> [Shiv91] </ref>, to model a real-time workload, we assume that subcube hold times are normally distributed with the standard deviation equal to the mean, and with the distribution truncated at 0 and at one standard deviation greater than the mean.
Reference: [Pete77] <author> J. L. Peterson and T. A. Norman, </author> <title> Buddy Systems, </title> <journal> Communications of ACM, </journal> <volume> vol. 20, no. 6, </volume> <pages> pp. 421-431, </pages> <month> June </month> <year> 1977. </year>
Reference-contexts: Job scheduling determines the order in which jobs are considered for processor allocation. Several strategies for processor allocation have been proposed that vary widely in complexity, including Buddy <ref> [Pete77] </ref>, Single and Multiple Gray Code [Chen87], and MSS [Dutt91]. In spite of its poor subcube recognition properties, the Buddy strategy has been shown to perform well in hypercube systems under general-purpose workloads [Krue91].
Reference: [Saad88] <author> Y. Saad and M. H. Schultz, </author> <title> Topological Properties of Hypercubes, </title> <journal> IEEE Trans. Computers, </journal> <volume> C-37, </volume> <pages> pp. 867 - 872, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: Multiprocessors have emerged as an important computing means for real-time applications, due to their capability for high throughput and reliability through component multiplicity. 1 Due to its numerous useful properties <ref> [Saad88] </ref>, the n-dimensional hypercube (or binary n-cube), is a widely used interconnection topology for parallel computers. Its scalability and rich topology are the main reasons for the attention hypercubes have received from academic researchers as well as from the computer industry.
Reference: [Seit85] <author> C. L. Seitz, </author> <title> The Cosmic Cube, </title> <journal> Communications of ACM, </journal> <volume> vol. 28, no. 1, </volume> <pages> pp. 22-23, </pages> <month> Jan. </month> <year> 1985. </year>
Reference: [Zhu90] <author> Y. Zhu and M. Ahuja, </author> <title> Preemptive Job Scheduling on a Hypercube, </title> <booktitle> Proc. Int. Conf. on Parallel Processing, </booktitle> <pages> pp. 301-304, </pages> <month> Aug. </month> <year> 1990. </year> <month> 22 </month>
References-found: 28

