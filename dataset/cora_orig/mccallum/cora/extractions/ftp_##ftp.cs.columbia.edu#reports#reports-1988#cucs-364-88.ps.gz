URL: ftp://ftp.cs.columbia.edu/reports/reports-1988/cucs-364-88.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1988.html
Root-URL: http://www.cs.columbia.edu
Title: The RB Language  
Author: Jonathan M. Smith Gerald Q. Maguire, Jr. 
Keyword: Distributed Execution, Parallel Processing, Programming Languages.  
Address: Philadelphia, PA 19104-6389  New York, NY 10027  
Affiliation: Distributed Systems Laboratory Department of Computer and Information Science, University of Pennsylvania  Computer Science Department, Columbia University,  
Abstract: Typical algorithms for distributed or parallel computations are cooperative, meaning that the sequential component is broken down into cooperating pieces, which are distributed across available hardware. An approach wich has recently gained some attention is competitive processing, where several versions of a sequential program are distributed across available processors to gain performance from algorithmic diversity. There is also potential for fault tolerance from available hardware by executing the sequential versions, called alternatives, on a distributed configuration. Schemes for implementing competitive concurrent processing have been described in the literature, but there is little implementation experience. RB is a practical step towards gaining such experience. RB is a programming language for specifying alternative methods of performing a computation, where at most one of the results of the alternatives is used. Our prototype implementation uses a combination of a language preprocessor for C and a runtime library to provide the desired semantics. Using other base programming languages, e.g., Ada, or other methods of managing alternatives is straightforward. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Eric Charles Cooper, </author> <title> ``Replicated Distributed Programs,'' </title> <type> Ph.D. Thesis, </type> <institution> University of Cal-ifornia, Berkeley (1985). </institution>
Reference-contexts: It could also be viewed as a set of ``competing'' transactions, at most one of which will take effect. It is clear that Avalon's mechanisms could be combined with RB's, and vice-versa. Distribution of computation across several nodes offers attractive possibilities for both reliability and performance. Cooper <ref> [1] </ref> discusses the use of replicated distributed programs in - -- order to take advantage of this potential. Cooper's CIRCUS system transparently replicates computations across several nodes in order to increase reliability. Goldberg [4] has also discussed process replication for performance improvements.
Reference: [2] <author> W. Feller, </author> <title> An Introduction to Probability Theory and Its Applications, </title> <publisher> Wiley, </publisher> <address> New York (1971). </address>
Reference-contexts: The theoretical basis for the hhhhhhhhhhhhhhh This work was supported in part by equipment grants from the Hewlett-Packard Corporation and AT&T, NSF grant CDR-84-21402, and the Industrial Affiliates of the Distributed Systems Laboratory. - -- technique comes from order statistics <ref> [2] </ref>. Consider independent identically-distributed random variables -X 1 , . . . , X n which measure execution time and whose distribution function is 1 . 257text: S12 &lt;- F; b=0,h=60,lf=2,rf=2 F (t )=Prob (X i t ).
Reference: [3] <author> J. Galambos, </author> <title> The Asymptotic Theory of Extreme Order Statistics, </title> <booktitle> 2nd Edition, Krieger (1987). </booktitle>
Reference: [4] <author> Arthur P. Goldberg and David R. Jefferson, </author> <title> ``Transparent Process Cloning: A Tool for Load Management of Distributed Programs,'' </title> <booktitle> in Proceedings, International Conference on Parallel Processing (1987), </booktitle> <pages> pp. 728-734. </pages>
Reference-contexts: Distribution of computation across several nodes offers attractive possibilities for both reliability and performance. Cooper [1] discusses the use of replicated distributed programs in - -- order to take advantage of this potential. Cooper's CIRCUS system transparently replicates computations across several nodes in order to increase reliability. Goldberg <ref> [4] </ref> has also discussed process replication for performance improvements. Transparent replication can easily be combined with the use of parallel execution, as shown by our "REPLICATES OF" notation. 5.
Reference: [5] <author> H. Hecht, </author> <title> ``Fault-Tolerant Software,'' </title> <journal> IEEE Transactions on Reliability, </journal> <pages> pp. </pages> <month> 227-232 (August </month> <year> 1979). </year>
Reference-contexts: The first such method is referred to as the primary; they have typically been rank-ordered by some metric, e.g., observed performance. Assuming that the acceptance test performs perfectly, the method fails on inputs where all methods fail the acceptance test. Note that the acceptance test is applicationspecific; Hecht <ref> [5] </ref> provides a detailed discussion of the forms such acceptance tests might take. Recovery blocks provide a useful model to base RB's syntax and some of its semantics upon.
Reference: [6] <author> M. P. Herlihy and J. M. Wing, </author> <title> ``Avalon: Language Support for Reliable Distributed Systems,'' </title> <booktitle> in Digest of Papers, The Seventeenth International Symposium on Fault-Tolerant Computing, </booktitle> <address> Pittsburgh, Pennsylvania (July 6-8, </address> <year> 1987), </year> <pages> pp. 89-95. </pages> <note> Also Technical Report - -- CMU-CS-86-147 </note>
Reference-contexts: This performance improvement has been demonstrated on problems such as polynomial zero-finding [10] and searching for ``semi-perfect'' numbers. 4. Related Work RB's implementation is similar in spirit to that of Herlihy and Wing's Avalon <ref> [6] </ref> language. RB is used to specify alternatives in order to gain performance from their diversity, and Avalon is used to specify reliable distributed programs.
Reference: [7] <author> J.J. Horning, H.C. Lauer, P.M. Melliar-Smith, and B. Randell, </author> <title> ``A program structure for error detection and recovery.,'' </title> <booktitle> in Proceedings, Conference on Operating Systems: Theoretical and Practical Aspects (April 1974), </booktitle> <pages> pp. 177-193. </pages>
Reference-contexts: A straightforward analysis shows that 1 . 257text: S12 &lt;- F; b=0,h=60,lf=2,rf=2 F * (t )=1-(1-F (t )) n . For an The recovery block <ref> [7] </ref> is a language construct analogous to a block in block structured programming languages. A block has both private variables and access to global variables (those declared external to the block). The block either reliably updates the external variables, or fails.
Reference: [8] <author> R. Sandberg, D. Goldberg, S. Kleiman, D. Walsh, and R. Lyon, </author> <title> ``The Design and Implementation of the Sun Network File System,'' </title> <booktitle> in USENIX Proceedings (June 1985), </booktitle> <pages> pp. 119-130. </pages>
Reference-contexts: The time required to select at most one of the alternative results (the error case is executed if no results are successful). Item 1 is a function of the computation being performed; 2-4 are overhead contributed by the RB implementation. The fact that a checkpoint to NFS <ref> [8] </ref> file storage for a 30K process takes 0.2 second gives us a measure of the cost of 2 and 3; performance of our mechanism is discussed in Smith and Ioannidis [11].
Reference: [9] <author> Jonathan M. Smith and Gerald Q. Maguire,Jr., </author> <title> ``Transparent Concurrent Execution of Mutually Exclusive Alternatives,'' </title> <booktitle> in Proceedings, Ninth International Conference on Distributed Computing Systems, </booktitle> <address> Newport Beach, CA (June, </address> <year> 1989), </year> <pages> pp. 44-52. </pages>
Reference-contexts: 1. Introduction There are many situations where there exist several alternative methods for computing a result, where a result in the most general case is a state change. When there are differences in the execution times of the methods, ``Multiple Worlds'' <ref> [9, 10] </ref> exploits this difference by picking the first process to complete and eliminating slower processes. <p> Recovery blocks provide a useful model to base RB's syntax and some of its semantics upon. In reality, RB is an outgrowth of an attempt to generate more practical examples of the scheme described by Smith and Maguire for ``competitive computation''. <ref> [9] </ref> RB allows the specified alternative methods to be executed concurrently. In the paper, we begin by discussing RB's syntax and semantics. We follow with some discussion of the implementation experiences and measurements we have gathered from components that have been constructed.
Reference: [10] <author> Jonathan M. Smith and Gerald Q. Maguire,Jr., </author> <title> ``Exploring ``Multiple Worlds'' in Parallel,'' </title> <booktitle> in Proceedings, International Conference on Parallel Processing, </booktitle> <publisher> The Pennsylvania State University Press, </publisher> <address> St. Charles, Illinois (August 8-12, </address> <year> 1989), </year> <pages> pp. 239-245. </pages>
Reference-contexts: 1. Introduction There are many situations where there exist several alternative methods for computing a result, where a result in the most general case is a state change. When there are differences in the execution times of the methods, ``Multiple Worlds'' <ref> [9, 10] </ref> exploits this difference by picking the first process to complete and eliminating slower processes. <p> Note also that if we specify an ENSURE TRUE acceptance test and REPLICATES OF a single alternate, we have pure replication of a computation. Using replicas which have a random component gives us the induced execution time distributions described by Smith and Maguire <ref> [10] </ref>. Iteration of the creation and modification of an address space by an alternate is a potentially useful feature. <p> In fact, if there is some variance between the execution times, the ``fastest first'' behavior will take advantage of the variance to offer improved performance. This performance improvement has been demonstrated on problems such as polynomial zero-finding <ref> [10] </ref> and searching for ``semi-perfect'' numbers. 4. Related Work RB's implementation is similar in spirit to that of Herlihy and Wing's Avalon [6] language. RB is used to specify alternatives in order to gain performance from their diversity, and Avalon is used to specify reliable distributed programs.
Reference: [11] <author> Jonathan M. Smith and John Ioannidis, </author> <title> ``Implementing remote fork() with checkpoint/restart,'' </title> <journal> IEEE Technical Committee on Operating Systems Newsletter, </journal> <pages> pp. </pages> <month> 12-16 (February, </month> <year> 1989). </year>
Reference-contexts: Our checkpointing and process migration implementation is described in detail in Smith and Ioannidis <ref> [11] </ref>. In RB, the checkpoint is created with a call to frz () and a control variable is iterated through the values it can take on, updating the checkpoint and transferring it to a remote system on each iteration. <p> See <ref> [11] </ref> for details. - -- 3.2. <p> The fact that a checkpoint to NFS [8] file storage for a 30K process takes 0.2 second gives us a measure of the cost of 2 and 3; performance of our mechanism is discussed in Smith and Ioannidis <ref> [11] </ref>. The cost of 4 is quite variable, depending on the execution times of the modules and the number of messages necessary to achieve synchronization.
Reference: [12] <author> Richard Stallman, </author> <title> GNU Emacs Manual, Fourth Edition, Version 17, Free Software Foundation, </title> <publisher> Inc., </publisher> <address> 100 Mass Ave., Cambridge, MA 02138 (February 1986). </address> - -- 
Reference-contexts: See [11] for details. - -- 3.2. Performance The preprocessor itself is quite fast; when applied to a large (3200 line) C program with no RB constructs (GNU Emacs' <ref> [12] </ref> sysdep.c ) the RB prototype requires 11 seconds; this compares with the 4 seconds required by cb, a "pretty-printer" for the C programming language executing on the same workstation. For the example program above, the RB prototype and cb require 0.24 seconds and 0.14 seconds, respectively.
References-found: 12

