URL: http://www.aic.nrl.navy.mil:80/~aha/aaai95-fss/papers/garland.ps.Z
Refering-URL: http://www.aic.nrl.navy.mil:80/~aha/aaai95-fss/papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: faeg, altermang@cs.brandeis.edu  
Title: Preparation of Multi-Agent Knowledge for Reuse  
Author: Andrew Garland and Richard Alterman 
Address: Waltham, MA 02254  
Affiliation: Computer Science Department Center for Complex Systems Brandeis University  
Abstract: It is often possible to envision the ways in which knowledge will be reused. By preparing the knowledge appropriately at storage time, we can simplify the later task of adapting the stored knowledge. Preparation can simplify, remove inefficiencies, and segment the trace data into useful ideas. In this paper, we apply this principle to a computational model that deals with the problem of a distributed collective memory for multi-agent systems and we provide technical detail about how the experience of the agents is prepared before storage. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Alterman, R. </author> <year> (1988). </year> <title> Adaptive planning. </title> <journal> Cognitive Science, </journal> <volume> 12 </volume> <pages> 393-421. </pages>
Reference-contexts: Old plans are stored somewhat abstractly so they require some refinement before they are deployed. In either case, agents are assumed to be adaptive planners <ref> (Alterman, 1988) </ref>, so if the plan does not exactly match the current circumstances, differences and changes will be teased out during the ongoing interaction between the agent and the environment.
Reference: <author> Carbonell, J. </author> <year> (1983). </year> <title> Derivational analogy and its role in problem solving. </title> <booktitle> In Proceedings of the Third National Conference on Artificial Intelligence. </booktitle>
Reference: <author> Cole, M. & Engestrom, Y. </author> <year> (1993). </year> <title> A cultural-historical approach to distributed cognitition. </title> <editor> In Salomon, G. (Ed.), </editor> <booktitle> Distributed Cognitions, </booktitle> <pages> pp. 1-46. </pages> <publisher> Cambridge University Press. </publisher>
Reference: <author> Corkill, D. </author> <year> (1979). </year> <title> Hierarchical planning in distributed environment. </title> <booktitle> In Proceedings of the Sixth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 168-175. </pages>
Reference-contexts: An agent creates a plan from scratch using a given set of STRIPS-like operators (Fikes & Nilsson, 1971) using a hierarchical search strategy like ABSTRIPS (Sacerdoti,1974). Unlike other distributed planners <ref> (e.g., Corkill, 1979) </ref>, the agents do not use communication in their planning process. This means that the plans generated may not be globally efficient or even feasible.
Reference: <author> Durfee, E. & Lesser, V. </author> <year> (1987). </year> <title> Using partial global plans to coordinate distributed problem solvers. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 875-883. </pages>
Reference: <author> Fikes, R. E. & Nilsson, N. J. </author> <year> (1971). </year> <title> STRIPS: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2(3) </volume> <pages> 189-208. </pages>
Reference-contexts: HL2 starts talking to HL1: "HL1, help me achieve ((UNLOAD-TOGETHER HL2 HL1 HBOX1 HANDTR1 ROOM2))" "HL2, You're ready now, huh? ok." "HL1, I'm hanging up." old) that occurs results from communication between agents at runtime. An agent creates a plan from scratch using a given set of STRIPS-like operators <ref> (Fikes & Nilsson, 1971) </ref> using a hierarchical search strategy like ABSTRIPS (Sacerdoti,1974). Unlike other distributed planners (e.g., Corkill, 1979), the agents do not use communication in their planning process. This means that the plans generated may not be globally efficient or even feasible.
Reference: <author> Genesereth, M., Ginsberg, M., & Rosenschien, J. </author> <year> (1986). </year> <title> Cooperation without communications. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 51-57. </pages>
Reference-contexts: Agents do not share an overarching plan (Dur-fee & Lesser, 1987), rather cooperative plans emerge from local interactions (Mataric, 1992). The capacities of other agents is not treated as a given <ref> (Genesereth, Ginsberg, & Rosenschien, 1986) </ref>, but this information can be implicitly acquired through the mechanisms of collective memory. The basic cycle for the system goes as follows: 1. Generating a problem for the community to solve. 2. Solving the problem with the community. 3.
Reference: <author> Georgeff, M. P. </author> <year> (1983). </year> <title> The representation of events in multi-agent domains. </title> <booktitle> In Proceedings of the Third National Conference on Artificial Intelligence, </booktitle> <pages> pp. 125-129. </pages>
Reference-contexts: Over the generations of problem-solving, certain hypotheses, saved in collective memory, will be more useful than others. 2 An Architecture to Support Collective Memory 2.1 The Agent Community The control structure for the community of agents is not hierarchical nor is planning centralized <ref> (Georgeff, 1983) </ref>. Agents do not share an overarching plan (Dur-fee & Lesser, 1987), rather cooperative plans emerge from local interactions (Mataric, 1992).
Reference: <author> Laird, J. E., Rosenbloom, P. S., & Newell, A. </author> <year> (1986). </year> <title> Chunking in SOAR: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 11-46. </pages>
Reference-contexts: The notion of storing solutions to previously solved problems is consistent with other models of case-based learning, as well as models of learning based on chunking <ref> (e.g., Laird, Newell, & Rosenbloom, 1986) </ref>. In this paper, we will describe the techniques and principles we are currently using to prepare the data before storage into collective memory.
Reference: <author> Mataric, M. </author> <year> (1992). </year> <title> Designing emergent behaviors: From local interactions to collective intelligence. </title> <booktitle> In From Animals to Animats 2, </booktitle> <pages> pp. 432-441. </pages>
Reference-contexts: Agents do not share an overarching plan (Dur-fee & Lesser, 1987), rather cooperative plans emerge from local interactions <ref> (Mataric, 1992) </ref>. The capacities of other agents is not treated as a given (Genesereth, Ginsberg, & Rosenschien, 1986), but this information can be implicitly acquired through the mechanisms of collective memory. The basic cycle for the system goes as follows: 1. Generating a problem for the community to solve. 2.
Reference: <author> Rosenschien, J. & Genesereth, M. </author> <year> (1985). </year> <title> Deals among rational agents. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 91-99, </pages> <address> Los Angeles, CA. </address>
Reference-contexts: This attitude falls in the middle of the spectrum of possibilities which ranges from totally cooperative to malevolent <ref> (Rosenschien & Gene-sereth, 1985) </ref>. Even if an agent is willing to cooperate, she may be unable to do so. However, an agent who is unwilling or unable to assist can propose an alternative. We use the term `coordination' to refer to an appropriate sequencing of actions for cooperating agents.
Reference: <author> Sacerdoti, E. </author> <year> (1974). </year> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5 </volume> <pages> 115-135. </pages>
Reference-contexts: An agent creates a plan from scratch using a given set of STRIPS-like operators (Fikes & Nilsson, 1971) using a hierarchical search strategy like ABSTRIPS <ref> (Sacerdoti,1974) </ref>. Unlike other distributed planners (e.g., Corkill, 1979), the agents do not use communication in their planning process. This means that the plans generated may not be globally efficient or even feasible.
Reference: <author> Veloso, M. & Carbonell, J. </author> <year> (1993). </year> <title> Derivational analogy in prodigy: Automating case acquisition, storage, and utilization. </title> <journal> Machine Learning, </journal> <volume> 10 </volume> <pages> 249-278. </pages>
References-found: 13

