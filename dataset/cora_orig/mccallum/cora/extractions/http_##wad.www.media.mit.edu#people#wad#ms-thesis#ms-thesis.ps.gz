URL: http://wad.www.media.mit.edu/people/wad/ms-thesis/ms-thesis.ps.gz
Refering-URL: http://wad.www.media.mit.edu/people/wad/ms-thesis/index.html
Root-URL: http://www.media.mit.edu
Title: Synthetic Movies  
Author: by John A. Watlington Andrew Lippman Stephen A. Benton 
Degree: 1987 Submitted to the Media Arts and Sciences Section in Partial Fulfillment of the Requirements for the Degree of Master of Science at the  All Rights reserved. Author  Certified by  Accepted by  Chairman Departmental Commitee on Graduate Students  
Note: c Massachusetts Institute of Technology,  
Date: September 1989  1989  August 4, 1989  
Affiliation: S.B., Electrical Engineering Massachusetts Institute of Technology,  Massachusetts Institute of Technology  Media Arts and Sciences  Lecturer, Associate Director, MIT Media Laboratory  
Pubnum: Section  
Abstract-found: 0
Intro-found: 1
Reference: [Akeley88] <author> K. Akeley, T. Jermoluk, </author> <title> "High Performance Polygon Rendering", </title> <journal> ACM Computer Graphics, </journal> <volume> Vol. 22, No. 4, </volume> <month> Aug. </month> <year> 1988, </year> <month> p.239. </month>
Reference-contexts: Much work has been done in the field of rendering, resulting in the development 1 Examples of these are the Stellar Graphics Supercomputer [Apgar88], the Silicon Graphics Workstations <ref> [Akeley88] </ref>, AT+T's Pixel Machine, and UNC's Pixel Planes-4 [Goldfeather89] 17 of techniques that allow realistic generation of synthetic images. It is the acting real that presents a more serious problem in computer animation.
Reference: [Apgar88] <author> B. Apgar, B. Bersack, A. Mammen, </author> <title> "A Display System for the Stellar Graphics Supercomputer Model GS1000", </title> <journal> ACM Computer Graphics, </journal> <volume> Vol. 22, No. 4, </volume> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: Much work has been done in the field of rendering, resulting in the development 1 Examples of these are the Stellar Graphics Supercomputer <ref> [Apgar88] </ref>, the Silicon Graphics Workstations [Akeley88], AT+T's Pixel Machine, and UNC's Pixel Planes-4 [Goldfeather89] 17 of techniques that allow realistic generation of synthetic images. It is the acting real that presents a more serious problem in computer animation.
Reference: [Backer88] <author> D.S. </author> <title> Backer, "Structures and Interactivity of Media: A Prototype for the Electronic Book," </title> <type> PhD Dissertation, </type> <institution> Massachusetts Institute of Technology, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: The framestore was used to provide still computer graphics images and text, but was not used in generating image sequences. Although this limited the electronic book to interframe synthesis, the 21 "Movie Manual" is a good example of a synthetic movie <ref> [Backer88] </ref>. 2.5 The Oxyacetylene Welding Simulator Another example of a synthetic movie is a training simulator designed by D. Hon of Ixion Systems to teach oxyacetylene welding [Ixion][Brush89]. This simulator uses a videodisc as a large framestore to store the images required for the simulator.
Reference: [Baumwell88] <author> M. Baumwell, C. Birse, R. Collyer, </author> <note> "NuBus Interrupt Latency (I was a teenage DMA junkie)", Macintosh Technical Note #221, </note> <institution> Apple Programmers and Developers Association, </institution> <month> Dec. </month> <year> 1988. </year>
Reference-contexts: Although the theoretical data transfer rate over the NuBus is in excess of 35 MByte/sec., actual data rates obtained between the Mac II processor and a peripheral on the NuBus are much lower, on the order of 4 MBytes/sec <ref> [Baumwell88] </ref>. Due to the lack of a DMA controller, the Mac IIx is not capable of sustaining this rate. The IranScan frame buffer (shown in Fig. 4.3) consists of two frame buffers, one of which may be superimposed over the second.
Reference: [Bove88] <author> V.M. Bove, </author> <title> "Pictoral Applications for range sensing cameras", </title> <booktitle> Proc. SPIE, </booktitle> <year> 1988. </year>
Reference: [Bove89] <author> V.M. Bove, </author> <title> "Synthetic Movies Derived from Multi-Dimensional Image Sensors", </title> <type> PhD Dissertation, </type> <institution> Massachusetts Institute of Technology, </institution> <month> June </month> <year> 1989. </year>
Reference-contexts: Batch mode processing limited interaction with the computer to punching programs onto paper cards or tape, then loading them into the computer. Output usually consisted of printing to 3 This is assuming that a camera capable of recording more than just luminance information is available. See Section 6.4 <ref> [Bove89] </ref>. 13 a line printer. When the teletype appeared, and simple operating systems were designed to use them; it was a great improvement. <p> Another common class of object representations attempt to describe objects as 1 Although some particle systems model the entire volume of the object (voxels), for the purposes of synthetic movies only describing the particles along the surface (surfels) is sufficient <ref> [Bove89] </ref>. 26 combinations of primitive geometrical objects. Examples of this class are con-structive solid geometry (CSG) and superquadric representations. These representations tend to be very manipulable. The two dimensional view required for display by conventional display devices must be rendered from the three dimensional object description. <p> One possibility is the model building camera developed by V. Michael Bove <ref> [Bove89] </ref>. This camera records range information derived using depth-from-focus methods as well as luminance information for an image. A sequence of these images, or the images recorded by multiple cameras viewing the same scene are used to generate a three dimensional particle representation of the object [Linhardt88].
Reference: [Brett87] <author> C. Brett, S. Pieper, D. Zeltzer, </author> <title> "Putting It All Together: An Integrated Package for Viewing and Editing 3D Microworlds", </title> <booktitle> Proc. 4th Usenix Computer Graphics Workshop, </booktitle> <address> Cambridge, Massachusetts, </address> <month> Oct. </month> <year> 1987. </year>
Reference: [Brtndmo89] <author> H.P. Brtndmo, G. Davenport, </author> <title> "Creating and Viewing the Elastic Charles A Hypermedia Journal", </title> <institution> MIT Media Laboratory, Film/Video Section working paper, </institution> <month> July </month> <year> 1989. </year>
Reference-contexts: The interframe synthetic 22 movie generated reflects the internal model of the weld maintained by the personal computer. 2.6 The Elastic Charles A very recent example of an interframe synthetic movie, utilizing advances in computer technology, is the "Elastic Charles" project <ref> [Brtndmo89] </ref>. The "Elastic Charles" is a hypermedia journal, a prototype electronic magazine. It contains a collection of multimedia stories about the history, ecology, current news and usage of the Charles River in Massachusetts. These stories are primarily visual, but are augmented with text, graphics and sound. <p> In many intraframe synthetic movies, the movie description is actually a set of constraints and procedures for manipulating the sequences. In Hypermedia, for example, a set of procedures for browsing through information, with the ability to 29 establish and examine links to related information, is provided <ref> [Brtndmo89] </ref>. The course of the movie is determined by the user input received, possibly prompted by additional visual or aural cues. 3.2.2 Interframe Movie Descriptions Interframe descriptions describe the actual contents of the image sequence, in a frame by frame manner.
Reference: [Brush89] <institution> Discussion with Dr. George Brush, College of Aeronautics, </institution> <address> New York, </address> <month> July </month> <year> 1989. </year> <journal> [DSPatch] |, "The Lamborghini of ADSP-2100 Applications", DSPatch, Analog Devices, </journal> <volume> No. 11, </volume> <month> Spring </month> <year> 1989. </year> <month> 67 </month>
Reference: [DuBois89] <author> DuBois, P.,"TransSkel: </author> <title> A Transportable Application Skeleton", </title> <institution> TransSkel v2.0 documentation, Wisconsin Regional Primate Research Center, </institution> <month> Feb. </month> <year> 1989. </year>
Reference-contexts: The majority of the software was written in MPW C. Some hardware dependent or speed restricting parts of the drawing routines were written in 68020 assembly language. A public domain library of routines, TransSkel <ref> [DuBois89] </ref>, which abstracts out the interface to the Macintosh operating system, was used to simplify program development. The User Interface Toolbox of the Macintosh, along with the Operating System Utilities, provided support for windowing, mouse actions, menus, and user dialogs.
Reference: [Feiner82] <author> S. Feiner, D. Salesin, T. Banchoff, "Dial: </author> <title> A Diagrammatic Animation Language", </title> <journal> IEEE Computer Graphics, </journal> <volume> Vol. 2, Num. 7, </volume> <month> Sept. </month> <year> 1982, </year> <note> p. 43. </note> <author> [Foley83] J.D. Foley, A. </author> <title> Van Dam,Fundamentals of Interactive Computer Graphics, </title> <publisher> Addison Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1984, </year> <note> p. 3. </note>
Reference: [Fortin83] <author> D. Fortin, J.F. Lamy, D. Thalmann, </author> <title> "A Multiple Track Animator System for Motion Synchronization," </title> <booktitle> Proc. ACM SIGGRAPH/SIGART Interdisciplinary Workshop, </booktitle> <address> Toronto, Canada, </address> <month> April </month> <year> 1983, </year> <note> p. 180. </note>
Reference: [Ginsberg83] <author> C. Ginsberg, </author> <title> "Human Body Motion as Input to an Animated Graphical Display", </title> <type> S.M. Thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1983. </year>
Reference: [Goldfeather89] <author> J. Goldfeather, H. Fuchs, S. Molnar, G. Turk, </author> <title> "Near Real-Time CSG Rendering Using Tree Normalization and Geometric Pruning", </title> <journal> IEEE Computer Graphics, </journal> <volume> Vol. 9, No. 3, </volume> <month> May </month> <year> 1989, </year> <note> p. 20. </note>
Reference-contexts: Much work has been done in the field of rendering, resulting in the development 1 Examples of these are the Stellar Graphics Supercomputer [Apgar88], the Silicon Graphics Workstations [Akeley88], AT+T's Pixel Machine, and UNC's Pixel Planes-4 <ref> [Goldfeather89] </ref> 17 of techniques that allow realistic generation of synthetic images. It is the acting real that presents a more serious problem in computer animation.
Reference: [Hecht79] <author> E. Hecht, A. Zajac, </author> <title> Optics, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1979, </year> <month> p.112. </month>
Reference-contexts: The scaling value used is derived from the formula for a simple lens: M T = f =z o , where f is the focal length of the lens being simulated and z o is the depth of the object <ref> [Hecht79] </ref>. The focal length used in drawing a frame is determined by the background image being used.
Reference: [Heckbert82] <author> P. Heckbert, </author> <title> "Color Image Quantization for Frame Buffer Display," </title> <journal> ACM Computer Graphics, </journal> <volume> vol. 16, no. 3, </volume> <pages> pp. 297-305, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: An image displayed in a ScanRam window may be double buffered without redrawing the entire screen. This requires less screen memory, as well as allowing faster screen updating. In addition, the pixel depth provided by ScanRam allows the use of realistic color <ref> [Heckbert82] </ref>. The color lookup table (CLUT) hardware also supports double buffering, allowing it to be updated without disturbing the displayed image. The display window generated by Video Finger has a content region of 320x240 pixels, which is one-quarter of the screen. <p> This image set was then color quantized to provide the actual images used in the object representation. The color lookup table was generated by applying Heckbert's median cut algorithm <ref> [Heckbert82] </ref> to a histogram generated from a small number of representative images from the image set. Although the software supports objects having multiple CLUTs, the color 56 statistics of the object views are relatively constant, allowing most objects to be reasonably encoded using one 256 entry color table.
Reference: [Ixion] <institution> Information booklet, Ixion Systems, </institution> <address> Seattle, Washington. </address>
Reference: [Kay77] <author> A. Kay, A. Goldberg, </author> <title> "Personal Dynamic Media", </title> <booktitle> Computer 10(3), </booktitle> <month> March </month> <year> 1977, </year> <note> p. 30. </note>
Reference: [Levy84] <author> Steven Levy, </author> <title> Hackers: </title> <booktitle> Heroes of the Computer Revolution, </booktitle> <address> Anchor Press/Doubleday, Garden City, New York, </address> <year> 1984, </year> <month> p.45. </month>
Reference-contexts: The graphics display of Spacewar was very limited, using simple line graphics to present the users with two miniature spaceships that could be manipulated in front of a astronomically correct background of stars <ref> [Levy84] </ref>. The first video games to be available to the public were commercial video games such as "Pong" and "Space Invaders". These first games were very simplistic, due to the level of computer hardware available at affordable costs. Many other games of increasing complexity, however, soon followed.
Reference: [Linhardt88] <author> P.M. Linhardt, </author> <title> "Integration of Range Images from Multiple Viewpoints into a Particle Database," </title> <type> MSVS Thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> Feb. </month> <year> 1989. </year>
Reference-contexts: Michael Bove [Bove89]. This camera records range information derived using depth-from-focus methods as well as luminance information for an image. A sequence of these images, or the images recorded by multiple cameras viewing the same scene are used to generate a three dimensional particle representation of the object <ref> [Linhardt88] </ref>. This database may be converted into other forms for rendering. Although the computing requirements of rendering a view directly from the object database generated by the camera are too large to consider doing it on the Mac II, the representation used by Video Finger could easily be generated.
Reference: [Lippman80] <author> A. Lippman, </author> <title> "Movie Maps: An Application of the Optical Videodisc to Computer Graphics Laboratory," </title> <booktitle> Proc. ACM SIGGRAPH, </booktitle> <year> 1980. </year>
Reference: [Lippman81] <author> A. Lippman, </author> <title> "The Computational Videodisc," </title> <journal> IEEE Trans. on Consumer Electronics, </journal> <volume> vol. CE-27, no. 3, </volume> <month> Aug. </month> <year> 1981. </year>
Reference: [Lippman87] <author> A. Lippman, W. Bender, </author> <title> "News and Movies in the 50 Megabit Living Room," </title> <booktitle> IEEE Globecom, </booktitle> <address> Tokyo, Japan, </address> <month> Nov. </month> <year> 1987. </year> <month> 68 </month>
Reference: [Maxwell83] <author> D. Maxwell, </author> <title> "Graphical Marionette: A Modern-Day Pinocchio", </title> <type> MSVS Thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> June </month> <year> 1983. </year>
Reference: [Mohl81] <author> R. Mohl, </author> <title> "Cognitive Space in the Interactive Movie Map: An Investigation of Spatial Learning in Virtual Environments," </title> <type> PhD Dissertation, </type> <institution> Massachusetts Institute of Technology, </institution> <month> Sept. </month> <year> 1981. </year>
Reference: [Morris88] <author> L.R. Morris, S.A. Dyer, </author> <title> "Floating Point Signal Processing Chips: </title> <journal> The End of the Supercomputer Era ?", IEEE Micro, </journal> <volume> Vol. 8, No. 6, </volume> <month> Dec. </month> <year> 1988, </year> <note> p. 86. </note> <author> [Netravali89] A. Netravali, B. </author> <title> Haskell, Digital Pictures: Representation and Compression, </title> <publisher> Plenum Press, </publisher> <address> New York,1989. </address>
Reference-contexts: Such systems exist now [Akeley88][Apgar88][Goldfeather89], but the specialized hardware required is very costly. This is changing, however, thanks to advances in VLSI technology. As the chart in Fig. 7.1 1 shows, the personal com 1 The data in the chart was obtained from Morris & Dyer <ref> [Morris88] </ref> 64 puters of the early 1990s will benefit from microprocessors that outperform many large computers of the 1980s. The development of more realistic synthetic movies on personal computers will be helped tremendously. 65 Chapter 8 Conclusion This thesis was an exploration of synthetic movies.
Reference: [Pentland89] <author> A. Pentland, J. Williams, </author> <title> "Good Vibrations: Modal Dynamics for Graphics and Animations", </title> <journal> ACM Computer Graphics, </journal> <volume> Vol. 23, No. 3, </volume> <month> July </month> <year> 1989, </year> <note> p. 215. </note>
Reference-contexts: An acceptable representation of deformable objects has been the subject of much recent research [Terzopoulos88][Platt88]. One new deformable object representation, which is promising due to its low computing requirements, describes the deformations using a modal analysis <ref> [Pentland89] </ref>. The rendering stage that gives these representations much of their manipulability is computationally expensive, and well beyond the limited computing power available presently in personal computers.
Reference: [Platt88] <author> J. Platt, A. Barr, </author> <title> "Constraint Methods for Flexible Models", </title> <journal> ACM Computer Graphics, </journal> <volume> Vol. 22, No. 4, </volume> <month> Aug. </month> <year> 1988, </year> <note> p. 279. </note>
Reference: [Pratt78] <author> W.K. Pratt, </author> <title> Digital Image Processing, </title> <publisher> John Wiley and Sons Inc., </publisher> <address> New York, </address> <year> 1978. </year>
Reference: [Reeves83] <author> W.T. Reeves, </author> <title> "Particle Systems ATechnique for Modeling a Class of Fuzzy Objects", </title> <journal> ACM Trans. on Graphics, </journal> <volume> vol. 2, no. 2, </volume> <month> April </month> <year> 1983, </year> <month> p.91. </month>
Reference: [Reynolds82] <author> C.W. Reynolds, </author> <title> "Computer Animation with Scripts and Actors", </title> <journal> ACM Computer Graphics, </journal> <volume> Vol. 16, No. 3, </volume> <month> July </month> <year> 1982, </year> <month> p.289. </month>
Reference: [Schreiber86] <author> W.F. Schreiber, </author> <title> Fundamentals of Electronic Imaging Systems, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1986. </year>
Reference: [Sturman89] <author> D. Sturman, D. Zeltzer, S. Pieper, </author> <title> "The Use of Constraints in the bolio System", </title> <booktitle> Course Notes, Tutorial #29, ACM SIGGRAPH 1989, </booktitle> <address> Boston, Massachusetts, </address> <month> August </month> <year> 1989. </year>
Reference: [Terzopoulos88] <author> D. Terzopoulos, K. Fleischer, </author> <title> "Modeling Inelastic Deformation: Viscoelasticity, Plasticity, Fracture", </title> <journal> ACM Computer Graphics, </journal> <volume> Vol. 22, No. 4, </volume> <month> Aug. </month> <year> 1988, </year> <month> p.269. </month>
Reference: [Watlington87] <author> J. Watlington, </author> <title> "A Decoder for Vector Quantized Color Motion Image Sequences", </title> <type> S.B. Thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1988. </year>
Reference: [Watlington88a] <author> J. Watlington, </author> <title> "Movie Player Technical Description", MIT Me--dia Laboratory, Movies of the Future Group, Internal Memo, </title> <month> Fall </month> <year> 1988. </year>
Reference: [Watlington88b] <author> J. Watlington, </author> <title> "Color Image Segmentation for Separation of Background Surfaces", MIT 4.906 Final Project Report, Fall 1988. [XEROX Star] "Designing the Star User Interface", </title> <journal> Byte, </journal> <year> 1982, </year> <month> p242-282. </month>
Reference-contexts: Instead, a small number (three or four) of representative views should be sampled in generating the CLUT. 6.3 Segmentation The RGB original image set contained images of the objects against a background. The background region of the image was identified using color segmentation routines developed for this purpose <ref> [Watlington88b] </ref>. The particular segmentation algorithm used was a region merge algorithm which attempted to form clusters in a two dimensional color space. The color space used for the segmentation was normalized red vs. normalized blue.
Reference: [Zeltzer85] <author> D. Zeltzer, </author> <title> "Towards an Integrated View of 3-D Computer Animation", Procs. Graphics Interface '85, </title> <address> Montreal, </address> <month> May </month> <year> 1985. </year>
Reference-contexts: In the animator level of control, the motion/behavior of objects is described algorithmically, usually in some sort of programming notation. The task level of control stipulates the motion in the scene in terms of events and relationships between the objects <ref> [Zeltzer85] </ref>. Unfortunately, the synthesis of realistic images is currently possible only by the use of rendering techniques, such as ray tracing, which are not very amenable to rapid computation. It is for this reason that alternative means of generating synthetic movies merit research and development.
Reference: [Zeltzer88] <author> D. Zeltzer, S. Pieper, </author> <title> D.J. Sturman, "An Integrated Graphical Simulation Platform", </title> <note> Submitted for publication, </note> <month> November </month> <year> 1988. </year>
Reference-contexts: The movie description may not be explicitly defined in some interframe synthetic movies. Instead, these movies are driven directly by software state machines or constraint systems. Indeed, examples of these may be more numerous than explicitly defined movies. They include interactive video games, flight simulators, interactive graphical simulators <ref> [Zeltzer88] </ref> and many applications at the user interface. 30 Chapter 4 Video Finger: An Example Synthetic Movie This thesis presents an example implementation of a synthetic movie, Video Finger. Video Finger is an application which uses a synthetic movie to convey information about the state of the computer workplace.
Reference: [Zworykin54] <author> V. K. Zworykin, G. Morton, </author> <title> Television, 2nd Edition, </title> <publisher> John Wiley & Sons, Inc., </publisher> <address> New York, 1954, p. </address> <pages> 817-818. 70 </pages>
Reference-contexts: The difficulties introduced when interpolating color values make the use of an RGB frame buffer desirable. The psychophysical limits of the human visual system suggest that a frame buffer using a YIQ representation for color would be more appropriate <ref> [Zworykin54] </ref>. The peripheral bus bandwidth would be doubled, however, if a "true" color frame buffer is used, requiring a more powerful computer. * The object edges should be anti-aliased. Unfortunately, anti-aliasing can only be done as the view is being transferred into the display buffer.
References-found: 40

