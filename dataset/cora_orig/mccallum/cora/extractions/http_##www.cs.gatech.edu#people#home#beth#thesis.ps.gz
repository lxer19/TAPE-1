URL: http://www.cs.gatech.edu/people/home/beth/thesis.ps.gz
Refering-URL: http://www.cs.gatech.edu/people/home/beth/
Root-URL: 
Title: SOFTWARE APPROACH TO HAZARD DETECTION USING ON-LINE ANALYSIS OF SAFETY CONSTRAINTS  
Author: BY BETH A. PLALE 
Degree: M.S., Temple University, 1991 M.B.A., University of LaVerne, 1986  1984 DISSERTATION Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy in Computer Science in the Graduate School of the  
Date: 1998  
Affiliation: B.S., University of Southern Mississippi,  State University of New York at Binghamton  
Abstract-found: 0
Intro-found: 1
Reference: [AHL + 95] <author> A. Afjeh, P. Homer, H. Lewandowski, J. Reed, and R. Schlichting. </author> <title> Development of an intelligent monitoring and control system for a heterogeneous numerical propulsion system simulation. </title> <booktitle> In Proc. 28th Annual Simulation Symposium, </booktitle> <address> Phoenix, AZ, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: For example, event time is the only event attribute available for comparison in a constraint. Afjeh et. al <ref> [AHL + 95] </ref> propose a monitoring and control system for observing the progress of a parallel propulsion system simulation and for steering the simulation. Monitoring data is obtained from the simulation via one or more watchdog processes then forwarded to the analysis component.
Reference: [Avi85] <author> A. Avizienis. </author> <title> The n-version approach to fault tolerant software. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 11(12) </volume> <pages> 1491-1501, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: program verification and hazard detection have complementary roles: program verification can be used to demonstrate correctness of verifiable components while detection techniques can be employed at run-time to control hazards involving unverified components, the environment, and the interface between verified and unverified components. 3.5.2 Test and design-oriented approaches N-version programming <ref> [Avi85] </ref> is a design approach that introduces the notion of multiple versions of separately developed code to provide redundant functionality. Voting is then used to arbitrate responses.
Reference: [BA94] <author> Tucker Balch and Ronald Arkin. </author> <title> Communication in reactive multiagent robot systems. </title> <booktitle> Autonomous Robots, </booktitle> <volume> 1(1) </volume> <pages> 27-52, </pages> <year> 1994. </year>
Reference-contexts: an evaluation of the methods or model used by this thesis research, explores alternative approaches, and discusses potential improvements and future work. 10 Chapter 2 Motivation 2.1 An autonomous robotics application The sample application used in our work is a multiagent reactive robotic system simulation developed by Balch and Arkin <ref> [BA94] </ref> in their work on the Autonomous Robot Architecture (AuRA) at the Georgia Institute of Technology. The work was undertaken to investigate the importance of communication in robotic societies. The authors tested their strategy through an iteration of simulation and instantiation of real systems.
Reference: [Bir97] <author> Kenneth Birman. </author> <title> Keynote speech. </title> <booktitle> 6th IEEE Int'l Symposium on High Performance Distributed Computing (HPDC-6), </booktitle> <year> 1997. </year>
Reference-contexts: The growing importance of this class of system is best illustrated by an observation made in a recent keynote speech by Kenneth Birman in which he observed that a growing number of software components that were never intended to be safety-critical are today appearing in safety critical settings <ref> [Bir97] </ref>. For example, an emergency room physician may access a remotely located patient record for information essential to an accurate diagnosis. A delay in responding to the request could potentially endanger the patient.
Reference: [BJHL96] <author> Monica Brockmeyer, Farnam Jahanian, Connie Heitmeyer, and Bruce Labaw. </author> <title> An approach to monitoring and assertion-checking of real time specifications in Mode-chart. </title> <booktitle> In Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <month> April </month> <year> 1996. </year>
Reference-contexts: First, while Cnet detection and analysis is easily distributed, this is not possible with an expert system-based approach. Second, rules in expert systems are typically designed to capture domain-specific knowledge which is acquired through significant setup times. Brockmeyer and Jahanian <ref> [BJHL96] </ref> incorporate a monitoring and assertion checking tool into the Modechart Toolset (MT). The monitoring and assertion checking is performed on trace data from symbolic executions of real-time specifications written in Modechart, the same language used for specification of assertions.
Reference: [CG89] <author> Ingeman J. Cox and Narian H. Gehani. </author> <title> Exception handling in robotics. </title> <journal> Computer, </journal> <volume> 22(3) </volume> <pages> 43-49, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: We make the assumption that the user defined code in the analysis executable is small and simple. Without this assumption, we could not make any guarantees about meeting the detection needs of a safety-critical application. The activate and deactivate actions may also be useful for loosely hierarchical error recovery <ref> [CG89] </ref>. For example, when a robot encounters an obstacle in its path, its first response could be to wait some amount of time in the hope that the obstacle will move. If this simple error recovery fails, its second response would be to determine a new route.
Reference: [Cho95] <author> Jan Chomicki. </author> <title> Efficient checking of temporal integrity constraints using bounded history encoding. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 20(2), </volume> <month> June </month> <year> 1995. </year>
Reference-contexts: We have extended ATSQL2 in a minor way as discussed in <ref> [Cho95] </ref> to allow for the specification of real-time properties. As specified by the generality thesis statement of Section 1.2, we assert that the language-based approach to safety specification advocated in this work provides sufficient generality for stating the wide range of safety constraints for continuous safety-critical systems.
Reference: [Eis94] <author> Greg Eisenhauer. </author> <title> Portable self-describing binary data streams. </title> <type> Technical Report GIT-CC-94-45, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <year> 1994. </year> <note> (anon. ftp from ftp.cc.gatech.edu). </note>
Reference-contexts: DataExchange is a communication library built at Georgia Tech that provides services such as dynamic connection of clients, information filtering, and control flow. It is built on top of PBIO <ref> [Eis94] </ref>, Portable Binary I/O, a self describing binary I/O package built at Georgia Tech with a uniform interface for supporting binary on-line communication based on TCP/IP and Unix stream sockets, as well as binary I/O of disk files.
Reference: [EN94] <author> Ramez Elmasri and Shamkant B. Navathe. </author> <title> Fundamentals of Database Systems. </title> <publisher> Addison-Wesley, </publisher> <address> 2 edition, </address> <year> 1994. </year>
Reference-contexts: Cost functions are commonly used in relational databases during query plan selection to estimate the I/O cost of the query. I/O costs include access cost to secondary storage, storage cost, cost of storing intermediate files <ref> [EN94] </ref>. For Cnet's application, we do not care about I/O costs and instead formulate cost functions that are used during query reoptimization. The set of cost factors and cost functions we employ are shown in Figures 16 and 17 respectively. We illustrate its use with the following example.
Reference: [ESS97] <author> Greg Eisenhauer, Beth (Plale) Schroeder, and Karsten Schwan. DataExchange: </author> <title> High performance communication in distributed laboratories. </title> <booktitle> In Proceedings Ninth IASTED Int'l Conference on Parallel and Distributed Computing Systems, </booktitle> <month> October </month> <year> 1997. </year>
Reference-contexts: difficult than moving from simulation to real-life robots: the shared memory map is replaced by communication using a message passing scheme. 12 In a distributed simulation, robots communicate their current position and position of goals they may have moved to one another via a message passing scheme such as DataExchange <ref> [ESS97] </ref>. Real-life robots, on the other hand, transmit this same information via sensors and actuators. 2.2 Hazard detection in the robot application Meaningful constraints and corresponding actions can be specified over the behavior of the robot group just described. <p> The analysis tool establishes itself as the recipient of a set of primitive event types by registering its interest in the event types with the DataExchange library <ref> [ESS97] </ref>. DataExchange is a communication library built at Georgia Tech that provides services such as dynamic connection of clients, information filtering, and control flow. <p> The analysis tool executed as a two thread process (the second thread for the reoptimizer). Communication between the simulation and analysis tool was achieved using the DataExchange communication infrastructure <ref> [ESS97] </ref>. Testing occurred by 'injecting' faults into the robotics application that were known to trigger one or more constraint violations in the analysis tool. Inject is used figuratively because true injection was not used: faults were instead inserted as hard-coded changes in the robotics application.
Reference: [GEK + 95] <author> Weiming Gu, Greg Eisenhauer, Eileen Kraemer, Karsten Schwan, John Stasko, Jef-frey Vetter, and Nirupama Mallavarupu. </author> <title> Falcon: On-line monitoring and steering of large-scale parallel programs. </title> <booktitle> In Proceedings of FRONTIERS'95, </booktitle> <month> February </month> <year> 1995. </year>
Reference-contexts: A sensor is specified using a sensor specification language and built by a sensor compiler. The sensor specification language and compiler are part of the Falcon system <ref> [GEK + 95] </ref>, a system for on-line monitoring and steering of continuous systems. As shown on the left side of Figure 3, sensor specifications are compiled by a sensor/constraint compiler that generates sensor definition code. The sensors are incorporated into the application and accessed through instrumentation points. <p> Partial event ordering will guarantee a partial order on an event stream and would be applied to the event stream before events reached the dispatcher. A partial ordering tool has been developed at Georgia Tech as part of Falcon <ref> [GEK + 95] </ref> and could be adapted to our environment with minimal effort. <p> Testing was performed by executing the analysis tool and the robotics application together in a 'live' setting. The robotics simulation, threaded at the robot level, runs on any machine supporting the Cthreads package <ref> [GEK + 95] </ref> but testing was generally performed under Solaris on an UltraSPARC 1. The analysis tool executed as a two thread process (the second thread for the reoptimizer). Communication between the simulation and analysis tool was achieved using the DataExchange communication infrastructure [ESS97].
Reference: [GHS94] <author> Richard Gerber, Seongsoo Hong, and Manas Saksena. </author> <title> Guaranteeing end-to-end timing constraints by calibrating intermediate processes. </title> <booktitle> In Proceedings 15th Real Time Systems Symposium, </booktitle> <pages> pages 192-203. </pages> <publisher> IEEE, </publisher> <month> December </month> <year> 1994. </year>
Reference-contexts: Additionally, checks are made with simple state tables which limit the ability to specify complex hazards with numerous conditions and hazards that may occur based only on the passing of time (i.e., real-time constraints). Gerber's work <ref> [GHS94] </ref> on guaranteeing end-to-end timing constraints is an automated design methodology for generating a solution to a set of tasks that keeps consistent a set of end-to-end timing constraints.
Reference: [GJ96] <author> Narain Gehani and H.V. Jagadish. </author> <title> Active Database Systems, chapter 8. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1996. </year> <month> 93 </month>
Reference-contexts: Our implementation does not prevent the user from specifying conflicting constraints. In general it is not possible to automate constraint conflict detection <ref> [GJ96] </ref>; it is up to the user to ensure that such conflicts do not occur. With Cnet, this problem is mitigated by the fact that Cnet's constraint management interface permits the user to easily add and remove hazards should a 19 conflict become apparent.
Reference: [Gu95] <author> Weiming Gu. </author> <title> On-line Monitoring and Interactive Steering of large-scale parallel and distributed applications. </title> <type> PhD thesis, </type> <institution> Georgia Institute of Technology, </institution> <year> 1995. </year>
Reference-contexts: With respect to performance, the impact of event size pales compared to the effects of network bandwidth. Since there are so many factors affecting the performance of computer networks, measurements done on Falcon did not include communication costs from monitoring latencies <ref> [Gu95] </ref>. Specifically, the measured monitoring latency included only the elapsed time between the 82 time of sensor record generation and the time of sensor record receipt, and (minimal) processing by a local monitoring thread.
Reference: [Ham72] <author> Willie Hammer. </author> <title> Handbook of system and product safety. </title> <publisher> Prentice Hall, </publisher> <year> 1972. </year>
Reference-contexts: With hazard detection it is possible to capture global faults specified over multiple imperfect components. 3.1 Hazard identification How are hazards identified? Hazard identification is one of the first steps in the process of hazard analysis <ref> [Ham72] </ref>. Hazard analysis, carried out in the earliest life-cycle phases of a project, is a process consisting of identifying hazards, assessing these hazards as to the criticality and likelihood of each (i.e., assessing risk), and designing devices to eliminate or control the hazards.
Reference: [HK93] <author> Y. Huang and C. M. R. Kintala. </author> <title> Software implemented fault tolerance: Technologies and experience. </title> <booktitle> In Proceedings of 23rd Intl. Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 2-9, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: As we stated in Section 3.3, we do not deal with such conditions. One could employ a technique such as watchdog timers <ref> [HK93] </ref> to detect the unanticipated absence of sensor sources. 61 Once a primitive event has been propagated through the net, the dispatcher services all other outstanding event requests. These outstanding requests could include request for actions, query reoptimization, or user requests.
Reference: [HL96] <author> M. P. E. Heimdahl and Nancy G. Leveson. </author> <title> Completeness and consistency checking of software requirements. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 22(6), </volume> <month> June </month> <year> 1996. </year>
Reference-contexts: At the highest level of the hierarchy, and the most desirable to achieve, is a safe system. A safe system is one that is free from accidents or unacceptable losses [Lev95]. There is important research and development being done in 1 providing intrinsically safe systems <ref> [HL96, Lut93, MMS90, RPRL96, RL96] </ref>, systems incapable of evolving into a state that could lead to injury or loss of life. But the goal of an intrinsically safe system is difficult to achieve for some of today's complex, dynamic applications running in parallel or distributed environments.
Reference: [HMG + 97] <author> Jeffrey K. Hollingsworth, Barton P. Miller, Marcelo J. R. Goncalves, Oscar Naim, Zhichen Xu, and Ling Zheng. </author> <title> MDL: A language and compiler for dynamic program instrumentation. </title> <booktitle> In Proceedings International Conference on Parallel Architectures and Compilation Techniques, </booktitle> <month> November </month> <year> 1997. </year>
Reference-contexts: The model simply states that a constraint can be specified over the extracted state; if the extracted state can be expanded dynamically, then the implementation can more closely realize the model. There are, in fact, approaches to instrumenting an application at run-time <ref> [HMG + 97] </ref>. Chapter 4 The Constraint Language 4.1 Language description The constraints given in Section 2.1 are expressed in a natural language. A natural language is, however, not a practical choice for constraint specification. <p> The monitoring framework currently employs default application level instrumentation where instrumentation points are inserted by a user. The approach does not preclude the use of other instrumentation techniques such as binary editing <ref> [HMG + 97] </ref> or event delivery mechanisms such 86 as event mechanisms that are part of the CORBA Common Object Services specification.
Reference: [JCE + 94] <author> C. S. Jensen, J. Clifford, R. Elmasri, S. K. Gadia, P. Hayes, and S. Jajodia [eds]. </author> <title> A glossary of temporal database concepts. </title> <journal> ACM SIGMOD Record, </journal> <volume> 23(1) </volume> <pages> 52-64, </pages> <month> mar </month> <year> 1994. </year>
Reference-contexts: Transaction time, on the other hand, is the time at which a tuple or set of tuples entered the database [SA86]. Transaction time provides a history of all past states of the database and is useful as a record of corrections or modifications to past database states. Valid-time databases <ref> [JCE + 94] </ref>, on the other hand, are databases supporting valid time but not transaction time. For purposes of monitoring, a valid time database is sufficient [Sno88a]. The reason for this is apparent when one considers the following.
Reference: [KCFW94] <author> John C. Knight, Aaron G. Cass, Antonio M. Fernandez, and Kevin G. Wika. </author> <title> Testing a safety-critical application. </title> <type> Technical Report CS-94-08, </type> <institution> University of Virginia, </institution> <year> 1994. </year>
Reference-contexts: N-version programming is transparent to the external world so a system incorporating design diversity could at the same 31 time employ an external hazard detection tool for additional levels of safety. Software testing of safety-critical systems has been addressed in <ref> [KCFW94] </ref> where an automated approach to testing is explored based on the use of simulated devices and reversal checks.
Reference: [KEP + 95] <author> Joh Kuhl, Douglas Evans, Yiannis Papelis, Richard Romano, and Ginger Wat-son. </author> <title> The Iowa Driving Simulator: An immersive research environment. </title> <journal> Computer, </journal> <volume> 28(7) </volume> <pages> 35-41, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: More generally, our detection approach is useful in a variety of environments. For instance, in the Iowa Driving Simulator (IDS) <ref> [KEP + 95] </ref> a fully immersive ground-vehicle simulator can place a driver in a highly realistic driving environment. Hazard conditions in such an environment are the same as in real-life but without the attendant risk of harm or loss. <p> Applying hazard detection to other safety-critical applications as a means of strengthening the approach through application to environments with different hazards. One such environment is a virtual environment such as the Iowa Driving Simulator (IDS) <ref> [KEP + 95] </ref>. In IDS, a fully immersive ground-vehicle simulator can place a driver in a highly realistic driving environment. Hazard conditions in such an environment are the same as in real-life but without the attendant risk of harm or loss. Application to an agent environment.
Reference: [KSO90] <author> Carol Kilpatrick, Karsten Schwan, and David Ogle. </author> <title> Using languages for capture, analysis and display of performance information for parallel and distributed applications. </title> <booktitle> In Proceedings 1990 Int'l Conference on Programming Languages, </booktitle> <year> 1990. </year>
Reference-contexts: The relational approach to monitoring complex systems is further refined in [Sno88b]. Based, in part, on the relational approach originated by Snodgrass, Ogle et al. explore application-dependent and on-line monitoring of parallel and distributed applications [OSS93, Ogl88]. Kilpatrick and Schwan <ref> [KSO90] </ref> further refine the language-based approach for specifying application-dependent monitoring requests. Kilpatrick also explores the idea of integrating all components of a parallel programming environment using the uniform Entity-Relationship information model (also see [SRVO88]). <p> Based, in part, on the relational approach originated by Snodgrass, Ogle et al. explore application-dependent and on-line monitoring of parallel and distributed applications [OSS93]. Kilpatrick and Schwan <ref> [KSO90] </ref> further refine the language-based approach for specifying application-dependent monitoring requests. Kilpatrick also explores the idea of integrating all components of a parallel programming environment using the uniform Entity-Relationship information model. As evidenced by earlier work, the relational model is an appropriate formalism for processing monitoring information.
Reference: [KV93] <author> Herman Kopetz and Paulo Verissimo. </author> <title> Real-time and dependability concepts. In Sape Mullender, editor, Distributed Systems. </title> <publisher> Addison-Wesley, </publisher> <address> 2 edition, </address> <year> 1993. </year>
Reference-contexts: The remainder of the system does not have the strict guarantees required of a real-time system, and its effort is considered to be best-effort as opposed to guaranteed-response <ref> [KV93] </ref>. Finally, unlike implanted devices, another class of safety-critical systems and one characterized by inaccessibility of the device once installed (e.g., defibrillators), the continuous systems considered in our work are accessible so that they may be instrumented for effective hazard detection and response. <p> External detection also makes possible the specification of hazards over distributed sources including those with which embedded detection approaches may have difficulty, such as legacy code or software representatives <ref> [KV93] </ref> (code developed to shadow a hardware sensor or device.) In an environment where constraint specification is itself a dynamic process, subject to learning on behalf of the users, evolving and dynamic applications, and changing environments, external hazard detection has the advantage of minimizing the cost of adding constraints in that
Reference: [Lev86] <author> Nancy Leveson. </author> <title> Software safety: Why, what, and how. </title> <journal> Computing Surveys, </journal> <volume> 18(2) </volume> <pages> 125-163, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: System safety engineers have had in place a hierarchy of techniques for a number of years and in 1986 Leveson <ref> [Lev86] </ref> adapted the hierarchy to software. At the highest level of the hierarchy, and the most desirable to achieve, is a safe system. A safe system is one that is free from accidents or unacceptable losses [Lev95]. <p> Potential hazards that need to be considered during hazard analysis include normal operating modes, maintenance modes, system failure modes, failures or unusual incidents in the environment, and errors in human performance. Hazards for some particular types of systems are identified by law or government standards <ref> [Lev86] </ref>. Once hazards are identified, they are assigned a severity and probability. Hazard severity involves a qualitative measure of the worst credible mishap that could result from the hazard. Typical categories include negligible, marginal, serious, or critical hazard severity level. <p> Voting is then used to arbitrate responses. Leveson <ref> [Lev86] </ref> however, showed in an earlier paper that there is not the extent of diversity of design in software components as is found in hardware components. <p> of gallons of water in the primary and secondary cooling systems to draw off the intense heat of the reactor core, but the cooling system was not working: a pilot-operated relief valve (PORV), designed to relieve pressure, had failed to close after the core had relieved itself sufficiently of pressure <ref> [Lev86] </ref>. Our support for multisource hazards is based on an external approach to hazard detection where analysis is performed outside the application. The benefits of an external approach go beyond satisfying the need for multisource hazards. This separability feature is discussed next, in Section 5.1.
Reference: [Lev91] <author> Nancy G. Leveson. </author> <title> Software safety in embedded computer systems. </title> <journal> Communications of the ACM, </journal> <pages> pages 34-46, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: Automatic pressure relief valves, lockins, lockouts, and interlocks are common hardware hazard prevention approaches. A trip computer in a nuclear power plant that initiates procedures to shut down the plant when operating conditions are hazardous <ref> [Lev91] </ref> is a common example of a software prevention approach. This thesis addresses the issue of software safety through a software approach to hazard detection. The premise of our work is that hazard situations can and do occur, and are often complex, involving multiple sources. <p> certainly be desirable, but the application exhibits sufficient characteristics of continuous systems to be representative, it is of a size that facilitates manipulation, and it is accessible thus promoting experimentation. 16 Chapter 3 Model and Architecture for Adaptive Hazard Detection Hazard detection is a viable approach to improving software safety <ref> [Lev91] </ref> and we argue that for continuous safety critical systems, it is a necessary component in the safety arsenal. <p> In Chapter 6 the overall implementation is evaluated and provides additional evidence of the system's ability to meet this important requirement. 57 5.1 Separability Multisource hazards, hazards consisting of input events from multiple distributed sources, constitute an important and substantial subset of hazard descriptions <ref> [Lev91] </ref>. Implementing detection of multisource hazards requires making tradeoffs between latency, perturbation, encapsulation, and scalability. There are two general approaches to constraint location. In one, constraints are located in the application itself. In the other, hazard detection is performed external to the application.
Reference: [Lev93] <author> Nancy Leveson. </author> <title> An investigation of the Therac-25 accidents. </title> <journal> Computer, </journal> <volume> 26(7) </volume> <pages> 18-41, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Therapeutic linear accelerators accelerate electrons to create high-energy beams that can destroy tumors with minimal impact on surrounding healthy tissue. Six people either died or suffered serious injuries from massive overdoses between June 1985 and January 1987 before the problems were acknowledged and addressed <ref> [Lev93] </ref>. The causes of the accidents were complex and were derived from multiple sources. But overall, blame fell largely upon the accelerator's control and user interface software and the processes used in its development. <p> For example, software problems included race conditions resulting from multitasking that allowed concurrent access to shared memory, lack of proper synchronization mechanisms, and test and set operations that were not indivisible. The accident, detailed and documented carefully by Leveson and Turner in <ref> [Lev93] </ref>, illustrates the need for identifying such safety critical software and developing techniques to reduce the possibility that software problems will compromise property, personal, and economic safety.
Reference: [Lev95] <author> Nancy G. Leveson, </author> <title> editor. Safeware: System safety and computers. </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: At the highest level of the hierarchy, and the most desirable to achieve, is a safe system. A safe system is one that is free from accidents or unacceptable losses <ref> [Lev95] </ref>. There is important research and development being done in 1 providing intrinsically safe systems [HL96, Lut93, MMS90, RPRL96, RL96], systems incapable of evolving into a state that could lead to injury or loss of life. <p> A hazard is a state or condition of the system that combined with some environmental conditions could lead to an accident or loss event <ref> [Lev95] </ref>. Automatic pressure relief valves, lockins, lockouts, and interlocks are common hardware hazard prevention approaches. A trip computer in a nuclear power plant that initiates procedures to shut down the plant when operating conditions are hazardous [Lev91] is a common example of a software prevention approach. <p> It diverges from analysis techniques in that it circumvents the problematic tracing of hazards to their causes by performing run-time checking of the hazard itself, without need for tracing the hazard to its causes. For example, State Machine Hazard Analysis (SMHA) <ref> [Lev95] </ref> is an analysis technique, described in more detail in Section 3.5, that is used for tracing hazards back to their causes. <p> Directly related work is discussed in 29 Section 5.6. 3.5.1 Formal approaches State Machine Hazard Analysis (SHMA) <ref> [Lev95] </ref>, is a specification technique wherein a state search, either forward (inductive) or backward (deductive), is conducted on a model of the system.
Reference: [LPBZ96] <author> Ling Liu, Calton Pu, Roger Barga, and Tong Zhou. </author> <title> Differential evaluation of continual queries. </title> <type> Technical Report TR95-17, </type> <institution> Department of Computer Science, University of Alberta, </institution> <year> 1996. </year>
Reference-contexts: op2 [list EVENT ROBOT_STATE_EV 1] sel1 C:1 sel1C:1 $op1 pickRobotDist $op2 pickRobotRad " eq_i AGG_EV INTERNAL_OP EventQ_setProperties evq7 sel1 sel1Q0C:1 AGG_EV Op_LinkCreate link0 gate0 evq4 link0 gate0 evq5 link0 proj2 evq6 link0 cartes0 evq7 Node_wrapUp C:1 disp0 ###################################################### 52 4.4 Related research In Liu and Pu's work on continual queries <ref> [LPBZ96] </ref>, a client specifies a continual query over information stored in a distributed environment such as the Internet. The objective is to compute the query and return the entire resulting relation upon the first triggering only. On subsequent triggerings, only change information is returned. <p> This approach, although similar to ours in its support of temporal and complex specifications, cannot be directly applied to on-line hazard detection. In Liu and Pu's work on continual queries <ref> [LPBZ96] </ref>, a client specifies a continual query over information stored in a distributed environment such as the Internet. The objective is to compute the query and return the entire resulting relation upon the first triggering only. On subsequent triggerings, only change information is returned.
Reference: [LS83] <author> Nancy G. Leveson and Timothy J. Shimeall. </author> <title> Safety assertions for process-control systems. </title> <booktitle> In Proceedings 13th Int'l Symposium on Fault Tolerant Computing, </booktitle> <pages> pages 236-240, </pages> <month> June </month> <year> 1983. </year> <month> 94 </month>
Reference-contexts: In addition, the compiler generates completely platform independent code making it very easy to perform analysis at a remote location (i.e., closer to the source) or for distributing pieces of the analysis tool across heterogeneous machines. In contrast to previous static analysis approaches <ref> [LS83] </ref>, Cnet is designed to support evolving 8 applications. The long running nature of such applications requires that the analysis tool be adaptable to changes in application state or user-level knowledge. <p> In addition, prior approaches to monitoring were static, that is, they required that all constraints be known at compile time. Given the exploratory and `what-if' potential of safety constraints, applying the relational model to hazard detection must be accommodated by adaption techniques. Leveson's work in the early 1980's <ref> [LS83] </ref> is early recognition of the need for run-time checking for hazard prevention. Her synchronous approach, however, requires embedding all constraints in the application.
Reference: [Lut93] <author> Robyn R. Lutz. </author> <title> Targeting safety related errors during software requirements anal-ysis. </title> <booktitle> In Proceedings 1st ACM SIGSOFT Symposium on Foundations of Software Engineering. ACM, </booktitle> <year> 1993. </year>
Reference-contexts: At the highest level of the hierarchy, and the most desirable to achieve, is a safe system. A safe system is one that is free from accidents or unacceptable losses [Lev95]. There is important research and development being done in 1 providing intrinsically safe systems <ref> [HL96, Lut93, MMS90, RPRL96, RL96] </ref>, systems incapable of evolving into a state that could lead to injury or loss of life. But the goal of an intrinsically safe system is difficult to achieve for some of today's complex, dynamic applications running in parallel or distributed environments.
Reference: [MH95] <author> John McLean and Constance Heitmeyer. </author> <title> High assurance computer systems: A research agenda, safety track report. </title> <booktitle> In America in the Age of Information, National Science and Technology Council Committee on Information and Communications Forum, </booktitle> <year> 1995. </year>
Reference-contexts: Electronic telephone and telecommunications networks are also safety critical systems if one considers that loss of service removes the capability to summon emergency services. Similarly, loss of long-distance service can cause serious 4 disruption of business activities and an ensuing loss of revenue <ref> [MH95] </ref>. Continuous safety critical systems are distinguished from the broader class of safety-critical systems in that: * they are long-running, * they consist of components distributed over multiple physical resources, * they may evolve, and * they may include COTS components.
Reference: [ML97a] <author> Aloysius K. Mok and Guangtian Liu. </author> <title> Early detection of timing constraint violation at run-time. </title> <booktitle> In Proceedings of the 18th Annual Real-time Systems Symposium. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1997. </year>
Reference-contexts: An approach to detecting timing constraint violations in real-time systems is discussed in <ref> [ML97a] </ref>. Additionally, logical time does not impact the design of our analysis tool; its performance is measured in terms of physical time. <p> Identified in the work are techniques for identifying implicit constraints given the explicit constraint set provided by the user. As described more fully in <ref> [ML97a] </ref>, identified also are cases where an implicit constraint can detect a violation earlier than can an explicit constraint.
Reference: [ML97b] <author> Aloysius K. Mok and Guangtian Liu. </author> <title> Efficient runtime monitoring of timing constraints. </title> <booktitle> In Proceedings of the Real-time Technology and Applications Symposium. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1997. </year>
Reference-contexts: To eliminate the overhead of the interpreter executing while the application is running, we prevent dynamic addition of synchronous constraints. Perturbation is minimized through the use of a separate monitoring thread to perform the evaluation. 5.6 Related research In <ref> [ML97b] </ref>, Mok and Liu describe an approach to run-time monitoring of timing constraints. The work defines simple constraints as a timing condition between two events.
Reference: [MLR + 97] <author> Francesmary Modugno, Nancy G. Leveson, Jon D. Reese, Kurt Partridge, and Sean D. Sandys. </author> <title> Integrated safety analysis of requirements specifications. </title> <booktitle> In Proceedings 3rd Intl. Symposium on Requirements Engineering. IEEE, </booktitle> <month> January </month> <year> 1997. </year>
Reference-contexts: The continuum can be used to determine the levels of time and effort to be applied in controlling or eliminating the hazard. We assume the user employs hazard analysis to identify the hazards for which constraints are specified. According to <ref> [MLR + 97] </ref>, system engineers can be quite effective in identifying system hazards, of which there are usually a limited number. <p> The difficulty in hazard analysis lies not so much in identifying hazards as it is in finding all the causes of such hazards so that the hazard can be mitigated at its sources <ref> [MLR + 97] </ref>. Our approach, like many safety analysis techniques, assumes hazards have been identified a priori. <p> The process is repeated until each cause is traced to its sources. For a complex system, tracing all causes to their sources can be a difficult and onerous task <ref> [MLR + 97] </ref>. A hazard detection approach has the advantage of allowing the hazard to be described as a conjunction or disjunction of causes (not sources). <p> Tracing an event forward can generate a large number of states and the problem of identifying all reachable states from an initial state may be unsolvable using a reasonable set of resources. For this reason, forward analysis is often limited to only a small set of temporally ordered events <ref> [MLR + 97] </ref>. In a backward search, the analyst starts with a final event or state and traces back to preceding events or states. The backward search is a useful technique for eliminating or controlling hazards during system development by, in essence, investigating potential accidents before they occur.
Reference: [MMS90] <author> Louise E. Moser and P.M. Melliar-Smith. </author> <title> Formal verification of safety-critical systems. </title> <journal> Software Practice and Experience, </journal> <volume> 20(8) </volume> <pages> 799-821, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: At the highest level of the hierarchy, and the most desirable to achieve, is a safe system. A safe system is one that is free from accidents or unacceptable losses [Lev95]. There is important research and development being done in 1 providing intrinsically safe systems <ref> [HL96, Lut93, MMS90, RPRL96, RL96] </ref>, systems incapable of evolving into a state that could lead to injury or loss of life. But the goal of an intrinsically safe system is difficult to achieve for some of today's complex, dynamic applications running in parallel or distributed environments.
Reference: [MRW92] <author> Allen D. Malony, Daniel A. Reed, and Harry A. G. Wijshoff. </author> <title> Performance measurement intrusion and perturbation analysis. </title> <booktitle> 3(4) </booktitle> <pages> 433-450, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Such perturbation is generally predictable, and its effects on the correctness of timing information can be eliminated using straightforward techniques for perturbation analysis <ref> [MRW92] </ref>. We shift our discussion to the right side of Figure 3 which focuses on the flow from constraint specifications to executable entities. The model implementation defines hazard detection in terms of nodes, queues between nodes, 24 and a dispatcher controlling overall execution.
Reference: [Neu95] <author> Peter G. Neumann. </author> <title> Computer Related Risks. </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: For example, the confluence of events that caused the 1990 AT&T system runaway (a combination of heavy load, software errors, and neighboring switches) resulted in a 9 hour nationwide blockade that was not anticipated despite extensive testing of the involved 114 electronic switching systems <ref> [Neu95] </ref>. Multiple cause failures such as this are difficult to detect using localized checks and, with the multiple components involved, difficult to 'design out' by formal means.
Reference: [NS95] <author> S. Nadjm-Tehrani and J.-E. Stromberg. </author> <title> Proving dynamic properties in an aerospace application. </title> <booktitle> In Proceedings of the 16th Annual Real-time Systems Symposium, </booktitle> <pages> pages 2-10. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1995. </year>
Reference-contexts: SDA is a hazard analysis technique, as is SHMA, and as such complements hazard detection approaches by its ability to identify potential hazards. Program verification. Program verification is the process of formally verifying that an implementation has exactly the same meaning as described in a design <ref> [NS95, SMF97] </ref>. Because program verification can verify a program or collection of programs completely correct, it can achieve intrinsically safe systems. However, systems in which assumptions about the environment can be violated or those containing unverified components, such as COTS components, cannot be formally verified.
Reference: [Ogl88] <author> David Ogle. </author> <title> The Real-Time Monitoring of Distributed and Parallel Systems. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Sciences, The Ohio State University, </institution> <month> Aug </month> <year> 1988. </year>
Reference-contexts: The relational approach to monitoring complex systems is further refined in [Sno88b]. Based, in part, on the relational approach originated by Snodgrass, Ogle et al. explore application-dependent and on-line monitoring of parallel and distributed applications <ref> [OSS93, Ogl88] </ref>. Kilpatrick and Schwan [KSO90] further refine the language-based approach for specifying application-dependent monitoring requests. Kilpatrick also explores the idea of integrating all components of a parallel programming environment using the uniform Entity-Relationship information model (also see [SRVO88]).
Reference: [O'N94] <author> Patrick O'Neil. </author> <title> Database: Principles, Programming, Performance. </title> <publisher> Morgan Kauf-mann, </publisher> <year> 1994. </year>
Reference-contexts: CostF unction P red1 = value 1=COLCARD P red1 &gt; value (HIGHKEY value)=(HIGHKEY LOW KEY ) P red1 &lt; value (value LOW KEY )=(HIGHKEY LOW KEY ) 5.3.1.1 Cost Functions A cost function of a predicate P, CF (P) is the fraction of events resulting from the predicate restriction P <ref> [O'N94] </ref>. Estimating cost functions is done under a number of assumptions, including uniform distribution of individual attribute values and independent joint distributions of values from any two unallied attributes. Cost functions are commonly used in relational databases during query plan selection to estimate the I/O cost of the query.
Reference: [OSS93] <author> David Ogle, Karsten Schwan, and Richard Snodgrass. </author> <title> Application-dependent dynamic monitoring of distributed and parallel systems. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(7) </volume> <pages> 762-778, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: The relational approach to monitoring complex systems is further refined in [Sno88b]. Based, in part, on the relational approach originated by Snodgrass, Ogle et al. explore application-dependent and on-line monitoring of parallel and distributed applications <ref> [OSS93, Ogl88] </ref>. Kilpatrick and Schwan [KSO90] further refine the language-based approach for specifying application-dependent monitoring requests. Kilpatrick also explores the idea of integrating all components of a parallel programming environment using the uniform Entity-Relationship information model (also see [SRVO88]). <p> The program states and activities observed by the monitor are 72 specified by a high-level query language called TQuel (considerably refined in [Sno95]). Based, in part, on the relational approach originated by Snodgrass, Ogle et al. explore application-dependent and on-line monitoring of parallel and distributed applications <ref> [OSS93] </ref>. Kilpatrick and Schwan [KSO90] further refine the language-based approach for specifying application-dependent monitoring requests. Kilpatrick also explores the idea of integrating all components of a parallel programming environment using the uniform Entity-Relationship information model.
Reference: [Ous95] <author> John Ousterhout. </author> <title> Tcl and the Tk toolkit. </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: An event arriving at a node is queued on its input queue. The components of Cnet's analysis tool are the Cnet library, a Tcl <ref> [Ous95] </ref> interpreter, the dispatcher, DataExchange/PBIO, and a set of nodes. The Cnet library, introduced earlier, is discussed in 4.3.2. The dispatcher is the heart of the run-time environment.
Reference: [PES + 98] <author> Beth Plale, Greg Eisenhauer, Karsten Schwan, Jeremy Heiner, Vernard Martin, and Jeffrey Vetter. </author> <title> From interactive applications to distributed laboratories. </title> <note> To appear in IEEE Concurrency, </note> <year> 1998. </year>
Reference-contexts: There are elegant approaches to response enactment, referred to as steering, two of which are described in the context of the Distributed Laboratories project at Georgia Tech <ref> [PES + 98] </ref>, and which could be usefully integrated into this work. 75 Chapter 6 Performance Evaluation of Cnet 6.1 Microbenchmarking Evaluation is carried out to demonstrate the strength of the language-based approach in its ability to allow for optimizations that can result in reduced execution times for the individual constraints.
Reference: [PK93] <author> Patrick R.H. Place and Kyo C. Kang. </author> <title> Safety-critical software: Status report and annotated bibliography. </title> <type> Technical Report CMU/SEI-92-TR-5, </type> <institution> Software Engineering Institute, Carnegie Mellon University, </institution> <year> 1993. </year> <month> 95 </month>
Reference-contexts: Software testing of safety-critical systems has been addressed in [KCFW94] where an automated approach to testing is explored based on the use of simulated devices and reversal checks. A claim of the work, and one reiterated by Place and Kang in <ref> [PK93] </ref>, is that it is not one approach that will guarantee the safety properties of a system, but a range of techniques that will be needed, from verification, to design, to test, to run-time detection. 3.6 Summary The chapter introduced a model of hazard detection in terms of primitive relations, derived
Reference: [PS97] <author> Beth Plale and Karsten Schwan. Cnet: </author> <title> language-based approach to on-line constraint analysis. </title> <type> Technical Report GIT-CC-97-36, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <year> 1997. </year> <note> http://www.cc.gatech.edu/tech reports. </note>
Reference-contexts: The user manages the constraint set by creating rules in the constraint language. 66 As described in <ref> [PS97] </ref>, the language provides five rules: the create rule, alter rule, drop rule, activate rule, and deactivate rule, all of which are available to the user for managing the active constraint set.
Reference: [PV95] <author> Anuj Puri and Pravin Varaiya. </author> <title> Driving safely in smart cars. </title> <month> June </month> <year> 1995. </year>
Reference-contexts: A safety critical system is considered such when a problem or hazard occurring in the system could potentially compromise economic, property, or personal safety. The Automated Vehicle/Highway System (AVHS) <ref> [PV95] </ref> is a transportation system under development at UC Berkeley in which car-like vehicles travel in strictly controlled platoons so as to be able to minimize the distance between each vehicle.
Reference: [RL96] <author> Joh Damon Reese and Nancy G. Leveson. </author> <title> Software deviation analysis: A "safeware" technique. </title> <type> Technical report, </type> <institution> University of Washington, </institution> <year> 1996. </year>
Reference-contexts: At the highest level of the hierarchy, and the most desirable to achieve, is a safe system. A safe system is one that is free from accidents or unacceptable losses [Lev95]. There is important research and development being done in 1 providing intrinsically safe systems <ref> [HL96, Lut93, MMS90, RPRL96, RL96] </ref>, systems incapable of evolving into a state that could lead to injury or loss of life. But the goal of an intrinsically safe system is difficult to achieve for some of today's complex, dynamic applications running in parallel or distributed environments.
Reference: [RPRL96] <author> Vivek Ratan, Kurt Partridge, Jon Reese, and Nancy G. Leveson. </author> <title> Safety analysis tools for requirements specifications. </title> <booktitle> In Proceedings Compass96, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: At the highest level of the hierarchy, and the most desirable to achieve, is a safe system. A safe system is one that is free from accidents or unacceptable losses [Lev95]. There is important research and development being done in 1 providing intrinsically safe systems <ref> [HL96, Lut93, MMS90, RPRL96, RL96] </ref>, systems incapable of evolving into a state that could lead to injury or loss of life. But the goal of an intrinsically safe system is difficult to achieve for some of today's complex, dynamic applications running in parallel or distributed environments. <p> SHMA is one project of the The Safety-Critical Software Project group at the University of Washington. The group has developed additional tools for automating safety analysis. One such tool performs software deviation analysis (SDA) <ref> [RPRL96] </ref>. SDA is based on the underlying model that accidents are caused by deviations in system parameters. The automated technique derives a set of scripts or scenarios from a specification of the system.
Reference: [SA86] <author> R. T. Snodgrass and I. Ahn. </author> <title> Temporal databases. </title> <journal> IEEE Computer, </journal> <volume> 19(9) </volume> <pages> 35-42, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: Valid time is the time known and maintained by the application. It can be a physical time, logical time, or both. Transaction time, on the other hand, is the time at which a tuple or set of tuples entered the database <ref> [SA86] </ref>. Transaction time provides a history of all past states of the database and is useful as a record of corrections or modifications to past database states. Valid-time databases [JCE + 94], on the other hand, are databases supporting valid time but not transaction time.
Reference: [SAS97] <author> Beth (Plale) Schroeder, Sudhir Aggarwal, and Karsten Schwan. </author> <title> Software approach to hazard detection using on-line analysis of safety constraints. </title> <booktitle> In Proceedings 16th Symposium on Reliable and Distributed Systems, </booktitle> <pages> pages 80-87. </pages> <publisher> IEEE Computer Society, </publisher> <month> October </month> <year> 1997. </year>
Reference-contexts: A general overview of the work is given in <ref> [SAS97] </ref>. As shown in Figure 1, Cnet consists of a language and compiler, an analysis component consisting of a library for building executable versions of the queries and a run-time environment to handle event data, action requests, and analysis, and constraint management user interface.
Reference: [SBJS96] <author> Richard T. Snodgrass, Michael H. Bohlen, Christian S. Jensen, and Andreas Steiner. </author> <title> Adding valid time to SQL/temporal. </title> <editor> In ISO/IEC JTC1/SC21/WG3 DBL MAD-146r2, </editor> <month> November </month> <year> 1996. </year>
Reference-contexts: Fact: ATSQL2 2 R: ATSQL2 is a relational query language <ref> [SBJS96] </ref>. Corollary: 8 x, if x 2 H, then x can be specified with our language 2. <p> The language we have developed is a relational query language that incorporates features of the active database rule language Starburst [WC96] for its meta statements, and a subset of the relational temporal query language ATSQL2 <ref> [SBJS96] </ref> for specifying constraint conditions. We have extended ATSQL2 in a minor way as discussed in [Cho95] to allow for the specification of real-time properties. <p> Unlike Starburst, which uses SQL to specify the condition, our language uses the temporal query language ATSQL2 for specifying the constraint condition. ATSQL2, a superset of SQL and a variant of TSQL2 [Sno95] is currently being proposed for incorporation into SQL3 <ref> [SBJS96] </ref>. The constraint condition is described in more detail in Section 4.1.1. The THEN clause specifies a list of actions to be executed when the constraint evaluates to true. Actions are introduced in Section 4.1.2. <p> The constraint condition (ATSQL2 query) must be specified in a relational algebraic form. There is no loss of generality in expressing an ATSQL2 query in relational algebraic form since for the set of statements we support, there is an equivalent representation in relational algebra <ref> [SBJS96] </ref>. It is 43 assumed the constraint condition is in conjunctive normal form, that is, the selects are AND'ed together where each select consists of simple comparisons connected only by OR's.
Reference: [SMF97] <author> T. Stauner, O. Muller, and M. Fuchs. </author> <title> Using HyTech to verify an automotive control system. </title> <editor> In O. Maler, editor, </editor> <title> HART 97: Hybrid and Real-time Systems, </title> <booktitle> Lecture Notes in Computer Science 1201, </booktitle> <pages> pages 139-153. </pages> <publisher> Springer-Verlag, </publisher> <year> 1997. </year>
Reference-contexts: SDA is a hazard analysis technique, as is SHMA, and as such complements hazard detection approaches by its ability to identify potential hazards. Program verification. Program verification is the process of formally verifying that an implementation has exactly the same meaning as described in a design <ref> [NS95, SMF97] </ref>. Because program verification can verify a program or collection of programs completely correct, it can achieve intrinsically safe systems. However, systems in which assumptions about the environment can be violated or those containing unverified components, such as COTS components, cannot be formally verified.
Reference: [Sno82] <author> Richard Snodgrass. </author> <title> Monitoring distributed systems: A relational approach. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, Department of Computer Science, Carnegie-Mellon University, </institution> <address> Pittsburgh, PA 15213, </address> <month> December </month> <year> 1982. </year>
Reference-contexts: The primary goal, to minimize the amount of information returned, is most effectively met when the returned relation is large. The primary goal of on-line hazard detection is fast response, which forces query reevaluation upon every event data arrival. Consequently the returned relation is often a single tuple. Snodgrass <ref> [Sno82] </ref> developed an information based approach to modeling program behavior that treats monitoring information (runtime data, states of processes, states of processors, messages, etc.) as relations. The program states and activities observed by the monitor are specified by a high-level query language called TQuel (considerably refined in [Sno95]). <p> The rule processing algorithm is a simple depth-first traverse of a DAG. Are there other rule processing algorithms that may be better? Snodgrass measured the performance using both a depth-first traverse algorithm and a breadth-first approach and found no significant benefit of one over the other <ref> [Sno82] </ref>. The semantics of rule evaluation do not change from one approach to the other.
Reference: [Sno88a] <author> Richard Snodgrass. </author> <title> A relational approach to monitoring complex systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 6(2) </volume> <pages> 156-196, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: The C:1 query has a corresponding relational algebraic form: 37 ( d:idSelfr:rad ( r:rad&gt;=200 ( r:id=d:idSelf ( d:dist&lt;10 (RobotRadEv fi RobotDistEv))))) involving the relational operations selection ( F ), projection ( d 1 ;d 2 ;:::;d m ), and Cartesian product (fi). According to <ref> [Sno88a] </ref>, constraints specifiable with a subset of ATSQL2 (the subset of which our language is a proper subset), have a corresponding relational algebraic form involving the relational operations selection ( F ), projection ( d 1 ;d 2 ;:::;d m ), Cartesian product (fi), and intersection ("). <p> Valid-time databases [JCE + 94], on the other hand, are databases supporting valid time but not transaction time. For purposes of monitoring, a valid time database is sufficient <ref> [Sno88a] </ref>. The reason for this is apparent when one considers the following. Events flow through a collection of constraints and, if not retained by a constraint, will leave promptly. <p> To implement the PRECEDES operator fully requires infinite storage; an unrealistic option. We adopt the solution taken in <ref> [Sno88a] </ref> by introducing a parameter to limit the life of an event participating in a select operation (and in the process to limit the semantics of the PRECEDES operator as well). We call the parameter a bounding parameter. <p> The implicit condition makes the problem more tractable by allowing representation with 45 finite buffer space. But what is a reasonable buffer size for storing events used in Cartesian product? This depends strongly on the temporal ordering of the two input streams and on their relative synchrony <ref> [Sno88a] </ref>. For two event streams, each with a guaranteed partial order and containing an event for every logical timestep, minimal storage would be required. But if ordering or relative synchrony are absent, the buffer size requirement is potentially unlimited.
Reference: [Sno88b] <author> Richard Snodgrass. </author> <title> A relational approach to monitoring complex systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(2) </volume> <pages> 157-196, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: The program states and activities observed by the monitor are specified by a high-level query language called TQuel (considerably refined in [Sno95]). The relational approach to monitoring complex systems is further refined in <ref> [Sno88b] </ref>. Based, in part, on the relational approach originated by Snodgrass, Ogle et al. explore application-dependent and on-line monitoring of parallel and distributed applications [OSS93, Ogl88]. Kilpatrick and Schwan [KSO90] further refine the language-based approach for specifying application-dependent monitoring requests. <p> Our detection oriented approach is oriented toward detecting constraint violations that cannot all be known a priori. The work is relevant though in that it defines a class of constraints specifiable and monitorable by our tool. Snodgrass <ref> [Sno88b] </ref> develops an information based approach to modeling program behavior that treats monitoring information (runtime data, states of processes, states of processors, messages, etc.) as relations. The program states and activities observed by the monitor are 72 specified by a high-level query language called TQuel (considerably refined in [Sno95]).
Reference: [Sno95] <author> Richard T. Snodgrass, </author> <title> editor. The TSQL2 Temporal Query Language. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: The condition is a query, specified in a relational database query language. Unlike Starburst, which uses SQL to specify the condition, our language uses the temporal query language ATSQL2 for specifying the constraint condition. ATSQL2, a superset of SQL and a variant of TSQL2 <ref> [Sno95] </ref> is currently being proposed for incorporation into SQL3 [SBJS96]. The constraint condition is described in more detail in Section 4.1.1. The THEN clause specifies a list of actions to be executed when the constraint evaluates to true. Actions are introduced in Section 4.1.2. <p> Snodgrass [Sno82] developed an information based approach to modeling program behavior that treats monitoring information (runtime data, states of processes, states of processors, messages, etc.) as relations. The program states and activities observed by the monitor are specified by a high-level query language called TQuel (considerably refined in <ref> [Sno95] </ref>). The relational approach to monitoring complex systems is further refined in [Sno88b]. Based, in part, on the relational approach originated by Snodgrass, Ogle et al. explore application-dependent and on-line monitoring of parallel and distributed applications [OSS93, Ogl88]. <p> Snodgrass [Sno88b] develops an information based approach to modeling program behavior that treats monitoring information (runtime data, states of processes, states of processors, messages, etc.) as relations. The program states and activities observed by the monitor are 72 specified by a high-level query language called TQuel (considerably refined in <ref> [Sno95] </ref>). Based, in part, on the relational approach originated by Snodgrass, Ogle et al. explore application-dependent and on-line monitoring of parallel and distributed applications [OSS93]. Kilpatrick and Schwan [KSO90] further refine the language-based approach for specifying application-dependent monitoring requests.
Reference: [SRVO88] <author> Karsten Schwan, Rajiv Ramnath, Sridhar Vasudevan, and David Ogle. </author> <title> A language and system for the construction and timing of parallel programs. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 14(4) </volume> <pages> 455-471, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: Kilpatrick and Schwan [KSO90] further refine the language-based approach for specifying application-dependent monitoring requests. Kilpatrick also explores the idea of integrating all components of a parallel programming environment using the uniform Entity-Relationship information model (also see <ref> [SRVO88] </ref>). As evidenced above, it has been firmly established that the relational model is an appropriate formalism for processing monitoring information. Prior applications of this formalism were primarily geared toward performance evaluation.
Reference: [WC96] <author> Jennifer Widom and Stefano Ceri, </author> <title> editors. Active Database Systems. </title> <publisher> Morgan Kauf-mann, </publisher> <year> 1996. </year>
Reference-contexts: The language we have adopted for our use is based on the active database rule definition language of the Starburst system <ref> [WC96] </ref>. The language includes temporal query language support. Such a language is additionally beneficial in its declarative style and ease of use. A hazard condition is an observable state of the system or a relationship between observable states separated by time. <p> A relational query language, on the other hand, given its declarative style, optimization potential, and ease of use is highly suitable. The language we have developed is a relational query language that incorporates features of the active database rule language Starburst <ref> [WC96] </ref> for its meta statements, and a subset of the relational temporal query language ATSQL2 [SBJS96] for specifying constraint conditions. We have extended ATSQL2 in a minor way as discussed in [Cho95] to allow for the specification of real-time properties. <p> The rule would be triggered whenever an update occurred to the employee's bonus. Starburst <ref> [WC96] </ref> is an active database rule language that provides a rich set of semantics for specifying and managing rules, for prioritizing rules, and for inducing a partial ordering on the set of defined rules. <p> The semantics of rule evaluation do not change from one approach to the other. It may be useful to allow the user to attach a priority to a constraint, or as is provided by Starburst <ref> [WC96] </ref>, to include as part of rule creation PRECEDES rule-list and FOLLOWS rule-list clauses used to specify priority orderings between rules.
Reference: [WK94] <author> Kevin G. Wilka and John C. Knight. </author> <title> A safety kernel architecture. </title> <type> Technical Report CS-94-04, </type> <institution> Dept. of Computer Science, University of Virginia, </institution> <year> 1994. </year> <month> 96 </month>
Reference-contexts: Fast response requires query reevaluation upon every event data arrival. Because constraints are infrequently violated, there often is no returned relation, or if there is, it is a single event. The objectives of the two approaches are entirely different. The safety kernel architecture <ref> [WK94] </ref>, derived from the concept of a security kernel, encapsulates and enforces the safety policies of a system.
References-found: 59

