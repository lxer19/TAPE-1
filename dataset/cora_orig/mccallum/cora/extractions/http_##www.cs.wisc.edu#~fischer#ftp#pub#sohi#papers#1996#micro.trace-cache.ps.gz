URL: http://www.cs.wisc.edu/~fischer/ftp/pub/sohi/papers/1996/micro.trace-cache.ps.gz
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/sohi/papers/1996/
Root-URL: http://www.cs.wisc.edu
Email: ericro@cs.wisc.edu  sbennett@ichips.intel.com  jes@ece.wisc.edu  
Phone: Telephone:  
Title: Trace Cache: a Low Latency Approach to High Bandwidth Instruction Fetching  
Author: Eric Rotenberg Steve Bennett James E. Smith 
Note: Copyright 1996 IEEE. Published in the Proceedings of the 29th Annual International Symposium on Mi-croarchitecture, Dec. 2-4, 1996, Paris, France. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works, must be obtained from the IEEE. Contact: Manager, Copyrights and Permissions IEEE  Intl. 908-562-3966  
Address: Wisconsin Madison  Wisconsin Madison  445 Hoes Lane P.O. Box 1331 Piscataway, NJ 08855-1331, USA.  
Affiliation: Computer Science Dept. Univ. of  Intel Corporation  Dept. of Elec. and Comp. Engr. Univ. of  Service Center  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T. Conte, K. Menezes, P. Mills, and B. Patel. </author> <title> Optimization of instruction fetch mechanisms for high issue rates. </title> <booktitle> 22nd Intl. Symp. on Computer Architecture, </booktitle> <pages> pp. 333-344, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Their approach hides multiple individual branch predictions within a single prediction; e.g. rather than make 2 branch predictions, make 1 prediction that selects from among 4 paths. This enables the use of more accurate two-level predictors. Another hardware scheme proposed by Conte, Mills, Menezes, and Patel <ref> [1] </ref> uses two passes through an interleaved branch target buffer. Each pass through the branch target buffer produces a fetch address, allowing two nonadjacent cache lines to be fetched. In addition, the interleaved branch target buffer enables detection of any number of branches in a cache line. <p> We then show how the core fetch unit is augmented with the trace cache. 2.1. Core fetch unit The core fetch unit is implemented using established hardware schemes. It is called interleaved sequential in <ref> [1] </ref>. Fetching up to the first predicted taken branch each cycle can be done using the combination of an accurate multiple branch predictor [16], an interleaved branch target buffer (BTB) [1][8], a return address stack (RAS) [6], and a 2-way interleaved instruction cache [1][4]. Refer to Figure 3. <p> The BTB must be n-way interleaved, where n is the number of instructions in a cache line. This is so that all instructions within a cache line can be checked for branches in parallel <ref> [1] </ref>. The BTB can detect other types of control transfer instructions as well. If a jump is detected, the jump address may be predicted. (Jump target predictions are not considered in this paper, however.) Return addresses can almost always be obtained with no penalty by using a call/return stack. <p> The align ment network must (1) interchange the cache lines from numerous banks (with more than two banks, the permutations grow quickly), and (2) collapse the basic blocks together, eliminating unused intervening instructions. Though not discussed in [16], logic like the collapsing buffer <ref> [1] </ref> discussed in the next section will be needed to do this. 3.2. Collapsing buffer The instruction fetch mechanism proposed by Conte, Mills, Menezes, Patel [1] is illustrated in Figure 7. <p> Though not discussed in [16], logic like the collapsing buffer <ref> [1] </ref> discussed in the next section will be needed to do this. 3.2. Collapsing buffer The instruction fetch mechanism proposed by Conte, Mills, Menezes, Patel [1] is illustrated in Figure 7. It is composed of (1) an interleaved instruction cache, (2) an interleaved branch target buffer (BTB), (3) a multiple branch predictor, (4) special logic after the BTB, and (5) an interchange and alignment network featuring a collapsing buffer. <p> The instruction fetch pipeline is likely to have three stages: (1) initial BTB lookup and BTB logic, (2) instruction cache access and second BTB lookup, and (3) interchange switch, masking, and collapsing buffer. The collapsing buffer takes only a single stage if implemented as a bus-based crossbar <ref> [1] </ref>. 4. Simulation methodology 4.1. Processor model Our simulation model follows the basic structure shown in Figure 1 a fetch engine and an execute engine decou-pled via instruction issue buffers. Various fetch engines - trace cache, branch address cache, and collapsing buffer - are modeled in detail. <p> For the SPEC workload, however, TC enjoys a noticeable lead over CB. This is most likely because the original collapsing buffer was not designed to handle backward taken intrablock branches <ref> [1] </ref>, whereas the TC can handle any arbitrary trace. For the majority of the benchmarks, BAC performs worst of the three, but this is particularly noticeable in the SPEC runs. There are two reasons for this. First, instruction cache bank conflicts are the primary performance loss for BAC.
Reference: [2] <author> S. Dutta and M. Franklin. </author> <title> Control flow prediction with treelike subgraphs for superscalar processors. </title> <booktitle> 28th Intl. Symp. on Microarchitecture, </booktitle> <pages> pp. 258-263, </pages> <month> Nov </month> <year> 1995. </year>
Reference-contexts: Similarly, a hit in the branch address cache combined with multiple branch predictions produces the starting addresses of the next several basic blocks. These addresses are fed into a highly interleaved instruction cache to fetch multiple basic blocks in a single cycle. A second study by Franklin and Dutta <ref> [2] </ref> uses a similar approach to the branch address cache (providing multiple branch targets), but with a new method for predicting multiple branches in a single cycle.
Reference: [3] <author> M. Franklin and M. Smotherman. </author> <title> A fill-unit approach to multiple instruction issue. </title> <booktitle> 27th Intl. Symp. on Microarchi-tecture, </booktitle> <pages> pp. 162-171, </pages> <month> Nov </month> <year> 1994. </year>
Reference-contexts: The fill unit, proposed by Melvin, Shebanow and Patt [10], caches RISC-like instructions which are derived from a CISC instruction stream. This predecoding eased the problem of supporting a complex instruction set such as VAX on the HPS restricted dataflow engine. Franklin and Smother-man <ref> [3] </ref> extended the fill unit's role to dynamically assemble VLIW-like instruction words from a RISC instruction stream, which are then stored in a shadow cache. The goal of this structure is to ease the issue complexity of a wide issue processor. 1.3.
Reference: [4] <author> G. F. Grohoski. </author> <title> Machine organization of the ibm rs/6000 processor. </title> <journal> IBM Journal of R&D, </journal> <volume> 34(1) </volume> <pages> 37-58, </pages> <month> Jan </month> <year> 1990. </year>
Reference-contexts: The cache is interleaved so that 2 consecutive cache lines can be accessed; this allows fetching sequential code that spans a cache line boundary, always guaranteeing a full cache line or up to the first taken branch <ref> [4] </ref>. This scheme requires minimal complexity for aligning instructions: (1) logic to swap the order of the two cache lines (interchange switch), (2) a left-shifter to align the instructions into a 16-wide instruction latch, and (3) logic to mask off unused instructions.
Reference: [5] <author> N. Jouppi. </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers. </title> <booktitle> 17th Intl. Symp. on Computer Architecture, </booktitle> <pages> pp. 364-373, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: cache hit rates, the design could use a small buffer to store recent traces; a trace in this buffer is only committed to the trace cache after one or more hits to that trace. 7) victim trace cache: An alternative to judicious trace selection is to use a victim cache <ref> [5] </ref>. It may keep valuable traces from being permanently displaced by useless traces. 3. Other high bandwidth fetch mechanisms In this section we analyze the organization of two previously proposed fetch mechanisms aimed at fetching and aligning multiple noncontiguous basic blocks each cycle.
Reference: [6] <author> D. Kaeli and P. Emma. </author> <title> Branch history table prediction of moving target branches due to subroutine returns. </title> <booktitle> 18th Intl. Symp. on Computer Architecture, </booktitle> <pages> pp. 34-42, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: It is called interleaved sequential in [1]. Fetching up to the first predicted taken branch each cycle can be done using the combination of an accurate multiple branch predictor [16], an interleaved branch target buffer (BTB) [1][8], a return address stack (RAS) <ref> [6] </ref>, and a 2-way interleaved instruction cache [1][4]. Refer to Figure 3. The core fetch unit is designed to fetch as many contiguous instructions possible, up to a maximum instruction limit and a maximum branch limit.
Reference: [7] <author> J. Larus. </author> <title> Efficient program tracing. </title> <journal> IEEE Computer, </journal> <volume> 26(5) </volume> <pages> 52-61, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: SPEC92 floating-point results can be found in [12]. The SPEC92 benchmarks were compiled on a Sun SPARCstation 10/30 using gcc -O4 -static -fschedule-insns -fschedule-insns2. SPARC instruction traces were generated using the Quick Profiler and Tracer (QPT) <ref> [7] </ref> and then fed into the trace-driven SPARC processor simulator. The SPEC92 benchmarks were simulated to completion. The IBS benchmarks are MIPS traces obtained via a logic analyzer connected to the CPU of a DECstation 3100. These benchmarks are a better test of instruction fetch performance than SPEC92 [14].
Reference: [8] <author> J. Lee and A. J. Smith. </author> <title> Branch prediction strategies and branch target buffer design. </title> <journal> IEEE Computer, </journal> <volume> 21(7) </volume> <pages> 6-22, </pages> <month> Jan </month> <year> 1984. </year>
Reference-contexts: First, Yeh, Marr, and Patt [16] consider a fetch mechanism that provides high bandwidth by predicting multiple branch target addresses every cycle. The method features a Branch Address Cache, a natural extension of the branch target buffer <ref> [8] </ref>. With a branch target buffer, a single branch prediction and a BTB hit produces the starting address of the next basic block. Similarly, a hit in the branch address cache combined with multiple branch predictions produces the starting addresses of the next several basic blocks.
Reference: [9] <author> J. Losq. </author> <title> Generalized history table for branch prediction. </title> <journal> IBM Technical Disclosure Bulletin, </journal> <volume> 25(1) </volume> <pages> 99-101, </pages> <month> June </month> <year> 1982. </year>
Reference: [10] <author> S. Melvin, M. Shebanow, and Y. Patt. </author> <title> Hardware support for large atomic units in dynamically scheduled machines. </title> <booktitle> 21st Intl. Symp. on Microarchitecture, </booktitle> <pages> pp. 60-66, </pages> <month> Dec </month> <year> 1988. </year>
Reference-contexts: The work also proposes compiler techniques to reduce the frequency of taken branches. Two previously proposed hardware structures are similar to the trace cache but exist in different applications. The fill unit, proposed by Melvin, Shebanow and Patt <ref> [10] </ref>, caches RISC-like instructions which are derived from a CISC instruction stream. This predecoding eased the problem of supporting a complex instruction set such as VAX on the HPS restricted dataflow engine.
Reference: [11] <author> S.-T. Pan, K. So, and J. T. Rahmeh. </author> <title> Improving the accuracy of dynamic branch prediction using branch correlation. </title> <booktitle> 5th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp. 76-84, </pages> <month> Oct </month> <year> 1992. </year>
Reference: [12] <author> E. Rotenberg, S. Bennett, and J. Smith. </author> <title> Trace cache: a low latency approach to high bandwidth instruction fetching. </title> <type> Tech Report 1310, </type> <institution> CS Dept., Univ. of Wisc. - Madison, </institution> <year> 1996. </year>
Reference-contexts: In the course of this work, many microarchitectural and logic design issues arose. We looked at issues for not only the trace cache, but other proposed mechanisms as well. The results of this detailed study are documented in <ref> [12] </ref>. 1.5. Paper overview In the next section the trace cache fetch unit is described in detail. Section 3 follows up with an analysis of other proposed high bandwidth fetch mechanisms. In Section 4 we describe the simulation methodology including the processor model, workload, and performance metric. <p> Multiporting the pattern history table and changing its organization slightly extends the single correlated branch predictor to multiple predictions each cycle, as proposed in [16]. (Refer to <ref> [12] </ref> for an implementation.) BTB logic combines the BTB hit information with the branch predictions to produce the next fetch address, and to generate trailing zeroes in the valid instruction bit vectors (if there is a predicted taken branch). <p> Operation latencies are similar to those of the MIPS R10000 processor. 4.2. Workload The six integer SPEC92 benchmarks and six benchmarks from the Instruction Benchmark Suite (IBS) [14] are used to evaluate the performance of the various fetch mechanisms. SPEC92 floating-point results can be found in <ref> [12] </ref>. The SPEC92 benchmarks were compiled on a Sun SPARCstation 10/30 using gcc -O4 -static -fschedule-insns -fschedule-insns2. SPARC instruction traces were generated using the Quick Profiler and Tracer (QPT) [7] and then fed into the trace-driven SPARC processor simulator. The SPEC92 benchmarks were simulated to completion. <p> For the majority of the benchmarks, BAC performs worst of the three, but this is particularly noticeable in the SPEC runs. There are two reasons for this. First, instruction cache bank conflicts are the primary performance loss for BAC. Data in <ref> [12] </ref> shows that BAC is comparable to TC if bank conflicts are ignored. Second, the BAC treats basic blocks as atomic units. As a result, a BAC entry will provide only as many basic block addresses as will fit within the 16 instruction fetch limit.
Reference: [13] <author> J. E. Smith. </author> <title> A study of branch prediction strategies. </title> <booktitle> 8th Symp. on Computer Architecture, </booktitle> <pages> pp. 135-148, </pages> <month> May </month> <year> 1981. </year>
Reference: [14] <author> R. Uhlig, D. Nagle, T. Mudge, S. Sechrest, and J. Emer. </author> <title> Instruction fetching: Coping with code bloat. </title> <booktitle> 22nd Intl. Symp. on Computer Architecture, </booktitle> <pages> pp. 345-356, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: After issue, execution takes a certain number of cycles based on the operation. Operation latencies are similar to those of the MIPS R10000 processor. 4.2. Workload The six integer SPEC92 benchmarks and six benchmarks from the Instruction Benchmark Suite (IBS) <ref> [14] </ref> are used to evaluate the performance of the various fetch mechanisms. SPEC92 floating-point results can be found in [12]. The SPEC92 benchmarks were compiled on a Sun SPARCstation 10/30 using gcc -O4 -static -fschedule-insns -fschedule-insns2. <p> The SPEC92 benchmarks were simulated to completion. The IBS benchmarks are MIPS traces obtained via a logic analyzer connected to the CPU of a DECstation 3100. These benchmarks are a better test of instruction fetch performance than SPEC92 <ref> [14] </ref>. For one thing, a significant fraction of the traces are kernel and X-server references, increasing in struction path lengths. To simulate the IBS traces, we devel-oped a trace-driven MIPS processor simulator similar to the SPARC one. 4.3.
Reference: [15] <author> T.-Y. Yeh. </author> <title> Two-level Adaptive Branch Prediction and Instruction Fetch Mechanisms for High Performance Superscalar Processors. </title> <type> PhD thesis, </type> <institution> EECS Dept., University of Michigan - Ann Arbor, </institution> <year> 1993. </year>
Reference-contexts: While storing counters with each branch achieves multiple branch prediction trivially, branch prediction accuracy is limited. Branch prediction is fundamental to ILP, and should have precedence over other factors. For high branch prediction accuracy, we use a 4kB GAg (14) correlated branch predictor <ref> [15] </ref>. The 14 bit global branch history register indexes into a single pattern history table. This predictor was chosen for its accuracy and because it is more easily extended to multiple branch predictions than other predictors which require address information [16][2].
Reference: [16] <author> T.-Y. Yeh, D. T. Marr, and Y. N. Patt. </author> <title> Increasing the instruction fetch rate via multiple branch prediction and a branch address cache. </title> <booktitle> 7th Intl. Conf. on Supercomputing, </booktitle> <pages> pp. 67-76, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Related prior work Three recent studies have focused on high bandwidth instruction fetching and are closely related to the research reported here. All of these attempt to fetch multiple, possibly noncontiguous basic blocks each cycle from the instruction cache. First, Yeh, Marr, and Patt <ref> [16] </ref> consider a fetch mechanism that provides high bandwidth by predicting multiple branch target addresses every cycle. The method features a Branch Address Cache, a natural extension of the branch target buffer [8]. <p> Core fetch unit The core fetch unit is implemented using established hardware schemes. It is called interleaved sequential in [1]. Fetching up to the first predicted taken branch each cycle can be done using the combination of an accurate multiple branch predictor <ref> [16] </ref>, an interleaved branch target buffer (BTB) [1][8], a return address stack (RAS) [6], and a 2-way interleaved instruction cache [1][4]. Refer to Figure 3. The core fetch unit is designed to fetch as many contiguous instructions possible, up to a maximum instruction limit and a maximum branch limit. <p> This predictor was chosen for its accuracy and because it is more easily extended to multiple branch predictions than other predictors which require address information <ref> [16] </ref>[2]. Multiporting the pattern history table and changing its organization slightly extends the single correlated branch predictor to multiple predictions each cycle, as proposed in [16]. (Refer to [12] for an implementation.) BTB logic combines the BTB hit information with the branch predictions to produce the next fetch address, and to generate trailing zeroes in the valid instruction bit vectors (if there is a predicted taken branch). <p> The analysis compares these mechanisms against the trace cache, with latency being a key point for comparison. 3.1. Branch address cache The branch address cache fetch mechanism proposed by Yeh, Marr, and Patt <ref> [16] </ref> is shown in Figure 5. There are four primary components: (1) a branch address cache (BAC), (2) a multiple branch predictor, (3) an interleaved instruction cache, and (4) an interchange and alignment network. <p> The align ment network must (1) interchange the cache lines from numerous banks (with more than two banks, the permutations grow quickly), and (2) collapse the basic blocks together, eliminating unused intervening instructions. Though not discussed in <ref> [16] </ref>, logic like the collapsing buffer [1] discussed in the next section will be needed to do this. 3.2. Collapsing buffer The instruction fetch mechanism proposed by Conte, Mills, Menezes, Patel [1] is illustrated in Figure 7.
Reference: [17] <author> T.-Y. Yeh and Y. N. Patt. </author> <title> A comprehensive instruction fetch mechanism for a processor supporting speculative execution. </title> <booktitle> 25th Intl. Symp. on Microarchitecture, </booktitle> <pages> pp. 129-139, </pages> <month> Dec </month> <year> 1992. </year>
References-found: 17

