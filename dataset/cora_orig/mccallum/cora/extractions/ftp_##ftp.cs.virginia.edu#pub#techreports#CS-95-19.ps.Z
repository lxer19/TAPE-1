URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-95-19.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Abstract: 1 Campus-Wide Computing: Early Results Using Legion at the University of Virginia 1 Andrew S. Grimshaw Anh Nguyen-Tuong William A. Wulf Abstract The Legion project at the University of Virginia is an attempt to provide system services that provide the illusion of a single virtual machine to users, a virtual machine that provides both improved response time via parallel execution and greater throughput. Legion is targeted towards both workstation clusters and towards larger, wide-area, assemblies of workstations, supercomputers, and parallel supercomputers. Rather than construct Legion from scratch we are extending an existing object-oriented parallel processing system by aggressively incorporating lessons learned over twenty years by the heterogeneous distributed systems community. The campus-wide virtual computer is an early Legion prototype. In this paper we present challenges that had to be overcome to realize a working CWVC, as well as performance on a production biochemistry application. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. F. Altschul, W. Gish, W. Miller, E. W. Myers, D. J. Lipman, </author> <title> Basic local alignment search tool, </title> <journal> J. Mol. Biol., </journal> <volume> 215, </volume> <pages> pp. 403-410, </pages> <year> 1990. </year>
Reference-contexts: Three popular algorithms are Smith-Waterman [44], FASTA [39], and Blast <ref> [1] </ref>. The latter two algorithms are heuristics; the quality of the score is traded for speed. Smith-Waterman is the benchmark algorithm, generating the most reliable scores although at considerable time expense. We used the Smith-Waterman algorithm to compare our performance against previously published numbers in the biochemistry community [14][42].
Reference: [2] <author> H. Bal, J. Steiner, and A. Tanenbaum, </author> <title> Programming Languages for Distributed Computing Systems, </title> <journal> ACM Computing Surveys, pp. </journal> <volume> 261-322, vol. 21, no. 3, </volume> <month> Sept. </month> <year> 1989. </year>
Reference: [3] <author> A. Black, N. Hutchinson, E. Jul, and H. Levy, </author> <title> ``Distribution and Abstract Types in Emerald, </title> <institution> University of Washington, TR 85-08-05, </institution> <month> August, </month> <year> 1985. </year>
Reference: [4] <author> G. Bernard et al., </author> <title> Primitives for Distributed Computing in a Heterogeneous Local Area Network Environment, </title> <journal> IEEE Trans on Soft. Eng. </journal> <volume> vol. 15, no. 12, </volume> <month> December 89. </month>
Reference: [5] <author> B. N. Bershad, and H. M. Levy, </author> <title> Remote Computation in a Heterogeneous Environment. </title> <type> Tech. Rep. </type> <institution> 87-06-04, Dept. of Computer Science, University of Washington, </institution> <address> Seattle, </address> <month> June, </month> <year> 1987. </year>
Reference: [6] <author> B. N. Bershad, et al., </author> <title> A Remote Procedure Call Facility for Interconnecting Heterogeneous Computer Systems, </title> <journal> IEEE Trans. Software. Eng. SE, </journal> <volume> vol. 13, no. 8, </volume> <pages> pp. 880-894, </pages> <month> August, </month> <year> 1987. </year>
Reference: [7] <author> J. Boyle et al., </author> <title> Portable Programs for Parallel Processors, </title> <publisher> Holt, Rinehart and Winston, </publisher> <address> New York, </address> <year> 1987. </year>
Reference: [8] <author> D. Callahan and K. Kennedy, </author> <title> Compiling Programs for Distributed-Memory Multiprocessors The Journal of Supercomputing, </title> <journal> no. </journal> <volume> 2, </volume> <pages> pp. 151-169, </pages> <address> 1988, </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference: [9] <author> N. Carriero and D. Gelernter, </author> <title> Linda in Context, </title> <journal> Communications of the ACM, </journal> <volume> vol. 32, no. 4, </volume> <pages> pp. 444-458, </pages> <month> April, </month> <year> 1989. </year>
Reference: [10] <author> N. Carriero, D. Gelernter, and T.G. Mattson, </author> <title> Linda in Heterogeneous Computing Environments, </title> <booktitle> Proceedings of WHP 92 Workshop on Heterogeneous Processing, </booktitle> <publisher> IEEE Press, </publisher> <pages> pp. 43-46, </pages> <month> March, </month> <year> 1992. </year> <month> 24 </month>
Reference: [11] <author> B. Chapman, P. Mehrotra, and H. Zima, </author> <title> Programming in Vienna Fortran, </title> <journal> Scientific Programming, </journal> <volume> vol. 1, no. 1, </volume> <month> Aug. </month> <year> 1992, </year> <pages> pp. 31-50. </pages>
Reference: [12] <author> A.L.Cheung, and A.P. Reeves, </author> <title> High Performance Computing on a Cluster of Workstations, </title> <booktitle> Proceedings of the First Symposium on High-Performance Distributed Computing, </booktitle> <pages> pp. 152-160, </pages> <month> Sept., </month> <year> 1992. </year>
Reference: [13] <author> R. Chin and S. Chanson, </author> <title> Distributed Object-Based Programming Systems, </title> <journal> ACM Computing Surveys, pp. </journal> <volume> 91-127, vol. 23, no. 1, </volume> <month> March., </month> <year> 1991. </year>
Reference: [14] <author> A. S. Deshpande, D. S. Richards, and W. R. Pearson, </author> <title> A platform for biological sequence comparison of parallel computers, </title> <journal> CABIOS, </journal> <volume> 7, </volume> <pages> pp. 237-247, </pages> <year> 1991. </year>
Reference-contexts: First, the number of open files can rapidly exceed the limits of the operating system. (These limits can be changed by recompiling the a. The CM-2 performance numbers were obtained from <ref> [14] </ref>, the Paragon and DEC Alphas from [42]. TABLE 6 .
Reference: [15] <author> V. Donaldson, F. Berman, and R. Paturi, </author> <title> Program Speedup in a Heterogeneous Computing Network, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 21, </volume> <pages> pp. 316-322, </pages> <year> 1994. </year>
Reference-contexts: Is speedup meaningful in the CWVC? A generalized definition for speedup in a heterogeneous environment is given in <ref> [15] </ref>. In our particular case, we characterize the performance of complib in terms of the number of matrix entries per second obtained.
Reference: [16] <author> F. Ferstl, </author> <title> CODINE Technical Overview, </title> <address> Genias, </address> <month> April, </month> <year> 1993. </year>
Reference: [17] <author> R. F. Freund and D. S. Cornwell, Superconcurrency: </author> <title> A form of distributed heterogeneous supercomputing, </title> <journal> Supercomputing Review, </journal> <volume> Vol. 3, </volume> <month> Oct. </month> <year> 1990, </year> <pages> pp. 47-50. </pages>
Reference: [18] <author> E. Gabber, </author> <title> VMMP: A Practical Tool for the Development of Portable and Efficient Programs for Multiprocessors, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol. 1, No. 3, </volume> <month> July </month> <year> 1990. </year>
Reference: [19] <author> P. B. Gibbond, </author> <title> A Stub Generator for Multi-Language RPC in Heterogeneous Environments, </title> <journal> IEEE Trans. Software. Eng. SE, </journal> <volume> vol. 13, no. 1, </volume> <pages> pp. 77-87, </pages> <month> January, </month> <year> 1987. </year>
Reference: [20] <author> T. P. Green and J. Snyder, DQS, </author> <title> A Distributed Queueing System, </title> <institution> Florida State University, </institution> <month> March </month> <year> 1993. </year>
Reference: [21] <author> A. S. Grimshaw, W. A. Wulf, J. C. French, A.C. Weaver, and Paul Reynolds Jr. Legion: </author> <title> The Next Logical Step Toward a Nationwide Virtual Computer, </title> <institution> Computer Science Technical Report, University of Virginia, </institution> <type> CS 94-21, </type> <month> June, </month> <year> 1994. </year>
Reference-contexts: The Legion project at the University of Virginia is an attempt to provide system services that provide the illusion of a single virtual machine to users, a virtual machine that provides both improved response time via parallel execution and greater throughput <ref> [21] </ref>. Legion is targeted towards both workstation clusters and towards larger, wide-area, assemblies of workstations, supercomputers, and parallel supercomputers. <p> Support for other Models - PVM V 3.0 Clearly we cannot expect all Legion users to use MPL. Other parallel processing languages and models must be supported. This is particularly true for legacy codes. Our plan for legacy code and multiple model interoperability is detailed in <ref> [21] </ref>. One of the early tests for our plan is support for PVM [46]. PVM is a message passing parallel processing system that has gained wide-spread acceptance in the user community, and is a de facto standard.
Reference: [22] <author> A.S. Grimshaw, J.B.Weissman, E.A. West, and E. Loyot, </author> <title> Meta Systems: An Approach Combining Parallel Processing And Heterogeneous Distributed Computing Systems, </title> <journal> Journal of Parallel and Distributed Computing, pp. </journal> <volume> 257-270, vol. 21, no. 3, </volume> <month> June, </month> <year> 1994. </year>
Reference: [23] <author> A. S. Grimshaw, E. A. West, and W.R. Pearson, </author> <title> No Pain and Gain! - Experiences with Mentat on Biological Application, </title> <journal> Concurrency: Practice & Experience, </journal> <pages> pp. 309-328, </pages> <note> Vol. 5, issue 4, </note> <month> July, </month> <year> 1993. </year>
Reference-contexts: This natural data-parallelism is easy to exploit. The main program manipulates three objects, the source genome library, the target genome library, and a recorder object that performs the statistical analysis and saves the results. The application is written in the Mentat programming language and is described in detail in <ref> [23] </ref>. The main program for loop is shown in Figure 3 below. The effect is that a pipe is formed, with sequence extraction from the source, sequence comparison in the target, and statistics generation are executed in a pipelined fashion.
Reference: [24] <author> A. S. Grimshaw, </author> <title> Easy to Use Object-Oriented Parallel Programming with Mentat, </title> <booktitle> IEEE Computer, </booktitle> <pages> pp. 39-51, </pages> <month> May, </month> <year> 1993. </year>
Reference: [25] <author> A. S. Grimshaw, W. T. Strayer, and P. Narayan, </author> <title> Dynamic Object-Oriented Parallel Processing, </title> <booktitle> IEEE Parallel & Distributed Technology: Systems & Applications, </booktitle> <pages> pp. 33-47, </pages> <month> May, </month> <year> 1993. </year>
Reference: [26] <author> A. S. Grimshaw, J. B. Weissman, and W. T. Strayer, </author> <title> Portable Run-Time Support for Dynamic Object-Oriented Parallel Processing, </title> <note> to appear in ACM TOCS, and earlier version is available in Computer Science Technical Report, </note> <institution> CS-93-40, University of Virginia, </institution> <month> July, </month> <year> 1993. </year>
Reference-contexts: The first is the instantiation manager (IM) which is responsible for scheduling, keeping track of all Legion objects on the host, monitoring the load on the system, and other management functions. The second is the token matching unit (TMU) which supports language features <ref> [26] </ref>. The system configuration file (config.db) contains the names of all hosts in Legion 4 . The set of IMs running on those hosts define the system. If an IM goes down then Legion is down on that host.
Reference: [27] <author> P. J. Hatcher, et al, </author> <title> Data-Parallel Programming on MIMD Computers, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> vol. 2, no. 3, </volume> <pages> pp. 377-383. </pages>
Reference: [28] <institution> International Business Machines Corporation, IBM LoadLeveler: </institution> <note> Users Guide., </note> <institution> Kingston, </institution> <address> NY, </address> <month> March </month> <year> 1993. </year>
Reference: [29] <author> J.A. Kaplan and M.L. Nelson, </author> <title> A Comparison of Queueing, Cluster, and Distributed Computing Systems, </title> <type> NASA Technical Memorandum 109025, </type> <institution> NASA LaRC, </institution> <month> October, </month> <year> 1993. </year>
Reference: [30] <editor> Ashfaq Khokhar, et. al., </editor> <booktitle> Heterogeneous Supercomputing: Problems and Issues, Proceedings of WHP 92 Workshop on Heterogeneous Processing, </booktitle> <publisher> IEEE Press, </publisher> <pages> pp. 3-12, </pages> <address> Beverly Hills, CA, </address> <month> March, </month> <year> 1992. </year>
Reference: [31] <author> B. A. Kingsbury, </author> <title> The Network Queueing System, </title> <address> Palo Alto, CA, </address> <month> March </month> <year> 1993. </year>
Reference: [32] <author> E. Levy, and A. Silberschatz, </author> <title> Distributed File Systems: Concepts and Examples, </title> <journal> ACM Computing Surveys, </journal> <volume> vol. 22, No. 4, </volume> <pages> pp. 321-374, </pages> <month> December, 1090. </month>
Reference-contexts: Nevertheless we intend to borrow heavily from early distributed file system projects such as Andrew because issues such as naming, location transparency, fault transparency, replication transparency, and migration have been addressed both in the literature <ref> [32] </ref> and in one or more existing operational systems. Our solution is to construct a federated file system using the local host file systems as the component elements.
Reference: [33] <author> M. Litzkow and M. Livny, </author> <title> Experience with the Condor Distributed Batch System, </title> <booktitle> Proceedings of the IEEE Workshop on Experimental Distributed Systems, </booktitle> <address> Huntsville, AL, </address> <month> October, </month> <year> 1990. </year>
Reference: [34] <author> D. B. Loveman, </author> <title> High Performance Fortran, </title> <journal> IEEE Parallel & Distributed Technology: Systems & Applica 25 tions, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 25-42, </pages> <month> February, </month> <year> 1993. </year>
Reference: [35] <author> J.H. Morris, et al., Andrew: </author> <title> A distributed personal computing environment, </title> <journal> Communications of the ACM, </journal> <volume> vol. 29, no. 3, </volume> <month> March </month> <year> 1986. </year>
Reference: [36] <author> S. Mullender ed., </author> <title> Distributed Systems, </title> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference: [37] <author> N. Nedeljkovic, and M.J. Quinn, </author> <title> Data-Parallel Programming on a Network of Heterogeneous Workstations, </title> <booktitle> Proceedings of the First Symposium on High-Performance Distributed Computing, </booktitle> <pages> pp. 28-36, </pages> <address> Syra-cuse, NY, </address> <month> Sept., </month> <year> 1992. </year>
Reference: [38] <author> J.R. Nicol, C.T. Wilkes, and F.A. Manola, </author> <title> Object-Orientation in Heterogeneous Distributed Systems, </title> <journal> IEEE Computer, vol.26, </journal> <volume> no. 6., </volume> <pages> pp. 57-67, </pages> <month> June, </month> <year> 1993. </year>
Reference: [39] <author> D. Notkin, N., </author> <title> et al.,Heterogeneous Computing Environments: Report on the ACM SIGOPS Workshop on Accommodating Heterogeneity, </title> <journal> Communications of the ACM, </journal> <volume> vol. 30, no. 2, </volume> <pages> pp. 132-140, </pages> <month> February, </month> <year> 1987. </year>
Reference-contexts: Three popular algorithms are Smith-Waterman [44], FASTA <ref> [39] </ref>, and Blast [1]. The latter two algorithms are heuristics; the quality of the score is traded for speed. Smith-Waterman is the benchmark algorithm, generating the most reliable scores although at considerable time expense.
Reference: [40] <author> D. Notkin, et al., </author> <title> Interconnecting Heterogeneous Computer Systems, </title> <journal> Communications of the ACM, </journal> <volume> vol. 31, no. 3, </volume> <pages> pp. 258-273, </pages> <month> March, </month> <year> 1988. </year>
Reference: [41] <author> W. R. Pearson and D. Lipman, </author> <title> Improved tools for biological sequence analysis, </title> <booktitle> Proc. </booktitle> <institution> Natl. Acad. Sci. USA, </institution> <month> 85, </month> <pages> pp. 2444-2448, </pages> <year> 1988. </year>
Reference: [42] <author> W. R. Pearson, </author> <type> Personal communication, </type> <month> February, </month> <year> 1995. </year>
Reference-contexts: First, the number of open files can rapidly exceed the limits of the operating system. (These limits can be changed by recompiling the a. The CM-2 performance numbers were obtained from [14], the Paragon and DEC Alphas from <ref> [42] </ref>. TABLE 6 .
Reference: [43] <editor> R. Rouselle et al., </editor> <booktitle> The Virtual Computing Environment, Proceedings of the Third International Symposium on High Performance Distributed Computing, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> August, </month> <year> 1994. </year>
Reference: [44] <author> T. F. Smith and M. S. Waterman, </author> <title> Identification of common molecular subsequences, </title> <journal> J. Mol. Biol., </journal> <volume> 147, </volume> <pages> pp. 195-197, </pages> <year> 1981. </year>
Reference-contexts: Three popular algorithms are Smith-Waterman <ref> [44] </ref>, FASTA [39], and Blast [1]. The latter two algorithms are heuristics; the quality of the score is traded for speed. Smith-Waterman is the benchmark algorithm, generating the most reliable scores although at considerable time expense.
Reference: [45] <author> Sun Microsystems. </author> <title> External Data Representation Reference Manual. Sun Microsystems, </title> <month> Jan. </month> <year> 1985. </year>
Reference: [46] <author> V.S. Sunderam, </author> <title> PVM: A framework for parallel distributed computing, </title> <journal> Concurrency: Practice and Experience, </journal> <volume> vol. 2(4), </volume> <pages> pp. 315-339, </pages> <month> December, </month> <year> 1990. </year>
Reference-contexts: Other parallel processing languages and models must be supported. This is particularly true for legacy codes. Our plan for legacy code and multiple model interoperability is detailed in [21]. One of the early tests for our plan is support for PVM <ref> [46] </ref>. PVM is a message passing parallel processing system that has gained wide-spread acceptance in the user community, and is a de facto standard.
Reference: [47] <editor> R. N. Taylor, et al., </editor> <booktitle> Foundations for the Arcadia Environment Architecture, Proceedings of the Third ACM SIGSOFT/SIGPLAN Symposium on Practical Software Development, </booktitle>
Reference: [48] <author> M.M. Theimer, and B. Hayes, </author> <title> Heterogeneous Process Migration by Recompilation, </title> <booktitle> Proc. 11th Intl. Conference on Distributed Computing Systems, </booktitle> <address> Arlington, TX, </address> <month> May, </month> <year> 1991, </year> <pages> pp. 18-25. </pages>
Reference: [49] <editor> B. Walker, et al., </editor> <booktitle> The LOCUS Distributed Operating System, Proceedings of the 9th ACM Symposium on Operating Systems Principles (Bretton Woods, </booktitle> <editor> N. H., </editor> <address> Oct.) </address> <publisher> ACM, </publisher> <address> New York, </address> <year> 1983 </year>
Reference: [50] <author> Mu-Cheng Wang, et. al., </author> <title> Augmenting the Optimal Selection Theory for Superconcurrency, </title> <booktitle> Proceedings of WHP 92 Workshop on Heterogeneous Processing, </booktitle> <publisher> IEEE Press, </publisher> <pages> pp. 13-22, </pages> <address> Beverly Hills, CA, </address> <month> March, </month> <year> 1992 </year>
Reference: [51] <author> Min-You Wu, and G.C. Fox, </author> <title> A Test Suite Approach for Fortran90D Compilers on MIMD Distributed Memory Parallel Computers, </title> <booktitle> Proceedings of the First Symposium on High-Performance Distributed Computing, </booktitle> <pages> pp. 393-400, </pages> <address> Syracuse, NY, </address> <month> Sept., </month> <year> 1992. </year>
References-found: 51

