URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR94388-S.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: Give-N-Take A Balanced Code Placement Framework  
Author: Reinhard v. Hanxleden Ken Kennedy 
Address: P.O. Box 1892 Houston, TX 77251-1892  
Affiliation: Rice University  
Note: Center for Research on Parallel Computation  From the Proceedings of the ACM SIGPLAN '94 Conference on Program Language Design and Implementation, Orlando, Florida, June 1994.  
Date: March, 1994  
Pubnum: CRPC-TR94388-S  
Abstract-found: 0
Intro-found: 1
Reference: [AL93] <author> S. P. Amarasinghe and M. S. Lam. </author> <title> Communication optimization and code generation for distributed memory machines. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 28(6) </volume> <pages> 126-138, </pages> <month> June </month> <year> 1993. </year> <booktitle> Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Several researchers have already addressed the communication generation problem, although often restricted to relatively simple array reference patterns. Amarasinghe and Lam optimize communication generation using Last Write Trees <ref> [AL93] </ref>. They assume affine loop bounds and array indices, they do not allow loops within conditionals (such as in Figure 1). Gupta and Schonberg use Available Section Descriptors, computed by interval based data flow analysis, to determine the availability of data on a virtual processor grid [GS93].
Reference: [All70] <author> F. E. Allen. </author> <title> Control flow analysis. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 5(7) </volume> <pages> 1-19, </pages> <year> 1970. </year>
Reference-contexts: It can be used for forward problems (like available expressions) <ref> [All70, Coc70] </ref> and backward problems (like live variables) [Ken71], and it has also been used for code motion [DP93] and incremental analysis [Bur90]. We are using a variant of interval analysis that is based on Tar-jan intervals [Tar74].
Reference: [Bur90] <author> M. Burke. </author> <title> An interval-based approach to exhaustive and incremental interprocedural data-flow analysis. </title> <journal> 13 ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(3) </volume> <pages> 341-395, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: It can be used for forward problems (like available expressions) [All70, Coc70] and backward problems (like live variables) [Ken71], and it has also been used for code motion [DP93] and incremental analysis <ref> [Bur90] </ref>. We are using a variant of interval analysis that is based on Tar-jan intervals [Tar74].
Reference: [CK88] <author> D. Callahan and K. Kennedy. </author> <title> Compiling programs for distributed-memory multiprocessors. </title> <journal> Journal of Supercomputing, </journal> <volume> 2 </volume> <pages> 151-169, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: These and other implementation details on the usage of Give-N-Take for communication generation, like the value number based data flow universe, are described elsewhere [Han93]. If we do not use a strict owner computes rule <ref> [CK88] </ref>, then non-owned data may not only be locally referenced, but also locally defined.
Reference: [CK92] <author> S. Carr and K. Kennedy. </author> <title> Scalar replacement in the presence of conditional control flow. </title> <type> Technical Report TR92283, </type> <institution> Rice University, CRPC, </institution> <month> November </month> <year> 1992. </year> <note> To appear in Software Practice& Experience. </note>
Reference-contexts: Therefore, combinations of dependence analysis and PRE have been used, for example for determining reaching definitions [GS90] or performing scalar replacement <ref> [CK92] </ref>. Duesterwald et al. incorporate iteration distance vectors (assuming regular array references) into an array reference data flow framework, which is then applied to memory optimizations and controlled loop unrolling [DGS93]. Several researchers have already addressed the communication generation problem, although often restricted to relatively simple array reference patterns.
Reference: [CM69] <author> J. Cocke and R. Miller. </author> <title> Some analysis techniques for optimizing computer programs. </title> <booktitle> In Proceedings of the 2nd Annual Hawaii International Conference on System Sciences, </booktitle> <pages> pages 143-146, </pages> <year> 1969. </year>
Reference-contexts: This can be achieved, for example, by node splitting <ref> [CM69] </ref>. * For each non-empty interval T (h), there exists a unique n 2 T (h) such that (n; h) 2 E; i.e., there is only one Cycle edge out of T (h).
Reference: [Coc70] <author> J. Cocke. </author> <title> Global common subexpression elimination. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 5(7) </volume> <pages> 20-24, </pages> <year> 1970. </year>
Reference-contexts: It can be used for forward problems (like available expressions) <ref> [All70, Coc70] </ref> and backward problems (like live variables) [Ken71], and it has also been used for code motion [DP93] and incremental analysis [Bur90]. We are using a variant of interval analysis that is based on Tar-jan intervals [Tar74].
Reference: [DGS93] <author> E. Duesterwald, R. Gupta, and M. L. Soffa. </author> <title> A practical data flow framework for array reference analysis and its use in optimizations. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 28(6) </volume> <pages> 68-77, </pages> <month> June </month> <year> 1993. </year> <booktitle> Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Duesterwald et al. incorporate iteration distance vectors (assuming regular array references) into an array reference data flow framework, which is then applied to memory optimizations and controlled loop unrolling <ref> [DGS93] </ref>. Several researchers have already addressed the communication generation problem, although often restricted to relatively simple array reference patterns. Amarasinghe and Lam optimize communication generation using Last Write Trees [AL93]. They assume affine loop bounds and array indices, they do not allow loops within conditionals (such as in Figure 1).
Reference: [Dha88a] <author> D.M. Dhamdhere. </author> <title> A fast algorithm for code movement optimization. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 23(10) </volume> <pages> 172-180, </pages> <year> 1988. </year>
Reference-contexts: Example applications include common subexpression elimination, loop invariant code motion, and strength reduction. The original dataflow framework for performing PRE was developed by Morel and Renvoise [MR79] and has since then experienced various refinements <ref> [JD82, DS88, Dha88a, Dha91, DRZ92, KRS92] </ref>. <p> However, it may often be possible to shift production to a neighboring non-synthetic node. This can either be done at code generation time, or by post-processing the results of Give-N-Take, in a way that is similar to a mechanism employed in edge-placement <ref> [Dha88a] </ref> for avoiding code proliferation. Our implementation took the latter route, by running a backward pass on G which checks whether these movements can be done without conflicts. 6 Summary This paper has outlined a general code generation framework, based on Tarjan intervals, that handles several different classes of problems.
Reference: [Dha88b] <author> D.M. Dhamdhere. </author> <title> Register assignment using code placement techniques. </title> <journal> Computer Languages, </journal> <volume> 13(2) </volume> <pages> 75-93, </pages> <year> 1988. </year>
Reference-contexts: For example, when placing register loads and stores, certain loads may become redundant with previous definitions. This is generally treated as a special case, for example by developing different, but interdependent sets of equations for loads and stores <ref> [Dha88b] </ref>. Pessimistic loop handling: One difficulty with flow analysis has traditionally been the treatment of loop constructs that allow zero-trip instances, like a Fortran DO loop. Hoisting code out of such loops is generally considered unsafe, as it may introduce statements on paths where they have not existed before. <p> For an After problem, "early" and "late" have to be interchanged. (Classical PRE, for example, can be classified as a Lazy, Before problem.) This means that the same framework can be used for different flavors of problems; there are no separate sets of equations for loads and stores <ref> [Dha88b] </ref>, or for Reads and Writes [GV91]. The rest of this paper is organized as follows. Section 2 introduces the communication generation problem, which will be used as an illustrating example application of Give-N-Take.
Reference: [Dha91] <author> D.M. Dhamdhere. </author> <title> Practical adaptation of the global optimization algorithm of Morel and Renvoise. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(2) </volume> <pages> 291-294, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Example applications include common subexpression elimination, loop invariant code motion, and strength reduction. The original dataflow framework for performing PRE was developed by Morel and Renvoise [MR79] and has since then experienced various refinements <ref> [JD82, DS88, Dha88a, Dha91, DRZ92, KRS92] </ref>.
Reference: [DK83] <author> D.M. Dhamdhere and J.S. Keith. </author> <title> Characterization of program loops in code optimization. </title> <journal> Computer Languages, </journal> <volume> 8 </volume> <pages> 69-76, </pages> <year> 1983. </year>
Reference-contexts: we often would like to hoist computation out of such loops even if the number of iterations is not known at compile time. 1 Several techniques exist to handle zero-trip loops, like for example adding an extra guard and a pre-header node to each loop [Sor89], explicitly introducing zero-trip paths <ref> [DK83] </ref>, or collapsing innermost loops [HKK + 92]. These strategies, however, result in some loss of information due to explicit control flow graph manipulations, and they do not fully apply to nested loops.
Reference: [DP93] <author> D.M. Dhamdhere and H. Patil. </author> <title> An elimination algorithm for bidirectional data flow problems using edge placement. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15(2) </volume> <pages> 312-336, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: It can be used for forward problems (like available expressions) [All70, Coc70] and backward problems (like live variables) [Ken71], and it has also been used for code motion <ref> [DP93] </ref> and incremental analysis [Bur90]. We are using a variant of interval analysis that is based on Tar-jan intervals [Tar74].
Reference: [DRZ92] <author> D.M. Dhamdhere, B.K. Rosen, and F.K. Zadeck. </author> <title> How to analyze large programs efficiently and informatively. </title> <booktitle> In Proceedings of the ACM SIGPLAN '92 Conference on Program Language Design and Implementation, </booktitle> <pages> pages 212-223, </pages> <address> San Francisco, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Example applications include common subexpression elimination, loop invariant code motion, and strength reduction. The original dataflow framework for performing PRE was developed by Morel and Renvoise [MR79] and has since then experienced various refinements <ref> [JD82, DS88, Dha88a, Dha91, DRZ92, KRS92] </ref>.
Reference: [DS88] <author> K. Drechsler and M. Stadel. </author> <title> A solution to a problem with Morel and Renvoise's "Global optimization by suppression of partial redundancies". </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 10(4) </volume> <pages> 635-640, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Example applications include common subexpression elimination, loop invariant code motion, and strength reduction. The original dataflow framework for performing PRE was developed by Morel and Renvoise [MR79] and has since then experienced various refinements <ref> [JD82, DS88, Dha88a, Dha91, DRZ92, KRS92] </ref>.
Reference: [GS90] <author> T. Gross and P. Steenkiste. </author> <title> Structured dataflow analysis for arrays and its use in an optimizing compiler. </title> <journal> Software|Practice and Experience, </journal> <volume> 20(2) </volume> <pages> 133-155, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: Therefore, combinations of dependence analysis and PRE have been used, for example for determining reaching definitions <ref> [GS90] </ref> or performing scalar replacement [CK92]. Duesterwald et al. incorporate iteration distance vectors (assuming regular array references) into an array reference data flow framework, which is then applied to memory optimizations and controlled loop unrolling [DGS93].
Reference: [GS93] <author> M. Gupta and E. Schonberg. </author> <title> A framework for exploiting data availability to optimize communication. </title> <booktitle> In Proceedings of the Sixth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: We assume that these data have to be written back to their owners before they can be used by other processors, as shown in Figure 3. (An alternative would be the direct exchange between a non-owner that writes data and another nonowner that reads them <ref> [GS93] </ref>. <p> They assume affine loop bounds and array indices, they do not allow loops within conditionals (such as in Figure 1). Gupta and Schonberg use Available Section Descriptors, computed by interval based data flow analysis, to determine the availability of data on a virtual processor grid <ref> [GS93] </ref>. They apply (regular) mapping functions to map this information to individual processors and list redundant communication elimination and communication generation as possible applications. Granston and Veidenbaum combine dependence analysis and 3 PRE to detect redundant global memory accesses in parallelized and vectorized codes [GV91].
Reference: [GV91] <author> E. Granston and A. Veidenbaum. </author> <title> Detecting redundant accesses to array data. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <address> Albuquerque, NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: "early" and "late" have to be interchanged. (Classical PRE, for example, can be classified as a Lazy, Before problem.) This means that the same framework can be used for different flavors of problems; there are no separate sets of equations for loads and stores [Dha88b], or for Reads and Writes <ref> [GV91] </ref>. The rest of this paper is organized as follows. Section 2 introduces the communication generation problem, which will be used as an illustrating example application of Give-N-Take. <p> They apply (regular) mapping functions to map this information to individual processors and list redundant communication elimination and communication generation as possible applications. Granston and Veidenbaum combine dependence analysis and 3 PRE to detect redundant global memory accesses in parallelized and vectorized codes <ref> [GV91] </ref>. Their technique tries to eliminate these operations where possible, also across loop nests and in the presence of conditionals, and they eliminate reads of non-owned variables if these variables have already been read or written locally.
Reference: [GW76] <author> S. Graham and M. Wegman. </author> <title> A fast and usually linear algorithm for global data flow analysis. </title> <journal> Journal of the ACM, </journal> <volume> 23(1) </volume> <pages> 172-202, </pages> <month> January </month> <year> 1976. </year>
Reference-contexts: Therefore, GiveNTake has to evaluate each equation only once for each node, which implies guaranteed termination and low computational complexity (it also implies fastness <ref> [GW76] </ref>). However, since the direction of the flow of information varies across the equations, we still need multiple passes over the control flow graph, solving a different set of equations during each pass.
Reference: [Han93] <author> R. v. Hanxleden. </author> <title> Handling irregular problems with Fortran D | A preliminary report. </title> <booktitle> In Proceedings of the Fourth Workshop on Compilers for Parallel Computers, </booktitle> <address> Delft, The Nether-lands, </address> <month> December </month> <year> 1993. </year> <note> D Newsletter #9, available via anonymous ftp from softlib.rice.edu as pub/CRPC-TRs/reports/CRPC-TR93339-S. </note>
Reference-contexts: Communication schedule generation, which is a non-trivial problem in itself [HKK + 92], and the conversion from global to local name space are also excluded. These and other implementation details on the usage of Give-N-Take for communication generation, like the value number based data flow universe, are described elsewhere <ref> [Han93] </ref>. If we do not use a strict owner computes rule [CK88], then non-owned data may not only be locally referenced, but also locally defined.
Reference: [HK93] <author> R. v. Hanxleden and K. Kennedy. </author> <title> A code placement framework and its application to communication generation. </title> <type> Technical Report CRPC-TR93337-S, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> October </month> <year> 1993. </year> <note> Available via anonymous ftp from softlib.rice.edu as pub/CRPC-TRs/reports/CRPC-TR93337-S. </note>
Reference-contexts: Section 5 gives an efficient algorithm for solving the Give-N-Take equations. Section 6 concludes with a brief summary. A discussion of possible extensions, such as the combination of Give-N-Take with dependence analysis, and formal correctness proofs of Give-N-Take can be found elsewhere <ref> [HK93] </ref>. do i = 1; N enddo if test then do j = 1; N enddo do k = 1; N enddo else do l = 1; N enddo endif problem, where the array x is assumed to be distributed or shared. <p> In our specific case, this is more an optimization than a correctness issue.) A special case are zero-trip loop constructs, like a Fortran DO loop. Give-N-Take tries to hoist 4 items out of such loops, unless explicitly told oth-erwise on a general <ref> [HK93] </ref> or case-by-case (Sec tion 4.1) basis. (C3) Sufficiency : For each consumer at node n in the program, there must be a producer on each incoming path reaching n, without any destroyer in between; see Figure 6. (All references to non-owned data must be locally satisfiable due to preceding Reads <p> possible.) (O3) Things are produced as early as possible for Eager, Before and Lazy, After problems; see (O3 0 ) Things are produced as late as possible for Lazy, Before and Eager, After problems; see Note that while the correctness criteria are treated as strict requirements that Give-N-Take must fulfill <ref> [HK93] </ref>, the optimality criteria are viewed more as general guidelines (and are phrased correspondingly vague). 3.3 The Interval Flow Graph A general data flow analysis algorithm that considers loop nesting hierarchies is interval analysis. <p> In our communication problem, this includes an array portion p if either the contents of this portion get modified at n, or if p itself gets changed, for example if p is an indirect array reference and n modifies the indirection array <ref> [HK93] </ref>. 8 STEAL (n) = STEAL init (n) [ STEAL loc (LastChild (n)) (1) GIVE (n) = GIVE init (n) [ GIVE loc (LastChild (n)) (2) BLOCK (n) = STEAL (n) [ GIVE (n) [ [ s2Succs E (n) BLOCK loc (s) (3) TAKEN out (n) = " s2Succs FJS (n) <p> A formal proof that it does indeed obey all ordering constraints, as well as a proof that Give-N-Take meets the correctness constraints (C1), (C2), and (C3), can be found elsewhere <ref> [HK93] </ref>. As already noted, each equation is evaluated only once for each node. Furthermore, each equation depends only on a subset of neighbors.
Reference: [HKK + 92] <author> R. v. Hanxleden, K. Kennedy, C. Koelbel, R. Das, and J. Saltz. </author> <title> Compiler analysis for irregular problems in Fortran D. </title> <editor> In U. Banerjee et al., editor, </editor> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> volume 757, </volume> <pages> pages 97-111. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <month> August </month> <year> 1992. </year> <booktitle> From the Proceedings of the Fifth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> New Haven, CT. </address> <note> Available via anonymous ftp from softlib.rice.edu as pub/CRPC-TRs/reports/CRPC-TR92287-S. </note>
Reference-contexts: hoist computation out of such loops even if the number of iterations is not known at compile time. 1 Several techniques exist to handle zero-trip loops, like for example adding an extra guard and a pre-header node to each loop [Sor89], explicitly introducing zero-trip paths [DK83], or collapsing innermost loops <ref> [HKK + 92] </ref>. These strategies, however, result in some loss of information due to explicit control flow graph manipulations, and they do not fully apply to nested loops. This paper presents a data flow framework, called Give-N-Take, that aims to overcome these limitations in a general context. <p> Note that the examples shown in this paper do not include data declarations, initializations, distribution statements, etc. The communication statements are in a high level format that does not include any schedule parameters, message tags, and so on. Communication schedule generation, which is a non-trivial problem in itself <ref> [HKK + 92] </ref>, and the conversion from global to local name space are also excluded. These and other implementation details on the usage of Give-N-Take for communication generation, like the value number based data flow universe, are described elsewhere [Han93].
Reference: [HKT92a] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Compiler support for machine-independent parallel programming in Fortran D. </title> <editor> In J. Saltz and P. Mehrotra, editors, </editor> <title> Languages, Compilers, and Run-Time Environments for Distributed Memory Machines. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1992. </year>
Reference-contexts: Possible communication placements are shown in Figure 2. 2 A Code Placement Example: Communication Generation An example of code placement is the generation of communication statements when compiling data parallel languages, like Fortran D <ref> [HKT92a] </ref> or High Performance Fortran [KLS + 94]. For example, a processor of a distributed memory machine may reference owned data, which by default reside on the processor, as well as non-owned data, which reside on other processors.
Reference: [HKT92b] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Evaluation of compiler optimizations for Fortran D on MIMD distributed-memory machines. </title> <booktitle> In Proceedings of the 1992 ACM International Conference on Supercomputing, </booktitle> <address> Washington, DC, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Figure 1 shows an example node code containing references to distributed data. Since generating an individual message for each datum to be exchanged would be prohibitively expensive on most architectures, optimizations like message vectorization, latency hiding, and avoiding redundant communication are crucial for achieving acceptable performance <ref> [HKT92b] </ref>. The profitability of such optimizations depends heavily on the actual machine characteristics; however, even for machines with low latencies or shared-memory architectures, the performance can benefit from maximizing reuse and minimizing the total number of shared data accesses. placements for the example from Figure 1.
Reference: [JD82] <author> S.M. Joshi and D.M. Dhamdhere. </author> <title> A composite hoisting-strength reduction transformation for global program optimization, parts I & II. </title> <journal> International Journal of Computer Mathematics, </journal> <volume> 11 </volume> <pages> 21-41, 111-126, </pages> <year> 1982. </year>
Reference-contexts: Example applications include common subexpression elimination, loop invariant code motion, and strength reduction. The original dataflow framework for performing PRE was developed by Morel and Renvoise [MR79] and has since then experienced various refinements <ref> [JD82, DS88, Dha88a, Dha91, DRZ92, KRS92] </ref>.
Reference: [Ken71] <author> K. Kennedy. </author> <title> A global flow analysis algorithm. </title> <journal> International Journal of Computer Mathematics, </journal> <volume> 3 </volume> <pages> 5-15, </pages> <year> 1971. </year>
Reference-contexts: It can be used for forward problems (like available expressions) [All70, Coc70] and backward problems (like live variables) <ref> [Ken71] </ref>, and it has also been used for code motion [DP93] and incremental analysis [Bur90]. We are using a variant of interval analysis that is based on Tar-jan intervals [Tar74].
Reference: [KLS + 94] <author> C. Koelbel, D. Loveman, R. Schreiber, G. Steele, Jr., and M. Zosel. </author> <title> The High Performance Fortran Handbook. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: Possible communication placements are shown in Figure 2. 2 A Code Placement Example: Communication Generation An example of code placement is the generation of communication statements when compiling data parallel languages, like Fortran D [HKT92a] or High Performance Fortran <ref> [KLS + 94] </ref>. For example, a processor of a distributed memory machine may reference owned data, which by default reside on the processor, as well as non-owned data, which reside on other processors.
Reference: [KRS92] <author> J. Knoop, O. Ruthing, and B. Steffen. </author> <title> Lazy code motion. </title> <booktitle> In Proceedings of the ACM SIGPLAN '92 Conference on Program Language Design and Implementation, </booktitle> <address> San Francisco, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Example applications include common subexpression elimination, loop invariant code motion, and strength reduction. The original dataflow framework for performing PRE was developed by Morel and Renvoise [MR79] and has since then experienced various refinements <ref> [JD82, DS88, Dha88a, Dha91, DRZ92, KRS92] </ref>. <p> We will refer to node n as LastChild (h). * There are no critical edges, which connect a node with multiple outgoing edges to a node with multiple incoming edges. This can be achieved, for example, by inserting synthetic nodes <ref> [KRS92] </ref>. Code generated for synthetic nodes would reside in newly created basic blocks, like for example a new else branch or a landing pad for a jump out of a loop.
Reference: [MR79] <author> E. Morel and C. </author> <title> Renvoise. Global optimization by suppression of partial redundancies. </title> <journal> Communications of the ACM, </journal> <volume> 22(2) </volume> <pages> 96-103, </pages> <month> February </month> <year> 1979. </year>
Reference-contexts: 1 Introduction Partial Redundancy Elimination (PRE) is a classical optimization framework for moving and placing code in a program. Example applications include common subexpression elimination, loop invariant code motion, and strength reduction. The original dataflow framework for performing PRE was developed by Morel and Renvoise <ref> [MR79] </ref> and has since then experienced various refinements [JD82, DS88, Dha88a, Dha91, DRZ92, KRS92].
Reference: [MR90] <author> T. Marlowe and B. Ryder. </author> <title> Properties of data flow frameworks. </title> <journal> Acta Informatica, </journal> <volume> 28 </volume> <pages> 121-163, </pages> <year> 1990. </year>
Reference-contexts: Furthermore, whatever has been produced can be consumed arbitrarily often, until it gets destroyed. Data flow frameworks are commonly characterized by a pair hL; F i, where L is a meet semilattice and F is a class of functions (see Marlowe and Ryder <ref> [MR90] </ref> for a discussion of these and other general aspects of data flow frameworks). Roughly speaking, L characterizes the solution space (or universe) of the framework, such as the set of common subexpressions or available constants, and their interrelationships. <p> nodes makes O (N ) = O (E).) However, it has been noted by several researchers that for typical programs, both the average out-degree of flow graph nodes and the maximal loop nesting depth can be assumed to be bounded by small constant independent of the size of the program <ref> [MR90] </ref>. Therefore, the increase of G should be The dashed nodes are synthetic nodes inserted to break critical edges. The dashed edge (2; 10) is a Synthetic edge caused by Jump edge (4; 10) (since 4 2 T (2)).
Reference: [RP86] <author> B.G. Ryder and M.C. Paull. </author> <title> Elimination algorithms for data flow analysis. </title> <journal> ACM Computing Surveys, </journal> <volume> 18 </volume> <pages> 77-316, </pages> <year> 1986. </year>
Reference-contexts: Right: possible solution obeying correctness criterion C1. solution obeying C2. solution obeying C3. 5 solution obeying O1. solution obeying O2. solution obeying O3. solution obeying O3 0 . intervals reflect the loop structure more closely than Allen-Cocke intervals <ref> [RP86] </ref>. Note that a node nested in multiple loops is a member of the Tarjan interval of the header of each enclosing loop. Unlike in classical interval analysis, we do not explicitly construct a sequence of graphs in which intervals are recursively collapsed into single nodes.
Reference: [Sor89] <author> A. Sorkin. </author> <title> Some comments on "A solution to a problem with Morel and Renvoise's `Global optimization by suppression of partial redundancies'". </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(4) </volume> <pages> 666-668, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: introducing a division by zero), we often would like to hoist computation out of such loops even if the number of iterations is not known at compile time. 1 Several techniques exist to handle zero-trip loops, like for example adding an extra guard and a pre-header node to each loop <ref> [Sor89] </ref>, explicitly introducing zero-trip paths [DK83], or collapsing innermost loops [HKK + 92]. These strategies, however, result in some loss of information due to explicit control flow graph manipulations, and they do not fully apply to nested loops.
Reference: [Tar74] <author> R. E. Tarjan. </author> <title> Testing flow graph reducibility. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 9 </volume> <pages> 355-365, </pages> <year> 1974. </year> <month> 14 </month>
Reference-contexts: It can be used for forward problems (like available expressions) [All70, Coc70] and backward problems (like live variables) [Ken71], and it has also been used for code motion [DP93] and incremental analysis [Bur90]. We are using a variant of interval analysis that is based on Tar-jan intervals <ref> [Tar74] </ref>. Like Allen-Cocke intervals, a Tar-jan interval T (h) is a set of control flow nodes that corresponds to a loop in the program text, entered through a unique header node h, where h 62 T (h). <p> We also define Header (n) = m if n is the sink of an Entry edge originating in m (otherwise, Header (n) = ;). Note that Cycle and Jump edges correspond to Tar-jan's cycle and cross edges, respectively <ref> [Tar74] </ref>. However, we divide his forward edges into Forward and Entry edges depending on whether they enter an interval or not (while others divide them into forward and tree edges depending on whether they are part of an embedded tree or not).
References-found: 33

