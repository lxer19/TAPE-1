URL: ftp://multimedia.cc.gatech.edu/papers/Mercator/UIST94.ps
Refering-URL: http://www.cs.gatech.edu/gvu/multimedia/mercator/mercator.html
Root-URL: 
Email: keith@cc.gatech.edu, beth@cc.gatech.edu  
Title: An Architecture for Transforming Graphical Interfaces issues of translating an interactive, spatially presented, visually-dense interface
Author: W. Keith Edwards and Elizabeth D. Mynatt 
Keyword: Auditory interfaces, GUIs, X, visual impairment, multimodal interfaces.  
Note: Much has happened since November 1992. Both formal and  
Address: Atlanta, GA 30332-0280  
Affiliation: Graphics, Visualization, and Usability Center College of Computing Georgia Institute of Technology  
Abstract: During UIST 1992, we presented a set of strategies for mapping graphical interfaces into auditory interfaces primarily with the aim of providing access for blind users [ME92]. These strategies, implemented in a system called Mercator, demonstrated a scheme for monitoring X Windows [Sch87] applications transparently to both the applications and the X Windows environment. Guidelines for creating a complex auditory version of the graphical interface using auditory icons and hierarchical navigation were also introduced. designing these hooks which were accepted by the X ABSTRACT While graphical user interfaces have gained much popularity in recent years, there are situations when the need to use existing applications in a nonvisual modality is clear. Examples of such situations include the use of applications on hand-held devices with limited screen space (or even no screen space, as in the case of telephones), or users with visual impairments. We have developed an architecture capable of transforming the graphical interfaces of existing applications into powerful and intuitive nonvisual interfaces. Our system, called Mercator, provides new input and output techniques for working in the nonvisual domain. Navigation is accomplished by traversing a hierarchical tree representation of the interface structure. Output is primarily auditory, although other output modalities (such as tactile) can be used as well. The mouse, an inherently visually-oriented device, is replaced by keyboard and voice interaction. Our system is currently in its third major revision. We have gained insight into both the nonvisual interfaces presented by our system and the architecture necessary to construct such interfaces. This architecture uses several novel techniques to efficiently and flexibly map graphical interfaces into new modalities. 
Abstract-found: 1
Intro-found: 1
Reference: [BBV90] <author> L.H. Boyd, W.L. Boyd, </author> <title> and G.C. Vander-heiden. The graphical user interface: Crisis, </title> <journal> danger and opportunity. Journal of Visual Impairment and Blindness, </journal> <pages> pages 496502, </pages> <month> December </month> <year> 1990. </year>
Reference: [Bur92] <author> David Burgess. </author> <title> Low Cost Sound Spatilization. </title> <booktitle> In UIST 92: The Fifth Annual Symposium on User Interface Software and Technology and Technology, </booktitle> <month> November </month> <year> 1992. </year>
Reference-contexts: In our previous release, the non-speech audio server ran only on DSP-equipped workstations (either a NeXT machine or a Sun SPARCstation equipped with an Ariel DSP board). The current system will run on any Sun SPARCstation, although a SPARCstation 10 or better is required for spatialization <ref> [Bur92] </ref>. We are undertaking a commercialization effort to bring our work to the potential users of such a system. FUTURE ISSUES There are several new directions we wish to pursue with both the Mercator interface and the Mercator implementation. Our current implementation of the Mercator core is single-threaded.
Reference: [Bux86] <author> William Buxton. </author> <booktitle> Human interface design and the handicapped user. In CHI86 Conference Proceedings, </booktitle> <pages> pages 291297, </pages> <year> 1986. </year>
Reference: [Gav89] <author> William W. Gaver. </author> <title> The sonicfinder: An interface that uses auditory icons. Human Computer Interaction, </title> <address> 4:6794, </address> <year> 1989. </year>
Reference-contexts: In general, the blind user is allowed to interact with the graphical interface independent of its spatial presentation. The contents of the application interface are conveyed through the use of speech and nonspeech audio. The first Mercator system established the use of auditory icons <ref> [Gav89] </ref> and filtears [LC91] to convey the type of an object and its attributes. For example, a text-entry field is represented by the sound of an old-fashioned typewriter, while a text field which is not editable (such as an error message bar) is represented by the sound of a printer.
Reference: [LC91] <author> Lester F. Ludwig and Michael Cohen. </author> <title> Multidimensional audio window management. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> Volume 34, Number 3, </volume> <pages> pages 319-336, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: In general, the blind user is allowed to interact with the graphical interface independent of its spatial presentation. The contents of the application interface are conveyed through the use of speech and nonspeech audio. The first Mercator system established the use of auditory icons [Gav89] and filtears <ref> [LC91] </ref> to convey the type of an object and its attributes. For example, a text-entry field is represented by the sound of an old-fashioned typewriter, while a text field which is not editable (such as an error message bar) is represented by the sound of a printer.
Reference: [My94] <author> Mynatt, E.D., </author> <title> Mapping GUIs to Auditory Interfaces, </title> <editor> In Kramer G. (ed), </editor> <title> Auditory Display: </title> <booktitle> The Proceedings of ICAD 92. SFI Studies in the Sciences of Complexity Proc. </booktitle> <volume> Vol. </volume> <pages> XVIII, </pages> <publisher> Addison-Wesley, </publisher> <month> April </month> <year> 1994. </year>
Reference: [ME92] <author> Elizabeth Mynatt and W. Keith Edwards. </author> <title> Mapping GUIs to Auditory Interfaces. </title> <booktitle> In UIST 92: The Fifth Annual Symposium on User Interface Software and Technology Conference Proceedings, </booktitle> <month> November </month> <year> 1992. </year>
Reference-contexts: Previous Mercator papers have discussed the preferred use of audio output for North American users, as well as the object model for the auditory interface <ref> [ME92] </ref>. In short, information about the graphical interface is modeled in a tree-structure which represents the graphical objects in the interface (push buttons, menus, large text areas and so on) and the hierarchical relationships between those objects. The blind users interaction is based on this hierarchical model.
Reference: [MW94] <author> Elizabeth Mynatt and Gerhard Weber. </author> <title> Nonvisual Presentation of Graphical User Interfaces: Contrasting Two Approaches, </title> <booktitle> in the Proceedings of the ACM Conference on Human Factors in Computing Systems, </booktitle> <year> 1994. </year>
Reference: [Ous90] <author> J.K. Ousterhout. </author> <title> TCL: An Embeddable Command Language, </title> <booktitle> in the Proceedings of the 1990 Winter USENIX Conference, </booktitle> <pages> pp. 133-146. </pages>
Reference-contexts: The interpreted approach has the benefit that we can quickly experiment with new auditory interfaces without having to recompile the system. It also allows easy customization of interfaces by users and administrators. The interpreted language is based on TCL (the Tool Command Language <ref> [Ous90] </ref>), with extensions specific to Mercator. TCL is a light-weight language complete with data types such as lists and arrays, subroutines, and a variety of control flow primitives, so Mercator rules have available to them all of the power of a general-purpose programming language.
Reference: [Pet91] <author> Chris D. Peterson. </author> <title> Editres-a graphical resource editor for x toolkit applications. </title> <booktitle> In Conference Proceedings, Fifth Annual X Technical Conference, </booktitle> <address> Boston, Massachusetts, </address> <month> January, </month> <year> 1991. </year>
Reference-contexts: Our first system also used the Editres widget customization protocol which Internal External Hybrid Early Mercator SystemCurrent Mercator System (Modify Applications) (Modify Toolkits) (Use Only Existing Facilities) Per-application Access Systems FIGURE 1. A Spectrum of Solutions for Information Capture appeared in X11R5 <ref> [Pet91] </ref>, but we found that Editres was insufficient for all our needs. The use of these approaches was the only practical solution available to us in our first system, however, because of our requirement for application transparency.
Reference: [Sch87] <author> Robert W. Scheier. </author> <title> X window system protocol specification, </title> <type> version 11. </type> <institution> Massachusetts Institute of Technology, Cambridge, Massa-chusetts, and Digital Equipment Corporation, Maynard, Massachusetts, </institution> <year> 1987. </year>
Reference: [Ste86] <author> Stefik, M.J., Bobrow, D.G., and Kahn, K.M. </author> <title> Integrating Access-Oriented Programming into a Multiparadigm Environment. </title> <booktitle> IEEE Software, </booktitle> <address> 3,1, </address> <publisher> IEEE Press, </publisher> <month> January, </month> <year> 1986, </year> <pages> 10-18. </pages>
Reference-contexts: The call-out to actions occurs automatically whenever the data store is updated. This technique is reminiscent of access-oriented programming systems, in which changing a system variable causes some code to be run <ref> [Ste86] </ref>. Here is an example of an extremely simple action. This action is defined as a TCL procedure with four arguments: the name of the application, its class, the initial current location within that application, and an ID token which can be used to programmatically refer to the application.
References-found: 12

