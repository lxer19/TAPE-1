URL: http://choices.cs.uiuc.edu/sane/cacm.ps.gz
Refering-URL: http://choices.cs.uiuc.edu/sane/home.html
Root-URL: http://www.cs.uiuc.edu
Email: froy,jcoomes,dave,ycli,liao,sblim,tinq,raila,roush,sane,sefika,singhai,stang@cs.uiuc.edu  
Title: Customizable Object-Oriented Operating Systems  
Author: Roy H. Campbell John Coomes Amitabh Dave Yongcheng Li Willy S. Liao Swee Lim Tin Qian David K. Raila Ellard Roush Aamod Sane Mohlalefi Sefika Ashish Singhai See-Mong Tan 
Date: December 6, 1995  
Address: 1304 W. Springfield Urbana, IL 61801  
Affiliation: Department of Computer Science University of Illinois at Urbana-Champaign Digital Computer Laboratory  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Richard Rashid. </author> <title> Threads of a New System. UNIX Review, </title> <year> 1986. </year>
Reference-contexts: Many modern operating systems allow customization of some aspects of system behavior. Several operating system kernels have system primitives that explicitly allow user-level programs to hook into the flow of control of system activities. An example is user-level pagers in Mach <ref> [1] </ref> and Spring [2]. Mach's virtual memory architecture allows the association of memory regions with user-level programs that are invoked through interprocess communications whenever events of interest, such as page-ins and page-outs, occur in that region. <p> It extends Choices by supporting embeddable scripts for customization. The system can be dynamically customized via the addition and modification of scripts at run time. Customization in existing operating systems, including Choices, are restricted to compile time modifications. For example, in systems like Mach <ref> [1] </ref>, V++[36], SPIN [37] and Apertos [38], application-specific meta-level policies are implemented by user-provided compiled code. The Synthesis [39] kernel and its offspring, Synthetix [40], adopt a less conventional customization strategy that incorporates run-time code generation.
Reference: [2] <author> J. Mitchell et al. </author> <title> An Overview of the Spring System. </title> <booktitle> In Proceedings of Compcon 'Spring 1994, </booktitle> <month> February </month> <year> 1994. </year>
Reference-contexts: Many modern operating systems allow customization of some aspects of system behavior. Several operating system kernels have system primitives that explicitly allow user-level programs to hook into the flow of control of system activities. An example is user-level pagers in Mach [1] and Spring <ref> [2] </ref>. Mach's virtual memory architecture allows the association of memory regions with user-level programs that are invoked through interprocess communications whenever events of interest, such as page-ins and page-outs, occur in that region. Ease of design and efficiency of implementation determine how successfully an operating system can be customized.
Reference: [3] <author> Roy Campbell, Nayeem Islam, Peter Madany, and David Raila. </author> <title> Designing and Implementing Choices:an Object-Oriented System in C++. </title> <journal> Communications of the ACM, </journal> <month> September </month> <year> 1993. </year>
Reference-contexts: Ease of design and efficiency of implementation determine how successfully an operating system can be customized. This article offers our solution to the problem of building customizable operating systems and describes the results achieved in implementing a customizable operating system. We have built an object-oriented, customizable operating system, Choices <ref> [3, 4] </ref>. We advocate object-oriented programming to structure customizable operating systems, and Choices is designed as an interacting collection of object frameworks. Descriptions of Choices, of framework methodology and its application to OS subsystems is given in the next section. <p> Relational queries allow selective scrutiny of special groups of objects respecting user-selectable properties and attributes. * Choices permits new services to be automatically loaded in the system as needed by application and system programs without rebooting the kernel <ref> [3] </ref>. OS View allows scanning or browsing of all the currently loaded services and their corresponding classes and class hierarchies.
Reference: [4] <author> Roy H. Campbell and Nayeem Islam. </author> " <title> Choices: A Parallel Object-Oriented Operating System". </title> <editor> In Gul Agha, Peter Wegner, and Akinori Yonezawa, editors, </editor> <booktitle> Research Directions in Concurrent Object-Oriented Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: Ease of design and efficiency of implementation determine how successfully an operating system can be customized. This article offers our solution to the problem of building customizable operating systems and describes the results achieved in implementing a customizable operating system. We have built an object-oriented, customizable operating system, Choices <ref> [3, 4] </ref>. We advocate object-oriented programming to structure customizable operating systems, and Choices is designed as an interacting collection of object frameworks. Descriptions of Choices, of framework methodology and its application to OS subsystems is given in the next section. <p> The message passing system provides a uniform model for parallel programming on all these platforms <ref> [9, 4, 13, 14] </ref>. The hardware features that the message passing system can exploit to provide high performance vary widely between shared memory multiprocessors and networks of workstations and seem to require separate implementations of the system.
Reference: [5] <author> Douglis and Ousterhout. </author> <title> Transparent process migration: Design alternatives and the Sprite implementation. </title> <journal> Software Practice and Experience, </journal> <volume> 21(8) </volume> <pages> 757-786, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: For example, Choices achieves a process migration latency of 13.9 ms with SPARCStation 2s on Ethernet, due in part to framework design that identified and eliminated unnecessary operations from the critical path. By contrast, Sprite <ref> [5] </ref> has a migration latency of 330 ms on SparcStation 1s on Ethernet. Using these object-oriented techniques we have implemented three different customizable subsystems in Choices: file systems, message passing and distributed shared memory. <p> On a SPARCStation 2 it takes 13.9 ms to migrate an application process over a local area ethernet [10]. The Sprite operating system achieves the next fastest result found in the literature on comparable hardware, at a latency of 330 ms on a SparcStation 1 over Ethernet <ref> [5] </ref>. Choices process migration uses a new algorithm (called the Freeze Free Algorithm [10]) that sends only the absolute minimum state necessary to begin process execution on the destination host.
Reference: [6] <author> V. S. Sunderam. </author> <title> PVM: A framework for parallel distributed computing. </title> <journal> Concurrency, Practice and Experience, </journal> <volume> 2(4) </volume> <pages> 315-340, </pages> <month> [12] </month> <year> 1990. </year>
Reference-contexts: In the Intel Hypercube (a message-passing multiprocessor machine), customizing the message passing framework for both the hardware and the application's communication patterns reduces execution time by 21% in an eight-node machine over that with PVM <ref> [6] </ref>. Customized policies in the Choices adaptive file-caching service resulted in a five-fold speedup for a large-scale parallel computation over Sun NFS.
Reference: [7] <author> Bjarne Stroustrup. </author> <title> The C++ Programming Language. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1986. </year>
Reference-contexts: Finally, we conclude our article with discussion of directions for our future work. 2 Frameworks and Subsystems in Choices Customization in Choices is achieved using frameworks and subsystems implemented in C++ <ref> [7] </ref>. A framework implements the design for software components that operate together to perform an action or set of actions. Frameworks in Choices encapsulate abstract design solutions for specific features of the system. Frameworks are reusable, customizable, and provide a specific interface and a reusable implementation.
Reference: [8] <author> L. Peter Deutsch. </author> <title> Design Reuse and Frameworks in the Smalltalk-80 Programming System. </title> <editor> In Ted J. Biggerstaff and Alan J. Perlis, editors, </editor> <booktitle> Software Reusability, </booktitle> <volume> volume II, </volume> <pages> pages 55-71. </pages> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference-contexts: There are frameworks for the process subsystem, the virtual memory subsystem, the message passing system [9] and so forth. Frameworks specify the interactions that are permitted between components and their relationships to each other <ref> [8] </ref>. The interfaces that the frameworks in Choices export to clients define a contract between the framework and the programmer. The framework agrees to perform its function on the objects provided by the client and the client agrees to customize the objects in particular ways specified by the framework. <p> Since subclasses must obey the framework specifications for behavior by providing the same interface to other framework objects, they can be inserted easily into an existing design <ref> [8] </ref>. Customization by subclassing is a common theme in this paper and in good object-oriented framework design. Oject-oriented programming facilitates incremental specialization and refinement of object behavior via subclassing, and these properties carry over into frameworks.
Reference: [9] <author> N. Islam. </author> <title> Customized Message Passing and Scheduling for Parallel and Distributed Applications. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1994. </year>
Reference-contexts: Every logical or physical system entity, such as CPUs, disks, memory, schedulers, address spaces, locks, and so forth is represented as a C++ object belonging to a C++ class in a framework within Choices. There are frameworks for the process subsystem, the virtual memory subsystem, the message passing system <ref> [9] </ref> and so forth. Frameworks specify the interactions that are permitted between components and their relationships to each other [8]. The interfaces that the frameworks in Choices export to clients define a contract between the framework and the programmer. <p> The message passing system provides a uniform model for parallel programming on all these platforms <ref> [9, 4, 13, 14] </ref>. The hardware features that the message passing system can exploit to provide high performance vary widely between shared memory multiprocessors and networks of workstations and seem to require separate implementations of the system. <p> Buffering strategies including single copy, double copy and copy by reference are implemented by the classes of the Data Transfer framework. Experimental results have shown that the copying strategy is an application specific parameter that can have a significant impact on application performance <ref> [9] </ref>. The Network I/O framework provides an interface to the network the message passing system is being run on. The message passing framework allows customizability at a fine grain as well as a coarse grain. <p> Figure 3 gives analytical results which document the number of network messages, network interrupts and send buffers required to reliably implement the communication required by the Simplex application on an unreliable network with multicast capability when using PVM, Amoeba, and Choices <ref> [9] </ref>. Both PVM and Amoeba are examples of systems not designed for customizability. PVM cannot be customized to use hardware multicast and therefor uses simple sends to implement multicast increasing the message and interrupt count. PVM also acknowledges each application message individually.
Reference: [10] <author> Ellard Roush. </author> <title> The Freeze Free Algorithm for Process Migration. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <note> Expected in May 1995. </note>
Reference-contexts: Our experience with process migration shows that the organization required by object-oriented frameworks actually has substantial benefits. 2.2 Framework Performance Benefits: Process Migration Choices supports very low-latency process migration. On a SPARCStation 2 it takes 13.9 ms to migrate an application process over a local area ethernet <ref> [10] </ref>. The Sprite operating system achieves the next fastest result found in the literature on comparable hardware, at a latency of 330 ms on a SparcStation 1 over Ethernet [5]. Choices process migration uses a new algorithm (called the Freeze Free Algorithm [10]) that sends only the absolute minimum state necessary <p> an application process over a local area ethernet <ref> [10] </ref>. The Sprite operating system achieves the next fastest result found in the literature on comparable hardware, at a latency of 330 ms on a SparcStation 1 over Ethernet [5]. Choices process migration uses a new algorithm (called the Freeze Free Algorithm [10]) that sends only the absolute minimum state necessary to begin process execution on the destination host. The organization of kernel state required in framework design in Choices dramatically speeds up the excision and insertion of process state from the kernel.
Reference: [11] <author> A. Goscinski. </author> <title> Distributed Operating Systems: The Logical Design. </title> <publisher> Addison-Wesley, </publisher> <address> Sydney, Australia, </address> <year> 1991. </year>
Reference-contexts: The organization of kernel state required in framework design in Choices dramatically speeds up the excision and insertion of process state from the kernel. Results show that a system such as Accent <ref> [11] </ref> spends on average 17.5% of overall migration latency simply excising process state from different parts of the system [12]. In contrast Choices spends only 3.6% of overall migration latency for the combined time to excise at the old 3 host and to insert at the new host.
Reference: [12] <author> Zayas. </author> <title> The Use of Copy-on-Reference in a Process Migration System. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1987. </year> <note> also Technical Report CMU-CS-87-121. </note>
Reference-contexts: Results show that a system such as Accent [11] spends on average 17.5% of overall migration latency simply excising process state from different parts of the system <ref> [12] </ref>. In contrast Choices spends only 3.6% of overall migration latency for the combined time to excise at the old 3 host and to insert at the new host.
Reference: [13] <author> Nayeem Islam, Robert E. McGrath, and Roy Campbell. </author> <title> "Parallel Distributed Application Performance and Message Passing: A case study". In Symposium on Experiences with Distributed and Multiprocessor Systems (SEDMS IV), </title> <address> San Diego, California, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: The message passing system provides a uniform model for parallel programming on all these platforms <ref> [9, 4, 13, 14] </ref>. The hardware features that the message passing system can exploit to provide high performance vary widely between shared memory multiprocessors and networks of workstations and seem to require separate implementations of the system.
Reference: [14] <author> Nayeem Islam and Roy H. Campbell. </author> <title> "Design Considerations for Shared Memory Multiprocessor Message Systems". </title> <journal> In IEEE Transactions on Parallel and Distributed Systems, </journal> <month> November </month> <year> 1992. </year>
Reference-contexts: The message passing system provides a uniform model for parallel programming on all these platforms <ref> [9, 4, 13, 14] </ref>. The hardware features that the message passing system can exploit to provide high performance vary widely between shared memory multiprocessors and networks of workstations and seem to require separate implementations of the system.
Reference: [15] <author> Kai Li and Paul Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: Similarly, if two processors modify their caches simultaneously, the implementation must choose between the values written. Various solutions to these two problems differentiate distributed shared memory systems: Kai Li's pioneering system used a single-writer per page policy <ref> [15] </ref>, Munin introduced weak consistency models [16, 17], and recent research considers other models and implementation techniques [18, 19, 20, 21, 22]. In our work, we have investigated three aspects: architectures for building protocols [23], correctness of protocols [24, 25], and distributed memory models for high-latency networks [26].
Reference: [16] <author> John B. Carter, John K. Bennet, and Willy Zwaenepoel. </author> <title> Techniques for reducing consistency-related communication in distributed shared memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <note> 1995. To appear. </note>
Reference-contexts: Similarly, if two processors modify their caches simultaneously, the implementation must choose between the values written. Various solutions to these two problems differentiate distributed shared memory systems: Kai Li's pioneering system used a single-writer per page policy [15], Munin introduced weak consistency models <ref> [16, 17] </ref>, and recent research considers other models and implementation techniques [18, 19, 20, 21, 22]. In our work, we have investigated three aspects: architectures for building protocols [23], correctness of protocols [24, 25], and distributed memory models for high-latency networks [26].
Reference: [17] <author> Honghui Lu, Sandhya Dawrkadas, Alan L. Cox, and Willy Zwaenepoel. </author> <title> Message passing versus distributed shared memory on networks of workstations. </title> <booktitle> In Proceedings of Supercomputing '95, </booktitle> <month> December </month> <year> 1995. </year> <note> To appear. 14 </note>
Reference-contexts: Similarly, if two processors modify their caches simultaneously, the implementation must choose between the values written. Various solutions to these two problems differentiate distributed shared memory systems: Kai Li's pioneering system used a single-writer per page policy [15], Munin introduced weak consistency models <ref> [16, 17] </ref>, and recent research considers other models and implementation techniques [18, 19, 20, 21, 22]. In our work, we have investigated three aspects: architectures for building protocols [23], correctness of protocols [24, 25], and distributed memory models for high-latency networks [26]. <p> In all three experiments, we compare performance with applications with and without adaptive coordinators (this corresponds to lazy release consistency <ref> [17] </ref>). Noticeable improvement occurs for SOR (Successive Over Relaxation) only with XUNET since barrier synchronization is not very expensive with local area networks.
Reference: [18] <author> Divyakant Agrawal, Manhoi Choy, Hong Va Lenong, and Ambuj K. Singh. </author> <title> Mixed consistency: A model for paralle programming. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 101-110, </pages> <year> 1994. </year>
Reference-contexts: Various solutions to these two problems differentiate distributed shared memory systems: Kai Li's pioneering system used a single-writer per page policy [15], Munin introduced weak consistency models [16, 17], and recent research considers other models and implementation techniques <ref> [18, 19, 20, 21, 22] </ref>. In our work, we have investigated three aspects: architectures for building protocols [23], correctness of protocols [24, 25], and distributed memory models for high-latency networks [26].
Reference: [19] <author> B. N. Bershad and M. J. Zekauskas. Midway: </author> <title> Shared memory parallel programming with entry consistency for distributed memory multiprocessors. </title> <type> Technical Report CMU-CS-91-170, </type> <institution> Carnegie Mellon University, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: Various solutions to these two problems differentiate distributed shared memory systems: Kai Li's pioneering system used a single-writer per page policy [15], Munin introduced weak consistency models [16, 17], and recent research considers other models and implementation techniques <ref> [18, 19, 20, 21, 22] </ref>. In our work, we have investigated three aspects: architectures for building protocols [23], correctness of protocols [24, 25], and distributed memory models for high-latency networks [26].
Reference: [20] <author> Matthew Zekauskas, Wayne A. Sawdon, and Brian N. Bershad. </author> <title> Software write detection for a distributed shared memory. </title> <booktitle> In Operating Systems Design and Implementation (OSDI), </booktitle> <year> 1994. </year>
Reference-contexts: Various solutions to these two problems differentiate distributed shared memory systems: Kai Li's pioneering system used a single-writer per page policy [15], Munin introduced weak consistency models [16, 17], and recent research considers other models and implementation techniques <ref> [18, 19, 20, 21, 22] </ref>. In our work, we have investigated three aspects: architectures for building protocols [23], correctness of protocols [24, 25], and distributed memory models for high-latency networks [26].
Reference: [21] <author> Kirk L. Johnson, M. Frans Kaashoek, and Deborah A. Wallach. </author> <title> Crl: High-performance all-software distributed shared memory. </title> <booktitle> In Proceedings of the ACM Symposium on Operating System Principles, </booktitle> <year> 1995. </year>
Reference-contexts: Various solutions to these two problems differentiate distributed shared memory systems: Kai Li's pioneering system used a single-writer per page policy [15], Munin introduced weak consistency models [16, 17], and recent research considers other models and implementation techniques <ref> [18, 19, 20, 21, 22] </ref>. In our work, we have investigated three aspects: architectures for building protocols [23], correctness of protocols [24, 25], and distributed memory models for high-latency networks [26].
Reference: [22] <author> Ranjit John and Mustaque Ahamad. </author> <title> Evaluation of causal distributed shared memory for data-race-free programs. </title> <type> Technical Report GIT-CC-94/34, </type> <institution> Georgia Institute of Technology, </institution> <year> 1994. </year>
Reference-contexts: Various solutions to these two problems differentiate distributed shared memory systems: Kai Li's pioneering system used a single-writer per page policy [15], Munin introduced weak consistency models [16, 17], and recent research considers other models and implementation techniques <ref> [18, 19, 20, 21, 22] </ref>. In our work, we have investigated three aspects: architectures for building protocols [23], correctness of protocols [24, 25], and distributed memory models for high-latency networks [26].
Reference: [23] <author> Aamod Sane and Roy H. Campbell. </author> <title> Object-oriented state machines: Subclassing, composition, delegation and genericity. </title> <booktitle> In Proceedings of the Conference on Object-Oriented Programming Systems, Languages and Applications (OOPSLA'95), </booktitle> <pages> pages 17-32, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: In our work, we have investigated three aspects: architectures for building protocols <ref> [23] </ref>, correctness of protocols [24, 25], and distributed memory models for high-latency networks [26]. <p> In general, we would like to use all standard object-oriented constructions such as subclassing, composition or delegation with state machines, and would like to reason about substitutability. Object-oriented state machines <ref> [23] </ref> were developed to achieve systematic code reuse for protocols. In Choices, such machines structure the interaction of the virtual memory system with the rest of the system.
Reference: [24] <author> Aamod Sane and Roy H. Campbell. </author> <title> Compiling knowledge based programs. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Distributed Computing 1995, </booktitle> <pages> pages 268-268, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: In our work, we have investigated three aspects: architectures for building protocols [23], correctness of protocols <ref> [24, 25] </ref>, and distributed memory models for high-latency networks [26]. <p> In short, just as it is argued that the standard shared memory is overly consistent, we argue that traditional synchronization constructs are overly conservative. A principled approach to analyzing and exploiting patterns in synchronization is suggested based on the logic of knowledge <ref> [24, 25] </ref>, which enables us to formalize and reason about statements involving what one process knows about another. We use a notion of coordinators [26] to explore the fine details of traditional synchronization constructs. A prototype implementation has shown the effectiveness of this approach.
Reference: [25] <author> Aamod Sane. </author> <title> Synthesizing process interaction protocols. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> November </month> <year> 1995. </year> <note> Submitted for publication. </note>
Reference-contexts: In our work, we have investigated three aspects: architectures for building protocols [23], correctness of protocols <ref> [24, 25] </ref>, and distributed memory models for high-latency networks [26]. <p> In short, just as it is argued that the standard shared memory is overly consistent, we argue that traditional synchronization constructs are overly conservative. A principled approach to analyzing and exploiting patterns in synchronization is suggested based on the logic of knowledge <ref> [24, 25] </ref>, which enables us to formalize and reason about statements involving what one process knows about another. We use a notion of coordinators [26] to explore the fine details of traditional synchronization constructs. A prototype implementation has shown the effectiveness of this approach.
Reference: [26] <author> Aamod Sane and Roy Campbell. </author> <title> Coordinated memory: A distributed memory model and its implementation on a gigabit network. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> October </month> <year> 1995. </year>
Reference-contexts: In our work, we have investigated three aspects: architectures for building protocols [23], correctness of protocols [24, 25], and distributed memory models for high-latency networks <ref> [26] </ref>. <p> A principled approach to analyzing and exploiting patterns in synchronization is suggested based on the logic of knowledge [24, 25], which enables us to formalize and reason about statements involving what one process knows about another. We use a notion of coordinators <ref> [26] </ref> to explore the fine details of traditional synchronization constructs. A prototype implementation has shown the effectiveness of this approach. In this implementation, applications are written using a library of synchronization constructs that implicitly inform the implementation about synchronization patterns.
Reference: [27] <author> F. X. Nursalim Hadi. </author> <title> Checkpointing in Distributed Virtual Memory by Using Local Virtual Memory. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <year> 1995. </year>
Reference-contexts: Object-oriented state machines [23] were developed to achieve systematic code reuse for protocols. In Choices, such machines structure the interaction of the virtual memory system with the rest of the system. This is especially convenient in deriving custom distributed memory consistency protocols; one user <ref> [27] </ref> of our system added checkpointing to our distributed shared memory implementation in a few weeks without ever consulting us. However, the state machines are only a part of the overall architecture.
Reference: [28] <author> Aamod Sane and Roy Campbell. </author> <title> Resource exchanger: A behavioral pattern for low overhead concurrent resource management. In Pattern Languages of Program Design. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, </address> <year> 1996. </year> <note> (To appear). </note>
Reference-contexts: However, the state machines are only a part of the overall architecture. We are isolating and identifying other aspects of our system to generalize it beyond virtual memory management using design patterns <ref> [28, 29] </ref>. 5.2 Customizing Consistency Maintenance Ideally, a distributed shared memory implementation would be indistinguishable from a true multiprocessor while allowing high-performance computation. However, maintaining the consistency of data copies requires substantial communication that hinders performance.
Reference: [29] <author> Aamod Sane and Roy Campbell. Detachable inspector/removable cout: </author> <title> A structural pattern for designing transparent layered services. In Pattern Languages of Program Design. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, </address> <year> 1996. </year> <note> (To appear). </note>
Reference-contexts: However, the state machines are only a part of the overall architecture. We are isolating and identifying other aspects of our system to generalize it beyond virtual memory management using design patterns <ref> [28, 29] </ref>. 5.2 Customizing Consistency Maintenance Ideally, a distributed shared memory implementation would be indistinguishable from a true multiprocessor while allowing high-performance computation. However, maintaining the consistency of data copies requires substantial communication that hinders performance.
Reference: [30] <author> Krueger K., Loftesness D., Vahdat A, and Anderson T. </author> <title> Tools for the Development of Application-Specific Virtual Memory Management. </title> <booktitle> In OOPSLA, </booktitle> <pages> pages 48-64, </pages> <year> 1993. </year>
Reference-contexts: Analyzing and customizing the run-time dynamics of systems built as black boxes is difficult and time-consuming. Adapting system components for non-traditional applications, including but not limited to multimedia, remains a daunting task for application programmers <ref> [30] </ref>. To address the issue of navigating the diverse environment provided by the Choices systems, we developed an open visualization and manipulation model that complements the direction taken by the object 10 technology [31].
Reference: [31] <author> Mohlalefi Sefika and Roy H. Campbell. </author> <title> An Open Visual Model For Object-Oriented Operating Systems. </title> <booktitle> In Fourth International Workshop on Object Orientation in Operating Systems, Lund, </booktitle> <address> Sweden, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: To address the issue of navigating the diverse environment provided by the Choices systems, we developed an open visualization and manipulation model that complements the direction taken by the object 10 technology <ref> [31] </ref>. The model enhances system comprehensibility and usability by systematically representing arbitrary system components as objects within a common visual notation for browsing and manipulation. <p> Our approach exploits the advantages of interactive software visualization to simplify both the scrutiny and steering of the run-time properties of an object-oriented operating system. We implemented an interactive interface tool, OS View <ref> [31] </ref>, to browse and configure Choices using our approach. The tool visualizes and manipulates behavioral and structural dynamics, aiding understanding and programming.
Reference: [32] <author> D. Zernik, M. Snir, and D. Malki. </author> <title> Using Visualization Tools to Understand Concurrency. </title> <journal> IEEE Software, </journal> <pages> pages 87-92, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Indeed, visualization has been established as effective in a variety of software understanding-intensive tasks, including dynamic analysis of sophisticated concurrent programs <ref> [32] </ref>. Our approach exploits the advantages of interactive software visualization to simplify both the scrutiny and steering of the run-time properties of an object-oriented operating system. We implemented an interactive interface tool, OS View [31], to browse and configure Choices using our approach.
Reference: [33] <author> Roy H. Campbell and See-Mong Tan. </author> <title> Choices: An Object-Oriented Multimedia Operating System. </title> <booktitle> In Fifth Workshop on Hot Topics in Operating Systems, </booktitle> <address> Orcas Island, Washington, </address> <month> May </month> <year> 1995. </year> <journal> IEEE Computer Society. </journal>
Reference-contexts: The tool "opens up" the system and allows the user, subject to security constraints, to experiment with alternative resource management policies and visualize its impact on the system and on application performance. We are extending our ideas in Choices <ref> [33, 34, 35] </ref>, the successor to Choices. Choices is a redesign of Choices as a micro-kernel operating system, and is also constructed on the concept of customizable object-oriented frameworks. It extends Choices by supporting embeddable scripts for customization.
Reference: [34] <author> See-Mong Tan, David Raila, and Roy H. Campbell. </author> <title> An Object-Oriented Nano-Kernel for Operating System Hardware Support. </title> <booktitle> In Fourth International Workshop on Object-Orientation in Operating Systems, Lund, </booktitle> <address> Sweden, </address> <month> August </month> <year> 1995. </year> <journal> IEEE Computer Society. </journal> <volume> 15 </volume>
Reference-contexts: The tool "opens up" the system and allows the user, subject to security constraints, to experiment with alternative resource management policies and visualize its impact on the system and on application performance. We are extending our ideas in Choices <ref> [33, 34, 35] </ref>, the successor to Choices. Choices is a redesign of Choices as a micro-kernel operating system, and is also constructed on the concept of customizable object-oriented frameworks. It extends Choices by supporting embeddable scripts for customization.
Reference: [35] <author> Willy S. Liao, David M. Putzolu, and Roy H. Campbell. </author> <title> Building a Secure, Location Transparent Object Invocation System. </title> <booktitle> In Fourth International Workshop on Object-Orientation in Operating Systems, Lund, </booktitle> <address> Sweden, </address> <month> August </month> <year> 1995. </year> <journal> IEEE Computer Society. </journal>
Reference-contexts: The tool "opens up" the system and allows the user, subject to security constraints, to experiment with alternative resource management policies and visualize its impact on the system and on application performance. We are extending our ideas in Choices <ref> [33, 34, 35] </ref>, the successor to Choices. Choices is a redesign of Choices as a micro-kernel operating system, and is also constructed on the concept of customizable object-oriented frameworks. It extends Choices by supporting embeddable scripts for customization.
Reference: [36] <author> David Cheriton. </author> <title> The V Distributed System. </title> <journal> Communications of the ACM, </journal> <pages> pages 314-334, </pages> <year> 1988. </year>
Reference: [37] <author> B. N. Bershad, S. Savage, P. Pardyak, E. G. Sirer, M. E. Fiuczynski, D. Becker, bers C.Cha, and S. Eggers. </author> <title> Extensibility, Safety and Performance in the SPIN Operating System. </title> <booktitle> In Proceedings of the 15th Symposium on Operating System Principles, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: It extends Choices by supporting embeddable scripts for customization. The system can be dynamically customized via the addition and modification of scripts at run time. Customization in existing operating systems, including Choices, are restricted to compile time modifications. For example, in systems like Mach [1], V++[36], SPIN <ref> [37] </ref> and Apertos [38], application-specific meta-level policies are implemented by user-provided compiled code. The Synthesis [39] kernel and its offspring, Synthetix [40], adopt a less conventional customization strategy that incorporates run-time code generation.
Reference: [38] <author> Yasuhiko Yokote. </author> <title> The Apertos Reflecive Operating System: The Concept and Its Implementation. </title> <booktitle> In Proceedings of the 1992 International Conference on Object-Oriented Programming, Systems, Languages, and Applications, </booktitle> <month> October </month> <year> 1992. </year>
Reference-contexts: The system can be dynamically customized via the addition and modification of scripts at run time. Customization in existing operating systems, including Choices, are restricted to compile time modifications. For example, in systems like Mach [1], V++[36], SPIN [37] and Apertos <ref> [38] </ref>, application-specific meta-level policies are implemented by user-provided compiled code. The Synthesis [39] kernel and its offspring, Synthetix [40], adopt a less conventional customization strategy that incorporates run-time code generation.
Reference: [39] <author> Calton Pu, Henry Massalin, and John Ioannidis. </author> <title> The Synthesis kernel. </title> <journal> Computing Systems, </journal> <volume> 1(1) </volume> <pages> 12-32, </pages> <year> 1988. </year>
Reference-contexts: Customization in existing operating systems, including Choices, are restricted to compile time modifications. For example, in systems like Mach [1], V++[36], SPIN [37] and Apertos [38], application-specific meta-level policies are implemented by user-provided compiled code. The Synthesis <ref> [39] </ref> kernel and its offspring, Synthetix [40], adopt a less conventional customization strategy that incorporates run-time code generation. However, the introspection and feedback scheme that triggers the generation of new code is still fixed and pre-determined at compile time.
Reference: [40] <author> Calton Pu, Tito Autrey, Andrew Black, Charles Consel, Crispin Cowan, Jon Inouye, Lakshmi Kethana, Jonathan Walpole, and Ke Zhang. </author> <title> Optimistic Incremental Specialization: Streamlining a Commercial Operating System. </title> <booktitle> In 15th ACM Symposium on Operating Systems Principles (SOSP'95), </booktitle> <address> Copper Mountain, Colorado, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: Customization in existing operating systems, including Choices, are restricted to compile time modifications. For example, in systems like Mach [1], V++[36], SPIN [37] and Apertos [38], application-specific meta-level policies are implemented by user-provided compiled code. The Synthesis [39] kernel and its offspring, Synthetix <ref> [40] </ref>, adopt a less conventional customization strategy that incorporates run-time code generation. However, the introspection and feedback scheme that triggers the generation of new code is still fixed and pre-determined at compile time.
Reference: [41] <author> Yongcheng Li, See-Mong Tan, Mohalehfi Sefika, Roy H. Campbell, and Willy S. Liao. </author> <title> Dynamic Customization in the Choices Operating System. </title> <note> Submitted to Reflection '96 Conference. </note>
Reference-contexts: In short, none of the current operating systems provides a fully open architecture for dynamic customization, where new application-specific policies can be generated on-the-fly, activated, deactivated, or completely removed without excessive recompilation and restructuring. Choices allows user programs to embed scripts into the kernel <ref> [41] </ref>. Scripting objects in Choices are user installable alternatives to kernel objects representing resource management policies. These objects execute user defined policies written in a scripting language. Scripts are attractive as kernel extension languages.
Reference: [42] <author> J. Gosling and H. McGilton. </author> <title> The Java Language Environment: A White Paper. Sun Microsystems Computer Company, </title> <type> 2550 Garcia Avenue, </type> <institution> Mountain View, California 94043. </institution> <note> http://www.sun.com, May 1995. </note>
Reference-contexts: These objects execute user defined policies written in a scripting language. Scripts are attractive as kernel extension languages. As they are interpreted, the safety aspects of embedding user code into the kernel is entirely constrained by the interpreter. The recent introduction of the Java <ref> [42] </ref> interpreted programming language offers the potential for efficient script execution at speeds comparable to compiled code [42]. In the current release of Java (beta release 1.0b1), the language compiles to a machine-independent byte-code. <p> As they are interpreted, the safety aspects of embedding user code into the kernel is entirely constrained by the interpreter. The recent introduction of the Java <ref> [42] </ref> interpreted programming language offers the potential for efficient script execution at speeds comparable to compiled code [42]. In the current release of Java (beta release 1.0b1), the language compiles to a machine-independent byte-code. Future releases will incorporate compilation from byte-code to native machine code as programs are loaded into the interpreter ("just-in-time compilation"), thus trading greater cost at start up to more efficient later execution.
References-found: 42

