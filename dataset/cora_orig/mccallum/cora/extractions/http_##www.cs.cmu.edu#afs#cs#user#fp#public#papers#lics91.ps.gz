URL: http://www.cs.cmu.edu/afs/cs/user/fp/public/papers/lics91.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs/user/fp/public/papers/
Root-URL: 
Email: Internet: fp@cs.cmu.edu  
Title: Unification and Anti-Unification in the Calculus of Constructions  
Author: Frank Pfenning 
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: We present algorithms for unification and anti-unification in the Calculus of Constructions, where occurrences of free variables (the variables subject to in-stantiation) are restricted to higher-order patterns, a notion investigated for the simply-typed -calculus by Miller. Most general unifiers and least common anti-instances are shown to exist and are unique up to a simple equivalence. The unification algorithm is used for logic program execution and type and term reconstruction in the current implementation of Elf and has shown itself to be practical. The main application of the anti-unification algorithm we have in mind is that of proof generalization. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Peter B. Andrews, Sunil Issar, Dan Nesmith, and Frank Pfenning. </author> <title> The TPS theorem proving system. In M.E. </title> <editor> Stickel, editor, </editor> <booktitle> 10th International Conference on Automated Deduction, Kaiser-slautern, Germany, </booktitle> <pages> pages 641-642. </pages> <publisher> Springer-Verlag LNCS 449, </publisher> <month> July </month> <year> 1990. </year> <title> System abstract. </title>
Reference-contexts: 1 Introduction Higher-order logic with an embedded simply-typed - calculus has been used as the basis for a number of theorem provers (for example <ref> [1, 19] </ref>) and the programming language Prolog [16]. Central to these systems is an implementation of Huet's pre-unification algorithm for the simply-typed -calculus [12] which has shown itself to be very useful in practice, despite the undecidability of higher-order unification [8].
Reference: [2] <author> Thierry Coquand. </author> <title> An algorithm for testing conversion in type theory. </title> <editor> In Gerard Huet and Gordon D. Plotkin, editors, </editor> <title> Logical Frameworks. </title> <publisher> Cambridge University Press, </publisher> <year> 1991. </year> <note> To appear. </note>
Reference-contexts: For the restriction of this system to the LF type theory, this has recently been proved independently by Coquand <ref> [2] </ref> and Salvesen [25].
Reference: [3] <author> Thierry Coquand and Gerard Huet. </author> <title> The Calculus of Constructions. </title> <journal> Information and Computation, </journal> 76(2/3):95-120, February/March 1988. 
Reference-contexts: in circumstances where proofs are important as objects of study (say, for program extraction, proof transformation, or proof generalization, to give but three examples), benefits may be derived from using a richer type theory, such as offered by the LF Logical Framework [10] or the more general Calculus of Constructions <ref> [3] </ref>. A number of program development and theorem proving environments have been constructed on the basis of such type theories (see, for example, [6, 18, 20]). <p> We have ::= Prop j Type kinds M ::= c j x j j fx:M g N j [x:M ] N j (M N ) terms ::= j [x:M ] contexts ::= j [c:M ] signatures Following <ref> [3] </ref> we call fx:M g N a product; [x:M ] N is - abstraction. Unfortunately this terminology does not exactly match up with what is used in the LF logical framework, where Type is used instead of Prop, and Type would be called Kind (if it were made explicit). <p> We also assume that the fixed signature is valid (in the obvious sense), but omit the corresponding judgment and rules. We consider fi and -conversion ( ~ = ) in the "full" form (see <ref> [3, Page 102] </ref>). -conversion plays an important role, because the various algorithms we give are defined on canonical forms (or long fi-normal forms). This notion is defined formally through the inference system in Figure 2.
Reference: [4] <author> Scott Dietzen and Frank Pfenning. </author> <title> Higher-order and modal logic as a framework for explanation-based generalization. </title> <booktitle> Machine Learning, </booktitle> <year> 1991. </year> <note> To 11 appear. Available as Technical Report CMU-CS--89-160, </note> <institution> Carnegie Mellon University. </institution>
Reference-contexts: Generalization from one proof (or explanation-based generalization, in the terminology of the Artificial Intelligence literature) has been investigated by Hagiya [9] in the setting of type theory, and by Dietzen and the author in setting of Prolog <ref> [4] </ref>. Our extension to the Calculus of Constructions yields an algorithm for finding the least general generalization (or anti-unifier) of two proofs, which may be a more general proof schema.
Reference: [5] <author> Gilles Dowek. </author> <title> A proof synthesis algorithm for a mathematical vernacular in a restriction of the Calculus of Constructions. </title> <type> Unpublished manuscript, </type> <month> January </month> <year> 1991. </year>
Reference-contexts: But they may also be useful in the context of a Mathematical Vernacular <ref> [5] </ref> or a program development environment based on the Calculus of Constructions (CC) [18, 6]. For this reason, and also because it streamlines the presentation, we chose the Calculus of Constructions as the formalism for the presentation of the ideas. <p> To our knowledge, it has not been shown that every term in the Calculus of Constructions is equivalent to a unique canonical form|we will take this as a working hypothesis as in <ref> [5] </ref>. For the restriction of this system to the LF type theory, this has recently been proved independently by Coquand [2] and Salvesen [25].
Reference: [6] <author> Dominic Duggan. Caliban: </author> <title> A Programming Language and Environment Based on Types as Specifications. </title> <type> PhD thesis, </type> <institution> University of Maryland, College Park, </institution> <year> 1991. </year> <note> In preparation. </note>
Reference-contexts: A number of program development and theorem proving environments have been constructed on the basis of such type theories (see, for example, <ref> [6, 18, 20] </ref>). In order to give sophisticated assistance for proof development and management in these frameworks, pre-unification algorithms for LF have been developed independently by Elliott [7] and Pym [23]. The drawbacks of non-determinism and undecidability were inherited by these algorithms from the simply-typed case. <p> But they may also be useful in the context of a Mathematical Vernacular [5] or a program development environment based on the Calculus of Constructions (CC) <ref> [18, 6] </ref>. For this reason, and also because it streamlines the presentation, we chose the Calculus of Constructions as the formalism for the presentation of the ideas. There are currently a number of closely related formulations of the Calculus of Constructions.
Reference: [7] <author> Conal M. Elliott. </author> <title> Extensions and Applications of Higher-Order Unification. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> May </month> <year> 1990. </year> <note> Available as Technical Report CMU-CS-90-134. </note>
Reference-contexts: A number of program development and theorem proving environments have been constructed on the basis of such type theories (see, for example, [6, 18, 20]). In order to give sophisticated assistance for proof development and management in these frameworks, pre-unification algorithms for LF have been developed independently by Elliott <ref> [7] </ref> and Pym [23]. The drawbacks of non-determinism and undecidability were inherited by these algorithms from the simply-typed case. A combination of the ideas of Miller and Elliott for a deterministic, though incomplete algorithm for the LF Logical Framework is presented by the author in [21]. <p> Such a well-typedness requirement cannot be maintained when considering unification for LF (or the Calculus of Constructions) without the restriction to patterns, where a complicated "acceptability" condition must be substituted instead (see <ref> [7] </ref>). To obtain some intuition about the unification of higher-order patterns, consider the following unification problems.
Reference: [8] <author> Warren D. Goldfarb. </author> <title> The undecidability of the second-order unification problem. </title> <journal> Theoretical Computer Science, </journal> <volume> 13 </volume> <pages> 225-230, </pages> <year> 1981. </year>
Reference-contexts: Central to these systems is an implementation of Huet's pre-unification algorithm for the simply-typed -calculus [12] which has shown itself to be very useful in practice, despite the undecidability of higher-order unification <ref> [8] </ref>. However, the non-determinism, more so than the undecidability, presents some problems with full higher-order unification as the basis for proof development environments and logic programming languages. <p> This is not possible here, since many terms do not have any ground instances. Since it is undecidable if a given type is inhabited, this would make the equivalence relation on cterms undecidable. In general, unification is undecidable already in the simply-typed -calculus <ref> [8] </ref>. Thus, some restriction must be placed on the occurrences of free variables (those in ) in order to obtain a class of cterms for which unification is decidable and most general unifiers exist.
Reference: [9] <author> Masami Hagiya. </author> <title> Generalization from partial parameterization in higher-order type theory. </title> <journal> Theoretical Computer Science, </journal> <volume> 63 </volume> <pages> 113-139, </pages> <year> 1989. </year>
Reference-contexts: One of the fundamental operations on proofs is that of generalization: we abstract away from the particulars of a proof to obtain a more general one. Generalization from one proof (or explanation-based generalization, in the terminology of the Artificial Intelligence literature) has been investigated by Hagiya <ref> [9] </ref> in the setting of type theory, and by Dietzen and the author in setting of Prolog [4]. Our extension to the Calculus of Constructions yields an algorithm for finding the least general generalization (or anti-unifier) of two proofs, which may be a more general proof schema.
Reference: [10] <author> Robert Harper, Furio Honsell, and Gordon Plotkin. </author> <title> A framework for defining logics. </title> <journal> Journal of the ACM, </journal> <note> to appear. A preliminary version appeared in Symposium on Logic in Computer Science, pages 194-204, </note> <month> June </month> <year> 1987. </year>
Reference-contexts: Thus, in circumstances where proofs are important as objects of study (say, for program extraction, proof transformation, or proof generalization, to give but three examples), benefits may be derived from using a richer type theory, such as offered by the LF Logical Framework <ref> [10] </ref> or the more general Calculus of Constructions [3]. A number of program development and theorem proving environments have been constructed on the basis of such type theories (see, for example, [6, 18, 20]). <p> However, unlike in the first-order situation, not every pair of patterns has an upper bound. 2 The Calculus of Constructions We began the work described herein in the context of the LF Logical Framework <ref> [10] </ref> and we still consider Elf [20, 21] as the primary vehicle for the applications of the results presented in this paper. But they may also be useful in the context of a Mathematical Vernacular [5] or a program development environment based on the Calculus of Constructions (CC) [18, 6]. <p> Key here is a lemma that the invariants stated at the beginning are preserved. Termination of the operational version of the algorithm can easily be seen. 6 Examples of Anti-Unification The examples below are mostly situated in the LF subcalculus of the Calculus of Constructions <ref> [10] </ref>. We show those parts of a full axiomatization of first-order logic in LF which are necessary for our examples in notation.
Reference: [11] <author> Robert Harper and Robert Pollack. </author> <title> Type checking, universe polymorphism, and typical ambiguity in the Calculus of Constructions. </title> <booktitle> In TAP-SOFT '89, Proceedings of the International Joint Conference on Theory and Practice in Software Development, Barcelona, Spain, </booktitle> <pages> pages 241-256. </pages> <publisher> Springer-Verlag LNCS 352, </publisher> <month> March </month> <year> 1989. </year>
Reference-contexts: There are currently a number of closely related formulations of the Calculus of Constructions. The choice of formalization is mainly a matter of economy of presentation of the inference rules and the various algorithms. The formulation we use here is taken from <ref> [11] </ref>, but closely related formulations appear throughout the literature. We use M; N for terms in general and u; v and x; y; z for variables, where the occurrences of u in [u:M ] N and fu:M g N are binding occurrences.
Reference: [12] <author> Gerard Huet. </author> <title> A unification algorithm for typed -calculus. </title> <journal> Theoretical Computer Science, </journal> <volume> 1 </volume> <pages> 27-57, </pages> <year> 1975. </year>
Reference-contexts: 1 Introduction Higher-order logic with an embedded simply-typed - calculus has been used as the basis for a number of theorem provers (for example [1, 19]) and the programming language Prolog [16]. Central to these systems is an implementation of Huet's pre-unification algorithm for the simply-typed -calculus <ref> [12] </ref> which has shown itself to be very useful in practice, despite the undecidability of higher-order unification [8]. However, the non-determinism, more so than the undecidability, presents some problems with full higher-order unification as the basis for proof development environments and logic programming languages. <p> Rigid-Rigid The terminology is borrowed from Huet <ref> [12] </ref>. This has two analogous subcases: it may be that we are unifying two atomic terms beginning with constants or with variables in dom (). Thus h stands either for a constant c or a Uvar.
Reference: [13] <author> Gerard Huet. </author> <type> Resolution d'equations dans des langages d'ordre 1; 2; . . .; !. PhD thesis, </type> <institution> Univer-site Paris VII, </institution> <month> September </month> <year> 1976. </year>
Reference-contexts: We define the notion of a canonical form through the inference system in Figure 2. The main judgment is ` M ) A (read: M is canonical of type A in context ). 3 Higher-Order Patterns In the theory of first-order unification and anti-unification <ref> [22, 24, 13, 14] </ref>, the authors construct a semi-lattice of terms with free variables, ordered under instantiation of these variables. Here we are dealing with a typed language, so we need to consider terms in a context which assigns types to the free variables. <p> Consider, for example, Prop t (Prop ! Prop). Since we have no variables of type Type, there is no variable or other term which can be instantiated to both of these terms. The central ingredient in the elegant formulation of first-order anti-unification by Huet <ref> [13] </ref> is a global function which maps pairs of terms to variables. Consider f (a; a) t f (b; b) = f (x; x) if (a; b) = x. The function is used to guarantee that the same disagreements are mapped to the same variable (x, in this example).
Reference: [14] <author> J-L. Lassez, M.J. Maher, and K. Marriott. </author> <title> Unification revisited. </title> <editor> In J. Minker, editor, </editor> <booktitle> Foundations of Deductive Databases, chapter 15, </booktitle> <pages> pages 587-626. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: We define the notion of a canonical form through the inference system in Figure 2. The main judgment is ` M ) A (read: M is canonical of type A in context ). 3 Higher-Order Patterns In the theory of first-order unification and anti-unification <ref> [22, 24, 13, 14] </ref>, the authors construct a semi-lattice of terms with free variables, ordered under instantiation of these variables. Here we are dealing with a typed language, so we need to consider terms in a context which assigns types to the free variables. <p> Moreover, there is an effective algorithm which computes a greatest common instance h; M i if it exists and fails otherwise. The proof is delicate and tedious, but not difficult, following the standard patterns (see, for example, Lassez et al. <ref> [14] </ref>). Given the invariants maintained in the deductive system, the main difficulty is in showing that the partial permutations we construct cover all possible instances (for the basic idea of this proof, see Miller [15]).
Reference: [15] <author> Dale Miller. </author> <title> A logic programming language with lambda-abstraction, function variables, and simple unification. </title> <editor> In Peter Schroeder-Heister, editor, </editor> <booktitle> Extensions of Logic Programming: International Workshop, Tubingen FRG, </booktitle> <month> December </month> <year> 1989, </year> <pages> pages 253-281. </pages> <publisher> Springer-Verlag LNCS 475, </publisher> <year> 1991. </year>
Reference-contexts: This has lead to search for a restriction on the occurrences of variables in simply-typed -terms such that the unification problem becomes deterministic and decidable. Such a class was discovered by Miller <ref> [15] </ref> and applied by Nipkow [17] to higher-order rewriting and by the author [21] to the simplification of constraints and type reconstruction in Elf. Though our class is more general, since it is situated in the Calculus of Constructions, we follow Nipkow and call such restricted terms here higher-order patterns. <p> Thus, some restriction must be placed on the occurrences of free variables (those in ) in order to obtain a class of cterms for which unification is decidable and most general unifiers exist. A very natural class has been discovered by Miller <ref> [15] </ref> as the basis for the logic programming language L . This class has been applied to higher-order rewriting by Nipkow [17]. A generalization useful in the programming language Elf based on the LF Logical Framework is given by the author in [21]. <p> Miller <ref> [15] </ref> develops a closely related notion for the simply-typed -calculus. His presentation is untyped, which already suggests that the algorithm does not rely on specific properties of simple types and may generalize even to an impredicative setting such as the Calculus of Constructions. <p> Given the invariants maintained in the deductive system, the main difficulty is in showing that the partial permutations we construct cover all possible instances (for the basic idea of this proof, see Miller <ref> [15] </ref>). It is easy to see that the operational interpretation of this system will always terminate (either with failure, if no deduction can be constructed) or with a greatest common instance and a most general unifier.
Reference: [16] <author> Gopalan Nadathur and Dale Miller. </author> <title> An overview of Prolog. </title> <editor> In Robert A. Kowalski and Ken-neth A. Bowen, editors, </editor> <booktitle> Logic Programming: Proceedings of the Fifth International Conference and Symposium, </booktitle> <volume> Volume 1, </volume> <pages> pages 810-827, </pages> <address> Cam-bridge, Massachusetts, August 1988. </address> <publisher> MIT Press. </publisher>
Reference-contexts: 1 Introduction Higher-order logic with an embedded simply-typed - calculus has been used as the basis for a number of theorem provers (for example [1, 19]) and the programming language Prolog <ref> [16] </ref>. Central to these systems is an implementation of Huet's pre-unification algorithm for the simply-typed -calculus [12] which has shown itself to be very useful in practice, despite the undecidability of higher-order unification [8].
Reference: [17] <author> Tobias Nipkow. </author> <title> Higher-order critical pairs. </title> <booktitle> In Sixth Annual Symposium on Logic in Computer Science. IEEE, </booktitle> <month> July </month> <year> 1991. </year> <note> To appear. </note>
Reference-contexts: This has lead to search for a restriction on the occurrences of variables in simply-typed -terms such that the unification problem becomes deterministic and decidable. Such a class was discovered by Miller [15] and applied by Nipkow <ref> [17] </ref> to higher-order rewriting and by the author [21] to the simplification of constraints and type reconstruction in Elf. Though our class is more general, since it is situated in the Calculus of Constructions, we follow Nipkow and call such restricted terms here higher-order patterns. <p> A very natural class has been discovered by Miller [15] as the basis for the logic programming language L . This class has been applied to higher-order rewriting by Nipkow <ref> [17] </ref>. A generalization useful in the programming language Elf based on the LF Logical Framework is given by the author in [21]. It is used in Elf for term reconstruction and proof search (in the manner of constraint logic programming).
Reference: [18] <author> Christine Paulin-Mohring. </author> <title> Extracting F ! programs from proofs in the calculus of constructions. </title> <booktitle> In Sixteenth Annual Symposium on Principles of Programming Languages, </booktitle> <pages> pages 89-104. </pages> <publisher> ACM Press, </publisher> <month> January </month> <year> 1989. </year>
Reference-contexts: A number of program development and theorem proving environments have been constructed on the basis of such type theories (see, for example, <ref> [6, 18, 20] </ref>). In order to give sophisticated assistance for proof development and management in these frameworks, pre-unification algorithms for LF have been developed independently by Elliott [7] and Pym [23]. The drawbacks of non-determinism and undecidability were inherited by these algorithms from the simply-typed case. <p> But they may also be useful in the context of a Mathematical Vernacular [5] or a program development environment based on the Calculus of Constructions (CC) <ref> [18, 6] </ref>. For this reason, and also because it streamlines the presentation, we chose the Calculus of Constructions as the formalism for the presentation of the ideas. There are currently a number of closely related formulations of the Calculus of Constructions.
Reference: [19] <author> Lawrence C. Paulson and Tobias Nipkow. </author> <title> Isabelle tutorial and user's manual. </title> <type> Technical Report 189, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <month> January </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Higher-order logic with an embedded simply-typed - calculus has been used as the basis for a number of theorem provers (for example <ref> [1, 19] </ref>) and the programming language Prolog [16]. Central to these systems is an implementation of Huet's pre-unification algorithm for the simply-typed -calculus [12] which has shown itself to be very useful in practice, despite the undecidability of higher-order unification [8].
Reference: [20] <author> Frank Pfenning. </author> <title> Elf: A language for logic definition and verified meta-programming. </title> <booktitle> In Fourth Annual Symposium on Logic in Computer Science, </booktitle> <pages> pages 313-322. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1989. </year>
Reference-contexts: A number of program development and theorem proving environments have been constructed on the basis of such type theories (see, for example, <ref> [6, 18, 20] </ref>). In order to give sophisticated assistance for proof development and management in these frameworks, pre-unification algorithms for LF have been developed independently by Elliott [7] and Pym [23]. The drawbacks of non-determinism and undecidability were inherited by these algorithms from the simply-typed case. <p> However, unlike in the first-order situation, not every pair of patterns has an upper bound. 2 The Calculus of Constructions We began the work described herein in the context of the LF Logical Framework [10] and we still consider Elf <ref> [20, 21] </ref> as the primary vehicle for the applications of the results presented in this paper. But they may also be useful in the context of a Mathematical Vernacular [5] or a program development environment based on the Calculus of Constructions (CC) [18, 6]. <p> p q u) t [p:o][q:o][u:true (p ^ q)] andi p q (andel p q u) (ander p q u) = [p:o][q:o][u:true (p ^ q)] andi (x 1 p q) (x 1 q p) (x 2 p q u) (x 3 p q u) in the implementation of the Elf language <ref> [20, 21] </ref> and exhibits good characteristics in terms of performance. The algorithm is used for the solution of constraints during the execution of a logic program and for performing term and type reconstruction after parsing. However, many improvements are still possible and the subject of current investigation.
Reference: [21] <author> Frank Pfenning. </author> <title> Logic programming in the LF logical framework. </title> <editor> In Gerard Huet and Gordon D. Plotkin, editors, </editor> <title> Logical Frameworks. </title> <publisher> Cambridge University Press, </publisher> <year> 1991. </year> <note> To appear. </note>
Reference-contexts: This has lead to search for a restriction on the occurrences of variables in simply-typed -terms such that the unification problem becomes deterministic and decidable. Such a class was discovered by Miller [15] and applied by Nipkow [17] to higher-order rewriting and by the author <ref> [21] </ref> to the simplification of constraints and type reconstruction in Elf. Though our class is more general, since it is situated in the Calculus of Constructions, we follow Nipkow and call such restricted terms here higher-order patterns. This concept is developed in Section 3. <p> The drawbacks of non-determinism and undecidability were inherited by these algorithms from the simply-typed case. A combination of the ideas of Miller and Elliott for a deterministic, though incomplete algorithm for the LF Logical Framework is presented by the author in <ref> [21] </ref>. This forms the basis for the programming language Elf and has shown itself very effective in practice. In Section 4 we present a generalization of this algorithm to the full Calculus of Constructions. <p> However, unlike in the first-order situation, not every pair of patterns has an upper bound. 2 The Calculus of Constructions We began the work described herein in the context of the LF Logical Framework [10] and we still consider Elf <ref> [20, 21] </ref> as the primary vehicle for the applications of the results presented in this paper. But they may also be useful in the context of a Mathematical Vernacular [5] or a program development environment based on the Calculus of Constructions (CC) [18, 6]. <p> This class has been applied to higher-order rewriting by Nipkow [17]. A generalization useful in the programming language Elf based on the LF Logical Framework is given by the author in <ref> [21] </ref>. It is used in Elf for term reconstruction and proof search (in the manner of constraint logic programming). The practical experience for the implementation of type reconstruction for Elf and the Calculus of Constructions provides strong evidence for the utility of this class of terms. <p> p q u) t [p:o][q:o][u:true (p ^ q)] andi p q (andel p q u) (ander p q u) = [p:o][q:o][u:true (p ^ q)] andi (x 1 p q) (x 1 q p) (x 2 p q u) (x 3 p q u) in the implementation of the Elf language <ref> [20, 21] </ref> and exhibits good characteristics in terms of performance. The algorithm is used for the solution of constraints during the execution of a logic program and for performing term and type reconstruction after parsing. However, many improvements are still possible and the subject of current investigation.
Reference: [22] <author> Gordon D. Plotkin. </author> <title> A note on inductive generalization. </title> <journal> Machine Intelligence, </journal> <volume> 5 </volume> <pages> 153-163, </pages> <year> 1970. </year>
Reference-contexts: We define the notion of a canonical form through the inference system in Figure 2. The main judgment is ` M ) A (read: M is canonical of type A in context ). 3 Higher-Order Patterns In the theory of first-order unification and anti-unification <ref> [22, 24, 13, 14] </ref>, the authors construct a semi-lattice of terms with free variables, ordered under instantiation of these variables. Here we are dealing with a typed language, so we need to consider terms in a context which assigns types to the free variables. <p> We were not able to find a corresponding formulation in this setting, due to the nature of the type dependencies. Thus we return to a formulation similar to algorithms presented by Plotkin <ref> [22] </ref> and Reynolds [24]. In our setting, there are several complicating factors. We discuss each of them in turn. We assume that we are considering a subproblem of anti-unifying h 0 ; M 0 i and h 00 ; M 00 i, and we fix 0 and 00 .
Reference: [23] <author> David Pym. </author> <title> Proofs, Search and Computation in General Logic. </title> <type> PhD thesis, </type> <institution> University of Edin-burgh, </institution> <year> 1990. </year> <note> Available as CST-69-90, also published as ECS-LFCS-90-125. </note>
Reference-contexts: In order to give sophisticated assistance for proof development and management in these frameworks, pre-unification algorithms for LF have been developed independently by Elliott [7] and Pym <ref> [23] </ref>. The drawbacks of non-determinism and undecidability were inherited by these algorithms from the simply-typed case. A combination of the ideas of Miller and Elliott for a deterministic, though incomplete algorithm for the LF Logical Framework is presented by the author in [21].
Reference: [24] <author> John C. Reynolds. </author> <title> Transformational systems and the algebraic structure of atomic formulas. </title> <journal> Machine Intelligence, </journal> <volume> 5 </volume> <pages> 135-151, </pages> <year> 1970. </year>
Reference-contexts: We define the notion of a canonical form through the inference system in Figure 2. The main judgment is ` M ) A (read: M is canonical of type A in context ). 3 Higher-Order Patterns In the theory of first-order unification and anti-unification <ref> [22, 24, 13, 14] </ref>, the authors construct a semi-lattice of terms with free variables, ordered under instantiation of these variables. Here we are dealing with a typed language, so we need to consider terms in a context which assigns types to the free variables. <p> We were not able to find a corresponding formulation in this setting, due to the nature of the type dependencies. Thus we return to a formulation similar to algorithms presented by Plotkin [22] and Reynolds <ref> [24] </ref>. In our setting, there are several complicating factors. We discuss each of them in turn. We assume that we are considering a subproblem of anti-unifying h 0 ; M 0 i and h 00 ; M 00 i, and we fix 0 and 00 . <p> Moreover, there is an effective algorithm which computes a least common anti instance h; M i if it exists and fails otherwise. The proof follows patterns similar to the one given by Reynolds <ref> [24] </ref>, though significantly more intricate in the details, due the presence of binding operators and types. Key here is a lemma that the invariants stated at the beginning are preserved.
Reference: [25] <author> Anne Salvesen. </author> <title> The Church-Rosser theorem for LF with fi-reduction. Unpublished notes to a talk given at the First Workshop on Logical Frameworks in Antibes, </title> <month> May </month> <year> 1990. </year> <month> 12 </month>
Reference-contexts: For the restriction of this system to the LF type theory, this has recently been proved independently by Coquand [2] and Salvesen <ref> [25] </ref>.
References-found: 25

