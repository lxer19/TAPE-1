URL: http://www.cs.umn.edu/Research/Agassiz/Paper/huang.tr97-036.ps.Z
Refering-URL: http://www.cs.umn.edu/Research/Agassiz/agassiz_pubs.html
Root-URL: http://www.cs.umn.edu
Title: Reducing Cache Misses for CC-NUMA by Careful Page-mapping  
Author: Jian Huang and Zhiyuan Li 
Date: July 15, 1997  
Address: Minneapolis, MN 55455  
Affiliation: Department of Computer Science University of Minnesota  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T. Romer, D. Lee, B. Bershad, J. Chen. </author> <title> Dynamic Page-Mapping Policies for Cache Conflict Resolution on Standard Hardware. </title> <booktitle> Proceedings of the First Symposium on Operating System Design and Implementation, </booktitle> <month> Nov. 94. </month>
Reference-contexts: We expect a similar, if not greater performance impact on CC-NUMA due to the higher cache-miss penalty. Various techniques have been proposed and used in page-mapping, including page-coloring, bin-hopping, best-bin, hierarchical method [15], compiler-assisted page-coloring [5] and dynamic re-mapping <ref> [1] </ref>. Page-coloring and bin-hopping are simple and hence the most popular ones. Silicon Graphics Inc., adopts page-coloring scheme in its products, while DEC ships OSF/1 with bin-hopping. 2 Previously, bin-hopping and page-coloring were discussed for UMA machines only. In this paper, we study page-mapping techniques in the context of CC-NUMA.
Reference: [2] <author> J. Carter, J. Bennnett, W. Zwaenepoel. </author> <title> Techniques for Reducing Consistency-Related Communication in Distributed Shared-Memory Systems. </title> <journal> ACM Transactions On Computer Systems, </journal> <volume> Vol. 13, No. 3, </volume> <month> Aug., </month> <pages> 95, Page 205. </pages>
Reference: [3] <author> S. Adve, K. Gharachorloo. </author> <title> Shared Memory Consistency Models: A Tutorial. </title> <type> Technical Report 9512, </type> <institution> Department of Electrical and Computer Engineering, Rice University. </institution>
Reference-contexts: Four popular SPEC Floating Point benchmark programs were parallelized for experiments. An inter-procedural parallelizing compiler is used to perform data-task co-allocation. All experiments are done on an execution-driven super-scalar simulator with non-blocking two-level caches [4] and weak-ordered memory consistency <ref> [3] </ref>. The rest of the paper is organized as follows: Section 2 discuses the extensions of page coloring and bin-hopping in the context of CC-NUMA. Section 3 describes the experimental set-up. Section 4 compares the results of page-coloring and bin-hopping and presents a renovation of page-coloring. <p> Each chunk is then assigned to a processor. Our experiments showed that other scheduling schemes are inferior to simple scheduling for the selected benchmarks. NUMAsim is an execution-driven multi-processor simulator based on MINT [28]. However, modifications are done to support super-scalar CPU model [8] and weak-ordered memory consistency <ref> [3] </ref>. The key parameters of our processor model and component latency are summarized in Table 1. These parameters are selected based on those of several existing and developing commercial systems. The retirement of instructions is in-order.
Reference: [4] <author> T. Chen, J-L. Bear. </author> <title> Reducing Memory Latency via Non-blocking and Prefetching Caches. </title> <type> Technical Report TR-92-06-03, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <note> also appeared in the 3rd Int'l Symposium on Architectural Support for Programming Languages and Operating System, </note> <month> October </month> <year> 1992. </year>
Reference-contexts: A renovated page-coloring scheme, whose performance is close to that of bin-hopping is presented. Four popular SPEC Floating Point benchmark programs were parallelized for experiments. An inter-procedural parallelizing compiler is used to perform data-task co-allocation. All experiments are done on an execution-driven super-scalar simulator with non-blocking two-level caches <ref> [4] </ref> and weak-ordered memory consistency [3]. The rest of the paper is organized as follows: Section 2 discuses the extensions of page coloring and bin-hopping in the context of CC-NUMA. Section 3 describes the experimental set-up.
Reference: [5] <author> E. Bugnion, J. M. Anderson, T. C. Mowry, M. Rosenblum and M. S. Lam. </author> <title> Compiler-directed page coloring for multiprocessors. </title> <booktitle> To appear in Proc. of the 7th Int. Sym. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: hence program performance, on uniprocessor machines as well as multiprocessor with uniform memory access <ref> [5] </ref>[15]. We expect a similar, if not greater performance impact on CC-NUMA due to the higher cache-miss penalty. Various techniques have been proposed and used in page-mapping, including page-coloring, bin-hopping, best-bin, hierarchical method [15], compiler-assisted page-coloring [5] and dynamic re-mapping [1]. Page-coloring and bin-hopping are simple and hence the most popular ones. Silicon Graphics Inc., adopts page-coloring scheme in its products, while DEC ships OSF/1 with bin-hopping. 2 Previously, bin-hopping and page-coloring were discussed for UMA machines only.
Reference: [6] <author> J. Gu, Z. Li, G. Lee. </author> <title> Experience with Efficient Array Data-Flow Analysis for Array Privatization, </title> <booktitle> to appear in Proc. of Sixth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> June </month> <year> 1997. </year> <month> 16 </month>
Reference: [7] <author> J. Gu, Z. Li, G. Lee. </author> <title> Symbolic Array Dataflow Analysis for Array Privatization and Program Par-allelization, </title> <booktitle> in Proc. Supercomputing '95, </booktitle> <month> Dec., </month> <year> 1995. </year>
Reference: [8] <author> J. Hennesey, D. Patterson. </author> <title> Computer Architecture, A Quantitive Approach. </title> <publisher> Morgan Caufmann Publishers. </publisher>
Reference-contexts: Each chunk is then assigned to a processor. Our experiments showed that other scheduling schemes are inferior to simple scheduling for the selected benchmarks. NUMAsim is an execution-driven multi-processor simulator based on MINT [28]. However, modifications are done to support super-scalar CPU model <ref> [8] </ref> and weak-ordered memory consistency [3]. The key parameters of our processor model and component latency are summarized in Table 1. These parameters are selected based on those of several existing and developing commercial systems. The retirement of instructions is in-order.
Reference: [9] <author> A. Agarwal, D. Kranz, and V. Natarajan. </author> <title> Automatic partitioning of parallel loops and data arrays for distributed shared memory multiprocessors. </title> <booktitle> In Proc. International Conference on Parallel Processing, volume I: Architecture, </booktitle> <pages> pages 2-11, </pages> <address> St. Charles, IL, </address> <year> 1993. </year>
Reference: [10] <author> A. Agarwal et al. </author> <title> The MIT alewife machine: A large-scale distributed-memory multiprocessor. </title> <type> Technical Report 454, </type> <institution> MIT/LCS, </institution> <year> 1991. </year>
Reference-contexts: 1 Introduction Cache-Coherent Non-Uniform Memory Access (CC-NUMA) multiprocessors become increasingly attractive as an architecture which provides a transparent access to local and remote memories and a good scalability. Systems based on this architecture include research prototypes such as the Stanford DASH [17] and FLASH [16], MIT Alewife <ref> [10] </ref>, University of Toronto NUMAchine [29], and Sun's S3.mp [25], as well as commercial products including the Sequent STiNG [21] Hewlett-Packard SPP [13], and Silicon Graphics Origin 2000. A CC-NUMA machine has a number of nodes connected by an interconnection network.
Reference: [11] <author> J. M. Anderson and M. S. Lam. </author> <title> Global optimizations for parallelism and locality on scalable parallel machines. </title> <booktitle> In Proc. ACM SIGPLAN Conf. on Prog. Lang. Design and Imp., </booktitle> <pages> pages 112-125, </pages> <month> June </month> <year> 1993. </year>
Reference: [12] <institution> Cray Research Inc. CrayT3D Technical Summary, </institution> <year> 1993. </year>
Reference: [13] <author> Hewlett-Packard Co. </author> <title> HP releases high-end technical-solutions road map with consistent architecture to beyond year 2000. </title> <address> http://www.convex.com/. </address>
Reference-contexts: Systems based on this architecture include research prototypes such as the Stanford DASH [17] and FLASH [16], MIT Alewife [10], University of Toronto NUMAchine [29], and Sun's S3.mp [25], as well as commercial products including the Sequent STiNG [21] Hewlett-Packard SPP <ref> [13] </ref>, and Silicon Graphics Origin 2000. A CC-NUMA machine has a number of nodes connected by an interconnection network. Each node consists of one or a few processors, a private cache hierarchy, and a local memory module (Figure 1).
Reference: [14] <author> K. Kennedy and U. Kremer. </author> <title> Automatic data layout for High Performance Fortran. </title> <booktitle> In Proc. Supercomputing '95, </booktitle> <month> December </month> <year> 1995. </year> <month> 17 </month>
Reference: [15] <author> Richard E. Kessler and Mark D. Hill. </author> <title> Page placement algorithms for large real-indexed caches. </title> <journal> In ACM Transactions on Computer Systems, </journal> <volume> 10(4), </volume> <month> November </month> <year> 1992. </year>
Reference-contexts: in cache, and hence program performance, on uniprocessor machines as well as multiprocessor with uniform memory access [5]<ref> [15] </ref>. We expect a similar, if not greater performance impact on CC-NUMA due to the higher cache-miss penalty. Various techniques have been proposed and used in page-mapping, including page-coloring, bin-hopping, best-bin, hierarchical method [15], compiler-assisted page-coloring [5] and dynamic re-mapping [1]. Page-coloring and bin-hopping are simple and hence the most popular ones. Silicon Graphics Inc., adopts page-coloring scheme in its products, while DEC ships OSF/1 with bin-hopping. 2 Previously, bin-hopping and page-coloring were discussed for UMA machines only. <p> Some number of cache-sets may be occupied when a page is being referenced. For a given physical page, there are a certain number of cache-sets which can cache the data of this page. All these cache-sets together are called a cache-bin <ref> [15] </ref>. The page-mapping process is essentially the selection of a cache-bin for a particular virtual page. Since the number of cache-bins are limited, we may see frequent cache-set conflicts, if we do not utilize all the bins intelligently. Figure 2 explains this selection process. <p> Part of the SI is inside the page-offset and should be left untouched during the mapping process. The rest of the SI is considered as the color of a page, which is also called the cache-bin ID <ref> [15] </ref>. Selection of a cache-bin ID for a faulting virtual page will affect the number of cache-set conflicts in the later cache references, and in turn the overall execution time of a process. Page-coloring and bin-hopping schemes are extended to handle page-faults in CC-NUMA here.
Reference: [16] <author> J. Kuskin et al. </author> <title> The Stanford FLASH multiprocessor. </title> <booktitle> In Proc. Int. Sym. on Computer Architecture, </booktitle> <pages> pages 302-313, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction Cache-Coherent Non-Uniform Memory Access (CC-NUMA) multiprocessors become increasingly attractive as an architecture which provides a transparent access to local and remote memories and a good scalability. Systems based on this architecture include research prototypes such as the Stanford DASH [17] and FLASH <ref> [16] </ref>, MIT Alewife [10], University of Toronto NUMAchine [29], and Sun's S3.mp [25], as well as commercial products including the Sequent STiNG [21] Hewlett-Packard SPP [13], and Silicon Graphics Origin 2000. A CC-NUMA machine has a number of nodes connected by an interconnection network.
Reference: [17] <author> D. Lenoski et al. </author> <title> The Stanford DASH multiprocessor. </title> <journal> Computer, </journal> <volume> 25(3) </volume> <pages> 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Cache-Coherent Non-Uniform Memory Access (CC-NUMA) multiprocessors become increasingly attractive as an architecture which provides a transparent access to local and remote memories and a good scalability. Systems based on this architecture include research prototypes such as the Stanford DASH <ref> [17] </ref> and FLASH [16], MIT Alewife [10], University of Toronto NUMAchine [29], and Sun's S3.mp [25], as well as commercial products including the Sequent STiNG [21] Hewlett-Packard SPP [13], and Silicon Graphics Origin 2000. A CC-NUMA machine has a number of nodes connected by an interconnection network.
Reference: [18] <author> W. Li and K. Pingali. </author> <title> Access normalization: Loop restructuring for NUMA computers. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 11(4), </volume> <month> November </month> <year> 1993. </year>
Reference: [19] <author> Z. Li. </author> <title> Propagating symbolic relations on an interprocedural and hierarchical control flow graph. </title> <type> Technical Report CSci-93-87, </type> <institution> University of Minnesota, </institution> <year> 1993. </year>
Reference: [20] <author> D. J. Lilja. </author> <title> Exploiting the parallelism available in loops. </title> <journal> IEEE Computer, </journal> <volume> 27(2) </volume> <pages> 13-26, </pages> <year> 1994. </year>
Reference: [21] <author> T. Lovette and R. Clapp. STiNG: </author> <title> A CC-NUMA computer system for the commercial marketplace. </title> <booktitle> In Proc. Int. Sym. on Computer Architecture, </booktitle> <pages> pages 308-317, </pages> <year> 1996. </year>
Reference-contexts: Systems based on this architecture include research prototypes such as the Stanford DASH [17] and FLASH [16], MIT Alewife [10], University of Toronto NUMAchine [29], and Sun's S3.mp [25], as well as commercial products including the Sequent STiNG <ref> [21] </ref> Hewlett-Packard SPP [13], and Silicon Graphics Origin 2000. A CC-NUMA machine has a number of nodes connected by an interconnection network. Each node consists of one or a few processors, a private cache hierarchy, and a local memory module (Figure 1).
Reference: [22] <author> T. N. Nguyen. </author> <title> Interprocedural Compiler Analysis for Reducing Memory Latency and Network Traffic. </title> <type> PhD thesis, </type> <institution> University of Minnesota, </institution> <year> 1996. </year>
Reference-contexts: The discussion of data-allocation schemes is out of the scope of this paper. However, we do all the evaluations based on what we believe a good data-task co-allocation scheme <ref> [22] </ref> to minimize the effect of them. The distributed data on a CC-NUMA machine in different memory modules may compete for a limited portion of each node's private cache. <p> The content will be written to cache asynchronously. Sixteen outstanding misses can be tolerated. Detailed description of the simulator is attached in Appendix. The Panorama compiler uses a data-task co-allocation scheme <ref> [22] </ref> to align the data with tasks. It instruments the FORTRAN source code by inserting directives to identify the starting and ending address of an array and to specify the data allocation decisions. The simulator uses the inserted information and re-maps addresses at run-time for simulation. <p> They are swim256, and tomcatv from SPEC 92 benchmarks, ora and mgrid from SPEC 95 benchmarks. To alleviate the effect of poor data-task alignment, we did all experiments on the base of compiler-assisted data-task co-allocation <ref> [22] </ref>. All mapping techniques are based on the organization of level-two caches. Hence the associativity of level-one cache is fixed at 2-way. In order to shorten the simulation time, we reduce the iterative time steps in some programs.
Reference: [23] <author> T. N. Nguyen, Z. Li, J. Huang, G. Jin, D. Kim. </author> <title> Performance Evaluation of Memory Allocation Schemes on CC-NUMA Multiprocessors, </title> <type> Technical Report TR 96-043, </type> <institution> Department of Computer Science, Univerity of Minnesota. </institution> <month> 18 </month>
Reference: [24] <author> T. N. Nguyen, J. Gu, and Z. Li. </author> <title> An interprocedural parallelizing compiler and its support for hierarchical memory research. </title> <editor> In C.-H. Huang, P. Sadayappan, U. Banerjee, D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Proc. 8th Int. Workshop on Languages and Compilers for Parallel Computing, Lecture Notes in Computer Science 1033, </booktitle> <pages> pages 96-110, </pages> <address> Columbus, Ohio, </address> <month> August </month> <year> 1995. </year>
Reference: [25] <author> A. Nowatzyk et al. </author> <title> The S3.mp scalable shared memory multiprocessor. </title> <booktitle> In Proc. Int. Sym. on Computer Architecture, </booktitle> <year> 1995. </year>
Reference-contexts: Systems based on this architecture include research prototypes such as the Stanford DASH [17] and FLASH [16], MIT Alewife [10], University of Toronto NUMAchine [29], and Sun's S3.mp <ref> [25] </ref>, as well as commercial products including the Sequent STiNG [21] Hewlett-Packard SPP [13], and Silicon Graphics Origin 2000. A CC-NUMA machine has a number of nodes connected by an interconnection network.
Reference: [26] <author> W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T. Vetterling. </author> <title> Numerical Recipes: The Art of Scientific Computing (Fortran Version). </title> <publisher> Cambridge University Press, </publisher> <year> 1989. </year>
Reference: [27] <author> P. Stenstrom, J. Truman, and A. Gupta. </author> <title> Comparative performance evaluation of cache-coherent NUMA and COMA architectures. </title> <booktitle> In Proc. Int. Sym. on Comp. Arch., </booktitle> <pages> pages 80-91, </pages> <year> 1992. </year>
Reference: [28] <author> J. E. Veenstra and R. J. Fowler. </author> <title> MINT tutorial and user manual. </title> <type> Technical Report 452, </type> <institution> University of Rochester, </institution> <month> June </month> <year> 1993. </year> <institution> Dep. of Computer Science. </institution>
Reference-contexts: This technique divides a n-iteration parallel loop into chunks of n/p iterations for p processors. Each chunk is then assigned to a processor. Our experiments showed that other scheduling schemes are inferior to simple scheduling for the selected benchmarks. NUMAsim is an execution-driven multi-processor simulator based on MINT <ref> [28] </ref>. However, modifications are done to support super-scalar CPU model [8] and weak-ordered memory consistency [3]. The key parameters of our processor model and component latency are summarized in Table 1. These parameters are selected based on those of several existing and developing commercial systems.
Reference: [29] <author> Z. Vranesic et al. </author> <title> The NUMAchine multiprocessor. </title> <type> Technical report, </type> <institution> University of Toronto, </institution> <year> 1995. </year>
Reference-contexts: Systems based on this architecture include research prototypes such as the Stanford DASH [17] and FLASH [16], MIT Alewife [10], University of Toronto NUMAchine <ref> [29] </ref>, and Sun's S3.mp [25], as well as commercial products including the Sequent STiNG [21] Hewlett-Packard SPP [13], and Silicon Graphics Origin 2000. A CC-NUMA machine has a number of nodes connected by an interconnection network.
Reference: [30] <author> M. Dubois, J. Wang, L. Barroso, K. Lee,Y. Chen. </author> <title> Delayed Consistency and Its Effects on the Miss Rate of Parallel Programs. </title> <booktitle> The 2nd Int'l Symposium on Architectural Support for Programming Languages and Operating System, </booktitle> <month> October </month> <year> 1991. </year> <pages> 19 20 21 22 </pages>
References-found: 30

