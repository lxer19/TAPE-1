URL: http://www.cs.cmu.edu/afs/cs/usr/skoenig/www/sven/papers/colt96.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs/usr/skoenig/www/sven/abstracts/colt96.html
Root-URL: 
Email: skoenig@cs.cmu.edu, smir@cs.cmu.edu  
Title: Graph Learning with a Nearest Neighbor Approach  
Author: Sven Koenig and Yury Smirnov 
Address: Pittsburgh, PA 15213-3891, USA  
Affiliation: School of Computer Science, Carnegie Mellon University  
Abstract: In this paper, we study how to traverse all edges of an unknown graph G = (V; E) that is bi-directed and strongly connected. This problem can be solved with a simple algorithm that traverses all edges at most twice, and no algorithm can do better in the worst case. Artificial Intelligence researchers, however, often use the following online nearest neighbor algorithm: repeatedly take a shortest path to the closest unexplored edge and traverse it. We prove bounds on the worst-case complexity of this algorithm. We show, for example, that its worst-case complexity is close to optimal for some classes of graphs, such as graphs with linear or star topology and dense graphs with edge lengths one. In general, however, its complexity can grow faster than linear in the sum of all edge lengths, although not faster than log(V ) times the sum of all edge lengths.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G.D. Benson and A. </author> <title> Prieditis. Learning continuous-space navigation heuristics in real time. </title> <booktitle> In Proceedings of the Conference on Simulation of Adaptive Behavior: From Animals to Animats, </booktitle> <year> 1992. </year>
Reference-contexts: Both Incremental Best-First Search (IBFS) [9] and the Dynamic A* (D*) algorithm [12] are versions of OnNNA. The Learning Real-Time A* (LRTA*) algorithm [7], Prioritized Sweeping [8], and the navigation method by Ben-son and Prieditis <ref> [1] </ref> are fast approximations of the behavior of OnNNA.
Reference: [2] <author> M. Betke, R. Rivest, and M. Singh. </author> <title> Piecemeal learning of an unknown environment. </title> <journal> Machine Learning, </journal> <volume> 18(2/3), </volume> <year> 1995. </year>
Reference-contexts: We assume that the robots are not able to recognize a corridor from the opposite direction when they have traversed it in one direction, unless they have already traversed it in the opposite direction as well. Different from piecemeal learning <ref> [2] </ref>, we do not require the robots to return periodically to their starting position for recharging. Similar exploration problems arise in distributed computing when exploring unidirected networks [6] and in task learning, for example when a skill acquired by a newborn does not imply the opposite skill.
Reference: [3] <author> A. Blum, P. Chalasani, D. Coppersmith, B. Pulleyblank, P. Raghavan, and M. Sudan. </author> <title> The minimum latency problem. </title> <booktitle> In Proceedings of the Symposium on Theory of Computing, </booktitle> <pages> pages 163-171, </pages> <year> 1994. </year>
Reference-contexts: Thus, the directed edge from 0 to 1 has been traversed 2 N times, which is not a constant <ref> [3] </ref>. Theorem 5 Let G = (V; E) be an arbitrary star with center s 2 V and edge lengths one and W V be an arbitrary set of vertices with s 2 W .
Reference: [4] <author> X. Deng and C.H. Papadimitriou. </author> <title> Exploring an unknown graph. </title> <booktitle> In Proceedings of the Symposium on Foundations of Computer Science, </booktitle> <pages> pages 355-361, </pages> <year> 1990. </year>
Reference-contexts: We highlight the advantages of the algorithm that we study in this paper and explain why it has been used by researchers from Artificial Intelligence, although its worst-case complexity has been unknown so far <ref> [4] </ref>. (The remainder of this section can be skipped by readers who are only interested in the results.) Consider the following two graph learning strategies: Definition 2 Depth-First Search (DFS) Take unexplored edges whenever possible (ties can be broken arbitrarily). <p> n, m, while DFS can explore the rest of the graph as follows: n, g, f, b, f, b, f, g, n, m, j, i, j, h, j, k, j, k, j, h, j, i, j, m, l, c, d, a, 1 The exact origin of the algorithm is unclear. <ref> [4] </ref> and [6] stated it explicitly as a graph learning algorithm, but it has been used earlier as part of proofs about Eulerian tours, for example in [5]. d, e, d, e, d, a, d, c, l, m.
Reference: [5] <author> C. Hierholzer. </author> <title> Uber die Moglichkeit, einen Linienzug ohne Wiederholung und ohne Unterbrechung zu umfahren. </title> <journal> Mathe-matische Annalen, </journal> <volume> 6 </volume> <pages> 30-32, 1873 (sic!). </pages>
Reference-contexts: j, k, j, k, j, h, j, i, j, m, l, c, d, a, 1 The exact origin of the algorithm is unclear. [4] and [6] stated it explicitly as a graph learning algorithm, but it has been used earlier as part of proofs about Eulerian tours, for example in <ref> [5] </ref>. d, e, d, e, d, a, d, c, l, m. Both algorithms traverse every edge of a graph exactly twice and thus the length of their exploration tour is 2 weight (G).
Reference: [6] <author> E. Korach, S. Kutten, and S. Moran. </author> <title> A modular technique for the design of efficient distributed leader finding algorithms. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(1) </volume> <pages> 84-101, </pages> <year> 1990. </year>
Reference-contexts: Different from piecemeal learning [2], we do not require the robots to return periodically to their starting position for recharging. Similar exploration problems arise in distributed computing when exploring unidirected networks <ref> [6] </ref> and in task learning, for example when a skill acquired by a newborn does not imply the opposite skill. Examples are opening and closing a jar or switching a TV set on and off. <p> while DFS can explore the rest of the graph as follows: n, g, f, b, f, b, f, g, n, m, j, i, j, h, j, k, j, k, j, h, j, i, j, m, l, c, d, a, 1 The exact origin of the algorithm is unclear. [4] and <ref> [6] </ref> stated it explicitly as a graph learning algorithm, but it has been used earlier as part of proofs about Eulerian tours, for example in [5]. d, e, d, e, d, a, d, c, l, m.
Reference: [7] <author> R.E. Korf. </author> <title> Real-time heuristic search. </title> <journal> Artificial Intelligence, </journal> <volume> 42(2-3):189-211, </volume> <month> 3 </month> <year> 1990. </year>
Reference-contexts: A possible sequence of vertices that OnNNA can traverse on the graph from Figure 1 is given in the proof of Theorem 2. Both Incremental Best-First Search (IBFS) [9] and the Dynamic A* (D*) algorithm [12] are versions of OnNNA. The Learning Real-Time A* (LRTA*) algorithm <ref> [7] </ref>, Prioritized Sweeping [8], and the navigation method by Ben-son and Prieditis [1] are fast approximations of the behavior of OnNNA.
Reference: [8] <author> A.W. Moore and C.G. Atkeson. </author> <title> Prioritized sweeping: Reinforcement learning with less data and less time. </title> <journal> Machine Learning, </journal> <volume> 13 </volume> <pages> 103-130, </pages> <year> 1993. </year>
Reference-contexts: A possible sequence of vertices that OnNNA can traverse on the graph from Figure 1 is given in the proof of Theorem 2. Both Incremental Best-First Search (IBFS) [9] and the Dynamic A* (D*) algorithm [12] are versions of OnNNA. The Learning Real-Time A* (LRTA*) algorithm [7], Prioritized Sweeping <ref> [8] </ref>, and the navigation method by Ben-son and Prieditis [1] are fast approximations of the behavior of OnNNA.
Reference: [9] <author> J.C. Pemberton and R.E. Korf. </author> <title> Incremental path planning on graphs with cycles. </title> <booktitle> In Proceedings of the AI Planning Systems Conference, </booktitle> <pages> pages 179-188, </pages> <year> 1992. </year>
Reference-contexts: A possible sequence of vertices that OnNNA can traverse on the graph from Figure 1 is given in the proof of Theorem 2. Both Incremental Best-First Search (IBFS) <ref> [9] </ref> and the Dynamic A* (D*) algorithm [12] are versions of OnNNA. The Learning Real-Time A* (LRTA*) algorithm [7], Prioritized Sweeping [8], and the navigation method by Ben-son and Prieditis [1] are fast approximations of the behavior of OnNNA.
Reference: [10] <author> D.J. Rosenkrantz, R.E. Stearns, and P.M. Lewis II. </author> <title> An analysis of several heuristics for the traveling salesman problem. </title> <journal> SIAM Journal of Computing, </journal> <volume> 6(3) </volume> <pages> 563-581, </pages> <year> 1977. </year>
Reference-contexts: They showed that the length of any OffNNA (s; V; G)-TSP tour on such cliques is at most 1 2 dlog 2 jV je + 1 2 times the length of a shortest (standard) TSP tour on G, and that this bound is tight <ref> [10] </ref>. Theorem 3 Let G = (V; E) be an arbitrary graph, W V be an arbitrary set of vertices, and s be any vertex in W . <p> The length of an edge e 2 E 0 equals the length of a shortest path between both of its vertices on G. These lengths are symmetrical and satisfy the triangle inequality. The result by Rosenkrantz, Stearns, and Lewis <ref> [10] </ref> applies to G 0 : the length of any OffNNA (s; W; G 0 )-TSP tour on G 0 is at most 1 2 dlog 2 jW je + 1 2 times the length of a shortest (standard) TSP tour on G 0 . <p> Then, the worst-case complexity of OffNNA is O (log jV j weight (G)). For the worst-case example presented by Rosenkrantz, Stearns, and Lewis <ref> [10] </ref>, OffNNA traverses every edge at most once and thus it holds that L OffNNA (s; W; G) weight (G).
Reference: [11] <author> Y. Smirnov, S. Koenig, M. Veloso, and R. Simmons. </author> <title> Efficient goal-directed exploration. </title> <booktitle> In Proceedings of the National Conference on AI, page to appear, </booktitle> <year> 1996. </year>
Reference-contexts: This graph learning the value of this edge. In this paper, we are basically studying the uninformed case, where all edge values are zero. However, we are able to reduce the complexity analysis of OnNNA with edge values to this case <ref> [11] </ref>. problem can be solved with a worst-case complexity of two times the weight of the graph, and no algorithm can do better in the worst case. We therefore pursue the question whether the worst-case complexity of OnNNA is linear in the weight of the graph. <p> Second, we are developing algorithms that maintain the flexibility of the on-line nearest neighbor algorithm, but are able to make performance guarantees that are linear in the weight of the graph <ref> [11] </ref>. Acknowledgements Thanks to Avrim Blum and Lonnie Chrisman for stimulating discussions and to Peter Stone for helpful comments.
Reference: [12] <author> A. Stentz. </author> <title> The focussed D* algorithm for real-time replanning. </title> <booktitle> In Proceedings of the IJCAI, </booktitle> <pages> pages 1652-1659, </pages> <year> 1995. </year>
Reference-contexts: A possible sequence of vertices that OnNNA can traverse on the graph from Figure 1 is given in the proof of Theorem 2. Both Incremental Best-First Search (IBFS) [9] and the Dynamic A* (D*) algorithm <ref> [12] </ref> are versions of OnNNA. The Learning Real-Time A* (LRTA*) algorithm [7], Prioritized Sweeping [8], and the navigation method by Ben-son and Prieditis [1] are fast approximations of the behavior of OnNNA.
References-found: 12

