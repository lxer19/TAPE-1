URL: ftp://ftp.csd.uu.se/pub/papers/theses/0018.ps.gz
Refering-URL: http://www.csd.uu.se/~thomasl/reform.html
Root-URL: 
Title: The Compilation and Execution of Recursion-Parallel Prolog on Shared Memory Multiprocessors  
Author: Thomas Lindgren UPMAIL 
Degree: Thesis for the Degree of Licentiate of Philosophy  
Address: Box 311 S-751 05 UPPSALA SwedenISSN 0283-359X  
Affiliation: Computing Science Department Uppsala University  
Note: UPPSALA THESES IN COMPUTING SCIENCE No. 18/93  
Abstract-found: 0
Intro-found: 1
Reference: 1. <author> H. At-Kaci, </author> <title> The WAM: A (Real) Tutorial, </title> <publisher> MIT Press, </publisher> <year> 1991. </year> <note> f3, 48, 55g </note>
Reference-contexts: execution models The large head unification of nrev ([1; 2; 3; 4]; RevList) creates the following goals: nrev ([]; Ys 4 ); append (Ys 4 ; [4]; Ys 3 ); append (Ys 3 ; [3]; Ys 2 ); append (Ys 2 ; [2]; Ys 1 ); append (Ys 1 ; <ref> [1] </ref>; RevList) Each of the append/3 goals is a separate process, all starting simultaneously after the sequential nrev/2 call finishes. <p> If a term t belongs to the concretization of X , then sel (all (X ); t) = ftg. Parameter descriptors are handled similarly. For example, if the variable X has type list nv f, then for the element <ref> [1; 2; 3jA] </ref> (which belongs to list nv f), the variable descriptor elt (X ) refers to the elements 1,2,3 while tl (X) refers to the final tail A. The descriptor all (X ) refers to the entire term [1; 2; 3jA]. <p> variable X has type list nv f, then for the element <ref> [1; 2; 3jA] </ref> (which belongs to list nv f), the variable descriptor elt (X ) refers to the elements 1,2,3 while tl (X) refers to the final tail A. The descriptor all (X ) refers to the entire term [1; 2; 3jA]. Parameter descriptors are used for call and success patterns to describe sharing between arguments. Source variable descriptors are used by i-states to describe dependences between variables in the clause being analyzed. <p> In this section we provide a high-level overview of the machine. For a closer look, the reader is urged to consult At-Kaci <ref> [1] </ref>. The WAM consists of a set of registers and four global data areas: a code area, a local stack, a global stack and a trail stack. Registers hold procedure parameters and temporary values and point into the local and global stacks.
Reference: 2. <author> K.A.M. Ali, R. Karlsson, </author> <title> The Muse or-parallel Prolog model and its performance, </title> <booktitle> in Proceedings of the North American Conference on Logic Programming, </booktitle> <publisher> MIT Press, </publisher> <year> 1990. </year> <note> f3, 90g </note>
Reference-contexts: ([X|Xs],Zs) :- nrev (Xs,Ys), append (Ys,[X],Zs). 20 Recursion-parallel execution models The large head unification of nrev ([1; 2; 3; 4]; RevList) creates the following goals: nrev ([]; Ys 4 ); append (Ys 4 ; [4]; Ys 3 ); append (Ys 3 ; [3]; Ys 2 ); append (Ys 2 ; <ref> [2] </ref>; Ys 1 ); append (Ys 1 ; [1]; RevList) Each of the append/3 goals is a separate process, all starting simultaneously after the sequential nrev/2 call finishes. <p> If a term t belongs to the concretization of X , then sel (all (X ); t) = ftg. Parameter descriptors are handled similarly. For example, if the variable X has type list nv f, then for the element <ref> [1; 2; 3jA] </ref> (which belongs to list nv f), the variable descriptor elt (X ) refers to the elements 1,2,3 while tl (X) refers to the final tail A. The descriptor all (X ) refers to the entire term [1; 2; 3jA]. <p> variable X has type list nv f, then for the element <ref> [1; 2; 3jA] </ref> (which belongs to list nv f), the variable descriptor elt (X ) refers to the elements 1,2,3 while tl (X) refers to the final tail A. The descriptor all (X ) refers to the entire term [1; 2; 3jA]. Parameter descriptors are used for call and success patterns to describe sharing between arguments. Source variable descriptors are used by i-states to describe dependences between variables in the clause being analyzed. <p> Third, there are restrictions to the language to eliminate troublesome constructs, such as call/1, assert/1 and others. One could envision lifting these restrictions. Fourth, we could combine recursion-parallelism with other forms of parallelism. In particular, or-parallelism such as in Muse <ref> [2] </ref> might be a useful addition. Compilation. One of the points of Reform Prolog is that absolute performance in a restricted execution model is preferrable to more general but slower models.
Reference: 3. <author> U. Banerjee, R. Eigenmann, A. Nicolau, D.A. Padua, </author> <title> Automatic program parallelization, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 81, no. 2, </volume> <month> February, </month> <year> 1993 </year> <month> f8g </month>
Reference-contexts: The predicate is list recursive. nrev ([],[]). nrev ([X|Xs],Zs) :- nrev (Xs,Ys), append (Ys,[X],Zs). 20 Recursion-parallel execution models The large head unification of nrev ([1; 2; 3; 4]; RevList) creates the following goals: nrev ([]; Ys 4 ); append (Ys 4 ; [4]; Ys 3 ); append (Ys 3 ; <ref> [3] </ref>; Ys 2 ); append (Ys 2 ; [2]; Ys 1 ); append (Ys 1 ; [1]; RevList) Each of the append/3 goals is a separate process, all starting simultaneously after the sequential nrev/2 call finishes.
Reference: 4. <author> J. Barklund, J. Bevemyr, </author> <title> Executing bounded quantifications on shared memory multiprocessors, </title> <note> to appear at PLILP'93 f6, 74g </note>
Reference-contexts: The predicate is list recursive. nrev ([],[]). nrev ([X|Xs],Zs) :- nrev (Xs,Ys), append (Ys,[X],Zs). 20 Recursion-parallel execution models The large head unification of nrev ([1; 2; 3; 4]; RevList) creates the following goals: nrev ([]; Ys 4 ); append (Ys 4 ; <ref> [4] </ref>; Ys 3 ); append (Ys 3 ; [3]; Ys 2 ); append (Ys 2 ; [2]; Ys 1 ); append (Ys 1 ; [1]; RevList) Each of the append/3 goals is a separate process, all starting simultaneously after the sequential nrev/2 call finishes. <p> Reductions can be compiled according to the following principle, which is a modification of that used by Barklund and Bevemyr in coding bounded quantifications <ref> [4] </ref>: 1. The sequential worker executes a primitive that creates a vector-list with a length equal to the number of workers, and initializes each entry of the vector to an appropriate value (for summations, 0; for products, 1). This is the temporary value table. 2.
Reference: 5. <author> J. Barklund, J. Bevemyr, </author> <title> Prolog with arrays and bounded quantifications, in Logic Programming and Automated Reasoning, </title> <publisher> LNCS 698, Springer Verlag, </publisher> <year> 1993 </year> <month> f80g </month>
Reference-contexts: The interpretive element of a scan, in that a term represents the arithmetic operations to be performed, could be eliminated by either compiling the scan into loop code similar to that used in sequential implementations of bounded quantifiers <ref> [5] </ref>. The sequential portion could be reduced by parallelizing the primitive scan operation at least partially. Neither of these approaches have currently been implemented. Chapter 5 Evaluation We have implemented the ideas presented in this thesis in a prototype compiler.
Reference: 6. <author> J. Barklund, H. Millroth, </author> <title> Nova Prolog, </title> <type> UPMAIL Technical Report 52, </type> <institution> Computing Science Department, Uppsala University, </institution> <year> 1988. </year> <month> f6g </month>
Reference: 7. <author> J. Barklund, H. Millroth, </author> <title> Providing iteration and concurrency in logic programs through bounded quantifications, </title> <booktitle> in International Conference on Fifth Generation Systems, </booktitle> <year> 1992. </year> <month> f6g </month>
Reference: 8. <author> J. Bevemyr, </author> <title> A Recursion Parallel Prolog Engine, </title> <booktitle> Licentiate of Philosophy Thesis, Uppsala Theses in Computer Science 16/93, 1993. f11, </booktitle> <volume> 57, 76, </volume> <month> 79g </month>
Reference-contexts: The design and implementation of the Reform engine is described in greater detail by Bevemyr <ref> [8] </ref>. 4.3 COMPILER OVERVIEW The Reform compiler is responsible for the following tasks: 1. Generating code to perform head unifications and start all processes. This is described in Section 4.4, Section 4.5 and Section 4.6. 2. Ensuring safeness by compile-time suspension when shared variables may be conditionally bound. <p> By performing all the head unifications of the predicate at once, ample fine-grained parallelism is exposed. In our current benchmark set, which emphasizes medium- and coarse-grained parallelism, the time spent in head unifications is small (on the order of 0.5% or less of the execution time <ref> [8] </ref>). On the multiprocessors used in our experiments, with 4 and 24 processors, this time was insignificant. If the large unification instructions were to become a bottleneck, there are several things that can be done. Most of the build instructions contains large amounts of fine-grained parallelism. <p> For some methods to implement the lock and unlock instructions, consult Beve-myr's Licentiate thesis <ref> [8] </ref>. 4.10.5 Recurrences The advantage of encoding reductions as we do is that each worker can compute the partial result over its allocated recursion levels independently of the others, and compiled arithmetic can be retained.
Reference: 9. <author> J. Bevemyr, T. Lindgren, H. Millroth, </author> <title> Exploiting recursion-parallelism in Prolog, </title> <editor> in PARLE-93, eds. A. Bode, M. Reeve, G. Wolf, </editor> <publisher> LNCS 694, Springer Verlag, </publisher> <year> 1993. </year> <note> f12, 84g </note>
Reference-contexts: We discuss the reasons for this below. 5.2.1 Comparison to previous implementations Bevemyr, Millroth and the author have previously described an implementation of Reform Prolog for the Sequent Symmetry <ref> [9] </ref>, where some of the above benchmarks were executed. There are some differences in the code executed as well as benchmarks, which we further describe below. However, there is some interest in comparing the benchmark results for the two implementations. <p> machine than on the Sequent machine. (We have previously measured a normalized efficiency of 0.83 for Nrev on the Sequent.) This may be due to each worker being substantially faster on the Sun. 5.2.2 Quality of generated code We compared the generated code with hand coded versions of the programs <ref> [9, 10] </ref>, which were generated by manually introducing suspension and locking unification instructions. 5.2. Execution times 85 In the case of Map, the code was identical to the hand coded version.
Reference: 10. <author> J. Bevemyr, T. Lindgren, H. Millroth, </author> <title> Reform Prolog: The language and its implementation, </title> <booktitle> in Logic Programming: Proceedings of the Tenth International Conference, </booktitle> <publisher> MIT Press, </publisher> <year> 1993. </year> <note> f12, 84g 93 94 </note>
Reference-contexts: machine than on the Sequent machine. (We have previously measured a normalized efficiency of 0.83 for Nrev on the Sequent.) This may be due to each worker being substantially faster on the Sun. 5.2.2 Quality of generated code We compared the generated code with hand coded versions of the programs <ref> [9, 10] </ref>, which were generated by manually introducing suspension and locking unification instructions. 5.2. Execution times 85 In the case of Map, the code was identical to the hand coded version.
Reference: 11. <author> M. Bruynooghe, </author> <title> A practical framework for the abstract interpretation of logic programs, </title> <journal> Journal of Logic Programming 10 </journal> <pages> 91-124, </pages> <year> 1991. </year> <month> f53g </month>
Reference-contexts: Debray [24] also considers this solution. Le Charlier and Van Hentenryck [44] use a more sophisticated method to avoid superfluous recomputation by keeping track of dependences between goals. Debray's algorithm statically approximates recomputation dependences through the call graph, while Le Charlier and Van Hentenryck does so dynamically. Bruynooghe <ref> [11] </ref> has defined a framework based on abstract proof trees; in our work, we found Debray's more operational formulation more suitable for our purposes. We think our analysis could be recast into Bruynooghe's framework with a minor effort.
Reference: 12. <author> H. Burkhardt, S. Frank, B. Knobe, J. Rothnie, </author> <title> Overview of the KSR1 Computer System, </title> <type> Technical report KSR-TR-9202001, </type> <institution> Kendall Square Research, </institution> <year> 1992 </year> <month> f11g </month>
Reference: 13. <author> M. Carlsson, </author> <title> Design and Implementation of an Or-Parallel Prolog Engine, </title> <type> Ph.D. Thesis, </type> <institution> SICS-RITA/02, </institution> <year> 1990. </year> <month> f3g </month>
Reference: 14. <author> K.L. Clark, F. McCabe, </author> <title> The control facilities of IC-Prolog, in Expert Systems in the Micro-Electronic World (ed. </title> <editor> D. Michie), </editor> <publisher> Edinburgh University Press, </publisher> <year> 1979. </year> <month> f5g </month>
Reference: 15. <author> K.L. Clark, S. Gregory, </author> <title> A relational language for parallel programming, </title> <booktitle> in Proceedings ACM Symposium on Functional Programming and Computer Architecture, </booktitle> <year> 1981. </year> <month> f5g </month>
Reference: 16. <author> K.L. Clark, S. Gregory, </author> <title> PARLOG: A parallel logic programming language, </title> <type> report DOC 83/5, </type> <institution> Department of Computing, Imperial College, </institution> <address> London, </address> <year> 1983. </year> <month> f5g </month>
Reference: 17. <author> M. Codish, M. Falaschi, K. Marriott, </author> <title> Suspension analysis for concurrent logic programs, </title> <booktitle> in Logic Programming: Proceedings of the Eighth International Conference f54g </booktitle>
Reference-contexts: Analyses of concurrent logic languages [19] suffer from the same disadvantages. There are properties that do not rely on execution order, however, and these can be inferred more efficiently <ref> [17, 25] </ref>. Likewise, Muthukumar and Hermenegildo's sharing analysis [52] detects sharing and groundness to reduce independence tests in independent and-parallel implementations, without considering parallel execution (which is not necessary).
Reference: 18. <author> M. Codish, A. Mulkers, M. Bruynooghe, M. Garcia de la Banda, M. Hermenegildo, </author> <title> Improving abstract interpretations by combining domains, </title> <booktitle> in Proceedings of the 1993 Symposium on Partial Evaluation and Program Manipulation, </booktitle> <publisher> ACM Press 1993. f53g </publisher>
Reference-contexts: The least upper bound of these two values is often defined to be any. By introducing free+nil, our analyser can continue the analysis with precise types. Independence is also considered by Stndergaard [65] as well as Codish et al. <ref> [18] </ref>. These domains have a more precise notion of sharing, but do not trace types as extensively as ours. Furthermore, they do not incorporate the indlist type which seems to be pragmatically useful in the case of Reform Prolog.
Reference: 19. <author> C. Codognet, P. Codognet, M.-M. Corsini, </author> <title> Abstract interpretation for concurrent logic languages, </title> <booktitle> in Logic Programming: Proceedings of the 1990 North American Conference, </booktitle> <publisher> MIT Press 1990 f54g </publisher>
Reference-contexts: Analyses of concurrent logic languages <ref> [19] </ref> suffer from the same disadvantages. There are properties that do not rely on execution order, however, and these can be inferred more efficiently [17, 25].
Reference: 20. <author> J.S. Conery, D.F. Kibler, </author> <title> Parallel interpretation of logic programs, </title> <booktitle> in Proceedings ACM Symposium on Functional Programming and Computer Architecture, </booktitle> <year> 1981. </year> <month> f4g </month>
Reference: 21. <author> P. Cousot, R. Cousot, </author> <title> Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints, </title> <booktitle> in Conference Record of the Fourth ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1977. </year> <month> f26g </month>
Reference-contexts: Abstract interpretation. Static analysis of a programming language can be expressed as an abstract interpretation of the formal semantics of the language, as proposed by Cousot and Cousot <ref> [21, 22] </ref>. The abstract interpretation of a program yields a conservative approximation of the runtime results. If properly defined, the abstract interpretation procedure is guaranteed to terminate.
Reference: 22. <author> P. Cousot, R. Cousot, </author> <title> Abstract interpretation and application to logic programs, </title> <journal> Journal of Logic Programming, 1992:13:103-179. f26, </journal> <volume> 27, 37g 95 </volume>
Reference-contexts: Abstract interpretation. Static analysis of a programming language can be expressed as an abstract interpretation of the formal semantics of the language, as proposed by Cousot and Cousot <ref> [21, 22] </ref>. The abstract interpretation of a program yields a conservative approximation of the runtime results. If properly defined, the abstract interpretation procedure is guaranteed to terminate. <p> Prove the correctness of abstract operations using this connection. (v) Prove termination by showing that the abstract operations are monotonic, and the abstract domain has no infinite ascending chains. (Infinite chains can be accomodated by using widening and narrowing operations <ref> [22] </ref>, but we will not consider that approach further.) Cousot and Cousot have shown that all relevant properties of the semantics are conservatively approximated if the domains are connected by a Galois surjection. <p> The abstract semantics yields a set of equations to be solved, either statically or iteratively. The framework of Debray performs a sequence of chaotic iterations <ref> [22] </ref> to arrive at a fixpoint. We will be quite informal when defining our analysis. We will define an abstract domain that captures several properties that are interesting when executing Reform Prolog but refrain from formal proofs of correctness. <p> Finally, we define the concretization of i-states and patterns. The call and success patterns the analyser works with are elements of a family product domain defined below. We say that the reduction of a domain <ref> [22] </ref> is the domain of equivalence classes of elements in the original domain, where elements are equivalent if they have the 38 Analysing recursion parallel programs same concretization. For instance, there is no need to distinguish whether ground terms are linear, indlist or nonlinear since they contain no variables.
Reference: 23. <author> J. Crammond, </author> <title> The abstract machine and implementation of parallel Parlog, </title> <booktitle> New Generation Computing 10 (1992), </booktitle> <pages> pp. 385-422, </pages> <publisher> Springer Verlag 1992. f77, 79g </publisher>
Reference-contexts: On the other hand, control tokens require explicit release of the token which may be a considerable overhead if many tokens are used. Crammond <ref> [23] </ref> describes the suspension machinery for an implementation of parallel Parlog, a concurrent logic language. Suspension is controlled by abstract machine instructions that are versions of the get and unify instructions of the WAM that suspend on unbound variables. Thus, these operations cannot be strength-reduced to their simpler sequential counterparts. <p> However, Shen notes that a compiler might do the job, similarly to compilers for independent and-parallel languages. 4.10.4 Locking unification Most of the implementations seem to use the simple strategy of constructing the term and performing a general unification, when atomic writes are required. For instance, Crammond notes <ref> [23] </ref>: When constructing a structure term in output unification, it is necessary to construct a complete term before unifying it with a goal call argument since some other process may start accessing it immediately.
Reference: 24. <author> S.K. Debray, </author> <title> Static inference of modes and data dependencies in logic programs, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 11, No. 3, </volume> <month> July </month> <year> 1989, </year> <pages> pp. 418-450. </pages> <editor> f27, </editor> <volume> 28, 33, 40, </volume> <month> 53g </month>
Reference-contexts: Thus, for the analysis designer it remains to be constructed an appropriate semantics and an appropriate abstract domain. For logic programming, there have been several proposals for abstract interpretation algorithms based on top-down and bottom-up semantics, or even their combination. We have chosen the framework proposed by Debray <ref> [25, 24] </ref>, since it very clearly approximates a standard interpreter for Prolog. Since we analyse full Prolog, including cut, metaprimitives and higher-order operations, we felt the semantics should be fairly low-level and close to the way Prolog actually executes. <p> Both these classes of objects are composed from several domains that represent types and constraints on variables. 3.2.1 Types The type domain of the Reform compiler is an extension of the domain described by Debray and Warren <ref> [26, 24] </ref>. The Debray-Warren domain and a simplification of the domain used in the Reform compiler (without recursive list types) are shown in Figure 3.1. The full type domain of the Reform compiler, including difference list handling, is shown in Figure 3.2. <p> In the case of possible aliases, step (iii) merges aliasing classes by performing the coupled closure operation <ref> [24] </ref>. The coupled closure of two aliasing components p 0 and p 00 is the least aliasing component p such that if d p 0 p 00 $ d 0 , then d p $ d 0 . <p> : : : ; X n =t n g j 1 i n; t i 2 fl (T i )g The independence, locality and aliasing components constrain free variables simi larly to the pattern case. 3.3 ABSTRACT INTERPRETATION ALGORITHM The basic global analysis algorithm is adapted from that of Debray <ref> [25, 24] </ref>. 3.3. Abstract interpretation algorithm 41 Debray describes a framework for global analysis. To actually arrive at a program analysis, the operations below must be provided. <p> Adding such types is an interesting possibility for future extensions. 3.6.2 Analysis algorithm Taylor [68] considers several alternatives for fixpoint computation, also settling on maintaining a single call-success pattern pair. Debray <ref> [24] </ref> also considers this solution. Le Charlier and Van Hentenryck [44] use a more sophisticated method to avoid superfluous recomputation by keeping track of dependences between goals. Debray's algorithm statically approximates recomputation dependences through the call graph, while Le Charlier and Van Hentenryck does so dynamically.
Reference: 25. <author> S.K. Debray, </author> <title> Efficient dataflow analysis of logic programs, </title> <journal> Journal of the ACM, </journal> <volume> Vol 39, No. 4, </volume> <month> October </month> <year> 1992. </year> <journal> f27, </journal> <volume> 30, 40, 43, 53, </volume> <month> 54g </month>
Reference-contexts: Thus, for the analysis designer it remains to be constructed an appropriate semantics and an appropriate abstract domain. For logic programming, there have been several proposals for abstract interpretation algorithms based on top-down and bottom-up semantics, or even their combination. We have chosen the framework proposed by Debray <ref> [25, 24] </ref>, since it very clearly approximates a standard interpreter for Prolog. Since we analyse full Prolog, including cut, metaprimitives and higher-order operations, we felt the semantics should be fairly low-level and close to the way Prolog actually executes. <p> If instantiating one of the term may instantiate the other, the terms are possibly aliased. Assuming that the concretization of an abstract element is a set of terms, we say that an abstract domain is substitution-closed <ref> [25] </ref> when every element T satisfies fx j x 2 fl (T )g fl (T ); for any substitution Thus, all instantiations of a term belonging to the concretization of an abstract element also belong to the concretization of the same abstract element. <p> : : : ; X n =t n g j 1 i n; t i 2 fl (T i )g The independence, locality and aliasing components constrain free variables simi larly to the pattern case. 3.3 ABSTRACT INTERPRETATION ALGORITHM The basic global analysis algorithm is adapted from that of Debray <ref> [25, 24] </ref>. 3.3. Abstract interpretation algorithm 41 Debray describes a framework for global analysis. To actually arrive at a program analysis, the operations below must be provided. <p> We will see that the data-parallel style of recursion-parallel programs simplifies analysis as compared to more general efforts <ref> [25] </ref>. Locality annotation Prior to parallel analysis of a recursion-parallel body, the types are annotated as robust or local; this phase simulates the large head unification phase of concrete execution. It is performed once per body to be executed, since locality information can change between calls. <p> Bruynooghe [11] has defined a framework based on abstract proof trees; in our work, we found Debray's more operational formulation more suitable for our purposes. We think our analysis could be recast into Bruynooghe's framework with a minor effort. Debray <ref> [25] </ref> also considers a much more general framework for analysing concurrent logic programs. We have not compared our formulation with his, but note that more general parallel execution also may lead to a lessening of precision. <p> Analyses of concurrent logic languages [19] suffer from the same disadvantages. There are properties that do not rely on execution order, however, and these can be inferred more efficiently <ref> [17, 25] </ref>. Likewise, Muthukumar and Hermenegildo's sharing analysis [52] detects sharing and groundness to reduce independence tests in independent and-parallel implementations, without considering parallel execution (which is not necessary).
Reference: 26. <author> S.K. Debray, D.S. Warren, </author> <title> Automatic mode inference for logic programs, </title> <journal> Journal of Logic Programming, </journal> <volume> Vol. 5, No. 3, </volume> <year> 1988. </year> <note> f28, 30g </note>
Reference-contexts: Both these classes of objects are composed from several domains that represent types and constraints on variables. 3.2.1 Types The type domain of the Reform compiler is an extension of the domain described by Debray and Warren <ref> [26, 24] </ref>. The Debray-Warren domain and a simplification of the domain used in the Reform compiler (without recursive list types) are shown in Figure 3.1. The full type domain of the Reform compiler, including difference list handling, is shown in Figure 3.2. <p> This property allows us to ignore the effects of aliasing. Unfortunately, the locality (below), independence (below) and type domains are not substitution-closed. Without recording which terms may share free variables (i.e. which terms are possibly aliased), analysis over a non-substitution closed domain may yield incorrect results <ref> [26] </ref>. 3.2. An abstract domain for types, locality and safeness 31 Example. Consider the following program fragment: ..., X = Y, Y = 3, ... Assume that X and Y are both free initially. When Y is unified with 3, it becomes ground.
Reference: 27. <author> D. De Groot, </author> <title> Restricted AND-parallelism, </title> <booktitle> in Proceedings of the International Conference on Fifth Generation Systems, </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1984. </year> <month> f4g </month>
Reference: 28. <author> P. Feautrier, </author> <title> Dataflow analysis of array and scalar references, </title> <journal> International Journal of Parallel Programming, </journal> <volume> Vol. 20, No. 1, </volume> <month> February </month> <year> 1991, </year> <note> Plenum Press f7g </note>
Reference: 29. <author> G. File, S. Rossi, </author> <title> Static analysis of Prolog with cut, in Logic Programming and Automated Reasoning, </title> <publisher> LNCS 698, Springer Verlag, </publisher> <year> 1993 </year> <month> f54g </month>
Reference-contexts: Likewise, Muthukumar and Hermenegildo's sharing analysis [52] detects sharing and groundness to reduce independence tests in independent and-parallel implementations, without considering parallel execution (which is not necessary). File and Rossi <ref> [29] </ref> consider the general analysis of programs with cuts, and present a semantics where cuts are executed if execution is guaranteed to reach the cut, and ignored otherwise.
Reference: 30. <author> G. Gupta, V. Santos Costa, R. Yang, M.V. Hermenegildo, IDIOM: </author> <title> Intergrat-ing Dependent and-, Independent and- and Or-parallelism, </title> <booktitle> in Logic Programming: Proceedings of the 1991 International Symposium, </booktitle> <publisher> MIT Press, </publisher> <year> 1991. </year> <month> f4g </month>
Reference: 31. <author> G. Gupta, </author> <title> M.V. Hermenegildo, ACE: And/Or-parallel copying-based execution of logic programs, in Parallel Execution of Logic Programs, </title> <publisher> LNCS 569, Springer Verlag, </publisher> <year> 1991. </year> <month> f4g </month>
Reference: 32. <author> E. Hagersten, A. Landin, S. Haridi, </author> <title> DDM A cache-only memory architecture, </title> <journal> IEEE Computer, </journal> <volume> 25(9) </volume> <pages> 44-54, </pages> <month> Sept. </month> <year> 1992 </year> <month> f11g </month>
Reference: 33. <author> W.L. Harrison III, </author> <title> The interprocedural analysis and parallelization of Scheme programs, </title> <journal> Lisp and Symbolic Computation, </journal> <volume> Vol. 2, no. 3/4, </volume> <year> 1989 </year> <month> f8g </month>
Reference: 34. <author> B. Hausman, A. Ciepielewski, S. Haridi, </author> <title> Or-parallel Prolog made efficient on shared memory multiprocessors, </title> <booktitle> in 1987 IEEE International Symposium on Logic Programming, </booktitle> <publisher> IEEE Press, </publisher> <year> 1987. </year> <month> f3g </month>
Reference: 35. <author> M.V. Hermenegildo, </author> <title> An abstract machine for restricted AND-parallel execution of logic programs, </title> <booktitle> in Third International Conference on Logic Programming, </booktitle> <publisher> Springer LNCS 225, </publisher> <month> July </month> <year> 1986. </year> <note> f4, 78g 96 </note>
Reference-contexts: The solution in Reform Prolog allows for shorter suspension, in that time-dependent operations do not act as barriers. Shen's DDAS [62] uses yet another scheme for synchronization between dependent goals. DDAS extends the conditional graph expressions <ref> [35] </ref> of independent and-parallelism with a new pseudo-test, dep/1. All variables in the argument of dep/1 are lazily marked as dependent, and only the leftmost process in the computation may bind dependent variables. All other processes suspend on encountering a dependent variable, until it is instantiated or they become leftmost.
Reference: 36. <author> M.V. Hermenegildo, K.J. Greene, </author> <title> &-Prolog and its performance: exploiting independent and-parallelism, </title> <booktitle> in Proceedings of the Seventh International Conference on Logic Programming, </booktitle> <publisher> MIT Press 1990. f4g </publisher>
Reference: 37. <author> M.V. Hermenegildo, F. Rossi, </author> <title> Non-strict independent and-parallelism, </title> <booktitle> in Proceedings of the Seventh International Conference on Logic Programming, </booktitle> <publisher> MIT Press 1990. f4g </publisher>
Reference: 38. <author> G. Janssens, M. Bruynooghe, </author> <title> Deriving descriptions of possible values of program variables by means of abstract interpretation, </title> <journal> Journal of Logic Programming 1992:13:205-258. f52, 90g </journal>
Reference-contexts: Thus, the call insert/3 is recomputed both in parallel and sequential mode. 3.6 RELATED WORK AND DISCUSSION 3.6.1 Abstract domain Our domain does not in general track functors, which is done by more complex abstract domains (e.g. depth-k abstraction, Bruynooghe's and Janssens' type graphs <ref> [38] </ref>). However, we can handle difference lists, which type graphs are unable to capture. The reasoning is this: type graphs can express certain aliases only on paths through the graph that do not traverse an Or-node. Expressing recursive lists require Or-nodes. <p> First, for the purpose of native code generation, a compiler requires low-level information on whether trailing and dereferencing operations are necessary, and so on. Second, the types derived by our analyser are perhaps too simple. Janssens and Bruynooghe propose type graphs <ref> [38] </ref>, that can describe arbitrary inductively defined terms. Suitably extended, e.g., to handle difference lists, such a concept could prove the basis of a better abstract domain. Third, from the practical perspective, our representation of aliasing is inexact when compared to other, non-transitive, approaches [52].
Reference: 39. <author> A. King, P. Soper, </author> <title> Schedule analysis of concurrent logic programs, </title> <booktitle> in Proceedings of the Joint International Symposium on Logic Programming, </booktitle> <publisher> MIT Press 1992. f6g </publisher>
Reference: 40. <author> R.A. Kowalski, </author> <title> Predicate logic as a computer language, </title> <booktitle> in Information Processing 74, </booktitle> <pages> pp. 569-574, </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1974. </year> <month> f3g </month>
Reference: 41. <author> A.J.Kusalik, </author> <title> Serialization of process reduction in Concurrent Prolog, New Generation Computing 2(1984) 289-298. </title> <publisher> f77g </publisher>
Reference-contexts: Thus, sequential execution is avoided as far as possible. Terms typically are unshared only when first initialized and then intermittently (e.g., if the system can somehow detect that all other sharing processes have terminated). 4.10. Related work and discussion 77 Kusalik <ref> [41] </ref> describes two method to serialize Concurrent Prolog programs. Concurrent Prolog lacks any serialization mechanism other than the commit operator, which requires all goals to the left of it to have terminated before solving goals to the right.
Reference: 42. <author> J.R. Larus, </author> <title> P.N. Hilfinger, Detecting conflicts between structure accesses, </title> <booktitle> in Proceedings of the SIGPLAN'88 Conference on Programming Language Design and Implementation, </booktitle> <publisher> ACM Press, </publisher> <year> 1988 </year> <month> f9g </month>
Reference: 43. <author> J.R. Larus, </author> <title> P.N. Hilfinger, Restructuring Lisp programs for concurrent execution, </title> <booktitle> in Proceedings of the ACM/SIGPLAN PPEALS 1988 Parallel Programming: Experience with Applications, Languages and Systems, </booktitle> <publisher> ACM Press 1988 f9g </publisher>
Reference: 44. <author> B. Le Charlier, K. Musumbu, P. Van Hentenryck, </author> <title> A generic abstract interpretation algorithm and its complexity analysis (extended abstract), </title> <booktitle> in Logic Programming: Proceedings of the Eighth International Conference, </booktitle> <publisher> MIT Press, </publisher> <year> 1991. </year> <month> f53g </month>
Reference-contexts: Adding such types is an interesting possibility for future extensions. 3.6.2 Analysis algorithm Taylor [68] considers several alternatives for fixpoint computation, also settling on maintaining a single call-success pattern pair. Debray [24] also considers this solution. Le Charlier and Van Hentenryck <ref> [44] </ref> use a more sophisticated method to avoid superfluous recomputation by keeping track of dependences between goals. Debray's algorithm statically approximates recomputation dependences through the call graph, while Le Charlier and Van Hentenryck does so dynamically.
Reference: 45. <author> D. Lenoski, J. Laudon, K. Gharachorloo, W.-D. Weber, A. Gupta, J. Hen-nessy, M. Horowitz, M. Lam, </author> <title> The Stanford DASH Multiprocessor, </title> <journal> IEEE Computer, </journal> <volume> 25(3) </volume> <pages> 63-79, </pages> <month> March </month> <year> 1992 </year> <month> f11g </month>
Reference: 46. <author> J. Lloyd, </author> <booktitle> Foundations of Logic Programming (2nd ed.), </booktitle> <publisher> Springer Verlag, f3g </publisher>
Reference: 47. <author> B.C. Massey, E. Tick, </author> <title> Sequentialization of parallel programs with modes, in Logic Programming and Automated Reasoning, </title> <publisher> LNCS 698, Springer Verlag, </publisher> <year> 1993 </year> <month> f6g </month>
Reference: 48. <author> H. Millroth, </author> <title> Reforming the compilation of logic programs, </title> <type> Ph.D. Thesis, </type> <note> Up-psala Theses in Computer Science 10, 1991. f7, 17, 18g 97 </note>
Reference: 49. <author> H. Millroth, </author> <title> Reforming compilation of logic programs, </title> <booktitle> in Logic Programming: Proceedings of the Eighth International Conference, </booktitle> <publisher> MIT Press, </publisher> <year> 1991. </year> <month> f7g </month>
Reference: 50. <author> H. Millroth, </author> <title> Reform compilation for non-linear recursion, </title> <booktitle> Proceedings of the International Conference on Logic Programming and Automated Reasoning, </booktitle> <publisher> LNCS 624, Springer Verlag, </publisher> <year> 1992. </year> <note> f7, 15g </note>
Reference: 51. <author> H. Millroth, </author> <type> personal communication. </type> <institution> f15g </institution>
Reference: 52. <author> K. Muthukumar, </author> <title> M.V. Hermenegildo, Compile-time derivation of variable dependency using abstract interpretation, </title> <journal> Journal of Logic Programming, 1992:13:315-347. f54, 90g </journal>
Reference-contexts: Analyses of concurrent logic languages [19] suffer from the same disadvantages. There are properties that do not rely on execution order, however, and these can be inferred more efficiently [17, 25]. Likewise, Muthukumar and Hermenegildo's sharing analysis <ref> [52] </ref> detects sharing and groundness to reduce independence tests in independent and-parallel implementations, without considering parallel execution (which is not necessary). <p> Suitably extended, e.g., to handle difference lists, such a concept could prove the basis of a better abstract domain. Third, from the practical perspective, our representation of aliasing is inexact when compared to other, non-transitive, approaches <ref> [52] </ref>. Should these provide a markedly better precision than ours, when 6.4. Related work: imperative languages 91 used on real programs, it may be useful to investigate such better methods. Fourth, to analyse large programs, there are software engineering considerations in that analysis currently can use prohibitive amounts of memory.
Reference: 53. <author> L. </author> <title> Naish, </title> <booktitle> Parallel NU-Prolog, Logic Programming: Proceedings of the Fifth International Conference and Symposium, </booktitle> <publisher> MIT Press, </publisher> <year> 1988. </year> <note> f5, 20, 66g </note>
Reference-contexts: Our approach is inspired by the PNU-Prolog language designed by Naish <ref> [53] </ref>. <p> On the other hand, if the locking unification finds a nonvariable term, it behaves just like a standard unification instruction. This approach is similar to that of Naish <ref> [53] </ref>. A locking unification is done as follows: lock and get structure F/N Xi Xj unify N arguments unlock Xi Xj The overhead of using locking instructions apart from the extra instruction, is that register allocation is worsened.
Reference: 54. <author> C. Pancake, </author> <title> Multithreaded languages for scientific and technical computing, </title> <booktitle> in Proceedings of the IEEE, </booktitle> <volume> Vol. 81, No. 2, </volume> <month> February </month> <year> 1993. </year> <month> f8g </month>
Reference: 55. <author> G.H. Pollard, </author> <title> Parallel execution of Horn clause programs, </title> <type> Ph.D. Thesis, </type> <institution> Imperial College, </institution> <address> London, </address> <year> 1981. </year> <month> f3g </month>
Reference: 56. <author> V. Santos Costa, D.H.D. Warren, R. Yang, Andorra-I: </author> <title> A parallel Prolog system that transparently exploits both and- and or-parallelism, </title> <booktitle> in Third ACM SIGPLAN Symposium on Principles & Practices of Parallel Programming, </booktitle> <year> 1991. </year> <month> f4g </month>
Reference: 57. <author> V. Santos Costa, D.H.D. Warren, R. Yang, </author> <title> The Andorra-I preprocessor: supporting full Prolog on the basic Andorra model, </title> <booktitle> in Logic Programming: Proceedings of the Eighth International Conference, </booktitle> <publisher> MIT Press 1991. f4, </publisher> <address> 53, 77, 78g </address>
Reference-contexts: The types used conform quite well to the WAM model of indexing but can be made better. In particular, distinguishing numbers, atoms and structures, as well as knowing when a list has at least one element could give far better precision in this regard. The Andorra-I preprocessor <ref> [57] </ref> extends Taylor's domain with disjunctions of terms for better precision. For instance, the Andorra-I system can find that a variable is bound either to a structure f (: : :) or a structure g (: : :). <p> Much like Reform Prolog, the Andorra-I language as implemented by Costa, Warren and Yang [58], is an implementation of dependent and-parallel Prolog. Andorra-I extends Prolog with coroutining and constraint solving, which is not done in Reform Prolog. Furthermore, Andorra-I too bases suspension on compile-time analysis <ref> [57] </ref>. 78 Compiling recursion-parallel programs To handle the impure operations of Prolog, Andorra-I uses sequential conjunction to separate sensitive goals. The preprocessor uses the results of a preceding type inference phase to generate modes to find what calls are sensitive. <p> Finally, all the transitive callers of sensitive calls are marked as sensitive. The Andorra-I preprocessor then introduces sequential conjunctions to the right of all sensitive calls. This ensures that time-dependent operations still executes correctly. For instance, consider the following clause <ref> [57] </ref>: p (X,Y) :- a (X,Y,W), b (X,W,Z), c (X,Z). Assume that b/3 is sensitive. Then the preprocessor rewrites p/2 into the following clause, where the double-colon connective denotes sequential conjunction. p (X,Y) :- a (X,Y,W), b (X,W,Z) :: c (X,Z).
Reference: 58. <author> V. Santos Costa, D.H.D. Warren, R. Yang, </author> <title> The Andorra-I engine: a parallel implementation of the basic Andorra model, </title> <booktitle> in Logic Programming: Proceedings of the Eighth International Conference, </booktitle> <publisher> MIT Press 1991. f4, 77g </publisher>
Reference-contexts: Suspension is controlled by abstract machine instructions that are versions of the get and unify instructions of the WAM that suspend on unbound variables. Thus, these operations cannot be strength-reduced to their simpler sequential counterparts. Much like Reform Prolog, the Andorra-I language as implemented by Costa, Warren and Yang <ref> [58] </ref>, is an implementation of dependent and-parallel Prolog. Andorra-I extends Prolog with coroutining and constraint solving, which is not done in Reform Prolog.
Reference: 59. <author> R. Sedgewick, </author> <title> Algorithms (2nd edition), </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year> <month> f32g </month>
Reference-contexts: We will assume this to occur implicitly subsequently. Furthermore, aliasing is a transitive property by our definition: if two descriptors become aliased, then their aliases will also become aliased. This allows us an efficient implementation of aliasing in terms of equivalence classes and UNION-FIND algorithms <ref> [59] </ref>. Possible aliases. The analyser maintains possible aliases as an aliasing component. When some descriptor in a possible alias set may have been further instantiated, the other descriptors in the alias set may cause other variables to change type.
Reference: 60. <author> E.Y. Shapiro, </author> <title> A subset of Concurrent Prolog and its interpreter, </title> <type> ICOT Technical Report TR-003, </type> <institution> Institute for New Generation Computing Technology, </institution> <address> Tokyo, </address> <year> 1983. </year> <month> f5g </month>
Reference: 61. <author> K. Shen, </author> <title> Exploiting dependent and-parallelism in Prolog: the dynamic dependent and-parallel scheme (DDAS), </title> <booktitle> in Proceedings of the Joint International Symposium on Logic Programming, </booktitle> <publisher> MIT Press, </publisher> <year> 1992. </year> <month> f5g </month>
Reference: 62. <author> K. Shen, </author> <title> Studies of And-Or Parallelism, </title> <type> Ph.D. Thesis, </type> <institution> Cambridge University, </institution> <note> revised June 1992. f5, 6, 78g 98 </note>
Reference-contexts: The solution in Reform Prolog allows for shorter suspension, in that time-dependent operations do not act as barriers. Shen's DDAS <ref> [62] </ref> uses yet another scheme for synchronization between dependent goals. DDAS extends the conditional graph expressions [35] of independent and-parallelism with a new pseudo-test, dep/1. All variables in the argument of dep/1 are lazily marked as dependent, and only the leftmost process in the computation may bind dependent variables.
Reference: 63. <author> J.P. Singh, J.L. Hennessy, </author> <title> An empirical investigation of the effectiveness and limitations of automatic parallelization, </title> <booktitle> in Proceedings of the International Symposium on Shared Memory Multiprocessing, </booktitle> <address> Tokyo, </address> <month> April </month> <year> 1991 </year> <month> f8g </month>
Reference: 64. <author> A. Singhal, Y.N. Patt, </author> <title> Unification parallelism: how much can we exploit?, </title> <booktitle> in Proceedings of the North American Conference on Logic Programming 1989, </booktitle> <publisher> MIT Press, </publisher> <year> 1989. </year> <month> f76g </month>
Reference-contexts: expression of the first argument and the recursion level register. 2 4.10 RELATED WORK AND DISCUSSION 4.10.1 Head unification A previous study by Singhal and Patt concluded that the parallelism available in unification is quite small for normal programs since the terms involved are usually 76 Compiling recursion-parallel programs small <ref> [64] </ref>. Simulated speedups of a factor two were reported. However, Reform compilation collects a number of small unifications into a single, large one. By performing all the head unifications of the predicate at once, ample fine-grained parallelism is exposed.
Reference: 65. <author> H. Stndergaard, </author> <title> An application of abstract interpretation of logic programs: Occur check reduction, </title> <booktitle> in ESOP'86 Proceedings European Symposium on Programming, </booktitle> <publisher> LNCS 213, Springer Verlag, </publisher> <year> 1986. </year> <month> f53g </month>
Reference-contexts: The least upper bound of these two values is often defined to be any. By introducing free+nil, our analyser can continue the analysis with precise types. Independence is also considered by Stndergaard <ref> [65] </ref> as well as Codish et al. [18]. These domains have a more precise notion of sharing, but do not trace types as extensively as ours. Furthermore, they do not incorporate the indlist type which seems to be pragmatically useful in the case of Reform Prolog.
Reference: 66. <author> L. Sterling, E. Shapiro, </author> <title> The Art of Prolog, </title> <publisher> MIT Press, </publisher> <year> 1986 </year> <month> f3g </month>
Reference: 67. <author> P. Tang & P.-C. Yew, </author> <title> Processor Self-Scheduling for Multiple Nested Parallel Loops, </title> <booktitle> Proc. 1986 Int. Conf. Parallel Processing, </booktitle> <month> August </month> <year> 1986. </year> <month> f8g </month>
Reference: 68. <author> A. Taylor, </author> <title> High Performance Prolog Implementation, </title> <type> Ph.D. Thesis, </type> <institution> Basser Department of Computer Science, Sydney University, </institution> <year> 1991. </year> <note> f52, 53, 91g </note>
Reference-contexts: Expressing recursive lists require Or-nodes. If a certain alias is not maintained, the tail of the list will collapse into a Max-node (our any), which collapses the entire type graph into a Max-node. One might thus consider extending the scope of certain aliases for type graphs somewhat. Taylor <ref> [68] </ref> uses a domain quite similar to ours. His domain is more extensive in that it differentiates constants into numbers, atoms, and so on. Furthermore, it incorporates depth-k abstraction and maintains low-level information on free variables. Our treatment of lists is similar to Taylor's but more restricted. <p> Adding such types is an interesting possibility for future extensions. 3.6.2 Analysis algorithm Taylor <ref> [68] </ref> considers several alternatives for fixpoint computation, also settling on maintaining a single call-success pattern pair. Debray [24] also considers this solution. Le Charlier and Van Hentenryck [44] use a more sophisticated method to avoid superfluous recomputation by keeping track of dependences between goals. <p> What Fortran and C lose for analysis purposes, they regain at the compilation stage. Compilers for imperative languages generally produce superior code to even such efforts as Aquarius Prolog [74] or Parma <ref> [68] </ref>, which define the state-of-the-art at the time of writing.
Reference: 69. <author> E. Tick, </author> <title> Parallel Logic Programming, </title> <publisher> MIT Press, </publisher> <year> 1991. </year> <month> f6g </month>
Reference: 70. <editor> S A. Tarnlund, </editor> <booktitle> Logic information processing, TRITA-IBADB 1034, </booktitle> <institution> Department of Information Processing and Computer Science, Royal Institute of Technology and University of Stockholm, </institution> <year> 1975. </year> <note> f3, 6g </note>
Reference: 71. <author> S A. </author> <title> Tarnlund, Reform, </title> <type> unpublished manuscript, </type> <institution> Computing Science Department, Uppsala University, </institution> <year> 1991. </year> <month> f7g </month>
Reference: 72. <author> K. Ueda, </author> <title> Guarded Horn clauses, </title> <type> ICOT Technical Report TR-103, </type> <institution> Institute for New Generation Computing Technology, </institution> <address> Tokyo, </address> <year> 1985. </year> <month> f5g </month>
Reference: 73. <author> K. Ueda, M. Morita, </author> <title> A new implementation technique for flat GHC, </title> <booktitle> in Logic Programming: Proceedings of the Seventh International Conference, </booktitle> <publisher> MIT Press, </publisher> <year> 1990. </year> <month> f5g </month>
Reference: 74. <author> P.L. Van Roy, </author> <title> Can Logic Programming Execute as Fast as Imperative Programming?, </title> <type> Ph.D. Thesis, </type> <institution> UCB/CSD 90/600, Computer Science Division (EECS), University of California, Berkeley, </institution> <year> 1990. </year> <month> f91g </month>
Reference-contexts: What Fortran and C lose for analysis purposes, they regain at the compilation stage. Compilers for imperative languages generally produce superior code to even such efforts as Aquarius Prolog <ref> [74] </ref> or Parma [68], which define the state-of-the-art at the time of writing.
Reference: 75. <author> A. Voronkov, </author> <title> Logic programming with bounded quantifiers, in Logic Programming, </title> <publisher> LNAI 592, Springer Verlag, </publisher> <year> 1992. </year> <month> f6g </month>
Reference: 76. <author> D.H.D. Warren, </author> <title> Implementing Prolog compiling predicate logic, </title> <type> DAI Technical Reports 39-40, </type> <institution> Edinburgh University f48g </institution>
Reference-contexts: Accurate success patterns do not really help the compilation of the current parallel predicate; however, subsequent predicates may benefit considerably by getting more precise call patterns. 2 3.4.2 Abstract indexing WAM-based Prolog implementations employ clause indexing <ref> [76, pp. 68-77] </ref>[1] to narrow down the sequence of clauses to be tried when entering a call.
Reference: 77. <author> D.H.D. Warren, </author> <title> An abstract Prolog instruction set, </title> <type> Report 309, </type> <institution> SRI International, </institution> <address> Menlo Park, California, USA, </address> <year> 1983. </year> <note> f10, 55g 99 </note>
Reference-contexts: the concrete execution of Reform Prolog and show how recursion-parallel programs are compiled, how suspension and locking unifications can be eliminated and how arithmetic recurrences can be compiled. 4.1 OVERVIEW OF THE WARREN ABSTRACT MACHINE The execution engine of Reform Prolog is based on the Warren Abstract Machine, or WAM <ref> [77] </ref>. In this section we provide a high-level overview of the machine. For a closer look, the reader is urged to consult At-Kaci [1]. The WAM consists of a set of registers and four global data areas: a code area, a local stack, a global stack and a trail stack.
Reference: 78. <author> D.H.D. Warren, </author> <title> The SRI-model for or-parallel execution of Prolog, </title> <booktitle> in 1987 IEEE International Symposium in Logic Programming, </booktitle> <publisher> IEEE Press 1987. f3g </publisher>
Reference: 79. <author> D.H.D. Warren, </author> <title> The Andorra model, </title> <booktitle> presented at Gigalips workshop, </booktitle> <institution> University of Manchester, </institution> <year> 1988. </year> <month> f4g </month>
Reference: 80. <author> M. Wolfe, </author> <title> Optimizing Supercompilers for Supercomputers, </title> <publisher> MIT Press, </publisher> <year> 1989 </year> <month> f7g </month>
Reference: 81. <author> R. Yang, </author> <title> A Parallel Logic Programming Language and Its Implementation, </title> <type> Ph.D. Thesis, </type> <institution> Department of Electrical Engineering, Keio University, Yoko-hama, </institution> <year> 1986. </year> <month> f4g </month>
Reference: 82. <author> R. Yang, T. Beaumont, I. Dutra, V. Santos Costa, D.H.D. Warren, </author> <title> Performance of the compiler-based Andorra-I system, </title> <booktitle> in Logic Programming: Proceedings of the Tenth International Conference on Logic Programming, </booktitle> <publisher> MIT Press, </publisher> <year> 1993. </year> <institution> f4g UPMAIL Computing Science Department Uppsala University Box 311 S-751 05 UPPSALA Sweden Phone: </institution> <note> Nat 018 - 18 25 00 Int +46 18 18 25 00 Fax: Nat 018 - 52 12 70 Int +46 18 52 12 70 ISSN 0283-359X </note>
References-found: 82

