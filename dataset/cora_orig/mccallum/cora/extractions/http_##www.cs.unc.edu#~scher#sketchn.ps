URL: http://www.cs.unc.edu/~scher/sketchn.ps
Refering-URL: http://www.cs.unc.edu/~scher/frameless.html
Root-URL: http://www.cs.unc.edu
Title: Perceptually-Driven Graphics  
Author: Ellen J. Scher Zagier 
Abstract: The purpose of this paper is to explicitly raise a topic that has either been on the back burner, has found itself a subtopic of other areas, or has been traditionally embedded in a tangential field. The secondary purpose is to explore a topic which is of interest to many facets of computer graphics and is relatively new enough to inspire very lively discussion and creative thinking. Perceptually-driven graphics, as I present it here, has the primary purpose of computing only that information which is ultimately usable by the human visual system. Its purpose is pure efficiency. In all but a few very experimental systems, the amount of computation done to produce a final image is many orders of magnitude greater than the amount of information the human visual system can possibly process. Perceptually-driven graphics ideally takes into account every piece of usable, existing knowledge about what the eye actually "sees" to drive computation. It directly exploits the logarithmic falloff of resolution from foveal center to extreme periphery. This paper will also stimulate questions such as: How does a perceptually-driven graphics system fit in with current image-based rendering strategies and with Frameless Rendering? How does it work with new research in multiuser displays? And finally, how crucial is effective eye tracking technology? 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Gary Bishop, Henry Fuchs, Leonard McMillan, and Ellen J. Scher Zagier. </author> <title> Frameless rendering: Double buffering considered harmful. </title> <booktitle> In Computer Graphics (SIGGRAPH '94 Proceedings), </booktitle> <pages> pages 175-176, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: Tracing Rays We propose a front end renderer to the Frameless Rendering updating and display scheme back end. (Frameless Rendering is a rendering paradigm which performs stochastic temporal filtering by updating pixels in a random order, based on most recent available input data, and displaying them to the screen immediately <ref> [1] </ref>.) The renderer is an antialiasing raytracer which handles diffuse reflections with a sample size proportional to the photoreceptor size. Consider a camera collecting information from the real world. A digitizing frame-grabber can be used to extract discrete, typically uniform samples over space and time.
Reference: [2] <author> E.C. Chang and C.K. Yap. </author> <title> A wavelet approach to foveating images. </title> <booktitle> In 13th ACM Symposium on Computational Geometry, </booktitle> <year> 1997. </year>
Reference-contexts: This knowledge has been used in Computer Graphics for ideas for sampling in volume rendering [4] and for research into new displays, a wavelet approach is used to foveate images, that is, match retinal resolution based on an assumed eyepoint and point of attention <ref> [2] </ref>. fl Department of Computer Science, University of North Carolina, Chapel Hill, NC 27599-3175. scher@cs.unc.edu 1 2 Some Features of the Human Visual System I describe some of the many features of the human visual system that ultimately must be addressed in creating a system that mimics what the eye perceives.
Reference: [3] <author> James T. Kajiya. </author> <title> The rendering equation. </title> <editor> In David C. Evans and Russell J. Athay, editors, </editor> <booktitle> Computer Graphics (SIGGRAPH '86 Proceedings), </booktitle> <volume> volume 20, </volume> <pages> pages 143-150, </pages> <month> Aug </month> <year> 1986. </year>
Reference-contexts: near the foveal center would be more densely distributed and a sparse sampling would be tolerable in the periphery. 2 A combination of existing techniques can be combined to build a renderer that handles diffuse as well as specular lighting and computes the sample values independently by tracing independent rays <ref> [3] </ref>. A Monte Carlo method can be used for stochasticly sampling rays to approximate the surface reflectance function.
Reference: [4] <author> Marc Levoy and Ross Whitaker. </author> <booktitle> Gaze-directed volume rendering. Computer Graphics (Proc. 1990 Symposium on Interactive 3D Graphics), </booktitle> <volume> 24(2) </volume> <pages> 217-223, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: This is colloquially understood as the falloff of resolution from fovea to periphery. This knowledge has been used in Computer Graphics for ideas for sampling in volume rendering <ref> [4] </ref> and for research into new displays, a wavelet approach is used to foveate images, that is, match retinal resolution based on an assumed eyepoint and point of attention [2]. fl Department of Computer Science, University of North Carolina, Chapel Hill, NC 27599-3175. scher@cs.unc.edu 1 2 Some Features of the Human
Reference: [5] <author> Don P. Mitchell. </author> <title> The antialiasing problem in ray tracing. </title> <booktitle> In SIGGRAPH '90 Advanced Topics in Ray Tracing course notes, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: A Monte Carlo method can be used for stochasticly sampling rays to approximate the surface reflectance function. A sufficient number of independent rays are cast nonuniformly to avoid aliasing artifacts <ref> [5] </ref>. 3.2 Display Sample size and distribution, based on a user's eyepoint, can address only one user's eyepoint per display. Currently, for many users to be accommodated, they each need to have their own visual interface into the synthetic world.
Reference: [6] <author> Ellen J. Scher Zagier. </author> <title> A human's eye view: Motion blur and frameless rendering. </title> <journal> In ACM Crossroads Magazine, </journal> <year> 1997. </year>
Reference-contexts: The eye does not have full spatial resolution when information is shown temporally. The blur in an image sequence can conform to the motion smear, or final blur on the retina <ref> [6] </ref>. Critical Fusion Frequency, or the eye's "frame rate" has always been a factor in designing displays. The fact that the critical fusion frequency is lower as intensity decreases can be exploited with dark scenes. Image compression techniques take advantage of our sensitivity to lightness-darkness over opponent colors.
Reference: [7] <author> Eric L. Schwartz. </author> <title> Computational studies of the spatial architecture of primate visual cortex. </title> <booktitle> In Cerebral Cortex, </booktitle> <pages> pages 359-410, </pages> <year> 1994. </year>
Reference-contexts: Many of the breakthroughs along the ultimate lines of perceptually-driven graphics lie in the field of Human Vision and Visual Perception. A cortical (the part of the brain receiving the retinal encoding) description of the complex logarithmic mapping of spatial resolution has been rigorously researched mathematically <ref> [7] </ref>. This is colloquially understood as the falloff of resolution from fovea to periphery.
Reference: [8] <author> Seth Shostak. </author> <title> The ultimate motion image system: What and when. </title> <booktitle> In Advanced Imaging, </booktitle> <year> 1997. </year>
Reference-contexts: Most systems provide the necessary information for one feature with overkill, such as retinal resolution, and other features inadequately, such as brightness dynamic range. Some of these items have been raised before in developing a future imaging system <ref> [8] </ref>. Image contrast, the ratio of image intensities, is of more importance to the human visual system than absolute intensity.
Reference: [9] <author> Turner Whitted. </author> <title> An improved illumination model for shaded display. </title> <journal> Communications of the ACM, </journal> <volume> 23(6) </volume> <pages> 343-349, </pages> <month> June </month> <year> 1980. </year> <month> 4 </month>
Reference-contexts: In order to optimize computational efficiency, a graphics system should take advantage of the variance in size, color resolution, etc. among retinal samples. This necessarily requires a sample-based system. Thus the pipeline for Raytracing <ref> [9] </ref> is the model I use. It is likely that ultimately all stages of the pipeline will be driven by the way the human visual system functions. The first two stages, Display Traversal and Modeling Transformation are beyond the scope of this paper.
References-found: 9

