URL: http://www.cscs.ch/~wylie/doc/EPCC-TN92-05.ps.gz
Refering-URL: 
Root-URL: 
Email: bjnw@epcc.ed.ac.uk, mgn@epcc.ed.ac.uk and lyndon@epcc.ed.ac.uk  
Title: EPCC-TN92-05.07 High Performance Fortran: A Perspective  
Author: Brian J N Wylie Michael G Norman Lyndon J Clarke 
Note: Electronic addresses:  14:09, January 4, 1993 Id: perspective.tex,v 1.24 1993/01/04 14:04:15 bjnw Exp bjnw  
Date: May 1992  
Address: Edinburgh EH9 3JZ Scotland  
Affiliation: Edinburgh Parallel Computing Centre University of Edinburgh  
Abstract: z Minor corrections and revision of this document have been performed since its original writing, but its perspective and the HPF proposals described have not been updated to reflect subsequent proposals. Draft versions of the HPF language specification started to appear in mid August, with a full draft offered for public comment at the end of November '92 [5] 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Siegfried Benkner, Barbara M Chapman, and Hans P Zima. </author> <title> `Vienna Fortran-90'. </title> <editor> In Robert Voigt and Joel Saltz, editors, </editor> <booktitle> Proceedings of the Scalable High-Performance Computing Conference, </booktitle> <pages> pages 51-59. </pages> <publisher> IEEE Computer Society Press, </publisher> <address> April 1992. (Williamsburg, VA, </address> <month> April 26-29). </month>
Reference-contexts: Vienna Fortran <ref> [1] </ref> is a language extension of Fortran which provides a wide range of facilities for mapping of data structures across distributed-memory processors. Programs 10 EPCC-TN92-05.07 in Vienna Fortran are written using global data references, providing the advantages of a shared memory programming paradigm while explicitly controlling the placement of data.
Reference: [2] <author> Barbara M Chapman, Piyush Mehrotra, and Hans P Zima. </author> <title> `Programming in Vienna Fortran'. </title> <type> ICASE Report 92-9, </type> <institution> Institute for Computer Applications in Science and Engineering, NASA Langley Research Center, </institution> <address> Hampton, VA 23665, USA, </address> <month> March </month> <year> 1992. </year> <note> (Also available from Vienna as ACPC/TR 92-3). </note>
Reference-contexts: Mapping functions and inverses are required for all data arrays. Scalars and non-decomposed arrays are replicated. The Vienna Fortran language extensions (as described in <ref> [2, 24] </ref>) provide the following features: * The processors which execute the program may be explicitly specified and re ferred to. It is possible to impose one or more structures to them. * The distributions of arrays can be specified using annotations.
Reference: [3] <author> Raja Das, Joel Saltz, and Harry Berryman. </author> <title> `A Manual for PARTI Runtime Primitives'. </title> <type> ICASE Interim Report 17, </type> <institution> Institute for Computer Applications in Science and Engineering, NASA Langley Research Center, </institution> <address> Hampton, VA 23665, USA, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Saltz and Fox are working on extensions to HPF which allow more irregular applications, but require a more sophisticated RTE. The PARTI environment (Parallel Automated Run-Time Toolkit at ICASE, developed by Joel Saltz and his group) offers a lot of this functionality. <ref> [3, 16] </ref> For example, PARTI operates on loops within which data access patterns imply dependencies which cannot be pre-analysed by the compiler. It again makes use of inspector and executor phases.
Reference: [4] <author> J Ferrante, K J Ottenstein, and J D Warren. </author> <title> `The Program Dependence Graph and its Use in Optimisation'. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3), </volume> <year> 1987. </year>
Reference-contexts: seen as a fusion of two different existing technologies: the hypercube experience in developing the tools and techniques used to write explicit message passing programs for data parallel applications [6], and the compiler work in dependency analysis used in optimising compilers for superscalar architectures and in shared memory parallelising compilers <ref> [14, 4] </ref>. The hypercube experience brings with it an understanding of the tricks that are required to get a message passing program to execute efficiently. The compiler work allows the definition of (a subset of) the legal transformations that may be made to the program.
Reference: [5] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification, </title> <note> 1992. Most recent draft available as a technical report CRPC-TR 92225 from the Center for Research in Parallel Computation at Rice University, or via anonymous ftp from titan.cs.rice.edu:public/HPFF/draft. </note>
Reference: [6] <author> G C Fox, M A Johnson, G A Lyzenga, S W Otto, J K Salmon, and D Walker. </author> <title> Solving Scientific Problems on Concurrent Processors. </title> <publisher> Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1988. </year>
Reference-contexts: HPF can be seen as a fusion of two different existing technologies: the hypercube experience in developing the tools and techniques used to write explicit message passing programs for data parallel applications <ref> [6] </ref>, and the compiler work in dependency analysis used in optimising compilers for superscalar architectures and in shared memory parallelising compilers [14, 4]. The hypercube experience brings with it an understanding of the tricks that are required to get a message passing program to execute efficiently.
Reference: [7] <author> Geoffrey Fox, Seema Hiranandani, Ken Kennedy, Charles Koelbel, Uli Kre-mer, Chau-Wen Tseng, and Min-You Wu. </author> <title> `Fortran D Language Specification'. </title> <type> Technical report, </type> <institution> Center for Research on Parallel Computations, Rice University, Houston, TX-77251, USA, </institution> <month> January </month> <year> 1992. </year> <note> Earlier version previously available as CRPC-TR90079. [Document source available via anonymous FTP from titan.cs.rice.edu:public/HPFF]. </note>
Reference-contexts: The `D' in Fortran-D is not specified, but is said to stand for any and all of: directives, data, decomposition and distribution. The Rice group has been more interested in Fortran-77D, and Syracuse in Fortran-90D, but both groups have worked closely on the compilers for both dialects. <ref> [7, 8] </ref> It is designed to support what are, in the views of its authors, two fundamental stages of writing a data-parallel program: problem mapping, that is indicating the co-location of array elements (which are commonly accessed together in program statements) so as to minimise the requirements for communication, and machine
Reference: [8] <author> Ken Kennedy. </author> <title> `Compiler Support for Programming Regular Problems in Fortran-D'. Material for `Compilers for Scalable Architectures' tutorial presented at the `Scalable High-Performance Computing Conference' (Williamsburg, </title> <address> VA, </address> <month> April </month> <year> 1992), </year> <month> April </month> <year> 1992. </year>
Reference-contexts: The `D' in Fortran-D is not specified, but is said to stand for any and all of: directives, data, decomposition and distribution. The Rice group has been more interested in Fortran-77D, and Syracuse in Fortran-90D, but both groups have worked closely on the compilers for both dialects. <ref> [7, 8] </ref> It is designed to support what are, in the views of its authors, two fundamental stages of writing a data-parallel program: problem mapping, that is indicating the co-location of array elements (which are commonly accessed together in program statements) so as to minimise the requirements for communication, and machine
Reference: [9] <author> Chuck Koelbel. </author> <booktitle> `HPFF April 22nd (Dallas) Meeting Notes'. Distributed electronically on USENET, </booktitle> <month> May </month> <year> 1992. </year> <note> [Document source obtained via anonymous FTP from titan.cs.rice.edu:public/HPFF]. </note>
Reference-contexts: HPF proposals appear to incorporate the majority of this Vienna Fortran functionality, with the likely exception of user-defined distribution functions. 3.4 Language details preliminary HPF Abstracted from Guy Steele's April 21st proposal to HPF [18] and the minutes of the April 22nd HPFF meeting <ref> [9] </ref>: Data (i.e., array) distribution in HPF will incorporate a three-level mapping which combines features of Fortran-D and Vienna Fortran. In outline, (hardware-independent) data arrays are mapped to conceptual entities called templates (which were previously called decompositions) which are in turn mapped to (virtual) processor grids.
Reference: [10] <author> David B Loveman. </author> <title> `Digital Equipment Corporation High Performance Fortran Language Specification Proposals'. </title> <note> Presented to HPFF and distributed electronically, January 1992. [Document source obtained via anonymous FTP from titan.cs.rice.edu:public/HPFF]. </note>
Reference-contexts: Furthermore, the port of existing programs to parallel architectures is likely to become much easier. A number of vendor proposals have been made and are being considered by the HPFF <ref> [10, 15, 19] </ref>. 5 Where's Europe? While it is clear that Hans Zima's group in Vienna have earned the right to play an important r ole in the formulation of a universal High-Performance Fortran, the financial out-lay involved in participation is such that European involvement is likely to be minimal.
Reference: [11] <author> Michael Metcalf and John Reid. </author> <title> Fortran-90 Explained. </title> <publisher> Oxford Science Publications, </publisher> <year> 1990. </year> <title> HPF PERSPECTIVE 23 </title>
Reference-contexts: A number of the out-dated and idiosyncratic features of the language have been deprecated although none have been removed from the language at this stage, since Fortran-77 is a complete subset of Fortran-90. Details are summarised in [17] and extensively documented in <ref> [11] </ref>. Fortran-90 therefore provides an effective high-level language for numerical and scientific problems, which should be natural for such programmers.
Reference: [12] <author> M G Norman, J R Henderson, I G Main, and D J Wallace. </author> <title> `The Use of the CAPE Environment in the Simulation of Rock Fracturing'. </title> <journal> Concurrency Practice and Experience, </journal> <volume> 3(6) </volume> <pages> 687-698, </pages> <year> 1991. </year>
Reference-contexts: HPF will let you do this, but it is conceptually rather difficult, the more so because the mapping is hidden by the data-parallel abstraction. EPCC has had experience with CAPE in this area. <ref> [12] </ref> has a more complete description of these two problems and concludes that the data-parallel abstraction is ineffective.
Reference: [13] <author> Michael G Norman and Peter Thanisch. </author> <title> `Models of Machines and Modules for Mapping so as to Minimise Makespan in Multicomputers'. </title> <type> Technical Report EPCC-TR-91-14, </type> <institution> Edinburgh Parallel Computing Centre, </institution> <year> 1991. </year>
Reference-contexts: There are two problems that HPF has to solve: mapping of computation to processors and the formulation of the communication implied in so doing. Optimisation of mapping is of course NP-Complete in most formulations, and also incredibly difficult to formulate (see <ref> [13] </ref>).
Reference: [14] <author> D A Padua and M J Wolfe. </author> <title> `Advanced Compiler Optimisations for Supercomputers'. </title> <journal> Comm. ACM, </journal> <volume> 29(12), </volume> <year> 1986. </year>
Reference-contexts: seen as a fusion of two different existing technologies: the hypercube experience in developing the tools and techniques used to write explicit message passing programs for data parallel applications [6], and the compiler work in dependency analysis used in optimising compilers for superscalar architectures and in shared memory parallelising compilers <ref> [14, 4] </ref>. The hypercube experience brings with it an understanding of the tricks that are required to get a message passing program to execute efficiently. The compiler work allows the definition of (a subset of) the legal transformations that may be made to the program.
Reference: [15] <author> Douglas M Pase, Tom MacDonald, and Andrew Meltzer. </author> <title> `MPP Fortran Programming Model'. Distributed electronically, </title> <month> March </month> <year> 1992. </year> <note> [Document source obtained via anonymous FTP from titan.cs.rice.edu:public/HPFF]. </note>
Reference-contexts: Furthermore, the port of existing programs to parallel architectures is likely to become much easier. A number of vendor proposals have been made and are being considered by the HPFF <ref> [10, 15, 19] </ref>. 5 Where's Europe? While it is clear that Hans Zima's group in Vienna have earned the right to play an important r ole in the formulation of a universal High-Performance Fortran, the financial out-lay involved in participation is such that European involvement is likely to be minimal.
Reference: [16] <author> Joel Saltz. </author> <title> `Runtime Compilation'. Material for `Compilers for Scalable Architectures' tutorial presented at the `Scalable High-Performance Computing Conference' (Williamsburg, </title> <address> VA, </address> <month> April </month> <year> 1992), </year> <month> April </month> <year> 1992. </year>
Reference-contexts: Saltz and Fox are working on extensions to HPF which allow more irregular applications, but require a more sophisticated RTE. The PARTI environment (Parallel Automated Run-Time Toolkit at ICASE, developed by Joel Saltz and his group) offers a lot of this functionality. <ref> [3, 16] </ref> For example, PARTI operates on loops within which data access patterns imply dependencies which cannot be pre-analysed by the compiler. It again makes use of inspector and executor phases.
Reference: [17] <author> Mark Sawyer. </author> <title> `A Summary of Fortran-90'. </title> <type> Technical Report EPCC-TN92-04, </type> <institution> EPCC NSG, </institution> <month> May </month> <year> 1992. </year> <note> Version 1.2. </note>
Reference-contexts: A number of the out-dated and idiosyncratic features of the language have been deprecated although none have been removed from the language at this stage, since Fortran-77 is a complete subset of Fortran-90. Details are summarised in <ref> [17] </ref> and extensively documented in [11]. Fortran-90 therefore provides an effective high-level language for numerical and scientific problems, which should be natural for such programmers.
Reference: [18] <author> Guy L Steele Jr. </author> <title> `Proposal for alignment and distribution directives in HPF'. </title> <note> Made available electronically for distribution via anonymous FTP from titan.cs.rice.edu:public/HPFF, </note> <month> April </month> <year> 1992. </year>
Reference-contexts: HPF proposals appear to incorporate the majority of this Vienna Fortran functionality, with the likely exception of user-defined distribution functions. 3.4 Language details preliminary HPF Abstracted from Guy Steele's April 21st proposal to HPF <ref> [18] </ref> and the minutes of the April 22nd HPFF meeting [9]: Data (i.e., array) distribution in HPF will incorporate a three-level mapping which combines features of Fortran-D and Vienna Fortran.
Reference: [19] <author> Guy L Steele Jr. </author> <title> `Thinking Machines Corporation Proposals for Amending High Performance Fortran'. Distributed as electronic text, </title> <month> January </month> <year> 1992. </year> <note> [Document source obtained via anonymous FTP from titan.cs.rice.edu:public/HPFF]. </note>
Reference-contexts: Furthermore, the port of existing programs to parallel architectures is likely to become much easier. A number of vendor proposals have been made and are being considered by the HPFF <ref> [10, 15, 19] </ref>. 5 Where's Europe? While it is clear that Hans Zima's group in Vienna have earned the right to play an important r ole in the formulation of a universal High-Performance Fortran, the financial out-lay involved in participation is such that European involvement is likely to be minimal.
Reference: [20] <institution> Thinking Machines Corporation, Cambridge, MA, USA. </institution> <type> CM-5 Technical Summary, </type> <month> October </month> <year> 1991. </year>
Reference-contexts: This is naturally exploited in data-parallel HPF PERSPECTIVE 9 programs on SIMD architectures, such as the CM-2 by Thinking Machines Corporation (TMC). <ref> [20] </ref> The CM-Fortran language developed by TMC [21] essentially only caters for the array subcomponent of the Fortran-90 language, and additionally provides a few extensions to it which are natural for SIMD architectures, e.g., the (single-statement) FORALL, and a few compiler directives: DIMENSION array (M1,M2,M3), vector (M1) CMF$ LAYOUT array (
Reference: [21] <institution> Thinking Machines Corporation, </institution> <address> Cambridge, MA, USA. </address> <note> CM Fortran Reference Manual, July 1991. Version 1.1. </note>
Reference-contexts: This is naturally exploited in data-parallel HPF PERSPECTIVE 9 programs on SIMD architectures, such as the CM-2 by Thinking Machines Corporation (TMC). [20] The CM-Fortran language developed by TMC <ref> [21] </ref> essentially only caters for the array subcomponent of the Fortran-90 language, and additionally provides a few extensions to it which are natural for SIMD architectures, e.g., the (single-statement) FORALL, and a few compiler directives: DIMENSION array (M1,M2,M3), vector (M1) CMF$ LAYOUT array ( :SERIAL, :NEWS, :SEND) CMF$ ALIGN vector (I)
Reference: [22] <author> Clemens-August Thole. </author> <title> `High Performance Fortran Forum: Aims, Organisation and Current Status of the Proposal'. </title> <booktitle> Presented at the European Workshop on High-Level Programming Models for Parallel Architectures (Brussels, May 19th, </booktitle> <year> 1992), </year> <month> May </month> <year> 1992. </year> <title> (copies of overheads). </title>
Reference-contexts: Further MIMD support is unclear, although there is likely to be an ON clause which would specify which processors should execute particular statements. An example of a code fragment containing preliminary HPF directives, presented by Clemens-August Thole in <ref> [22] </ref>, is shown in Figure 3. Note that this example uses HPF PERSPECTIVE 17 the identifier `P' in two separate namespaces the first for directives (and meaning `processors') and the other for the program (`pressure'). <p> A European Workshop on High-Level Programming Models for Parallel Architectures was used to discuss in a European context, HPFF developments in the US. The 20 EPCC-TN92-05.07 meeting, in Brussels on May 19th, followed and reported on April's HPFF meeting <ref> [22] </ref>. Coordination of the newly-established European Working Group on HPF (aka HPF-Europe) is being temporarily undertaken by Clemens-August Thole (as chairman) and Arthur Veen (as vice-chairman). This is intended to meet at another Brussels workshop on June 22nd will also follow the next scheduled HPFF meeting.
Reference: [23] <author> Joel Williamson. </author> <title> `Convex Views on Fortran-D and HPF'. </title> <note> Presented to HPFF and distributed electronically., January 1992. (copy of overhead slides). </note>
Reference-contexts: Accordingly, the Center for Standards of the US Department of Defense announced in November 1991 the rejection of Fortran-90 for DoD contract work, with the recommendation to stick with Fortran-77 (with various extensions) and Ada. (As reported on USENET and in <ref> [23] </ref>.) A different understanding of the DoD position is that Fortran-90 will not be required in system specifications, but that a full Fortran-90 implementation (and compiler) would satisfy requirements.
Reference: [24] <author> Hans Zima, Peter Brezany, Barbara Chapman, Piyush Mehrotra, and Andreas Schwald. </author> <title> `Vienna Fortran A Language Specification: Version 1.1'. </title> <type> Technical Report ACPC/TR 92-4, </type> <institution> Austrian Center for Parallel Computation, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: Mapping functions and inverses are required for all data arrays. Scalars and non-decomposed arrays are replicated. The Vienna Fortran language extensions (as described in <ref> [2, 24] </ref>) provide the following features: * The processors which execute the program may be explicitly specified and re ferred to. It is possible to impose one or more structures to them. * The distributions of arrays can be specified using annotations.
References-found: 24

