URL: http://www.cms.dmu.ac.uk/General/WWW/People/cph/Public/five95-sve.ps.gz
Refering-URL: http://www.cms.dmu.ac.uk/General/WWW/People/cph/Public/
Root-URL: 
Email: email: -d.snowdon, c.greenhalgh, s.benford-@cs.nott.ac.uk  
Title: What You See Is Not What I See: Subjectivity in Virtual Environments  
Author: Dave Snowdon, Chris Greenhalgh, Steve Benford 
Keyword: subjectivity, CSCW, visualization, collaborative virtual environments  
Web: http://www.crg.cs.nott.ac.uk  
Address: Nottingham NG7 2RD, UK  
Affiliation: Department of Computer Science, The University of Nottingham,  
Abstract: This paper discusses the issue of subjectivity in collaborative virtual environments. First, we identify current uses of subjectivity in virtual reality systems. We then examine three existing and representative collaborative applications to identify potential benefits of subjectivity. A framework for describing subjectivity based on networks of shared data and transformations is introduced. This framework is then used as a vehicle for discussing issues of subjectivity, mutual awareness, representation and embodiment. Finally, we touch on a number of further issues including notions of evolving consensus views and some possible problems caused by subjectivity. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <institution> Division Ltd. </institution> <year> (1993), </year> <note> dVS Technical Overview, Version 2.0.4 </note>
Reference-contexts: 1. Introduction Most current multi-user virtual reality systems provide a highly objective virtual environment. That is, all users see the environment in the same way, albeit from different viewpoints and all users see same objects in the same places with the same appearances. Both dVS <ref> [1] </ref> and DIVE [2] adopt a typical approach in which a virtual world is encoded as entries in a distributed database in which the same information is relayed to all participants in that world.
Reference: 2. <author> Carlsson, C. and Hagsand, O., </author> <year> (1993), </year> <title> DIVE - A Multi-User Virtual Reality System, </title> <booktitle> VRAIS93, IEEE Virtual Reality Annual International Symposium, </booktitle> <pages> pp 394-400. </pages>
Reference-contexts: 1. Introduction Most current multi-user virtual reality systems provide a highly objective virtual environment. That is, all users see the environment in the same way, albeit from different viewpoints and all users see same objects in the same places with the same appearances. Both dVS [1] and DIVE <ref> [2] </ref> adopt a typical approach in which a virtual world is encoded as entries in a distributed database in which the same information is relayed to all participants in that world.
Reference: 3. <author> Snowdon, D., West, A.J., </author> <year> (1994) </year> <month> AVIARY: </month> <title> Design issues for future large-scale Virtual Environments, MIT Presence, </title> <type> 3(4). </type>
Reference-contexts: Both dVS [1] and DIVE [2] adopt a typical approach in which a virtual world is encoded as entries in a distributed database in which the same information is relayed to all participants in that world. AVIARY <ref> [3] </ref> lacks an explicit database model, depending solely on peer to peer message passing, but again the same messages are relayed identically to all participants in a world. NPSNET [4] falls part way between these, having a model of nominally consistent distributed state, but emphasising its multicast message-based realisation.
Reference: 4. <author> Zyda, M.J., Pratt, D.R., Falby, J.S., Lombardo, C. and Kelleher, K.M., </author> <title> The Software Required for Computer Generation of Virtual Environments, Presence, </title> <type> 2(2), </type> <month> Spring </month> <year> 1993, </year> <pages> pp 130-140. </pages>
Reference-contexts: AVIARY [3] lacks an explicit database model, depending solely on peer to peer message passing, but again the same messages are relayed identically to all participants in a world. NPSNET <ref> [4] </ref> falls part way between these, having a model of nominally consistent distributed state, but emphasising its multicast message-based realisation. An exception is provided by the simple subjective worlds created as applications of VEOS [5].
Reference: 5. <author> Bricken, W., and Coco, G., </author> <title> The VEOS Project, </title> <booktitle> in Presence, </booktitle> <volume> Vol. 3, No. 2, </volume> <month> Spring </month> <year> 1994, </year> <pages> pp. 111-129, </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: NPSNET [4] falls part way between these, having a model of nominally consistent distributed state, but emphasising its multicast message-based realisation. An exception is provided by the simple subjective worlds created as applications of VEOS <ref> [5] </ref>. However, experiences with the strictly objective WYSIWIS (What You See Is What I see) paradigm for 2D interfaces suggest that collaborative applications in general require some degree of subjectivity, leading to variants such as Relaxed WYSIWIS [6].
Reference: 6. <author> Stefik, M., Bobrow, D.G., Foster, G., Lanning, S., and Tatar, D., </author> <month> (April, </month> <year> 1987), </year> <title> WYSIWIS Revised: Early Experiences with Multi-User Interfaces, </title> <journal> ACM Transactions on Office Information Systems, </journal> <volume> Vol. 5, No. 2, </volume> <pages> pp 147-167. </pages>
Reference-contexts: However, experiences with the strictly objective WYSIWIS (What You See Is What I see) paradigm for 2D interfaces suggest that collaborative applications in general require some degree of subjectivity, leading to variants such as Relaxed WYSIWIS <ref> [6] </ref>. Learning from 2D interfaces, this paper aims to explore the issue of subjectivity in collaborative virtual environments. Our argument proceeds in two stages.
Reference: 7. <author> Benford, S., and Fahln, L. </author> <year> (1994), </year> <title> Viewpoints, Actionpoints and Spatial Frames for Collaborative User Interfaces, </title> <booktitle> 6th ERCIM workshop, </booktitle> <address> June 1994, Stockholm. </address>
Reference-contexts: This is our experience of the everyday world; as such, we expect people to be skilled at relating to viewpoints and reasoning about these kind of subjective effects. <ref> [7] </ref> discusses independence of viewpoints (and actionpoints - points of interaction) within common spatial frames of reference at some length. <p> However, we argue that the notion of a common spatial frame which defines the placement of objects is generally more fundamental to the creation of a shared space than other presentational details <ref> [7] </ref>. An empty space is essentially meaningless; the (relative or absolute) placement of objects embodies the meaning of the space. There are two special cases of subjective location-changing transformations that should be noted. <p> So if the view inferred from another users representation is very different from the view that user actually has then it cannot be considered to be an embodiment. This may be because the users have different spatial frames of reference (see <ref> [7] </ref> for a more detailed discussion of viewpoints and common spatial frames); it may also be because they are seeing different objects or because of extreme differences in the presentation of those objects (which make them hard to relate together).
Reference: 8. <author> Stone, M. C., Fishkin, K. and Bier, E. A. </author> <year> (1994), </year> <title> The Movable Filter as a User Interface Tool, </title> <booktitle> In CHI94, </booktitle> <pages> pp 306-312. </pages>
Reference-contexts: As a further note, while independent viewpoints are almost universal in virtual reality, they are much less common in 2D collaborative applications (but see for example <ref> [8] </ref>). 2.2 Distancing effects A common technique in interactive computer graphics, which is equally applicable in multi-user virtual environments, is to make distant objects less detailed than nearby objects. <p> Controllers work in teams and as part of their work informally check the work of the other team members; it is therefore important that each member of the team can instantly understand anothers display, which would be impossible if uncontrolled customisation of views were permitted <ref> [8] </ref>. Also the positions of objects - the spatial frame - is common to all observers because it is taken directly from a current physical situation. Within this common spatial frame most actions could be subjective, applying only to the users view.
Reference: 9. <author> Graves, D. </author> <year> (1989), </year> <title> A Laymans Guide to United Kingdom Air Traffic Control, </title> <publisher> Airlife Publishing Ltd. </publisher>
Reference-contexts: We use this application as an example of one which displays real-world data in a relatively realistic (and constrained) manner. The application has been implemented using the AVIARY system. 3.1.1 The ATC application The purpose of ATC <ref> [9, 10] </ref> is to direct ights to their destinations both safely and efficiently. Safety is attained by keeping aircraft separated from each other [9]. The application described here seeks to provide an alternative to the 2D computer enhanced radar displays used by controllers to track and identify aircraft. <p> The application has been implemented using the AVIARY system. 3.1.1 The ATC application The purpose of ATC [9, 10] is to direct ights to their destinations both safely and efficiently. Safety is attained by keeping aircraft separated from each other <ref> [9] </ref>. The application described here seeks to provide an alternative to the 2D computer enhanced radar displays used by controllers to track and identify aircraft. Aircraft have a position in 3D space, a direction and speed, ight code and an intended ight path.
Reference: 10. <author> Bentley, R., Hughes, J.A., Randall, D., Rodden, T., Sawyer, P., Shapiro, D., and Sommerville, I. </author> <year> (1992), </year> <title> Ethnographically-informed systems design for air traffic control, </title> <booktitle> In proceedings of CSCW92, </booktitle> <pages> pp 123-129. </pages>
Reference-contexts: We use this application as an example of one which displays real-world data in a relatively realistic (and constrained) manner. The application has been implemented using the AVIARY system. 3.1.1 The ATC application The purpose of ATC <ref> [9, 10] </ref> is to direct ights to their destinations both safely and efficiently. Safety is attained by keeping aircraft separated from each other [9]. The application described here seeks to provide an alternative to the 2D computer enhanced radar displays used by controllers to track and identify aircraft. <p> will y through in the near future.artifact 3.1.2 Subjective Operations A previously reported observational study of working practices in ATC control rooms has uncovered the subtle manner in which controllers monitor each others work and conversely make their work implicitly available for others to see within a shared spatial setting <ref> [10] </ref>. <p> It has been argued that such awareness is significant to enabling communication and to the general on-going coordination of work in real world settings (e.g. studies of real-world control rooms for ATC <ref> [10] </ref> and the London Underground [15]). In terms of our consideration of subjective virtual worlds, this notion of awareness implies that users should be aware of other users whose actions potentially impact on their own.
Reference: 11. <author> Bentley, R., Rodden, T., Sawyer, P. and Sommerville, I., </author> <title> An Architecture for Tailoring Cooperative Multi-User Displays, </title> <booktitle> In proceedings of CSCW92, </booktitle> <pages> pp 187-194. </pages>
Reference-contexts: This study has informed the design of a 2-D user interface architecture which maintains consistent subjective views with potentially quite different presentational aspects, derived from a common pool of ight data <ref> [11] </ref>. In the ATC application there therefore appear to be strong reasons for limiting the customisation of a users view of the world.
Reference: 12. <author> Benford, S., Snowdon, D., Greenhalgh, C., Ingram, R. Knox, I. and Brown, C. </author> <year> (1995), </year> <title> VR-VIBE: A Virtual Environment for Co-operative Information Retrieval, </title> <booktitle> in Eurographics95. </booktitle>
Reference-contexts: Operations and information which might remain objective include: regions of responsibility of particular controllers, cues for cooperation or transfer of responsibility between controllers and major hazards or complications with far-reaching effects. 3.2 VR-VIBE - an abstract visualisation VR-VIBE <ref> [12] </ref> is an application which generates a visualization of a set of documents.
Reference: 13. <author> Benford, S., Bowers, J., Fahln, L., Greenhalgh, C., and Snowdon, D., </author> <title> User Embodiment in Collaborative Virtual Environments, </title> <booktitle> in Proc. ACM Conference on Human Factors in Computing Systems (CHI95), </booktitle> <address> May 7-11, 1995, Denver, Colorado, USA. </address>
Reference-contexts: different colours, representing personal interest) and different locations (as a result of manipulating POIs). 3.3 User representation Users are normally embodied in a collaborative virtual environment as artifacts; this supports the sense of self and presence, and facilitates interaction and cooperation between users by communicating presence, location, identity, etc. (see <ref> [13] </ref>). As artifacts in the environment subjective operations may also be applied to other users embodiments. Potential uses of subjectivity include: Another user has a very complex embodiment and you wish to substitute it for a simpler one since it is consuming too much of your machines resources.
Reference: 14. <author> Greenhalgh, C., and Benford, S. </author> <title> (1995) MASSIVE: A Collaborative Virtual Environment for Tele-Conferencing, </title> <note> To appear in ACM TOCHI, ACM Press. </note>
Reference-contexts: Once users spatial frames diverge it is anticipated that any form of collaboration that implicitly or explicitly depends on spatial location (e.g. CAD, many forms of information visualization such as VR-VIBE, or the spatial model of interaction <ref> [14] </ref>) will become very difficult if not impossible. In practice users might have to negotiate a common spatial frame before they could begin to collaborate effectively. 5.
Reference: 15. <author> Heath, C. and Luff, P. </author> <title> (1991) Collaborative activity and technological design: task coordination in London Underground control rooms, </title> <editor> in Bannon, L., Robinson, M., and Schmidt, K. (eds.) </editor> <booktitle> Proc of the Second European Conference on Computer Supported Cooperative Work (ECSCW91), </booktitle> <publisher> Kluwer, Dordrecht. </publisher>
Reference-contexts: It has been argued that such awareness is significant to enabling communication and to the general on-going coordination of work in real world settings (e.g. studies of real-world control rooms for ATC [10] and the London Underground <ref> [15] </ref>). In terms of our consideration of subjective virtual worlds, this notion of awareness implies that users should be aware of other users whose actions potentially impact on their own.
Reference: 16. <author> Abigail Sellen, Bill Buxton, John Arnott, </author> <title> (1992) Using Spatial Cues to Improve Videoconferencing, </title> <booktitle> in Proc. ACM Conference on Human Factors in Computing Systems (CHI92), </booktitle> <address> May 3-7, Monterey, California, New York: </address> <publisher> ACM, pp.651-652. </publisher>
Reference: 17. <author> Yusuke Ichikawa, Ken-ichi Okada, Giseok Jeong, Shunsuke Tanaka and Yutaka Matsushita, </author> <title> (1995) MAJIC Videoconferencing System: Experiments, Evaluation and Improvement, </title> <booktitle> in Proc. of the Fourth European Conference on Computer Supported Cooperative Work (ECSCW95), </booktitle> <address> September 10-14, Stockholm, Sweden, Dordrecht: </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: There is no common context or spatial frame of reference between the participants and in only rarely ([16], <ref> [17] </ref>) is the remote participants image explicitly linked to their viewpoint. On the other hand, a tele-pointer in a shared 2-D editor might be properly considered to be a primitive (albeit rather fuzzy) embodiment, since the tele-pointer is constrained to lie within the users field of view.
References-found: 17

