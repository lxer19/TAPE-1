URL: http://charm.cs.uiuc.edu/papers/ParJavaPDPTA97.ps
Refering-URL: http://charm.cs.uiuc.edu/papers/ParJavaPDPTA97.html
Root-URL: http://www.cs.uiuc.edu
Title: Design and Implementation of Parallel Java with Global Object Space  
Author: L. V. Kale, Milind Bhandarkar, and Terry Wilmarth 
Keyword: parallel, message-driven programming, object-oriented, Java  
Address: Urbana, IL, U.S.A.  
Affiliation: Parallel Programming Laboratory Department of Computer Science University of Illinois, Urbana-Champaign  
Abstract: Java 1 has emerged as a dominant language that could eventually replace C++. It is believed that using Java would boost programmer productivity because of its well-thought design, independence from backward-compatibility with C, absence of arbitrary pointers, etc. We present the design and implementation of a parallel extension to Java. The parallel extension provides dynamic creation of remote objects with load balancing, and object groups. The language constructs are based on those of Charm++[1]. The parallel Java extension is implemented using the Converse[2] interoperability framework, which makes it possible to integrate parallel libraries written in Java with modules in other parallel languages in a single application. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L.V. Kale and S. Krishnan. Charm++: </author> <title> A portable concurrent object oriented system based on C++. </title> <booktitle> In Proceedings of the Conference on Object Oriented Programming Systems, Languages and Applications, </booktitle> <month> September </month> <year> 1993. </year>
Reference: [2] <author> L. V. Kale, Milind Bhandarkar, Narain Jagathesan, Sanjeev Krishnan, and Joshua Yelon. </author> <title> Converse: An Interoperable Framework for Parallel Programming. </title> <booktitle> In Proceedings of the 10th International Parallel Processing Symposium, </booktitle> <pages> pages 212-217, </pages> <address> Honolulu, Hawaii, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: Before describing our implementation we first briefly review Converse and the relevant Java features. 3.1 Converse Converse <ref> [2] </ref> is a runtime framework that supports multilingual parallel programming.
Reference: [3] <author> James Gosling, Bill Joy, and Guy Steele. </author> <title> The Java Language Specification. </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year>
Reference-contexts: When the scheduler is exposed to the MPI developer, MPI can transfer the control to scheduler for performing other computations while it waits for the specific message. 3.2 The Java Language Much of our implementation makes use of available Java <ref> [3] </ref> facilities. We discuss the Java Remote Method Invocation API and some of the drawbacks of its use.
Reference: [4] <author> Sanjeev Krishnan and L. V. Kale. </author> <title> A parallel array abstraction for data-driven objects. </title> <booktitle> In Proc. Parallel Object-Oriented Methods and Applications Conference, </booktitle> <month> February </month> <year> 1996. </year>
Reference-contexts: Object groups (Branch-Office chares) are a restricted form of the more general object array abstraction. This abstraction supports multidimensional arrays of remote objects. These arrays are range-addressable, support static mapping and object migration. Object arrays have been implemented in Charm++ <ref> [4] </ref> and have been found useful in several scientific applications. In our current implementation, the only mode of inter-object communication is through remote method invocation.
Reference: [5] <author> A. Sinha and L.V. Kale. </author> <title> Information Sharing Mechanisms in Parallel Programs. </title> <editor> In H.J. Siegel, editor, </editor> <booktitle> Proceedings of the 8th International Parallel Processing Sym posium, </booktitle> <pages> pages 461-468, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: However for many programming tasks, better mechanisms of sharing information between objects can be used to make the structure of the program simple to understand and modify. In Charm++, we have already shown the utility of such abstractions called specifically shared variables <ref> [5] </ref>. Message prioritization provides an elegant way to optimize a parallel message-driven program [6]. This optimization is achieved by associating priorities with computations specified by messages in order to speed up processing of tasks on the critical path of the program.
Reference: [6] <author> L.V. Kale, B. Ramkumar, V. Saletore, and A. B. Sinha. </author> <title> Prioritization in parallel symbolic computing. </title> <editor> In T. Ito and R. Halstead, editors, </editor> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> volume 748, </volume> <pages> pages 12-41. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: In Charm++, we have already shown the utility of such abstractions called specifically shared variables [5]. Message prioritization provides an elegant way to optimize a parallel message-driven program <ref> [6] </ref>. This optimization is achieved by associating priorities with computations specified by messages in order to speed up processing of tasks on the critical path of the program.
Reference: [7] <author> L. V. Kale, Milind Bhandarkar, Robert Brunner, Neal Krawetz, James Phillips, and Aritomo Shinozaki. </author> <title> A case study in multilingual parallel programming. </title> <type> Technical report, </type> <institution> Theoretical Biophysics Group, Beckman Institute, University of Illinois, Urbana, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: The concept of sequential components in JavaBeans can be extended to parallel components, thus providing a bridge to the fast method invocation mechanism of Converse. This capability will be demonstrated in NAMD, a molecular dynamics simulation program we have been developing at University of Illinois <ref> [7] </ref>. We will build customizable parallel components for various entities in the simulations. It will then be possible to tie these components together using a scripting language in a customized molecular dynamics application. 5 Conclusion We described the design and implementation of a parallel Java extension.
Reference: [8] <author> Michael Philippsen and Matthias Zenger. </author> <title> JavaParty-Transparent Remote Objects in Java. </title> <booktitle> In ACM 1997 PPoPP Workshop on Java for Science and Engineering Computation (To Appear), </booktitle> <address> Las Vegas, Nevada, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: This can provide a boost in programmer productivity. A few other approaches to parallel Java have been made recently. JavaParty <ref> [8] </ref> supports synchronous and asynchronous method invocation of remote objects. It requires modification to the Java compiler. Some other approaches, [9], [10] provide CSP like channels for communicating Java processes.
Reference: [9] <author> Erik D. Demaine. </author> <title> Higher-Order Concur-rency in Java. </title> <booktitle> In Proceedings of the Parallel Programming and Java Conference (WoTUG-20), </booktitle> <pages> pages 34-47, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: This can provide a boost in programmer productivity. A few other approaches to parallel Java have been made recently. JavaParty [8] supports synchronous and asynchronous method invocation of remote objects. It requires modification to the Java compiler. Some other approaches, <ref> [9] </ref>, [10] provide CSP like channels for communicating Java processes. Our approach differs from them primarily in our support for interoperability with other parallel languages, and in our parallel object primitives which we believe are a better match with both parallel programming requirements, and the Java programming model.
Reference: [10] <author> Gerald Hilderink, Jan Broenink, Wiek Vervoort, and Andre Bakkers. </author> <title> Communicating Java Threads. </title> <note> In WoTUG-20: Parallel Programming and Java Conference (To Appear), </note> <month> April </month> <year> 1997. </year>
Reference-contexts: This can provide a boost in programmer productivity. A few other approaches to parallel Java have been made recently. JavaParty [8] supports synchronous and asynchronous method invocation of remote objects. It requires modification to the Java compiler. Some other approaches, [9], <ref> [10] </ref> provide CSP like channels for communicating Java processes. Our approach differs from them primarily in our support for interoperability with other parallel languages, and in our parallel object primitives which we believe are a better match with both parallel programming requirements, and the Java programming model.
References-found: 10

