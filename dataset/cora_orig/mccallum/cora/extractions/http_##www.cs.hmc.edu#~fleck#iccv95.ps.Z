URL: http://www.cs.hmc.edu/~fleck/iccv95.ps.Z
Refering-URL: http://www.cs.hmc.edu/~fleck/iowa-lab/wide.html
Root-URL: http://www.cs.hmc.edu
Title: Robot Aerobics: Four Easy Steps to a More Flexible Calibration  
Author: Daniel E. Stevenson and Margaret M. Fleck 
Address: Iowa City, IA 52242, USA  
Affiliation: Department of Computer Science University of Iowa  
Abstract: In this paper, we present a method for calibrating intrinsic and extrinsic camera parameters. This algorithm can easily be modified by other users to suit their particular calibration needs, without requiring a high precision calibration target or complicated linear algebra. The algorithm uses controlled motions and a single light source to simulate calibration targets in convenient 3D locations. These convenient calibration targets enable us to simplify the calibration algorithm and gather dense data for lens distortion. Dense data makes the distortion correction more accurate than traditional low-order polynomial fits, and allows us to calibrate wide-angle lenses (&gt; 70 ffi field of view). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Basu, </author> <title> Anup (1993) "Active Calibration: Alternative Strategy and Analysis," </title> <booktitle> IEEE CVPR 1993, </booktitle> <pages> 495-500. </pages>
Reference-contexts: The moving camera algorithms calibrate camera parameters by observing the motion of features as the camera is moved in a known direction. All existing algorithms in this class are seriously flawed. Many <ref> [1, 3, 5, 7, 8, 9] </ref> assume there is no radial distor tion and, thus, cannot be used with wide-angle lenses. Some [1, 3, 4, 13] cannot calibrate extrinsic parameters: they are set by manual alignment, introducing unknown errors. Algorithms based on zooming [11] will not work on non-zoom lenses. <p> All existing algorithms in this class are seriously flawed. Many [1, 3, 5, 7, 8, 9] assume there is no radial distor tion and, thus, cannot be used with wide-angle lenses. Some <ref> [1, 3, 4, 13] </ref> cannot calibrate extrinsic parameters: they are set by manual alignment, introducing unknown errors. Algorithms based on zooming [11] will not work on non-zoom lenses. Finally, previous algorithms provide only sketchy information about radial distortion. Only Oh and Hall [13] gather dense data on the distortion function. <p> This should be sufficient precision for most practical applications. Notice that the principal point cannot be found by translating along an estimate of the camera axis and detecting the focus of expansion as proposed in [6] (cf. also <ref> [1, 3, 4] </ref>). The focus of expansion is determined by which axis you translate along: pick a (slightly) different axis direction and you get a (substantially) different focus of expansion and thus a different hypothesis for the principal point.
Reference: [2] <author> Margaret M. </author> <title> Fleck (1995) "Perspective Projection: the Wrong Imaging Model," </title> <type> TR 95-01, </type> <institution> Comp. Sci., U. Iowa, </institution>
Reference-contexts: Therefore, we use a more general two-stage imaging model <ref> [2] </ref>: perspective projection onto a sphere, followed by a radially symmetric projection onto the image plane. <p> Stereographic projection (k tan ( ff 2 )), which has convenient geometric properties, approximates the fisheye projections <ref> [2] </ref>. Direct representation of the radial projection function offers several advantages for wide-angle lenses. The projection function values are always relatively small, whereas the distortion between a fisheye lens and perspective projection becomes infinite as the field of view approaches 180 ffi .
Reference: [3] <author> Dron, </author> <title> Lisa (1993) "Dynamic Camera Self-Calibration from Controlled Motion Sequences," </title> <booktitle> IEEE CVPR 1993, </booktitle> <pages> 501-506. </pages>
Reference-contexts: The moving camera algorithms calibrate camera parameters by observing the motion of features as the camera is moved in a known direction. All existing algorithms in this class are seriously flawed. Many <ref> [1, 3, 5, 7, 8, 9] </ref> assume there is no radial distor tion and, thus, cannot be used with wide-angle lenses. Some [1, 3, 4, 13] cannot calibrate extrinsic parameters: they are set by manual alignment, introducing unknown errors. Algorithms based on zooming [11] will not work on non-zoom lenses. <p> All existing algorithms in this class are seriously flawed. Many [1, 3, 5, 7, 8, 9] assume there is no radial distor tion and, thus, cannot be used with wide-angle lenses. Some <ref> [1, 3, 4, 13] </ref> cannot calibrate extrinsic parameters: they are set by manual alignment, introducing unknown errors. Algorithms based on zooming [11] will not work on non-zoom lenses. Finally, previous algorithms provide only sketchy information about radial distortion. Only Oh and Hall [13] gather dense data on the distortion function. <p> This should be sufficient precision for most practical applications. Notice that the principal point cannot be found by translating along an estimate of the camera axis and detecting the focus of expansion as proposed in [6] (cf. also <ref> [1, 3, 4] </ref>). The focus of expansion is determined by which axis you translate along: pick a (slightly) different axis direction and you get a (substantially) different focus of expansion and thus a different hypothesis for the principal point.
Reference: [4] <author> Du, </author> <title> Fenglei and Michael Brady (1993) "Self-Calibration of the Intrinsic Parameters of Cameras for Active Vision Systems," </title> <booktitle> IEEE CVPR 1993, </booktitle> <pages> 477-482. </pages>
Reference-contexts: All existing algorithms in this class are seriously flawed. Many [1, 3, 5, 7, 8, 9] assume there is no radial distor tion and, thus, cannot be used with wide-angle lenses. Some <ref> [1, 3, 4, 13] </ref> cannot calibrate extrinsic parameters: they are set by manual alignment, introducing unknown errors. Algorithms based on zooming [11] will not work on non-zoom lenses. Finally, previous algorithms provide only sketchy information about radial distortion. Only Oh and Hall [13] gather dense data on the distortion function. <p> Algorithms based on zooming [11] will not work on non-zoom lenses. Finally, previous algorithms provide only sketchy information about radial distortion. Only Oh and Hall [13] gather dense data on the distortion function. Other methods calculate one <ref> [4, 19, 20] </ref>, two [17], or three [11] parameters of a polynomial approximation. These algorithms have been tested only on low-distortion lenses: field of view less than 65 ffi or precision fisheye lenses [6, 13, 19]. <p> This should be sufficient precision for most practical applications. Notice that the principal point cannot be found by translating along an estimate of the camera axis and detecting the focus of expansion as proposed in [6] (cf. also <ref> [1, 3, 4] </ref>). The focus of expansion is determined by which axis you translate along: pick a (slightly) different axis direction and you get a (substantially) different focus of expansion and thus a different hypothesis for the principal point.
Reference: [5] <author> Faugeras, </author> <title> Olivier (1992) "Camera Self-Calibration: Theory and Experiment," </title> <booktitle> European Conf. Comp. Vision 1992, </booktitle> <pages> 321-334. </pages>
Reference-contexts: The moving camera algorithms calibrate camera parameters by observing the motion of features as the camera is moved in a known direction. All existing algorithms in this class are seriously flawed. Many <ref> [1, 3, 5, 7, 8, 9] </ref> assume there is no radial distor tion and, thus, cannot be used with wide-angle lenses. Some [1, 3, 4, 13] cannot calibrate extrinsic parameters: they are set by manual alignment, introducing unknown errors. Algorithms based on zooming [11] will not work on non-zoom lenses.
Reference: [6] <author> Fiala, John C., Ronald Lumia, Karen J. Roberts, and Albert J. </author> <month> Wavering </month> <year> (1994) </year> <month> "TRICLOPS: </month> <title> A Tool for Studying Active Vision," </title> <journal> Intern. J. of Comp. </journal> <pages> Vision 12/2-3, 231-250. </pages>
Reference-contexts: Only Oh and Hall [13] gather dense data on the distortion function. Other methods calculate one [4, 19, 20], two [17], or three [11] parameters of a polynomial approximation. These algorithms have been tested only on low-distortion lenses: field of view less than 65 ffi or precision fisheye lenses <ref> [6, 13, 19] </ref>. There is no reason to believe the wide variety of distortion functions for wide-angle lenses [15] (Figure 1) can be accurately modeled by low-order polynomials. <p> This should be sufficient precision for most practical applications. Notice that the principal point cannot be found by translating along an estimate of the camera axis and detecting the focus of expansion as proposed in <ref> [6] </ref> (cf. also [1, 3, 4]). The focus of expansion is determined by which axis you translate along: pick a (slightly) different axis direction and you get a (substantially) different focus of expansion and thus a different hypothesis for the principal point.
Reference: [7] <author> Hartley, Richard I. </author> <title> (1992) "Estimation of Relative Camera Positions for Uncalibrated Cameras," </title> <booktitle> Euro-pean Conf. Comp. Vision 1992, </booktitle> <pages> 579-587. </pages>
Reference-contexts: The moving camera algorithms calibrate camera parameters by observing the motion of features as the camera is moved in a known direction. All existing algorithms in this class are seriously flawed. Many <ref> [1, 3, 5, 7, 8, 9] </ref> assume there is no radial distor tion and, thus, cannot be used with wide-angle lenses. Some [1, 3, 4, 13] cannot calibrate extrinsic parameters: they are set by manual alignment, introducing unknown errors. Algorithms based on zooming [11] will not work on non-zoom lenses.
Reference: [8] <author> Hartley, Richard I. </author> <title> (1994) "Self-Calibration from Multiple Views with a Rotating Camera," </title> <booktitle> European Conf. Comp. Vision 1994, </booktitle> <volume> vol. </volume> <pages> I., 471-478. </pages>
Reference-contexts: The moving camera algorithms calibrate camera parameters by observing the motion of features as the camera is moved in a known direction. All existing algorithms in this class are seriously flawed. Many <ref> [1, 3, 5, 7, 8, 9] </ref> assume there is no radial distor tion and, thus, cannot be used with wide-angle lenses. Some [1, 3, 4, 13] cannot calibrate extrinsic parameters: they are set by manual alignment, introducing unknown errors. Algorithms based on zooming [11] will not work on non-zoom lenses.
Reference: [9] <author> Horaud, R., F. Dornaika, B. Boufama, and R. Mohr. </author> <title> (1994) "Self Calibration of a Stereo Head Mounted onto a Robot Arm," </title> <booktitle> European Conf. Comp. Vision 1994, </booktitle> <volume> vol. </volume> <pages> I., 455-462. </pages>
Reference-contexts: The moving camera algorithms calibrate camera parameters by observing the motion of features as the camera is moved in a known direction. All existing algorithms in this class are seriously flawed. Many <ref> [1, 3, 5, 7, 8, 9] </ref> assume there is no radial distor tion and, thus, cannot be used with wide-angle lenses. Some [1, 3, 4, 13] cannot calibrate extrinsic parameters: they are set by manual alignment, introducing unknown errors. Algorithms based on zooming [11] will not work on non-zoom lenses. <p> The weak link in this system is the robot arm. Its positioning accuracy, though acceptable for ordinary robotics applications, creates small but visible errors in camera calibration (compare <ref> [9] </ref>). We are currently designing a hand-operated calibration mount for higher-precision calibration of intrinsic parameters.
Reference: [10] <author> Kingslake, Rudolf, </author> <title> A History of the Photographic Lens, </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1989. </year>
Reference-contexts: Because the cos 4 intensity drop-off makes design of perspective lenses difficult for wide fields of view and impossible for fields of view above 140 ffi , many wide-angle lenses are designed with "fisheye" projection functions: k sin (ff), k (ff), and k sin ( ff 2 ) <ref> [10, 14] </ref> (Figure 1). Stereographic projection (k tan ( ff 2 )), which has convenient geometric properties, approximates the fisheye projections [2]. Direct representation of the radial projection function offers several advantages for wide-angle lenses. <p> The projection function values are always relatively small, whereas the distortion between a fisheye lens and perspective projection becomes infinite as the field of view approaches 180 ffi . The radial projection function can describe lenses with field of view 180 ffi <ref> [10] </ref>. There is no need for a separate focal length parameter. Finally, a table lookup algorithm can be used to undistort a camera image into any of the ideal projection models. <p> Step B3: Intensity Drop-off In an ideal perspective lens, the apparent brightness of an object decreases by approximately cos 4 (ff), where ff is the angular distance from the optical axis <ref> [10] </ref>. Because much of the drop-off is due to variation in how many pixels represent each solid angle, this effect is greatly reduced or eliminated in fisheye lenses [10]. <p> the apparent brightness of an object decreases by approximately cos 4 (ff), where ff is the angular distance from the optical axis <ref> [10] </ref>. Because much of the drop-off is due to variation in how many pixels represent each solid angle, this effect is greatly reduced or eliminated in fisheye lenses [10]. Our algorithm measures the effect as follows: 1: Center the dot at the principal point. 2: Compute the angle OE required to move the dot into a corner of the image. 3: Rotate in direction OE by small angular steps (currently 1 ffi ).
Reference: [11] <author> Li, </author> <title> Mengxiang (1994) "Camera Calibration of a Head-Eye System for Active Vision," </title> <booktitle> European Conf. Comp. Vision 1994, </booktitle> <pages> 543-554. </pages>
Reference-contexts: Previous image-based calibration algorithms fall into two classes. The complex target algorithms <ref> [11, 17, 18, 19] </ref> compute calibration from a target containing many features whose 3D configuration is precisely known. For example, Tsai [17] uses a set of corners on a planar target, translated using a precision stage. <p> Many [1, 3, 5, 7, 8, 9] assume there is no radial distor tion and, thus, cannot be used with wide-angle lenses. Some [1, 3, 4, 13] cannot calibrate extrinsic parameters: they are set by manual alignment, introducing unknown errors. Algorithms based on zooming <ref> [11] </ref> will not work on non-zoom lenses. Finally, previous algorithms provide only sketchy information about radial distortion. Only Oh and Hall [13] gather dense data on the distortion function. Other methods calculate one [4, 19, 20], two [17], or three [11] parameters of a polynomial approximation. <p> Algorithms based on zooming <ref> [11] </ref> will not work on non-zoom lenses. Finally, previous algorithms provide only sketchy information about radial distortion. Only Oh and Hall [13] gather dense data on the distortion function. Other methods calculate one [4, 19, 20], two [17], or three [11] parameters of a polynomial approximation. These algorithms have been tested only on low-distortion lenses: field of view less than 65 ffi or precision fisheye lenses [6, 13, 19].
Reference: [12] <author> Lenz, Reimar K. and Roger Y. Tsai, </author> <title> "Techniques for Calibration of the Scale Factor and Image Center for High Accuracy 3-D Machine Vision Metrology," </title> <note> IEEE PAMI 10/5 (1988) 713-720. </note>
Reference-contexts: In particular, the algorithm should handle wide-angle lenses because these are useful in navigation, analysis of egomotion, and photography in confined spaces. (The human eye has a 180 ffi horizontal field of view.) Finally, the method should not require specialized optical equipment (as in <ref> [12, 20] </ref>). Previous image-based calibration algorithms fall into two classes. The complex target algorithms [11, 17, 18, 19] compute calibration from a target containing many features whose 3D configuration is precisely known. For example, Tsai [17] uses a set of corners on a planar target, translated using a precision stage.
Reference: [13] <author> Oh, Sung Jun and Ernest L. </author> <title> Hall (1989) "Calibration of an Omnidirectional Vision Navigation System Using an Industrial Robot," </title> <booktitle> Optical Engineering 28/9, </booktitle> <pages> 955-962. </pages>
Reference-contexts: All existing algorithms in this class are seriously flawed. Many [1, 3, 5, 7, 8, 9] assume there is no radial distor tion and, thus, cannot be used with wide-angle lenses. Some <ref> [1, 3, 4, 13] </ref> cannot calibrate extrinsic parameters: they are set by manual alignment, introducing unknown errors. Algorithms based on zooming [11] will not work on non-zoom lenses. Finally, previous algorithms provide only sketchy information about radial distortion. Only Oh and Hall [13] gather dense data on the distortion function. <p> Some [1, 3, 4, 13] cannot calibrate extrinsic parameters: they are set by manual alignment, introducing unknown errors. Algorithms based on zooming [11] will not work on non-zoom lenses. Finally, previous algorithms provide only sketchy information about radial distortion. Only Oh and Hall <ref> [13] </ref> gather dense data on the distortion function. Other methods calculate one [4, 19, 20], two [17], or three [11] parameters of a polynomial approximation. These algorithms have been tested only on low-distortion lenses: field of view less than 65 ffi or precision fisheye lenses [6, 13, 19]. <p> Only Oh and Hall [13] gather dense data on the distortion function. Other methods calculate one [4, 19, 20], two [17], or three [11] parameters of a polynomial approximation. These algorithms have been tested only on low-distortion lenses: field of view less than 65 ffi or precision fisheye lenses <ref> [6, 13, 19] </ref>. There is no reason to believe the wide variety of distortion functions for wide-angle lenses [15] (Figure 1) can be accurately modeled by low-order polynomials.
Reference: [14] <author> Ray, Sidney F. </author> <title> (1994) Applied Photographic Optics, second edition, </title> <publisher> Focal Press, Oxford. </publisher>
Reference-contexts: Because the cos 4 intensity drop-off makes design of perspective lenses difficult for wide fields of view and impossible for fields of view above 140 ffi , many wide-angle lenses are designed with "fisheye" projection functions: k sin (ff), k (ff), and k sin ( ff 2 ) <ref> [10, 14] </ref> (Figure 1). Stereographic projection (k tan ( ff 2 )), which has convenient geometric properties, approximates the fisheye projections [2]. Direct representation of the radial projection function offers several advantages for wide-angle lenses.
Reference: [15] <author> Smith, Warren J. </author> <title> (1992) Modern Lens Design: A Resource Manual, </title> <publisher> McGraw-Hill, </publisher> <address> New York. </address>
Reference-contexts: These algorithms have been tested only on low-distortion lenses: field of view less than 65 ffi or precision fisheye lenses [6, 13, 19]. There is no reason to believe the wide variety of distortion functions for wide-angle lenses <ref> [15] </ref> (Figure 1) can be accurately modeled by low-order polynomials. For example, Figure 2 shows the systematic errors between two Tsai-type fifth-order (2-parameter) polynomials and measured data for our 2.6mm lens (116:5 ffi field of view).
Reference: [16] <author> Stevenson, Daniel E. and Margaret M. </author> <title> Fleck (1994) "Robot Aerobics: Four Easy Steps to a More Flexible Calibration," </title> <type> TR 94-09, </type> <institution> Comp. Sci., U. of Iowa. </institution>
Reference-contexts: On a high-precision mount (e.g. a set of optical stages), it could produce very high-precision measurements of intrinsic camera parameters. Even on a robot arm whose positioning is definitely suspect, it produces results precise enough for most vision applications. See <ref> [16] </ref> for additional details. Acknowledgments We would like to thank Terry Boult, Michael Cov-ington, Brian Madden, Howard Moraff, Steve Os-borne, and Mike Wall.
Reference: [17] <author> Tsai, Roger Y., </author> <title> "An Efficient and Accurate Camera Calibration Technique for 3D Machine Vision," </title> <booktitle> IEEE CVPR 1986, </booktitle> <pages> 364-374. </pages>
Reference-contexts: Previous image-based calibration algorithms fall into two classes. The complex target algorithms <ref> [11, 17, 18, 19] </ref> compute calibration from a target containing many features whose 3D configuration is precisely known. For example, Tsai [17] uses a set of corners on a planar target, translated using a precision stage. <p> Previous image-based calibration algorithms fall into two classes. The complex target algorithms [11, 17, 18, 19] compute calibration from a target containing many features whose 3D configuration is precisely known. For example, Tsai <ref> [17] </ref> uses a set of corners on a planar target, translated using a precision stage. These algorithms are fast, but they require special precision targets and are "black boxes" which the typical user can neither understand nor modify. <p> Algorithms based on zooming [11] will not work on non-zoom lenses. Finally, previous algorithms provide only sketchy information about radial distortion. Only Oh and Hall [13] gather dense data on the distortion function. Other methods calculate one [4, 19, 20], two <ref> [17] </ref>, or three [11] parameters of a polynomial approximation. These algorithms have been tested only on low-distortion lenses: field of view less than 65 ffi or precision fisheye lenses [6, 13, 19]. <p> Because the lens may have considerable radial distortion, extrinsic parameters must be calibrated with only limited information about image geometry. We can use angles about the image center (as in <ref> [17] </ref>). Because radial projection functions are monotonic and symmetric about the principal point, we can also determine which of two points is further from the principal point (not used by [17]). Controlled motion of the camera is used to reveal errors in each parameter. <p> We can use angles about the image center (as in <ref> [17] </ref>). Because radial projection functions are monotonic and symmetric about the principal point, we can also determine which of two points is further from the principal point (not used by [17]). Controlled motion of the camera is used to reveal errors in each parameter. We command a motion which should have a particular effect on the position of the calibration dot. The difference between the actual motion of the dot and the ideal motion is measured by an evaluation function. <p> Our controlled motions allow us to simulate features at any desired 3D location. Because a fixed calibration target may not contain a suitable set of features, and because he did not use the monotonicity of radial projection functions, Tsai <ref> [17] </ref> was unable to compute T z before the focal length and distortion parameters. 5 Accuracy of Extrinsic Parameters The implementation of Step A uses a simplified version of the steepest descent algorithm. <p> The variation between the lines in Figure 4 (left) is 6 pixels even when the principal point is displaced 20 pixels. This is consistent with the theoretical analysis in <ref> [17] </ref>: the appearance of the image is not very sensitive to changes in the principal point. The principal point can probably be localized to within 5 to 10 pixels, by integrating the radial projection function differences from Figure 4 across the entire field of view.
Reference: [18] <author> Wei, </author> <title> Guo-Qing and Song De Ma (1994) "Implicit and Explicit Camera Calibration: Theory and Experiments," </title> <journal> IEEE PAMI 16/5, </journal> <pages> 469-480. </pages>
Reference-contexts: Previous image-based calibration algorithms fall into two classes. The complex target algorithms <ref> [11, 17, 18, 19] </ref> compute calibration from a target containing many features whose 3D configuration is precisely known. For example, Tsai [17] uses a set of corners on a planar target, translated using a precision stage.
Reference: [19] <author> Weng, Juyang, P. Cohen, and M. </author> <title> Herniou (1992) "Camera Calibration with Distortion Models and Accuracy Evaluation," </title> <journal> IEEE PAMI 14/10, </journal> <pages> 965-980. </pages>
Reference-contexts: Previous image-based calibration algorithms fall into two classes. The complex target algorithms <ref> [11, 17, 18, 19] </ref> compute calibration from a target containing many features whose 3D configuration is precisely known. For example, Tsai [17] uses a set of corners on a planar target, translated using a precision stage. <p> Algorithms based on zooming [11] will not work on non-zoom lenses. Finally, previous algorithms provide only sketchy information about radial distortion. Only Oh and Hall [13] gather dense data on the distortion function. Other methods calculate one <ref> [4, 19, 20] </ref>, two [17], or three [11] parameters of a polynomial approximation. These algorithms have been tested only on low-distortion lenses: field of view less than 65 ffi or precision fisheye lenses [6, 13, 19]. <p> Only Oh and Hall [13] gather dense data on the distortion function. Other methods calculate one [4, 19, 20], two [17], or three [11] parameters of a polynomial approximation. These algorithms have been tested only on low-distortion lenses: field of view less than 65 ffi or precision fisheye lenses <ref> [6, 13, 19] </ref>. There is no reason to believe the wide variety of distortion functions for wide-angle lenses [15] (Figure 1) can be accurately modeled by low-order polynomials.
Reference: [20] <author> Willson, Reg G. </author> <title> (1994) "Modeling and Calibration of Automated Zoom Lenses," </title> <type> Ph.D. thesis, ECE, </type> <institution> Carnegie-Mellon, CMU-RI-TRI-94-03. </institution>
Reference-contexts: In particular, the algorithm should handle wide-angle lenses because these are useful in navigation, analysis of egomotion, and photography in confined spaces. (The human eye has a 180 ffi horizontal field of view.) Finally, the method should not require specialized optical equipment (as in <ref> [12, 20] </ref>). Previous image-based calibration algorithms fall into two classes. The complex target algorithms [11, 17, 18, 19] compute calibration from a target containing many features whose 3D configuration is precisely known. For example, Tsai [17] uses a set of corners on a planar target, translated using a precision stage. <p> Algorithms based on zooming [11] will not work on non-zoom lenses. Finally, previous algorithms provide only sketchy information about radial distortion. Only Oh and Hall [13] gather dense data on the distortion function. Other methods calculate one <ref> [4, 19, 20] </ref>, two [17], or three [11] parameters of a polynomial approximation. These algorithms have been tested only on low-distortion lenses: field of view less than 65 ffi or precision fisheye lenses [6, 13, 19]. <p> To detect asymmetries, we repeat calibration steps B2 and B3, rotating the camera in eight directions (left, right, up, down, and four diagonals). Ideally, data from all eight directions should be identical: any differences indicate errors in alignment parameters. In some lenses (e.g. <ref> [20] </ref>), the drop-off in intensity response towards the edges of the image is large enough that it could be used to detect a mis-placed principal point. Because our lenses are closer to fish-eye projection than perspective, intensities vary little across our images.
References-found: 20

