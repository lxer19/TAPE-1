URL: http://www.cs.washington.edu/homes/karlin/papers/butterfly.ps
Refering-URL: http://www.cs.washington.edu/homes/karlin/papers.html
Root-URL: http://www.cs.washington.edu
Title: On the Fault Tolerance of the Butterfly  
Author: Anna R. Karlin Greg Nelson Hisao Tamaki 
Abstract: We study the robustness of the butterfly network against random static faults. Suppose that each edge of the butterfly is present independently of other edges with probability p. Our main result is that there is a 0-1 law on the existence of a linear-sized component. More formally, there is a critical probability pfl such that for p above pfl, the faulted butterfly almost surely contains a linear-sized component, whereas for p below pfl, the faulted butterfly almost surely does not contain a linear-sized component. 
Abstract-found: 1
Intro-found: 1
Reference: [AKS82] <author> M. Ajtai, J. Komlos, and E. Szemeredi. </author> <title> Largest random component of a k-cube. </title> <journal> Combinatorica, </journal> <volume> 2(1) </volume> <pages> 1-7, </pages> <year> 1982. </year>
Reference-contexts: Then G has critical probability 1=2. This was proved by Kesten in 1980, and is the best known result of percolation theory [Kes80]. * Let C d denote the hypercube of dimension d. Then C has critical probability 1=d. This was proved by Ajtai, Komlos, and Szemeredi in 1981 <ref> [ES79, AKS82] </ref>. Page 1 We have altered the usual statement of these the-orems to fit them into our mold. For example, the result for the grid is usually stated as the critical probability for the existence of an infinite component in the faulted infinite grid. <p> Although the details are different, the idea of using two stages of randomization, and branching process theory in order to construct connected components in the first randomization can be found in the hypercube result of <ref> [AKS82] </ref>. The next two subsections give the details of the proof. 3.1 Part 1 The proof of part 1 relies on a result from the theory of branching processes. Recall that a discrete-time branching process consists of an initial population. In our case, the initial population has size 1.
Reference: [AL91] <author> B. Aiello and F.T. Leighton. </author> <title> Coding theory, hypercube embeddings, and fault tolerance. </title> <booktitle> In Proceedings of the 3rd ACM Annual Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1991. </year>
Reference-contexts: network structure. (In fact, the slowdown factor of the simulation is O (load + dilation + congestion) due to the result of Leighton, Maggs, and Rao [LMR] on off-line routing.) Efficient fault-avoiding self-embeddings have been constructed for the hypercube (by Hastad, Leighton and Newman [HLN87, HLN89] and Aiello and Leighton <ref> [AL91] </ref>) and the grid (by a mammoth collaboration [KKL + 90]). But the butterfly has proved harder to deal with, since it does not have the high connectivity of the hypercube, and it does not have the simple geometric structure of the grid, which can be exploited to circumnavigate faults.
Reference: [AS92] <author> N. Alon and J. H. Spencer. </author> <title> The probabilistic method. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Therefore, we can use the FKG inequality (see, for example, <ref> [AS92] </ref>) to obtain Pr (w 0 k connected in B d =p) Pr (D&C 1 & . . . &C k &E) p d 0 ffi k : We now use symmetry considerations to infer that this bound on connection probability applies to any pair of nodes u on level 0
Reference: [ER60] <author> P. Erd-os and A. Renyi. </author> <title> On the evolution of random graphs. </title> <journal> Publ. Math. Inst. Hun-gar. Acad. Sci., </journal> <volume> 5 </volume> <pages> 17-61, </pages> <year> 1960. </year> <note> known from [Bol85]. </note>
Reference-contexts: In particular: * Let K d denote the complete graph on d nodes. Then K has critical probability 1=d. This is a central result of the fundamental paper on random graph theory, by Erd-os and Renyi in 1960 <ref> [ER60] </ref>. * Let G d denote the d by d two-dimensional grid. Then G has critical probability 1=2. This was proved by Kesten in 1980, and is the best known result of percolation theory [Kes80]. * Let C d denote the hypercube of dimension d.
Reference: [ES79] <author> P. Erd-os and J. Spencer. </author> <title> Evolution of the n-cube. </title> <journal> Computers and Math. with Applications, </journal> <volume> 5 </volume> <pages> 33-40, </pages> <year> 1979. </year>
Reference-contexts: Then G has critical probability 1=2. This was proved by Kesten in 1980, and is the best known result of percolation theory [Kes80]. * Let C d denote the hypercube of dimension d. Then C has critical probability 1=d. This was proved by Ajtai, Komlos, and Szemeredi in 1981 <ref> [ES79, AKS82] </ref>. Page 1 We have altered the usual statement of these the-orems to fit them into our mold. For example, the result for the grid is usually stated as the critical probability for the existence of an infinite component in the faulted infinite grid.
Reference: [HLN87] <author> J. Hastad, F.T. Leighton, and M. Newman. </author> <title> Reconfiguring a hypercube in the presence of faults. </title> <booktitle> In Proceedings of the 19th ACM Annual Symposium on Theory of Computing, </booktitle> <pages> pages 274-284, </pages> <year> 1987. </year>
Reference-contexts: evidence of the robustness of the network structure. (In fact, the slowdown factor of the simulation is O (load + dilation + congestion) due to the result of Leighton, Maggs, and Rao [LMR] on off-line routing.) Efficient fault-avoiding self-embeddings have been constructed for the hypercube (by Hastad, Leighton and Newman <ref> [HLN87, HLN89] </ref> and Aiello and Leighton [AL91]) and the grid (by a mammoth collaboration [KKL + 90]).
Reference: [HLN89] <author> J. Hastad, F.T. Leighton, and M. New-man. </author> <title> Fast computation using faulty hyper-cubes. </title> <booktitle> In Proceedings of the 21st ACM Annual Symposium on Theory of Computing, </booktitle> <pages> pages 251-263, </pages> <year> 1989. </year>
Reference-contexts: evidence of the robustness of the network structure. (In fact, the slowdown factor of the simulation is O (load + dilation + congestion) due to the result of Leighton, Maggs, and Rao [LMR] on off-line routing.) Efficient fault-avoiding self-embeddings have been constructed for the hypercube (by Hastad, Leighton and Newman <ref> [HLN87, HLN89] </ref> and Aiello and Leighton [AL91]) and the grid (by a mammoth collaboration [KKL + 90]).
Reference: [Kes80] <author> H. Kesten. </author> <title> The critical probability of bond percolation on the square lattice equals 1/2. </title> <journal> Communication in Mathematical Physics, </journal> <volume> 74 </volume> <pages> 41-59, </pages> <year> 1980. </year>
Reference-contexts: Then G has critical probability 1=2. This was proved by Kesten in 1980, and is the best known result of percolation theory <ref> [Kes80] </ref>. * Let C d denote the hypercube of dimension d. Then C has critical probability 1=d. This was proved by Ajtai, Komlos, and Szemeredi in 1981 [ES79, AKS82]. Page 1 We have altered the usual statement of these the-orems to fit them into our mold.
Reference: [KKL + 90] <author> C. Kaklamanis, A.R. Karlin, F.T. Leighton, V. Milenkovic, P. Raghavan, S. Rao, C. Thomborson, and A. Tsantilas. </author> <title> Asymptotically tight bounds for computing with faulty arrays of processors. </title> <booktitle> In Proceedings of the 31st Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 285-296. </pages> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference-contexts: Interestingly, for the 2-dimensional grid, the critical probability for the existence of a linear-sized component coincides with the critical probability for other properties also related to the efficiency of computation, such as the ability of message routing and the ability of embedding the fault-free version <ref> [Rag89, KKL + 90, Mat92] </ref>. Whether or not the same phenomena occur on the butterfly is an interesting question, towards which we make a small amount of progress as described in the following paragraphs. <p> the simulation is O (load + dilation + congestion) due to the result of Leighton, Maggs, and Rao [LMR] on off-line routing.) Efficient fault-avoiding self-embeddings have been constructed for the hypercube (by Hastad, Leighton and Newman [HLN87, HLN89] and Aiello and Leighton [AL91]) and the grid (by a mammoth collaboration <ref> [KKL + 90] </ref>). But the butterfly has proved harder to deal with, since it does not have the high connectivity of the hypercube, and it does not have the simple geometric structure of the grid, which can be exploited to circumnavigate faults.
Reference: [LMR] <author> F.T. Leighton, B.M. Maggs, and S.B. Rao. </author> <title> Packet routing and job-shop scheduling in O(congestion + dilation) steps. </title> <journal> Combina-torica. </journal> <note> to appear. </note>
Reference-contexts: congestion implies an efficient simulation of the fault-free network by the faulty network, and thus can be considered evidence of the robustness of the network structure. (In fact, the slowdown factor of the simulation is O (load + dilation + congestion) due to the result of Leighton, Maggs, and Rao <ref> [LMR] </ref> on off-line routing.) Efficient fault-avoiding self-embeddings have been constructed for the hypercube (by Hastad, Leighton and Newman [HLN87, HLN89] and Aiello and Leighton [AL91]) and the grid (by a mammoth collaboration [KKL + 90]).
Reference: [LMS92] <author> F. T. Leighton, B. Maggs, and R. Sitara-man. </author> <title> On the unexpected fault-tolerance of some popular bounded-degree networks. </title> <booktitle> In Proceedings of the 33d Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 542-552. </pages> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: There is a polynomial time algorithm for constructing the embedding. In related work, Leighton, Maggs and Sitaraman <ref> [LMS92] </ref> have shown that for small, but constant edge-failure probability, 2 an n-node butterfly can emulate a fault-free version of itself with a slowdown of 2 O (log fl n) . Their emulation uses redundant computation.
Reference: [Mat92] <author> T.R. Mathies. </author> <title> Percolation theory and computing with faulty arrays of processors. </title> <booktitle> In Proceedings of the 3rd ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 100-103, </pages> <year> 1992. </year>
Reference-contexts: Interestingly, for the 2-dimensional grid, the critical probability for the existence of a linear-sized component coincides with the critical probability for other properties also related to the efficiency of computation, such as the ability of message routing and the ability of embedding the fault-free version <ref> [Rag89, KKL + 90, Mat92] </ref>. Whether or not the same phenomena occur on the butterfly is an interesting question, towards which we make a small amount of progress as described in the following paragraphs.
Reference: [Pip92] <author> N. Pippenger. </author> <title> The asymptotic optimality of spider-web networks. </title> <journal> Discrete applied mathematics, </journal> 37/38:437-450, 1992. 
Reference-contexts: Thus, we have a branching process with Z 1 = X d 0 (p). Since we chose d 0 3 A stronger version of this lemma, for the special case Z 1 is binomial, is given in <ref> [Pip92] </ref>. Page 4 so that E (X d 0 (p)) &gt; 1, Lemma 3.2 applies. Let fl be the value of the limit in the statement of the lemma.
Reference: [Rag89] <author> P. Raghavan. </author> <title> Robust algorithms for packet routing in a mesh. </title> <booktitle> In Proceedings of the 1st ACM Annual Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 344-350, </pages> <year> 1989. </year>
Reference-contexts: Interestingly, for the 2-dimensional grid, the critical probability for the existence of a linear-sized component coincides with the critical probability for other properties also related to the efficiency of computation, such as the ability of message routing and the ability of embedding the fault-free version <ref> [Rag89, KKL + 90, Mat92] </ref>. Whether or not the same phenomena occur on the butterfly is an interesting question, towards which we make a small amount of progress as described in the following paragraphs.
Reference: [Tam92] <author> H. Tamaki. </author> <title> Efficient self-embedding of butterfly networks with random faults. </title> <booktitle> In Proceedings of the 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 533-541, </pages> <year> 1992. </year>
Reference-contexts: This theorem implies that there is a sense in which the butterfly is far more fault-tolerant to random faults than previous results have suggested. Although it was known that there exists a constant p &lt; 1 such that B d =p contains a linear-sized component <ref> [Tam92] </ref>, the value of p readily extractable from the proof therein is astronomically close to 1. In comparison to the 2-dimensional grid which has critical probability 0.5, our theorem shows that the butterfly, with the same degree 4 as the grid, withstands significantly more faults. <p> But the butterfly has proved harder to deal with, since it does not have the high connectivity of the hypercube, and it does not have the simple geometric structure of the grid, which can be exploited to circumnavigate faults. Recently one of the authors (Tamaki <ref> [Tam92] </ref>) has constructed fault-avoiding self-embeddings of the butterfly, such that the load is O (1) and the congestion and dilation are both polyloglog in the number of nodes. However, the allowable probability of edge failure extracted from the proof of [Tam92] is unrealistically small. <p> Recently one of the authors (Tamaki <ref> [Tam92] </ref>) has constructed fault-avoiding self-embeddings of the butterfly, such that the load is O (1) and the congestion and dilation are both polyloglog in the number of nodes. However, the allowable probability of edge failure extracted from the proof of [Tam92] is unrealistically small. Using the techniques in the proof of theorem 1.1 we can improve this result to Page 2 obtain the following. <p> For p &gt; 0:586, we can show that the constant c in this theorem is greater than 1/2. This allows us to show that the base case in the inductive proof of the embedding result in <ref> [Tam92] </ref> essentially holds Page 7 for p &gt; 0:586 yielding Theorem 1.2. The details can be found in [Tam93]. Now we turn to the uniqueness of the linear-sized component.
Reference: [Tam93] <author> H. Tamaki. </author> <title> Structural robustness of the butterfly and related networks against random faults. </title> <type> PhD Thesis, </type> <institution> Department of Computer Science, University of Toronto, </institution> <year> 1993. </year> <pages> Page 9 </pages>
Reference-contexts: This allows us to show that the base case in the inductive proof of the embedding result in [Tam92] essentially holds Page 7 for p &gt; 0:586 yielding Theorem 1.2. The details can be found in <ref> [Tam93] </ref>. Now we turn to the uniqueness of the linear-sized component. Theorem 5.4 For any constants p &gt; pfl and * &gt; 0, the probability tends to 0 (as d ! 1) that the second largest connected component of B d =p contains at least *n d nodes.
References-found: 16

