URL: ftp://synapse.cs.byu.edu/pub/papers/ventura.icannga97.ps
Refering-URL: ftp://synapse.cs.byu.edu/pub/papers/details.html
Root-URL: 
Email: dan@axon.cs.byu.edu, martinez@cs.byu.edu  
Title: An Artificial Neuron with Quantum Mechanical Properties  
Author: Dan Ventura and Tony Martinez 
Address: Provo, Utah 84602 USA  
Affiliation: Department of Computer Science Brigham Young University,  
Web: (http://axon.cs.byu.edu)  
Note: Neural Networks and Machine Learning Laboratory  
Abstract: Abs tract: Quantum computation uses microscopic quantum level effects to perform computational tasks and has produced results that in some cases are exponentially faster than their classical counterparts. Choosing the best weights for a neural network is a time consuming problem that makes the harnessing of this quantum parallelism appealing. This paper briefly covers necessary high-level quantum theory and introduces a model for a quantum neuron. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Brassard, Gilles, </editor> <booktitle> New Trends in Quantum Computation, 13th Symposium on Theoretical Aspects of Computer Science, </booktitle> <year> 1996. </year>
Reference-contexts: Much effort has been made in both areas and some progress has been realized. The field of quantum computation <ref> [1] </ref>, which has been completely unrelated to that of neural networks until very recently, applies ideas from quantum mechanics to the study of computation and has made interesting progress.
Reference: [2] <author> Shor, Peter W., </author> <title> Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer, </title> <note> to appear in the SIAM Journal of Computing, </note> <year> 1996. </year>
Reference-contexts: Most notably, quantum algorithms for prime factorization and discrete logarithms have recently been discovered that provide exponential improvement over the best known classical methods <ref> [2] </ref>. Recently some work has been done in the area of combining classical artificial neural networks with ideas from the field of quantum mechanics in pursuit of goal (A).
Reference: [3] <author> Taylor, John R. and Zafiratos, Chris D., </author> <title> M o d e r n Physics for Scientists and Engineers, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1991. </year>
Reference-contexts: The theory is well established and is covered in its basic form by many textbooks (see for example <ref> [3] </ref>). Several ideas from this theory that are necessary for the following presentation must be briefly mentioned. Linear superposition is closely related to the familiar mathematical principle of linear combination.
Reference: [4] <author> Perus, Mitja, </author> <title> Neuro-Quantum Parallelism in Brain-Mind and Computers, </title> <journal> Informatica, </journal> <volume> vol. 20, </volume> <pages> pp. 173-183, </pages> <year> 1996. </year>
Reference-contexts: However, a few notable exceptions do exist. Perus has published an interesting set of mathematical analogies between the quantum formalism and neural network theory <ref> [4] </ref>. Menneer and Narayanan have proposed a model weakly inspired (their term) by the many worlds interpretation of quantum mechanics in which a network is trained for each instance in the training set and the final network is a superposition of these [5].
Reference: [5] <author> Menneer, Tammy and Narayanan, Ajit, </author> <title> Quantum-inspired Neural Networks, </title> <type> technical report R329, </type> <institution> Department of Computer Science, University of Exeter, Exeter, </institution> <address> United Kingdom, </address> <year> 1995. </year>
Reference-contexts: Menneer and Narayanan have proposed a model weakly inspired (their term) by the many worlds interpretation of quantum mechanics in which a network is trained for each instance in the training set and the final network is a superposition of these <ref> [5] </ref>. Finally, Behrman et. al. have developed a novel approach to implementing a quantum neural network using quantum dots [6].
Reference: [6] <author> Behrman, E. C., Steck, J. E., and Skinner, S. R., </author> <title> "A Quantum Dot Neural Network", </title> <note> preprint submitted to Physical Review Letters. </note>
Reference-contexts: Finally, Behrman et. al. have developed a novel approach to implementing a quantum neural network using quantum dots <ref> [6] </ref>. It uses a quantum dot for each input and the system is allowed to evolve quantum mechanically through time while being observed (and thus forced to decoher) at fixed time intervals.
Reference: [7] <author> Ventura, Dan and Martinez, Tony, </author> <title> Application of Quantum Mechanical Properties to Machine Learning, </title> <booktitle> submitted to the International Conference on Machine Learning, </booktitle> <year> 1997. </year>
Reference-contexts: Further, the idea of linear superposition may be applied not only to the weight vector of a neuron, but also to its inputs, its output, and its activation function, among other things. See <ref> [7] </ref> for an application to the problem of choosing useful features from the exponentially large set of possibilities. Also, other quantum mechanical concepts such as the quantum nature of energy, spin, momentum, etc. and EPR phenomenon may find application as this field is explored further.
References-found: 7

