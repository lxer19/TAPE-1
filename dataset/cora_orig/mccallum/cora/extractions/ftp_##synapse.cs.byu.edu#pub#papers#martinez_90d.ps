URL: ftp://synapse.cs.byu.edu/pub/papers/martinez_90d.ps
Refering-URL: ftp://synapse.cs.byu.edu/pub/papers/details.html
Root-URL: 
Title: In Future Generation Computing Systems, vol.  Smart Memory Architecture and Methods  
Author: Tony R. Martinez 
Affiliation: Computer Science Department, Brigham Young University  
Date: 1990.  
Pubnum: 6, No. 1, pp.26-58,  
Abstract: This paper discusses potential functionalities of smart memories. Smart memory entails the tight coupling of memory and logic. A specific architecture called the memory processor model is proposed. The model seeks to alleviate the von Neumann bottleneck, take advantage of technology trends, improve overall system speed, and add encapsulation advantages. Speed is increased through locality of processing, communication savings, higher-level functionality, and parallelism. Data objects are accessed through descriptors, which give the memory a meta-knowledge concerning the objects, allowing for nontraditional access mechanisms. Both data types and operations are programmable, and the model is streamlined for memory operations and services. Innovative processing schemes, coupled with emerging technology densities, allow for substantial fine-grain parallelism in traditional and novel memory operations. Three important paradigms introduced are descriptor processing, where operations are accomplished without access to the actual data, associative descriptor processing, supporting highly parallel access and processing, and the single-program multiple-data method, allowing parallelism by simultaneous processing of data objects distributed amongst multiple smart memories. Examples of specific operations are presented. This paper presents initial studies into the smart memory mechanism with the goal of describing its potential and stimulating further work. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Backus, J., </author> <title> "Can Programming Be Liberated from the von Neumann Style? A Functional Style and Its Algebra of Programs," </title> <journal> Communications of the ACM, </journal> <pages> pp. 613-641, </pages> <month> (August </month> <year> 1978). </year>
Reference-contexts: In a multiprocessor environment, the bottleneck is exacerbated due to memory contention, distance between nodes, and synchronization. Perhaps the most pervasive effect of this bottleneck has been psychological <ref> [1] </ref>. The memory-fetch and process paradigm has colored not only languages and architectures, but our concepts of computation and problem solving in general. 3.1.2 Technology Trends One factor causing the separation of logic (processing) and memory is that in early computing systems they were built from two different technologies. <p> A name could point into such a list at any level of the descriptor hierarchy. 8 Type Type Type Type Type Type Type Type 247 Type Type Type Type Type Type Type Type Type Type Type Type Type Type Type Type Integer String Array List string variable length B <ref> [1] </ref> B [3] name A different problem arises when the structure of the data object is also variable and dynamic. An example of this is a list where the number of elements and the depth of the elements change in time. <p> Hunks are larger fixed sized seg ments of the value memory. A hunk corresponds to more normal page sizes and data objects reside within word boundaries. An example is an array of integers as shown in Descriptor a <ref> [1] </ref> a [2] a [i] link There might be a small set of different sized hunks to choose from. (The same could apply with chunks). Each data value in a hunk could take up more than one word of memory.
Reference: [2] <author> Batcher, K. E., </author> <title> "Design of a Massively Parallel Processor," </title> <journal> IEEE Transactions of Computers, </journal> <volume> Vol. C-29, 9, pp.836-840, </volume> <year> (1980). </year>
Reference-contexts: Neither the types and the operations need be defined when an SM is cast into hardware, but are programmable to match the specific needs of a given system or application. Massively parallel SIMD processors have been considered by many as a type of smart memory. These include the MPP <ref> [2] </ref> and the connection machine [10]. These models are very large complete architectures, differing greatly from the architecturally small (chip-level) modularly grown mechanisms presented in this paper. Associative processors [19] support mechanisms similar to some presented in this paper, but again are large special purpose processing systems. <p> Hunks are larger fixed sized seg ments of the value memory. A hunk corresponds to more normal page sizes and data objects reside within word boundaries. An example is an array of integers as shown in Descriptor a [1] a <ref> [2] </ref> a [i] link There might be a small set of different sized hunks to choose from. (The same could apply with chunks). Each data value in a hunk could take up more than one word of memory. Conversely, there could be many values per word (i.e. a bit array).
Reference: [3] <author> Charniak, E., C.K. Riesbeck, and D.V. McDermott, </author> <booktitle> Artificial Intelligence Pro gramming, </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <address> New Jersey (1980). </address>
Reference-contexts: name could point into such a list at any level of the descriptor hierarchy. 8 Type Type Type Type Type Type Type Type 247 Type Type Type Type Type Type Type Type Type Type Type Type Type Type Type Type Integer String Array List string variable length B [1] B <ref> [3] </ref> name A different problem arises when the structure of the data object is also variable and dynamic. An example of this is a list where the number of elements and the depth of the elements change in time. <p> Extended Traditional Memory Manipulation Traditional symbolic data types which could require support from SM include sets, lists, stacks, arrays, structures, environments, text (strings), graphs, frames, semantic nets, and discriminant nets <ref> [3] </ref>. Common operations on objects, such as insert, car/cdr, etc., could be implemented directly as primitives of the SM. Operations dealing with the structure of an object (such as size-of, number-of-dimensions, etc.) can be done strictly through descriptor processing (DP). <p> If the written object is a value, then A would no longer be a virtual value. If the data written into a name is a program, then the object would become virtual. This mechanism is similar to the AI method of procedural attachment <ref> [3] </ref>. The typing mechanism allows for generic operations on the object. The operation increment, for example, could be simultaneously issued to different data objects, and each could execute it differently, according to their type.
Reference: [4] <author> Cole, </author> <title> B.C., "Smart Memories are Eating into the Jelly-Bean Market," </title> <publisher> Electronics, </publisher> <pages> pp. 65-69, </pages> <month> (Feb. 5, </month> <year> 1987). </year>
Reference-contexts: The model proposed in this paper implements the meta-knowledge by storing information about each object in a structure called a descriptor. There are logic-enhanced memories which are currently coming on the market <ref> [4] </ref>. However, as a rule, these memories are very specialized and are streamlined to a single function. These include FIFO queues, cachetag RAMs, and video RAMs.
Reference: [5] <author> Danforth, S., "LNL, </author> <title> A Lazy Narrowing Language with Conditional Rules and In vertible Primitives," </title> <type> MCC Technical Report - PP-132-86, </type> <month> (Dec. </month> <year> 1986). </year>
Reference-contexts: The SM can maintain multiple indices for different sets of processor (s) accessing simultaneously within the same data object. A descriptor tag can also be used for primitive support of futures [9], binding of logic variables, and automatic testing of constrained variables <ref> [5] </ref>. Debugging tools can use a field in the descriptor to aid in the process of debugging programs. Such items as breakpoints, usage counts, timestamping, etc., can be optionally part of the processing mechanisms. System functions can be greatly enhanced through the SM mechanism.
Reference: [6] <author> Dennis, J., </author> <title> "Data Flow Supercomputers," </title> <journal> Computer, </journal> <volume> Vol. 13, 11, </volume> <pages> pp. 48-56, </pages> <year> (1980). </year>
Reference-contexts: This overlapping of latency with processing is similar to state-multiplexing as it takes place in the HEP computer [17] and in circulating data flow machines <ref> [6] </ref>. Since more work is done on data resident on the SM chips, much less communication need take place over bus or other interconnect topologies between processors and memories. This communication bandwidth savings both increases speed and makes available more of the expensive communication bandwidth for other purposes.
Reference: [7] <author> Griswold, R.E, and J.F. Poage, I.P. Polonsky, </author> <title> The SNOBOL4 Programming Lan guage, </title> <publisher> Prentice Hall, Inc., </publisher> <address> New Jersey (1971). </address>
Reference-contexts: Other symbols include: match any character, match end-of-line, match anything except this character, etc. Other higher level search mechanisms could be implemented as primitive in the SM. A sampling of these comes from the Snobol programming language <ref> [7] </ref>. These include disjunctive pattern types (where the operand pattern is A or B or C ...), match everything up to a pattern, match everything between two delimiting patterns, etc. A final notion is that of SM memory recruitment. Any SM has a limited amount of memory.
Reference: [8] <author> Guzman, A., and M. Hermenegildo, </author> <title> "Constructs and Evaluation Strategies for Intelligent Speculative Parallelism - Armageddon Revisited," </title> <type> MCC Technical Report , 1987. </type>
Reference-contexts: For example, a condition on a data object could be when modified send value to accessor x, or if deleted delete array Z. Flexibility can be gained through the use of virtual data <ref> [8] </ref>. This refers to accessing of an object which does not really physically exist. A processing mechanism is called when the data is accessed, the value is computed and then returned. For example, an object A could be defined as the sum of objects B and C.
Reference: [9] <author> Halstead, R. </author> <title> "Implementation of Multilisp: Lisp on a Multiprocessor," </title> <booktitle> ACM Sym posium on Lisp and Functional Programming, </booktitle> <address> Austin, Texas, </address> <pages> pp. 9-17, </pages> <month> (Aug. </month> <year> 1984). </year>
Reference-contexts: The SM can maintain multiple indices for different sets of processor (s) accessing simultaneously within the same data object. A descriptor tag can also be used for primitive support of futures <ref> [9] </ref>, binding of logic variables, and automatic testing of constrained variables [5]. Debugging tools can use a field in the descriptor to aid in the process of debugging programs. Such items as breakpoints, usage counts, timestamping, etc., can be optionally part of the processing mechanisms.
Reference: [10] <author> Hillis, W.D., </author> <title> The Connection Machine, </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> (1985). </year>
Reference-contexts: Massively parallel SIMD processors have been considered by many as a type of smart memory. These include the MPP [2] and the connection machine <ref> [10] </ref>. These models are very large complete architectures, differing greatly from the architecturally small (chip-level) modularly grown mechanisms presented in this paper. Associative processors [19] support mechanisms similar to some presented in this paper, but again are large special purpose processing systems. <p> The most efficient distribution depends on the data and operations required, and can be set accordingly. Similar methods have been shown to be very efficient, as shown by applications on the connection machine <ref> [10] </ref>. For operations which require data to be gathered and possibly processed during gathering (i.e. retrieve the 10 largest values in a distributed object), a hierarchical topology of SM would allow logarithmic time for gathering. 5.4. <p> Other operations benefit from SPMD, while still necessitating access and manipulation of their values. Set operations (intersect, union, member, etc.) have been shown to fit this scheme by applications of the connection machine <ref> [10] </ref>. Replace-text (string1, string2) could do parallel replacement of all occurrences of one string in a text object with another, by having the text object symbolically interleaved amongst SM's.
Reference: [11] <author> Hoare, </author> <title> C.A.R., "Monitors: An Operating System Structuring Concept," </title> <journal> Communi cations of the ACM, </journal> <volume> 17(10), </volume> <pages> pp. 549-557, </pages> <month> (Oct. </month> <year> 1974). </year>
Reference-contexts: When using distributed and parallel systems, synchronization of data becomes one the most important and difficult issues. The SM encapsulates the data such that the SM 20 acts as a monitor <ref> [11] </ref>, handling implicitly synchronization of the access of any object using internal locks and control. Explicit synchronization can also be supported through a visible lock bit in the descriptor and indivisible operations for setting it.
Reference: [12] <author> Lundstrom, S. F., and R. L. Larsen, </author> <title> "Computer and Information Technology in the year 2000 - a Projection," </title> <journal> Computer, </journal> <volume> 18(9), </volume> <pages> pp. 68-79, </pages> <month> (Sept. </month> <year> 1985). </year>
Reference-contexts: With the onset of integrated circuit processing and memory elements, the two are now built from the same technology and it follows that their integration should be much easier. The increasing density of on-chip circuitry allows freedom to place increased functionality on a single chip. It has been predicted <ref> [12] </ref> that there will be a 1000 fold 4 increase in the density of circuitry on a chip in the next 15 years. <p> Even more critical is the disparity between on-chip processing and off-chip communication. In today's VLSI technology the high cost of off-chip communication (in terms of pin-out, speed, and power) is already becoming a bottleneck. The article <ref> [12] </ref> also predicted that while on-chip density would increase by a factor of 1000 in the next 15 years, bandwidth off and on a chip would increase by only a factor of 64. Thus, this disparity will continue to worsen at a dramatic rate.
Reference: [13] <author> Martinez, T. R., </author> <title> "Smart Memories: Potential Functionality and a Proposed Archi tecture," </title> <type> MCC Technical Report PP-178-87, </type> <month> (June </month> <year> 1987). </year> <month> 23 </month>
Reference-contexts: For example, by considering descriptors as abstract channels and processors, ADP can be used to accomplish complex communication events in multiprocessor systems, as proposed in <ref> [13] </ref>. 5.3. Single-Program Multiple-Data Method Another important mechanism is called single program multiple data (SPMD) processing. Program is used instead of the traditional instruction since there is no notion of lockstep execution of a broadcast opcode.
Reference: [14] <author> Martinez, T. R., </author> <title> "Smart Memory: The Memory Processor Model," </title> <booktitle> IFIP International Conference, </booktitle> <address> Rome, Italy, </address> <month> March </month> <year> 1990. </year>
Reference: [15] <author> Myers, G. J., </author> <title> Composite/Structured Design, </title> <address> New York: </address> <publisher> Van Norstrand Reinhold, </publisher> <year> (1978). </year>
Reference-contexts: These types of improvements have previously been sought through data-abstraction, objectoriented programming, structured design, and other paradigms. The potential advantages of these schemes have been well documented and are not reproduced here <ref> [15] </ref>. Some of the advantages gained specifically for data objects include storage and operation abstraction, synchronization mechanisms, security and protection, typing information, etc. These and other benefits are detailed in the SM functionality section. 3.2.
Reference: [16] <author> Rice, R., and W. R. Smith, </author> <title> "SYMBOL - A Major Departure from Classic Software Dominated von Neumann Computing Systems," </title> <booktitle> Spring Joint Computer Confer ence, </booktitle> <pages> pp. 575-616, </pages> <year> (1971). </year>
Reference-contexts: Only those chunks modified would have to be changed (modified, deleted, or added), and the other chunks would not have to be manipulated (with the exception of some link changes for chunks bordering new or deleted chunks). This method was used for storage of strings in the symbol computer <ref> [16] </ref>. 11 Data objects having fixed size are stored in hunks. Hunks are larger fixed sized seg ments of the value memory. A hunk corresponds to more normal page sizes and data objects reside within word boundaries.
Reference: [17] <author> Smith, B, </author> <title> "A pipelined, shared resource MIMD computer," </title> <booktitle> Proc. 1978 Intl. confer ence on Parallel Processing, </booktitle> <pages> pp. 6-8 </pages> . 
Reference-contexts: This overlapping of latency with processing is similar to state-multiplexing as it takes place in the HEP computer <ref> [17] </ref> and in circulating data flow machines [6]. Since more work is done on data resident on the SM chips, much less communication need take place over bus or other interconnect topologies between processors and memories.
Reference: [18] <author> Warren, R., </author> <title> MCC Parallel Processing Group, Private Conversation. </title>
Reference-contexts: In a parallel environment, another accessor might have no knowledge of the accomplished computation, and ask for the same value to be recomputed. The SM could then give it a fast response using the cached value. Another powerful mechanisms is that of mapped on-conditions tied to data structures <ref> [18] </ref>. These could be flagged in the descriptor with a corresponding pointer to the code to be executed. For example, a condition on a data object could be when modified send value to accessor x, or if deleted delete array Z.
Reference: [19] <author> Yau, S.S, and H.S. Fung, </author> <title> "Associative Processor Architecture - A Survey," </title> <journal> Com puting Surveys, </journal> <volume> Vol. 9, No. 1, </volume> <year> (1977). </year>
Reference-contexts: Massively parallel SIMD processors have been considered by many as a type of smart memory. These include the MPP [2] and the connection machine [10]. These models are very large complete architectures, differing greatly from the architecturally small (chip-level) modularly grown mechanisms presented in this paper. Associative processors <ref> [19] </ref> support mechanisms similar to some presented in this paper, but again are large special purpose processing systems. There are a number of possible system topologies into which SM modules could integrate. All memory could be stored in SM modules. <p> A recurring theme in the descriptor mechanism has been to allow regularity (fixed size and field semantics) and its concomitant speed potential, to be used in an irregular and dynamic environment (symbolic data in the value memory). The techniques are similar to those of associative processing <ref> [19] </ref>, but with new operations specifically tailored for memory usage. The basic notion is to make all or part of the descriptor memory a CAM. The descriptor memory would still have potential for normal access when needed.
References-found: 19

