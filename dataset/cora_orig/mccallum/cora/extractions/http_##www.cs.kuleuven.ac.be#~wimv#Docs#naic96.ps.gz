URL: http://www.cs.kuleuven.ac.be/~wimv/Docs/naic96.ps.gz
Refering-URL: http://www.cs.kuleuven.ac.be/~wimv/ICL/papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email:fWimV,Hendrik,LucDRg@cs.kuleuven.ac.be  
Title: Inductive Constraint Logic and the Mutagenesis Problem  
Author: Wim Van Laer Hendrik Blockeel Luc De Raedt 
Address: Celestijnenlaan 200A, B-3001 Heverlee, Belgium  
Affiliation: Department of Computer Science, Katholieke Universiteit Leuven  
Abstract: A novel approach to learning first order logic formulae from positive and negative examples is incorporated in a system named ICL (Inductive Constraint Logic). In ICL, examples are viewed as interpretations which are true or false for the target theory, whereas in present inductive logic programming systems, examples are true and false ground facts (or clauses). Furthermore, ICL uses a clausal representation, which corresponds to a conjunctive normal form where each conjunct forms a constraint on positive examples, whereas classical learning techniques have concentrated on concept representations in disjunctive normal form. We present some experiments with this new system on the mutagenesis problem. These experiments illustrate some of the differences with other systems, and indicate that our approach should work at least as well as the more classical approaches.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Ade, L. De Raedt, and M. Bruynooghe. </author> <title> Declarative Bias for Specific-to-General ILP Systems. </title> <journal> Machine Learning, </journal> <volume> 20(1/2):119 - 154, </volume> <year> 1995. </year>
Reference-contexts: From these models, one can automatically derive a refinement operator that only generates clauses that are allowed by the syntax. A full discussion of this declarative bias mechanism is outside the scope of this paper, but see <ref> [1, 18] </ref> for more details. 3 The Mutagenesis Problem A classification problem that has received some attention lately, is that of classifying nitroaromatic molecules into mutagenic and non-mutagenic ones. As in a lot of chemical problems, the data from which to learn are structured.
Reference: [2] <author> P. Clark and T. Niblett. </author> <title> The CN2 algorithm. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 261-284, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Present work on inductive concept-learning is usually classified as belonging to either the attribute value learning paradigm (see <ref> [14, 10, 2] </ref>, etc.) or the inductive logic programming paradigm [13, 12]. The differences between the two paradigms are due to the representation formalism employed.
Reference: [3] <author> L. De Raedt and W. Van Laer. </author> <title> Inductive constraint logic. </title> <booktitle> In Proceedings of the 5th Workshop on Algorithmic Learning Theory, Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: A possible explanation for this comes from the fact that in attribute value learning examples are true and false interpretations (i.e. models and non-models, or positive and negative examples) of a target theory, whereas in inductive logic programming, examples are true and false facts (or clauses). Recently, <ref> [3] </ref> have defined a notion of concept-learning in first order logic, in which examples are true and false interpretations of a target theory, and the target theory is a set of clauses. Each clause in the target theory can be seen as a constraint. <p> So whenever we say an example e is true (false) for a clause (or theory), we mean that M (B [ e) is true (false) for that clause (theory). Our setting is illustrated in Examples 1 and 2 (taken from <ref> [3] </ref>). Example 1 The well-known autolander problem (from the Irvine database) is described by a table (see figure 1) in attribute value representation (only a part is shown). This attribute value learning problem can directly be specified in terms of the framework. <p> This relationship between CNF and DNF will be illustrated in the mutagenesis experiments. 2.4 Practical aspects For a complete overview of the algorithm, we refer to <ref> [3] </ref>. There is a working implementation in ProLog by BIM. ICL uses a covering approach, and uses beam search as search strategy.
Reference: [4] <author> M. Genesereth and N. Nilsson. </author> <booktitle> Logical foundations of artificial intelligence. </booktitle> <publisher> Mor-gan Kaufmann, </publisher> <year> 1987. </year>
Reference-contexts: introduce the inductive constraint logic framework; in Section 3, we introduce the mutagenesis problem; in Section 4, we report experiments on the mutagenesis problem; and finally we conclude in Section 5. 2 Inductive constraint logic 2.1 Definitions and framework We assume familiarity with first order logic and model theory (see <ref> [9, 4] </ref> for an introduction). A first order alphabet is a set of predicate symbols, constant symbols and functor symbols. A clause is a formula of the form A 1 ; :::; A m B 1 ; :::; B n where the A i and B i are logical atoms.
Reference: [5] <author> R.D. King, S. Muggleton, R.A. Lewis, and M.J.E. Sternberg. </author> <title> Drug design by machine learning: the use of inductive logic programming to model the structure-activity relationships of trimethoprim analogues binding to dihydrofolate reduc-tase. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <volume> 89(23), </volume> <year> 1992. </year>
Reference-contexts: Furthermore, for many complex and structural induction problems the view that examples are interpretations is a very natural one, cf. for instance the bongard problems (see example 2), the drug activity problem <ref> [5] </ref>, the mutagenesis problem [16] and Michalski's classical eastbound westbound train problem [11], which was recently used as the basis for a machine learning competition. 2.3 CNF and DNF Class Descriptions Classical ILP systems learn a logic program that enables one to discriminate between those examples that belong to some class,
Reference: [6] <author> R.D. King, M.J.E. Sternberg, A. Srinivasan, and S.H . Muggleton. </author> <title> Knowledge discovery in a database of mutagenic chemicals. </title> <booktitle> In MLnet familiarisation Workshop: Statistics, Machine Learning and Kn owledge Discovery, </booktitle> <year> 1995. </year>
Reference-contexts: Therefore, the problem is particularly suited for ILP learners. Experiments where the ILP-system Progol was compared with statistical learners, neural networks and attribute-value learners <ref> [16, 17, 6, 8, 7] </ref> have confirmed that Progol indeed performs better than non-ILP systems in several respects (higher accuracy, less complex theories, more easily interpretable rules).
Reference: [7] <author> R.D. King, M.J.E. Sternberg, A. Srinivasan, and S.H. Muggleton. </author> <title> Relating chemical activity to structure: an examination of ilp successes. </title> <journal> New Generation Computing, </journal> <year> 1995. </year>
Reference-contexts: Therefore, the problem is particularly suited for ILP learners. Experiments where the ILP-system Progol was compared with statistical learners, neural networks and attribute-value learners <ref> [16, 17, 6, 8, 7] </ref> have confirmed that Progol indeed performs better than non-ILP systems in several respects (higher accuracy, less complex theories, more easily interpretable rules).
Reference: [8] <author> R.D. King, M.J.E. Sternberg, A. Srinivasan, and S.H. Muggleton. </author> <title> Representing molecular structure in structure activity relationships: The use of atoms and their bond connectivities to predict mutagenicity using inductive logic programming. </title> <journal> J. Am. Chem. Soc., </journal> <year> 1995. </year>
Reference-contexts: Therefore, the problem is particularly suited for ILP learners. Experiments where the ILP-system Progol was compared with statistical learners, neural networks and attribute-value learners <ref> [16, 17, 6, 8, 7] </ref> have confirmed that Progol indeed performs better than non-ILP systems in several respects (higher accuracy, less complex theories, more easily interpretable rules).
Reference: [9] <author> J.W. Lloyd. </author> <title> Foundations of logic programming. </title> <publisher> Springer-Verlag, </publisher> <address> 2nd edition, </address> <year> 1987. </year>
Reference-contexts: introduce the inductive constraint logic framework; in Section 3, we introduce the mutagenesis problem; in Section 4, we report experiments on the mutagenesis problem; and finally we conclude in Section 5. 2 Inductive constraint logic 2.1 Definitions and framework We assume familiarity with first order logic and model theory (see <ref> [9, 4] </ref> for an introduction). A first order alphabet is a set of predicate symbols, constant symbols and functor symbols. A clause is a formula of the form A 1 ; :::; A m B 1 ; :::; B n where the A i and B i are logical atoms.
Reference: [10] <author> R.S. Michalski. </author> <title> A theory and methodology of inductive learning. </title> <editor> In R.S Michal--ski, J.G. Carbonell, and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning: an artificial intelligence approach, </booktitle> <volume> volume 1. </volume> <publisher> Morgan Kaufmann, </publisher> <year> 1983. </year>
Reference-contexts: 1 Introduction Present work on inductive concept-learning is usually classified as belonging to either the attribute value learning paradigm (see <ref> [14, 10, 2] </ref>, etc.) or the inductive logic programming paradigm [13, 12]. The differences between the two paradigms are due to the representation formalism employed.
Reference: [11] <author> R.S. Michalski and R.E. Stepp. </author> <title> Learning from observation: conceptual clustering. </title> <editor> In R.S Michalski, J.G. Carbonell, and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning: an artificial intelligence approach, </booktitle> <volume> volume 1. </volume> <publisher> Tioga Publishing Company, </publisher> <year> 1983. </year>
Reference-contexts: Furthermore, for many complex and structural induction problems the view that examples are interpretations is a very natural one, cf. for instance the bongard problems (see example 2), the drug activity problem [5], the mutagenesis problem [16] and Michalski's classical eastbound westbound train problem <ref> [11] </ref>, which was recently used as the basis for a machine learning competition. 2.3 CNF and DNF Class Descriptions Classical ILP systems learn a logic program that enables one to discriminate between those examples that belong to some class, and those that do not.
Reference: [12] <editor> S. Muggleton, editor. </editor> <booktitle> Inductive Logic Programming. </booktitle> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Present work on inductive concept-learning is usually classified as belonging to either the attribute value learning paradigm (see [14, 10, 2], etc.) or the inductive logic programming paradigm <ref> [13, 12] </ref>. The differences between the two paradigms are due to the representation formalism employed. Although the inductive logic programming paradigm is generally believed to be more expressive, there is no straightforward and generally accepted way to represent an attribute value learning problem as an inductive logic programming task.
Reference: [13] <author> S. Muggleton and L. De Raedt. </author> <title> Inductive logic programming : Theory and methods. </title> <journal> Journal of Logic Programming, </journal> <volume> 19,20:629-679, </volume> <year> 1994. </year>
Reference-contexts: 1 Introduction Present work on inductive concept-learning is usually classified as belonging to either the attribute value learning paradigm (see [14, 10, 2], etc.) or the inductive logic programming paradigm <ref> [13, 12] </ref>. The differences between the two paradigms are due to the representation formalism employed. Although the inductive logic programming paradigm is generally believed to be more expressive, there is no straightforward and generally accepted way to represent an attribute value learning problem as an inductive logic programming task. <p> First, notice that ICL is meant to learn binary concepts from examples. As such it addresses the same task as propositional learners (but in a more expressive framework) and it does not learn logic programs from examples as Progol, FOIL and many other ILP systems do, cf. <ref> [13] </ref>. In these systems, examples are usually true and false ground facts of a target predicate, and the result is a logic program. Another difference with the majority of ILP systems, is that there is a clear view of how to use examples in heuristics.
Reference: [14] <author> J.R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: 1 Introduction Present work on inductive concept-learning is usually classified as belonging to either the attribute value learning paradigm (see <ref> [14, 10, 2] </ref>, etc.) or the inductive logic programming paradigm [13, 12]. The differences between the two paradigms are due to the representation formalism employed.
Reference: [15] <author> A. Srinivasan, S.H. Muggleton, and R.D. King. </author> <title> Comparing the use of background knowledge by inductiv e logic programming systems. </title> <editor> In L. De Raedt, editor, </editor> <booktitle> Proceedings of the 5th International Workshop on Inductive Logic Programming. </booktitle> <publisher> IOS Press, </publisher> <year> 1995. </year>
Reference-contexts: First of all, we have run it on the same data on which Progol and FOIL have been run (see <ref> [15] </ref>), to have a means of comparing ICL with these systems. In [15], four different background theories are used, and the results of FOIL and Progol compared. <p> First of all, we have run it on the same data on which Progol and FOIL have been run (see <ref> [15] </ref>), to have a means of comparing ICL with these systems. In [15], four different background theories are used, and the results of FOIL and Progol compared. In the experiment we discuss here, we use background B3 of the above paper, which consists of knowledge about atoms, bonds, log P and * LUMO . <p> Also, ICL does not show the strong bias towards numeric equations that is apparent in FOIL's theories (with this background knowledge, FOIL uses only equations on log P and * LUMO values in its theory, and no structural conditions; see <ref> [15] </ref>). The theories found by ICL are therefore closer to Progol's than to FOIL's.
Reference: [16] <author> A. Srinivasan, S.H. Muggleton, R.D. King, and M.J.E. Sternberg. Mutagenesis: </author> <title> Ilp experiments in a non-determinate biological domain. </title> <editor> In S. Wrobel, editor, </editor> <booktitle> Proceedings of the 4th International Workshop on Inductive Logic Programming, volume 237 of GMD-Studien, </booktitle> <pages> pages 217-232. </pages> <institution> Gesellschaft fur Mathematik und Datenverarbeitung MBH, </institution> <year> 1994. </year>
Reference-contexts: This corresponds to learning a conjunctive normal form instead of a disjunctive normal form. Furthermore, as examples are interpretations, most of the other attribute value learning techniques, such as noise handling heuristics, can be nicely upgraded towards the ICL framework. Some experiments on the mutagenesis problem <ref> [16] </ref> show that the current implementation of ICL already works quite well (i.e. as well as Progol, and better than FOIL), but also indicate a number of possible improvements to ICL. We illustrate the relationship between ICL's CNF solutions and the classical DNF solutions using the results from these experiments. <p> Furthermore, for many complex and structural induction problems the view that examples are interpretations is a very natural one, cf. for instance the bongard problems (see example 2), the drug activity problem [5], the mutagenesis problem <ref> [16] </ref> and Michalski's classical eastbound westbound train problem [11], which was recently used as the basis for a machine learning competition. 2.3 CNF and DNF Class Descriptions Classical ILP systems learn a logic program that enables one to discriminate between those examples that belong to some class, and those that do <p> Therefore, the problem is particularly suited for ILP learners. Experiments where the ILP-system Progol was compared with statistical learners, neural networks and attribute-value learners <ref> [16, 17, 6, 8, 7] </ref> have confirmed that Progol indeed performs better than non-ILP systems in several respects (higher accuracy, less complex theories, more easily interpretable rules).
Reference: [17] <author> A. Srinivasan, S.H. Muggleton, M.J.E. Sternberg, and R.D. King. </author> <title> Theories for mutagenicity: a study in first-order and feature-based induction. </title> <journal> Artificial Intelligence, </journal> <note> 1995. To appear. </note>
Reference-contexts: Therefore, the problem is particularly suited for ILP learners. Experiments where the ILP-system Progol was compared with statistical learners, neural networks and attribute-value learners <ref> [16, 17, 6, 8, 7] </ref> have confirmed that Progol indeed performs better than non-ILP systems in several respects (higher accuracy, less complex theories, more easily interpretable rules).
Reference: [18] <author> W. Van Laer, L. Dehaspe, and L. De Raedt. </author> <title> Applications of a logical discovery engine. </title> <booktitle> In Proceedings of the AAAI Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 263-274, </pages> <year> 1994. </year>
Reference-contexts: From these models, one can automatically derive a refinement operator that only generates clauses that are allowed by the syntax. A full discussion of this declarative bias mechanism is outside the scope of this paper, but see <ref> [1, 18] </ref> for more details. 3 The Mutagenesis Problem A classification problem that has received some attention lately, is that of classifying nitroaromatic molecules into mutagenic and non-mutagenic ones. As in a lot of chemical problems, the data from which to learn are structured.
References-found: 18

