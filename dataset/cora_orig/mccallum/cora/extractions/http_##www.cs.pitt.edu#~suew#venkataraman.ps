URL: http://www.cs.pitt.edu/~suew/venkataraman.ps
Refering-URL: http://www.cs.pitt.edu/~suew/dbwshop2.html
Root-URL: 
Title: Remote Load-Sensitive Caching for Multi-Server Database Systems  
Author: Shivakumar Venkataraman Jeffrey F. Naughton Miron Livny 
Address: San Jose, CA 95141  
Affiliation: IBM Santa Teresa Labs Computer Sciences Dept Computer Sciences Dept  Univ of Wisconsin-Madison Univ of Wisconsin-Madison  
Abstract: The recent dramatic improvements in the performance of commodity hardware has made clusters of workstations or PCs an attractive and economical platform upon which to build scalable database servers. These clusters have large aggregate memory capacities; however, since this global memory is distributed, good algorithms are necessary for memory management, or this large aggregate memory will go underutilized. The goal of this study is to develop and evaluate buffer management algorithms for database clusters. We propose a new buffer management algorithm, remote load-sensitive caching (RLS-caching), that uses novel techniques to combine data placement with a simple modification of standard client-server page replacement algorithms to approximate a global LRU page replacement policy. Through an implementation in the SHORE database system, we evaluate the performance of RLS-caching against other buffer management algorithms. Our study demonstrates that RLS-caching indeed effectively manages the distributed memory of a server cluster. 
Abstract-found: 1
Intro-found: 1
Reference: [BCF + 95] <author> N. Boden, etal. </author> <title> Myrinet A Gigabit-per-Second Local Area Network. </title> <journal> IEEE Micro, </journal> <volume> 15(1) </volume> <pages> 29-36, </pages> <month> Feb </month> <year> 1995. </year>
Reference-contexts: We call such a system a multi-server database system. One of the key factors that has accelerated this trend towards multi-server database system is the availability of networks with very high bandwidths, low latencies, and at low cost. For example, in a Myrinet <ref> [BCF + 95] </ref> fl This research is sponsored by the Advanced Research Project Agency, ARPA order number 018 (formerly 8230), monitored by the U.S.
Reference: [CDF + 94] <author> M. Carey, etal. </author> <title> Shoring Up Persistent Applications. </title> <booktitle> In ACM SIGMOD, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: The buffer management algorithms dynamically adapt to changing loads at various servers. We make use of data place ment to simplify the implementation of the buffer management algorithms. 3 Multi-Server Architecture The multi-server architecture we consider is loosely based on the SHORE <ref> [CDF + 94] </ref> database system architecture. The multi-server database system architecture consists of a group of communicating servers. <p> The servers perform two basic functions: 1) they manage persistent objects they store, and 2) they provide applications with access to persistent objects that are managed either locally, or by other remote servers. A full discussion of the SHORE architecture can be found in Carey et al. <ref> [CDF + 94] </ref>. In this section we list the features relevant to the description of the buffer management algorithms.
Reference: [DWAP94] <author> M. Dahlin, R. Wang, T. Anderson, and D. Patterson. </author> <title> Cooperative Caching : Using Remote Client Memory to Improve File System Performance. </title> <booktitle> In First OSDI Conf., </booktitle> <month> Nov </month> <year> 1994. </year>
Reference-contexts: In other operating systems literature, the Network of Workstations (NOW) project at U.C Berkeley, Dahlin et al. <ref> [DWAP94] </ref>, evaluate algorithms that make use of remote memory in a cluster of workstations connected by a fast interconnect. Their approach to identify and utilize memory is to store a page that is the last copy in memory at a randomly chosen server. <p> This technique is known as forwarding and has been studied by Franklin et al. [FCL92], and Dahlin et al. <ref> [DWAP94] </ref> and shown to be beneficial. The owner reads the page from disk only if the page is absent in global memory. If the owner reads the page from disk and sends it to the primary server, it retains a copy of the page in local memory.
Reference: [DY91] <author> A. Dan and P. Yu. </author> <title> Analytical Modelling of a Hierarchical Buffer for a Data Sharing Environment. </title> <booktitle> In ACM SIGMETRICS, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: Rahm [Rah92] presents the use of extended memory to improve the performance of transaction processing systems. In a data sharing environment, Dan and Yu <ref> [DY91] </ref> use an analytical model to study buffer management in a two level buffer hierarchy. Our work is different from these in that, we deal with a symmetric multi-server architecture. The buffer management algorithms dynamically adapt to changing loads at various servers.
Reference: [FCL92] <author> M. Franklin, M. Carey, and M. Livny. </author> <title> Global Memory Management in Client-Server DBMS Architectures. </title> <booktitle> In VLDB Conf., </booktitle> <address> Vancouver, Canada, </address> <month> Aug </month> <year> 1992. </year>
Reference-contexts: This study is done using file access traces for a collection of workstations connected by an ATM network. In a client-server database setting, Franklin et al. <ref> [FCL92] </ref> study ways to augment the memory of the server in a client-server database system by utilizing the memory and disk resources at client workstations. Rahm [Rah92] presents the use of extended memory to improve the performance of transaction processing systems. <p> This technique is known as forwarding and has been studied by Franklin et al. <ref> [FCL92] </ref>, and Dahlin et al. [DWAP94] and shown to be beneficial. The owner reads the page from disk only if the page is absent in global memory. <p> The owner reads the page from disk only if the page is absent in global memory. If the owner reads the page from disk and sends it to the primary server, it retains a copy of the page in local memory. This page is marked as hated <ref> [FCL92] </ref> (referred to as a hate hint) in the owner's memory and is placed on a Last-In First-Out (LIFO) list. When a page is needed for replacement, the hated pages are replaced first (except for the Reserve policy as it will be explained later). <p> We briefly describe these two algorithms. Following the description, we describe a new algorithm, RLS-caching, that uses declustering and approximate global state information to utilize global memory efficiently. 4.2.1 Client-Server:ClSv ClSv is the simple client-server buffer management algorithm discussed in <ref> [FCL92] </ref>. Briefly, each server manages its own buffer pool, the server replaces hated pages first followed by the rest of the pages in the buffer pool in LRU order.
Reference: [FMP + 95] <author> M. Feeley, etal. </author> <title> Implementing Global Memory Management in a Workstation Cluster. </title> <booktitle> In ACM SOSP, </booktitle> <month> Dec </month> <year> 1995. </year>
Reference-contexts: We use this as the starting point of this paper. Working from an operating systems point of view, Feeley et al. <ref> [FMP + 95] </ref> take a different approach to the global memory management problem | they begin from scratch, devising techniques for implementing a true global LRU policy, in which the global distributed memory is viewed logically as as a single centralized memory. This work was done contemporarily with our work.
Reference: [Rah92] <author> E. Rahm. </author> <title> Performance Evaluation of Extended Storage Architecture for Transaction Processing. </title> <booktitle> In ACM SIGMOD, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: In a client-server database setting, Franklin et al. [FCL92] study ways to augment the memory of the server in a client-server database system by utilizing the memory and disk resources at client workstations. Rahm <ref> [Rah92] </ref> presents the use of extended memory to improve the performance of transaction processing systems. In a data sharing environment, Dan and Yu [DY91] use an analytical model to study buffer management in a two level buffer hierarchy.
Reference: [Ven96] <author> S. Venkataraman. </author> <title> Global Memory Management for Multi-Server Database Systems. </title> <type> Technical report, </type> <institution> University of Wisconsin-Madison, </institution> <month> Sept </month> <year> 1996. </year>
Reference-contexts: If the page sent to the primary server has a copy elsewhere in memory, the primary server marks the page as a "duplicate". A low overhead algorithm to maintain "duplicate" information is described in Venkataraman <ref> [Ven96] </ref>. 4 Global Buffer Management We use the centralized memory model to guide us in designing the distributed buffer management algorithm. If the global memory is at a centralized location, one method for efficiently managing memory would be to use LRU replacement policy. <p> The Multi Programming Level (MPL) at each node was restricted to one. In <ref> [Ven96] </ref> we explore the effect of larger MPL and the case where clients share access to locality sets; we omit those tests here as they did not yield any additional insight. The workloads that we examined in this paper are primarily read only. <p> This experiment studies how the algorithms make uniform use of memory at all the servers. We also ran experiments to verify the results of our simulation study in [VLN95]. We do not present the results here due to the lack of space, the details can be found in <ref> [Ven96] </ref>. 5.3 Expt 1: Idle Memory In this experiment, we evaluate the performance of the three policies that decluster the data and study their ability to identify and utilize idle memory.
Reference: [VLN95] <author> S. Venkataraman, M. Livny, and J. Naughton. </author> <title> Impact of Data Placement on Memory Management for Multi-Server OODBMS. </title> <booktitle> In IEEE ICDE, </booktitle> <address> Taipei, Taiwan, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: Section 6 describes some useful techniques that we developed to efficiently implement the algorithms. In Section 7 we summarize the results of our implementation and performance study. 2 Related Work In Venkataraman et al. <ref> [VLN95] </ref> we demonstrated that data placement is an important factor in determining how global memory is utilized. This paper shows that declustering alone is not sufficient to fully utilize global memory, and that page replacement algorithms that are sensitive to loads at remote servers are necessary. <p> Before proceeding to the description of the buffer management algorithms we describe the data placement policies used to simplify the implementation of buffer management. Further detail on these policies is contained in <ref> [VLN95] </ref>. We describe them here briefly for completeness. 4.1 Data Placement The decision on how to place data on disk at the servers is static and must be carefully made as data re-organization on disk is very expensive. In [VLN95] we studied the benefits of the data placement strategies and concluded <p> Further detail on these policies is contained in <ref> [VLN95] </ref>. We describe them here briefly for completeness. 4.1 Data Placement The decision on how to place data on disk at the servers is static and must be carefully made as data re-organization on disk is very expensive. In [VLN95] we studied the benefits of the data placement strategies and concluded that declustering enables us to utilize memory effectively. <p> The first two, ClSv-Decl, and Reserve were described and studied in <ref> [VLN95] </ref>. We briefly describe these two algorithms. Following the description, we describe a new algorithm, RLS-caching, that uses declustering and approximate global state information to utilize global memory efficiently. 4.2.1 Client-Server:ClSv ClSv is the simple client-server buffer management algorithm discussed in [FCL92]. <p> The Reserve algorithm overcomes this problem by allowing each server to reserve a certain portion of its buffer pool for the data resident on the local disk. In <ref> [VLN95] </ref> we studied buffer management algorithms by reserving various percentages of a server's memory for local data. In order to provide an insight into the effect of reservation, we present results by fixing the percentage of buffer reserved for local pages at 60% in this paper. <p> In the second experiment we study clients accessing data from locality sets with both hot and cold pages. This experiment studies how the algorithms make uniform use of memory at all the servers. We also ran experiments to verify the results of our simulation study in <ref> [VLN95] </ref>. <p> This shows that the RLS-caching makes uniform use of memory at all the servers (at servers that are busy and at those servers that are idle), and is a good indicator that RLS-caching makes uniform use of global memory and therefore approximates global LRU. 5.5 Summary of Results In <ref> [VLN95] </ref> we clearly demonstrated the superiority of declustering over clustering. In experiments in this paper we reduced the idle memory available in the system by introducing small clients and showed that RLS-caching is superior to the other two policies.
References-found: 9

