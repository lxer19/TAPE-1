URL: http://suif.stanford.edu/papers/lim94.ps
Refering-URL: http://suif.stanford.edu/papers/papers.html
Root-URL: 
Email: Email: faimee,lamg@cs.stanford.edu  
Title: Communication-Free Parallelization via Affine Transformations  
Author: Amy W. Lim Monica S. Lam 
Address: Stanford, CA 94305  
Affiliation: Computer Systems Laboratory, Stanford University,  
Abstract: The paper describes a parallelization algorithm for programs consisting of arbitrary nestings of loops and sequences of loops. The code produced by our algorithm yields all the degrees of communication-free parallelism that can be obtained via loop fission, fusion, interchange, reversal, skewing, scaling, reindexing and statement reordering. The algorithm first assigns the iterations of instructions in the program to processors via affine processor mappings, then generates the correct code by ensuring that the code executed by each processor is a subsequence of the original sequential execution sequence.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J. R. Allen, D. Callahan, and K. Kennedy. </author> <title> Automatic decomposition of scientific programs for parallel execution. </title> <booktitle> In Proceedings, 14th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <address> Munich, Germany, </address> <month> January </month> <year> 1987. </year>
Reference-contexts: This would affect the utilization of hardware and cause poor performance. For example, all the three instructions in the following code have 2 degrees of parallelism. for i 11 = 1 to N do x <ref> [i 11 ; i 12 ; 1] </ref> = x [i 11 ; i 12 ; 1] + ; (S 1 ) for i 22 = 1 to N do for i 31 = 1 to N do x [1; i 31 ; i 32 ] = x [1; i 31 ; <p> This would affect the utilization of hardware and cause poor performance. For example, all the three instructions in the following code have 2 degrees of parallelism. for i 11 = 1 to N do x <ref> [i 11 ; i 12 ; 1] </ref> = x [i 11 ; i 12 ; 1] + ; (S 1 ) for i 22 = 1 to N do for i 31 = 1 to N do x [1; i 31 ; i 32 ] = x [1; i 31 ; i 32 ] + ; (S 3 ) But <p> degrees of parallelism. for i 11 = 1 to N do x [i 11 ; i 12 ; 1] = x [i 11 ; i 12 ; 1] + ; (S 1 ) for i 22 = 1 to N do for i 31 = 1 to N do x <ref> [1; i 31 ; i 32 ] </ref> = x [1; i 31 ; i 32 ] + ; (S 3 ) But to exploit all these parallelism using affine mappings, we need to map the iterations of each instruction to a "surface" of a 3-dimensional processor array. <p> N do x [i 11 ; i 12 ; 1] = x [i 11 ; i 12 ; 1] + ; (S 1 ) for i 22 = 1 to N do for i 31 = 1 to N do x <ref> [1; i 31 ; i 32 ] </ref> = x [1; i 31 ; i 32 ] + ; (S 3 ) But to exploit all these parallelism using affine mappings, we need to map the iterations of each instruction to a "surface" of a 3-dimensional processor array. <p> It starts with the outermost index p as follows: if (p = 1 N ) then x <ref> [1; N ] </ref> = x [1; N ] + y [0; N ]; if (2 N p N 1) then MERGE 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : i 2 = i 1 p for i 1 = max (1; p) to min (N; N + p 1) <p> It starts with the outermost index p as follows: if (p = 1 N ) then x <ref> [1; N ] </ref> = x [1; N ] + y [0; N ]; if (2 N p N 1) then MERGE 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : i 2 = i 1 p for i 1 = max (1; p) to min (N; N + p 1) y [i 1 ; i <p> p) to min (N; N + p 1) y [i 1 ; i 2 ] = x [i 1 ; i 2 1] fl y [i 1 ; i 2 ]; (S 2 ) &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; = if (p = N ) then y <ref> [N; 1] </ref> = x [N; 0] fl y [N; 1]; The range of p is partitioned into intervals so that the same set of statements is executed by all the possible values of p within an interval. We recursively reapply the algorithm to the indices at the inner levels. <p> y [i 1 ; i 2 ] = x [i 1 ; i 2 1] fl y [i 1 ; i 2 ]; (S 2 ) &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; = if (p = N ) then y <ref> [N; 1] </ref> = x [N; 0] fl y [N; 1]; The range of p is partitioned into intervals so that the same set of statements is executed by all the possible values of p within an interval. We recursively reapply the algorithm to the indices at the inner levels. <p> We recursively reapply the algorithm to the indices at the inner levels. The final code for our example is: if (p = 1 N ) then x <ref> [1; N ] </ref> = x [1; N ] + y [0; N ]; if (2 N p N 1) then if (1 p N 1) then y [p; 1] = x [p; 0] fl y [p; 1]; x [i 1 ; i 1 p] = x [i 1 ; i 1 <p> We recursively reapply the algorithm to the indices at the inner levels. The final code for our example is: if (p = 1 N ) then x <ref> [1; N ] </ref> = x [1; N ] + y [0; N ]; if (2 N p N 1) then if (1 p N 1) then y [p; 1] = x [p; 0] fl y [p; 1]; x [i 1 ; i 1 p] = x [i 1 ; i 1 p] + y [i 1 <p> The final code for our example is: if (p = 1 N ) then x [1; N ] = x [1; N ] + y [0; N ]; if (2 N p N 1) then if (1 p N 1) then y <ref> [p; 1] </ref> = x [p; 0] fl y [p; 1]; x [i 1 ; i 1 p] = x [i 1 ; i 1 p] + y [i 1 1; i 1 p]; if (2 N p 0) then x [N + p; N ] = x [N + p; N <p> The final code for our example is: if (p = 1 N ) then x [1; N ] = x [1; N ] + y [0; N ]; if (2 N p N 1) then if (1 p N 1) then y <ref> [p; 1] </ref> = x [p; 0] fl y [p; 1]; x [i 1 ; i 1 p] = x [i 1 ; i 1 p] + y [i 1 1; i 1 p]; if (2 N p 0) then x [N + p; N ] = x [N + p; N ] + y [N + p 1; N <p> = x [i 1 ; i 1 p] + y [i 1 1; i 1 p]; if (2 N p 0) then x [N + p; N ] = x [N + p; N ] + y [N + p 1; N ]; if (p = N ) then y <ref> [N; 1] </ref> = x [N; 0] fl y [N; 1]; 4 Related Work There has been a lot of work on code optimizations for parallel machines. In the following, we restrict our discussion to compiler techniques that are also based on linear and affine transforms. <p> + y [i 1 1; i 1 p]; if (2 N p 0) then x [N + p; N ] = x [N + p; N ] + y [N + p 1; N ]; if (p = N ) then y <ref> [N; 1] </ref> = x [N; 0] fl y [N; 1]; 4 Related Work There has been a lot of work on code optimizations for parallel machines. In the following, we restrict our discussion to compiler techniques that are also based on linear and affine transforms.
Reference: 2. <author> J. R. Allen and K. Kennedy. </author> <title> Automatic translation of Fortran programs to vector form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> October </month> <year> 1987. </year>
Reference: 3. <author> S. P. Amarasinghe and M. S. Lam. </author> <title> Communication optimization and code generation for distributed memory machines. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: We generate the loop bounds of the instances to be executed by a particular processor ~p from B 0 by projecting the loop indices away in the reverse order of the original loop indices. 2. Merge all the subsequences for each instruction <ref> [3] </ref>. Let ~ i [1 : n] denote the first n elements of the iteration vector ~ i. Suppose instructions S j and S k share n common loops.
Reference: 4. <author> C. Ancourt and F. Irigoin. </author> <title> Scanning polyhedra with DO loops. </title> <booktitle> In Proceedings of the Third ACM/SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 39-50, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Instead, we use the following algorithm which can eliminate all the dynamic tests from the innermost loops: 1. Find tight loop bounds for each instruction in the program. This step is based on Ancourt and Irigoin's polyhedron-scanning code generation technique <ref> [4] </ref>. Let the loop index variables surrounding an instruction be i 1 ; : : : ; i n , and let B be the set of linear inequalities describing the loop bounds of instruction S j .
Reference: 5. <author> J. M. Anderson and M. S. Lam. </author> <title> Global optimizations for parallelism and locality on scalable parallel machines. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Thus, in a sense, unimodular transforms map the original loop indices to a processor-time domain. Some of the ideas in this paper are derived from Anderson and Lam's algorithm that minimizes communication across multiple loops <ref> [5] </ref>. In particular, we use the same approach of first finding the nullspace in processor mappings before determining the rest of the mappings. There are several major differences between the two algorithms. Anderson and Lam ignore neighborhood (or displacement) communication, whereas we do not.
Reference: 6. <author> E. Ayguade and J. Torres. </author> <title> Partitioning the statement per iteration space using non-singular matrices. </title> <booktitle> In Proceedings of the 1993 ACM International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1993. </year>
Reference: 7. <author> U. Banerjee. </author> <title> Speedup of Ordinary Programs. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> October </month> <year> 1979. </year>
Reference: 8. <author> U. Banerjee. </author> <title> Unimodular transformations of double loops. </title> <booktitle> In Proceedings of the Third Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 192-219, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: A recent focus in parallelizing compiler research has been to devise algorithms that can combine these transformations to achieve specific goals. Loop interchanges, reversals and skewing and combinations thereof have been modeled as unimodular transformations <ref> [8, 20, 21] </ref>. Algorithms that use unimodular transformations and tiling to improve parallelism and locality on loops whose dependences are represented as distance and direction vectors have been developed. <p> Unimodular loop transforms map a sequential loop nest to another legal sequential loop nest. Parallelizers based on unimodular loop transforms attempt to transform the code such that the outermost possible loops are parallelizable <ref> [8, 20, 21] </ref>. If the outermost loop is parallelizable, the algorithm has found a communication-free partition for the loop nest. The code in this form can easily be translated into the desired SPMD code because each processor simply executes the code nested within the parallel loop.
Reference: 9. <author> U. Banerjee. </author> <title> Loop Transformations for Restructuring Compilers. </title> <publisher> Kluwer Academic, </publisher> <year> 1993. </year>
Reference: 10. <author> S. Carr and K. Kennedy. </author> <title> Compiler blockability of numerical algorithms. </title> <booktitle> In Proceedings Supercomputing '92, </booktitle> <pages> pages 114-125, </pages> <month> November </month> <year> 1992. </year>
Reference: 11. <author> P. Feautrier. </author> <title> Some efficient solution to the affine scheduling problem, part II, multidimensional time. </title> <journal> Int. J. of Parallel Programming, </journal> <volume> 21(6), </volume> <month> December </month> <year> 1992. </year>
Reference-contexts: The virtual processor space is mapped onto hardware directly; dependences in the program are mapped onto communication on the typically neighboring connections in a systolic array. More recently, Feautrier uses an affine model to schedule instructions for maximum parallelism <ref> [11, 12] </ref>. His approach is to schedule the instructions to maximize parallelism first, then minimize communication [13]. In the scheduling step, he finds for each instruction an affine mapping to the time domain.
Reference: 12. <author> P. Feautrier. </author> <title> Some efficient solutions to the affine scheduling problem, part I, one dimensional time. </title> <journal> Int. J. of Parallel Programming, </journal> <volume> 21(5) </volume> <pages> 313-348, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: The virtual processor space is mapped onto hardware directly; dependences in the program are mapped onto communication on the typically neighboring connections in a systolic array. More recently, Feautrier uses an affine model to schedule instructions for maximum parallelism <ref> [11, 12] </ref>. His approach is to schedule the instructions to maximize parallelism first, then minimize communication [13]. In the scheduling step, he finds for each instruction an affine mapping to the time domain.
Reference: 13. <author> P. Feautrier. </author> <title> Towards automatic distribution. </title> <type> Technical Report 92.95, </type> <institution> Institut Blaise Pascal/Laboratoire MASI, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: More recently, Feautrier uses an affine model to schedule instructions for maximum parallelism [11, 12]. His approach is to schedule the instructions to maximize parallelism first, then minimize communication <ref> [13] </ref>. In the scheduling step, he finds for each instruction an affine mapping to the time domain. Feautrier refers to O (n q ) computations that have O (n q1 ) degrees of parallelism as computations that execute in linear time.
Reference: 14. <author> C. H. Huang and P. Sadayappan. </author> <title> Communication-free hyperplane partitioning of nested loops. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 19 </volume> <pages> 90-102, </pages> <year> 1993. </year>
Reference-contexts: Correctness is guaranteed by making sure that the instructions executed on each processor are a subsequence of the original sequential execution. The SPMD code for each processor inherits the original hierarchical loop structure of the original program. Huang and Sadayappan also studied the problem of finding a communication-free partitioning <ref> [14] </ref>. Instead of finding the maximum degree of parallelism in a program, their algorithm only finds one dimension of parallelism. Their program domain is restricted to a sequence of perfectly nested loops, and the instructions within a loop body are scheduled together as indivisible units.
Reference: 15. <author> W. Kelly and W. Pugh. </author> <title> A framework for unifying reordering transformations. </title> <type> Technical Report CS-TR-2995.1, </type> <institution> University of Maryland, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: This paper shows an algorithm that can combine unimodular transformations with loop fusion, fission, scaling and reindexing to optimize programs with an arbitrary nesting of loops and sequences of loops. While it has been shown that these transformations can be modeled as affine transforms <ref> [15] </ref>, researchers are still trying to find algorithms that can exploit this model effectively. In this paper, we show how we can use this affine framework to solve an important problem in parallelization. The following is a synopsis of the key ideas presented in this paper.
Reference: 16. <author> K. Kennedy and K. S. McKinley. </author> <title> Optimizing for parallelism and data locality. </title> <booktitle> In Proceedings of the 1992 ACM International Conference on Supercomputing, </booktitle> <pages> pages 323-334, </pages> <month> July </month> <year> 1992. </year>
Reference: 17. <author> K. Kennedy and K. S. McKinley. </author> <title> Maximizing loop parallelism and improving data locality via loop fusion and distribution. </title> <booktitle> In Proceedings of the Sixth Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1993. </year>
Reference: 18. <author> V. Sarkar and R. Thekkath. </author> <title> A general framework for iteration-reordering loop transformations. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 175-187, </pages> <month> June </month> <year> 1992. </year>
Reference: 19. <author> J. Torres, E. Ayguade, J. Labarta, and M. Valero. </author> <title> Align and distribute-based linear loop transformations. </title> <booktitle> In Proceedings of the Sixth Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1993. </year>
Reference: 20. <author> M. E. Wolf. </author> <title> Improving Locality and Parallelism in Nested Loops. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> August </month> <year> 1992. </year> <note> Published as CSL-TR-92-538. </note>
Reference-contexts: A recent focus in parallelizing compiler research has been to devise algorithms that can combine these transformations to achieve specific goals. Loop interchanges, reversals and skewing and combinations thereof have been modeled as unimodular transformations <ref> [8, 20, 21] </ref>. Algorithms that use unimodular transformations and tiling to improve parallelism and locality on loops whose dependences are represented as distance and direction vectors have been developed. <p> Unimodular loop transforms map a sequential loop nest to another legal sequential loop nest. Parallelizers based on unimodular loop transforms attempt to transform the code such that the outermost possible loops are parallelizable <ref> [8, 20, 21] </ref>. If the outermost loop is parallelizable, the algorithm has found a communication-free partition for the loop nest. The code in this form can easily be translated into the desired SPMD code because each processor simply executes the code nested within the parallel loop.
Reference: 21. <author> M. E. Wolf and M. S. Lam. </author> <title> A loop transformation theory and an algorithm to maximize parallelism. </title> <journal> Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 452-470, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: A recent focus in parallelizing compiler research has been to devise algorithms that can combine these transformations to achieve specific goals. Loop interchanges, reversals and skewing and combinations thereof have been modeled as unimodular transformations <ref> [8, 20, 21] </ref>. Algorithms that use unimodular transformations and tiling to improve parallelism and locality on loops whose dependences are represented as distance and direction vectors have been developed. <p> Unimodular loop transforms map a sequential loop nest to another legal sequential loop nest. Parallelizers based on unimodular loop transforms attempt to transform the code such that the outermost possible loops are parallelizable <ref> [8, 20, 21] </ref>. If the outermost loop is parallelizable, the algorithm has found a communication-free partition for the loop nest. The code in this form can easily be translated into the desired SPMD code because each processor simply executes the code nested within the parallel loop.
Reference: 22. <author> M. J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1989. </year>
Reference: 23. <author> M. J. Wolfe. </author> <title> Massive parallelism through program restructuring. </title> <booktitle> In Symposium on Frontiers on Massively Parallel Computation, </booktitle> <pages> pages 407-415, </pages> <month> October </month> <year> 1990. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
References-found: 23

