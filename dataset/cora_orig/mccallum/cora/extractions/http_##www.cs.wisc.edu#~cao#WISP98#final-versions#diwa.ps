URL: http://www.cs.wisc.edu/~cao/WISP98/final-versions/diwa.ps
Refering-URL: http://www.cs.wisc.edu/~cao/WISP98-program.html
Root-URL: http://www.cs.wisc.edu
Email: -diwa,jar-@sce.carleton.ca  
Title: Predicting the QoS of an Electronic Commerce Server: Those Mean Percentiles  
Author: Diwakar Krishnamurthy and Jerome Rolia 
Address: Ottawa, Canada, K1S 5B6  
Affiliation: Systems and Computer Engineering, Carleton University,  
Abstract: This paper presents a case study on Quality of Service (QoS) measures for an electronic commerce server. Electronic commerce systems typically rely on a combination of an HTTP server and a database server that may or may not be integrated with other enterprise information resources. Some interactions with these systems cause requests for static HTML pages. Others cause significant amounts of database processing. Response time percentiles are well-accepted measures of QoS for such requests. In this paper we measure the behavior of an electronic commerce server under several controlled loads and study response time measures for several workload abstractions. Response time measures are captured for individual URLs, groups of functionally related URLs, and for sequences of URLs. We consider the implications of each approach from both qualitative and quantitative perspectives. Last, we use an analytic model combined with empirical knowledge of server behavior to show that mean response time can be a good predictor for the 90-percentile of response times. The approach presumes a call admission system is in place that limits the number of customers accepted for service. The approach could be used to support real-time call admission algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Microsoft Site Server - http://www.microsoft.com/siteserver </institution>
Reference: [2] <institution> Oracle Internet Commerce Server http://www.oracle.com/ </institution>
Reference: [3] <institution> IBM Net.Commerce http://www.internet.ibm.com/commercepoint/net.comm erce </institution>
Reference: [4] <institution> A Synthetic Workload Model for Internet Mosaic Traffic, Martin Arlitt, Carey Williamson, University of Saskatchewan. In ACM SIGMETRICS, </institution> <address> Philadelphia, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: These environmental features should be taken into account when considering QoS requirements for Internet servers. Others have considered benchmarking for Internet server systems. We present a few examples from the literature. Arlitt and Williamson <ref> [4] </ref> create a traffic model for workload submitted by World Wide Web (WWW) clients. They achieve this by instrumenting the Mosaic browser and observing the client traffic traces. This provides a simulation model of the client side workload for WWW servers.
Reference: [5] <institution> Webperf - http://playground.sun.com/pub/prasadw/webperf/ </institution>
Reference-contexts: For electronic commerce systems, we must focus on the server system itself. It is the only aspect of the system within our administrative domain of control. Several efforts are underway to provide industry standard benchmarks for Web Servers. Webperf <ref> [5] </ref> from Standard Performance Evaluation Corporation (SPEC) and Webstone [6] are benchmarks (and benchmarking tools) for web servers. They each calculate throughput in HTTP operations per second and client response times per HTTP operation.
Reference: [6] <author> Webstone: </author> <title> Performance Benchmarking http://www.sgi.com/products/webforce/ </title>
Reference-contexts: For electronic commerce systems, we must focus on the server system itself. It is the only aspect of the system within our administrative domain of control. Several efforts are underway to provide industry standard benchmarks for Web Servers. Webperf [5] from Standard Performance Evaluation Corporation (SPEC) and Webstone <ref> [6] </ref> are benchmarks (and benchmarking tools) for web servers. They each calculate throughput in HTTP operations per second and client response times per HTTP operation. The workload characterization is based on request rate distribution, content size distribution, request type distribution and other parameters. Webstone [6] is freely downloadable from the Internet. <p> Performance Evaluation Corporation (SPEC) and Webstone <ref> [6] </ref> are benchmarks (and benchmarking tools) for web servers. They each calculate throughput in HTTP operations per second and client response times per HTTP operation. The workload characterization is based on request rate distribution, content size distribution, request type distribution and other parameters. Webstone [6] is freely downloadable from the Internet. With Webstone, it is possible to analyze your own server logs of Universal Resource Locators (URL) hits to create an accurate synthetic benchmark for your particular system. However, electronic commerce servers maintain state information about customers using the servers.
Reference: [7] <institution> SiteWalker A Tool Supporting Performance Characterization and Capacity Planning for Electronic Commerce Systems, </institution> <address> D. </address> <note> Krishnamurthy and J. Rolia. Submitted for publication in the GI/IFIP Conference on Trends in Electronic Commerce, </note> <institution> Hamburg, Germany, </institution> <month> June </month> <year> 1998. </year>
Reference-contexts: However, electronic commerce servers maintain state information about customers using the servers. More sophisticated workload generation techniques are needed to cause valid user behavior. Dilley et al <ref> [7] </ref> describe tools and techniques for characterizing the performance behavior of a large scale Web server. Three classes of work were used to characterize the system's behavior, html, cgi, and image. Each class used system and Internet resources differently and had very different response time measures.
Reference: [8] <institution> Measurement Tools and Modeling Techniques for Evaluating Web Server Performance, John Dilley, Rich Friedrich, Tai Jin, Hewlett-Packard Laboratories, Palo Alto, CA, USA. In HP Laboratories Technical Report HPL-96-161. </institution>
Reference-contexts: Client response time measurements for each URL hit are collected by the applet. All response time measures are stored and used for subsequent analysis. The workload generation is driven by an automatically generated graph data structure that describes the URL web of the shopping mall <ref> [8] </ref>. We refer to this graph as a site map and note that it changes as products and services are added and removed from the site. For this study the emulated users have statistically identical behavior.
Reference: [9] <author> The Method of Layers, J. Rolia and K. </author> <title> Sevcik. </title> <journal> In IEEE Transactions on Software Engineering, </journal> <volume> Vol. 21, No. 8, </volume> <pages> pp. 689 700, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: We choose to use Layered Queuing Models (LQM) and the Method of Layers (MOL) <ref> [9] </ref> for modeling the system. LQMs are QNMs [10] extended to include contention for software resources such as pools of server processes as well as contention for devices including CPUs and Disks. Process can offer many services and can request service from other processes in a layered manner.
Reference: [10] <author> Quantitative System Performance: </author> <title> Computer System Analysis Using Queuing Network Models. </title> <editor> E.D. Lazowska, J. Zahorjan, G.S. Graham, K.C. Sevcik, </editor> <publisher> Prentice-Hall, </publisher> <year> 1984. </year>
Reference-contexts: We choose to use Layered Queuing Models (LQM) and the Method of Layers (MOL) [9] for modeling the system. LQMs are QNMs <ref> [10] </ref> extended to include contention for software resources such as pools of server processes as well as contention for devices including CPUs and Disks. Process can offer many services and can request service from other processes in a layered manner.
Reference: [11] <institution> Predicting the Performance of Software Systems, </institution> <note> J. Rolia. In CSRI Technical Report 260, </note> <institution> University of Toronto, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: The choice of services is determined by the choice of workload classes Mean Value Analysis (MVA) residence time expressions have been developed that take into account many kinds of software interactions <ref> [11] </ref> and have been integrated within the MOL. For the LQM developed within this paper, expressions are used that capture the performance impact of an HTTPd server pool with a bounded size [11]. <p> Value Analysis (MVA) residence time expressions have been developed that take into account many kinds of software interactions <ref> [11] </ref> and have been integrated within the MOL. For the LQM developed within this paper, expressions are used that capture the performance impact of an HTTPd server pool with a bounded size [11]. Also the performance impact of work caused by a customer request but that does not take place until after the customer leaves the server is captured [11]. These are referred to as multi-server and post-rendezvous service behaviors, respectively. We now describe the construction, calibration and validation of the model. <p> the LQM developed within this paper, expressions are used that capture the performance impact of an HTTPd server pool with a bounded size <ref> [11] </ref>. Also the performance impact of work caused by a customer request but that does not take place until after the customer leaves the server is captured [11]. These are referred to as multi-server and post-rendezvous service behaviors, respectively. We now describe the construction, calibration and validation of the model. Our choice of processes and services on the server node was problematic and largely determined by the monitoring support offered by Windows NT.
Reference: [12] <institution> TPC Electronic Commerce Web Benchmark-http://www.tpc.org/miscellaneous/TPC_W.folder/TPC W12.15.97/INDEX.HTM. </institution>
Reference-contexts: The use of the site map causes a random sequence of fixed database queries and static page requests between CGI requests. In future studies the workload will be chosen to better match real site behavior and/or the TCP/W <ref> [12] </ref> benchmark once it is released. The experimental design varies the number of clients using the system from 1 to 5 and the mean times between successive requests. The time between client URL hits is defined as the client think time.
References-found: 12

