URL: http://www.cs.ucl.ac.uk/staff/jon/mmn/cam/a1.ps
Refering-URL: http://www.cs.ucl.ac.uk/staff/jon/mmn/cam/documents.html
Root-URL: http://www.cs.ucl.ac.uk
Title: Assumptions Made for the BT URI Project Working Document 1 Management Summary re-assessed either continuously
Author: Paul Wernick 
Note: This document, and the assumptions presented in it, are to be regarded as provisional conclusions only. As the project advances and knowledge of the environment within which implementations of the architecture will have to operate and the constraints placed on such implementations, these assumptions will need to be  September 8, 1995 1 pdw22/Authman/assumptions.tex  
Date: September 8, 1995  
Address: Cambridge  
Affiliation: Computer Laboratory University of  
Abstract: This document describes in detail the assumptions which are to be made in defining the security architecture for the URI project. This work is important in that it helps to set the limits to the architecture's scope, gives a basis for informed critiques of the architecture, and provides the designers of implementations based on it with a series of rationales for making design decisions in the light of knowledge of the architecture's objectives. It will also provide a basis for modifying the architecture in a controlled manner should any of these assumptions become invalid over time due to experience or changes in the environment within which designs based on it are operating. Our assumptions have diverged in many ways from those in in the TINA documents [Hub93] and [HRG94]. The reasons for this can be broadly summarised as being due to our desire for independence for the architecture of all design and implementation technical matters, our taking a wider view in identifying the stakeholders in the architecture both with regard to their identities and their degree of sophistication in security-related matters, our belief that access to the services protected by the architecture must be as easy as possible to make it more likely that they will be used, and our assumption that not all of the entities involved in the network will trust each other. We hope that the completed architecture will have a long lifetime compared with specific aspects of the environment within which it is to be used, and therefore believe that it must remain independent of any specific technical, security or commercial assumptions or interests. This fundamental concern underlies many of the assumptions described below. 
Abstract-found: 1
Intro-found: 1
Reference: [And94a] <author> R.J. Anderson. </author> <title> Liability and computer security: Nine principles. </title> <editor> In D. Gollmann, editor, </editor> <booktitle> Computer Security - ESORICS '94, number 875 in Lecture Notes in Computer Science, </booktitle> <pages> pages 231-245. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: This assumption is necessary for several reasons: it may be necessary to produce documentation in court to support criminal prosecutions, as is becoming the case in bank ATM system-related fraud accusations (see <ref> [And94a] </ref>), it is possible (although this is a speculative comment) that commercial or legal/quasi-legal pressures other than those associated with litigation will require the publication of some security-related information, such as the basis of security policies related to privacy; it may not be possible to assess at this stage the effect
Reference: [And94b] <author> R.J. Anderson. </author> <title> Why cryptosystems fail. </title> <journal> Comm. ACM, </journal> <volume> 37(11) </volume> <pages> 32-40, </pages> <year> 1994. </year>
Reference: [CvH91] <author> D. Chaum and E. van Heyst. </author> <title> Group signatures. </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> 547 </volume> <pages> 257-265, </pages> <year> 1991. </year>
Reference-contexts: Examples of the assumptions which are explicitly excluded as being implementation-related include the un-feasibility of users computing RSA roots or discrete logs of large numbers (see <ref> [CvH91, p.258] </ref>), and the unforgeability of digital signatures (as assumed in [PW92]).
Reference: [Den79] <author> D.E. Denning. </author> <title> Secure personal computing in an insecure network. </title> <journal> Comm. ACM, </journal> <volume> 22(8) </volume> <pages> 476-482, </pages> <year> 1979. </year>
Reference-contexts: Necessary and/or useful assumptions about the security environment are listed be low. * A service user, service provider or network carrier should not have to rely on any other element of the architecture for the security of his or her data, unless that element is specifically designated as `trusted' (cf. <ref> [Den79, p.477] </ref>). September 8, 1995 9 pdw22/Authman/assumptions.tex * The security requirements of network administrators are not sufficiently dif-ferent from those of service provides and users to require the provision of a completely different security environment.
Reference: [Her94] <author> A. Herbert. </author> <title> An ANSA overview. </title> <journal> IEEE Network, </journal> <volume> 8(1) </volume> <pages> 18-23, </pages> <year> 1994. </year>
Reference: [HRG94] <author> S.D. Hubbard and M.A.Z. Rejman-Greene. TINA: </author> <title> Security guidelines for TINA. </title> <type> Technical report, </type> <institution> British Telecom, </institution> <month> Mar </month> <year> 1994. </year> <note> Version 1.0. </note>
Reference-contexts: Our assumptions have diverged in many ways from those in in the TINA documents [Hub93] and <ref> [HRG94] </ref>. <p> from the following sources: * our own knowledge, experience and introspection, * work by other researchers at the Computer Laboratory, 1 * consideration of literature concerning authentication in networks, such as [NS78], and * a critical examination of two documents from British Telecom ("BT") related to this project, [Hub93] and <ref> [HRG94] </ref>. In some cases, the assumptions presented here have been contrasted with assumptions in published work in order to illuminate the differences between them. 2.3 Caveats There are some remaining concerns regarding the contents of this document. <p> services protected by systems developed under he architecture will be found, and that providing assurance to service users that they will get through to the requested service or not be charged will form part of the architecture This assumption may lead us towards a secure, guaranteed-unique entity naming system see <ref> [HRG94, p.14] </ref>, where the need for a secure naming scheme is set down as a sub-requirement of the major objective of identifying, authen ticating and authorising all entities. * `Users must be responsible for their own security.' ([Den79, p.477]) We assume this, at least to some extent. <p> This may be especially true for cases in which delegation to administrators belonging to outside carriers occurs. * It is assumed that the architecture may be required to support different security policies in different political, economic or geographic sub-domains of the network. <ref> [HRG94, p.20] </ref> notes that security policies might differ in different domains which require to communicate. * Different data elements maintained by the network carrier may require different levels of, and different mechanisms to ensure, security (cf. [Hub93, p.10]). * Network carriers may at times require to delegate any aspect of the <p> September 8, 1995 24 pdw22/Authman/assumptions.tex 16 TINA: British Telecom Documents 16.1 Summary of Differences BT have produced two documents relevant to and/or extending the assumptions given above ([Hub93] and <ref> [HRG94] </ref>). The general attitude underlying BT's work can be related to the comment that [Hub93] `. . . concentrates in particular on the stakeholders with the most to lose the service and network providers' ([Hub93, p.4]). <p> The rationale for having a security architecture is strongly biased towards protecting the revenues of those who charge for services; see <ref> [HRG94, p.3] </ref>. Additionally, their methodology is based on first determining the requirements of a security system; neither document makes use of any possible prior investigation of the underlying assumptions such as that presented here. <p> During the work presented here, we have noted differences between the assumptions which we have made and those explicit and implicit in the TINA documents [Hub93] and <ref> [HRG94] </ref>. <p> The BT requirement that two-way authentication might require different levels of authentication at each end should also be reflected in this document. * <ref> [HRG94, p.19] </ref> demands that privileges be dependent on time of day, day of week and public holidays. The need for differences for these values in different countries is also alluded to ([HRG94, p.20]). <p> September 8, 1995 26 pdw22/Authman/assumptions.tex service is not new. However, there will be a need for a trusted time service to support these restrictions on use. * <ref> [HRG94, p.25] </ref> requires evidence of delivery as well as despatch to limit the ability to repudiate transactions. This assumes either that the mechanisms to support this will be available from the underlying network or that this functionality can be built on top of the exiting network. <p> This may for instance colour arguments as to who is allowed to access private data of users and other third parties are the security services `authorised' as representatives of `wider society' ? It is interesting to note that <ref> [HRG94, p.13] </ref> specifically refers to `allowing any TINA stakeholders to make use of a TINA-compliant network', implying that the only stakeholders are those who make use of the facilities of such a network. [Hub93, p.13] also raises this issue in stating that `The general principle that no unauthorised person should be <p> conflicting legal requirements for monitoring and privacy we may need to add the assumption that this will not happen to the extent that the network becomes unusable or the architecture un-implementable. * this document not distinguishing between the security of the network and of services provided under that network (see <ref> [HRG94, p.5] </ref>, which also notes the need to secure the development process `from conception to deployment and operation.'). * the view presented here of service users and service providers as being in different security domains (or at least not necessarily in the same security domain) rather than sub-domains of the TINA <p> We have not assumed that this limitation exists. * [Hub93, p.11]) may assume that there will be a trusted third party-based architecture, in that a requirement of the architecture is to `maintain a protected user-ID and authentication database'. <ref> [HRG94, p.29] </ref> explicitly requires the existence of a secure time or sequencing service, which `may be offered by a trusted third party.'; [HRG94, p.56] explicitly requires the existence of distributed accurate timing information related to charging mechanisms. <p> p.11]) may assume that there will be a trusted third party-based architecture, in that a requirement of the architecture is to `maintain a protected user-ID and authentication database'. [HRG94, p.29] explicitly requires the existence of a secure time or sequencing service, which `may be offered by a trusted third party.'; <ref> [HRG94, p.56] </ref> explicitly requires the existence of distributed accurate timing information related to charging mechanisms. A secure trading facility to provide a mechanism for securing the making of associations between entities is also needed ([HRG94, p.33]). <p> Is this justified? * some commercially-based assumptions are made explicit in the BT documents. In <ref> [HRG94, p.12] </ref> for instance, the `summary of the 8 core security requirements' table includes an entry `no cross-subsidies' under assuring the integrity of the charging and billing process. <p> It is interesting to note that the eight Core Requirements of BT regarding TINA have been accepted by ITU as baseline text with the exception of `Maintain Billing Integrity' <ref> [HRG94, p.6] </ref>. The omission points up the different agendas of standards-setting and commercial bodies, which needs to be borne in mind when considering the relevance and applicability of standards. * The flavour of the BT documents is from the architecture outwards, as against this document's outside-in viewpoint. <p> This is reasonable since the BT documents are defining the requirements of an architecture, whereas this document is seeking to bring out the assumptions explicit and implicit in such an archi tecture. September 8, 1995 28 pdw22/Authman/assumptions.tex * <ref> [HRG94, p.7] </ref> makes explicit the uncertain position regarding `areas such as: regulators allowing in the future rights of access to the `network elements or other interfaces within existing networks' for `other' service providers and service users, 25 and possible future EC privacy directives; without regard to currently-known or projected regulatory actions, <p> that `In the absence of a fixed legislative framework, and with rapid changes in technology, it appears prudent to consider some of the more exacting requirements during the initial stages of the design cycle and to build in some flexibility within the specification of TINA compliant networks and associated services.' <ref> [HRG94, p.7] </ref>. In a similar fashion, we have assumed in this document that the requirements of security and privacy explicit in the architecture need to be as widely-drawn as possible to ensure that future legal and regulatory provisions do not require major redesign work. <p> guidelines crystallise into legal or quasi-legal requirements the architecture is likely to need tailoring to meet the specifics of the new situation, despite the best attempts to make the architecture flexible, and we have explicitly assumed above that the architecture will need modification over time. * The detailed requirements in <ref> [HRG94] </ref> are framed in terms of `active objects'. <p> Is there any implication here that an object-oriented computational model is expected of implementations? Will an architecture described in object-oriented terms still make sense if future implementations are developed using another computational model? * <ref> [HRG94, p.15] </ref> notes that group (i.e. shared between more than one person) user identifiers should only be used under exceptional circumstances. <p> Does this imply that informal delegation by sharing user identifiers has already been dismissed as a mechanism, and is actively discouraged? * The BT documents make explicit that there will need to be trading-off decisions between security and such other requirements as performance see for example <ref> [HRG94, p.17] </ref>. It si a general assumption of computer systems developments that such assumptions need to be made. * [HRG94, p.12] sets as a requirement `Not to over-specify security mechanisms'. <p> It si a general assumption of computer systems developments that such assumptions need to be made. * <ref> [HRG94, p.12] </ref> sets as a requirement `Not to over-specify security mechanisms'. <p> result in problems (such as inefficient use of resources and user dissatisfaction with clumsy service use mechanisms, we suggest that the major issue in specifying security mechanisms in the architecture is actually the danger of under -specification, and the prob lems of over-specification should be seen in this context. * <ref> [HRG94, p.17] </ref> differentiates between `central and remote terminals' for user authentication mechanisms. The assumption that such a differentiation is useful and meaningful is explicitly made above. * [HRG94, p.20] states that external unregistered users [sic] should have `no access' as their default rights set. <p> The assumption that such a differentiation is useful and meaningful is explicitly made above. * <ref> [HRG94, p.20] </ref> states that external unregistered users [sic] should have `no access' as their default rights set. Is this reasonable under all circumstances - cf. anonymous ftp, anonymous help lines? 25 The defensiveness of BT with regard to market control can be seen here. <p> Is this reasonable under all circumstances - cf. anonymous ftp, anonymous help lines? 25 The defensiveness of BT with regard to market control can be seen here. September 8, 1995 29 pdw22/Authman/assumptions.tex * <ref> [HRG94, p.22] </ref> requires that an inactivity timeout be provided, with config-urable inactivity time. <p> might be inappropriate before it is forced, for example if a long batch job is running from a terminal with no user input required, or if a transaction is at a critical stage at which forced disconnection could result in problems such as loss of data or file corruption. * <ref> [HRG94, p.35] </ref>'s requirement for the provision of backup and recovery plans presumably implies the testing of these plans it is not explicit. * [HRG94, p.41] states that, as apart of the protection for personal data, `All reallocated data objects and re-usable data storage media should be re-initialised prior to reuse'. <p> required, or if a transaction is at a critical stage at which forced disconnection could result in problems such as loss of data or file corruption. * [HRG94, p.35]'s requirement for the provision of backup and recovery plans presumably implies the testing of these plans it is not explicit. * <ref> [HRG94, p.41] </ref> states that, as apart of the protection for personal data, `All reallocated data objects and re-usable data storage media should be re-initialised prior to reuse'. Should this in fact be changed to such media being wiped as soon as the data is no longer needed. <p> Compare - `Access controls and authentication procedures which apply to operational systems should also apply during the testing of such systems' <ref> [HRG94, p.45] </ref> with - `The design process should include the provision for the removal of all hardware or software modules which are used for test and development purposes only, including any which by-pass normal authentication proce dures' [our emphasis]. [HRG94, p.45]. and - `If any security function can be activated, de-activated <p> operational systems should also apply during the testing of such systems' <ref> [HRG94, p.45] </ref> with - `The design process should include the provision for the removal of all hardware or software modules which are used for test and development purposes only, including any which by-pass normal authentication proce dures' [our emphasis]. [HRG94, p.45]. and - `If any security function can be activated, de-activated or modified during start-up, normal operation or maintenance, all circumstances under which this can occur must be identified in the system documentation.' [HRG94, p.51] [HRG94, p.58] also demands that `A Third Party Service Provider should be able to subject <p> for test and development purposes only, including any which by-pass normal authentication proce dures' [our emphasis]. [HRG94, p.45]. and - `If any security function can be activated, de-activated or modified during start-up, normal operation or maintenance, all circumstances under which this can occur must be identified in the system documentation.' <ref> [HRG94, p.51] </ref> [HRG94, p.58] also demands that `A Third Party Service Provider should be able to subject all his calls to a reporting procedure, in order to confirm that they are of an allowable type subject to overriding any privacy requirements.' [our emphasis]. <p> and development purposes only, including any which by-pass normal authentication proce dures' [our emphasis]. [HRG94, p.45]. and - `If any security function can be activated, de-activated or modified during start-up, normal operation or maintenance, all circumstances under which this can occur must be identified in the system documentation.' [HRG94, p.51] <ref> [HRG94, p.58] </ref> also demands that `A Third Party Service Provider should be able to subject all his calls to a reporting procedure, in order to confirm that they are of an allowable type subject to overriding any privacy requirements.' [our emphasis].
Reference: [Hub93] <author> S.D. Hubbard. TINA: </author> <title> Internal team task 1 core security requirements for TINA. </title> <type> Technical report, </type> <institution> British Telecom, </institution> <month> Nov </month> <year> 1993. </year> <note> Version 1.0. </note>
Reference-contexts: Our assumptions have diverged in many ways from those in in the TINA documents <ref> [Hub93] </ref> and [HRG94]. <p> or derived from the following sources: * our own knowledge, experience and introspection, * work by other researchers at the Computer Laboratory, 1 * consideration of literature concerning authentication in networks, such as [NS78], and * a critical examination of two documents from British Telecom ("BT") related to this project, <ref> [Hub93] </ref> and [HRG94]. In some cases, the assumptions presented here have been contrasted with assumptions in published work in order to illuminate the differences between them. 2.3 Caveats There are some remaining concerns regarding the contents of this document. <p> Decisions as to whether and to what extent specific shared resources can be trusted are outside the scope of this architecture. * It will not be possible to foresee all of the possible implementation mechanisms for systems designed under the architecture (cf. <ref> [Hub93, p.8] </ref>). The architecture must be capable of simple modification to meet new implementation models with the minimum of change to existing implementations. <p> environment. 9 It will be assumed that network administrators will be aware of security considerations related to their work, and will be responsible for their own and delegated security-related work. * It will not be possible to foresee all of the possible threats to systems designed under the architecture (cf. <ref> [Hub93, p.8] </ref>). <p> September 8, 1995 12 pdw22/Authman/assumptions.tex * Implementations of the architecture may be required for legal, political or commercial reasons to be certified based on the architecture to recognised national or international standards (cf. <ref> [Hub93, p.6,10] </ref>). The architecture should not prevent this certification, and may usefully make the process easier by basing some of its design decisions on these standards where they are appropriate and satisfactory. <p> BT assume that by the time networks based on the architecture are deployed, it is likely that the differing sets of standards together with other security evaluation criteria `will have been merged into a common set of criteria.' <ref> [Hub93, p.7] </ref>). * Not all of the entities who need to communicate with each other in an environment protected by any or all of the security systems implemented under the architecture will trust each other. <p> security systems should take advantage of any predictable reasons for, and mistakes in, human activities of this kind. 13 * The currently identified threats against systems derived from the architecture, and against which the architecture will need to defend itself, can be divided in to the following categories (derived from <ref> [Hub93, p.8-9] </ref>): loss of accountability for actions, whether by impersonation of a valid system user (of any kind) by another person not so authorised, or the repudiation of an act by an authorised person, loss of confidentiality of data or identity, 13 This may, for instance, result in an examination of <p> to any controls over access or use, and the architecture should allow al application to be changed from being chargeable September 8, 1995 17 pdw22/Authman/assumptions.tex to free access and vice versa by modification to its data structures rather than by having to recode the applications. 14 Note in this context <ref> [Hub93, p.14] </ref>: `Appropriate audit mechanisms should be used to map each chargeable action to a specific customer' [our emphasis]. <p> In order to maintain generality these three must be seen for architecture purposes as being separate domains. Note that this assumption conflicts with that of <ref> [Hub93, p.5] </ref>, 15 in which the service and user domains are seen as being sub-domains of the TINA architecture as a whole. 16 This implies a considerable degree of control over user and service provider activities and system design decisions. * A number of service users and/or service providers will be <p> information flow.' ([NS78, p.993]. 14 This is an example of an instance in which the architecture should recommend strict admin istrative controls to prevent illicit use of an option which makes a service free to use. 15 However, the possibility of these being in different administrative domains is accepted see <ref> [Hub93, p.5-6] </ref>. 16 `The TINA services and their customers reside in a domain that is under the control of a TINA network operator.' September 8, 1995 18 pdw22/Authman/assumptions.tex 12 How the World is Organised No explicit or implicit assumptions are to be made in the architecture as to how the world <p> The architecture will need to support the conversion of these existing applications to work under it with a minimum of effort. * Different services, and different parts of single services, provided through the same carrier may require different levels of, and different mechanisms to sup port, security (cf. <ref> [Hub93, p.10] </ref>). * The same service provided by the same provider via the same carrier may require different levels of, and different mechanisms for, security for different users. * The same service provided via the same carrier may require different levels of, and different mechanisms for, security for different facilities offered <p> The decision as to the information needed by the service provider, and therefore what is to be available from the architecture, will be made during the research leading to the design of the architecture. Note in this context the requirement set by <ref> [Hub93, p.15] </ref>: `Include any security requirements specified by the customer in the service level agreement' However it is not stated here whether the `customer' is the service provider, the service user or the network carrier. * A service provider may require the use of security mechanisms over his or her services <p> This anonymity is currently under threat from legal, regulatory and private bodies. It is assumed that anonymity will be allowed to continue under future regulatory and legal regimes, and will be a required facility of the architecture. <ref> [Hub93, p.8] </ref> notes `loss of anonymity' as a possible risk if confidentiality is lost. This assumes that the legal and regulatory framework will allow such anonymity in practice. <p> Each of these network carriers may differ in any respect other than the minimum necessary technical agreement to achieve sufficient communication to support the architecture. * Different network administration function, and different parts of the same function, may require different levels of, and different mechanisms to support, security (cf. <ref> [Hub93, p.10] </ref>). * The same network administration function provided by the same carrier may require different levels of, and different mechanisms for, security for different administrators. <p> support different security policies in different political, economic or geographic sub-domains of the network. [HRG94, p.20] notes that security policies might differ in different domains which require to communicate. * Different data elements maintained by the network carrier may require different levels of, and different mechanisms to ensure, security (cf. <ref> [Hub93, p.10] </ref>). * Network carriers may at times require to delegate any aspect of the work of network management, between authorised individuals within an organisation, between organisations, and across security and/or administrative domains. <p> September 8, 1995 24 pdw22/Authman/assumptions.tex 16 TINA: British Telecom Documents 16.1 Summary of Differences BT have produced two documents relevant to and/or extending the assumptions given above (<ref> [Hub93] </ref> and [HRG94]). The general attitude underlying BT's work can be related to the comment that [Hub93] `. . . concentrates in particular on the stakeholders with the most to lose the service and network providers' ([Hub93, p.4]). The rationale for having a security architecture is strongly biased towards protecting the revenues of those who charge for services; see [HRG94, p.3]. <p> During the work presented here, we have noted differences between the assumptions which we have made and those explicit and implicit in the TINA documents <ref> [Hub93] </ref> and [HRG94]. <p> September 8, 1995 25 pdw22/Authman/assumptions.tex 16.2 Detailed Considerations Matters raised in the BT documents which may need to be reflected in this document include: * extending the list of stakeholders to reflect those in <ref> [Hub93, p.4] </ref> not covered above this involves splitting users (who use services) and subscribers (who pay for services) 24 , and adding consideration of designers, developers, deployers, managers and operators of systems based on the architecture. <p> It should be noted that <ref> [Hub93] </ref> does not regard wider society as a stakeholder in the architecture. However, the need to reflect regulatory and legal frameworks is included. The exclusion of society from stakeholder status may result in different priorities and attitudes to regulation and law. <p> The exclusion of society from stakeholder status may result in different priorities and attitudes to regulation and law. This difference will have to be kept in sight during the extension of this document. * no assumptions specifically related to loss of availability (cf. <ref> [Hub93, p.8] </ref>) have been included in this document. * [Hub93, p.10 et seq.] splits the core security requirements into first level (`core' security requirements, of which there are eight) and second level. The assumptions in this document relate arbitrarily to first and second-level assumptions. <p> This difference will have to be kept in sight during the extension of this document. * no assumptions specifically related to loss of availability (cf. [Hub93, p.8]) have been included in this document. * <ref> [Hub93, p.10 et seq.] </ref> splits the core security requirements into first level (`core' security requirements, of which there are eight) and second level. The assumptions in this document relate arbitrarily to first and second-level assumptions. <p> The assumptions in this document relate arbitrarily to first and second-level assumptions. The assumptions presented here may need to be organised to reflect the first-and second-level requirements in <ref> [Hub93] </ref>, after which an evaluation of the assumptions behind (particularly) the core requirements might be performed. * [Hub93, p.11-12] notes that as an example of rogue activity stakeholders might go beyond their allowed activities. <p> The assumptions in this document relate arbitrarily to first and second-level assumptions. The assumptions presented here may need to be organised to reflect the first-and second-level requirements in [Hub93], after which an evaluation of the assumptions behind (particularly) the core requirements might be performed. * <ref> [Hub93, p.11-12] </ref> notes that as an example of rogue activity stakeholders might go beyond their allowed activities. <p> That this might happen is worth making an explicit assumption, in order to concentrate the architecture specifier's mind on internal as well as external threats. * as demonstrated out by <ref> [Hub93, p.14] </ref>, it is necessary to assume that the stakeholders (as defined by BT) will need to be able to trust the charging and billing processes of the architecture. * assumptions related to international requirements that technical implementations do not interfere with free trade issues ([HRG94, p.10]) are currently not dealt <p> are the security services `authorised' as representatives of `wider society' ? It is interesting to note that [HRG94, p.13] specifically refers to `allowing any TINA stakeholders to make use of a TINA-compliant network', implying that the only stakeholders are those who make use of the facilities of such a network. <ref> [Hub93, p.13] </ref> also raises this issue in stating that `The general principle that no unauthorised person should be able to read or modify data belonging to anyone else is reasonable.' and in a reference to preventing unauthorised eavesdropping [Hub93, p.14] when is the `general principle' to be breached, for whose benefit <p> are those who make use of the facilities of such a network. [Hub93, p.13] also raises this issue in stating that `The general principle that no unauthorised person should be able to read or modify data belonging to anyone else is reasonable.' and in a reference to preventing unauthorised eavesdropping <ref> [Hub93, p.14] </ref> when is the `general principle' to be breached, for whose benefit and under whose authority? * The architecture may need to protect its records, logs etc. by itself keeping a log of third party access to and monitoring activity on those logs to demonstrate that privacy laws were not <p> Additionally, the delegation capabilities are limited by the requirement that delegatees be `appropriately privileged' users ([HRG94, p.14]), implying strongly that they have to be already known to the systems before delega tion occurs. We have not assumed that this limitation exists. * <ref> [Hub93, p.11] </ref>) may assume that there will be a trusted third party-based architecture, in that a requirement of the architecture is to `maintain a protected user-ID and authentication database'. [HRG94, p.29] explicitly requires the existence of a secure time or sequencing service, which `may be offered by a trusted third party.'; <p> A rationale for the need for such a function might be that we assume that people will be able to inject or replay messages at will (Needham Schroeder!). A time or sequencing mechanism is an implementation of one instance of a defence against this. * <ref> [Hub93, p.5, p.12] </ref> assumes that the network operators will monitor network activity for possible security problems. <p> monitoring function should be independent of any of the stakeholders to ensure independence of reporting. * BT's documents assume that the architecture may need to take cognisance of the bandwidth or security (satellite vs. land-line) requirements of data messages ([HRG94, p.15]) Our further comments on the BT documents are: * <ref> [Hub93, p.11] </ref>) makes an assumption about the legal and regulatory framework when it states that we need to `ensure that the audit trail can be used for resolution of disputes'. <p> We suggest that the best we can do is to ensure that the audit trail is obtained, maintained in a form and held to such a level of security that the courts or arbitrators are likely to accept its evidence. * <ref> [Hub93, p.6] </ref> assumes that the potential impacts of security loss for service providers and network providers are identical. Is this justified? * some commercially-based assumptions are made explicit in the BT documents.
Reference: [KCDJ94] <author> M. Krajewski, J.C. Chipchak, Chodorow D.A., and Trostle J.T. </author> <title> Applicability of smart cards to network user authentication. </title> <journal> Computing Systems, </journal> <volume> 7(1) </volume> <pages> 75-89, </pages> <year> 1994. </year>
Reference-contexts: Such functionality might include such facilities as the calculation of nonce keys, encryption and/or decryption (see, for example, <ref> [KCDJ94] </ref>), or the identification of the valid holder of the device by means of PINs etc.
Reference: [Lam93] <author> B.W. Lampson. </author> <title> Authentication in distributed systems. </title> <editor> In S. Mullender, editor, </editor> <booktitle> Distributed Systems, </booktitle> <pages> pages 543-580. </pages> <publisher> ACM Press/Addison-Wesley, </publisher> <year> 1993. </year>
Reference: [Lin94] <author> J. Linn. </author> <title> Generic interface to security services. </title> <journal> Computer Communications, </journal> <volume> 17(7) </volume> <pages> 483-491, </pages> <year> 1994. </year>
Reference: [McA90] <author> D.R. McAuley. </author> <title> Protocol Design for High Speed Networks. </title> <type> PhD thesis, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <year> 1990. </year> <note> Available as Technical Report No.186, </note> <institution> Computer Laboratory, University of Cambridge. </institution>
Reference-contexts: no assumptions as to how the architecture will be implemented, in particular whether any particular part of the implementation will be in hardware or software, where the hardware/software boundary might come, and whether the implementation will be based on shared use of general-purpose computing facilities or on dedicated equipment (cf. <ref> [McA90, p.2-3] </ref>). However the architecture will not of itself prevent any technically feasible division of implementation between hardware and software, or the use of resources shared with other applications.
Reference: [Muf89] <author> S. Muftic. </author> <title> Security Mechanisms for Computer Networks. </title> <publisher> Ellis Horwood, </publisher> <year> 1989. </year>
Reference-contexts: There may need to be provision for communication between arbitrary numbers of non-trusting principals or for trust being achievable by subsets of a nominated group of entities (see <ref> [Muf89, p.30] </ref>). Additionally, no assumptions are made concerning low-level computation-based aspects of current security mechanisms, because the implementation details which they represent are outside the scope of the architecture. <p> We suggest that we will be operating at the application layer, and can therefore assume that all lower levels will work sufficiently well to support the architecture, but not that they work perfectly i.e. they need constant checking in the protocols. Note that <ref> [Muf89, p.90] </ref> discusses where the security should appear in the 7-layer model; what follows is based on his work. Since peer-entity authentication is end-to-end, Muftic concludes that it must appear after the end-to-end channel has emerged, at the network layer (3) or above.
Reference: [NS78] <author> R.M. Needham and M.D. Schroeder. </author> <title> Using encryption for authentication in large networks of computers. </title> <journal> Comm. ACM, </journal> <volume> 21(12) </volume> <pages> 993-998, </pages> <year> 1978. </year>
Reference-contexts: of compliance with the architecture. 2.2 Sources of These Assumptions The assumptions described below have been obtained or derived from the following sources: * our own knowledge, experience and introspection, * work by other researchers at the Computer Laboratory, 1 * consideration of literature concerning authentication in networks, such as <ref> [NS78] </ref>, and * a critical examination of two documents from British Telecom ("BT") related to this project, [Hub93] and [HRG94].
Reference: [PW92] <author> B. Pfitzmann and M. Waidner. </author> <title> Unconditional byzantine agreement for any number of faulty processors. </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> 577 </volume> <pages> 339-350, </pages> <year> 1992. </year>
Reference-contexts: Examples of the assumptions which are explicitly excluded as being implementation-related include the un-feasibility of users computing RSA roots or discrete logs of large numbers (see [CvH91, p.258]), and the unforgeability of digital signatures (as assumed in <ref> [PW92] </ref>).
Reference: [R + 91] <editor> J. Rumbaugh et al. </editor> <booktitle> Object-Oriented Modeling and Design. Prentice-Hall International, </booktitle> <publisher> Inc., </publisher> <year> 1991. </year> <month> September 8, </month> <year> 1995 </year> <month> 33 pdw22/Authman/assumptions.tex </month>
Reference: [Rog89] <author> W.V.H. Rogers. </author> <title> The Law of Tort. Sweet and Maxwell, </title> <year> 1989. </year>
Reference-contexts: Note that questions of law may arise as to whether the duty of care is universal within a multi-carrier network, based on the perception of proximity between the parties involved (see <ref> [Rog89, p.43-44] </ref>) 12 .
Reference: [VK85] <author> V.L. Voydock and S.T. Kent. </author> <title> Security in high-level network protocols. </title> <journal> IEEE Communications Magazine, </journal> <volume> 23(7) </volume> <pages> 12-24, </pages> <year> 1985. </year> <month> September 8, </month> <year> 1995 </year> <month> 34 pdw22/Authman/assumptions.tex </month>
Reference-contexts: It probably also constrains us to the consideration of end-to-end rather than link-based security mechanisms (cf. <ref> [VK85] </ref>.
References-found: 17

