URL: http://www.demo.cs.brandeis.edu/papers/addam92.ps.gz
Refering-URL: http://www.demo.cs.brandeis.edu/papers/long.html
Root-URL: http://www.cs.brandeis.edu
Title: Abstract  
Abstract: Cognitive scientists, AI researchers in particular, have long-recognized the enormous benefits of modularity (e.g., Simon, 1969), as well as the need for self-organization (Samuel, 1967) in creating artifacts whose complexity approaches that of human intelligence. And yet these two goals seem almost incompatible, since truly modular systems are usually designed, and systems that truly learn are inherently nonmodular and produce only simple behaviors. Our paper seeks to remedy this shortcoming by developing a new architecture of Additive Adaptive Modules which we instantiate as Addam, a modular agent whose behavioral repertoire evolves as the complexity of the environment is increased. 1 
Abstract-found: 1
Intro-found: 1
Reference: <author> Beer, R. D. and Gallagher, J. C. </author> <year> (1991). </year> <title> Evolving dynamical neural networks for adaptive behavior. </title> <type> Technical Report CES-91-17, </type> <institution> Case Western Reserve University, Cleveland. </institution>
Reference: <author> Brooks, R. A. </author> <year> (1986). </year> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, 2(1):1423. </journal>
Reference-contexts: Unlike other attempts at learning that focus on a single behavior such as walking (Maes & Brooks or Beer & Gallagher, discussed above), we chose to focus on the subsumptive interaction of several behaviors, and hence Addams actuators are a level of abstraction above leg controllers <ref> (similar to Brooks, 1986) </ref>. Thus Addam is moved by simply specifying dx and dy. Internally, Addam consists of a set of dynamical systems (instantiated as feedforward connectionist networks) connected as shown above in Figure 1. This architecture is actually quite simple. <p> We choose preemption by following Brooks own advice in describing his goal of simplicity: If you notice that a particular interface is starting to rival in complexity the components it connects, then either the interface needs to be rethought or the decomposition of the system needs redoing <ref> (Brooks, 1986, p. 15) </ref>.
Reference: <author> Brooks, R. A. </author> <year> (1991). </year> <title> Intelligence without representa tions. </title> <journal> Artificial Intelligence, 47:139159. </journal>
Reference-contexts: Finally, we note a significant difference in methodology between our work and that of Brooks. In creating his agents, Brooks first performs a behavioral decomposition, but in implementing each layer, he performs a functional decomposition of the type he himself warns against <ref> (Brooks, 1991, p. 146) </ref>. In training Addam, on the other hand, we first perform a behavioral decomposition, and then let backpropagation decompose each behavior appropriately. This automation significantly lessens the arbitrary nature of behavior-based architectures which has thus far limited the import of Brooks work to cognitive science.
Reference: <author> Connell, J. H. </author> <year> (1990). </year> <title> Minimalist Mobile Robotics: A Colony-style Architecture for an Creature, </title> <booktitle> Volume 5 of Perspectives in Artificial Intelligence. </booktitle> <publisher> Academic Press, </publisher> <address> San Diego. </address>
Reference-contexts: However, since machine learning is not up to the task of evolving these systems, engineers of artificial animals have embedded themselves in the design loop as the learning algorithm, and thus all components of the system, as well as their interactions, must be carefully crafted by the engineer <ref> (see, e.g., Connell, 1990) </ref>. Research aimed at replacing the engineer in these systems is at an early stage.
Reference: <author> DeJong, G. and Mooney, R. </author> <year> (1986). </year> <title> Explanation-based learning: an alternative view. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 145-176. </pages>
Reference: <author> Elman, J. L. </author> <year> (1988). </year> <title> Finding structure in time. </title> <type> Technical Report CRL 8801, </type> <institution> University of California, </institution> <address> San Diego. </address>
Reference-contexts: Placing a simple system in a complex environment can work if the environment is non-threatening <ref> (Elman, 1988) </ref>, but often the cost of engineering the environment is greater than that of engineering a working system.
Reference: <author> Fahlman, S., and Lebiere, C. </author> <year> (1990). </year> <title> The cascade-correlation learning architecture. </title> <type> Technical Report CMU CS-90-100, </type> <institution> Carnegie Mellon University, Pittsburgh. </institution>
Reference: <author> Jacobs, R. A., Jordan, M. I., and Barto, A. G. </author> <year> (1990). </year> <title> Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks. </title> <journal> Cognitive Science, </journal> <volume> 15 </volume> <pages> 219-250. </pages>
Reference: <author> Jacobs, R. A., Jordan, M. I., Nowlan, S. J., and Hinton, G. E. </author> <year> (1991). </year> <title> Adaptive mixtures of local experts, </title> <journal> Neural Computation, </journal> <volume> 3(1) </volume> <pages> 79-87. </pages>
Reference: <author> Kirsh, D. </author> <year> (1991). </year> <journal> Today the earwig, tomorrow man? Artificial Intelligence, 47:161184. </journal>
Reference-contexts: Moreover, feedforward networks need not have been used either. We could have substituted sequential cascaded networks (Pollack, 1987), endowing Addam with internal state <ref> (cf Kirsh, 1991) </ref> and allowing even more complex behaviors. Finally, we note a significant difference in methodology between our work and that of Brooks.
Reference: <author> Lin, L. J. </author> <year> (1990). </year> <title> Programming robots using reinforcement learning and teaching. </title> <booktitle> In Proceedings of AAAI-90, </booktitle> <pages> pages 781786, </pages> <address> Menlo-Park, CA. </address> <publisher> AAAI, MIT Press. </publisher>
Reference: <author> Maes, P. and Brooks, R. A. </author> <year> (1990). </year> <title> Learning to coordinate behaviors. </title> <booktitle> In Proceedings of the Eighth National Conferences on AI, </booktitle> <pages> pages 769802. AAAI-90. </pages>
Reference-contexts: An earlier work that does not presume such an a priori modularization <ref> (Maes & Brooks, 1990) </ref> allows a six-legged robot to learn to walk, but there are no real modules in the final system. Beer and Gallagher (1991) attack this same problem of robotic mobility, but in a different way.
Reference: <author> Maes, P. </author> <year> (1991). </year> <title> The agent network architecture. </title> <booktitle> In AAAI Spring Symposium on Integrated Intelligent Architectures, </booktitle> <month> March. </month>
Reference: <author> Mitchell, T., Keller, R., and Kedar-Cebelli, S. </author> <year> (1986). </year> <title> Explanation-based generalization: a unifying view. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 47-80. </pages>
Reference: <author> Nowlan, S. J. and Hinton, G. E. </author> <year> (1991). </year> <title> Evaluation of adaptive mixtures of competing experts. </title> <editor> In Lipp-mann, R., Moody, J., and Touretzky, D., editors, </editor> <booktitle> Advances in Neural Information Processing 3. </booktitle> <publisher> Mor gan Kaufmann, </publisher> <pages> pages 774-780. </pages>
Reference: <author> Pollack, J. B. </author> <year> (1987). </year> <title> Cascaded back propagation on dynamic connectionist networks. </title> <booktitle> In Proceedings of the Fourth Annual Cognitive Science Conference, </booktitle> <pages> pages 391-404, </pages> <address> Seattle. </address>
Reference-contexts: Moreover, feedforward networks need not have been used either. We could have substituted sequential cascaded networks <ref> (Pollack, 1987) </ref>, endowing Addam with internal state (cf Kirsh, 1991) and allowing even more complex behaviors. Finally, we note a significant difference in methodology between our work and that of Brooks.
Reference: <author> Samuel, A. L. </author> <year> (1967). </year> <title> Some studies in machine learning using the game of checkers II recent progress. </title> <journal> IBM Journal of Research and Development, </journal> <pages> pages 601 617. </pages>
Reference: <author> Simon, H. </author> <year> (1969). </year> <booktitle> Sciences of the Artificial. </booktitle> <publisher> MIT Press. </publisher>
Reference: <author> Thelen, E., </author> <title> Dynamical systems and the generation of individual differences. </title> <editor> In Columbo, J. and Fagen, J. W., editors, </editor> <title> Individual Differences in Infancy, Reliability, Stability, and Prediction, </title> <publisher> Lawrence Erlbaum Associates, </publisher> <pages> pages 19-43. </pages>
References-found: 19

