URL: http://cobar.cs.umass.edu/pubfiles/ir-126.ps
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Title: Aspect Windows, 3-D Visualizations, and Indirect Comparisons of Information Retrieval Systems  
Author: Russell C. Swan and James Allan 
Web: http://www.cs.umass.edu/-~swan,~allan  
Address: Amherst, MA 01003  
Affiliation: Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts  
Abstract: We built two Information Retrieval systems that were targeted for the TREC-6 "aspect oriented" retrieval track. The systems were built to test the usefulness of different visualizations in an interactive IR setting|in particular, an "aspect window" for the chosen task, and a 3-D visualization of document inter-relationships. We studied 24 users of the system in order to investigate: whether the systems were more effective than a control system, whether experienced users outperformed novices, whether spatial reasoning ability was a good predictor of effective use of 3-D, and whether the systems could be compared indirectly via a control system. Our results show substantial differences in user performance are related to spatial reasoning ability and to a lesser degree other traits. We also obtained markedly different results from the direct and indirect comparisons. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Allan, J. Callan, W. B. Croft, L. Ballesteros, D. Byrd, R. Swan, and J. Xu. </author> <title> INQUERY does battle with trec-6. </title> <editor> In D. Harman, editor, </editor> <booktitle> Proceedings of the Sixth Text REtrieval Conference (TREC-6). National Institute of Standards and Technology Special Publication, </booktitle> <publisher> (in press). </publisher>
Reference-contexts: Eight documents were retrieved by the last block of users that had not been judged by NIST. These were treated as not relevant. We performed an ANalysis Of VAriance (ANOVA) using MacAnova [19]. More detailed descriptions of our experiment are available elsewhere <ref> [4, 1] </ref>. 4 Traits affecting performance We are interested in determining if there are any traits influencing searching effectiveness in general, and if there are any traits that lead a user to be more effective with one type of interface than another.
Reference: [2] <author> J. Allan, A. Leouski, and R. Swan. </author> <title> Interactive Cluster Visualization for Information Retrieval. </title> <type> Technical Report IR-116, </type> <institution> Center for Intelligent Information Retrieval, University of Massachusetts, Amherst, </institution> <year> 1997. </year>
Reference-contexts: A retrieved document that is far from any already-marked aspect is more likely to be useful. (We have been investigating variations on the visualization that enhance the ability for a user to find new and interesting material <ref> [2, 17] </ref>.) The three windows|result list, aspect, and 3-D| were tightly integrated. If a document is selected by a mouse click in any of the three windows, that document is highlighted in all windows in which it is visible.
Reference: [3] <author> G. Brajnik, S. Mizzaro, and C. Tasso. </author> <title> Evaluating user interfaces to information retrieval systems: A case study on user support. </title> <booktitle> In Proceedings of the 19th annual international ACM SIGIR conference on research and development in information retrieval, </booktitle> <pages> pages 128-136, </pages> <address> Zurich, </address> <year> 1996. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: Novice users may find such systems puzzling, but we do not feel that diminishes the value of a targeted system. Further, other researchers are investigating the usefulness of systems for users with little to no searching experience <ref> [23, 3] </ref>. On the other hand, we have no interest in building systems that are inherently difficult to use. Indeed, the better and easier to use a system's underlying design is, the more complexity we can introduce without overbur-dening the user [21].
Reference: [4] <author> D. Byrd, R. Swan, and J. Allan. </author> <title> TREC-6 interactive track report, part 1: Experimental procedure and initial results. </title> <type> Technical Report IR-117, </type> <institution> Center for Intelligent Information Retrieval, University of Massachusetts, Amherst, </institution> <month> November </month> <year> 1997. </year>
Reference-contexts: Eight documents were retrieved by the last block of users that had not been judged by NIST. These were treated as not relevant. We performed an ANalysis Of VAriance (ANOVA) using MacAnova [19]. More detailed descriptions of our experiment are available elsewhere <ref> [4, 1] </ref>. 4 Traits affecting performance We are interested in determining if there are any traits influencing searching effectiveness in general, and if there are any traits that lead a user to be more effective with one type of interface than another.
Reference: [5] <author> J. P. Callan, W. B. Croft, and S. M. Harding. </author> <title> The INQUERY retrieval system. </title> <booktitle> In Proceedings of the Third International Conference on Database and Expert Systems Applications, </booktitle> <pages> pages 78-83, </pages> <address> Valencia, Spain, 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: When a document is first placed in the list the save button is unlabeled. Reading the document causes the label to change to "U". Saving the document causes the label to change to "R". 2.1 Inquery Our system consisted of the Inquery search engine <ref> [5] </ref> with a new interface.
Reference: [6] <author> M. Chalmers and P. Chitson. Bead: </author> <title> Explorations in information visualization. </title> <booktitle> In Proceedings of the 15th annual international ACM SIGIR conference on research and development in information retrieval, </booktitle> <pages> pages 330-337, </pages> <address> Copenhagen,Denmark, 1992. </address> <publisher> ACM. </publisher>
Reference-contexts: The constraints are modelled as springs [15, 11, 7]). The resulting visualization is similar in style to BEAD <ref> [6] </ref>, differing in a few key aspects: BEAD was used on an entire (though small) corpus, and this display is used only on the retrieved set; the vectors used by BEAD were based on document abstracts rather than the full text.
Reference: [7] <author> J. D. Cohen. </author> <title> Drawing graphs to convey proxomoty: An incremental arrangement method. </title> <journal> ACM Transactions on CHI, </journal> <pages> pages 197-229, </pages> <year> 1997. </year>
Reference-contexts: That space was collapsed to 3 dimensions for visualization using a spring embedding algorithm (Spring embedding is a force directed placement graph drawing algorithm that generates an approximate solution to a graph layout when the distances between connected nodes are given as constraints. The constraints are modelled as springs <ref> [15, 11, 7] </ref>).
Reference: [8] <author> W. B. Croft. </author> <title> Organizing and Searching Large Document Collections. </title> <type> PhD thesis, </type> <institution> University of Cam-bridge, </institution> <year> 1979. </year> <month> 8 </month>
Reference-contexts: The Cluster Hypothesis [22] states that relevant documents tend to cluster, and it has been shown to be valid in top-ranked documents <ref> [8, 13] </ref>. Aspects represent different forms of relevance, and we believe that they will group together within the set of relevant documents.
Reference: [9] <author> S. T. Dumais and D. G. Schmitt. </author> <title> Iterative searching in an online database. </title> <booktitle> In Proceedings of Human Factors Society 35th Annual Meeting, </booktitle> <pages> pages 398-402, </pages> <year> 1991. </year>
Reference-contexts: On the first group we find significant effects from FA-1, VZ-2, and education, with FA-1 being the most significant. On the second group, we find significant positive correlations for VZ-2 and reported familiarity with mouse based interfaces. Dumais and Schmitt <ref> [9] </ref> report strong correlations between verbal ability measured by FA-1 and searching effectiveness in a setting without relevance feedback, and a weaker correlation with spatial ability.
Reference: [10] <author> R. B. Ekstrom, J. W. French, H. H. Harman, and D. Dermen. </author> <title> Manual for Kit of Factor-Referenced Cognitive Tests. Educational Testing Service, </title> <publisher> Princeton, </publisher> <address> New Jersey, </address> <year> 1976. </year> <title> Tests used by permission of ETS. </title>
Reference-contexts: AI 4 2 3 General ZP AI+ 4 4 Librarian ZP AI+ 4 3 5 General AI AI+ 4 6 Librarian AI AI+ 4 Table 2: Breakdown of participants Before the searches, each participant filled out a questionnaire to determine age, education, gender and computer experience, and two psychometric tests <ref> [10] </ref>, a test of verbal fluency (Controlled Associations, test FA-1) and a test for structural visualization (Paper Folding, test VZ-2). We gave each participant a piece of scratch paper before each search, and a short questionnaire after each.
Reference: [11] <author> T. M. J. Fruchterman and E. M. Reingold. </author> <title> Graph drawing by force directed placement. </title> <journal> Software - Practice and Experience, </journal> <volume> 21 </volume> <pages> 1129-1164, </pages> <year> 1991. </year>
Reference-contexts: That space was collapsed to 3 dimensions for visualization using a spring embedding algorithm (Spring embedding is a force directed placement graph drawing algorithm that generates an approximate solution to a graph layout when the distances between connected nodes are given as constraints. The constraints are modelled as springs <ref> [15, 11, 7] </ref>).
Reference: [12] <author> M. A. Hearst. </author> <title> Visualization of term distribution information in full text information retrieval. </title> <booktitle> In Human Factors in Computing Systems CHI '95 Conference Proceedings, </booktitle> <pages> pages 59-66, </pages> <address> Denver, </address> <year> 1995. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: The headline is generally used to decide if the full text is worth reviewing or not. Some systems <ref> [12, 23] </ref>, ZPRISE among them, give information about the query terms that appear in the document, expecting that they can be used to help decide whether to investigate further.
Reference: [13] <author> M. A. Hearst and J. O. Pedersen. </author> <title> Reexamining the cluster hypotheses: </title> <booktitle> Scatter/gather on retrieval results. In Proceedings of the 19th annual international ACM SIGIR conference on research and development in information retrieval, </booktitle> <address> Zurich, </address> <year> 1996. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: The Cluster Hypothesis [22] states that relevant documents tend to cluster, and it has been shown to be valid in top-ranked documents <ref> [8, 13] </ref>. Aspects represent different forms of relevance, and we believe that they will group together within the set of relevant documents.
Reference: [14] <author> M. Iivonen. Searchers and searchers: </author> <title> Differences between the most and least consistent searchers. </title> <editor> In Ed-ward A. Fox, Peter Ingwersen, and Raya Fidel, editors, </editor> <booktitle> Proceedings of the 18th annual international ACM SIGIR conference on research and development in information retrieval, </booktitle> <pages> pages 149-157, </pages> <address> Seat-tle, Washington, </address> <month> July </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: Experienced Searchers A distinction is frequently drawn in the IR literature between novice users and experienced users <ref> [14] </ref>. Librarians are often considered canonical examples of experienced information seekers because they have more information searching experience than the general users, are more educated, and have explicitly studied information and information systems.
Reference: [15] <author> T. Kamada and S. Kawai. </author> <title> An algorithm for drawing general undirected graphs. </title> <journal> Information Processing Letters, </journal> <volume> 31 </volume> <pages> 7-15, </pages> <year> 1989. </year>
Reference-contexts: That space was collapsed to 3 dimensions for visualization using a spring embedding algorithm (Spring embedding is a force directed placement graph drawing algorithm that generates an approximate solution to a graph layout when the distances between connected nodes are given as constraints. The constraints are modelled as springs <ref> [15, 11, 7] </ref>).
Reference: [16] <author> Eric Lagergren and Paul Over. </author> <title> Comparing interactive information retrieval systems across sites: The trec-6 interactive track matrix experiment. </title> <booktitle> In Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (these proceedings), </booktitle> <address> Mel-bourne, Australia, </address> <month> August </month> <year> 1998. </year> <note> ACM. </note>
Reference-contexts: This Latin square design allows blocking on both topics and users, and the average of the diagonals gives an estimate of system-specific differences. All groups participating in the TREC-6 Interactive Track used this experimental design, which is described in greater detail by Lagergren and Over <ref> [16] </ref>. We ran three groups, each composed of two blocks, one block of general users and one block of librarians. This design allowed us to block on experienced/novice users in our assessment of the systems. Table 2 shows which systems each group ran. <p> The design of the Interactive Track experiment calls for the use of a common control, the same six topics presented in the same order, and a common Latin Square design to allow indirect comparisons of systems between sites <ref> [16] </ref>. However, the design only requires four users per system. Small sample sizes can affect experiments in several ways. The most obvious and expected is a reduction in the power of the test|large differences between systems are required in order to obtain statistically significant results.
Reference: [17] <author> A. Leouski and J. Allan. </author> <title> Visual interactions with a multidimensional ranked list. </title> <booktitle> In Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (these proceedings), </booktitle> <address> Melbourne, Australia, </address> <month> August </month> <year> 1998. </year> <note> ACM. Poster presentation. </note>
Reference-contexts: A retrieved document that is far from any already-marked aspect is more likely to be useful. (We have been investigating variations on the visualization that enhance the ability for a user to find new and interesting material <ref> [2, 17] </ref>.) The three windows|result list, aspect, and 3-D| were tightly integrated. If a document is selected by a mouse click in any of the three windows, that document is highlighted in all windows in which it is visible.
Reference: [18] <author> M. G. McGee. </author> <title> Human Spatial Abilities. </title> <publisher> Praeger Publishers, </publisher> <year> 1979. </year>
Reference-contexts: For group 3, the librarians took six minutes less per search on average (p &lt; 0.03), but there was no significant difference in average recall or precision. 4.2 Spatial Ability and 3-D Interfaces Spatial ability is a highly heritable trait that varies greatly among individuals <ref> [18] </ref>. When a user is confronted with a 3-D interface it is reasonable to expect that their response to it, and effectiveness in using it, correlates with this trait.
Reference: [19] <author> G. W. Oehlert and C. </author> <title> Bingham. Macanova a program for statistical analysis and matrix algebra, 1997. </title> <institution> Department of Applied Statistics,University of Minnesota, </institution> <address> St. Paul, http://www.stat.umn.edu/~gary/macanova/ macanova.home.html. </address>
Reference-contexts: Eight documents were retrieved by the last block of users that had not been judged by NIST. These were treated as not relevant. We performed an ANalysis Of VAriance (ANOVA) using MacAnova <ref> [19] </ref>.
Reference: [20] <author> T. Saracevic and P. Kantor. </author> <title> A Study of Information Seeking and Retrieving. III. Searchers, searches, and overlap. </title> <journal> Journal of the American Society for Information Science, </journal> <pages> pages 197-216, </pages> <year> 1988. </year>
Reference-contexts: We see no difference in effectiveness between experienced searchers and novice searchers when we compare librarians against a general academic population. Large differences in effectiveness have been found before <ref> [20] </ref>, but these involved Boolean information retrieval systems and primitive GUIs. Experience and training in a Boolean IR setting may not transfer to a ranked list probabilistic setting, especially with modern GUI systems. Our hypothesis about who is likely to use a 3-D interface is not supported.
Reference: [21] <author> B. Shneiderman, D. Byrd, and W. B. Croft. </author> <title> Clarifying search a user-interface framework for text searches. </title> <journal> D-Lib Magazine, </journal> <year> 1997. </year>
Reference-contexts: On the other hand, we have no interest in building systems that are inherently difficult to use. Indeed, the better and easier to use a system's underlying design is, the more complexity we can introduce without overbur-dening the user <ref> [21] </ref>.
Reference: [22] <editor> C. J. van Rijsbergen. </editor> <booktitle> Information Retrieval. </booktitle> <address> But-terworths, London, </address> <year> 1979. </year>
Reference-contexts: But for an aspect retrieval task, the deciding point of whether to investigate a document further is not the information content, but the marginal information content|i.e., the information content in the context of what has already been seen. The Cluster Hypothesis <ref> [22] </ref> states that relevant documents tend to cluster, and it has been shown to be valid in top-ranked documents [8, 13]. Aspects represent different forms of relevance, and we believe that they will group together within the set of relevant documents.
Reference: [23] <author> A. Veerasamy and N. J. Belkin. </author> <title> Evaluation of a tool for visualization of information retrieval results. </title> <booktitle> In Proceedings of the 19th annual international ACM SIGIR conference on research and development in information retrieval, </booktitle> <pages> pages 85-92, </pages> <address> Zurich, </address> <year> 1996. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: Novice users may find such systems puzzling, but we do not feel that diminishes the value of a targeted system. Further, other researchers are investigating the usefulness of systems for users with little to no searching experience <ref> [23, 3] </ref>. On the other hand, we have no interest in building systems that are inherently difficult to use. Indeed, the better and easier to use a system's underlying design is, the more complexity we can introduce without overbur-dening the user [21]. <p> The headline is generally used to decide if the full text is worth reviewing or not. Some systems <ref> [12, 23] </ref>, ZPRISE among them, give information about the query terms that appear in the document, expecting that they can be used to help decide whether to investigate further.
References-found: 23

