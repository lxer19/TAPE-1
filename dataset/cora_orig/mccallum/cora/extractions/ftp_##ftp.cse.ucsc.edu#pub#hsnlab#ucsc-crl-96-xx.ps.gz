URL: ftp://ftp.cse.ucsc.edu/pub/hsnlab/ucsc-crl-96-xx.ps.gz
Refering-URL: http://www.cse.ucsc.edu/research/hsnlab/publications/publications_sorted_by_year.html
Root-URL: http://www.cse.ucsc.edu
Title: Two-Way TCP Traffic over ATM: Effects and Analysis  
Author: Lampros Kalampoukas Anujan Varma and K. K. Ramakrishnan 
Keyword: Rate control, TCP over ATM, congestion control, two-way traffic  
Address: Santa Cruz, CA 95064  Murray Hill, NJ 07974  
Affiliation: Board of Studies in Computer Engineering University of California, Santa Cruz  AT&T Bell Laboratories  
Date: October 1, 1996  
Pubnum: UCSC-CRL-95-??  
Abstract: We examine the performance of bidirectional TCP/IP connections over Asynchronous Transfer Mode (ATM) networks using the Available Bit Rate (ABR) service. The problem of "ack-compression" re-appears, although the queues are primarily at the end-systems. We further the understanding of the problem by quantitatively analyzing the periodic bursty behavior of the source IP queue. We are able to predict the peak values for the queue and arrive at a simple robust predictor for the degraded throughput, applicable for relatively general situations. The degradation in throughput due to bidirectional traffic can be significant. For example, even in the simple case of symmetrical connections with adequate window sizes, the throughput of each connection is only 66.67% of that under one-way traffic. We validate our analysis using simulation, where the ATM network uses the Explicit Rate option. We show that the analysis predicts the behavior of the queue and the throughput degradation not only in simple configurations, but also in more general situations, such as multiple synchronized connections between a pair of end-systems, multiple end-systems having different propagation times, and in configurations with significant amounts of cross-traffic. We observe the need to separate the flow of acknowledgments and data for the bidirectional TCP connection and for inter-leaving their processing at the end-systems to overcome the problem of ack compression. Per-VC queueing at the end-system needs to be extended one step further so that acknowledgements and data are treated separately in the network and end-systems. This research is supported by the Advanced Research Projects Agency (ARPA) under Contract No. F19628-93-C-0175 and by the NSF Young Investigator Award No. MIP-9257103. We thank MIL3 for donating to us the OPNET modeling and simulation tool. 
Abstract-found: 1
Intro-found: 1
Reference: [BF95] <author> Flavio Bonomi and Kerry W. Fendick. </author> <title> The Rate-Based Flow Control Framework for the Available Bit Rate ATM Service. </title> <journal> IEEE Network, </journal> <volume> 9(2) </volume> <pages> 25-39, </pages> <month> March/April </month> <year> 1995. </year>
Reference-contexts: The Available-Bit-Rate (ABR) service class [GC95] was defined to support delay-tolerant best-effort applications and employ rate-based feedback mechanisms to allow the sources to adjust their transmission rates to make full utilization of the available network capacity <ref> [BF95] </ref>. The rate-control framework developed by the ATM Forum allows a number of options for the switches to signal their congestion state to the source. The most promising of these, the explicit-rate marking option, is the focus of our work.
Reference: [CFF + 94] <author> Chran-Ham Chang, Dick Flower, John Forecase, Heather Gray, Bill Hawe, Ashok Nad-karni, K. K. Ramakrishnan, Uttam Shikarpur, and Kathy Wilde. </author> <title> High-Performance References 27 TCP/IP and UDP/IP Networking in DEC OSF/1 for Alpha AXP. </title> <booktitle> In Proceedings of the Third IEEE International Symposium on High Performance Distributed Computing, </booktitle> <pages> pages 35-42, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: For example, the transmission time of a 9-Kbyte packet at a link rate of 10 Mbits/second is approximately 8 msecs, while the TCP protocol processing time in real systems typically does not exceed a few hundred microseconds <ref> [Ram93, CFF + 94, ZSC91] </ref>. The effect of non-zero TCP processing time on throughput is considered in the simulation results presented in Section 5. The functionality assumed for the IP layer is simple.
Reference: [CL95] <author> Douglas E. Comer and John C. Lin. </author> <title> TCP Buffering and Performance over an ATM Network. Internetworking: </title> <journal> Research and Experience, </journal> <volume> 6 </volume> <pages> 1-13, </pages> <year> 1995. </year>
Reference-contexts: Although our analysis is focussed on TCP over ABR, the results apply equally well to TCP operating over other networks providing a steady rate, predictable delay, and in-order delivery. Several earlier studies have been reported on the behavior of TCP in ATM networks <ref> [CL95, FR94, KV95] </ref>, but none of them considers the effects of two-way traffic on TCP behavior.
Reference: [CSV96] <author> R. Cole, D. Shur, and C. Villamizar. </author> <title> IP over ATM: A Framework Document. Request for Comments (RFC): </title> <year> 1932, </year> <month> April </month> <year> 1996. </year>
Reference-contexts: The approach currently being undertaken is to map all TCP connections set up between the end-systems (in general, subnetworks containing the end-systems) to a single ATM connection <ref> [CSV96] </ref>. Synchronization among TCP connections that are transported within a common ATM virtual channel can give rise to the effects discussed above. 5.
Reference: [DWB + 93] <author> C. Dalton, G. Watson, D. Banks, C. Calamvokis, and A. Edwards. </author> <title> Afterburner (network-independent card for protocols). </title> <journal> IEEE Network, </journal> <volume> 7(4) </volume> <pages> 36-43, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Therefore, we anticipate that the TCP/IP processing overhead in a 150 SPECmark machine will be significantly lower, of the order of 50 seconds. This excludes copy and checksum overhead, which are beginning to become insignificant with hardware support in zero-copy interfaces <ref> [DWB + 93] </ref>. For our specific example, the segment transmission time at a link rate of 155 Mbits/second is t x = 0:56 msecs. Assuming a TCP processing time of 50 secs, the value of L pr is 0:09 segments.
Reference: [FJ92] <author> Sally Floyd and Van Jacobson. </author> <title> On Traffic Phase Effects in Packet-Switched Gateways. Internetworking: </title> <journal> Research and Experience, </journal> <volume> 3(3) </volume> <pages> 115-156, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: An important component of TCP is the collection of algorithms used to perform congestion control and recovery [Jac88, Jac90]. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively <ref> [FJ92, Mog92, ZC90, ZSC91] </ref>. In this paper, our interest is in analyzing the dynamics of TCP connections in an Asynchronous Transfer Mode (ATM) network in the presence of two-way traffic.
Reference: [FR94] <author> S. Floyd and A. Romanow. </author> <title> Dynamics of TCP traffic over ATM networks. </title> <booktitle> In Proceedings of ACM SIGCOMM'94, </booktitle> <pages> pages 79-88, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Although our analysis is focussed on TCP over ABR, the results apply equally well to TCP operating over other networks providing a steady rate, predictable delay, and in-order delivery. Several earlier studies have been reported on the behavior of TCP in ATM networks <ref> [CL95, FR94, KV95] </ref>, but none of them considers the effects of two-way traffic on TCP behavior.
Reference: [GC95] <author> N. Giroux and D. Chiswell. </author> <title> ATM-layer traffic management functions and procedures. </title> <booktitle> In Proceedings of INTEROP '95 Engineer Conference, </booktitle> <month> March </month> <year> 1995. </year>
Reference-contexts: Several earlier studies have been reported on the behavior of TCP in ATM networks [CL95, FR94, KV95], but none of them considers the effects of two-way traffic on TCP behavior. The Available-Bit-Rate (ABR) service class <ref> [GC95] </ref> was defined to support delay-tolerant best-effort applications and employ rate-based feedback mechanisms to allow the sources to adjust their transmission rates to make full utilization of the available network capacity [BF95].
Reference: [Jac88] <author> V. Jacobson. </author> <title> Congestion avoidance and control. </title> <booktitle> In Proceedings of ACM SIGCOMM'88, </booktitle> <pages> pages 314-329, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction The Transmission Control Protocol (TCP) has become the most widely used transport-layer protocol today, due largely to the explosive growth of the TCP/IP Internet in recent years. An important component of TCP is the collection of algorithms used to perform congestion control and recovery <ref> [Jac88, Jac90] </ref>. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively [FJ92, Mog92, ZC90, ZSC91]. In this paper, our interest is in analyzing the dynamics of TCP connections in an Asynchronous Transfer Mode (ATM) network in the presence of two-way traffic. <p> Before proceeding further, it is important to mention how ack compression originates at the end systems in the two-way environment and how it causes throughput degradation. The genesis of ack compression can be traced to the slow-start phase of a TCP connection that increases the window progressively at startup <ref> [Jac88] </ref>. The slow-start algorithm sets the initial window size to one and increases it by one with every acknowledgement received. This effectively doubles the window every round-trip time. Thus, during slow start, the receipt of every ack causes the end system to add two segments to its outgoing queue.
Reference: [Jac90] <author> Van Jacobson. </author> <title> Modified TCP Congestion Avoidance Algorithm. message to end2end-interest mailing list, </title> <month> April </month> <year> 1990. </year>
Reference-contexts: 1 Introduction The Transmission Control Protocol (TCP) has become the most widely used transport-layer protocol today, due largely to the explosive growth of the TCP/IP Internet in recent years. An important component of TCP is the collection of algorithms used to perform congestion control and recovery <ref> [Jac88, Jac90] </ref>. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively [FJ92, Mog92, ZC90, ZSC91]. In this paper, our interest is in analyzing the dynamics of TCP connections in an Asynchronous Transfer Mode (ATM) network in the presence of two-way traffic.
Reference: [KV95] <author> Lampros Kalampoukas and Anujan Varma. </author> <title> Performance of TCP over Multi-Hop ATM Networks: A Comparative Study of ATM Layer Congestion Control Schemes. </title> <booktitle> In Proceedings of ICC'95, </booktitle> <pages> pages 1472-1477, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Although our analysis is focussed on TCP over ABR, the results apply equally well to TCP operating over other networks providing a steady rate, predictable delay, and in-order delivery. Several earlier studies have been reported on the behavior of TCP in ATM networks <ref> [CL95, FR94, KV95] </ref>, but none of them considers the effects of two-way traffic on TCP behavior.
Reference: [KV96] <author> Lampros Kalampoukas and Anujan Varma. </author> <title> Analysis of Source Policy in Rate-Controlled ATM Networks. </title> <booktitle> In Proc. of ICC'96. IEEE, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: Note that the rate increase process is not smooth but consists of a sequence of steps. This is because of the gaps in the data flow during the TCP slow-start process, and has been analyzed in <ref> [KV96] </ref>. 5. Model Validation 17 each direction. at the ATM layer for the left-to-right connection. The progress for the left-to-right TCP connection is shown in Figure 5.4, in terms of the increase in TCP sequence numbers transmitted by the connection.
Reference: [KVR96] <author> Lampros Kalampoukas, Anujan Varma, and K. K. Ramakrishnan. </author> <title> Dynamics of an Explicit Rate Allocation Algorithm for ATM Networks. </title> <booktitle> In Proc. of International Broadband Communications Conference'96. </booktitle> <address> IFIP-IEEE, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: It has been shown that, by the use of a rate-allocation algorithm that maintains state, unfairness problems that occur in a datagram network due to the differences in round-trip delay of TCP connections can be avoided in an ATM network <ref> [KVR96] </ref>. 2. Dynamics of TCP in a Two-Way Traffic Environment 2 The use of ABR service with the explicit-rate option can facilitate a smooth flow of TCP traffic in the network, mitigating the effects due to interaction of traffic flows in the switches. <p> Furthermore, in the analysis of Section 3, we assume that the network provides a constant-delay path between the end nodes. Such an assumption is realistic in the ATM ABR environment when the switches employ explicit rate allocation, since the queue sizes in the switches can be maintained small <ref> [KVR96] </ref>. The queueing delays in network switches are taken into account in the simulation results of Section 5. The data segments transmitted by the TCP connection in one direction shares a common outgoing ATM virtual channel with the acks transmitted by the connection in the other direction. <p> There is one queue per output port for ABR traffic and its scheduling policy is FIFO, with each output queue being shared by all the virtual channels (VCs) sharing the outgoing link. The switches support the explicit rate allocation algorithm of Kalampoukas, et al. <ref> [KVR96] </ref>. Each of the nodes implements the ABR source policy defined by ATM Forum [Sat96]. <p> While the rate allocation algorithm converges to a steady state with a small queue (typically under 150 cells) in the unidirectional case <ref> [KVR96] </ref>, there is virtually no queueing in the switches with bidirectional TCP traffic. This is because of the idle periods on the link caused by TCP, allowing the switches to clear their queues. <p> The use of per-VC (virtual channel) queues at the end systems does not offer us a cure when the data and acks of a bidirectional TCP conversation share a common VC. In an earlier paper <ref> [KVR96] </ref> we examined the performance of TCP connections having very different round-trip times (RTT) in an ATM network. The maintenance of a current bandwidth allocation per virtual channel (VC) at the ATM switches was shown to achieve fairness in throughput superior to that in a datagram network.
Reference: [Mog92] <author> J. C. Mogul. </author> <title> Observing TCP dynamics in real networks. </title> <booktitle> In Proceedings of ACM SIGCOMM'92, </booktitle> <pages> pages 305-317, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: An important component of TCP is the collection of algorithms used to perform congestion control and recovery [Jac88, Jac90]. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively <ref> [FJ92, Mog92, ZC90, ZSC91] </ref>. In this paper, our interest is in analyzing the dynamics of TCP connections in an Asynchronous Transfer Mode (ATM) network in the presence of two-way traffic. <p> Alternatively, queueing outgoing acks at a higher priority eliminates ack compression, but requires support for message priorities in the protocol stack. This idea of processing acks at a higher priority was suggested by Mogul <ref> [Mog92] </ref> in the context of IP routers. A subject of our future work will be to investigate these and other solutions to improve the performance of two-way TCP over ATM.
Reference: [Ram93] <author> K. K. Ramakrishnan. </author> <title> Performance considerations in designing network interfaces. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 11(2) </volume> <pages> 203-219, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: For example, the transmission time of a 9-Kbyte packet at a link rate of 10 Mbits/second is approximately 8 msecs, while the TCP protocol processing time in real systems typically does not exceed a few hundred microseconds <ref> [Ram93, CFF + 94, ZSC91] </ref>. The effect of non-zero TCP processing time on throughput is considered in the simulation results presented in Section 5. The functionality assumed for the IP layer is simple. <p> Then, the TCP processing time expressed in terms of segment transmission time will be L pr = t pr =t s . We can obtain an estimate of t pr by following the guidelines in <ref> [Ram93] </ref>, where it was shown that the fixed part of the TCP, UDP and IP processing times scale well with the processor instruction execution times (or SPECmarks) of the underlying host. For a 25 SPECmark machine, the combined TCP/IP processing time for a packet is approximately 150 seconds [Ram93]. <p> guidelines in <ref> [Ram93] </ref>, where it was shown that the fixed part of the TCP, UDP and IP processing times scale well with the processor instruction execution times (or SPECmarks) of the underlying host. For a 25 SPECmark machine, the combined TCP/IP processing time for a packet is approximately 150 seconds [Ram93]. Therefore, we anticipate that the TCP/IP processing overhead in a 150 SPECmark machine will be significantly lower, of the order of 50 seconds. This excludes copy and checksum overhead, which are beginning to become insignificant with hardware support in zero-copy interfaces [DWB + 93].
Reference: [Sat96] <author> Shirish S. Sathaye. </author> <title> Traffic Management Specification, Version 4.0, ATM-Forum/95-0013R10. ATM Forum, Traffic Management Working Group, </title> <month> February </month> <year> 1996. </year>
Reference-contexts: The switches support the explicit rate allocation algorithm of Kalampoukas, et al. [KVR96]. Each of the nodes implements the ABR source policy defined by ATM Forum <ref> [Sat96] </ref>.
Reference: [SW95] <author> W. R. Stevens and Gary R. </author> <title> Wright. </title> <journal> TCP/IP Illustrated, </journal> <volume> volume 2. </volume> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1995. </year>
Reference-contexts: Therefore, to avoid packet losses at the source node, we assume that the IP queue has a size equal to the maximum window size of the sending TCP. The interaction between TCP and IP described above is consistent with the 4.4 BSD-Lite Unix Release <ref> [SW95] </ref>. 2.2 The Onset of Ack Compression We will now illustrate with an example how the window-growth process during the TCP slow-start phase leads to ack compression in a two-way configuration.
Reference: [WRM91] <author> Rick Wilder, K. K. Ramakrishnan, and Allison Mankin. </author> <title> Dynamics of Congestion Control and Avoidance of Two-Way Traffic in an OSI Testbed. </title> <journal> ACM Computer Communication Review, </journal> <volume> 21(2) </volume> <pages> 43-58, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: These packets and acknowledgements may share a common buffer in the end systems as well as network switches/routers. This sharing has been shown to result in an effect called ack compression, where acks of a connection arrive at the source bunched together <ref> [WRM91, ZSC91] </ref>. The result of ack-compression is a marked unfairness in the throughput received with competing connections, and reduced overall throughput compared to what could be expected without this effect [WRM91]. Ack compression may occur either at the end system or in a switch/router. <p> The result of ack-compression is a marked unfairness in the throughput received with competing connections, and reduced overall throughput compared to what could be expected without this effect <ref> [WRM91] </ref>. Ack compression may occur either at the end system or in a switch/router. In either case, the smooth flow of acknowledgements to the source is disturbed, potentially resulting in reduction of throughput for the TCP connections involved. <p> The effect of ack compression and the resulting dynamics of transport protocols under two-way traffic have been studied previously by Zhang, et al. [ZSC91], and by Wilder, et al. <ref> [WRM91] </ref>. Zhang, et al. [ZSC91] studied TCP dynamics under two-way traffic in a datagram network by simulation, and observed that the queues in the routers exhibit periodic behavior. Wilder, et al. [WRM91] observed a similar effect in OSI-based networks under two-way traffic causing unfairness and an overall reduction in throughput. <p> transport protocols under two-way traffic have been studied previously by Zhang, et al. [ZSC91], and by Wilder, et al. <ref> [WRM91] </ref>. Zhang, et al. [ZSC91] studied TCP dynamics under two-way traffic in a datagram network by simulation, and observed that the queues in the routers exhibit periodic behavior. Wilder, et al. [WRM91] observed a similar effect in OSI-based networks under two-way traffic causing unfairness and an overall reduction in throughput.
Reference: [ZC90] <author> Lixia Zhang and D. D. Clark. </author> <title> Oscillating Behavior of Network Traffic: A Case Study Simulation. </title> <journal> Intenetworking: Research and Experience, </journal> <volume> 1(2) </volume> <pages> 101-112, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: An important component of TCP is the collection of algorithms used to perform congestion control and recovery [Jac88, Jac90]. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively <ref> [FJ92, Mog92, ZC90, ZSC91] </ref>. In this paper, our interest is in analyzing the dynamics of TCP connections in an Asynchronous Transfer Mode (ATM) network in the presence of two-way traffic.
Reference: [ZSC91] <author> Lixia Zhang, S. Shenker, and D. D. Clark. </author> <title> Observations on the Dynamics of a Congestion Control Algorithm: The Effects of Two-Way Traffic. </title> <booktitle> In Proceedings of ACM SIGCOMM'91, </booktitle> <pages> pages 133-147, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: An important component of TCP is the collection of algorithms used to perform congestion control and recovery [Jac88, Jac90]. These algorithms give rise to a variety of interesting dynamics, some of which have been studied extensively <ref> [FJ92, Mog92, ZC90, ZSC91] </ref>. In this paper, our interest is in analyzing the dynamics of TCP connections in an Asynchronous Transfer Mode (ATM) network in the presence of two-way traffic. <p> These packets and acknowledgements may share a common buffer in the end systems as well as network switches/routers. This sharing has been shown to result in an effect called ack compression, where acks of a connection arrive at the source bunched together <ref> [WRM91, ZSC91] </ref>. The result of ack-compression is a marked unfairness in the throughput received with competing connections, and reduced overall throughput compared to what could be expected without this effect [WRM91]. Ack compression may occur either at the end system or in a switch/router. <p> In either case, the smooth flow of acknowledgements to the source is disturbed, potentially resulting in reduction of throughput for the TCP connections involved. The effect of ack compression and the resulting dynamics of transport protocols under two-way traffic have been studied previously by Zhang, et al. <ref> [ZSC91] </ref>, and by Wilder, et al. [WRM91]. Zhang, et al. [ZSC91] studied TCP dynamics under two-way traffic in a datagram network by simulation, and observed that the queues in the routers exhibit periodic behavior. <p> The effect of ack compression and the resulting dynamics of transport protocols under two-way traffic have been studied previously by Zhang, et al. <ref> [ZSC91] </ref>, and by Wilder, et al. [WRM91]. Zhang, et al. [ZSC91] studied TCP dynamics under two-way traffic in a datagram network by simulation, and observed that the queues in the routers exhibit periodic behavior. Wilder, et al. [WRM91] observed a similar effect in OSI-based networks under two-way traffic causing unfairness and an overall reduction in throughput. <p> For example, the transmission time of a 9-Kbyte packet at a link rate of 10 Mbits/second is approximately 8 msecs, while the TCP protocol processing time in real systems typically does not exceed a few hundred microseconds <ref> [Ram93, CFF + 94, ZSC91] </ref>. The effect of non-zero TCP processing time on throughput is considered in the simulation results presented in Section 5. The functionality assumed for the IP layer is simple.
References-found: 20

