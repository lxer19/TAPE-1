URL: http://www.cs.ubc.ca/spider/pope/EVL-Chapter.ps.gz
Refering-URL: http://www.cs.ubc.ca/spider/pope/EVL-Chapter.html
Root-URL: 
Title: 1 Learning Object Recognition Models from Images  
Author: Tomaso Poggio and Shree Nayar. Arthur R. Pope and David G. Lowe 
Affiliation: University of British Columbia  
Date: January 1995  
Note: To appear in Early Visual Learning, edited by  
Abstract: To recognize an object in an image one must have an internal model of how that object may appear. We describe a method for learning such models from training images. An object is modeled by a probability distribution describing the range of possible variation in the object's appearance. This distribution is organized on two levels. Large variations are handled by partitioning the training images into clusters that correspond to distinctly different views of the object. Within each cluster, smaller variations are represented by distributions that characterize the presence, position, and measurements of various discrete features of appearance. The learning process combines an incremental conceptual clustering algorithm for forming the clusters with a generalization algorithm for consolidating each cluster's training images into a single description. Recognition employs information about feature positions, numeric measurements, and relations in order to constrain and speed the search. Preliminary experiments have been conducted with a system that implements some aspects of the method; the system can learn to recognize a single characteristic view of an object in the presence of occlusion and clutter.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Ayache and O. D. Faugeras. </author> <title> HYPER: A new approach for the recognition and positioning of two-dimensional objects. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> PAMI-8(1):44-54, </volume> <month> Jan. </month> <year> 1986. </year>
Reference-contexts: solution that is optimal in the least-squares sense can be found by least-squares estimation, as described in section 4.2. 3 Match Quality Measure Recognition requires finding a consistent set of pairings between some model features and some image features, plus a viewpoint transformation that brings the 1 Ayache and Faugeras <ref> [1] </ref>, among others, have also used this formulation to express the transformation as a linear operation. 8 POPE AND LOWE paired features into close correspondence. Together, the pairings and transformation are called a match. <p> It does not seem possible to find an optimal match through anything less than exhaustive search. In practice, however, good matches can be found quickly by iterative alignment <ref> [1, 13, 15] </ref>.
Reference: [2] <author> R. Basri. </author> <title> Recognition by prototypes. </title> <booktitle> In Proc. Conf. Comput. Vision and Patt. Recognit., </booktitle> <pages> pages 161-167, </pages> <year> 1993. </year>
Reference-contexts: It uses the matching procedure to determine correspondences among the cluster's images. An important aspect of the recognition learning problem this work has not addressed is how a database of acquired model graphs should be organized and accessed. Possibilities include organizing the model graphs hierarchically <ref> [2, 26] </ref>, or using selected high-level features and their attributes to index the collection of model graphs. This issue is presently beyond the scope of our own work, however.
Reference: [3] <author> G. J. Bierman. </author> <title> Factorization Methods for Discrete Sequential Estimation. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: We need to refine the transformation estimate with each new pairing or group of pairings 1. LEARNING OBJECT RECOGNITION MODELS 17 adopted so that an improved estimate can then be used to identify additional pairings. Thus a recursive estimator is used. The square root information filter (SRIF) <ref> [3] </ref> is a recursive estimator well suited for this problem. Compared to the Kalman filter it is numerically more stable and faster for batched measurements; it also has the nice property of computing the total residual error as a side effect.
Reference: [4] <author> R. Brunelli and T. Poggio. </author> <title> HyperBF networks for real object recognition. </title> <booktitle> In Proc. Int. Joint Conf. Artificial Intell., </booktitle> <volume> volume 2, </volume> <pages> pages 1278-1284, </pages> <year> 1991. </year>
Reference-contexts: Neural networks, including radial basis function networks, have been used as trainable classifiers for object recognition (e.g., <ref> [4] </ref>). In this role, the network approximates a function that maps a vector of feature measurements to an object identifier, or to a vector of graded yes/no responses, one per object.
Reference: [5] <author> R. Brunelli and T. Poggio. </author> <title> Face recognition: Features versus templates. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 15(10) </volume> <pages> 1042-1052, </pages> <month> Oct. </month> <year> 1993. </year>
Reference-contexts: Nearest neighbor classifiers, which make fewer assumptions, are also commonly used. Rare are comparative evaluations of how various classifier/feature space 1. LEARNING OBJECT RECOGNITION MODELS 25 combinations perform on object recognition problems (such as <ref> [5] </ref>). The most difficult aspect of this approach seems to be deriving appropriate feature vectors from cluttered images. 7.3 Learning a structural model A structural model explicitly represents both shape primitives and their spatial relationships.
Reference: [6] <author> J. H. Connell and M. Brady. </author> <title> Generating and generalizing models of visual objects. </title> <journal> Artificial Intell., </journal> <volume> 31 </volume> <pages> 159-183, </pages> <year> 1987. </year> <title> 1. LEARNING OBJECT RECOGNITION MODELS 29 </title>
Reference-contexts: In general, a structural model is learned from training images by first obtaining structural descriptions from each image, and then inducing a generalization covering those descriptions. Connell and Brady <ref> [6] </ref> have described a system that learns structural models for recognizing 2-D objects in intensity images. The system incorporates many interesting ideas. They use graphs to represent the part/whole and adjacency relations among object regions described by smoothed local symmetries (ribbon shapes).
Reference: [7] <author> R. L. Delanoy, J. G. Verly, and D. E. Dudgeon. </author> <title> Automatic building and supervised discrimination learning of appearance models of 3-D objects. </title> <booktitle> In SPIE Proc. </booktitle> <volume> Vol. 1708: </volume> <booktitle> Applications of Artificial Intell. X: Machine Vision and Robotics, </booktitle> <pages> pages 549-560, </pages> <year> 1992. </year>
Reference-contexts: We would expect both these method to be sensitive 24 POPE AND LOWE to clutter in the training images and to parameters of the clustering algorithm. Delanoy, Verly, and Dudgeon <ref> [7] </ref> and Fichera et al. [10] have described object recognition systems that induce fuzzy predicates from training images. Their systems represent models as logical formulae, and, therefore, the systems need appropriate predicates. These are invented by clustering measurements of low-level primitives that have been recovered from training images.
Reference: [8] <author> B. Draper. </author> <title> Learning Object Recognition Strategies. </title> <type> PhD thesis, </type> <institution> Univ. of Massachusetts, </institution> <address> Amherst, Mass., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Our method, in comparison, uses a clustering measure based on objective performance goals (accuracy and efficiency), and an appearance representation less affected by occlusion. 7.5 Learning a recognition strategy Draper <ref> [8] </ref> has considered how a system equipped with a variety of special-purpose representations and algorithms might learn strategies for employing those techniques to recognize specific objects. A typical recognition task would be to locate a tree by fitting a parabola to the top of its crown.
Reference: [9] <author> S. Edelman. </author> <title> On learning to recognize 3-D objects from examples. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 15(8) </volume> <pages> 833-837, </pages> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: Then the concept consisting of all instances not matching some unknown template is not PAC-learnable. Shvayster speculates that some nonlearn-able concepts may become learnable, however, if some prior knowledge about the distribution of examples is available. Edelman <ref> [9] </ref> has argued that Shvayster's negative result is not applicable to object recognition because it uses an instance representation, the binary image, that is inappropriate.
Reference: [10] <author> O. Fichera, P. Pellegretti, F. Roli, and S. B. Serpico. </author> <title> Automatic acquisition of visual models for image recognition. </title> <booktitle> In Proc. IAPR Int. Conf. Patt. Recognit., </booktitle> <volume> volume 1, </volume> <pages> pages 95-98, </pages> <year> 1992. </year>
Reference-contexts: We would expect both these method to be sensitive 24 POPE AND LOWE to clutter in the training images and to parameters of the clustering algorithm. Delanoy, Verly, and Dudgeon [7] and Fichera et al. <ref> [10] </ref> have described object recognition systems that induce fuzzy predicates from training images. Their systems represent models as logical formulae, and, therefore, the systems need appropriate predicates. These are invented by clustering measurements of low-level primitives that have been recovered from training images.
Reference: [11] <author> D. H. Fisher. </author> <title> Knowledge acquisition via incremental conceptual clustering. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 139-172, </pages> <year> 1987. </year>
Reference-contexts: Clustering is incremental in that, as each training image is acquired, it is assigned to an existing cluster or used to form a new one. Like other conceptual clustering algorithms (e.g., cobweb <ref> [11] </ref>), the algorithm uses a global measure of overall clustering quality to guide clustering decisions. This measure is chosen to promote and balance two somewhat-conflicting qualities.
Reference: [12] <author> P. Gros. </author> <title> Matching and clustering: Two steps towards automatic object model generation in computer vision. </title> <booktitle> In Proc. AAAI Fall Symp.: Machine Learning in Comput. Vision, </booktitle> <year> 1993. </year>
Reference-contexts: One can cluster the training images (a form of unsupervised learning) to create one characteristic view from each cluster. While several researchers have done this with images rendered from CAD models, thus avoiding the feature correspondence problem, Gros <ref> [12] </ref> and Seibert and Waxman [25] have clustered real images. Gros measures the similarity of an image pair as the proportion of matching shape primitives, whereas Seibert and Waxman use a vector clustering algorithm with fixed-length vectors encoding global appearance.
Reference: [13] <author> D. P. Huttenlocher and S. Ullman. </author> <title> Recognizing solid objects by alignment with an image. </title> <journal> Int. J. Comput. Vision, </journal> <volume> 5(2) </volume> <pages> 195-212, </pages> <month> Nov. </month> <year> 1990. </year>
Reference-contexts: It does not seem possible to find an optimal match through anything less than exhaustive search. In practice, however, good matches can be found quickly by iterative alignment <ref> [1, 13, 15] </ref>.
Reference: [14] <author> A. K. Jain and R. Hoffman. </author> <title> Evidence-based recognition of 3-D objects. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 10(6) </volume> <pages> 783-801, </pages> <month> Nov. </month> <year> 1988. </year>
Reference-contexts: Jain and Hoffman <ref> [14] </ref> describe a system that learns rules for classifying objects in range images. The instances classified by their system are sets of shape primitives with associated measurements. The classifier applies a series of rules, each contributing evidence for or against various classifications.
Reference: [15] <author> D. G. Lowe. </author> <title> The viewpoint consistency constraint. </title> <journal> Int. J. Comput. Vision, </journal> <volume> 1 </volume> <pages> 57-72, </pages> <year> 1987. </year>
Reference-contexts: It does not seem possible to find an optimal match through anything less than exhaustive search. In practice, however, good matches can be found quickly by iterative alignment <ref> [1, 13, 15] </ref>.
Reference: [16] <author> B. A. McArthur. </author> <title> Incremental Synthesis of Three-Dimensional Object Models Using Random Graphs. </title> <type> PhD thesis, </type> <institution> Univ. of Waterloo, </institution> <year> 1991. </year>
Reference-contexts: A random graph is synthesized from examples by repeatedly merging the two nearest graphs. This learning method seems to have been demonstrated only with 2-D recognition problems and clean, synthetic images. However, McArthur <ref> [16] </ref> has extended the random graph formalism to allow continuous attributes, and he has used it to learn 3-D, object-centered models from images 26 POPE AND LOWE with known viewpoints.
Reference: [17] <author> H. Murase and S. K. Nayar. </author> <title> Learning and recognition of 3-D objects from brightness images. </title> <booktitle> In Proc. AAAI Fall Symp.: Machine Learning in Comput. Vision, </booktitle> <pages> pages 25-29, </pages> <year> 1993. </year>
Reference-contexts: Their systems represent models as logical formulae, and, therefore, the systems need appropriate predicates. These are invented by clustering measurements of low-level primitives that have been recovered from training images. Turk and Pentland [29] and Murase and Nayar <ref> [17] </ref> have induced features using principle component analysis. They compute the several most significant eigenvectors, or principle components, of the set of training images. Since these few eigenvectors span much of the subspace containing the training images, they can be used to concisely describe those images and others like them.
Reference: [18] <author> A. R. Pope and D. G. Lowe. </author> <title> Learning 3D object recognition models from 2D images. </title> <booktitle> In Proc. AAAI Fall Symp.: Machine Learning in Comput. Vision, </booktitle> <year> 1993. </year>
Reference-contexts: Section 7 discusses relevant work by others on this and similar problems, and section 8 summarizes the chapter's main ideas. Sections flagged by y contain technical details that can be safely skipped on a first reading. More information may be found in other recent publications <ref> [18, 19, 20] </ref>. 2 Representation Schemes 2.1 Image representation We represent an image in terms of discrete properties called features. Each feature has a particular type, a location within the image, and a vector of numeric attributes that further characterize it.
Reference: [19] <author> A. R. Pope and D. G. Lowe. </author> <title> Learning object recognition models from images. </title> <booktitle> In Proc. Int. Conf. Comput. Vision, </booktitle> <pages> pages 296-301, </pages> <year> 1993. </year>
Reference-contexts: Section 7 discusses relevant work by others on this and similar problems, and section 8 summarizes the chapter's main ideas. Sections flagged by y contain technical details that can be safely skipped on a first reading. More information may be found in other recent publications <ref> [18, 19, 20] </ref>. 2 Representation Schemes 2.1 Image representation We represent an image in terms of discrete properties called features. Each feature has a particular type, a location within the image, and a vector of numeric attributes that further characterize it. <p> Features Paired is the proportion of model features paired. Match Quality is the value of the match quality measure, g (E; T ). Adapted from <ref> [19] </ref>. features. Some differences are due to shifts in the relative positions of features with changing viewpoint|the seat and post remain fixed, for example, while the legs shift in various directions. <p> LEARNING OBJECT RECOGNITION MODELS 23 A and Bottle B are from model features corresponding to the lower left corners of bottles A and B. Spikes represent the two populations of sample values from which these distributions are estimated. The distribution labeled Milieu averages all corners from numerous images. From <ref> [19] </ref>. 7.1 Learning appearance primitives An object recognition system may learn new types of shape or appearance primitives to use in describing objects. Typically this is done by clustering existing primitives or groups of them, and then associating new primitives with the clusters that have been found.
Reference: [20] <author> A. R. Pope and D. G. Lowe. </author> <title> Modeling positional uncertainty in object recognition. </title> <type> Technical Report 94-32, </type> <institution> Dept. of Computer Science, Univ. of B.C., </institution> <month> Nov. </month> <year> 1994. </year> <note> WWW http://www.cs.ubc.ca/tr/1994/TR-94-32. </note>
Reference-contexts: Section 7 discusses relevant work by others on this and similar problems, and section 8 summarizes the chapter's main ideas. Sections flagged by y contain technical details that can be safely skipped on a first reading. More information may be found in other recent publications <ref> [18, 19, 20] </ref>. 2 Representation Schemes 2.1 Image representation We represent an image in terms of discrete properties called features. Each feature has a particular type, a location within the image, and a vector of numeric attributes that further characterize it.
Reference: [21] <author> A. R. Pope and D. G. Lowe. </author> <title> Vista: A software environment for computer vision research. </title> <booktitle> In Proc. Conf. Comput. Vision and Patt. Recognit., </booktitle> <pages> pages 768-772, </pages> <year> 1994. </year> <note> WWW http://www.cs.ubc.ca/nest/lci/vista/vista.html. 30 POPE AND LOWE </note>
Reference-contexts: have been processed in this way the model graph nears an equilibrium, containing the most consistent features with representative populations of sample attribute vectors and positions for each. 6 Experimental Results A system that learns a single, characteristic view has been implemented using facilities of the Vista computer vision environment <ref> [21] </ref>; implementation of the clustering procedure needed to learn multiple views is in progress. The system recognizes 3-D objects in 2-D intensity images, employing a repertoire of features designed to describe the appearance of manufactured objects. Straight and circular segments of intensity edges are the lowest-level features.
Reference: [22] <author> J. Rissanen. </author> <title> A universal prior for integers and estimation by minimum description length. </title> <journal> Ann. Statist., </journal> <volume> 11(2) </volume> <pages> 416-431, </pages> <year> 1983. </year>
Reference-contexts: The prior distribution P (M) can be designed to favor simple models, while the conditional distribution P (X j M) can be designed to favor models that characterize the training images accurately. * Prior distribution. We apply the minimum description length (MDL) principle <ref> [22] </ref> to define a prior distribution favoring simple models. Briefly, the MDL principle provides a method of constructing a prior probability distribution over a family of statistical models by relating the probability of each to the length of its description as written in some minimal-length encoding scheme.
Reference: [23] <author> E. Saund. </author> <title> Labeling of curvilinear structure across scales by token grouping. </title> <booktitle> In Proc. Conf. Comput. Vision and Patt. Recognit., </booktitle> <pages> pages 257-263, </pages> <year> 1992. </year>
Reference-contexts: Attributes are expressed so that they are invariant with respect to translation, rotation, and scaling of the feature within the image (using, for example, scale-normalized measures <ref> [23] </ref>). The repertoire of feature types must be sufficient to provide a rich description of any relevant image. A degree of redundancy is desirable, for it helps to ensure the completeness of the representation and it contributes stability.
Reference: [24] <author> J. Segen. </author> <title> Model learning and recognition of nonrigid objects. </title> <booktitle> In Proc. Conf. Comput. Vision and Patt. Recognit., </booktitle> <pages> pages 597-602, </pages> <year> 1989. </year>
Reference-contexts: New primitives thus represent particular configurations or abstractions of existing ones. The new configurations may improve the representation's descriptive power, and the new abstractions may allow more appropriate generalizations. Segen <ref> [24] </ref> has demonstrated this approach with a system that learns a representation for 2-D contours. The system's lowest-level primitives are distinguished points, such as curvature extrema, found on contours in training images. <p> In comparison, our formalism incorporates continuous attributes more easily using likelihoods rather than entropies, and our learning method does not require knowledge of viewpoint or feature correspondences. In Segen's system <ref> [24] </ref> for recognizing 2-D shapes, a graph node represents a relation among shape primitives, which are oriented point features (see page 23). But instead of specifying a particular relation, a node in the model graph specifies a probability distribution over possible relations.
Reference: [25] <author> M. Seibert and A. M. Waxman. </author> <title> Adaptive 3-D object recognition from multiple views. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 14(2) </volume> <pages> 107-124, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: One can cluster the training images (a form of unsupervised learning) to create one characteristic view from each cluster. While several researchers have done this with images rendered from CAD models, thus avoiding the feature correspondence problem, Gros [12] and Seibert and Waxman <ref> [25] </ref> have clustered real images. Gros measures the similarity of an image pair as the proportion of matching shape primitives, whereas Seibert and Waxman use a vector clustering algorithm with fixed-length vectors encoding global appearance.
Reference: [26] <author> K. Sengupta and K. L. Boyer. </author> <title> Information theoretic clustering of large structural modelbases. </title> <booktitle> In Proc. Conf. Comput. Vision and Patt. Recognit., </booktitle> <pages> pages 174-179, </pages> <year> 1993. </year>
Reference-contexts: It uses the matching procedure to determine correspondences among the cluster's images. An important aspect of the recognition learning problem this work has not addressed is how a database of acquired model graphs should be organized and accessed. Possibilities include organizing the model graphs hierarchically <ref> [2, 26] </ref>, or using selected high-level features and their attributes to index the collection of model graphs. This issue is presently beyond the scope of our own work, however.
Reference: [27] <author> H. Shvayster. </author> <title> Learnable and nonlearnable visual concepts. </title> <journal> IEEE Trans. Patt. Anal. Mach. Intell., </journal> <volume> 12(5) </volume> <pages> 459-466, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Significantly, the algorithm has no prior knowledge about the distribution of examples. Shvayster <ref> [27] </ref> has shown that some classes of concepts defined on binary images are not PAC-learnable from positive examples by any algorithm.
Reference: [28] <author> B. W. Silverman. </author> <title> Density Estimation for Statistics and Data Analysis. </title> <publisher> Chap-man and Hall, </publisher> <address> London, </address> <year> 1986. </year>
Reference-contexts: However, the attribute vector distributions could be complex as they depend not only on sensor noise and measurement errors, but also on systematic variations in object shape, lighting, and pose. Hence we use a non-parametric estimation method <ref> [28] </ref>. In its simplest, form, this method estimates probability density by summing contributions from a series of overlapping kernels. The density at x is given by ^ f (x) = nh d i h ; (9) where h is a constant smoothing factor, and K is a kernel function.
Reference: [29] <author> M. A. Turk and A. P. Pentland. </author> <title> Face recognition using eigenfaces. </title> <booktitle> In Proc. Conf. Comput. Vision and Patt. Recognit., </booktitle> <pages> pages 586-591, </pages> <year> 1991. </year>
Reference-contexts: Their systems represent models as logical formulae, and, therefore, the systems need appropriate predicates. These are invented by clustering measurements of low-level primitives that have been recovered from training images. Turk and Pentland <ref> [29] </ref> and Murase and Nayar [17] have induced features using principle component analysis. They compute the several most significant eigenvectors, or principle components, of the set of training images.
Reference: [30] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Commun. ACM, </journal> <volume> 27 </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: These efforts are based on the analogy that learning to recognize an object from images is like learning a concept from examples. Valiant <ref> [30] </ref> has provided a useful definition for characterizing the class of concepts that can be learned by a particular algorithm: Informally, a class is probably approximately correct (PAC) learnable by an algorithm if, with high probability, the algorithm learns a concept that correctly classifies a high proportion of examples using polynomially
Reference: [31] <author> J. J. Weng, N. Ahuja, and T. S. Huang. </author> <title> Learning recognition and segmentation of 3-D objects from 2-D images. </title> <booktitle> In Proc. Int. Conf. Comput. Vision, </booktitle> <pages> pages 121-128, </pages> <year> 1993. </year>
Reference-contexts: Consequently, each new primitive describes a commonly observed configuration of two distinguished points. The induction process is repeated with these new primitives to generate higher-level primitives describing groups of four, eight, and more distinguished points. Weng et al.'s Cresceptron system <ref> [31] </ref> is analogous in that it induces a hierarchy of primitives within a pre-programmed framework. Since these primitives are essentially templates, invariance to translation, rotation, and scaling in the image must be provided by prior segmentation or by an attentional mechanism.

References-found: 31

