URL: http://robotics.eecs.berkeley.edu/~mayi/psfile/MTNS98.ps.gz
Refering-URL: http://robotics.eecs.berkeley.edu/~mayi/publication.html
Root-URL: 
Email: fmayi,janka,sastryg@robotics.eecs.berkeley.edu  
Title: Optimal Motion From Image Sequences: A Riemannian Viewpoint  
Author: Yi Ma Jana Kosecka Shankar Sastry 
Keyword: epipolar constraint, essential manifold, optical flow, Stiefel manifolds, Grassmann manifolds, Newton algorithm.  
Address: Berkeley, CA 94720-1774  
Affiliation: Electronics Research Laboratory University of California at Berkeley  
Abstract: Motion recovery from image correspondences is typically a problem of optimizing an objective function associated with the epipolar (or Longuet-Higgins) constraint. This objective function is defined on the so called essential manifold, which has a nice intrinsic Riemannian structure. Based on existing optimization techniques on Riemannian manifolds, in particular on Stiefel or Grass-mann manifolds, we propose a Riemannian Newton algorithm to solve the motion recovery problem, making use of the natural geometric structure of the essential manifold. The same ideas also apply to conjugate gradient based algorithms. The proposed geometric algorithms have quadratic rates of convergence. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> William M. Boothby. </author> <title> An Introduction to Differential Manifolds and Riemannian Geometry. </title> <publisher> Academic Press, </publisher> <address> second edition, </address> <year> 1986. </year>
Reference-contexts: This paper relies on familiarity with Edelman et al's work [2] and some background of modern Riemannian geometry (a good reference for Riemannian geometry is Boothby <ref> [1] </ref>). Section 2 shows how to generalize optimization schemes on single Riemannian manifold to their product space. Section 3 then studies the intrinsic Rie-mannian structure of the essential manifold (the space of all essential matrices). <p> T (SO (3)). The tangent space of SO (3) at the identity is simply its Lie algebra so (3). Since SO (3) is a compact Lie group, it has an intrinsic bi-invariant metric <ref> [1] </ref> (such metric is unique up to a constant scale).
Reference: [2] <author> Alan Edelman, Tomas Arias, and Steven T. Smith. </author> <title> The geometry of algorithms with orthogonality constraints. </title> <note> SIAM J. Matrix Analysis Applications, to appear. </note>
Reference-contexts: Consequently, in these algorithms, solving for optimal updating direction typically involved using Lagrangian multipliers to deal with the constraints on the search space; and "walking" on such space was done approximately by the update-then-project procedure. Due to recent developments in optimization techniques on Riemannian manifolds <ref> [11, 2] </ref>, in this paper we give a top level mathematical view for the nonlinear optimization problem associated with the motion recovery and using Newton's method as an example, show how to apply the optimization theory on Riemannian manifolds to solve this problem by using the intrinsic Riemannian structure of the <p> This paper relies on familiarity with Edelman et al's work <ref> [2] </ref> and some background of modern Riemannian geometry (a good reference for Riemannian geometry is Boothby [1]). Section 2 shows how to generalize optimization schemes on single Riemannian manifold to their product space. <p> Recent developments in optimization algorithms on Riemannian manifolds have provided geometric insights for generalization of Newton and conjugate gradient methods to certain classes of Riemannian manifolds. Smith [11] gave a detailed treatment of the general theory of optimization on Riemannian manifolds; Edelman, Arias and Smith <ref> [2] </ref> then studied the case where the Riemannian manifolds are Stiefel and Grassmann manifolds, and presented a uniform geometric framework for Newton and conjugate gradient algorithms on Stiefel and Grassmann manifolds. <p> Previous algorithms for solving such problems were application dependent: the performance of proposed algorithms relied on particular parameterization chosen for the submanifold M and also depended on certain approximation schemes applied to update the states on the search space. However, the new results of <ref> [2] </ref> show that, on Stiefel or Grassmann manifolds, one may make use of the canonical Riemannian structure of these manifolds and systematically develop Newton and conjugate gradient methods on them. <p> for the derivation of this algo rithm as well as a discussion of applying the Riemannian Newton algorithm to the differential case. 5 Discussions and Future Work We only applied Newton's method which to the motion recovery problem has the fastest convergence rate (among algorithms using second order information, see <ref> [2] </ref> for a comparison). In fact, the application of other conjugate gradient algorithms would be easier since they usually only involve the calculation of the first order information (the gradient, not Hessian), at the cost of slower convergence rate.
Reference: [3] <author> B. Horn. </author> <title> Relative orientation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4 </volume> <pages> 59-78, </pages> <year> 1990. </year>
Reference-contexts: Further analysis of linear techniques reveals inherent bias in the translation estimate [4]. The performance of the numerical optimization techniques which use nonlinear objective function has been shown superior to the linear ones. Different objective function has been proposed by Horn <ref> [3] </ref>, where instead of minimizing directly the essential (coplanar) constraint the objective function expresses the true errors in relative orientation (i.e. translation and rotation). Horn proposed an iterative procedure where the update of the estimate takes into account the or-thonormal constraint of the unknown rotation. <p> Even from the efforts which rightly concentrated on the noise related aspects of the problem (i.e. trying different nonlinear objective functions etc.) none of the existing algorithms truly took advantage of the underlying geometrical structure of the problem. The underlying search space was usually parameterized for computational convenience <ref> [3, 12, 10] </ref> instead of being consistent to its intrinsic geometric structure. Consequently, in these algorithms, solving for optimal updating direction typically involved using Lagrangian multipliers to deal with the constraints on the search space; and "walking" on such space was done approximately by the update-then-project procedure. <p> In this sense, such algorithms will be different from other existing algorithms which make use of particular parameterizations of the underlying search space, such as quaternions <ref> [3, 12, 5, 10] </ref>. One may refer to Ma, Koscka and Sastry [9] for a detailed study of the Riemannian Newton algorithm for optimizing a general objective function on the normalized essential manifold.
Reference: [4] <author> A. D. Jepson and D. J. Heeger. </author> <title> Linear subspace methods for recovering translation direction. Spatial Vision in Humans and Robots, </title> <publisher> Cambridge Univ. Press, </publisher> <pages> pages 39-62, </pages> <year> 1993. </year>
Reference-contexts: The appeal of linear algorithms (for discrete case [10] and for differential case [7]) is the closed form solution to the problem which in the absence of noise provides true solution of the motion. Further analysis of linear techniques reveals inherent bias in the translation estimate <ref> [4] </ref>. The performance of the numerical optimization techniques which use nonlinear objective function has been shown superior to the linear ones.
Reference: [5] <author> Kenichi Kanatani. </author> <title> Geometric Computation for Machine Vision. </title> <publisher> Oxford Science Publications, </publisher> <year> 1993. </year>
Reference-contexts: In this sense, such algorithms will be different from other existing algorithms which make use of particular parameterizations of the underlying search space, such as quaternions <ref> [3, 12, 5, 10] </ref>. One may refer to Ma, Koscka and Sastry [9] for a detailed study of the Riemannian Newton algorithm for optimizing a general objective function on the normalized essential manifold.
Reference: [6] <author> H. C. Longuet-Higgins. </author> <title> A computer algorithm for reconstructing a scene from two projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: 1 Introduction The problem of recovering structure and motion from a sequence of images has been one of the central problems in computer vision over the past decade and has been studied extensively from various perspectives. The seminal work of Longuet-Higgins <ref> [6] </ref> on characterization of so called epipolar constraint, enabled decoupling of the structure and motion problems and led to the development of numerous linear and nonlinear algorithms for motion estimation (see [10, 13] for overviews).
Reference: [7] <author> Yi Ma, Jana Kosecka, and Shankar Sastry. </author> <title> Motion recovery from image sequences: Discrete viewpoint vs. differential viewpoint. </title> <booktitle> In Proceeding of European Conference on Computer Vision, </booktitle> <volume> Volume II, </volume> <pages> pages 337-53, </pages> <year> 1998. </year>
Reference-contexts: The epipolar constraint has been formulated both in discrete and differential setting and the recent work of the authors <ref> [7] </ref> demonstrated the possibility of the parallel development of linear algorithms for both cases: that of point feature measurements and optical flow. The appeal of linear algorithms (for discrete case [10] and for differential case [7]) is the closed form solution to the problem which in the absence of noise provides <p> been formulated both in discrete and differential setting and the recent work of the authors <ref> [7] </ref> demonstrated the possibility of the parallel development of linear algorithms for both cases: that of point feature measurements and optical flow. The appeal of linear algorithms (for discrete case [10] and for differential case [7]) is the closed form solution to the problem which in the absence of noise provides true solution of the motion. Further analysis of linear techniques reveals inherent bias in the translation estimate [4]. <p> However they do not make a connection and full exploitation of the differential geometric properties of the entire space of essential matrices as characterized in our recent paper <ref> [7] </ref>. Even from the efforts which rightly concentrated on the noise related aspects of the problem (i.e. trying different nonlinear objective functions etc.) none of the existing algorithms truly took advantage of the underlying geometrical structure of the problem.
Reference: [8] <author> Yi Ma, Jana Kosecka, and Shankar Sastry. </author> <title> Motion recovery from image sequences: Discrete viewpoint vs. differential viewpoint. </title> <institution> Electronic Research Laboratory Memorandum, UC Berkeley, UCB/ERL M98/11, </institution> <month> February </month> <year> 1998. </year>
Reference-contexts: and geodesics in the product space can be reduced to those for each factor manifold. 3 Riemannian Structure of the Essential Manifold In this section we study the intrinsic Riemannian structure of the essential manifold, which plays an important role in the motion recovery from image correspondences (for details see <ref> [8] </ref>). <p> However, the unit tangent bundle T 1 (SO (3)) is not exactly the normalized essential manifold E 1 . Indeed, T 1 (SO (3)) is a double covering of the normalized essential space E 1 , i.e. E 1 = T 1 (SO (3))=Z 2 (for details see <ref> [8] </ref>). <p> Please refer to the full version of the paper [9] for the proof. It is not just a coincidence that the conditions for the Hessian to be non-degenerate are exactly the same as that for the eight-point linear algorithm (see <ref> [10, 8] </ref>) to have a unique solution. A heuristic explanation is that the objective function here is a quadratic form of the epipolar constraint which the linear algorithm is directly based on. Now assume that the Hessian is non-degenerate.
Reference: [9] <author> Yi Ma, Jana Kosecka, and Shankar Sastry. </author> <title> Optimal motion from image sequences: A riemannian viewpoint. </title> <institution> Electronic Research Laboratory Memorandum, UC Berkeley, UCB/ERL M98/37, </institution> <month> June </month> <year> 1998. </year>
Reference-contexts: Section 5 gives the (Rieman-nian) Newton algorithm for optimizing the least square objective function associated with motion recovery. More details are given in the full version of this paper Ma, Kosecka and Sastry <ref> [9] </ref>. 2 Optimization on Riemannian Manifold Preparation Newton and conjugate gradient methods are classical nonlinear optimization techniques used to minimize a function f (x), where x belongs to an open subset of Eu-clidean space R n . <p> The following theorem guarantees that Edelman et al's methods can be easily generalized to any product of Stiefel (or Grassmann) manifolds (for a detailed discussion of the Riemannian structure on a product space, one may refer to Ma, Kosecka and Sastry <ref> [9] </ref>). Theorem 1 Consider M = M 1 fi M 2 the product Rie-mannian manifold of M 1 and M 2 . <p> The proof of this theorem is referred to the full version of the paper Ma, Koscka and Sastry <ref> [9] </ref>. However, the unit tangent bundle T 1 (SO (3)) is not exactly the normalized essential manifold E 1 . Indeed, T 1 (SO (3)) is a double covering of the normalized essential space E 1 , i.e. E 1 = T 1 (SO (3))=Z 2 (for details see [8]). <p> T 1 (SO (3)) ! E 1 The inverse of this map is given by: h 1 (R b S) = (R; R b S); (R exp ( b S); R b S) : For an intrinsic geometric interpretation of this double covering, one may refer to the full paper <ref> [9] </ref>. If we take for E 1 the Riemannian structure induced from the covering map h, the original optimization problem of optimizing a function F (E) on E 1 is equivalent to optimizing F (R; S) on T 1 (SO (3)). <p> In this sense, such algorithms will be different from other existing algorithms which make use of particular parameterizations of the underlying search space, such as quaternions [3, 12, 5, 10]. One may refer to Ma, Koscka and Sastry <ref> [9] </ref> for a detailed study of the Riemannian Newton algorithm for optimizing a general objective function on the normalized essential manifold. <p> Its Hessian is non-degenerate in a neighborhood of the optimal solution if there is a unique (up to a scale) solution to the system of linear equations: p T If so, the Riemannian Newton algorithm has quadratic rate of convergence. Please refer to the full version of the paper <ref> [9] </ref> for the proof. It is not just a coincidence that the conditions for the Hessian to be non-degenerate are exactly the same as that for the eight-point linear algorithm (see [10, 8]) to have a unique solution. <p> One may refer to <ref> [9] </ref> for the derivation of this algo rithm as well as a discussion of applying the Riemannian Newton algorithm to the differential case. 5 Discussions and Future Work We only applied Newton's method which to the motion recovery problem has the fastest convergence rate (among algorithms using second order information, see <p> For the motion recovery problem, one can use linear algorithms to get a close guess for the optimal motion and use it for initializing the proposed nonlinear algorithm. Simulation results of the proposed algorithms can be found in the full report <ref> [9] </ref>. Detailed study of the performance of the proposed algorithm and its sensitivity to noise on synthetic and real images is currently in progress.
Reference: [10] <author> Stephen Maybank. </author> <title> Theory of Reconstruction from Image Motion. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: The seminal work of Longuet-Higgins [6] on characterization of so called epipolar constraint, enabled decoupling of the structure and motion problems and led to the development of numerous linear and nonlinear algorithms for motion estimation (see <ref> [10, 13] </ref> for overviews). The epipolar constraint has been formulated both in discrete and differential setting and the recent work of the authors [7] demonstrated the possibility of the parallel development of linear algorithms for both cases: that of point feature measurements and optical flow. <p> The epipolar constraint has been formulated both in discrete and differential setting and the recent work of the authors [7] demonstrated the possibility of the parallel development of linear algorithms for both cases: that of point feature measurements and optical flow. The appeal of linear algorithms (for discrete case <ref> [10] </ref> and for differential case [7]) is the closed form solution to the problem which in the absence of noise provides true solution of the motion. Further analysis of linear techniques reveals inherent bias in the translation estimate [4]. <p> Even from the efforts which rightly concentrated on the noise related aspects of the problem (i.e. trying different nonlinear objective functions etc.) none of the existing algorithms truly took advantage of the underlying geometrical structure of the problem. The underlying search space was usually parameterized for computational convenience <ref> [3, 12, 10] </ref> instead of being consistent to its intrinsic geometric structure. Consequently, in these algorithms, solving for optimal updating direction typically involved using Lagrangian multipliers to deal with the constraints on the search space; and "walking" on such space was done approximately by the update-then-project procedure. <p> In this sense, such algorithms will be different from other existing algorithms which make use of particular parameterizations of the underlying search space, such as quaternions <ref> [3, 12, 5, 10] </ref>. One may refer to Ma, Koscka and Sastry [9] for a detailed study of the Riemannian Newton algorithm for optimizing a general objective function on the normalized essential manifold. <p> Please refer to the full version of the paper [9] for the proof. It is not just a coincidence that the conditions for the Hessian to be non-degenerate are exactly the same as that for the eight-point linear algorithm (see <ref> [10, 8] </ref>) to have a unique solution. A heuristic explanation is that the objective function here is a quadratic form of the epipolar constraint which the linear algorithm is directly based on. Now assume that the Hessian is non-degenerate.
Reference: [11] <author> Steven T. Smith. </author> <title> Geometric Optimization Methods for Adaptive Filtering. </title> <type> PhD thesis. </type> <institution> Harvard University, Cambridge, Massachusetts, </institution> <year> 1993. </year>
Reference-contexts: Consequently, in these algorithms, solving for optimal updating direction typically involved using Lagrangian multipliers to deal with the constraints on the search space; and "walking" on such space was done approximately by the update-then-project procedure. Due to recent developments in optimization techniques on Riemannian manifolds <ref> [11, 2] </ref>, in this paper we give a top level mathematical view for the nonlinear optimization problem associated with the motion recovery and using Newton's method as an example, show how to apply the optimization theory on Riemannian manifolds to solve this problem by using the intrinsic Riemannian structure of the <p> Recent developments in optimization algorithms on Riemannian manifolds have provided geometric insights for generalization of Newton and conjugate gradient methods to certain classes of Riemannian manifolds. Smith <ref> [11] </ref> gave a detailed treatment of the general theory of optimization on Riemannian manifolds; Edelman, Arias and Smith [2] then studied the case where the Riemannian manifolds are Stiefel and Grassmann manifolds, and presented a uniform geometric framework for Newton and conjugate gradient algorithms on Stiefel and Grassmann manifolds. <p> Since the parameterization and metrics are canonical and the state is updated along geodesics, the performance of so obtained algorithms is guaranteed: they typically have polynomial complexity and quadratic (super-linear) rate of convergence <ref> [11] </ref>. The purpose of this paper is to apply these new Rie-mannian optimization schemes to solve the computer vision problem of recovering 3D motion from image correspondences. <p> Then the Riemannian Newton algorithm will have quadratic rate of convergence according to Theorem 3.4 of Smith <ref> [11] </ref>. Theorem 3 Consider the objective function F (R; S) as above.
Reference: [12] <author> C. J. Taylor and D. J. Kriegman. </author> <title> Structure and motion from line segments in multiple images. </title> <journal> IEEE Transactions on PAMI, </journal> <volume> 17(11) </volume> <pages> 1021-32, </pages> <year> 1995. </year>
Reference-contexts: Horn proposed an iterative procedure where the update of the estimate takes into account the or-thonormal constraint of the unknown rotation. Horn's algorithm and the algorithm proposed by <ref> [12] </ref> are some of the few which consider explicitly the differential geometric properties of SO (3). However they do not make a connection and full exploitation of the differential geometric properties of the entire space of essential matrices as characterized in our recent paper [7]. <p> Even from the efforts which rightly concentrated on the noise related aspects of the problem (i.e. trying different nonlinear objective functions etc.) none of the existing algorithms truly took advantage of the underlying geometrical structure of the problem. The underlying search space was usually parameterized for computational convenience <ref> [3, 12, 10] </ref> instead of being consistent to its intrinsic geometric structure. Consequently, in these algorithms, solving for optimal updating direction typically involved using Lagrangian multipliers to deal with the constraints on the search space; and "walking" on such space was done approximately by the update-then-project procedure. <p> In this sense, such algorithms will be different from other existing algorithms which make use of particular parameterizations of the underlying search space, such as quaternions <ref> [3, 12, 5, 10] </ref>. One may refer to Ma, Koscka and Sastry [9] for a detailed study of the Riemannian Newton algorithm for optimizing a general objective function on the normalized essential manifold.
Reference: [13] <author> J. Weng, T.S. Huang, and N. Ahuja. </author> <title> Motion and Structure from Image Sequences. </title> <publisher> Springer Verlag, </publisher> <year> 1993. </year>
Reference-contexts: The seminal work of Longuet-Higgins [6] on characterization of so called epipolar constraint, enabled decoupling of the structure and motion problems and led to the development of numerous linear and nonlinear algorithms for motion estimation (see <ref> [10, 13] </ref> for overviews). The epipolar constraint has been formulated both in discrete and differential setting and the recent work of the authors [7] demonstrated the possibility of the parallel development of linear algorithms for both cases: that of point feature measurements and optical flow.
References-found: 13

