URL: http://ciir.cs.umass.edu/info/psfiles/irpubs/ir91.ps.gz
Refering-URL: http://hobart.cs.umass.edu/~zlu/pub.html
Root-URL: 
Email: fzlu,callan,croftg@cs.umass.edu  
Title: Applying Inference Networks to Multiple Collection Searching  
Author: Zhihong Lu James P. Callan W. Bruce Croft 
Address: Amherst, MA 01003-4610  
Affiliation: Computer Science Department, University of Massachusetts  
Abstract: The paper describes how to use inference networks to solve two problems in searching multiple collections: collection selection and result merging. The effectiveness of the approaches is demonstrated with the INQUERY system and 3 gigabyte TREC collections.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Howard Turtle and W. Bruce Croft. </author> <title> Evaluation of an Inference Network-Based Retrieval. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> Vol. 9, No. 3, </volume> <month> July </month> <year> 1993, </year> <pages> Pages 187-222. </pages>
Reference-contexts: In Section 5, we present the experimental results. In Section 6, we describe related work. In the final section, we summarize the results and discuss the future work. 1 2 The Current INQUERY Inference Network 2.1 Bayesian Inference Networks A Bayesian inference network <ref> [1] </ref> is a directed, acyclic dependency graph (DAG) in which nodes represent propositional variables or constants and edges represent dependence relations between propositions. If a proposition represented by node p "causes" or implies the proposition represented by node q, we draw a directed edge from p to q. <p> Given a set of prior probabilities for the root of the DAG, the network can be used to compute the probability or degree of belief associated with all remaining nodes. 2.2 The current INQUERY Inference Network The basic document retrieval inference network <ref> [1] </ref>, shown in Figure 1, consists of two component networks: a document network which is built once for a given collection and a query network which is built at query processing time.
Reference: [2] <author> James P. Callan, Zhihong Lu and W. Bruce Croft. </author> <title> Searching Distributed Collections with Inference Networks. </title> <booktitle> Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 21-28, </pages> <address> Seattle, </address> <month> July </month> <year> 1995. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: The TREC collections are heterogeneous, containing 17 collections from different sources and/or periods of time (Table 1). The 150 queries developed for TREC topics 50-150 and topics 201-250 were used in the experiments. <ref> [2] </ref> has reported the experimental results about TREC topics 50-150 against TREC volume 1 collections (7 collections), TREC volume 1 + 2 (13 collections) and TREC volume 1 + 2 + 3 (17 collections).
Reference: [3] <author> James Allan, Lisa Ballesteros, James P. Callan, W. </author> <title> Bruce Croft and Zhihong Lu "Recent Experiments with INQUERY", </title> <booktitle> Proceedings of the 4th Text REtrieval Conference (TREC-4), </booktitle> <month> Nov. </month> <year> 1995. </year> <institution> National Institute of Standards and Technology. </institution>
Reference-contexts: Here we report two more sets of experiments: * 50 queries (201-250 topics) on TREC volume 2+3 (2 gigabytes, 10 collections) which are queries and collections used in the database merging track of TREC4 <ref> [3] </ref>, and * 50 queries (201-250 topics) on 106 collections obtained by splitting the TREC volumes 2 & 3 according to the source and publication date (Table 2). 8 5.2 Experiments with collection selection 5.2.1 Metrics We define the metrics based the concepts of precision and recall.
Reference: [4] <author> Edie Rasmussen. </author> <title> Clustering Algorithms. </title> <editor> In Frakes and Baeza-Yates, editors, </editor> <booktitle> Information Retrieval: Data Structures and Algorithms. Chapter 16, </booktitle> <pages> pages 419-442. </pages> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: MFn-sel-m indicate the experiment which merges the document scores from the selected top collections (m is the average number of collections selected for each query) with the merging function MFn. A single pass clustering algorithm <ref> [4] </ref> is used to select the top collections based on their collection ranking scores. The experiments show that the raw scores approach is significantly worse than the normalized scores, especially in the case of 106 collections, it causes more than 30% losses in almost all levels of recall.
Reference: [5] <author> Katia Obraczka, Peter B. Danzig, and Shih-Hao Li. </author> <title> Internet Resource Discovery Services. </title> <booktitle> IEEE Computer, </booktitle> <month> September </month> <year> 1993. </year>
Reference-contexts: This suggests that the icf part hurts the results when the number of collections is relatively small. It is not clear if icf will hurt a large number of collections. 6 Related Work The problem of collection selection is a specific instance of the more general resource discovery problem <ref> [5] </ref>. The approaches to solving the resource discovery problem fall into two groups: browsing and searching [6]. Browsing allows users to follow pre-defined links between data items to find resources. Because the links are maintained manually, they are always out of date or non-existent.
Reference: [6] <author> Michael F. Schwartz. </author> <title> Searching as a Primary Internet Discovery Paradigm. Internet Society News 2(2), </title> <month> Summer </month> <year> 1993. </year>
Reference-contexts: It is not clear if icf will hurt a large number of collections. 6 Related Work The problem of collection selection is a specific instance of the more general resource discovery problem [5]. The approaches to solving the resource discovery problem fall into two groups: browsing and searching <ref> [6] </ref>. Browsing allows users to follow pre-defined links between data items to find resources. Because the links are maintained manually, they are always out of date or non-existent. In addition if you have no idea where to find information, finding information following links can be very frustrating.
Reference: [7] <author> WAIS 2.0: </author> <note> Technical Description http://www.wais.com/newhomepages/techtalk.html </note>
Reference-contexts: In addition if you have no idea where to find information, finding information following links can be very frustrating. Searching allows users to query a collection of "meta-information" about available collections. This approach is used in increasingly many Internet resource discovery systems (e.g. <ref> [7] </ref>, [8], [9], etc). The meta information typically provides some sort of summary of the contents of each collection. Some systems keep human-generated summaries of each collection [7][8]. Human-generated summaries are often out of date. Some systems only index a small portion of each document such as titles [9].
Reference: [8] <institution> ALIWEB http://www.nexor.co.uk/public/aliweb/doc/introduction.html </institution>
Reference-contexts: In addition if you have no idea where to find information, finding information following links can be very frustrating. Searching allows users to query a collection of "meta-information" about available collections. This approach is used in increasingly many Internet resource discovery systems (e.g. [7], <ref> [8] </ref>, [9], etc). The meta information typically provides some sort of summary of the contents of each collection. Some systems keep human-generated summaries of each collection [7][8]. Human-generated summaries are often out of date. Some systems only index a small portion of each document such as titles [9].
Reference: [9] <institution> World-wide Web Worm http://wwwmcb.cs.colorado.edu/home/mcbryan/WWWW.html </institution>
Reference-contexts: In addition if you have no idea where to find information, finding information following links can be very frustrating. Searching allows users to query a collection of "meta-information" about available collections. This approach is used in increasingly many Internet resource discovery systems (e.g. [7], [8], <ref> [9] </ref>, etc). The meta information typically provides some sort of summary of the contents of each collection. Some systems keep human-generated summaries of each collection [7][8]. Human-generated summaries are often out of date. Some systems only index a small portion of each document such as titles [9]. <p> systems (e.g. [7], [8], <ref> [9] </ref>, etc). The meta information typically provides some sort of summary of the contents of each collection. Some systems keep human-generated summaries of each collection [7][8]. Human-generated summaries are often out of date. Some systems only index a small portion of each document such as titles [9]. This approach sacrifices important information of the contents of each collection. Some systems index all terms that occur in the individual collections. GLOSS [10] and our approach belong to this category. GLOSS has two versions.
Reference: [10] <institution> Glossary of Servers http://gloss.stanford.edu </institution>
Reference-contexts: Human-generated summaries are often out of date. Some systems only index a small portion of each document such as titles [9]. This approach sacrifices important information of the contents of each collection. Some systems index all terms that occur in the individual collections. GLOSS <ref> [10] </ref> and our approach belong to this category. GLOSS has two versions.
Reference: [11] <author> Luis Gravano and Hector Garcia-Molina. </author> <title> Precision and Recall of GLOSS Estimator for Database Discovery. Stanford Univerdity Technical Note Number STAN-CS-TN-94-10. </title>
Reference-contexts: This approach sacrifices important information of the contents of each collection. Some systems index all terms that occur in the individual collections. GLOSS [10] and our approach belong to this category. GLOSS has two versions. In its boolean version <ref> [11] </ref>, GLOSS keeps the number of documents in a collection containing a particular term and estimates the number of potentially relevant 10 documents of a collection C for a Boolean AND query Q as jCj t*Q df t jCj , where t is a term in Q, df t is the
Reference: [12] <author> Luis Gravano and Hector Garcia-Molina. </author> <title> Generalizing GLOSS to Vector-Space Databases and Broker Hierarchies. </title> <booktitle> Proceedings of the 21st VLDB Conference, </booktitle> <address> Zurich, </address> <month> Switchland </month> <year> 1995. </year>
Reference-contexts: In its vector space version <ref> [12] </ref>, GLOSS keeps the number of documents in a collection C containing a particular term t (df t ) and the sum of weights of the term t over all documents in the collection C (w t ).
Reference: [13] <author> Norbert Fuhr. </author> <title> A Decision-Theoretic Approach to Database Selection in Networked IR. </title> <booktitle> Workshop on Distributed IR, </booktitle> <address> Germany, </address> <year> 1996. </year> <month> 12 </month>
Reference-contexts: Recently, a decision-theoretic approach is proposed to solve collection selection problem <ref> [13] </ref>, which uses expected recall-precision curve, expected number of relevant documents and cost factors for query processing and document delivery to make decision. But no performance studies are reported. In addition some approaches incorporate AI technology such as semantic knowledge to locate collections [14].
Reference: [14] <author> NetSerf: </author> <title> Using Semantic Knowledge to Find Internet Information Archives. </title> <booktitle> Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 4-11, </pages> <address> Seattle, </address> <month> July </month> <year> 1995. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: But no performance studies are reported. In addition some approaches incorporate AI technology such as semantic knowledge to locate collections <ref> [14] </ref>. Our approach to result merging assumes that the collection-wide information is accessible, i.e. we can use the particular statistics about collections in the merging function besides the ranked list of documents in response to a query.

References-found: 14

