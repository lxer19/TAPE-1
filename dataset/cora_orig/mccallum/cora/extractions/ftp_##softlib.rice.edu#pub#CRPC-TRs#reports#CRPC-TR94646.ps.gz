URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR94646.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: Typed Fusion with Applications to Parallel and Sequential Code Generation  
Author: Ken Kennedy Kathryn S. M c Kinley 
Address: Houston, TX 77251-1892 Amherst, MA 01003-4610  
Affiliation: Department of Computer Science Department of Computer Science Rice University, CITI University of Massachusetts, LGRC  
Abstract: Loop fusion is a program transformation that merges multiple loops into one and is an effective optimization both for increasing the granularity of parallel loops and for improving data locality. This paper introduces typed fusion, a formulation of loop fusion which captures the fusion and distribution problems encountered in sequential and parallel program optimization. Typed fusion is more general and applicable than previous work. We present a fast algorithm for a typed fusion on a graph G = (N; E), where nodes represent loops, edges represent dependence constraints between loops and each loop is assigned one of T distinct types. Only nodes of the same type may fuse. Only nodes of the same type may be fused. The asymptotic time bound for this algorithm is O((N + E)T ). The fastest previous algorithm considered only one or two types, but was still O(N E) [KM93]. When T &gt; 2 and there is no reason to prefer fusing one type over another, we prove the problem of finding a fusion with the fewest resultant loops to be NP-hard. Using typed fusion, we present fusion and distribution algorithms that improve data locality and a parallel code generation algorithm that incorporates compound transformations. We also give evidence of the effectiveness of this algorithm in practice.
Abstract-found: 1
Intro-found: 1
Reference: [AK87] <author> J. R. Allen and K. Kennedy. </author> <title> Automatic translation of Fortran programs to vector form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: Finally, Section 8 gives preliminary evidence of the effectiveness of typed fusion. 2 Technical Background 2.1 Dependence We assume the reader is familiar with data dependence [Ber66, KKP + 81] and the terms true, anti, output and input dependence, as well as the distinction between loop-independent and loop-carried dependences <ref> [AK87] </ref>. Parallel 1 An ADI solver written by Thomas M. Eidson at ICASE 2 loops have no loop-carried dependences and sequential loops have at least one. 2.2 Safe Loop Fusion Loop fusion is a loop-reordering transformation; it changes the order in which loop iterations are executed.
Reference: [AS79] <author> W. Abu-Sufah. </author> <title> Improving the Performance of Virtual Memory Computers. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, University of Illinois at Urbana-Champaign, </institution> <year> 1979. </year>
Reference-contexts: Since the direction of the dependence is preserved in the first two cases, fusion is legal. Fusion is illegal when a loop-independent dependence becomes a backward carried dependence after fusion. These dependences are called fusion-preventing dependences <ref> [AS79, War84] </ref>. Since a loop is parallel if it contains no loop-carried dependences and is sequential otherwise, fusion in case (b) is safe but prevents parallelization of the resultant loop. If either one or both of the loops were parallel, fusion would reduce loop parallelism.
Reference: [Ber66] <author> A. J. Bernstein. </author> <title> Analysis of programs for parallel processing. </title> <journal> IEEE Transactions on Electronic Computers, </journal> <volume> 15(5) </volume> <pages> 757-763, </pages> <month> October </month> <year> 1966. </year>
Reference-contexts: Finally, Section 8 gives preliminary evidence of the effectiveness of typed fusion. 2 Technical Background 2.1 Dependence We assume the reader is familiar with data dependence <ref> [Ber66, KKP + 81] </ref> and the terms true, anti, output and input dependence, as well as the distinction between loop-independent and loop-carried dependences [AK87]. Parallel 1 An ADI solver written by Thomas M.
Reference: [Cal87] <author> D. Callahan. </author> <title> A Global Approach to Detection of Parallelism. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> March </month> <year> 1987. </year>
Reference-contexts: Note that they need not have the same index variable. Previous algorithms for performing loop fusion have only considered the case when all loop headers are conformable <ref> [Cal87, GOST92, KM93] </ref>. In typed fusion, we consider a wider class of problems where the loops being considered for fusion need not have conformable headers. The type of a loop or loop nest is determined by its header (s). Two loop nests with conformable headers have the same type. <p> Goal: without violating the constraints, fuse nodes of the same type so that resultant program has a minimal number of nodes. 4 Related Work Typed fusion considers more general and complex problems and subsumes the problems that have previously been addressed in the fusion literature <ref> [Cal87, GOST92, KM93] </ref>. In addition to being more powerful, the typed fusion algorithm is O ((N + E)T ) and is quicker than previous solutions when applied to the same problem domain. <p> In Callahan's dissertation, a greedy loop fusion algorithm introduces both task and loop parallelism, but does not address improving data locality or granularity of loop parallelism <ref> [Cal87] </ref>. The greedy algorithm is O (N 2 + E) space and time and is applicable only to a collection of conformable nests of a single type. Gao et al. consider a weighted loop fusion problem for improving reuse on uniprocessors with and without pipelining [GOST92]. <p> Callahan proved that if a greedy algorithm is employed on a DAG with a single type, the resulting fusion has the smallest possible number of partitions <ref> [Cal87] </ref>. We also believe there exists a polynomial-time algorithm to find an optimal solution to the Unordered Typed fusion problem for two types. <p> At that point, it starts a new current partition. In his dissertation, Callahan proved that if a greedy algorithm is employed on a DAG where all the nodes are of the same type, the resulting fusion is optimal, i.e., it has the smallest possible number of partitions <ref> [Cal87] </ref>. The proof here is similar. TypedFusion carries out the greedy algorithm for a selected type because, for each node n, it finds the lowest-numbered node in visited (type (n)) that can be fused with n. 2 Complexity. There are two major phases in this algorithm: initialization and worklist iteration.
Reference: [GOST92] <author> G. Gao, R. Olsen, V. Sarkar, and R. Thekkath. </author> <title> Collective loop fusion for array contraction. </title> <booktitle> In Proceedings of the Fifth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> New Haven, CT, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Note that they need not have the same index variable. Previous algorithms for performing loop fusion have only considered the case when all loop headers are conformable <ref> [Cal87, GOST92, KM93] </ref>. In typed fusion, we consider a wider class of problems where the loops being considered for fusion need not have conformable headers. The type of a loop or loop nest is determined by its header (s). Two loop nests with conformable headers have the same type. <p> Goal: without violating the constraints, fuse nodes of the same type so that resultant program has a minimal number of nodes. 4 Related Work Typed fusion considers more general and complex problems and subsumes the problems that have previously been addressed in the fusion literature <ref> [Cal87, GOST92, KM93] </ref>. In addition to being more powerful, the typed fusion algorithm is O ((N + E)T ) and is quicker than previous solutions when applied to the same problem domain. <p> The greedy algorithm is O (N 2 + E) space and time and is applicable only to a collection of conformable nests of a single type. Gao et al. consider a weighted loop fusion problem for improving reuse on uniprocessors with and without pipelining <ref> [GOST92] </ref>. Their work is based on the maximum-flow/minimum-cut algorithm, but only considers sets of loops with conformable headers, i.e., a single type T = 1. Their algorithm is limited because it does not reorder nests and it is not clear if its additional complexity results in better solutions.
Reference: [KKP + 81] <author> D. Kuck, R. Kuhn, D. Padua, B. Leasure, and M. J. Wolfe. </author> <title> Dependence graphs and compiler optimizations. </title> <booktitle> In Conference Record of the Eighth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <address> Williamsburg, VA, </address> <month> January </month> <year> 1981. </year>
Reference-contexts: Finally, Section 8 gives preliminary evidence of the effectiveness of typed fusion. 2 Technical Background 2.1 Dependence We assume the reader is familiar with data dependence <ref> [Ber66, KKP + 81] </ref> and the terms true, anti, output and input dependence, as well as the distinction between loop-independent and loop-carried dependences [AK87]. Parallel 1 An ADI solver written by Thomas M.
Reference: [KM92] <author> K. Kennedy and K. S. M c Kinley. </author> <title> Optimizing for parallelism and data locality. </title> <booktitle> In Proceedings of the 1992 ACM International Conference on Supercomputing, </booktitle> <address> Washington, DC, </address> <month> July </month> <year> 1992. </year> <month> 12 </month>
Reference-contexts: In a little more detail, the following steps make up ParallelCodeGen. 1. For i = 1 to n attempt to parallelize l i . We use techniques described elsewhere <ref> [KM92] </ref> which perform loop interchange and other transformations to introduce outer loop parallelism and effectively exploit data locality. A parallelization strategy appropriate to the target architecture should be selected.
Reference: [KM93] <author> K. Kennedy and K. S. M c Kinley. </author> <title> Maximizing loop parallelism and improving data locality via loop fusion and distribution. </title> <booktitle> In Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Note that they need not have the same index variable. Previous algorithms for performing loop fusion have only considered the case when all loop headers are conformable <ref> [Cal87, GOST92, KM93] </ref>. In typed fusion, we consider a wider class of problems where the loops being considered for fusion need not have conformable headers. The type of a loop or loop nest is determined by its header (s). Two loop nests with conformable headers have the same type. <p> Example 1 (a) contains a fragment taken from the subroutine tridvpk in ERLEBACHER 1 where JMAXD, IMAXD, and N are compile time constants. If we only consider fusion problems where all the nests are conformable (as we did in our previous work <ref> [KM93] </ref>), we would only attempt to fuse L 3 and L 4 . <p> The algorithms below only perform safe fusions. 2.3 Loop Distribution If loop distribution is applied to create the finest possible loop nests, then to exploit data locality or increase the granularity of parallel loops, loop fusion must be applied <ref> [KM93] </ref>. Two applications which use typed fusion to perform loop distribution is described in Section 5. However, all the fusion algorithms are applicable to loop distribution. 3 Typed Fusion We represent the typed fusion problem with a graph in which each candidate loop nest is represented by a node. <p> Goal: without violating the constraints, fuse nodes of the same type so that resultant program has a minimal number of nodes. 4 Related Work Typed fusion considers more general and complex problems and subsumes the problems that have previously been addressed in the fusion literature <ref> [Cal87, GOST92, KM93] </ref>. In addition to being more powerful, the typed fusion algorithm is O ((N + E)T ) and is quicker than previous solutions when applied to the same problem domain. <p> For increasing the granularity of parallel loops, our previous work focused on a special case of typed fusion <ref> [KM93] </ref>. In this problem, all the nests have the same number of iterations and nodes are either marked parallel or sequential, i.e., T = 2. The solution presented is O (N E), but is only minimal in the number of parallel loops. <p> We now have an algorithm for this problem which is minimal in the number of parallel loops and the total number of loops. In our previous work, we also considered the same weighted fusion problem as Gao et al. and proved it NP-hard <ref> [KM93] </ref>. We prove below that even the unweighted problem is NP-hard for T &gt; 2. <p> This model may be further refined to keep register pressure down by assigning the same type only when the references may share a register after fusion. We can also weight the edges to further differentiate between fusion choices. This problem is NP-hard even for one type <ref> [KM93] </ref>. Extending this algorithm to the weighted problem for reuse is left for future work. 5.3 Parallel Code Generation Now we examine the problem of performing loop fusion as part of a general automatic parallel code generator. <p> The rest of the example is straightforward from examination of the TypedFusion algorithm. The final graph after fusion is shown in Figure 5. 8 Experimental Results and Discussion In our previous work, improvements in execution times due to untyped fusion ranged from 4 up to 32 percent <ref> [KM93] </ref>. Every time fusion was applied it was profitable. For example, untyped fusion of ERLEBACHER on uniprocessors improved performance between 4 and 17 percent.
Reference: [War84] <author> J. Warren. </author> <title> A hierachical basis for reordering transformations. </title> <booktitle> In Conference Record of the Eleventh Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <address> Salt Lake City, UT, </address> <month> January </month> <year> 1984. </year> <month> 13 </month>
Reference-contexts: Since the direction of the dependence is preserved in the first two cases, fusion is legal. Fusion is illegal when a loop-independent dependence becomes a backward carried dependence after fusion. These dependences are called fusion-preventing dependences <ref> [AS79, War84] </ref>. Since a loop is parallel if it contains no loop-carried dependences and is sequential otherwise, fusion in case (b) is safe but prevents parallelization of the resultant loop. If either one or both of the loops were parallel, fusion would reduce loop parallelism.
References-found: 9

