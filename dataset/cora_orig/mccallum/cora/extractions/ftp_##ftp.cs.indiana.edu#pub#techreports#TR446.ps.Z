URL: ftp://ftp.cs.indiana.edu/pub/techreports/TR446.ps.Z
Refering-URL: http://www.cs.indiana.edu/trindex.html
Root-URL: 
Title: LOW RANK OFF-DIAGONAL BLOCK PRECONDITIONERS FOR SOLVING SPARSE LINEAR SYSTEMS ON PARALLEL COMPUTERS  
Author: RANDALL BRAMLEY AND VLADIMIR ME NKOV 
Address: BLOOMINGTON  
Affiliation: DEPARTMENT OF COMPUTER SCIENCE INDIANA UNIVERSITY  
Abstract: For a sparse linear system Ax = b, preconditioners of the form C = D + L + U, where D is the block diagonal part of A (or incomplete factorization approximation of its blocks), and L and U are block strictly lower and upper triangular matrices composed of low-ranks approximations of the respective blocks of A, are examined. C is applied directly, by solving Cz = w, or partially, by applying one step of BSSOR to Cz = w. Use of low-rank approximations of off-diagonal blocks is common in dense systems, but apparently has not been considered for sparse systems. This paper examines ways of defining the off-diagonal blocks and provides a detailed analysis for systems occuring in solving Laplace equation on a uniform mesh. Methods of applying C as a parallel preconditioner are proposed and analyzed, their cost being compared to that of applying a Jacobi preconditioner D. Testing results are presented, comparing the use of low-rank approximations with Jacobi and block SSOR preconditioning. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. Alvarado, </author> <title> Ordering schemes for partitioned sparse inverses, 1989. SIAM Symposium on Sparse Matrices, </title> <address> Salishan Lodge, Gleneden Beach, OR, </address> <month> May 22-24 </month> <year> 1989. </year>
Reference-contexts: One way to recover parallelism is to increase the number of blocks in the partitioning of A and use a level scheduling <ref> [1, 2] </ref>. However, this also causes the quality of preconditioning to fall, and in the limiting case becomes pointwise symmetrized Gauss-Seidel, which typically provides poor quality of preconditioning. In this paper we borrow an idea from the solution of integral equations, and use low-rank approximations of the off-diagonal blocks.
Reference: [2] <author> E. Anderson, </author> <title> Parallel implementation of preconditioned conjugate gradient methods for solving sparse systems of linear equations, </title> <type> Master's thesis, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing Res. & Dev., </institution> <year> 1988. </year>
Reference-contexts: One way to recover parallelism is to increase the number of blocks in the partitioning of A and use a level scheduling <ref> [1, 2] </ref>. However, this also causes the quality of preconditioning to fall, and in the limiting case becomes pointwise symmetrized Gauss-Seidel, which typically provides poor quality of preconditioning. In this paper we borrow an idea from the solution of integral equations, and use low-rank approximations of the off-diagonal blocks.
Reference: [3] <author> O. Axelsson, </author> <title> Iterative Solution Methods, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, UK, 1 ed., </address> <year> 1994. </year>
Reference-contexts: Relation between the Sherman-Morrison-Woodbury based method and Schur complement-based methods. The SMW-formula based algorithm for solving (39) described in Section 6 is similar to Schur complement methods <ref> [3, Chapter 9] </ref>, where the solution of the system " A 21 A 22 x 1 # " y 2 is calculated by a process that involves matrix-vector multiplications with A 12 and A 21 and solving linear systems with A 11 and S = A 22 A 12 A 1
Reference: [4] <author> H. V. der Vorst, </author> <title> Bi-CGSTAB: A fast and smoothly converging variant of Bi-CG for the solution of nonsymmetric linear systems, </title> <journal> SIAM Journal of Scientific and Statistical Computing, </journal> <volume> 13 (1992), </volume> <pages> pp. 631-644. </pages>
Reference-contexts: Preliminary computational results. The direct LOB preconditioner, ap-plied using the SMW-based method in conjugate gradients stabilized <ref> [4] </ref> iterations was implemented in pC++ [5] on a 12-processor SGI Power Challenge. The report [10] describes the results for the implementation where I+G was factored sequentially, and (I + G)s = t was solved sequentially.
Reference: [5] <author> D. Gannon, S. X. Yang, and P. Beckman, </author> <title> User Guide for a Portable Parallel C++ Programming System, pC++, </title> <institution> Department of Computer Science and CICA, Indiana University, Bloomington, </institution> <note> IN, 1994. Available via World Wide Web at http://www.extreme.indiana.edu/sage/pcxx ug/pcxx ug.html. </note>
Reference-contexts: Preliminary computational results. The direct LOB preconditioner, ap-plied using the SMW-based method in conjugate gradients stabilized [4] iterations was implemented in pC++ <ref> [5] </ref> on a 12-processor SGI Power Challenge. The report [10] describes the results for the implementation where I+G was factored sequentially, and (I + G)s = t was solved sequentially. In that report, the direct LOB preconditioner and the SMW-based application method are referred to as the "LRA SMW preconditioner".
Reference: [6] <author> A. George and W.-H. Liu, </author> <title> The Computer Solution of Large Sparse Positive Definite Systems, </title> <publisher> Prentice-Hall, </publisher> <address> Engelwood Cliffs, NJ, </address> <year> 1981. </year>
Reference-contexts: Thus one can talk about the undirected graph of A, whose nodes correspond to variables, and in which nodes i and j are connected with an edge whenever a ij 6= 0 <ref> [6] </ref>. To describe the structure of the matrix A, it is handy to use the predicate neig (; ), which is defined to be true if and only if the nodes and are "neighbors" in the graph of A, i.e. if the a 6= 0. <p> The equation for H jkl shows that the block G kl can be non-zero only if U kl is non-zero, which, in its turn, can be non-zero only if Q kl is non-zero. 2 Since we use no-cancellation assumption <ref> [6, Section 2.2.2] </ref>, i.e. disregard exact cancellation in floating-point computation, it follows from Proposition 6.1 that G has the same non-zero block structure as Q. Corollary 6.2. If Q is strictly block upper or lower triangular, then so is G.
Reference: [7] <author> G. Golub and C. V. Loan, </author> <title> Matrix Computations, </title> <publisher> John Hopkins University Press, </publisher> <address> Baltimore, 2 ed., </address> <year> 1989. </year>
Reference-contexts: matrix A of rank r there are two sets of orthonormal real vectors fu s g s=1;:::;r and fv s g s=1;:::;r of appropriate dimensions, and a set of real positive numbers 1 2 : : : r such that A = s=1 s ; constituting its singular value decomposition <ref> [7] </ref>.
Reference: [8] <author> R. Horn and C. Johnson, </author> <title> Matrix Analysis, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, 1 ed., </address> <year> 1985. </year>
Reference: [9] <author> J. Meijerink and H. van der Vorst, </author> <title> An iterative solution method for linear systems of which the coefficient matrix is a symmetric M-matrix, </title> <journal> Math. Comp., </journal> <volume> 31 (1977), </volume> <pages> pp. 148-162. </pages>
Reference-contexts: Direct LOB preconditioner with original ODBs (C = D + (L + U ) with the same L and U as above), applied using the SMW-based method. In all preconditioners, blocks of D were obtained by an incomplete LU-factorization <ref> [9] </ref> of the diagonal blocks of A. Three levels of fill were allowed for the first two problems, and 14 for the third problem (the hardest).
Reference: [10] <author> V. </author> <title> Me ~ nkov, Solving block linear systems with low-rank off-diagonal blocks is easily par-allelizable, </title> <booktitle> 1995. Submitted to 1996 Copper Mountain Conference on Iterative Methods, </booktitle> <address> Copper Mountain, CO, </address> <month> April 9-13 </month> <year> 1996. </year> <note> Available via World Wide Web at http://ftp.cs.indiana.edu/pub/vmenkov/lowrank/cm96.dvi. </note>
Reference-contexts: Preliminary computational results. The direct LOB preconditioner, ap-plied using the SMW-based method in conjugate gradients stabilized [4] iterations was implemented in pC++ [5] on a 12-processor SGI Power Challenge. The report <ref> [10] </ref> describes the results for the implementation where I+G was factored sequentially, and (I + G)s = t was solved sequentially. In that report, the direct LOB preconditioner and the SMW-based application method are referred to as the "LRA SMW preconditioner". <p> show that in the low rank case (M = 66 or M = 84), the SMW-applied direct LOB preconditioner has a parallel efficiency of 0:85 or better, 3 Timing results for solving these two problems by the same solution methods, but with I + G handled sequentially, are presented in <ref> [10] </ref> 34 Num. Jacobi BSSOR direct BSSOR direct LOB, proc. LOB LOB orig. ODB orig.
Reference: [11] <author> J. M. Ortega and W. C. Rheinboldt, </author> <title> Iterative Solution of Nonlinear Equations in Several Variables, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: Block columns in (43) and (44) corresponding to zero blocks Q kl are absent (have no columns). Since B = D + U V T , the Sherman-Morrison-Woodbury formula <ref> [11] </ref> gives B 1 = (D + U V T ) 1 = D 1 D 1 U (I + G) 1 V T D 1 ;(45) with G = V T D 1 U of order M .
Reference: [12] <author> A. Yeremin and L. </author> <title> Kolotilina, On a family of two-level preconditionings of the incomplete block factorization type, </title> <journal> Sov. J. Numer. Anal. Math. Modeling, </journal> <volume> 1 (1986), </volume> <pages> pp. 293-320. 37 </pages>
Reference-contexts: In this paper we borrow an idea from the solution of integral equations, and use low-rank approximations of the off-diagonal blocks. By varying the rank of the ODBs the new method can be parametrized to vary in quality between that of block diagonal and block SSOR <ref> [12] </ref> preconditioner. 3. Proposed Approach.
References-found: 12

