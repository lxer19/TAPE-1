URL: http://pine.cs.yale.edu:4201/home/podc96-full.ps
Refering-URL: http://pine.cs.yale.edu:4201/home/podc96-abstract.html
Root-URL: http://www.cs.yale.edu
Title: Spreading Rumors Rapidly Despite an Adversary  
Author: James Aspnes William Hurwood 
Date: January 22, 1997  
Abstract: In the collect problem [32], n processors in a shared-memory system must each learn the values of n registers. We give a randomized algorithm that solves the collect problem in O(n log 3 n) total read and write operations with high probability, even if timing is under the control of a content-oblivious adversary (a slight weakening of the usual adaptive adversary). This improves on both the trivial upper bound of O(n 2 ) steps and the best previously known bound of O(n 3=2 log n) steps, and is close to the lower bound of (n log n) steps. Furthermore, we show how this algorithm can be used to obtain a multi-use cooperative collect protocol that is O(log 3 n)-competitive in the latency model of Ajtai et al.[3] and O(n 1=2 log 3=2 n)-competitive in the throughput model of Aspnes and Waarts [10]; in both cases the competitive ratios are within a polylogarithmic factor of optimal.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Abrahamson. </author> <title> On achieving consensus using a shared memory. </title> <booktitle> In Proc. 7th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 291-302, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: This assumption appears frequently in early work on consensus; it is the "weak model" of Abrahamson <ref> [1] </ref> and was used in the consensus paper of Chor, Israeli, and Li [19]. In general, the weak model in its various incarnations permits much better algorithms (e.g., [11, 18]) for such problems as consensus than the best known algorithms in the more traditional "strong model".
Reference: [2] <author> Y. Afek, H. Attiya, D. Dolev, E. Gafni, M. Merritt, and N. Shavit. </author> <title> Atomic snapshots of shared memory. </title> <booktitle> Proc. 9th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 1-13, </pages> <year> 1990. </year>
Reference: [3] <author> M. Ajtai, J. Aspnes, C. Dwork, and O. Waarts. </author> <title> A theory of competitive analysis for distributed algorithms. </title> <booktitle> In Proc. 33rd IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 401-411, </pages> <month> November </month> <year> 1994. </year> <note> Full version available. </note>
Reference-contexts: However, the naive solution is not the best possible, as processors can learn values indirectly from other processors, thus sharing the work of reading the registers. Indeed, Saks, Shavit, and Woll [32] describe a collect algorithm that finishes quickly when most processors are running concurrently, and Ajtai et al. <ref> [3] </ref> observed that the Certified Write-All algorithm of Anderson and Woll [5] could be modified in a straightforward way to solve the collect problem in O (n 3=2 log n) total operations. <p> This is 2 a substantial improvement on an upper bound of n 2 , but still far from the best known lower bound of (n log n) <ref> [3] </ref>. Repeated collects. The collect problem is motivated by its frequent appearance in other algorithms. <p> Indeed, one would expect that an algorithm that solved the one-time problem quickly could be extended to an algorithm that would give better performances in many circumstances. Ajtai et al. <ref> [3] </ref> provided a tool, known as latency competitiveness, that can be used to show the superiority of more sophisticated algorithms. In their model the performance of a distributed algorithm is 1 [32, 31] present collect algorithms that do not follow the pattern of the naive algorithm. <p> Update T to include the most recent timestamps for each processor. Set p to the successor field. fl Write out the new S and T . * Return S. We can characterize the performance of this algorithm by describing its collective latency <ref> [3] </ref>, an upper bound on the amount of work needed to complete all collects in progress at some time t: Theorem 9 Fix a starting time s. Let k, , n, and c be as in Theorem 8. <p> The competitive ratio that we obtain depends on the particular competitive model chosen; there are two natural possibilities for the collect problem, described in the following two sections. 4.1 Latency competitiveness The competitive latency model of Ajtai et al. <ref> [3] </ref> is a mechanism for applying the technique of competitive analysis, originally developed to deal with the unknown sequences of user inputs in on-line algorithms [33], to unknown patterns of system behavior as found in fault-tolerant distributed 17 specified by the scheduler (vertical bars). <p> The competitive latency of a candidate algorithm is the least constant k, if any, that guarantees that the expected total number of operations carried out by the candidate on a given schedule is at most k times the cost of an optimal distributed algorithm (called the champion by <ref> [3] </ref>) running on the 18 same schedule. Ajtai et al. show that if an algorithm has a maximum collective latency of L at all times, then its competitive ratio in the latency model is at most L=n + 1. <p> Unfortunately, this result is stated only for deterministic algorithms, and in any case the upper bound on the collective latency of our algorithm is only a high-probability guarantee and not absolute. However, as we show below, the proof in <ref> [3] </ref> of the relationship between collective latency and competitive latency does not really depend on these details, and works equally well to bound the expected latency competitiveness of a randomized algorithm given a bound on the expected collective latency. <p> Theorem 11 The expected competitive latency of the repeated collect algorithm is O (log 3 n). Proof: The proof is essentially identical to the proof in <ref> [3] </ref>, except that an absolute bound L on the total work done to finish any collects in progress at any given time must be replaced by a bound on the expected work. <p> We will assume without loss of generality that the adversary has chosen some fixed strategy, and that all expectations and probabilities are conditioned on the adversary following this strategy. In <ref> [3] </ref> it is shown that any schedule can be divided into a sequence of intervals I 1 ; I 2 ; : : : I k such that: 1. In the optimal champion algorithm, at least n operations are per formed during each interval except the last. 2.
Reference: [4] <author> J. Anderson. </author> <title> Composite registers. </title> <booktitle> Proc. 9th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 15-30, </pages> <month> August </month> <year> 1990. </year>
Reference: [5] <author> R. Anderson and H. Woll. </author> <title> Wait-free parallel algorithms for the Union-Find Problem. </title> <booktitle> In Proc. 23rd ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 370-380, </pages> <year> 1991. </year>
Reference-contexts: Indeed, Saks, Shavit, and Woll [32] describe a collect algorithm that finishes quickly when most processors are running concurrently, and Ajtai et al. [3] observed that the Certified Write-All algorithm of Anderson and Woll <ref> [5] </ref> could be modified in a straightforward way to solve the collect problem in O (n 3=2 log n) total operations. This is 2 a substantial improvement on an upper bound of n 2 , but still far from the best known lower bound of (n log n) [3].
Reference: [6] <author> J. Aspnes. </author> <title> Time- and space-efficient randomized consensus. </title> <journal> Journal of Algorithms 14(3) </journal> <pages> 414-431, </pages> <month> May </month> <year> 1993. </year> <title> An earlier version appeared in Proc. </title> <booktitle> 9th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 325-331, </pages> <month> August </month> <year> 1990. </year>
Reference: [7] <author> J. Aspnes and M. Herlihy. </author> <title> Fast randomized consensus using shared memory. </title> <note> In Journal of Algorithms 11(3), pp.441-461, </note> <month> September </month> <year> 1990. </year>
Reference: [8] <author> J. Aspnes and M. P. Herlihy. </author> <title> Wait-free data structures in the Asynchronous PRAM Model. </title> <booktitle> In Proceedings of the 2nd Annual Symposium on Parallel Algorithms and Architectures, </booktitle> <month> July </month> <year> 1990, </year> <pages> pp. 340-349, </pages> <address> Crete, Greece. </address>
Reference: [9] <author> J. Aspnes and O. Waarts. </author> <title> Randomized consensus in expected O(n log 2 n) operations per processor. </title> <booktitle> In Proc. 33rd IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 137-146, </pages> <month> October </month> <year> 1992. </year>
Reference: [10] <author> J. Aspnes and O. Waarts. </author> <title> Modular competitiveness for distributed algorithms. </title> <booktitle> Proc. 28th ACM Symposium on Theory of Computing, </booktitle> <month> May </month> <year> 1996, </year> <pages> pp. 237-246. </pages>
Reference-contexts: More details of the latency competitiveness measure, and of the related throughput competitiveness measure <ref> [10] </ref>, can be found in Sections 4.1 and 4.2. 1.1 Our results We describe (Section 2) an algorithm for the rumor-spreading game which requires only O (n log 2 n) steps with high probability, slightly more than the lower bound of (n log n). <p> Both of these ratios are also within a polylogarithmic factor of the best known lower bounds, and substantially improve on the best previously known ratios of O ( p and O (n 3=4 log n) <ref> [10] </ref>. 1.2 The model All of our results are carried out in a model where the algorithm is allowed to generate a random value and write it out as a single atomic operation. <p> on the cost of the champion is a function only of the structure of the schedule, the theorem holds even against an adaptive off-line adversary [14], which is allowed to choose the champion algorithm after seeing a complete execution of the candidate. 4.2 Throughput competitiveness More recently, Aspnes and Waarts <ref> [10] </ref> have proposed a different measure for the competitive performance of a distributed algorithm. <p> In <ref> [10] </ref> it is shown that any algorithm with a collective latency of L and an absolute bound of 2n operations on any single collect will have a competitive ratio of at most 4 p L + 2n; as with the competitive latency bound, this bound is stated only for deterministic algorithms, <p> The result is: Theorem 12 The expected competitive throughput of the repeated collect algorithm, modified so that no collect takes more than 2n steps, is O (n 1=2 log 3=2 n). Proof: The proof is a straightforward modification of the proof given for deterministic algorithms in <ref> [10] </ref>. We will give the outline of that proof below (much of which is taken from [10]), indicating where it must be modified to deal with a randomized algorithm. <p> Proof: The proof is a straightforward modification of the proof given for deterministic algorithms in <ref> [10] </ref>. We will give the outline of that proof below (much of which is taken from [10]), indicating where it must be modified to deal with a randomized algorithm. As in the proof of Theorem 11, we will assume without loss of generality that the adversary has chosen some fixed strategy, and that all expectations and probabilities are conditioned on the adversary using this strategy. <p> But it is not immediate that we can still use T n as a lower bound on the expected number of collects completed by a randomized algorithm. It is necessary to look closely at the proof that T n is a lower bound on the number of collects. In <ref> [10] </ref> it is shown that T p = 1 2 (C p + P p ) rises by at most 1 during any single collect operation carried out by p. <p> But we know from <ref> [10] </ref> that T (1) is at least 1 4 L+2n times the number of collects completed by the champion in any schedule, so E [T (1)] is at least 1 4 L+2n times the expected number of collects completed by the champion.
Reference: [11] <author> Y. Aumann and M.A. Bender. </author> <title> Efficient asynchronous consensus with the value-oblivious adversary scheduler. </title> <note> To appear, ICALP '96. </note>
Reference-contexts: This assumption appears frequently in early work on consensus; it is the "weak model" of Abrahamson [1] and was used in the consensus paper of Chor, Israeli, and Li [19]. In general, the weak model in its various incarnations permits much better algorithms (e.g., <ref> [11, 18] </ref>) for such problems as consensus than the best known algorithms in the more traditional "strong model".
Reference: [12] <author> H. Attiya, M. Herlihy, and O. Rachman. </author> <title> Efficient atomic snapshots using lattice agreement. </title> <type> Technical report, </type> <institution> Technion, Haifa, Israel, </institution> <year> 1992. </year> <note> A preliminary version appeared in proceedings of the 6th International Workshop on Distributed Algorithms, </note> <institution> Haifa, Israel, </institution> <month> November </month> <year> 1992, </year> <editor> (A. Segall and S. Zaks, eds.), </editor> <booktitle> Lecture Notes in Computer Science #647, </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pp. 35-53. </pages>
Reference: [13] <author> H. Attiya and O. Rachman. </author> <title> Atomic snapshots in O(n log n) operations. </title> <booktitle> In Proc. 12th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 29-40, </pages> <month> Aug. </month> <year> 1993. </year>
Reference: [14] <author> S. Ben-David, A. Borodin, R. Karp, G. Tardos, and A. Wigderson. </author> <title> On the power of randomization in online algorithms. </title> <booktitle> In Proceedings of the Twenty-Second Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 379-386. </pages> <publisher> ACM, </publisher> <year> 1990. </year>
Reference-contexts: Since the lower bound on the cost of the champion is a function only of the structure of the schedule, the theorem holds even against an adaptive off-line adversary <ref> [14] </ref>, which is allowed to choose the champion algorithm after seeing a complete execution of the candidate. 4.2 Throughput competitiveness More recently, Aspnes and Waarts [10] have proposed a different measure for the competitive performance of a distributed algorithm.
Reference: [15] <author> E. Borowsky and E. Gafni. </author> <title> Immediate atomic snapshots and fast renaming. </title> <booktitle> In Proc. 12th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 41-51, </pages> <month> August </month> <year> 1993. </year> <month> 25 </month>
Reference: [16] <author> G. Bracha and O. Rachman. </author> <title> Randomized consensus in expected O(n 2 log n) operations. </title> <booktitle> Proceedings of the Fifth International Workshop on Distributed Algorithms. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference: [17] <author> T. Chandra and C. Dwork. </author> <title> Using consensus to solve atomic snapshots. </title> <note> Submitted for Publication </note>
Reference: [18] <author> T. Chandra. </author> <title> Polylog randomized wait-free consensus. </title> <booktitle> In Proc. 15th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 166-175, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: This assumption appears frequently in early work on consensus; it is the "weak model" of Abrahamson [1] and was used in the consensus paper of Chor, Israeli, and Li [19]. In general, the weak model in its various incarnations permits much better algorithms (e.g., <ref> [11, 18] </ref>) for such problems as consensus than the best known algorithms in the more traditional "strong model".
Reference: [19] <author> B. Chor, A. Israeli, and M. Li. </author> <title> On processor coordination using asynchronous hardware. </title> <booktitle> In Proc. 6th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 86-97, </pages> <year> 1987. </year>
Reference-contexts: This assumption appears frequently in early work on consensus; it is the "weak model" of Abrahamson [1] and was used in the consensus paper of Chor, Israeli, and Li <ref> [19] </ref>. In general, the weak model in its various incarnations permits much better algorithms (e.g., [11, 18]) for such problems as consensus than the best known algorithms in the more traditional "strong model".
Reference: [20] <author> D. Dolev and N. Shavit. </author> <title> Bounded concurrent time-stamp systems are constructible! In Proc. </title> <booktitle> 21st ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 454-465, </pages> <year> 1989. </year> <note> An extended version appears in IBM Research Report RJ 6785, </note> <month> March </month> <year> 1990. </year>
Reference: [21] <author> C. Dwork, M. Herlihy, S. Plotkin, and O. Waarts. </author> <title> Time-lapse snapshots. </title> <booktitle> Proceedings of Israel Symposium on the Theory of Computing and Systems, </booktitle> <year> 1992. </year>
Reference: [22] <author> C. Dwork, M. Herlihy, and O. Waarts. </author> <title> Bounded round numbers. </title> <booktitle> In Proc. 12th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 53-64, </pages> <year> 1993. </year>
Reference: [23] <author> C. Dwork and O. Waarts. </author> <title> Simple and efficient bounded concurrent timestamping or bounded concurrent timestamp systems are comprehensible!, </title> <booktitle> In Proc. 24th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 655-666, </pages> <year> 1992. </year>
Reference: [24] <author> S. Even and B. Monien. </author> <title> On the number of rounds needed to disseminate information. </title> <booktitle> Proceedings of the First Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1989. </year>
Reference-contexts: The process continues until all participants know all of the rumors. Our goal is to minimize the total number of steps (i.e., the total number of telephone calls). One can think of this problem as an asynchronous version of the well-known gossip problem <ref> [24] </ref>. In the gossip problem, n persons wish to distribute n rumors among themselves; however, which persons communicate at each time is fixed in advance by the designer of the algorithm.
Reference: [25] <author> R. Gawlick, N. Lynch, and N. Shavit. </author> <title> Concurrent timestamping made simple. </title> <booktitle> Proceedings of Israel Symposium on Theory of Computing and Systems, </booktitle> <year> 1992. </year> <month> 26 </month>
Reference: [26] <author> S. Haldar. </author> <title> Efficient bounded timestamping using traceable use abstrac-tion Is writer's guessing better than reader's telling? Technical Report RUU-CS-93-28, </title> <institution> Department of Computer Science, Utrecht, </institution> <month> September </month> <year> 1993. </year>
Reference: [27] <author> M.P. Herlihy. </author> <title> Randomized wait-free concurrent objects. </title> <booktitle> In Proc. 10th ACM Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1991. </year>
Reference: [28] <author> A. Israeli and M. Li. </author> <title> Bounded time stamps. </title> <booktitle> In Proc. 28th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1987. </year>
Reference: [29] <author> A. Israeli and M. Pinhasov. </author> <title> A concurrent time-stamp scheme which is linear in time and space. </title> <type> Manuscript, </type> <year> 1991. </year>
Reference: [30] <author> L. M. Kirousis, P. Spirakis and P. Tsigas. </author> <title> Reading many variables in one atomic operation: solutions with linear or sublinear complexity. </title> <booktitle> In Proceedings of the 5th International Workshop on Distributed Algorithms, </booktitle> <year> 1991. </year>
Reference: [31] <author> Y. Riany, N. Shavit and D. Touitou. </author> <title> Practical Snapshots. </title> <booktitle> In Proceedings of Israel Symposium on Theory of Computing and Systems, </booktitle> <year> 1994. </year>
Reference-contexts: Ajtai et al. [3] provided a tool, known as latency competitiveness, that can be used to show the superiority of more sophisticated algorithms. In their model the performance of a distributed algorithm is 1 <ref> [32, 31] </ref> present collect algorithms that do not follow the pattern of the naive algorithm.
Reference: [32] <author> M. Saks, N. Shavit, and H. Woll. </author> <title> Optimal time randomized consensus | making resilient algorithms fast in practice. </title> <booktitle> In Proceedings of the 2nd ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pp. 351-362, </pages> <year> 1991. </year>
Reference-contexts: Furthermore, the algorithm used by each process to choose where it will look for more information can only make that choice based on the information obtained so far. The collect problem. The rumor-spreading problem above is closely related to the collect problem <ref> [32] </ref>. In the collect problem, each of n processes in a shared-memory system possesses some piece of information, which it stores in one of a set of single-writer multi-reader atomic registers. <p> However, the naive solution is not the best possible, as processors can learn values indirectly from other processors, thus sharing the work of reading the registers. Indeed, Saks, Shavit, and Woll <ref> [32] </ref> describe a collect algorithm that finishes quickly when most processors are running concurrently, and Ajtai et al. [3] observed that the Certified Write-All algorithm of Anderson and Woll [5] could be modified in a straightforward way to solve the collect problem in O (n 3=2 log n) total operations. <p> In the cooperative collect primitive, first abstracted by Saks, Shavit, and Woll <ref> [32] </ref>, processes perform the collect operation an operation in which each process learns the values of a set of n registers, with the guarantee that each value learned is fresh: it was present in the register at some point during the collect. <p> Ajtai et al. [3] provided a tool, known as latency competitiveness, that can be used to show the superiority of more sophisticated algorithms. In their model the performance of a distributed algorithm is 1 <ref> [32, 31] </ref> present collect algorithms that do not follow the pattern of the naive algorithm.
Reference: [33] <author> D. D. Sleator and R. E. Tarjan. </author> <title> Amortized efficiency of list update and paging rules. </title> <journal> Comm. of the ACM 28(2), </journal> <pages> pp. 202-208, </pages> <year> 1985. </year>
Reference-contexts: are two natural possibilities for the collect problem, described in the following two sections. 4.1 Latency competitiveness The competitive latency model of Ajtai et al. [3] is a mechanism for applying the technique of competitive analysis, originally developed to deal with the unknown sequences of user inputs in on-line algorithms <ref> [33] </ref>, to unknown patterns of system behavior as found in fault-tolerant distributed 17 specified by the scheduler (vertical bars). Scheduler also specifies timing of low-level operations (small circles). Cost to algorithm is number of low-level operations actually performed (filled circles). soon as previous operations end.
Reference: [34] <author> P. M. B. Vitanyi and B. Awerbuch. </author> <title> Atomic shared register access by asynchronous hardware. </title> <booktitle> In Proc. 27th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1986. </year> <month> 27 </month>
References-found: 34

