URL: http://elysium.cs.ucdavis.edu/~nico/publications/lctrts97.ps
Refering-URL: http://elysium.cs.ucdavis.edu/~nico/publications/publications.html
Root-URL: http://www.cs.ucdavis.edu
Email: nico@cs.ucdavis.edu  john@tera.com  rkyates@llnl.gov  
Title: Implicitly parallel real-time signal processing  
Author: Phillip L. Nico John Feo Robert Kim Yates 
Address: Davis, CA 95616  2815 Eastlake Avenue East Seattle, WA 98102  L-560, P.O. Box 808, Livermore, CA 94550  
Affiliation: Department of Computer Science University of California, Davis  Tera Computer Company  Lawrence Livermore National Laboratory  
Abstract: This paper describes a compiler system for automatic par-allelization, partitioning, and scheduling of real-time signal processing applications written in a functional language running on general-purpose hardware. The high performance levels achieved by commodity processors can meet the demands of many real-time signal processing applications; however, they are not used effectively in practice because tools are not available to automatically create parallel partitions and schedules for DSP application codes that have critical time needs. We have extended Sisal, a high-performance functional language for scientific computations, with constructs to express latency and throughput constraints. Given a description of the target architecture and an application with specified timing requirements, the Sert compiler generates a precise, minimal data dependency graph and then partitions and creates a parallel schedule for the graph to satisfy the specified constraints if possible. When complete, Sert's ability to rapidly and automatically generate parallel schedules for different system configurations will make it an effective aide to real-time systems developers. 
Abstract-found: 1
Intro-found: 1
Reference: [AVW93] <author> Joe Armstrong, Robert Virding, and Mike Williams. </author> <title> Concurrent Programming in ER-LANG. </title> <publisher> Prentice Hall, </publisher> <year> 1993. </year>
Reference-contexts: Lustre [HCRP91] is a real-time functional language based on the same synchronous theory as Signal; as with Signal, work has focussed on program properties rather than on parallel implementations. Erlang <ref> [AVW93] </ref> is a "partially" functional language (side effects are allowed) for soft real-time systems that has been used in industrial telecommunications switches. In Erlang parallelism must be programmed explicitly. Haskell [H + 92] is a lazy functional language that has been used for prototyping some signal processing applications [Gob94].
Reference: [Bea95] <author> Patrick C. Beard. </author> <title> An implementation of SISAL for distributed-memory architectures. </title> <type> Master's thesis, </type> <institution> U. of California, Davis, </institution> <month> June </month> <year> 1995. </year> <note> Also available as Lawrence Livermore National Laboratory Report UCRL-LR-122353. </note>
Reference-contexts: The main implementations of Sisal have been on shared memory multicomputers. However, some research has been done on implementing Sisal on distributed memory and non-uniform memory access architectures <ref> [HB91, PAM94a, WF93, Bea95] </ref>. 6 CONCLUSIONS In this paper we have described a functional language and compiler system for automatic parallelization, partitioning, and scheduling of real-time signal processing applications on general-purpose hardware.
Reference: [Can92] <author> David Cann. </author> <title> Retire FORTRAN? a debate rekindled. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 81-89, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: The language does not require lazy evaluation, and there are many built-in operators to facilitate parallel construction and manipulation of arrays of data. The result is that Sisal is as fast or faster than Fortran in many scientific applications <ref> [Can92] </ref>. Studies have shown that Sisal is a suitable signal processing language. It has demonstrated high performance in numerically intensive applications. The language includes a stream data type that supports potentially infinite sequences of values and potential for producer-consumer parallelism.
Reference: [CD95] <author> Tai M. Chung and Hank G. Dietz. </author> <title> Language constructs and transformation for hard real-time systems. </title> <booktitle> In Proc. of the 1995 ACM SIGPLAN Workshop on Languages, Compilers and Tools for Real-Time Systems, </booktitle> <pages> pages 45-53, </pages> <address> La Jolla, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Some in teresting work on the application of heuristics to real-time scheduling problems can be found in [RSL94, WRS92]. There has been considerable interest lately in the use of compiler directives to express timing constraints and in compiler techniques to transform programs to meet them <ref> [GH95, CD95, SMY95] </ref>. But that work concentrates on scheduling for a single processor, whereas we are primarily interested in creating a parallel partition of a program with concurrent scheduling on parallel processors. The main implementations of Sisal have been on shared memory multicomputers.
Reference: [Den95] <author> Jack B. Dennis. </author> <title> Static mapping of functional programs: An example in signal processing. </title> <booktitle> In Proc. of the High-Performance Functional Computing Conference '95, </booktitle> <address> Denver, Colorado, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: Computationally, the filters are regular and their behavior does not vary widely in response to input values. This determinism facilitates timing estimation and makes program transformation easier <ref> [Den95] </ref>. In this paper, we describe work in progress to define Sert and develop the necessary compiler technology to meet the needs of the RTSP community.
Reference: [DFRM94] <author> T. DeBoni, J. Feo, G. Rodrigue, and J. Muller. </author> <title> Implementation and performance of a domain decomposition algorithm in Sisal. </title> <booktitle> In Proc. of the Twenty-Seventh Ann. Hawaii Int. Conf. on System Sciences, </booktitle> <pages> pages 605-614, </pages> <year> 1994. </year>
Reference-contexts: Compared to conventional languages the lack of side effects enhances modularity and makes data dependencies much clearer to both the programmer and the compiler. The software engineering advantages are manifold: programs are much easier to write, modify, test and validate <ref> [DFRM94, Hen91] </ref>. Determinism guarantees that programs will run correctly regardless of the architecture features (operating system, memory hierarchy, communication network, number of processors) of the target machine. The benefits of determinism, particularly on parallel machines, should be obvious to anyone who has debugged a program with race conditions.
Reference: [DW79] <author> J. B. Dennis and K. S. Weng. </author> <title> An abstract implementation for concurrent computations with streams. </title> <booktitle> In Proc. of the 1979 Int. Conf. on Parallel Processing, </booktitle> <pages> pages 35-45, </pages> <address> Bellaire, Michigan, </address> <month> August 21-24, </month> <year> 1979. </year>
Reference-contexts: The development of better heuristics should allow us to handle more difficult tasks as well. 5 RELATED WORK The idea of using functional programs operating on streams of data to solve signal processing problems dates back to the early days of dataflow <ref> [Wen75, DW79] </ref>. One of the most elegant results in the theory of concurrency [Kah74] showed that the behavior of networks of time-insensitive processes communicating via streams can be simply described by domain-theoretic techniques.
Reference: [GGP92] <author> G. Gao, R. Govindarajan, and Prakash Panan-gaden. </author> <title> Well-behaved dataflow for DSP computation. </title> <booktitle> In ICASSP-92, 1992 International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <month> March </month> <year> 1992. </year>
Reference-contexts: Kahn's model can be extended to time-sensitive (even non-monotonic) processes such as a determinate, timed variant of the nondeterministic fair merge if time is made explicit in the semantics [YG93, Yat93]. Scheduling and buffer allocation in dataflow stream programs have been addressed in <ref> [Lee91a, Lee91b, GGP92] </ref>. Real-time programming with functional languages has also been done by groups using Signal, Lustre, Erlang and Haskell; however, these groups have not, to our knowledge, provided automatic parallelization to satisfy timing constraints. Signal [LGLL91] is a real-time equational language based on a particular synchronous theory of time.
Reference: [GH95] <author> R. Gerber and S. Hong. </author> <title> Compiling real-time programs with timing constraints refinement and structural code motion. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 21(5) </volume> <pages> 389-404, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Some in teresting work on the application of heuristics to real-time scheduling problems can be found in [RSL94, WRS92]. There has been considerable interest lately in the use of compiler directives to express timing constraints and in compiler techniques to transform programs to meet them <ref> [GH95, CD95, SMY95] </ref>. But that work concentrates on scheduling for a single processor, whereas we are primarily interested in creating a parallel partition of a program with concurrent scheduling on parallel processors. The main implementations of Sisal have been on shared memory multicomputers.
Reference: [GJ79] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and intractability: a guide to the theory of NP-completeness. W.H. </title> <publisher> Freeman, </publisher> <year> 1979. </year>
Reference-contexts: In some simple cases it is possible to find polynomial time scheduling algorithms, but in general these scheduling problems tend to be NP-hard <ref> [GJ79] </ref>. Some in teresting work on the application of heuristics to real-time scheduling problems can be found in [RSL94, WRS92]. There has been considerable interest lately in the use of compiler directives to express timing constraints and in compiler techniques to transform programs to meet them [GH95, CD95, SMY95].
Reference: [Gob94] <author> David M. Goblirsch. </author> <title> A software system for training phonetic hidden Markov models. </title> <type> Technical report, </type> <institution> The MITRE Corporation, </institution> <month> May </month> <year> 1994. </year> <note> Notes and programs available by ftp from haskell.systemsz.cs.yale.edu in file pub/haskell/incoming/hmms-2.0.tar.gz. </note>
Reference-contexts: Erlang [AVW93] is a "partially" functional language (side effects are allowed) for soft real-time systems that has been used in industrial telecommunications switches. In Erlang parallelism must be programmed explicitly. Haskell [H + 92] is a lazy functional language that has been used for prototyping some signal processing applications <ref> [Gob94] </ref>. Much more work has been done on the problem of scheduling for real-time systems than we could possibly report here. [SSDB95] and [ZLJW95] do a nice job of summarizing traditional scheduling results as applied to real-time systems.
Reference: [H + 92] <editor> Paul Hudak et al. </editor> <title> Report on the functional programming language Haskell. </title> <journal> SIGPLAN Notices, </journal> <volume> 27(5), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: The benefits of determinism, particularly on parallel machines, should be obvious to anyone who has debugged a program with race conditions. The greatest difference between Sisal and other functional languages such as Haskell <ref> [H + 92] </ref> is that Sisal is designed to allow efficient implementations on parallel supercomputers. The language does not require lazy evaluation, and there are many built-in operators to facilitate parallel construction and manipulation of arrays of data. <p> Erlang [AVW93] is a "partially" functional language (side effects are allowed) for soft real-time systems that has been used in industrial telecommunications switches. In Erlang parallelism must be programmed explicitly. Haskell <ref> [H + 92] </ref> is a lazy functional language that has been used for prototyping some signal processing applications [Gob94].
Reference: [HB91] <author> M. Haines and W. Bohm. </author> <title> Task management, virtual shared memory, and mutithreading in a distributed memory implementation of Sisal. </title> <booktitle> In Proc. of PARLE '91 Parallel Architectures and Languages Europe, </booktitle> <address> Eindhoven, The Netherlands, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: The main implementations of Sisal have been on shared memory multicomputers. However, some research has been done on implementing Sisal on distributed memory and non-uniform memory access architectures <ref> [HB91, PAM94a, WF93, Bea95] </ref>. 6 CONCLUSIONS In this paper we have described a functional language and compiler system for automatic parallelization, partitioning, and scheduling of real-time signal processing applications on general-purpose hardware.
Reference: [HCRP91] <author> N. Halbwachs, P. Caspi, P. Raymond, and D Pi-laud. </author> <title> The synchronous data flow programming language LUSTRE. </title> <journal> Proc. of the IEEE, </journal> <volume> 79(9) </volume> <pages> 1305-1320, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Signal [LGLL91] is a real-time equational language based on a particular synchronous theory of time. The emphasis of work on Signal to date has been on deducing properties of the program rather than on deriving multiprocessor implementations. Lustre <ref> [HCRP91] </ref> is a real-time functional language based on the same synchronous theory as Signal; as with Signal, work has focussed on program properties rather than on parallel implementations.
Reference: [Hen91] <author> Christopher P. Hendrickson. </author> <title> Programming a real code in a functional language. </title> <type> Technical Report UCRL-JC-108326, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: Compared to conventional languages the lack of side effects enhances modularity and makes data dependencies much clearer to both the programmer and the compiler. The software engineering advantages are manifold: programs are much easier to write, modify, test and validate <ref> [DFRM94, Hen91] </ref>. Determinism guarantees that programs will run correctly regardless of the architecture features (operating system, memory hierarchy, communication network, number of processors) of the target machine. The benefits of determinism, particularly on parallel machines, should be obvious to anyone who has debugged a program with race conditions.
Reference: [Kah74] <author> G. Kahn. </author> <title> The semantics of a simple language for parallel processing. </title> <booktitle> In Information Processing 74, </booktitle> <pages> pages 471-475, </pages> <year> 1974. </year>
Reference-contexts: One of the most elegant results in the theory of concurrency <ref> [Kah74] </ref> showed that the behavior of networks of time-insensitive processes communicating via streams can be simply described by domain-theoretic techniques.
Reference: [Lee91a] <author> E.A. Lee. </author> <title> Consistency in dataflow graphs. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> 2(2) </volume> <pages> 223-235, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Kahn's model can be extended to time-sensitive (even non-monotonic) processes such as a determinate, timed variant of the nondeterministic fair merge if time is made explicit in the semantics [YG93, Yat93]. Scheduling and buffer allocation in dataflow stream programs have been addressed in <ref> [Lee91a, Lee91b, GGP92] </ref>. Real-time programming with functional languages has also been done by groups using Signal, Lustre, Erlang and Haskell; however, these groups have not, to our knowledge, provided automatic parallelization to satisfy timing constraints. Signal [LGLL91] is a real-time equational language based on a particular synchronous theory of time.
Reference: [Lee91b] <author> E.A. Lee. </author> <title> Static scheduling of data-flow programs for DSP. </title> <editor> In J.-L. Gaudiot and L. Bic, editors, </editor> <booktitle> Advanced Topics in Data-Flow Computing. </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1991. </year>
Reference-contexts: Kahn's model can be extended to time-sensitive (even non-monotonic) processes such as a determinate, timed variant of the nondeterministic fair merge if time is made explicit in the semantics [YG93, Yat93]. Scheduling and buffer allocation in dataflow stream programs have been addressed in <ref> [Lee91a, Lee91b, GGP92] </ref>. Real-time programming with functional languages has also been done by groups using Signal, Lustre, Erlang and Haskell; however, these groups have not, to our knowledge, provided automatic parallelization to satisfy timing constraints. Signal [LGLL91] is a real-time equational language based on a particular synchronous theory of time.
Reference: [LGLL91] <author> P. LeGuernic, T. Gautier, M. LeBorgne, and C. LeMaire. </author> <title> Programming real-time applications with SIGNAL. </title> <journal> Proc. of the IEEE, </journal> <volume> 79(9) </volume> <pages> 1321-1336, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Scheduling and buffer allocation in dataflow stream programs have been addressed in [Lee91a, Lee91b, GGP92]. Real-time programming with functional languages has also been done by groups using Signal, Lustre, Erlang and Haskell; however, these groups have not, to our knowledge, provided automatic parallelization to satisfy timing constraints. Signal <ref> [LGLL91] </ref> is a real-time equational language based on a particular synchronous theory of time. The emphasis of work on Signal to date has been on deducing properties of the program rather than on deriving multiprocessor implementations.
Reference: [M + 85] <author> J. R. McGraw et al. </author> <title> SISAL: Streams and iteration in a single assignment language|language reference manual version 1.2. </title> <type> Technical Report M-146, </type> <institution> Lawrence Livermore National Laboratory, </institution> <year> 1985. </year>
Reference-contexts: Section 3 describes the extensions made to Sisal for managing timing constraints, while Section 4 looks briefly at how they might be applied to scheduling applications. Section 5 discusses some related work, and, finally, Section 6 offers some conclusions. 2 THE SISAL LANGUAGE Sisal <ref> [M + 85] </ref>, "Streams and Iteration in a Single Assignment Language," is a functional language designed for scientific applications on parallel computers.
Reference: [Nit89] <author> Peter Nitezki. </author> <title> Exploiting data parallelism in sig-nal processing in a data flow machine. </title> <journal> Computer Architecture News, </journal> <volume> 17(3) </volume> <pages> 54-61, </pages> <year> 1989. </year> <title> Also,Proc. </title> <booktitle> of the 16th International Symposium on Computer Architecture. </booktitle>
Reference-contexts: Our chosen application domain also offers significant advantages. Signal processing tasks generally operate as filters, consuming a stream of input datasets from a bank of sensors or other "real-world" input devices whose operations are well-defined and regular <ref> [Nit89] </ref>. Computationally, the filters are regular and their behavior does not vary widely in response to input values. This determinism facilitates timing estimation and makes program transformation easier [Den95].
Reference: [PAM94a] <author> S.S. Pande, D.P. Agrawal, and J. Mauney. </author> <title> Compiling functional parallelism on distributed-memory systems. </title> <journal> IEEE Parallel and Distributed Technology: Systems and Applications, </journal> <volume> 2(1), </volume> <month> Spring </month> <year> 1994. </year>
Reference-contexts: The main implementations of Sisal have been on shared memory multicomputers. However, some research has been done on implementing Sisal on distributed memory and non-uniform memory access architectures <ref> [HB91, PAM94a, WF93, Bea95] </ref>. 6 CONCLUSIONS In this paper we have described a functional language and compiler system for automatic parallelization, partitioning, and scheduling of real-time signal processing applications on general-purpose hardware.
Reference: [PAM94b] <author> S.S. Pande, D.P. Agrawal, and J. Mauney. </author> <title> A threshold scheduling strategy for Sisal on distributed memory machines. </title> <journal> J. of Parallel and Distributed Computing, </journal> <volume> 21(2) </volume> <pages> 223-236, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: In particular, this allows the Sisal compiler to estimate accurately the execution time of code segments and evaluate different scheduling and partitioning alternatives. Several research projects studying the program mapping problem have used Sisal and its intermediate form IF1 <ref> [Sar87, Wol94, PAM94b] </ref>.
Reference: [Pre86] <author> K. Preston, jr. </author> <title> Benchmark results | the abing-don cross. </title> <editor> In L. Uhr et al, editor, </editor> <title> Evaluation of multicomputers for Image Processing. </title> <publisher> Academic Press, </publisher> <address> Cambridge, Mass., </address> <year> 1986. </year>
Reference-contexts: Here, however, we present a very simple heuristic as a proof of concept. The Abingdon Cross <ref> [Pre86] </ref>, shown in Figure 3, is an image processing benchmark which consists of a series of filters to extract the skeletal axis of a cross from a larger image embedded in noise. The grayscale input image is first surrounded with a frame of black pixels in border ().
Reference: [RSL94] <author> Stefan Ronngren, Behrooz Shirazi, and Dan Lorts. </author> <title> Empirical evaluation of weighted and prioritized static scheduling heuristics for real-time multiprocessing. </title> <booktitle> In Proceedings of the Second Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <pages> pages 58-63, </pages> <year> 1994. </year>
Reference-contexts: In some simple cases it is possible to find polynomial time scheduling algorithms, but in general these scheduling problems tend to be NP-hard [GJ79]. Some in teresting work on the application of heuristics to real-time scheduling problems can be found in <ref> [RSL94, WRS92] </ref>. There has been considerable interest lately in the use of compiler directives to express timing constraints and in compiler techniques to transform programs to meet them [GH95, CD95, SMY95].
Reference: [Sar87] <author> Vivek Sarkar. </author> <title> Partitioning and Scheduling Parallel Programs for Execution on Multiprocessors. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> April </month> <year> 1987. </year> <type> Tech. </type> <institution> Rpt. CSL-TR-87-328. </institution>
Reference-contexts: In particular, this allows the Sisal compiler to estimate accurately the execution time of code segments and evaluate different scheduling and partitioning alternatives. Several research projects studying the program mapping problem have used Sisal and its intermediate form IF1 <ref> [Sar87, Wol94, PAM94b] </ref>.
Reference: [SMY95] <author> A. D. Stoyenko, T. J. Marlowe, and M. F. Younis. </author> <title> A language for complex real-time systems. </title> <journal> Computer Journal, </journal> <volume> 38(4) </volume> <pages> 319-338, </pages> <month> Novem-ber </month> <year> 1995. </year>
Reference-contexts: Some in teresting work on the application of heuristics to real-time scheduling problems can be found in [RSL94, WRS92]. There has been considerable interest lately in the use of compiler directives to express timing constraints and in compiler techniques to transform programs to meet them <ref> [GH95, CD95, SMY95] </ref>. But that work concentrates on scheduling for a single processor, whereas we are primarily interested in creating a parallel partition of a program with concurrent scheduling on parallel processors. The main implementations of Sisal have been on shared memory multicomputers.
Reference: [SSDB95] <author> J. A. Stankovic, M. Spuri, M. Di Natale, and G. C. Buttazzo. </author> <title> Implications of classical scheduling results for real-time systems. </title> <journal> IEEE Computer, </journal> <volume> 28(6) </volume> <pages> 16-25, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: In Erlang parallelism must be programmed explicitly. Haskell [H + 92] is a lazy functional language that has been used for prototyping some signal processing applications [Gob94]. Much more work has been done on the problem of scheduling for real-time systems than we could possibly report here. <ref> [SSDB95] </ref> and [ZLJW95] do a nice job of summarizing traditional scheduling results as applied to real-time systems. In some simple cases it is possible to find polynomial time scheduling algorithms, but in general these scheduling problems tend to be NP-hard [GJ79].
Reference: [Wen75] <author> K.S. Weng. </author> <title> Stream-oriented computation in recursive data flow schemes. </title> <type> Technical Report MAC/TM-68, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> October </month> <year> 1975. </year>
Reference-contexts: The development of better heuristics should allow us to handle more difficult tasks as well. 5 RELATED WORK The idea of using functional programs operating on streams of data to solve signal processing problems dates back to the early days of dataflow <ref> [Wen75, DW79] </ref>. One of the most elegant results in the theory of concurrency [Kah74] showed that the behavior of networks of time-insensitive processes communicating via streams can be simply described by domain-theoretic techniques.
Reference: [WF93] <author> R. Wolski and J. Feo. </author> <title> Program partitioning for NUMA multiprocessor computer systems. </title> <journal> J. of Parallel and Distributed Computing, </journal> <volume> 19(3), </volume> <month> November </month> <year> 1993. </year>
Reference-contexts: The main implementations of Sisal have been on shared memory multicomputers. However, some research has been done on implementing Sisal on distributed memory and non-uniform memory access architectures <ref> [HB91, PAM94a, WF93, Bea95] </ref>. 6 CONCLUSIONS In this paper we have described a functional language and compiler system for automatic parallelization, partitioning, and scheduling of real-time signal processing applications on general-purpose hardware.
Reference: [Wol94] <author> Richard M. Wolski. </author> <title> Program Partitioning and Scheduling for NUMA Computer Architectures. </title> <type> PhD thesis, </type> <institution> U. of California, Davis, </institution> <year> 1994. </year> <note> Also available as Lawrence Livermore National Laboratory Report URL-LR-117760. </note>
Reference-contexts: In particular, this allows the Sisal compiler to estimate accurately the execution time of code segments and evaluate different scheduling and partitioning alternatives. Several research projects studying the program mapping problem have used Sisal and its intermediate form IF1 <ref> [Sar87, Wol94, PAM94b] </ref>. <p> For the purposes of this example we have required it to accept one image every 2s and to take no longer than 10s per image. The target machine machine model will be a fictional 64-processor shared-memory architecture. Instruction timings are generated from a table of costs borrowed largely from <ref> [Wol94] </ref>. Table 3 gives the expected execution times of the constituent routines of ab cross () for various numbers of processors derived by manually traversing the IF1 graphs of the program and computing the worst case execution times with respect to the given operation costs. 1. Schedule everything sequentially. 2.
Reference: [WRS92] <author> Fuxing Wang, Krithi Ramamritham, and John Stankovic. </author> <title> Bounds on the performance of heuristic algorithms for multiprocessor scheduling of hard real-time tasks. </title> <booktitle> In IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 136-145, </pages> <year> 1992. </year>
Reference-contexts: In some simple cases it is possible to find polynomial time scheduling algorithms, but in general these scheduling problems tend to be NP-hard [GJ79]. Some in teresting work on the application of heuristics to real-time scheduling problems can be found in <ref> [RSL94, WRS92] </ref>. There has been considerable interest lately in the use of compiler directives to express timing constraints and in compiler techniques to transform programs to meet them [GH95, CD95, SMY95].
Reference: [Yat93] <author> R.K. Yates. </author> <title> Networks of real-time processes. </title> <booktitle> In Proceedings of Concur '93, </booktitle> <year> 1993. </year>
Reference-contexts: Kahn's model can be extended to time-sensitive (even non-monotonic) processes such as a determinate, timed variant of the nondeterministic fair merge if time is made explicit in the semantics <ref> [YG93, Yat93] </ref>. Scheduling and buffer allocation in dataflow stream programs have been addressed in [Lee91a, Lee91b, GGP92]. Real-time programming with functional languages has also been done by groups using Signal, Lustre, Erlang and Haskell; however, these groups have not, to our knowledge, provided automatic parallelization to satisfy timing constraints.
Reference: [YG93] <author> R.K. Yates and G.R Gao. </author> <title> A Kahn principle for networks of nonmonotonic real-time processes. </title> <booktitle> In Proceedings of PARLE '93, Parallel Architectures and Languages Europe. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Kahn's model can be extended to time-sensitive (even non-monotonic) processes such as a determinate, timed variant of the nondeterministic fair merge if time is made explicit in the semantics <ref> [YG93, Yat93] </ref>. Scheduling and buffer allocation in dataflow stream programs have been addressed in [Lee91a, Lee91b, GGP92]. Real-time programming with functional languages has also been done by groups using Signal, Lustre, Erlang and Haskell; however, these groups have not, to our knowledge, provided automatic parallelization to satisfy timing constraints.

References-found: 34

