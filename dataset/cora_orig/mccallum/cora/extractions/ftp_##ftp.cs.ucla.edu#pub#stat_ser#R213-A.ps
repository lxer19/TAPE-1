URL: ftp://ftp.cs.ucla.edu/pub/stat_ser/R213-A.ps
Refering-URL: http://singapore.cs.ucla.edu/csl_papers.html
Root-URL: http://www.cs.ucla.edu
Email: &lt;balke@cs.ucla.edu&gt; and &lt;judea@cs.ucla.edu&gt;  
Title: Probabilistic evaluation of counterfactual queries  
Author: Alexander Balke and Judea Pearl 
Address: Los Angeles, CA 90024  
Affiliation: Cognitive Systems Laboratory Computer Science Department University of California,  
Abstract: To appear in the Twelfth National Conference on Artificial Intelligence (AAAI-94), Seattle, WA, July 31 August 4, 1994. Technical Report R-213-A April, 1994 Abstract Evaluation of counterfactual queries (e.g., "If A were true, would C have been true?") is important to fault diagnosis, planning, and determination of liability. We present a formalism that uses probabilistic causal networks to evaluate one's belief that the counterfactual consequent, C, would have been true if the antecedent, A, were true. The antecedent of the query is interpreted as an external action that forces the proposition A to be true, which is consistent with Lewis' Miraculous Analysis. This formalism offers a concrete embodiment of the "closest world" approach which (1) properly reflects common understanding of causal influences, (2) deals with the uncertainties inherent in the world, and (3) is amenable to machine representation. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Balke, A., and Pearl, J. </author> <year> 1993. </year> <title> Nonparametric bounds on causal effects from partial compliance data. </title> <type> Technical Report R-199, </type> <institution> UCLA Cognitive Systems Lab. </institution>
Reference-contexts: We will refer to this domain-minimal variable as a response-function variable. r b is closely related to the potential response variables in Rubin's model of counterfactuals (Rubin 1974), which was introduced to facilitate causal inference in statistical analysis <ref> (Balke & Pearl 1993) </ref>. <p> If a reasonable distribution can be selected for each relevant disturbance variable, the implementation of the above algorithm is straightforward and the solution is unique; otherwise, bounds on the solution can be obtained using convex optimization techniques. <ref> (Balke & Pearl 1993) </ref> demonstrates this optimization task in 5 deriving bounds on causal effects from partially con-trolled experiments. A network generated by the above algorithm may often be simplified.
Reference: <author> Balke, A., and Pearl, J. </author> <year> 1994. </year> <title> Bounds on probabilistically evaluated counterfactual queries. </title> <type> Technical report, </type> <institution> UCLA Cognitive Systems Lab. </institution>
Reference-contexts: If prior distribu-tions over the relevant response-function variables cannot be assessed, we have developed methods of using the standard conditional-probability specification of Bayesian networks to compute upper and lower bounds on counterfactual probabilities <ref> (Balke & Pearl 1994) </ref>. The semantics and methodology introduced in this paper can be adopted to nonprobabilistic formalisms as well, as long as they support two essential components: abduction (to abduce plausible functional mechanisms from the factual observations) and causal projection (to infer the consequences of the action-like antecedent).
Reference: <author> Boutilier, C. </author> <year> 1992. </year> <title> A logic for revision and subjunctive queries. </title> <booktitle> In Proceedings Tenth National Conference on Artificial Intelligence, </booktitle> <pages> 609-15. </pages> <address> Menlo Park, CA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Druzdzel, M. J., and Simon, H. A. </author> <year> 1993. </year> <title> Causality in bayesian belief networks. </title> <booktitle> In Proceedings of the 9th Annual Conference on Uncertainty in Artificial Intelligence (UAI-93), </booktitle> <pages> 3-11. </pages>
Reference: <author> Ginsberg, M. L. </author> <year> 1986. </year> <title> Counterfactuals. </title> <booktitle> Artificial Intelligence 30 </booktitle> <pages> 35-79. </pages>
Reference-contexts: Ginsberg <ref> (Ginsberg 1986) </ref>, following a similar strategy, suggested that the logic of counterfactuals could be applied to problems in planning and diagnosis in Artificial Intelligence.
Reference: <author> Goodman, N. </author> <year> 1983. </year> <title> Fact, Fiction, and Forecast. </title> <address> Cam-bridge, MA: </address> <publisher> Harvard University Press, 4th edition. </publisher>
Reference: <author> Harper, W. L.; Stalnaker, R.; and Pearce, G., eds. </author> <year> 1981. </year> <title> Ifs: Conditionals, Belief, Decision, Chance, and Time. </title> <address> Boston, MA: D. </address> <publisher> Reidel. </publisher>
Reference: <author> Jackson, P. </author> <year> 1989. </year> <title> On the semantics of counterfactu-als. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <volume> 1382-7 vol. </volume> <pages> 2. </pages> <address> Palo Alto, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Lewis, D. </author> <year> 1976. </year> <title> Probability of conditionals and conditional probabilities. </title> <booktitle> The Philosophical Review 85 </booktitle> <pages> 297-315. </pages>
Reference-contexts: Therefore, it is more practical to ask not for the truth or falsity of a counterfactual, but for one's degree of belief in the counterfactual consequent given the antecedent. To account for such uncertainties, <ref> (Lewis 1976) </ref> has generalized the notion of "closest world" using the device of "imaging"; namely, the closest worlds are assigned probability scores, and these scores are combined to compute the probability of the consequent.
Reference: <author> Lewis, D. </author> <year> 1979. </year> <title> Counterfactual dependence and time's arrow. </title> <address> No^us 455-476. </address>
Reference-contexts: Our interpretation of counterfactual antecedents, which is similar to Lewis' <ref> (Lewis 1979) </ref> Miraculous Analysis, contrasts with interpretations that require that the counterfactual antecedent be consistent with the world in which the analysis occurs. The set of closest worlds delineated by the action-based interpretation contains all those which coincide with the factual world except on possible consequences of the action taken.
Reference: <author> Meyer, J.-J., and van der Hoek, W. </author> <year> 1993. </year> <title> Counter-factual reasoning by (means of) defaults. </title> <journal> Annals of Mathematics and Artificial Intelligence 9 </journal> <pages> 345-360. </pages>
Reference: <author> Nute, D. </author> <year> 1980. </year> <title> Topics in Conditional Logic. </title> <address> Boston: D. </address> <publisher> Reidel. </publisher>
Reference: <author> Pearl, J., and Verma, T. </author> <year> 1991. </year> <title> A theory of inferred causation. </title> <booktitle> In Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference, </booktitle> <pages> 441-452. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Probabilistic vs. functional specification In this section we will demonstrate that functionally modeled causal theories <ref> (Pearl & Verma 1991) </ref> are necessary for uniquely evaluating counterfactual queries, while the conditional probabilities used in the standard specification of Bayesian networks are insufficient for obtaining unique solutions. Reconsider the party example limited to the two variables A and B, representing Ann and Bob's attendance, respectively. <p> Assume that we are given a causal theory T = hD; fi D i as defined in <ref> (Pearl & Verma 1991) </ref>.
Reference: <author> Pearl, J. </author> <year> 1988. </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: For example, in the noisy-OR mechanism, which is often used to model causal interactions, the conditional probabilities are derivatives of a functional model involving AND/OR gates, corrupted by independent binary disturbances. This model is used, in fact, to simplify the specification of conditional probabilities in Bayesian networks <ref> (Pearl 1988) </ref>. 1 An observation by D. <p> Belief propagation. After instantiating the observations and actions in the network, evaluate the belief in c fl using the standard belief update methods for Bayesian networks <ref> (Pearl 1988) </ref>. The result is the solution to the counterfactual query. <p> At this time the algorithm has not been implemented but, given a subjective prior distribution over the re sponse variables, there are no new computational tasks introduced by this formalism, and the inference process follows the standard techniques for computing beliefs 7 in Bayesian networks <ref> (Pearl 1988) </ref>. If prior distribu-tions over the relevant response-function variables cannot be assessed, we have developed methods of using the standard conditional-probability specification of Bayesian networks to compute upper and lower bounds on counterfactual probabilities (Balke & Pearl 1994).
Reference: <author> Pearl, J. </author> <year> 1993a. </year> <title> Aspects of graphical models connected with causality. </title> <type> Technical Report R-195-LLL, </type> <institution> UCLA Cognitive Systems Lab. </institution> <note> Short version: Statistical Science 8(3) 266-269. </note>
Reference-contexts: In general, the domain for * b could contain many components, but it can always be replaced by an equivalent variable that is minimal, by partitioning the domain into equivalence regions, each corresponding to a single response function <ref> (Pearl 1993a) </ref>.
Reference: <author> Pearl, J. </author> <year> 1993b. </year> <title> From Adams' conditionals to default expressions, causal conditionals, and counterfac-tuals. </title> <type> Technical Report R-193, </type> <institution> UCLA Cognitive Systems Lab. </institution> <note> To appear in Festschrift for Ernest Adams, </note> <institution> Cambridge University Press, </institution> <year> 1994. </year>
Reference-contexts: This leads naturally to the use of probabilistic causal networks, since these networks combine causal and probabilistic knowledge and permit reasoning from causes to effects as well as, conversely, from effects to causes. To emphasize the causal character of counterfactu-als, we will adopt the interpretation in <ref> (Pearl 1993b) </ref>, according to which a counterfactual sentence "If it were A, then B would have been" states that B would prevail if A were forced to be true by some unspecified action that is exogenous to the other relationships considered in the analysis.
Reference: <author> Pearl, J. </author> <year> 1993c. </year> <title> From conditional oughts to qualitative decision theory. </title> <booktitle> In Uncertainty in Artificial Intelligence: Proceedings of the Ninth Conference, </booktitle> <pages> 12-20. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Every Bayes network can be represented by several functional specifications, each yielding different evaluations of a counterfactual. The problem is that, deciding what factual information deserves undoing (by the antecedent of the query) requires a model of temporal persistence, and, as noted in <ref> (Pearl 1993c) </ref>, such a model is not part of static Bayesian networks. Functional specification, however, implicitly contains the temporal persistence information needed. The next section introduces some useful notation for concisely expressing counterfactual sentences/queries. <p> However, in a dynamic environment subject to stochastic shocks a full temporal analysis using temporally-indexed networks may be warranted or, alternatively, a canonical model of persistence should be invoked <ref> (Pearl 1993c) </ref>. Acknowledgments The research was partially supported by Air Force grant #AFOSR 90 0136, NSF grant #IRI-9200918, Northrop Micro grant #92-123, and Rockwell Micro grant #92-122. Alexander Balke was supported by the Fannie and John Hertz Foundation. This work bene-fitted from discussions with David Heckerman.
Reference: <author> Pereira, L. M.; Aparicio, J. N.; and Alferes, J. J. </author> <year> 1991. </year> <title> Counterfactual reasoning based on revising assumptions. </title> <booktitle> In Logic Programming: Proceedings of the 1991 International Symposium, </booktitle> <pages> 566-577. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Poole, D. </author> <year> 1993. </year> <title> Probabilistic Horn abduction and Bayesian networks. </title> <booktitle> Artificial Intelligence 64(1) </booktitle> <pages> 81-130. </pages>
Reference: <author> Rubin, D. B. </author> <year> 1974. </year> <title> Estimating causal effects of treatments in randomized and nonrandomized studies. </title> <journal> Journal of Educational Psychology 66(5) </journal> <pages> 688-701. </pages>
Reference-contexts: We will refer to this domain-minimal variable as a response-function variable. r b is closely related to the potential response variables in Rubin's model of counterfactuals <ref> (Rubin 1974) </ref>, which was introduced to facilitate causal inference in statistical analysis (Balke & Pearl 1993).
Reference: <author> Skyrms, B. </author> <year> 1980. </year> <title> The prior propensity account of subjunctive conditionals. </title> <editor> In Harper, W.; Stalnaker, R.; and Pearce, G., eds., Ifs. D. </editor> <publisher> Reidel. </publisher> <pages> 259-265. </pages>
Reference-contexts: This is exactly the solution to the counterfactual query, P (b fl 1 ; a 0 ; b 0 ) = P 0 (r b =1) = P (r b =0) + P (r b =1) This analysis is consistent with the prior propensity account of <ref> (Skyrms 1980) </ref>.
Reference: <author> Spirtes, P.; Glymour, C.; and Scheines, R. </author> <year> 1993. </year> <title> Causation, Prediction, and Search. </title> <address> New York: </address> <publisher> Springer. </publisher>
Reference: <author> Whittaker, J. </author> <year> 1990. </year> <title> Graphical Models in Applied Mul-tivariate Statistics. </title> <address> New York: </address> <publisher> John Wiley & Sons. </publisher> <pages> 8 </pages>
Reference-contexts: The mean and covariance of the observable variables ~x are then given by: ~ x = S~ * (6) where S = (I B) 1 . Under such a model, there are well-known formulas <ref> (Whittaker 1990, p. 163) </ref> for evaluating the conditional mean and covariance of ~x under some observations ~o: ~ xjo = ~ x + x;o 1 x;xjo = x;x x;o 1 where, for every pair of sub-vectors, ~z and ~w, of ~x, z;w is the sub-matrix of x;x with entries corresponding to
References-found: 23

