URL: http://www.math.rutgers.edu/~sontag/FTP_DIR/neural-nets-siemens.ps.gz
Refering-URL: http://www.math.rutgers.edu/~sontag/papers.html
Root-URL: 
Title: Some Topics in Neural Networks and Control  
Author: Eduardo D. Sontag 
Abstract-found: 0
Intro-found: 1
Reference: [1] <editor> Albertini, F., and E.D. Sontag, </editor> <title> For neural networks, function determines form, </title> <booktitle> Neural Networks, </booktitle> <year> 1993, </year> <note> to appear. See also Proc. IEEE Conf. </note> <institution> Decision and Control, </institution> <address> Tucson, Dec. 1992, </address> <publisher> IEEE Publications, </publisher> <year> 1992, </year> <pages> pp. 26-31. </pages>
Reference-contexts: Before giving precise definitions of learnability in the sense just discussed, it is instructive to consider very informally a case which does not lead to learnability and one that does. Assume that the inputs u are real numbers uniformly distributed in the interval <ref> [0, 1] </ref> and that the set of functions F consists of the functions f k (u) := H (sin (ku)), over all positive integers k. That is, f k (u) is 1 if sin (ku) &gt; 0 and zero otherwise. <p> i ) for i = 1, . . . , s but f j (u) 6= f (u). (Recall that the set of values of (sin (lu 1 ), . . . , sin (lu s ), sin (lu)) , as l ranges over the positive integers, is dense in <ref> [1, 1] </ref> s+1 .) Since the learner is not able to decide, on the basis of the observed data, if f = f k or f = f j , the prediction f (u) cannot be made with any degree of reliability. <p> Contrast this example with the following one, at the other extreme: the functions F are now of the type f a (x) := H (x a), with a 2 <ref> [0, 1] </ref>. The concepts to be identified are the sets of the form fx &gt; ag. Identifying the concept means identifying the cut point a. <p> This is a generic set of triples, in the sense that the entries of the ones that do not satisfy the property are zeroes of certain nontrivial multivariable polynomials. Finally, let: S (n, m, p) = S (A, B, C, s) fi n,m,p . Then, in <ref> [1] </ref>, the following result was proved: Assume that s is odd and satisfies property (*). Then S ~ S if and only if S and S are sign-permutation equivalent. An analogous result can be proved when s is not odd, resulting in just permutation equivalence.
Reference: [2] <author> Albertini, F., E.D. Sontag, and V. Maillot, </author> <title> Uniqueness of weights for neural networks, in Artificial Neural Networks with Applications in Speech and Vision (R. Mammone, </title> <editor> ed.), </editor> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1993. </year>
Reference-contexts: His proof was based on explicit computations for the particular function tanh (x). An alternative proof is possible, using analytic continuations and residues, and allows a more general result to be established (see <ref> [2] </ref> for details, as well as [18] for further results using complex-variables techniques): Assume that s is a real-analytic function, and it extends to an analytic function s : C ! C defined on a subset D C of the form: D = fz j jIm zj l g n fz
Reference: [3] <author> Anthony, M., </author> <title> and N.L. Biggs, Computational Learning Theory: An Introduction, </title> <publisher> Cambridge U. Press, </publisher> <year> 1992. </year>
Reference-contexts: The next few paragraphs introduce the basic ideas, using terminology from learning theory; for more details see for instance the textbook <ref> [3] </ref>. In the PAC paradigm, a learner has access to data given by a labeled sample S = (u 1 , y 1 ), . . . , (u s , y s ).
Reference: [4] <editor> Aubin, J.-P., </editor> <booktitle> Mathematical Methods of Artificial Intelligence, </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1993, </year> <note> to appear. NEURAL NETWORKS AND CONTROL 32 </note>
Reference-contexts: Now one may attempt to minimize max x J (l , x) over l . This is the type of approach taken, for example, in <ref> [4] </ref>, in which the viability problem (make the state stay in a desired set) is attacked using neural net controllers. (The minimax character of the problem makes it suitable for nondifferentiable optimization techniques.) Estimate a Lyapunov or Bellman Function.
Reference: [5] <author> Baker, W.L., and J.A. Farrell, </author> <title> An introduction to connectionist learning control systems, </title> <booktitle> in [64]. </booktitle>
Reference-contexts: It is by no means the goal of this paper to provide an exhaustive survey of neurocontrol. Most recent major control conferences have had introductory courses devoted to the topic; in addition, many good overviews are available in the general literature (see for instance the papers <ref> [5] </ref>, [28], [8], [21], and other papers in the books [40] and [64]). Rather, there are two objectives.
Reference: [6] <author> Balc azar, J.L., R. Gavald a, H. Siegelmann, and E.D. Sontag, </author> <title> Some structural complexity aspects of neural computation, </title> <booktitle> in Proc. 8th Annual IEEE Conf. Structure in Complexity Theory, </booktitle> <address> San Diego, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: As with bilinear systems, it is obvious that if one imposes extra stability assumptions (fading memory type) it will be possible to obtain global approximations, but this is probably not very useful, as stability is often a goal of control rather than an assumption. 5.2. Computation The papers <ref> [51, 52, 6, 53] </ref>, and the references given there, dealt with computational capabilities of recurrent networks, seen from the point of view of classical formal language theory. <p> with real weights, that is, analog P, is exactly the same as a class also studied in computer science, namely the class of languages recognized in polynomial time by Turing machines which consult oracles, where the oracles are sparse sets. (Intermediate classes between P and analog P are studied in <ref> [6] </ref>.) This gives a precise characterization of the power of recurrent nets in terms of a known complexity class.
Reference: [7] <author> Barron, </author> <title> A.R., Neural net approximation, </title> <booktitle> in Proc. Seventh Yale Workshop on Adaptive and Learning Systems, </booktitle> <institution> Yale University, </institution> <year> 1992, </year> <pages> pp. 69-72. </pages>
Reference-contexts: In that case, it was remarked that f f (a) is in the closed convex hull of fVH (u b)g (in the uniform norm, and hence also in L 2 for any finite measure on [a, b ]). Generalizing, Barron in <ref> [7] </ref> suggested defining a function f : Q ! IR, where Q is a bounded subset of IR m , to have bounded variation with respect to halfspaces if this property holds: there exists a real number V so that, for some q 2 Q, f -f (q) is in the <p> Then, V f,Q 2C f . (Norm of w is standard Euclidean norm.) For the spaces ff j C f kg, k a fixed constant, Barron also proved (see references in <ref> [7] </ref>) that approximations by linear subspaces of dimension n would result in a worst-case error of at least O (n 1=d ), which is asymptotically worse than O (1= p n) when d &gt; 2.
Reference: [8] <author> Barto, </author> <title> A.G., Connectionist learning for control: An overview, </title> <booktitle> in [40]. </booktitle>
Reference-contexts: It is by no means the goal of this paper to provide an exhaustive survey of neurocontrol. Most recent major control conferences have had introductory courses devoted to the topic; in addition, many good overviews are available in the general literature (see for instance the papers [5], [28], <ref> [8] </ref>, [21], and other papers in the books [40] and [64]). Rather, there are two objectives. The first part of this paper attempts to explain the general context in which recent neuro-control work has taken place, namely the refocusing of attention on older numerical and learning techniques for control. <p> This is done by adjusting l after a complete training event, by means of, typically, a gradient descent step. The adaptive critic work by Barto and others (see <ref> [8] </ref> and the many references there) is one example of this approach, which is especially attractive when the overall goal is ill-defined in quantitative terms. <p> This type of work is also closely related to relatively old literature in learning control by researchers such as Mendel, Fu, and Sklansky in the mid to late 1960s and Narendra in the 1970s. See for instance references 64 and 74 in <ref> [8] </ref>, or 54 in [21]. Local Adaptive Control. One may consider several selected operating conditions, and design an adaptive (or a robust) controller for the linearization around each of them. <p> For instance, a human expert may be good at a given control task and one may want to duplicate her behavior. In this case, one may be able to fit a parameterized class of functions, on the basis of observations of typical controller operation; see references (e.g., 111) in <ref> [8] </ref>. Feedforward Control. A popular technique in neurocontrol is closely related to model reference adaptive control. Here a controller, in the form for instance of a recurrent network (see below), is trained in such a manner that when cascaded with the plant the composite system emulates a desired model. <p> The training is often done through gradient descent minimization of a cost functional. CONTROLLER PLANT DESIRED y A particular case that has been much explored experimentally -see for instance the references numbered 3, 4, 56, 58, 67, 79, and 90 in <ref> [8] </ref>- is the one where the desired model is a pure multiple delay (in discrete time) or integrator (continuous time), that is, the case of system inversion. A training set is obtained by generating inputs u () at random, and observing the corresponding outputs y () produced by the plant. <p> This issue was pointed out in the neural nets literature, and used in deriving algorithms. The article <ref> [8] </ref> (in particular references 46, 104, 105, and 106 there) deals with this issue in some detail. 2.6. Modeling via Recurrent Nets An especially popular architecture for systems identification (models S k l ) has been that of recurrent neural nets.
Reference: [9] <author> Benedek, G.M., and A. Itai, </author> <title> Learnability by fixed distributions, </title> <journal> Theoretical Comp. Sci. </journal> <volume> 86(1991): </volume> <pages> 377-389. </pages>
Reference-contexts: It is perfectly possible for an F not to be learnable in the above sense but to be learnable if the inputs are assumed to be Gaussian, for instance. Notions of Kolmogorov metric entropy are used to characterize such learning; see for instance <ref> [9] </ref> and [32]. (In the case of learning with respect to particular data distributions, the naive identification procedure is no longer guaranteed to work, and more sophisticated methods must be used.) Another variation consists of studying the computational effort required in order to use the identifier j; the definition given above
Reference: [10] <author> Baum, E.B., and D. Haussler, </author> <title> What size net gives valid generalization?, </title> <booktitle> Neural Computation 1(1989): </booktitle> <pages> 151-160. </pages>
Reference-contexts: So the VC dimension completely NEURAL NETWORKS AND CONTROL 20 characterizes learnability with respect to unknown distributions; in fact, the constant c in the sample complexity bound given earlier is a simple function of the number VC (F ), independent of F itself. It follows from the results in <ref> [10] </ref> that, for the class H (F n,s,m ) of classifiers implementable by 1HL nets with with n hidden units and m inputs (n and m fixed) and activation s = H, VC (F ) &lt; dmn (1 + log (n)), for a small constant d.
Reference: [11] <author> Blum, A., and R.L. Rivest, </author> <title> Training a 3-node neural network is NP-complete, </title> <booktitle> in Advances in Neural Information Processing Systems 2 (D.S. </booktitle> <editor> Touretzky, ed), </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990, </year> <pages> pp. 9-18. </pages>
Reference-contexts: complexity of the loading problem: do there exist weights that satisfy the desired objective? For fixed input dimension and Heaviside activations, this becomes essentially a linear programming problem, but even for such activations, the problem is NP-hard when scaling with respect to the number of input or output dimensions; see <ref> [11] </ref> and [29] for much on this issue. 4.5.
Reference: [12] <author> Blumer, A., A. Ehrenfeucht, D. Haussler, and M. Warmuth, </author> <title> Classifying learnable geometric concepts with the Vapnik-Chervonenkis dimension, </title> <booktitle> in Proc. 18th. Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 273-282, </pages> <publisher> ACM, Salem, </publisher> <year> 1986. </year>
Reference-contexts: is the supremum (possibly infinite) of the set of integers k for which there is some set S of cardinality k that can be shattered by F . (Thus, VC (F ) is at least as large as the capacity c (F ) defined earlier.) The main result, due to <ref> [12] </ref>, but closely related to previous results in statistics (see [63]) is: The class F is learnable if and only if VC (F ) &lt; 1.
Reference: [13] <author> Boyd, S., and L.O. Chua, </author> <title> Uniqueness of a basic nonlinear structure IEEE Trans. </title> <booktitle> Circuits and Systems CAS-30(1983): </booktitle> <pages> 648-651. </pages>
Reference-contexts: Results in this case are closely related to work in the 1970s by Rugh and coworkers and by Boyd and Chua in the early 1980s; see e.g. [55] and <ref> [13] </ref>. It appears to be harder to obtain elegant characterizations of the stronger (and more interesting) property IP. For obvious examples of functions not satisfying IP, take s (x) = e x , any periodic function, or any polynomial.
Reference: [14] <author> Carroll, S.M., and B.W. Dickinson, B.W., </author> <title> Construction of neural nets using the Radon transform, </title> <booktitle> in Proc. 1989 Int. Joint Conf. Neural Networks, </booktitle> <pages> pp. </pages> <publisher> I: </publisher> <pages> 607-611. </pages>
Reference-contexts: NEURAL NETWORKS AND CONTROL 15 Instead of polynomials, one can also base the reduction proof on Fourier expansions. For this, it is enough to see that trigonometric polynomials satisfy the conditions of the Stone-Weierstrass Theorem. Other proofs use various algorithms for reconstruction from projections, such as Radon transforms (see <ref> [14] </ref>). In conclusion, universality guarantees that functions of the type (5) are dense in C 0 . One can also establish density results for L q spaces, q &lt; 1, on compact sets, simply using for those spaces the density of continuous functions.
Reference: [15] <author> Chen, F.C., and H.K. Khalil, </author> <title> Adaptive control of nonlinear systems using neural networks, </title> <booktitle> Proc. IEEE Conf. Decision and Control, Hawaii, </booktitle> <address> Dec. 1990, </address> <publisher> IEEE Publications, </publisher> <year> 1990. </year>
Reference-contexts: In general, however, there are absolutely no guarantees that such a procedure solves the tracking problem, and only simulations are offered in the literature to justify the approach. (An exception are certain local convergence results; see e.g. <ref> [15] </ref>.) Moreover, the control problem itself was capable of being trivially solved by feedback linearization, once that the plant was identified.
Reference: [16] <author> Cybenko, G., </author> <title> Approximation by superpositions of a sigmoidal function, Math. Control, Signals, </title> <booktitle> and Systems 2(1989): </booktitle> <pages> 303-314. </pages>
Reference-contexts: Then, s is a universal activation if and only if it is not a polynomial. Previous results along these lines were obtained in [27], which established that any s which is continuous, nonconstant, and bounded is universal (see also <ref> [16] </ref> and [20, 61] for other related older results). The proof in [34] is based essentially on two steps: First, one reduces, by convolution, to the case in which s is infinitely differentiable (and nonpolynomial).
Reference: [17] <author> Darken, C., M. Donahue, L. Gurvits, and E. Sontag, </author> <title> Rate of approximation results motivated by robust neural network learning, </title> <booktitle> in Proc. Sixth ACM Workshop on Computational Learning Theory, </booktitle> <address> Santa Cruz, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Note that the approximations, as they use Maurey-type arguments, hold a priori only in L 2 (or other Hilbert spaces). Indeed, these arguments are false for approximation in L 1 , if the set G is arbitrary (see <ref> [17] </ref> for this and related remarks). However, Barron in the above reference was also able to prove a similar result for the particular case in which G corresponds to characteristic functions of half-spaces, using a deeper result due to Dudley.
Reference: [18] <author> Fefferman, C., </author> <title> Reconstructing a neural net from its output, </title> <type> submitted (preprint, </type> <institution> Mathematics Dept., Princeton, </institution> <year> 1993). </year>
Reference-contexts: His proof was based on explicit computations for the particular function tanh (x). An alternative proof is possible, using analytic continuations and residues, and allows a more general result to be established (see [2] for details, as well as <ref> [18] </ref> for further results using complex-variables techniques): Assume that s is a real-analytic function, and it extends to an analytic function s : C ! C defined on a subset D C of the form: D = fz j jIm zj l g n fz 0 , z 0 g for
Reference: [19] <author> Flick, T.E., L.K. Jones, R.G. Priest, and C. Herman, </author> <title> Pattern classification using projection pursuit, </title> <booktitle> Pattern Recognition 23(1990): </booktitle> <pages> 1367-1376. </pages>
Reference-contexts: are used in statistics and pattern classification, in particular when applying projection pursuit techniques, which incrementally build f by choosing the directions B i , i = 1, . . . , r in a systematic way so as to minimize an approximation or classification error criterion; see for instance <ref> [19] </ref>. Note that F s,m is precisely the set of those multiridge functions for which there are scalars c i such that s i = c i s for all i.
Reference: [20] <author> Funahashi, K., </author> <title> On the approximate realization of continuous mappings by neural networks, </title> <booktitle> Neural Networks 2(1989): </booktitle> <pages> 183-192. </pages>
Reference-contexts: Then, s is a universal activation if and only if it is not a polynomial. Previous results along these lines were obtained in [27], which established that any s which is continuous, nonconstant, and bounded is universal (see also [16] and <ref> [20, 61] </ref> for other related older results). The proof in [34] is based essentially on two steps: First, one reduces, by convolution, to the case in which s is infinitely differentiable (and nonpolynomial).
Reference: [21] <author> Franklin, J.A., </author> <title> Historical perspective and state of the art in connectionist learning control, </title> <booktitle> Proc. IEEE Conf. Decision and Control, </booktitle> <address> Tampa, Dec. 1989, </address> <publisher> IEEE Publications, </publisher> <year> 1989. </year>
Reference-contexts: It is by no means the goal of this paper to provide an exhaustive survey of neurocontrol. Most recent major control conferences have had introductory courses devoted to the topic; in addition, many good overviews are available in the general literature (see for instance the papers [5], [28], [8], <ref> [21] </ref>, and other papers in the books [40] and [64]). Rather, there are two objectives. The first part of this paper attempts to explain the general context in which recent neuro-control work has taken place, namely the refocusing of attention on older numerical and learning techniques for control. <p> This type of work is also closely related to relatively old literature in learning control by researchers such as Mendel, Fu, and Sklansky in the mid to late 1960s and Narendra in the 1970s. See for instance references 64 and 74 in [8], or 54 in <ref> [21] </ref>. Local Adaptive Control. One may consider several selected operating conditions, and design an adaptive (or a robust) controller for the linearization around each of them.
Reference: [22] <author> Grossberg, S., </author> <title> Some Nonlinear Networks Capable of Learning a Spatial Pattern of Arbitrary Complexity, </title> <booktitle> Proceedings of the National Academy of Sciences, USA 59(1968): </booktitle> <pages> 368-372. </pages>
Reference-contexts: During the mid 1970s many authors continued work on models of neural nets, notably Grossberg and his school see for instance <ref> [22] </ref> with most of this work attempting to produce differential equation models of various conditioning phenomena. Work by Kohonen and others (see [31] and references there) on feature extraction and clustering techniques was also prominent during this period.
Reference: [23] <author> Haussler, D., </author> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications, </title> <booktitle> Information and Computation 100(1992): </booktitle> <pages> 78-150. </pages>
Reference-contexts: Thus sigmoidal nets appear to have some special properties, vis a vis other possible more general parametric classes of functions, at least from a learnability viewpoint. Other results on finiteness of learning, but from a more statistical viewpoint (nonlinear regression, estimation of joint densities), are given in <ref> [23] </ref>, where metric entropy estimates are obtained for networks with bounded weights. The results on learnability just explained extend to other classes of feedforward nets, including 2HL nets (defined below) and nets involving products of inputs (high order nets), but such more general results will not be reviewed here.
Reference: [24] <author> Hebb, </author> <title> D.O., The Organization of Behavior, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1949. </year>
Reference: [25] <author> Hertz, J., A. Krogh, and R.G. Palmer, </author> <title> Introduction to the Theory of Neural Computation, </title> <publisher> Addison-Wesley, </publisher> <address> Redwood City, </address> <year> 1991. </year>
Reference-contexts: See the textbook <ref> [25] </ref> for a clear and well-written, if mathematically incomplete, introduction to neural nets. Motivating the use of nets is the belief still not mathematically justified that in some sense they are an especially appropriate family of parameterized models.
Reference: [26] <author> Hopfield, J.J., </author> <title> Neurons with graded responses have collective computational properties like those of two-state neurons, </title> <booktitle> Proc. </booktitle> <institution> of the Natl. Acad. of Sciences, </institution> <address> USA 81(1984): </address> <pages> 3088-3092. </pages>
Reference-contexts: Work by Kohonen and others (see [31] and references there) on feature extraction and clustering techniques was also prominent during this period. The resurgence in interest during the mid 1980s can be traced to two independent events. One was the work by Hopfield (see <ref> [26] </ref>) on the design of associative memories, and later the solution of optimization problems, using a special type of recurrent networks. The other was the suggestion to return to Rosenblatt's feedforward nets, but using now differentiable, sigmoidal, activation functions s.
Reference: [27] <author> Hornik, K., </author> <title> Approximation capabilities of multilayer feedforward networks, </title> <booktitle> Neural Networks 4(1991): </booktitle> <pages> 251-257. </pages> <booktitle> NEURAL NETWORKS AND CONTROL 33 </booktitle>
Reference-contexts: Then, s is a universal activation if and only if it is not a polynomial. Previous results along these lines were obtained in <ref> [27] </ref>, which established that any s which is continuous, nonconstant, and bounded is universal (see also [16] and [20, 61] for other related older results). <p> One can also establish density results for L q spaces, q &lt; 1, on compact sets, simply using for those spaces the density of continuous functions. Approximation results on noncompact spaces, in L q but for finite measures, are also possible but considerably harder; see <ref> [27] </ref>. It is false, on the other hand, that one can do uniform approximation of more or less arbitrary discontinuous functions, that is, approximation in L 1 , even on compact sets. <p> Pick any s which has the property that twice continuously differentiable functions can be approximated uniformly, together with their derivatives, using 1HL nets (most interesting twice-differentiable scalar nonlinearities will do; see <ref> [27] </ref>). Then, one can conclude that there is also a different k, this one a 1HL net with activation s, for which exactly the same stabilization property holds. A sketch of proof is as follows.
Reference: [28] <author> Hunt, K.J., D. Sbarbaro, R. Zbikowski, and P.J. Gawthrop, </author> <title> Neural networks for control systems: A survey, </title> <type> Automatica 28(1992): </type> <pages> 1083-1122. </pages>
Reference-contexts: It is by no means the goal of this paper to provide an exhaustive survey of neurocontrol. Most recent major control conferences have had introductory courses devoted to the topic; in addition, many good overviews are available in the general literature (see for instance the papers [5], <ref> [28] </ref>, [8], [21], and other papers in the books [40] and [64]). Rather, there are two objectives. The first part of this paper attempts to explain the general context in which recent neuro-control work has taken place, namely the refocusing of attention on older numerical and learning techniques for control.
Reference: [29] <author> Judd, J.S., </author> <title> Neural Network Design and the Complexity of Learning, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: the loading problem: do there exist weights that satisfy the desired objective? For fixed input dimension and Heaviside activations, this becomes essentially a linear programming problem, but even for such activations, the problem is NP-hard when scaling with respect to the number of input or output dimensions; see [11] and <ref> [29] </ref> for much on this issue. 4.5.
Reference: [30] <author> Killian, J., and H.T. </author> <title> Siegelmann, </title> <booktitle> On the power of sigmoid neural networks, in Proc. Sixth ACM Workshop on Computational Learning Theory, </booktitle> <address> Santa Cruz, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Computation The papers [51, 52, 6, 53], and the references given there, dealt with computational capabilities of recurrent networks, seen from the point of view of classical formal language theory. This work studied discrete-time recurrent networks, focusing on the activation s = p. (More general nonlinearities, as in <ref> [30] </ref>, as well as continuous-time systems are of interest, but note that using s = sign would give no more computational power than finite automata.) The main results after precise definitions are: (1) with rational matrices A, B, and C, recurrent networks are computationally equivalent, up to polynomial time, to Turing
Reference: [31] <author> Kohonen, T., </author> <title> Self-Organization and Associative Memory (3rd ed.), </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1989. </year>
Reference-contexts: During the mid 1970s many authors continued work on models of neural nets, notably Grossberg and his school see for instance [22] with most of this work attempting to produce differential equation models of various conditioning phenomena. Work by Kohonen and others (see <ref> [31] </ref> and references there) on feature extraction and clustering techniques was also prominent during this period. The resurgence in interest during the mid 1980s can be traced to two independent events.
Reference: [32] <author> Kulkarni, </author> <title> S.R. Problems of Computational and Information Complexity in Machine Vision and Learning, </title> <type> Ph.D. Thesis, </type> <institution> Department of Electrical Engineering and Computer Science, M.I.T., </institution> <year> 1991. </year>
Reference-contexts: It is perfectly possible for an F not to be learnable in the above sense but to be learnable if the inputs are assumed to be Gaussian, for instance. Notions of Kolmogorov metric entropy are used to characterize such learning; see for instance [9] and <ref> [32] </ref>. (In the case of learning with respect to particular data distributions, the naive identification procedure is no longer guaranteed to work, and more sophisticated methods must be used.) Another variation consists of studying the computational effort required in order to use the identifier j; the definition given above is purely
Reference: [33] <author> Lane, S.H., D. Handelman, J. Gelfand, and M. Flax, </author> <title> Function approximation using multi-layered neural networks with B-spline receptive fields, </title> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <editor> (R.P. Lippmann, J. Moody, D.S. Touretzky, eds.), </editor> <publisher> Morgan Kaufmann (San Mateo, </publisher> <year> 1991). </year>
Reference-contexts: Localized receptive fields play a role quite analogous, for approximation problems, to splines, and this connection is explored in <ref> [33] </ref>. The box labeled PC represents a precomputed (part of the) controller which also is invariant in structure during operation. Included here are, as examples: Gain Scheduled Control Laws.
Reference: [34] <author> Leshno, M., V.Ya. Lin, A. Pinkus, and S. Schocken, </author> <title> Multilayer feedforward networks with a non-polynomial activation function can approximate any function, </title> <booktitle> Neural Networks, </booktitle> <year> 1993. </year>
Reference-contexts: But most nonlinear functions are universal. A conclusive result has recently been obtained and is as follows; see <ref> [34] </ref>: Assume that s is locally Riemann integrable, that is, it is continuous except at most in a set of measure zero, and it is bounded on each compact. Then, s is a universal activation if and only if it is not a polynomial. <p> Previous results along these lines were obtained in [27], which established that any s which is continuous, nonconstant, and bounded is universal (see also [16] and [20, 61] for other related older results). The proof in <ref> [34] </ref> is based essentially on two steps: First, one reduces, by convolution, to the case in which s is infinitely differentiable (and nonpolynomial).
Reference: [35] <author> Livstone, M.M., J.A. Farrell, and W.L. Baker, </author> <title> A computationally efficient algorithm for training recurrent connectionist networks, </title> <booktitle> in Proc. Amer. Automatic Control Conference, </booktitle> <address> Chicago, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: The estimate x [tjt] can be used instead of x. (If only partial observations are available, an output mapping y = h (x) + x 2 may be assumed instead of the identity, and a similar procedure may be followed.) See, for instance, [37] and <ref> [35] </ref> for this type of parametric nonlinear adaptive control approach.
Reference: [36] <author> Macintyre, M., and E.D. Sontag, </author> <title> Finiteness results for sigmoidal `neural' networks, </title> <booktitle> in Proc. 25th Annual Symp. Theory Computing, </booktitle> <address> San Diego, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Again here, INTP (p) = 2=3 , and one can also show that 2=3 INTP (s s ) 1 for the standard sigmoid (the proof of the upper bound in this latter case involves some algebraic geometry; the value may be infinite for more general sigmoids; see also <ref> [36] </ref>). Furthermore, the inequality INTP (s) 1=3 holds for any universal nonlinearity. Obtaining the precise value for s s is a very interesting open problem. Note that the above discussion focused on general bounds on what can be achieved. <p> It is easy to construct examples of sigmoids, even extremely well-behaved ones (analytic and squashing, for instance) for which the VC dimension of the class H (F n,s,m ) is infinite; see [57]. However, for the standard sigmoid, a recent result in <ref> [36] </ref> proves that VC (F ) &lt; 1, so neural nets with activation s s are also learnable. Thus sigmoidal nets appear to have some special properties, vis a vis other possible more general parametric classes of functions, at least from a learnability viewpoint.
Reference: [37] <author> Matthews, M., </author> <title> A state-space approach to adaptive nonlinear filtering using recurrent neural networks, </title> <booktitle> Proc. 1990 IASTED Symp. on Artificial Intelligence Applications and Neural Networks, Z urich, </booktitle> <pages> pp. 197-200, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: The estimate x [tjt] can be used instead of x. (If only partial observations are available, an output mapping y = h (x) + x 2 may be assumed instead of the identity, and a similar procedure may be followed.) See, for instance, <ref> [37] </ref> and [35] for this type of parametric nonlinear adaptive control approach.
Reference: [38] <author> McBride, L.E., </author> <title> and K.S. Narendra, Optimization of time-varying systems, </title> <journal> IEEE Trans. Autom. Control, </journal> <volume> 10(1965): </volume> <pages> 289-294. </pages>
Reference-contexts: Viewing the parameters as constant states, the second term can be obtained by solving the variational or linearized equation along the trajectory corresponding to the control u (), for the system obtained when using the current parameters l ; see for instance Theorem 1 in [56]. (One old reference is <ref> [38] </ref>.) Such an approach is known in network circles as the real time recurrent learning algorithm, and it is often pointed out that it involves a fairly large amount of variables, as the full fundamental solution (an n fi n matrix of functions) must be solved for.
Reference: [39] <author> McCulloch, W.S., and W. Pitts, </author> <title> A logical calculus of the ideas immanent in nervous activity, </title> <journal> Bull. Math. Biophys. </journal> <volume> 5(1943): </volume> <pages> 115-133. </pages>
Reference-contexts: A Very Brief History In the 1940s, McCulloch and Pitts introduced in <ref> [39] </ref> the idea of studying the computational abilities of networks composed of simple models of neurons.
Reference: [40] <author> Miller, T., R.S. Sutton, and P.J. Werbos (eds.), </author> <title> Neural networks For Control, </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1990. </year>
Reference-contexts: Most recent major control conferences have had introductory courses devoted to the topic; in addition, many good overviews are available in the general literature (see for instance the papers [5], [28], [8], [21], and other papers in the books <ref> [40] </ref> and [64]). Rather, there are two objectives. The first part of this paper attempts to explain the general context in which recent neuro-control work has taken place, namely the refocusing of attention on older numerical and learning techniques for control. <p> Instead of characteristic functions, a more fuzzy weighting profile may be used, corresponding to degrees of membership. The possible overlap of regions of influence allows for distributed representations of the input; CMAC-type controllers (see e.g. papers in <ref> [40] </ref>) employ such representations together with hashing memory addressing systems for associative recall. Localized receptive fields play a role quite analogous, for approximation problems, to splines, and this connection is explored in [33].
Reference: [41] <author> Minsky, M., and S. Papert, </author> <title> Perceptrons: An Introduction to Computational Geometry, Expanded Edition, </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1988. </year>
Reference-contexts: When the expectations were not met, Rosenblatt suffered from the backlash, and the work was to a great extent abandoned. The book by Minsky and Papert <ref> [41] </ref> is widely credited with showing the mathematical limitations of perceptrons and contributing to the decline of the area, but Rosenblatt was already well-aware, judging from his book, of the difficulties with his models and analysis techniques.
Reference: [42] <author> Niranjan, M. and F. Fallside, </author> <title> Neural networks and radial basis functions in classifying static speech patterns, </title> <booktitle> Computer Speech and Language 4 (1990): </booktitle> <pages> 275-289. </pages>
Reference-contexts: The weights are programmable parameters that are then numerically adjusted in order to model a plant or a controller. In some of the literature, see e.g. <ref> [42, 44] </ref>, each scalar nonlinear unit acts on a scalar quantity equal to the distance between the incoming signal and a reference (vector) value; this is in contrast to operating on a linear combination of the components of the incoming signal, and gives rise to radial basis function nets, which are
Reference: [43] <author> Pisier, G., Remarques sur un resultat non publi e de B. Maurey, </author> <note> in Seminaire d'analyse fonctionelle 1980-1981, </note> <institution> Ecole Polytechnique, Palaiseau, </institution> <year> 1981. </year>
Reference-contexts: The rest of this section reviews some of the basic results in question. The main tool is the following Lemma, which is often attributed to Maurey (see <ref> [43] </ref>): NEURAL NETWORKS AND CONTROL 21 Let G be a bounded subset of a Hilbert space H, with kgk g for all g 2 G, and let G n be the subset of H consisting of all convex combinations of at most n elements of G.
Reference: [44] <author> Poggio, T., and F. Girosi, </author> <title> Networks for approximation and learning, </title> <booktitle> Proc. of the IEEE 78(1990): </booktitle> <pages> 1481-1497. </pages>
Reference-contexts: The weights are programmable parameters that are then numerically adjusted in order to model a plant or a controller. In some of the literature, see e.g. <ref> [42, 44] </ref>, each scalar nonlinear unit acts on a scalar quantity equal to the distance between the incoming signal and a reference (vector) value; this is in contrast to operating on a linear combination of the components of the incoming signal, and gives rise to radial basis function nets, which are
Reference: [45] <author> Polycarpou, </author> <title> M.M., and P.A. Ioannou, Neural networks and on-line approximators for adaptive control, </title> <booktitle> in Proc. Seventh Yale Workshop on Adaptive and Learning Systems, </booktitle> <pages> pp. 93-798, </pages> <institution> Yale University, </institution> <year> 1992. </year>
Reference-contexts: techniques for parameter identification possibly in conjunction with sliding mode robust control, to handle the regions where the true f differs considerably from the best possible model of the form F (x, l ) can be proved to converge in various senses; see especially [54], as well as for instance <ref> [45] </ref>.
Reference: [46] <author> Rosenblatt, F., </author> <title> Principles of Neurodynamics, </title> <publisher> Spartan Books, </publisher> <address> New York, </address> <year> 1962. </year>
Reference-contexts: It is a widely held misconception that this latter special case was the main one that he considered.) The book <ref> [46] </ref> summarized achievements in the area. His goal was more the understanding of real brains than the design of artificial pattern recognition devices, but many saw and promoted his work as a means towards the latter.
Reference: [47] <editor> Rumelhart, D.E., and J.L. McClelland, </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> vol. 1, </volume> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1986. </year>
Reference-contexts: Differentiability makes it possible to employ steepest descent on weight (parameter) space, in order to find nets that compute a desired function or interpolate at desired values. This was emphasized in the very popular series of books and papers by the Parallel Distributed Processing research group see for instance <ref> [47] </ref> NEURAL NETWORKS AND CONTROL 10 and came to be known under the term backpropagation. (The term comes from the fact that in computing the gradient of an error criterion with respect to parameters, via the chain rule, one multiplies a product such as the one in equation (4) from left
Reference: [48] <author> Scalero, R.S., and N. Tepedelenlioglu, </author> <title> Fast Algorithm for Training Feed-forward Neural Networks, </title> <journal> IEEE Trans. Signal Processing TSP-40(1992): </journal> <pages> 202-210. </pages>
Reference-contexts: In this category one often finds work in, for instance, the following topics (which will not be treated here): Numerical techniques for solving neural net approximation problems. Much work has been done on using conjugate gradient and quasi-Newton algorithms and other speeding-up techniques. See for instance <ref> [48, 50] </ref> and especially the report [49]. Statistical studies. In network learning systems, all the usual issues associated to estimation arise: the tradeoff between variance and bias (or, in AI terms, between generality and generalization).
Reference: [49] <author> Schiffmann, W., M. Joost, and R. Werner, </author> <title> Optimization of the Backpropagation Algorithm for Training Multilayer Perceptrons, </title> <type> Tech Report, </type> <institution> University of Koblenz, Institute of Physics, </institution> <month> January </month> <year> 1993. </year> <title> NEURAL NETWORKS AND CONTROL 34 </title>
Reference-contexts: Much work has been done on using conjugate gradient and quasi-Newton algorithms and other speeding-up techniques. See for instance [48, 50] and especially the report <ref> [49] </ref>. Statistical studies. In network learning systems, all the usual issues associated to estimation arise: the tradeoff between variance and bias (or, in AI terms, between generality and generalization). Cross-validation and other techniques are often applied; see for instance the book [65] for much on this topic.
Reference: [50] <author> Schmidhuber, J., </author> <title> Accelerated Learning in Back-Propagation Nets, in Connectionism in Perspective, </title> <publisher> Elsevier, </publisher> <year> 1989, </year> <pages> pp. 439-445. </pages>
Reference-contexts: In this category one often finds work in, for instance, the following topics (which will not be treated here): Numerical techniques for solving neural net approximation problems. Much work has been done on using conjugate gradient and quasi-Newton algorithms and other speeding-up techniques. See for instance <ref> [48, 50] </ref> and especially the report [49]. Statistical studies. In network learning systems, all the usual issues associated to estimation arise: the tradeoff between variance and bias (or, in AI terms, between generality and generalization).
Reference: [51] <editor> Siegelmann, H.T., and E.D. Sontag, </editor> <booktitle> On the computational power of neural nets, in Proc. Fifth ACM Workshop on Computational Learning Theory, </booktitle> <address> Pittsburgh, </address> <month> July </month> <year> 1992, </year> <pages> 440-449. </pages> <note> Extended version to appear in J. </note> <institution> Computer Syst. Sci.. </institution>
Reference-contexts: As with bilinear systems, it is obvious that if one imposes extra stability assumptions (fading memory type) it will be possible to obtain global approximations, but this is probably not very useful, as stability is often a goal of control rather than an assumption. 5.2. Computation The papers <ref> [51, 52, 6, 53] </ref>, and the references given there, dealt with computational capabilities of recurrent networks, seen from the point of view of classical formal language theory.
Reference: [52] <author> Siegelmann, H.T., and E.D. Sontag, </author> <title> Some results on computing with `neural nets', </title> <booktitle> Proc. IEEE Conf. Decision and Control, </booktitle> <address> Tucson, Dec. 1992, </address> <publisher> IEEE Publications, </publisher> <year> 1992, </year> <pages> pp. 1476-1481. </pages>
Reference-contexts: As with bilinear systems, it is obvious that if one imposes extra stability assumptions (fading memory type) it will be possible to obtain global approximations, but this is probably not very useful, as stability is often a goal of control rather than an assumption. 5.2. Computation The papers <ref> [51, 52, 6, 53] </ref>, and the references given there, dealt with computational capabilities of recurrent networks, seen from the point of view of classical formal language theory.
Reference: [53] <author> Siegelmann, H.T., and E.D. Sontag, </author> <title> Analog computation, neural networks, and circuits, </title> <journal> Theor. Comp. </journal> <note> Sci., to appear. </note>
Reference-contexts: As with bilinear systems, it is obvious that if one imposes extra stability assumptions (fading memory type) it will be possible to obtain global approximations, but this is probably not very useful, as stability is often a goal of control rather than an assumption. 5.2. Computation The papers <ref> [51, 52, 6, 53] </ref>, and the references given there, dealt with computational capabilities of recurrent networks, seen from the point of view of classical formal language theory. <p> It can be proved that languages recognizable in polynomial time by rational admissible pairs are exacly those in the class P of polynomial-time recursive languages. Using real weights, a new class, analog P, arises. This class includes many languages not in P, but a theorem in <ref> [53] </ref> shows that NP is most likely not included in analog P. For the rational case, one shows how to simulate an arbitrary Turing machine.
Reference: [54] <author> Slotine,J.-J., and R.M. Sanner, </author> <title> Neural networks for adaptive control and recursive identification: a theoretical framework, in Essays on Control: Perspectives in the Theory and its Applications (H.L. </title> <editor> Trentelman and J.C. Willems, eds.), </editor> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1993, </year> <pages> pp. 381-433. </pages>
Reference-contexts: procedure, or one based on Lyapunov techniques for parameter identification possibly in conjunction with sliding mode robust control, to handle the regions where the true f differs considerably from the best possible model of the form F (x, l ) can be proved to converge in various senses; see especially <ref> [54] </ref>, as well as for instance [45].
Reference: [55] <author> Smith, W.W., and W.J. Rugh, </author> <title> On the structure of a class of nonlinear systems, </title> <journal> IEEE Trans. Automatic Control AC-19(1974): </journal> <pages> 701-706. </pages>
Reference-contexts: Results in this case are closely related to work in the 1970s by Rugh and coworkers and by Boyd and Chua in the early 1980s; see e.g. <ref> [55] </ref> and [13]. It appears to be harder to obtain elegant characterizations of the stronger (and more interesting) property IP. For obvious examples of functions not satisfying IP, take s (x) = e x , any periodic function, or any polynomial.
Reference: [56] <author> Sontag, E.D., </author> <title> Mathematical Control Theory: Deterministic Finite Dimensional Systems, </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: If needed, one may assume that the control values themselves appear in y, and this is useful to keep in mind when the controller will consist of separate subsystems, as is done later. This setup can be formalized in various ways, using abstract definitions of control systems as in <ref> [56] </ref>, but the discussion in this paper will be completely intuitive. NEURAL NETWORKS AND CONTROL 2 2.2. <p> Other Techniques for Control When systems are not feedback linearizable, nonlinear control becomes a very hard problem, even leaving aside identification issues (as an illustration, see <ref> [56] </ref>, Section 4.8, and the many references given there, for stabilization questions). There are several adaptation approaches which have been popular in neurocontrol and which correspond to various combinations of tuners and parametric models. <p> are omitted, for notational convenience.) Viewing the parameters as constant states, the second term can be obtained by solving the variational or linearized equation along the trajectory corresponding to the control u (), for the system obtained when using the current parameters l ; see for instance Theorem 1 in <ref> [56] </ref>. (One old reference is [38].) Such an approach is known in network circles as the real time recurrent learning algorithm, and it is often pointed out that it involves a fairly large amount of variables, as the full fundamental solution (an n fi n matrix of functions) must be solved <p> Now, the proof of Theorem 12 in <ref> [56] </ref> shows that there is a neighborhood V of zero, independent of n, where exponential stability will hold, for all n sufficiently large, because f (x, k n (x)) = A n x + g n (x) , with A n ! A and with g n (x) being o (x) <p> Now continuity of solutions on the right-hand side gives the result globally on K. In general, smooth (or even continuous) stabilizers fail to exist, as discussed for instance in <ref> [56] </ref>, Section 4.8 and references there. Thus 1HL-network feedback laws, with continuous s, do not provide a rich enough class of controllers. This motivates the search for discontinuous feedback. <p> Use the notation S = S (A, B, C, s), omitting s if obvious from the context. One interprets the above data (A, B, C) as defining a controlled and observed dynamical system evolving in IR n (in the standard sense of control theory; see e.g. <ref> [56] </ref>) by means of a differential equation x = ~ s (Ax + Bu) , y = Cx in continuous-time (dot indicates time derivative), or a difference equation x + = ~ s (Ax + Bu) , y = Cx in discrete-time (+ indicates a unit time shift). <p> Next one finds a function computable by a 1HL net that uniformly approximates f (x, u) (for the extended system) close enough on K 1 fi K 2 ; this will imply the desired approximation of solutions, by any standard well-posedness result, as discussed e.g. in <ref> [56] </ref>, Theorem 37. <p> For any choice of positive integers n, m, p, denote by S c n,m,p the set of all triples of matrices (A, B, C), A 2 R nfin , B 2 R nfim , C 2 R pfin which are canonical (observable and controllable, as in <ref> [56] </ref>, section 5.5). This is a generic set of triples, in the sense that the entries of the ones that do not satisfy the property are zeroes of certain nontrivial multivariable polynomials. Finally, let: S (n, m, p) = S (A, B, C, s) fi n,m,p .
Reference: [57] <author> Sontag, E.D., </author> <title> Feedforward nets for interpolation and classification, </title> <journal> J. Comp. Syst. Sci. </journal> <volume> 45(1992): </volume> <pages> 20-48. </pages>
Reference-contexts: NEURAL NETWORKS AND CONTROL 17 Consider the property (*): 9 c s.t. s is differentiable at c and s 0 (c) 6= 0. Then, for classification, the following results are given in <ref> [57] </ref>: CLSF (H) = 1=3, CLSF d (H) = 2=3, CLSF (s) 2=3 assuming that s is sigmoidal and (*) holds. <p> It is easy to construct examples of sigmoids, even extremely well-behaved ones (analytic and squashing, for instance) for which the VC dimension of the class H (F n,s,m ) is infinite; see <ref> [57] </ref>. However, for the standard sigmoid, a recent result in [36] proves that VC (F ) &lt; 1, so neural nets with activation s s are also learnable.
Reference: [58] <author> Sontag, E.D., </author> <title> Feedback stabilization using two-hidden-layer nets, </title> <journal> IEEE Trans. Neural Networks 3 (1992): </journal> <pages> 981-990. </pages>
Reference-contexts: On the other hand, it can be shown that every system that is stabilizable, by whatever k, can also be stabilized using 2HL nets with discontinuous activations (under mild technical conditions, and using sampled control). See <ref> [58] </ref> for details. To summarize, if stabilization requires discontinuities in feedback laws, it may be the case that no possible 1HL net stabilizes. <p> It is trivial to NEURAL NETWORKS AND CONTROL 25 see that in general discontinuous functions f are needed, so nets with continuous s cannot be used. However, and this is the interesting part, <ref> [58] </ref> establishes that nets with just one hidden layer, even if discontinuous s is allowed, are not enough to guarantee the solution of all such problems. <p> More surprisingly, 1HLN feedback laws, even with H activations, are not in general enough intuitively, one is again trying to solve inverse problems but two hidden layer nets using H (and having direct i/o connections) are always sufficient. More precisely, <ref> [58] </ref> shows that the weakest possible type of open-loop asymptotic controllability is sufficient to imply the existence of (sampled) controllers built using such two-hidden layer nets, which stabilize on compact subsets of the state space.
Reference: [59] <author> Sontag, E.D., and H.J. Sussmann, </author> <title> Backpropagation separates where perceptrons do, </title> <booktitle> Neural Networks, </booktitle> <volume> 4(1991): </volume> <pages> 243-249. </pages>
Reference-contexts: Among the many numerical complications that arise when following such a procedure are the possibilities of (1) non-global local minima, and (2) multiple global minimizers. The first issue was dealt with by many different authors see for instance <ref> [59] </ref> and the references there and will not be reviewed here.
Reference: [60] <author> Sprecher, D.A. </author> <title> On the structure of continuous functions of several variables, </title> <journal> Transactions of the American Mathematical Society 115(1965): </journal> <pages> 340-355. </pages>
Reference-contexts: Approximation Properties Much has been written on the topic of function approximation by nets. Hilbert's 13th problem, on realizing functions by superpositions of scalar ones, is sometimes cited in this context. A positive solution of Hilbert's problem was obtained by Kolmogorov, with enhancements by Lorentz and Sprecher (see e.g. <ref> [60] </ref>).
Reference: [61] <author> Stinchcombe, M., and White, H. </author> <title> Approximating and learning unknown mappings using multilayer feedforward networks with bounded weights, </title> <booktitle> in Proc. 1990 International Joint Conf. Neural Networks, </booktitle> <pages> pp. III: 7-16, </pages> <publisher> IEEE Press, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: Then, s is a universal activation if and only if it is not a polynomial. Previous results along these lines were obtained in [27], which established that any s which is continuous, nonconstant, and bounded is universal (see also [16] and <ref> [20, 61] </ref> for other related older results). The proof in [34] is based essentially on two steps: First, one reduces, by convolution, to the case in which s is infinitely differentiable (and nonpolynomial).
Reference: [62] <author> Sussmann, H.J., </author> <title> Uniqueness of the weights for minimal feedforward nets with a given input-output map, </title> <booktitle> Neural Networks 5(1992): </booktitle> <pages> 589-593. </pages>
Reference-contexts: However, the most interesting activation for neural network applications is s (x) = tanh (x), or equivalently after a linear transformation, the standard sigmoid 1 1+e x . In this case, Sussmann showed in <ref> [62] </ref> that the IP property, and hence the desired uniqueness statement, hold. His proof was based on explicit computations for the particular function tanh (x).
Reference: [63] <author> Vapnik, V.N., </author> <title> Estimation of Dependencies Based on Empirical Data, </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1982. </year>
Reference-contexts: Very closely related ideas appeared in statistics even earlier, in the work of Vapnik and Chervonenkis see the excellent book <ref> [63] </ref> and the interactions between statistics and computer science are the subject of much current research. The next few paragraphs introduce the basic ideas, using terminology from learning theory; for more details see for instance the textbook [3]. <p> This leads computationally to the loading question discussed earlier. In the statistics literature see <ref> [63] </ref> this naive technique is a particular case of what is called empirical risk minimization. The above discussion corresponds to being able to learn uniformly with respect to unknown input distributions. <p> k for which there is some set S of cardinality k that can be shattered by F . (Thus, VC (F ) is at least as large as the capacity c (F ) defined earlier.) The main result, due to [12], but closely related to previous results in statistics (see <ref> [63] </ref>) is: The class F is learnable if and only if VC (F ) &lt; 1.
Reference: [64] <author> White, D.A., and D.A. Sofge (eds.), </author> <title> Handbook of Intelligent Control: Neural, Fuzzy and Adaptive Approaches, </title> <publisher> Van Nostrand Reinhold, </publisher> <address> NY, </address> <year> 1992. </year>
Reference-contexts: Most recent major control conferences have had introductory courses devoted to the topic; in addition, many good overviews are available in the general literature (see for instance the papers [5], [28], [8], [21], and other papers in the books [40] and <ref> [64] </ref>). Rather, there are two objectives. The first part of this paper attempts to explain the general context in which recent neuro-control work has taken place, namely the refocusing of attention on older numerical and learning techniques for control.
Reference: [65] <author> Weiss, </author> <title> S.M., and C.A. Kulikowski, Computer Systems That Learn, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year> <title> NEURAL NETWORKS AND CONTROL 35 </title>
Reference-contexts: Statistical studies. In network learning systems, all the usual issues associated to estimation arise: the tradeoff between variance and bias (or, in AI terms, between generality and generalization). Cross-validation and other techniques are often applied; see for instance the book <ref> [65] </ref> for much on this topic. Studies of the effect of incremental (on-line) versus all at once (batch or off-line) learning. In actual applications that involve gradient descent, often the complete gradient is not computed at each stage, but an approximation is used, which involves only new data.
References-found: 65

