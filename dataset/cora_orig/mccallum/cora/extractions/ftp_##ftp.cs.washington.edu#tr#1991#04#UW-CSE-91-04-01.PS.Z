URL: ftp://ftp.cs.washington.edu/tr/1991/04/UW-CSE-91-04-01.PS.Z
Refering-URL: http://www.cs.washington.edu/research/arch/synch-parallel.html
Root-URL: 
Title: On Synchronization Patterns in Parallel Programs  
Author: Jean-Loup Baer and Richard N. Zucker 
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract: Technical Report No. 91-04-01 April 1991 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Sarita V. Adve and Mark D. Hill. </author> <title> Weak Ordering ANew Definition and Some Implications. </title> <type> Technical Report #902, </type> <institution> Department of Computer Science, University of Wisconsin, Madison, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: For our purposes, strongly ordered and sequentially consistent accesses can be considered as synonymous (distinctions between the two are examined in <ref> [1] </ref>). Performed is defined formally in [7]. Basically it means that a STORE is performed when the value stored by the processor executing the instruction can be seen by all other processors, and that the value to be returned by a LOAD has been set and cannot be changed.
Reference: [2] <author> T. E. Anderson, B. N. Bershad, E. D. Lazowska, and H. M. Levy. </author> <title> Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism. </title> <type> Technical Report 90-04-02, </type> <institution> Department of Computer Science, University of Washington, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: The Presto programming environment is based on user-level threads instead of system level threads and thereby the losses due to lock contention might be recouped since there are no traps to the kernel <ref> [2] </ref>. A version of the Grav and Pdsa programs written directly in C, and trying to attain the same level of parallelism, would have this overhead to contend with. However, the lock contention, while present at the system level, would not show up in the application level traces.
Reference: [3] <author> Thomas E. Anderson. </author> <title> The Performance of Spin-Lock Alternatives for Shared-Memory Multiprocessors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(1) </volume> <pages> 6-16, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: A plausible explanation is that the processor with the lock must already have the working set for the critical section in its cache (for a detailed description of what happens when the lock is released in T&T&S see <ref> [3] </ref>). However, the increased bus contention does have an overall impact. The bus utilization for Grav doubled when using T&T&S and for Pdsa increased 40%, and this slows down even those processors that do not want the lock.
Reference: [4] <author> James Archibald and Jean-Loup Baer. </author> <title> Cache Coherence Protocols: Evaluation Using a Multiprocessor Simulation. </title> <journal> ACM Transactions on Computers Systems, </journal> <volume> 4(4) </volume> <pages> 273-298, </pages> <month> November </month> <year> 1986. </year>
Reference-contexts: Figure 1) from which the traces were collected. Each processor has a two way set-associative 64 Kbyte cache. The line size is 16 bytes. The caches are write-back with LRU replacement. The Illinois protocol is used for hardware enforced cache coherence <ref> [4] </ref>. The cache-bus interface includes a four element buffer. All memory requests, write-backs, cache-cache transfers, and coherence actions initiated by the processor must pass through this buffer. The buffer depth was initially set to four which is larger than the usual write buffer in a system with a write-back cache.
Reference: [5] <author> Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy. </author> <title> PRESTO: A System for Object-Oriented Parallel Programming. </title> <journal> Software Practice and Experience, </journal> <volume> 18(8), </volume> <month> August </month> <year> 1988. </year>
Reference-contexts: The C++ programs (the first three in table 1), were written using the Presto <ref> [5] </ref> programming environment. Presto consists mainly of a number of C++ classes which provide for synchronization and user level threads. The scheduling and context switching of the threads are executed at the user level. Thus, the instructions that perform the thread management are in the trace.
Reference: [6] <author> Edgar W. Dijkstra. </author> <title> Cooperating Sequential Processes. </title> <editor> In F. Genuys, editor, </editor> <booktitle> Programming Languages. </booktitle> <publisher> Academic Press, </publisher> <year> 1968. </year>
Reference-contexts: If this is not the case, then certain algorithms, such as Dekker's Algorithm for mutual exclusion <ref> [6] </ref> may not work correctly (an example of what could happen can be found in [7]).
Reference: [7] <author> Michel Dubois, Christoph Scheurich, and Faye Briggs. </author> <title> Memory Access Buffering in Multiprocessors. </title> <booktitle> In 13th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 434-442, </pages> <year> 1986. </year>
Reference-contexts: The buffer depth was initially set to four which is larger than the usual write buffer in a system with a write-back cache. This was in anticipation of the larger buffer requirements of a weakly consistent architecture <ref> [7] </ref>. The wisdom of such a choice is discussed in section 4. If a dirty line is in the buffer to be written-back, it is visible to the cache coherence mechanism. The bus modeled is a 64 bits wide (data and address) split transaction bus. Arbitration is round-robin. <p> These ideas have focused on ways to change the programmer's model of memory by relaxing the hardware constraints of having to enforce sequential consistency [16]. These alternative memory models include weak ordering <ref> [7] </ref>. It is important to know whether the additional hardware features required for an efficient implementation of weak ordering, e.g., buffers, are warranted in terms of improved execution time. <p> If this is not the case, then certain algorithms, such as Dekker's Algorithm for mutual exclusion [6] may not work correctly (an example of what could happen can be found in <ref> [7] </ref>). Weak ordering is defined as [7]: In a multiprocessor system, storage accesses are weakly ordered if: 1. accesses to global synchronizing variables are strongly ordered and if 2. no access to a synchronizing variable is issued in a processor before all previous global data accesses have been performed and if <p> If this is not the case, then certain algorithms, such as Dekker's Algorithm for mutual exclusion [6] may not work correctly (an example of what could happen can be found in <ref> [7] </ref>). Weak ordering is defined as [7]: In a multiprocessor system, storage accesses are weakly ordered if: 1. accesses to global synchronizing variables are strongly ordered and if 2. no access to a synchronizing variable is issued in a processor before all previous global data accesses have been performed and if 3. no access to global data <p> For our purposes, strongly ordered and sequentially consistent accesses can be considered as synonymous (distinctions between the two are examined in [1]). Performed is defined formally in <ref> [7] </ref>. Basically it means that a STORE is performed when the value stored by the processor executing the instruction can be seen by all other processors, and that the value to be returned by a LOAD has been set and cannot be changed.
Reference: [8] <author> S. J. Eggers and R. H. Katz. </author> <title> Evaluating The Performance of Four Snooping Cache Coherence Protocols. </title> <booktitle> In 16th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 2-15, </pages> <year> 1989. </year>
Reference-contexts: The program trace ran for three timesteps of evolution for a system of 2000 stars. Pdsa [18] does topological optimization using simulated annealing. FullConn is a run of a Synapse [19] distributed simulation of a fully-connected processor network. The three C programs are Pverify, Qsort, and Topopt. Pverify <ref> [8] </ref> is a combinational logic verification program which compares two different circuit implementations to determine whether they are functionally (Boolean) equivalent. The circuits used for the trace were combinational benchmarks for evaluating test generation algorithms. Topopt [8] does topological compaction of MOS circuits using dynamic windowing and partitioning techniques. <p> The three C programs are Pverify, Qsort, and Topopt. Pverify <ref> [8] </ref> is a combinational logic verification program which compares two different circuit implementations to determine whether they are functionally (Boolean) equivalent. The circuits used for the trace were combinational benchmarks for evaluating test generation algorithms. Topopt [8] does topological compaction of MOS circuits using dynamic windowing and partitioning techniques. It is based upon a simulated annealing algorithm for its topological optimizations. Its input was a technology independent multi-level logic circuit. Qsort [13] is a quicksort program run on 1,000,000 random integers.
Reference: [9] <author> S. J. Eggers, D. R. Keppel, E. J. Koldinger, and H. M. Levy. </author> <title> Techniques for Efficient Inline Tracing on a Shared-Memory Multiprocessor. </title> <booktitle> In ACM SIGMETRICS and Performance '90, International Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 37-47, </pages> <year> 1990. </year>
Reference-contexts: We used traces of programs running on a Sequent Symmetry Model B with 20 Intel 80386 processors. These traces were collected using the MPTrace system <ref> [9] </ref>. MPTrace is an in-line tracing technique. It only saves the entry address of each basic block and memory references within that block that cannot be statically reconstructed. In a post-processing phase the trace is expanded to give the full memory reference trace.
Reference: [10] <author> K. Gharachorloo et al. </author> <title> Memory Consistency and Event Ordering In Scalable Shared-memory Multiprocessors. </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: If the miss penalty were greater, e.g., because the memory latency is much higher as in a multistage interconnection based system, or the number of writes to memory increased (as in the case of a write-through cache), then the benefit would be greater and might justify the cost <ref> [10] </ref>. Delaying of various cache coherence signals does not appear to be as promising. These signals are generated when there is a write hit on a line in a shared state.
Reference: [11] <author> E. Felten. </author> <type> personal communication. </type>
Reference-contexts: In the C traces (the last three in table 1) these system functions are not included. The three Presto programs are Grav, Pdsa, and FullConn. Grav implements the Barnes and Hut clustering algorithm for simulating the time evolution of large numbers of stars interacting under gravity <ref> [11] </ref>. The program trace ran for three timesteps of evolution for a system of 2000 stars. Pdsa [18] does topological optimization using simulated annealing. FullConn is a run of a Synapse [19] distributed simulation of a fully-connected processor network. The three C programs are Pverify, Qsort, and Topopt.
Reference: [12] <author> Gary Graunke and Shreekant Thakkar. </author> <title> Synchronization Algorithms for Shared Memory Multiprocessors. </title> <journal> Computer, </journal> <volume> 23(6) </volume> <pages> 60-70, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: We study how these, and related, factors impact execution time and processor utilization in a shared-bus multiprocessor system. Two different locking schemes, a very efficient one (queuing locks <ref> [12] </ref>) and the more usual one (test-and-test-and-set [17]), will be tested. We will also perform experiments using a weakly consistent memory access model. The paper is organized as follows. In section 2 we cover the methodology we used when collecting our information and discuss the benchmarks selected and their characteristics. <p> To remove as many artifacts as possible for the study on locking patterns, we need a locking algorithm that causes minimal interference with processors doing useful work. For this reason, we have chosen to simulate a scheme similar to queuing locks <ref> [12] </ref>. In queuing locks a processor wanting to acquire a lock performs a single atomic exchange operation to get the address of a memory location, say M, and a special value, say A. It also stores an address N and a value B for the next processor.
Reference: [13] <author> Simon Kahan and Larry Ruzzo. </author> <title> Parallel Quicksand: Sorting on the Sequent. </title> <type> Technical Report 91-01-01, </type> <institution> Department of Computer Science, University of Washington, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: Topopt [8] does topological compaction of MOS circuits using dynamic windowing and partitioning techniques. It is based upon a simulated annealing algorithm for its topological optimizations. Its input was a technology independent multi-level logic circuit. Qsort <ref> [13] </ref> is a quicksort program run on 1,000,000 random integers. This is not the best benchmark since sorting is more likely to be done as a subroutine of a program and therefore is not typical of an entire program.
Reference: [14] <author> D. Kroft. </author> <title> Lockup-free Instruction Fetch/Prefetch Cache Organization. </title> <booktitle> In 8th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 81-87, </pages> <month> June </month> <year> 1981. </year>
Reference-contexts: One cannot forget that there would be extra costs involved in implementing weak consistency. Bypassing must be possible in the memory access buffer. Since the cache must be able to handle requests while a request is outstanding, the caches must be lockup-free <ref> [14] </ref> thus increasing the complexity of the cache and possibly increasing the cache cycle time.
Reference: [15] <author> D. Kuck, R. Kuhn, D. Padua, B. Leasure, and M. Wolfe. </author> <title> Dependence Graphs and Compiler Optimizations. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <month> July </month> <year> 1981. </year>
Reference-contexts: In a weakly ordered system, the only restrictions on the access of normal, i.e., non-synchronizing, memory references is that imposed by the program's own data dependencies <ref> [15] </ref>. Otherwise memory references may be executed in any order. Therefore an order that maximizes system performance may be used.
Reference: [16] <author> Leslie Lamport. </author> <title> How to Make a Multiprocessor Computer that Correctly Executes Multipro-cess Programs. </title> <journal> IEEE Transaction on Computers C-28, </journal> <volume> C-28(9):690-691, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: Several ideas have been put forward to reduce the frequency with which the full penalty of a cache miss must be paid. These ideas have focused on ways to change the programmer's model of memory by relaxing the hardware constraints of having to enforce sequential consistency <ref> [16] </ref>. These alternative memory models include weak ordering [7]. It is important to know whether the additional hardware features required for an efficient implementation of weak ordering, e.g., buffers, are warranted in terms of improved execution time. <p> In subsection 4.1 we describe what weak ordering is. In subsection 4.2 we present our simulation results. 4.1 Weak Ordering Most multiprocessor systems are sequentially consistent. Lamport <ref> [16] </ref> says: 11 [A system is sequentially consistent if] the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.
Reference: [17] <author> Z. Segall and L. Rudolph. </author> <title> Dynamic Decentralized Cache Schemes for an MIMD Parallel Processor. </title> <booktitle> In 11th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 340-347, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: We study how these, and related, factors impact execution time and processor utilization in a shared-bus multiprocessor system. Two different locking schemes, a very efficient one (queuing locks [12]) and the more usual one (test-and-test-and-set <ref> [17] </ref>), will be tested. We will also perform experiments using a weakly consistent memory access model. The paper is organized as follows. In section 2 we cover the methodology we used when collecting our information and discuss the benchmarks selected and their characteristics.
Reference: [18] <author> M. Upton, K. Samii, and S. Sugiyama. </author> <title> Integrated Placement for Mixed Standard Cell and Macro-Cell Designs. </title> <booktitle> In Proceedings of the 27th Design Automation Conference, </booktitle> <year> 1990. </year>
Reference-contexts: The three Presto programs are Grav, Pdsa, and FullConn. Grav implements the Barnes and Hut clustering algorithm for simulating the time evolution of large numbers of stars interacting under gravity [11]. The program trace ran for three timesteps of evolution for a system of 2000 stars. Pdsa <ref> [18] </ref> does topological optimization using simulated annealing. FullConn is a run of a Synapse [19] distributed simulation of a fully-connected processor network. The three C programs are Pverify, Qsort, and Topopt.
Reference: [19] <author> David B. Wagner. </author> <title> The Design of an Object-Oriented Parallel Simulation Environment. </title> <booktitle> In SCS Multiconference on Object-Oriented Simulation, </booktitle> <year> 1991. </year> <note> To appear. 17 </note>
Reference-contexts: The program trace ran for three timesteps of evolution for a system of 2000 stars. Pdsa [18] does topological optimization using simulated annealing. FullConn is a run of a Synapse <ref> [19] </ref> distributed simulation of a fully-connected processor network. The three C programs are Pverify, Qsort, and Topopt. Pverify [8] is a combinational logic verification program which compares two different circuit implementations to determine whether they are functionally (Boolean) equivalent.
References-found: 19

