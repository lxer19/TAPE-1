URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR93341-S.ps
Refering-URL: http://www.cs.rice.edu:80/~roth/papers.html
Root-URL: 
Title: Optimizing Fortran 90D Programs for SIMD Execution  
Author: Gerald Roth 
Address: P.O. Box 1892 Houston, TX 77251-1892  
Affiliation: Rice University  
Note: Center for Research on Parallel Computation  
Date: April, 1993  
Pubnum: CRPC-TR93341-S  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> E. Albert, K. Knobe, J. Lukas, and G. Steele, Jr. </author> <title> Compiling Fortran 8x array features for the Connection Machine computer system. </title> <booktitle> In Proceedings of the ACM SIGPLAN Symposium on Parallel Programming: Experience with Applications, Languages, and Systems (PPEALS), </booktitle> <address> New Haven, CT, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: The CM Fortran and MasPar Fortran compilers are described in more detail below. In addition to the general SIMD compiler development effort, Compass did research in the area of data optimization <ref> [1, 40, 41, 42, 43, 52] </ref>. The purpose of data optimization is to align data to improve locality and thus minimize interprocessor communication. Their method assumes an unlimited number of virtual processors.
Reference: [2] <author> J. R. Allen. </author> <title> Dependence Analysis for Subscripted Variables and Its Application to Pro gram Transformations. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> April </month> <year> 1983. </year>
Reference-contexts: Program transformations, such as loop reversal, will also be used to allow more arrays to be treated as offset arrays. This work has similarities to sectioning/strip mining of array syntax <ref> [2] </ref>, vector register allocation [4], and scalarization of Fortran 90 code [67]. We hope to exploit this previous work in the analysis phase. The program transformations of the previous efforts will also be useful, but they will need to be augmented with distributed-memory specific transformations.
Reference: [3] <author> J. R. Allen and K. Kennedy. </author> <title> Automatic translation of Fortran programs to vector form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: The scope of the work described in this document will be the generation of efficient code for distributed-memory SIMD machines from Fortran 90D. Compiling Fortran 77D to SIMD architectures will not be addressed in this work. However, using the techniques of automatic vectorization <ref> [3, 67] </ref> one can transform Fortran 77D into Fortran 90D, at which point the work described here can be employed to generate efficient SIMD code. Distributed-memory MIMD architectures and distributed-memory SIMD architectures share many characteristics.
Reference: [4] <author> J. R. Allen and K. Kennedy. </author> <title> Vector register allocation. </title> <journal> IEEE Transactions on Com puters, </journal> <volume> 41(10) </volume> <pages> 1290-1317, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Program transformations, such as loop reversal, will also be used to allow more arrays to be treated as offset arrays. This work has similarities to sectioning/strip mining of array syntax [2], vector register allocation <ref> [4] </ref>, and scalarization of Fortran 90 code [67]. We hope to exploit this previous work in the analysis phase. The program transformations of the previous efforts will also be useful, but they will need to be augmented with distributed-memory specific transformations.
Reference: [5] <author> ANSI X3J3/S8.115. </author> <title> Fortran 90, </title> <month> June </month> <year> 1990. </year>
Reference-contexts: The Fortran D source languages include both Fortran 77 [68] and Fortran 90 <ref> [5] </ref>, and the target architectures may be either MIMD or SIMD. Several aspects of the Fortran D project are already being addressed. The following three projects are all currently underway: 1.
Reference: [6] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kremer. </author> <title> A static performance estimator to guide data partitioning decisions. </title> <booktitle> In Proceedings of the Third ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Williamsburg, VA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Several aspects of the Fortran D project are already being addressed. The following three projects are all currently underway: 1. The automatic annotation of Fortran 77 or Fortran 90 programs with data decomposi tion statements to produce the corresponding Fortran 77D or Fortran 90D programs <ref> [6, 44] </ref>. 2. The generation of efficient MIMD code from Fortran 77D [30, 36, 64]. 3. The generation of efficient MIMD code from Fortran 90D [20]. The scope of the work described in this document will be the generation of efficient code for distributed-memory SIMD machines from Fortran 90D.
Reference: [7] <author> S. Benkner, B. Chapman, and H. Zima. </author> <title> Vienna Fortran 90. </title> <booktitle> In Proceedings of the 1992 Scalable High Performance Computing Conference, </booktitle> <address> Williamsburg, VA, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: They made major contributions to the issues of automatic data alignment and identification of collective communication primitives. 5 2.2.3 Vienna Fortran The Vienna Fortran project at the University of Vienna <ref> [7, 13, 70] </ref> is very similar, in both goals and methodologies, to the Fortran D project.
Reference: [8] <author> T. Blank. </author> <title> The MasPar MP-1 architecture. </title> <booktitle> In Proceedings of the 1990 Spring COMP CON, </booktitle> <address> San Francisco, CA, </address> <month> February </month> <year> 1990. </year>
Reference-contexts: For a broad discussion of general SIMD architectures see an appropriate computer architecture book [34, 38]. For a more complete description of the SIMD machines produced by Thinking Machines and MasPar see [35, 61] and <ref> [8, 54, 56] </ref> respectively. 2 Related Work 2.1 SIMD Distributed-Memory Compilers 2.1.1 Compass Compilers Compass (1961-1991) was an independent software house which was involved in the design and implementation of several SIMD compilers.
Reference: [9] <author> M. Bromley, S. Heller, T. McNerney, and G. Steele, Jr. </author> <title> Fortran at ten gigaflops: The Connection Machine convolution compiler. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Program Language Design and Implementation, </booktitle> <address> Toronto, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Thinking Machines has documented many of the shortcomings [59], and has suggested methods that programmers may use to work around them. Thinking Machines has also done some extensive work on compiling stencils <ref> [9] </ref>. A stencil is a computational pattern that calculates a new value for a matrix element by combining elements from neighboring matrix locations. The proper handling of stencils is very important to SIMD compilers, and can result in substantial performance gains. <p> The importance of stencils cannot be overstated; they occur as the computational kernels in many scientific and engineering applications. Bromley et al. at Thinking Machines Corporation have already done some impressive work on compiling stencils <ref> [9] </ref>. They have developed a compiler called the convolution compiler, however most people simply refer to it as the stencil compiler. There are, however, still several opportunities for improvement. First of all, the task of identifying stencils rests on the shoulders of the programmer.
Reference: [10] <author> D. Callahan. </author> <title> A Global Approach to Detection of Parallelism. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> March </month> <year> 1987. </year>
Reference-contexts: We are currently intending to use an annotated program dependence graph (PDG) [23] rather than using a preference graph as described by Knobe, Lukas, and Steele [41]. We believe annotating the PDG with regular section descriptors <ref> [10] </ref> will express the required array relationships in such a way to ease the analysis and produce alignments that require less communication. <p> To support the analysis and optimization of Fortran 90 programs we will develop and 13 implement within our compiler algorithms for analyzing the usage of whole arrays and array sections. Regular Section Descriptors (RSD's) <ref> [10] </ref> will form the foundation on which these algorithms will be built. Data optimization, context optimization, and collective communication recognition will rely heavily upon the analysis performed by these routines.
Reference: [11] <author> D. Callahan, K. Cooper, R. Hood, K. Kennedy, and L. Torczon. </author> <title> ParaScope: A parallel programming environment. </title> <journal> The International Journal of Supercomputer Applications, </journal> <volume> 2(4) </volume> <pages> 84-99, </pages> <month> Winter </month> <year> 1988. </year>
Reference-contexts: arrays in Fortran 90 is useful for distributed-memory MIMD architectures as well. 4 Research Plan This section describes our plans for implementing the Fortran 90D SIMD compiler, and a validation methodology to support our thesis. 4.1 Compiler Implementation Our distributed-memory SIMD compiler will be implemented within the ParaScope programming environment <ref> [11] </ref>. It will be a source-to-source translator similar to other com-pilers/tools in ParaScope. Given a Fortran 90D program, the SIMD compiler will translate it into an equivalent program written in a subset of Fortran 90 suitable for a vendor's native Fortran 90 compiler.
Reference: [12] <author> D. Callahan and K. Kennedy. </author> <title> Compiling programs for distributed-memory multipro cessors. </title> <journal> Journal of Supercomputing, </journal> <volume> 2 </volume> <pages> 151-169, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Fortran D directives enable a programmer to specify how the data is to be laid out across the memory of the machine. Compilers then often use the owner computes rule <ref> [12, 57, 69] </ref> to determine which processors will perform which computations. The owner computes rule states that computations are performed on the processors which will store the result of the computation.
Reference: [13] <author> B. Chapman, P. Mehrotra, and H. Zima. </author> <title> Vienna Fortran a Fortran language ex tension for distributed memory multiprocessors. </title> <editor> In J. Saltz and P. Mehrotra, editors, </editor> <title> Languages, Compilers, and Run-Time Environments for Distributed Memory Machines. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1992. </year>
Reference-contexts: They made major contributions to the issues of automatic data alignment and identification of collective communication primitives. 5 2.2.3 Vienna Fortran The Vienna Fortran project at the University of Vienna <ref> [7, 13, 70] </ref> is very similar, in both goals and methodologies, to the Fortran D project.
Reference: [14] <author> S. Chatterjee, J. Gilbert, R. Schreiber, and S. Teng. </author> <title> Optimal evaluation of array expres sions on massively parallel machines. </title> <type> Technical Report CSL-92-11, </type> <institution> Xerox Corporation, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: This two stage approach makes each stage conceptually clean, but prevents them from interacting. There are others, outside of Compass, who have done research in the area of data optimization. Chatterjee, Gilbert, Schreiber, and Teng <ref> [14, 15, 28, 29] </ref> describe algorithms to perform automatic array alignment at the statement level and the basic block level.
Reference: [15] <author> S. Chatterjee, J. Gilbert, R. Schreiber, and S. Teng. </author> <title> Automatic array alignment in data-parallel programs. </title> <booktitle> In Proceedings of the Twentieth Annual ACM Symposium on 15 the Principles of Programming Languages, </booktitle> <address> Charleston, SC, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: This two stage approach makes each stage conceptually clean, but prevents them from interacting. There are others, outside of Compass, who have done research in the area of data optimization. Chatterjee, Gilbert, Schreiber, and Teng <ref> [14, 15, 28, 29] </ref> describe algorithms to perform automatic array alignment at the statement level and the basic block level.
Reference: [16] <author> M. Chen, Y. Choo, and J. Li. </author> <title> Theory and pragmatics of compiling efficient parallel code. </title> <type> Technical Report YALEU/DCS/TR-760, </type> <institution> Dept. of Computer Science, Yale University, </institution> <address> New Haven, CT, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: Many of the analysis techniques (e.g., reaching decompositions) will also be very important for a SIMD compiler. However, many of the optimization techniques take advantage of the asynchronous nature of the processors and cannot be used on SIMD machines. 2.2.2 Crystal The Crystal project at Yale University <ref> [16, 48, 50, 51] </ref> researched the issues of compiling a high-level functional language for SPMD execution.
Reference: [17] <author> M. Chen and J. Cowie. </author> <title> Prototyping Fortran-90 compilers for massively parallel ma chines. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Program Language Design and Implementation, </booktitle> <address> San Francisco, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: The cost of this flexibility is that the compiler cannot use the knowledge of the number of processors in performing optimizations. 1 References to the CM-2 are meant to include the CM-200 [63] series. 4 2.1.4 Fortran-90-Y Yale University has recently embarked on a compiler project for Fortran 90 <ref> [17] </ref>. The Fortran-90-Y compiler uses an abstract semantic algebra, Yale Intermediate Representation (YR), as its intermediate language. YR defines a series of semantic domains and sets of operators within each domain, and combines them with shapes that represent iteration spaces. <p> We call this optimization context partitioning. As an example, the code in Figure 5 will be changed into that in Figure 6, for which a single PECODE block will be generated. Cowie and Chen <ref> [17] </ref>, in their work on the Fortran-90-Y compiler, state the goal of blocking computations over the same shape to form computational phases separated by communication phases. However, they currently only support a single transformation to address this goal: parallel loop fusion.
Reference: [18] <author> M. Chen and Y. Hu. </author> <title> Optimizations for compiling iterative spatial loops to massively parallel machines. </title> <booktitle> In Proceedings of the Fifth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> New Haven, CT, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: In addition to considering the data optimization problem [19], researchers on the Fortran-90-Y project have also looked into loop transformations that help optimize the node level programs when a BLOCK distribution is used <ref> [18] </ref>. 2.1.5 MIMD Emulators There has been growing interest in determining if SIMD architectures can successfully be used to handle problems that do not fit the data-parallel model [22, 37, 60, 66]. One method is to emulate MIMD execution by writing a SIMD program to interpret a MIMD instruction set.
Reference: [19] <author> M. Chen and J. Wu. </author> <title> Optimizing FORTRAN-90 programs for data motion on massively parallel systems. </title> <type> Technical Report YALE/DCS/TR-882, </type> <institution> Dept. of Computer Science, Yale University, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: Like the CM compiler and the MasPar compiler, the Yale compiler generates purely element-wise computations, i.e., all operands must be perfectly aligned; a restriction we will eliminate. In addition to considering the data optimization problem <ref> [19] </ref>, researchers on the Fortran-90-Y project have also looked into loop transformations that help optimize the node level programs when a BLOCK distribution is used [18]. 2.1.5 MIMD Emulators There has been growing interest in determining if SIMD architectures can successfully be used to handle problems that do not fit the
Reference: [20] <author> A. Choudhary, G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, S. Ranka, and C. Tseng. </author> <title> Compiling Fortran 77D and 90D for MIMD distributed-memory machines. </title> <booktitle> In Frontiers '92: The 4th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> McLean, VA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: The generation of efficient MIMD code from Fortran 77D [30, 36, 64]. 3. The generation of efficient MIMD code from Fortran 90D <ref> [20] </ref>. The scope of the work described in this document will be the generation of efficient code for distributed-memory SIMD machines from Fortran 90D. Compiling Fortran 77D to SIMD architectures will not be addressed in this work.
Reference: [21] <author> P. Christy. </author> <title> Virtual processors considered harmful. </title> <booktitle> In Proceedings of the 6th Distributed Memory Computing Conference, </booktitle> <pages> pages 99-103, </pages> <address> Portland, OR, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The first is to drive the PE array by broadcasting instructions and related data to all PEs. The second is to perform all scalar computations and control flow operations. Our target architecture will not support virtual processors as is done on the CM-2 in Paris mode <ref> [21] </ref>. Instead, virtualization will be accomplished by the compiler by using strip mining. Like the MasPar Fortran compiler, we will know the size of the PE array at compile time, and we will use that knowledge to determine the strip amount.
Reference: [22] <author> H. Dietz and W. Cohen. </author> <title> A control-parallel programming model implemented on SIMD hardware. </title> <booktitle> In Proceedings of the Fifth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> New Haven, CT, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: the Fortran-90-Y project have also looked into loop transformations that help optimize the node level programs when a BLOCK distribution is used [18]. 2.1.5 MIMD Emulators There has been growing interest in determining if SIMD architectures can successfully be used to handle problems that do not fit the data-parallel model <ref> [22, 37, 60, 66] </ref>. One method is to emulate MIMD execution by writing a SIMD program to interpret a MIMD instruction set. Each PE contains a program to be interpreted and its data.
Reference: [23] <author> J. Ferrante, K. Ottenstein, and J. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: The structure of our data optimizer has not yet been finalized. We are thus not able to make a preliminary comparison against existing data optimization techniques. We are currently intending to use an annotated program dependence graph (PDG) <ref> [23] </ref> rather than using a preference graph as described by Knobe, Lukas, and Steele [41]. We believe annotating the PDG with regular section descriptors [10] will express the required array relationships in such a way to ease the analysis and produce alignments that require less communication.
Reference: [24] <author> M. Flynn. </author> <title> Very high-speed comnputing systems. </title> <booktitle> Proceedings of the IEEE, </booktitle> <year> 54(12):1901 1909, </year> <month> December </month> <year> 1966. </year>
Reference-contexts: Section 3 describes our proposed research. We conclude in Section 4 with our research plan. 1.1 A Distributed-Memory SIMD Architecture SIMD is an acronym for Single Instruction stream, Multiple Data streams, and is one of the four categories proposed in Flynn's taxonomy of computer architectures <ref> [24] </ref>. A SIMD computer contains many data processors operating synchronously, each executing the same instruction from a single program counter. Each data processor is a fully functional ALU (Arithmetic Logical Unit). The SIMD architectures in which we are interested associate some local memory with each data processor.
Reference: [25] <author> G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, C. Tseng, and M. Wu. </author> <title> For tran D language specification. </title> <type> Technical Report TR90-141, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: To address the difficulties of programming distributed-memory parallel computers, Rice University has embarked on the Fortran D project to develop compilers that will address fl This work supported in part by the IBM Corporation through the Graduate Resident Study Program. 1 many of the impediments. Fortran D <ref> [25] </ref> combines the addition of annotations to the Fortran programming language with advanced compiler technology.
Reference: [26] <author> G. Fox, M. Johnson, G. Lyzenga, S. Otto, J. Salmon, and D. Walker. </author> <title> Solving Problems on Concurrent Processors, volume 1. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year>
Reference-contexts: Not only will this compiler support the validation of our thesis, but it will also establish the basis for future work on analyzing and optimizing Fortran 90 programs. This future work may include investigating compiler techniques for automatically generating SIMD code for loosely synchronous or wave-front style problems <ref> [26, 45] </ref> that is more efficient than the MIMD emulation methods described in Section 2.1.5. 4.2 Validation To test the effectiveness of our optimizations, we will measure the improvements they produce above the system compiler on the target SIMD architectures, the CM-2 and the MP-1.
Reference: [27] <author> M. Gerndt. </author> <title> Updating distributed variables in local computations. </title> <journal> Concurrency: Prac tice & Experience, </journal> <volume> 2(3) </volume> <pages> 171-193, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: If the analysis determines that an entire copy is not required, then we can treat the target array specially. We'll call such an array an offset array. Such arrays allow us to avoid the memory-to-memory copying; only the cross-processor data will be moved. We will exploit overlap areas <ref> [27] </ref> to store the communicated data locally within a PE. The use of overlaps will greatly simplify the task of generating code to drive the PE array when offset arrays are referenced.
Reference: [28] <author> J. Gilbert and R. Schreiber. </author> <title> Optimal data placement for distributed memory architec tures. </title> <booktitle> In Proceedings of the Fifth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 462-471, </pages> <address> Houston, TX, </address> <month> March </month> <year> 1991. </year>
Reference-contexts: This two stage approach makes each stage conceptually clean, but prevents them from interacting. There are others, outside of Compass, who have done research in the area of data optimization. Chatterjee, Gilbert, Schreiber, and Teng <ref> [14, 15, 28, 29] </ref> describe algorithms to perform automatic array alignment at the statement level and the basic block level.
Reference: [29] <author> J. Gilbert and R. Schreiber. </author> <title> Optimal expression evaluation for data parallel architec tures. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13(1) </volume> <pages> 58-64, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: This two stage approach makes each stage conceptually clean, but prevents them from interacting. There are others, outside of Compass, who have done research in the area of data optimization. Chatterjee, Gilbert, Schreiber, and Teng <ref> [14, 15, 28, 29] </ref> describe algorithms to perform automatic array alignment at the statement level and the basic block level.
Reference: [30] <author> M. W. Hall, S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Interprocedural compilation of Fortran D for MIMD distributed-memory machines. </title> <booktitle> In Proceedings of Supercomputing '92, </booktitle> <address> Minneapolis, MN, </address> <month> November </month> <year> 1992. </year> <month> 16 </month>
Reference-contexts: The following three projects are all currently underway: 1. The automatic annotation of Fortran 77 or Fortran 90 programs with data decomposi tion statements to produce the corresponding Fortran 77D or Fortran 90D programs [6, 44]. 2. The generation of efficient MIMD code from Fortran 77D <ref> [30, 36, 64] </ref>. 3. The generation of efficient MIMD code from Fortran 90D [20]. The scope of the work described in this document will be the generation of efficient code for distributed-memory SIMD machines from Fortran 90D. Compiling Fortran 77D to SIMD architectures will not be addressed in this work. <p> by using a Single Program Multiple Data (SPMD) model, in which the compiler generates a single node program which is executed on all the processors. 2.2.1 Fortran D The effort at Rice University to compile Fortran 77D to MIMD machines has resulted in many advanced compiler analysis techniques and optimizations <ref> [30, 36, 64] </ref>. Many of the analysis techniques (e.g., reaching decompositions) will also be very important for a SIMD compiler.
Reference: [31] <author> R. v. Hanxleden. </author> <title> Compiler support for the machine independent parallelization of irreg ular problems. </title> <type> Thesis proposal, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: The Fortran D project is designed to handle both regular and irregular computational patterns. This proposal addresses only Fortran D programs with regular computations. Irregular computational patterns are being addressed by others <ref> [31, 32, 33] </ref>. The remainder of this proposal is organized as follows. We first give a brief overview of the target SIMD architecture which this work assumes. Then in Section 2 we discuss related efforts. Section 3 describes our proposed research.
Reference: [32] <author> R. v. Hanxleden and K. Kennedy. </author> <title> Relaxing SIMD control flow constraints using loop transformations. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Program Language Design and Implementation, </booktitle> <address> San Francisco, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: The Fortran D project is designed to handle both regular and irregular computational patterns. This proposal addresses only Fortran D programs with regular computations. Irregular computational patterns are being addressed by others <ref> [31, 32, 33] </ref>. The remainder of this proposal is organized as follows. We first give a brief overview of the target SIMD architecture which this work assumes. Then in Section 2 we discuss related efforts. Section 3 describes our proposed research.
Reference: [33] <author> R. v. Hanxleden, K. Kennedy, C. Koelbel, R. Das, and J. Saltz. </author> <title> Compiler analysis for irregular problems in Fortran D. </title> <booktitle> In Proceedings of the Fifth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> New Haven, CT, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: The Fortran D project is designed to handle both regular and irregular computational patterns. This proposal addresses only Fortran D programs with regular computations. Irregular computational patterns are being addressed by others <ref> [31, 32, 33] </ref>. The remainder of this proposal is organized as follows. We first give a brief overview of the target SIMD architecture which this work assumes. Then in Section 2 we discuss related efforts. Section 3 describes our proposed research.
Reference: [34] <author> J. Hennessy and D. Patterson. </author> <title> Computer Architecture A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: Like the MasPar Fortran compiler, we will know the size of the PE array at compile time, and we will use that knowledge to determine the strip amount. For a broad discussion of general SIMD architectures see an appropriate computer architecture book <ref> [34, 38] </ref>.
Reference: [35] <author> W. Hillis. </author> <title> The Connection Machine. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year>
Reference-contexts: For a broad discussion of general SIMD architectures see an appropriate computer architecture book [34, 38]. For a more complete description of the SIMD machines produced by Thinking Machines and MasPar see <ref> [35, 61] </ref> and [8, 54, 56] respectively. 2 Related Work 2.1 SIMD Distributed-Memory Compilers 2.1.1 Compass Compilers Compass (1961-1991) was an independent software house which was involved in the design and implementation of several SIMD compilers.
Reference: [36] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Compiling Fortran D for MIMD distributed memory machines. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: The following three projects are all currently underway: 1. The automatic annotation of Fortran 77 or Fortran 90 programs with data decomposi tion statements to produce the corresponding Fortran 77D or Fortran 90D programs [6, 44]. 2. The generation of efficient MIMD code from Fortran 77D <ref> [30, 36, 64] </ref>. 3. The generation of efficient MIMD code from Fortran 90D [20]. The scope of the work described in this document will be the generation of efficient code for distributed-memory SIMD machines from Fortran 90D. Compiling Fortran 77D to SIMD architectures will not be addressed in this work. <p> by using a Single Program Multiple Data (SPMD) model, in which the compiler generates a single node program which is executed on all the processors. 2.2.1 Fortran D The effort at Rice University to compile Fortran 77D to MIMD machines has resulted in many advanced compiler analysis techniques and optimizations <ref> [30, 36, 64] </ref>. Many of the analysis techniques (e.g., reaching decompositions) will also be very important for a SIMD compiler.
Reference: [37] <author> P. Hudak and E. Mohr. </author> <title> Graphinators and the duality of SIMD and MIMD. </title> <booktitle> In Pro ceedings of the 1988 ACM Symposium on Lisp and Functional Programming, </booktitle> <address> Snowbird, Utah, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: the Fortran-90-Y project have also looked into loop transformations that help optimize the node level programs when a BLOCK distribution is used [18]. 2.1.5 MIMD Emulators There has been growing interest in determining if SIMD architectures can successfully be used to handle problems that do not fit the data-parallel model <ref> [22, 37, 60, 66] </ref>. One method is to emulate MIMD execution by writing a SIMD program to interpret a MIMD instruction set. Each PE contains a program to be interpreted and its data.
Reference: [38] <author> K. Hwang and F. Briggs. </author> <title> Computer Architecture and Parallel Processing. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1984. </year>
Reference-contexts: Like the MasPar Fortran compiler, we will know the size of the PE array at compile time, and we will use that knowledge to determine the strip amount. For a broad discussion of general SIMD architectures see an appropriate computer architecture book <ref> [34, 38] </ref>.
Reference: [39] <author> K. Knobe, J. Lukas, and W. Dally. </author> <title> Dynamic alignment on distributed memory systems. </title> <booktitle> In Proceedings of the Third Workshop on Compilers for Parallel Computers, </booktitle> <address> Vienna, Austria, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Although the data distribution directives and the owner computes rule greatly simplify the distributed-memory compiler's task of determining where operations are to be evaluated, they can result in less than optimal code <ref> [42, 39] </ref>. Often it would be more efficient to compute intermediate results on processors other than those that are the target of the final results, or to change the processors on which the final results are stored.
Reference: [40] <author> K. Knobe, J. Lukas, and G. Steele, Jr. </author> <title> Massively parallel data optimization. </title> <booktitle> In Frontiers '88: The 2nd Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> Fairfax, VA, </address> <month> October </month> <year> 1988. </year>
Reference-contexts: The CM Fortran and MasPar Fortran compilers are described in more detail below. In addition to the general SIMD compiler development effort, Compass did research in the area of data optimization <ref> [1, 40, 41, 42, 43, 52] </ref>. The purpose of data optimization is to align data to improve locality and thus minimize interprocessor communication. Their method assumes an unlimited number of virtual processors.
Reference: [41] <author> K. Knobe, J. Lukas, and G. Steele, Jr. </author> <title> Data optimization: Allocation of arrays to reduce communication on SIMD machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8(2) </volume> <pages> 102-118, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: The CM Fortran and MasPar Fortran compilers are described in more detail below. In addition to the general SIMD compiler development effort, Compass did research in the area of data optimization <ref> [1, 40, 41, 42, 43, 52] </ref>. The purpose of data optimization is to align data to improve locality and thus minimize interprocessor communication. Their method assumes an unlimited number of virtual processors. <p> We are thus not able to make a preliminary comparison against existing data optimization techniques. We are currently intending to use an annotated program dependence graph (PDG) [23] rather than using a preference graph as described by Knobe, Lukas, and Steele <ref> [41] </ref>. We believe annotating the PDG with regular section descriptors [10] will express the required array relationships in such a way to ease the analysis and produce alignments that require less communication.
Reference: [42] <author> K. Knobe, J. Lukas, and M. Weiss. </author> <title> Optimization techniques for SIMD Fortran compil ers. </title> <journal> Concurrency: Practice & Experience, </journal> <note> to appear 1993. Special issue on Compilers and Programming Environments for Parallel Computers. </note>
Reference-contexts: The CM Fortran and MasPar Fortran compilers are described in more detail below. In addition to the general SIMD compiler development effort, Compass did research in the area of data optimization <ref> [1, 40, 41, 42, 43, 52] </ref>. The purpose of data optimization is to align data to improve locality and thus minimize interprocessor communication. Their method assumes an unlimited number of virtual processors. <p> Although the data distribution directives and the owner computes rule greatly simplify the distributed-memory compiler's task of determining where operations are to be evaluated, they can result in less than optimal code <ref> [42, 39] </ref>. Often it would be more efficient to compute intermediate results on processors other than those that are the target of the final results, or to change the processors on which the final results are stored.
Reference: [43] <author> K. Knobe and V. Natarajan. </author> <title> Data optimization: Minimizing residual interprocessor data motion on SIMD machines. </title> <booktitle> In Frontiers '90: The 3rd Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> College Park, MD, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: The CM Fortran and MasPar Fortran compilers are described in more detail below. In addition to the general SIMD compiler development effort, Compass did research in the area of data optimization <ref> [1, 40, 41, 42, 43, 52] </ref>. The purpose of data optimization is to align data to improve locality and thus minimize interprocessor communication. Their method assumes an unlimited number of virtual processors.
Reference: [44] <author> U. Kremer. </author> <title> Automatic data alignment and distribution for distributed-memory ma chines in an interactive programming environment. </title> <type> Thesis proposal, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: Several aspects of the Fortran D project are already being addressed. The following three projects are all currently underway: 1. The automatic annotation of Fortran 77 or Fortran 90 programs with data decomposi tion statements to produce the corresponding Fortran 77D or Fortran 90D programs <ref> [6, 44] </ref>. 2. The generation of efficient MIMD code from Fortran 77D [30, 36, 64]. 3. The generation of efficient MIMD code from Fortran 90D [20]. The scope of the work described in this document will be the generation of efficient code for distributed-memory SIMD machines from Fortran 90D.
Reference: [45] <author> L. Lamport. </author> <title> The parallel execution of DO loops. </title> <journal> Communications of the ACM, </journal> <volume> 17(2):83 93, </volume> <month> February </month> <year> 1974. </year>
Reference-contexts: Not only will this compiler support the validation of our thesis, but it will also establish the basis for future work on analyzing and optimizing Fortran 90 programs. This future work may include investigating compiler techniques for automatically generating SIMD code for loosely synchronous or wave-front style problems <ref> [26, 45] </ref> that is more efficient than the MIMD emulation methods described in Section 2.1.5. 4.2 Validation To test the effectiveness of our optimizations, we will measure the improvements they produce above the system compiler on the target SIMD architectures, the CM-2 and the MP-1.
Reference: [46] <author> J. Li and M. Chen. </author> <title> Automating the coordination of interprocessor communication. </title> <booktitle> In Advances in Languages and Compilers for Parallel Computing, </booktitle> <address> Irvine, CA, August 1990. </address> <publisher> The MIT Press. </publisher> <pages> 17 </pages>
Reference-contexts: Notice how the second statement now contains only perfectly-aligned, element-wise array computations. This work will be similar to that of Li and Chen <ref> [46, 47, 49, 50] </ref>. But whereas their work was based upon pattern matching of reference patterns, ours will be based upon pattern matching of dependence patterns within the annotated program dependence graph.
Reference: [47] <author> J. Li and M. Chen. </author> <title> Generating explicit communication from shared-memory program references. </title> <booktitle> In Proceedings of Supercomputing '90, </booktitle> <address> New York, NY, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: Notice how the second statement now contains only perfectly-aligned, element-wise array computations. This work will be similar to that of Li and Chen <ref> [46, 47, 49, 50] </ref>. But whereas their work was based upon pattern matching of reference patterns, ours will be based upon pattern matching of dependence patterns within the annotated program dependence graph.
Reference: [48] <author> J. Li and M. Chen. </author> <title> Index domain alignment: Minimizing cost of cross-referencing between distributed arrays. </title> <booktitle> In Frontiers '90: The 3rd Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> College Park, MD, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: Many of the analysis techniques (e.g., reaching decompositions) will also be very important for a SIMD compiler. However, many of the optimization techniques take advantage of the asynchronous nature of the processors and cannot be used on SIMD machines. 2.2.2 Crystal The Crystal project at Yale University <ref> [16, 48, 50, 51] </ref> researched the issues of compiling a high-level functional language for SPMD execution.
Reference: [49] <author> J. Li and M. Chen. </author> <title> Synthesis of explicit communication from shared-memory program references. </title> <type> Technical Report YALEU/DCS/TR-755, </type> <institution> Dept. of Computer Science, Yale University, </institution> <address> New Haven, CT, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: Notice how the second statement now contains only perfectly-aligned, element-wise array computations. This work will be similar to that of Li and Chen <ref> [46, 47, 49, 50] </ref>. But whereas their work was based upon pattern matching of reference patterns, ours will be based upon pattern matching of dependence patterns within the annotated program dependence graph.
Reference: [50] <author> J. Li and M. Chen. </author> <title> Compiling communication-efficient programs for massively parallel machines. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 361-376, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Many of the analysis techniques (e.g., reaching decompositions) will also be very important for a SIMD compiler. However, many of the optimization techniques take advantage of the asynchronous nature of the processors and cannot be used on SIMD machines. 2.2.2 Crystal The Crystal project at Yale University <ref> [16, 48, 50, 51] </ref> researched the issues of compiling a high-level functional language for SPMD execution. <p> Notice how the second statement now contains only perfectly-aligned, element-wise array computations. This work will be similar to that of Li and Chen <ref> [46, 47, 49, 50] </ref>. But whereas their work was based upon pattern matching of reference patterns, ours will be based upon pattern matching of dependence patterns within the annotated program dependence graph.
Reference: [51] <author> J. Li and M. Chen. </author> <title> The data alignment phase in compiling programs for distributed memory machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13(2) </volume> <pages> 213-221, </pages> <month> Oc-tober </month> <year> 1991. </year>
Reference-contexts: Many of the analysis techniques (e.g., reaching decompositions) will also be very important for a SIMD compiler. However, many of the optimization techniques take advantage of the asynchronous nature of the processors and cannot be used on SIMD machines. 2.2.2 Crystal The Crystal project at Yale University <ref> [16, 48, 50, 51] </ref> researched the issues of compiling a high-level functional language for SPMD execution.
Reference: [52] <author> J. Lukas and K. Knobe. </author> <title> Data optimization and its effect on communication costs in MIMD Fortran code. </title> <booktitle> In Proceedings of the Fifth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <address> Houston, TX, </address> <month> March </month> <year> 1991. </year>
Reference-contexts: The CM Fortran and MasPar Fortran compilers are described in more detail below. In addition to the general SIMD compiler development effort, Compass did research in the area of data optimization <ref> [1, 40, 41, 42, 43, 52] </ref>. The purpose of data optimization is to align data to improve locality and thus minimize interprocessor communication. Their method assumes an unlimited number of virtual processors.
Reference: [53] <institution> MasPar Computer Corporation, Sunnyvale, CA. </institution> <note> MasPar Fortran Reference Manual, software version 1.1 edition, </note> <month> August </month> <year> 1991. </year>
Reference-contexts: We will refer to this Fortran 90 subset as Compass Fortran, since Compass Incorporated wrote the front ends of both the CM Fortran and MasPar Fortran compilers. The output of the compiler may then be compiled by the Fortran compiler of the target SIMD machine <ref> [53, 62] </ref>. To support the analysis and optimization of Fortran 90 programs we will develop and 13 implement within our compiler algorithms for analyzing the usage of whole arrays and array sections. Regular Section Descriptors (RSD's) [10] will form the foundation on which these algorithms will be built.
Reference: [54] <institution> MasPar Computer Corporation, Sunnyvale, CA. MasPar System Overview, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: For a broad discussion of general SIMD architectures see an appropriate computer architecture book [34, 38]. For a more complete description of the SIMD machines produced by Thinking Machines and MasPar see [35, 61] and <ref> [8, 54, 56] </ref> respectively. 2 Related Work 2.1 SIMD Distributed-Memory Compilers 2.1.1 Compass Compilers Compass (1961-1991) was an independent software house which was involved in the design and implementation of several SIMD compilers. <p> Since both are architecturally equivalent from the compiler's point of view, we will only discuss the MP-2 <ref> [54] </ref>. Since Compass wrote the front-end for both the MasPar Fortran compiler and the CM Fortran compiler, it is no surprise that the languages the two compilers accept are quite similar. A significant difference between the MasPar Fortran compiler and the CM Fortran compiler is how they handle data distribution.
Reference: [55] <author> A. Mohamed, G. Fox, G. v. Laszewski, M. Parashar, T. Haupt, K. Mills, Y. Lu, N. Lin, and N. Yeh. </author> <title> Applications benchmark set for Fortran-D and High Performance Fortran. </title> <type> Technical Report SCCS-327, </type> <institution> NPAC, Syracuse University, </institution> <year> 1992. </year>
Reference-contexts: The test cases we will use come from the Fortran D benchmark set <ref> [55] </ref>. We will time two versions of each Fortran 90D program in the benchmark set: the original Fortran 90 version and an optimized version that has been created by our SIMD compiler. The two versions will be compiled by the system compiler and their execution times compared.
Reference: [56] <author> J. Nickolls. </author> <title> The design of the MasPar MP-1: A cost effective massively parallel com puter. </title> <booktitle> In Proceedings of the 1990 Spring COMPCON, </booktitle> <address> San Francisco, CA, </address> <month> February </month> <year> 1990. </year>
Reference-contexts: For a broad discussion of general SIMD architectures see an appropriate computer architecture book [34, 38]. For a more complete description of the SIMD machines produced by Thinking Machines and MasPar see [35, 61] and <ref> [8, 54, 56] </ref> respectively. 2 Related Work 2.1 SIMD Distributed-Memory Compilers 2.1.1 Compass Compilers Compass (1961-1991) was an independent software house which was involved in the design and implementation of several SIMD compilers.
Reference: [57] <author> A. Rogers and K. Pingali. </author> <title> Process decomposition through locality of reference. </title> <booktitle> In Proceedings of the SIGPLAN '89 Conference on Program Language Design and Implementation, </booktitle> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Fortran D directives enable a programmer to specify how the data is to be laid out across the memory of the machine. Compilers then often use the owner computes rule <ref> [12, 57, 69] </ref> to determine which processors will perform which computations. The owner computes rule states that computations are performed on the processors which will store the result of the computation.
Reference: [58] <author> G. Sabot. </author> <title> Optimized CM Fortran compiler for the Connection Machine computer. </title> <booktitle> In Proceedings of the 25th Annual Hawaii International Conference on System Sciences, </booktitle> <address> Kauai, HI, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: The slicewise compiler ignores the bit-serial processors and uses only the floating-point accelerator chips. The CM Fortran compiler can take advantage of the slicewise model of the machine in different ways to improve program performance for many engineering and scientific applications <ref> [58] </ref>. In this document, any references to the CM Fortran compiler will be to the slicewise compiler unless noted otherwise. Even though the slicewise compiler gives improved performance, it also has several weaknesses. <p> However, they currently only support a single transformation to address this goal: parallel loop fusion. Loop fusion is lacking in that it only considers adjacent loops. The CM Fortran compiler performs this optimization, but only to a small extent <ref> [58] </ref>. 10 REAL, ARRAY (1024) :: A, B, C REAL SCALAR1 SCALAR1 = SCALAR1 + 1 A = B * C ! a single PECODE block will B = SIN (A) + SCALAR1 ! be generated The CM Fortran compiler also only considers adjacent loops, but it will attempt simple code
Reference: [59] <author> G. Sabot, (with D. Gingold, and J. Marantz). </author> <title> CM Fortran optimization notes: Slicewise model. </title> <type> Technical Report TMC-184, </type> <institution> Thinking Machines Corporation, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: The compiler's shortcomings include the lack of transformations to increase the size of elemental code blocks, inefficient use of memory for compiler temporary arrays, and generation of poor code for communication along serial dimensions. Thinking Machines has documented many of the shortcomings <ref> [59] </ref>, and has suggested methods that programmers may use to work around them. Thinking Machines has also done some extensive work on compiling stencils [9]. A stencil is a computational pattern that calculates a new value for a matrix element by combining elements from neighboring matrix locations.
Reference: [60] <author> W. Shu and M. Wu. </author> <title> Solving dynamic and irregular problems on SIMD architectures with runtime support. </title> <note> submitted to ICPP'93, </note> <month> August </month> <year> 1993. </year>
Reference-contexts: the Fortran-90-Y project have also looked into loop transformations that help optimize the node level programs when a BLOCK distribution is used [18]. 2.1.5 MIMD Emulators There has been growing interest in determining if SIMD architectures can successfully be used to handle problems that do not fit the data-parallel model <ref> [22, 37, 60, 66] </ref>. One method is to emulate MIMD execution by writing a SIMD program to interpret a MIMD instruction set. Each PE contains a program to be interpreted and its data.
Reference: [61] <institution> Thinking Machines Corporation, </institution> <address> Cambridge, MA. </address> <note> Connection Machine CM-2 Technical Summary, </note> <month> April </month> <year> 1987. </year>
Reference-contexts: For a broad discussion of general SIMD architectures see an appropriate computer architecture book [34, 38]. For a more complete description of the SIMD machines produced by Thinking Machines and MasPar see <ref> [35, 61] </ref> and [8, 54, 56] respectively. 2 Related Work 2.1 SIMD Distributed-Memory Compilers 2.1.1 Compass Compilers Compass (1961-1991) was an independent software house which was involved in the design and implementation of several SIMD compilers. <p> Like 3 the Compass work, they separate the issues of array alignment from array distribution. 2.1.2 CM Fortran Thinking Machines Corporation has developed two generations of a distributed-memory SIMD architecture, the most recent being the CM-2 1 <ref> [61] </ref>. CM Fortran, their Fortran derivative, is an implementation of Fortran 77 augmented with array constructs from Fortran 90. Their compiler for CM Fortran has also developed through two generations. The first generation was the Paris (or fieldwise) compiler which uses the bit-serial processors on the CM-2.
Reference: [62] <institution> Thinking Machines Corporation, </institution> <address> Cambridge, MA. </address> <note> CM Fortran Reference Manual, ver sion 1.0 edition, </note> <month> February </month> <year> 1991. </year>
Reference-contexts: We will refer to this Fortran 90 subset as Compass Fortran, since Compass Incorporated wrote the front ends of both the CM Fortran and MasPar Fortran compilers. The output of the compiler may then be compiled by the Fortran compiler of the target SIMD machine <ref> [53, 62] </ref>. To support the analysis and optimization of Fortran 90 programs we will develop and 13 implement within our compiler algorithms for analyzing the usage of whole arrays and array sections. Regular Section Descriptors (RSD's) [10] will form the foundation on which these algorithms will be built.
Reference: [63] <institution> Thinking Machines Corporation, </institution> <address> Cambridge, MA. </address> <note> Connection Machine CM-200 Tech 18 nical Summary, </note> <month> June </month> <year> 1991. </year>
Reference-contexts: The cost of this flexibility is that the compiler cannot use the knowledge of the number of processors in performing optimizations. 1 References to the CM-2 are meant to include the CM-200 <ref> [63] </ref> series. 4 2.1.4 Fortran-90-Y Yale University has recently embarked on a compiler project for Fortran 90 [17]. The Fortran-90-Y compiler uses an abstract semantic algebra, Yale Intermediate Representation (YR), as its intermediate language.
Reference: [64] <author> C. Tseng. </author> <title> An Optimizing Fortran D Compiler for MIMD Distributed-Memory Machines. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: The following three projects are all currently underway: 1. The automatic annotation of Fortran 77 or Fortran 90 programs with data decomposi tion statements to produce the corresponding Fortran 77D or Fortran 90D programs [6, 44]. 2. The generation of efficient MIMD code from Fortran 77D <ref> [30, 36, 64] </ref>. 3. The generation of efficient MIMD code from Fortran 90D [20]. The scope of the work described in this document will be the generation of efficient code for distributed-memory SIMD machines from Fortran 90D. Compiling Fortran 77D to SIMD architectures will not be addressed in this work. <p> by using a Single Program Multiple Data (SPMD) model, in which the compiler generates a single node program which is executed on all the processors. 2.2.1 Fortran D The effort at Rice University to compile Fortran 77D to MIMD machines has resulted in many advanced compiler analysis techniques and optimizations <ref> [30, 36, 64] </ref>. Many of the analysis techniques (e.g., reaching decompositions) will also be very important for a SIMD compiler.
Reference: [65] <author> M. Weiss. </author> <title> Strip mining on SIMD architectures. </title> <booktitle> In Proceedings of the 1991 ACM International Conference on Supercomputing, </booktitle> <address> Cologne, Germany, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Then based on usage patterns, it maps arrays to the virtual processors, striving to align them so that communication costs are minimized. A later stage of the compiler then uses strip mining to map the virtual processors to the physical processors <ref> [65] </ref>, also known as array distribution. This two stage approach makes each stage conceptually clean, but prevents them from interacting. There are others, outside of Compass, who have done research in the area of data optimization.
Reference: [66] <author> P. Wilsey, D. Hensgen, N. Abu-Ghazaleh, C. Slusher, and D. Hollinden. </author> <title> The concur rent execution of non-communicating programs on SIMD processors. </title> <booktitle> In Frontiers '92: The 4th Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> McLean, VA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: the Fortran-90-Y project have also looked into loop transformations that help optimize the node level programs when a BLOCK distribution is used [18]. 2.1.5 MIMD Emulators There has been growing interest in determining if SIMD architectures can successfully be used to handle problems that do not fit the data-parallel model <ref> [22, 37, 60, 66] </ref>. One method is to emulate MIMD execution by writing a SIMD program to interpret a MIMD instruction set. Each PE contains a program to be interpreted and its data.
Reference: [67] <author> M. J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Cam bridge, MA, </address> <year> 1989. </year>
Reference-contexts: The scope of the work described in this document will be the generation of efficient code for distributed-memory SIMD machines from Fortran 90D. Compiling Fortran 77D to SIMD architectures will not be addressed in this work. However, using the techniques of automatic vectorization <ref> [3, 67] </ref> one can transform Fortran 77D into Fortran 90D, at which point the work described here can be employed to generate efficient SIMD code. Distributed-memory MIMD architectures and distributed-memory SIMD architectures share many characteristics. <p> Program transformations, such as loop reversal, will also be used to allow more arrays to be treated as offset arrays. This work has similarities to sectioning/strip mining of array syntax [2], vector register allocation [4], and scalarization of Fortran 90 code <ref> [67] </ref>. We hope to exploit this previous work in the analysis phase. The program transformations of the previous efforts will also be useful, but they will need to be augmented with distributed-memory specific transformations.
Reference: [68] <author> X3J3 Subcommittee. </author> <title> American National Standard Programming Language Fortran (X3.9-1978). </title> <institution> American National Standards Institute, </institution> <address> New York, NY, </address> <year> 1978. </year>
Reference-contexts: The goal of the Fortran D project is to develop advanced compilers that take programs written in a data-parallel programming style and annotated with data decomposition statements, and automatically generate code that can be executed efficiently on different distributed-memory architectures. The Fortran D source languages include both Fortran 77 <ref> [68] </ref> and Fortran 90 [5], and the target architectures may be either MIMD or SIMD. Several aspects of the Fortran D project are already being addressed. The following three projects are all currently underway: 1.
Reference: [69] <author> H. Zima, H.-J. Bast, and M. Gerndt. </author> <title> SUPERB: A tool for semi-automatic MIMD/SIMD parallelization. </title> <journal> Parallel Computing, </journal> <volume> 6 </volume> <pages> 1-18, </pages> <year> 1988. </year>
Reference-contexts: Fortran D directives enable a programmer to specify how the data is to be laid out across the memory of the machine. Compilers then often use the owner computes rule <ref> [12, 57, 69] </ref> to determine which processors will perform which computations. The owner computes rule states that computations are performed on the processors which will store the result of the computation.
Reference: [70] <author> H. Zima, P. Brezany, B. Chapman, P. Mehrotra, and A. Schwald. </author> <title> Vienna Fortran | a language specification, version 1.1. </title> <type> Interim Report 21, </type> <institution> Institute for Computer Application in Science and Engineering, Hampton, VA, </institution> <month> March </month> <year> 1992. </year> <month> 19 </month>
Reference-contexts: They made major contributions to the issues of automatic data alignment and identification of collective communication primitives. 5 2.2.3 Vienna Fortran The Vienna Fortran project at the University of Vienna <ref> [7, 13, 70] </ref> is very similar, in both goals and methodologies, to the Fortran D project.
References-found: 70

