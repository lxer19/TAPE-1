URL: http://www.cs.umn.edu/Users/dept/users/kumar/datavis.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Title: Visual Data Mining: Framework and Algorithm Development  
Author: M. Ganesh, Eui-Hong (Sam) Han Vipin Kumar, Shashi Shekhar, Jaideep Srivastava 
Keyword: Data mining, visualization, classification, decision trees, algorithm development.  
Note: Contact author: Eui-Hong (Sam) Han  The authors are listed in alphabetical order and no seniority is implied.  
Address: 4-192 EECS Bldg., 200 Union St. SE  Minneapolis, MN 55455, USA  
Affiliation: Dept. of Computer Information Sciences  University of Minnesota  
Pubnum: Technical Report  
Email: email: han@cs.umn.edu  
Phone: Tel: (612) 626-7515  
Date: 96-021 (March 12, 1996)  
Abstract: Visual data mining is the use of visualization techniques to allow data miners and analysts to evaluate, monitor, and guide the inputs, products and process of data mining. It can help introduce user insights, preferences, and biases in the earlier stages of the data mining life-cycle to reduce its overall computation complexity and reduce the set of uninteresting patterns in the product. Even more useful may be the new insights developed by the data miners and analysts concerning the quality and implications of the decisions made by the data mining process. These new insights may facilitate the development of better algorithms and processes for data mining. This paper provides a framework for visual data mining via the loose-coupling of databases and visualization systems. The paper applies visual data mining towards designing new algorithms that can learn decision trees by manually refining some of the decisions made well-known algorithms such as C4:5. Experiments with a set of benchmark data sets from the literature show that a new algorithm consistently outperforms the well-known algorithms. The paper concludes with a discussion of the implications of visual data mining for the data mining, databases, and visualization systems. 
Abstract-found: 1
Intro-found: 1
Reference: [ABN92] <author> T. M. Anwar, H. W. Beck, and S. B. Navathe. </author> <title> Knowledge mining by imprecise querying: A classification-based approach. </title> <booktitle> In Proc. of the 8th Int'l Conf. on Data Engg., </booktitle> <pages> pages 622-630, </pages> <year> 1992. </year>
Reference-contexts: We believe there is a need to use semantically rich data models, e.g. the entity relationship model [EN94], to model the concepts. Some initial efforts in this direction include <ref> [ABN92, KKS94, LHLQ95] </ref>. Next, we need the ability to visualize database concepts like schemas, queries, indices, etc. in addition to the data.
Reference: [AIS93] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Database mining: A performance perspective. </title> <journal> IEEE Transactions on Knowledge and Data Engg., </journal> <volume> 5(6) </volume> <pages> 914-925, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: first briefly survey techniques in data mining and visualization and then evaluate the potential of visualization techniques for enhancing the effectiveness of data mining. 3 2.1 Data Mining: A Brief Survey Data mining is an active research area with the promise of high payoffs in many business and scientific domains <ref> [FPSM91, MCPS93, AIS93, AP95] </ref>. Industry, government, and scientific communities are being inundated with huge volumes of data that is routinely stored in online databases. Analyzing this data and extracting meaningful patterns from it is almost impossible without computer assistance to the human analyst. <p> Knowledge extracted during the mining process can be of various kinds, depending on the nature of the knowledge, its complexity, its uses, etc. Examples include classification rules, association rules, temporal sequences, causal graphs, etc. <ref> [AIS93] </ref>. In addition, this categorization helps in developing efficient algorithms for the specific categories of knowledge. The focus of traditional machine-learning research [Car90] was on the accuracy of the learned knowledge. <p> In recent years substantial advances have been made in developing data-mining techniques that provide high efficiency in addition to improved accuracy. Since a detailed survey of data mining research is beyond the scope of the present paper, we point readers to the following references <ref> [MCPS93, AIS93, AP95] </ref>. <p> The problem space of this search process consists of Model Candidates, a Model Candidate Generator, and Model Constraints. Many existing classification-learning algorithms like C4:5 [Qui93] and CDP <ref> [AIS93] </ref> fit nicely within this search framework. New learning algorithms that fit users' requirements can be developed by defining the components of the problem 12 based interface for the manipulation of search parameters space. We discuss the components of the search problem space in the context of ID3 like decision-tree-learning. <p> The over-fitted tree is then pruned, using a predicted error criterion, by replacing some subtrees with leaves or some intermediate nodes with some subtrees. For comparison purposes, we show the results with pruning (C4:5P ) and without pruning (C4:5). CDP has been developed as part of the Quest project <ref> [AIS93] </ref> at the IBM Almaden Research Center. This algorithm has been shown to have comparable accuracy to the C4:5 algorithm, while generating a relatively smaller number of nodes. <p> The CDP algorithm uses a dynamic pruning criterion to stop the generation of decision nodes if the error rate at a node of the tree is below some adaptive precision threshold. Benchmark Data: We have followed the experimental methodology described in <ref> [AIS93] </ref> very closely. Our data set consists of records with the attributes described in table 3. Attributes elevel, car and zipcode are discrete attributes, while all the other attributes are continuous. The data records are divided into classes based on classification functions of varying complexity. <p> In our experiments we have set the noise factor at 5%. Following the strategy in <ref> [AIS93] </ref>, we have selected training set sizes of 2500 tuples and test set sizes of 10000 tuples. We have generated 10 sets of data for the experiment. We used the same set of 10 functions described in [AIS93] for our experiments. <p> Following the strategy in <ref> [AIS93] </ref>, we have selected training set sizes of 2500 tuples and test set sizes of 10000 tuples. We have generated 10 sets of data for the experiment. We used the same set of 10 functions described in [AIS93] for our experiments. Performance Metrics: We have selected the following metrics to compare the efficiency, accuracy and size of final decision trees of the classification algorithms. The generation efficiency of the nodes is measured in terms of the total number of nodes generated. <p> For this experiment, we chose a 6% overall error rate as the acceptable error rate. We do not have a copy of the CDP algorithm, and thus we simulated the algorithm based on the description in <ref> [AIS93] </ref>. CDP uses a parameter maxlength for the adaptive precision threshold. We have chosen 10 for the parameter, which is the choice in [AIS93]. We also used the same value for CDP+. The experiments are repeated 10 times to obtain confidence intervals of 95 percent for the mean error values. <p> We do not have a copy of the CDP algorithm, and thus we simulated the algorithm based on the description in <ref> [AIS93] </ref>. CDP uses a parameter maxlength for the adaptive precision threshold. We have chosen 10 for the parameter, which is the choice in [AIS93]. We also used the same value for CDP+. The experiments are repeated 10 times to obtain confidence intervals of 95 percent for the mean error values. <p> On the y-axis, the number of nodes in the final decision trees is shown for each classification function. The final tree size for all algorithms except C4:5P is the same as the number of nodes generated. As noted in <ref> [AIS93] </ref>, the result shows that CDP has accuracy comparable to C4:5, while 20 problem. They represent C4.5, C4.5P, BF, CDP and CDP+ from left to right. problem. They represent C4.5, C4.5P, BF, CDP and CDP+ from left to right. 21 each problem.
Reference: [AP95] <author> R. Argawal and G. Psaila. </author> <title> Active data mining. </title> <booktitle> In Proc. of the First Int'l Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pages 3-8, </pages> <address> Montreal, Quebec, </address> <year> 1995. </year>
Reference-contexts: first briefly survey techniques in data mining and visualization and then evaluate the potential of visualization techniques for enhancing the effectiveness of data mining. 3 2.1 Data Mining: A Brief Survey Data mining is an active research area with the promise of high payoffs in many business and scientific domains <ref> [FPSM91, MCPS93, AIS93, AP95] </ref>. Industry, government, and scientific communities are being inundated with huge volumes of data that is routinely stored in online databases. Analyzing this data and extracting meaningful patterns from it is almost impossible without computer assistance to the human analyst. <p> Much of the data-mining research to date has focused on approaches to applying traditional machine learning and discovery methods to data stored in relational databases [FPSM91]. Recent years have seen more of a "systems" approach to the process <ref> [MCPS93, AP95, HS95] </ref>, where knowledge discovery and machine-learning techniques are components of an entire data mining system. Knowledge extracted during the mining process can be of various kinds, depending on the nature of the knowledge, its complexity, its uses, etc. <p> In recent years substantial advances have been made in developing data-mining techniques that provide high efficiency in addition to improved accuracy. Since a detailed survey of data mining research is beyond the scope of the present paper, we point readers to the following references <ref> [MCPS93, AIS93, AP95] </ref>.
Reference: [AS92] <author> M. B. Amin and S. Shekhar. </author> <title> Generalization by neural networks. </title> <booktitle> Proc. of the 8th Int'l Conf. on Data Engg., </booktitle> <month> April </month> <year> 1992. </year>
Reference-contexts: Another area of interest is in exploring specific data mining application domains such as database integration [GSR96], semantic query optimization [SHKC93] and generalization <ref> [AS92] </ref>. 7 Acknowledgments We would like to thank Dr. Arun Swami from Silicon Graphics Inc. and Dr. Bamshad Mobasher for their valuable contributions in the various stages of the project.
Reference: [AS94] <author> R. Agrawal and R. Srikant. </author> <title> Fast algorithms for mining association rules. </title> <booktitle> In Proc. of the 20th VLDB Conference, </booktitle> <pages> pages 487-499, </pages> <address> Santiago, Chile, </address> <year> 1994. </year>
Reference-contexts: 1 Introduction Data mining [SAD + 93] is the efficient and possibly unsupervised discovery of interesting, useful and previously unknown patterns in a data warehouse, which is a historical database designed to facilitate analysis and knowledge discovery. Common patterns of interest include classification [Qui86], associations <ref> [AS94, HS95] </ref>, clustering [Fis95], and sequential patterns [MTV95]. The process is often very slow, particularly when databases are large. The success of the data mining process is critically dependent upon the availability of user insights and biases [Mit77], even though the process may use unsupervised learning algorithms [Lan96].
Reference: [BF94] <author> C.G. Beshers and S.K. Feiner. </author> <title> Automated design of data visualizations. </title> <editor> In L. Rosenblum, R.A. Earnshaw, J. Encarnacao, H. Hagen, A. Kaufman, S. Klimenko, G. Nielson, F. Post, and D. Thalmann, editors, </editor> <booktitle> Scientific Visualization, </booktitle> <pages> pages 86-102. </pages> <publisher> Academic Press Inc., </publisher> <address> San Diego, CA, </address> <year> 1994. </year>
Reference-contexts: The users can perceive data characteristics such as multidimensional clusters or correlations by studying corresponding regions in the different windows. Control Interface: Control of most visualization systems is provided as a "point-and-click" interface, typically handled by a mouse. A new interface like one using DataGlove has been also proposed <ref> [BF94] </ref>. The ease of use of PCs over Unix machines has shown the clear superiority of the desktop paradigm over a textually oriented command line paradigm. Control Methods: Control methods refer to the various techniques that are available to an analyst to control navigation through the data. <p> However, octree representations, filtering schemes and transformation schemes have been proposed to reduce the memory requirement of the voxel model by compressing the information [Kau94b]. AutoVisual <ref> [BF94] </ref> designs visualizations for the n-Vision visualization system that use worlds within worlds, an interactive method of representing multivariate relations with a hierarchy of nested heterogeneous coordinate systems (worlds). Each world may contain a graph encoding a subset of the relation encoded by its parent world.
Reference: [BST + 94] <author> R. J. Brachman, P. G. Selfridge, L. G. Terveen, B. Altman, A. Borgida, F. Halper, T. Kirk, A. Lazar, D. L. McGuiness, and L. A. Resnick. </author> <title> Integrated support for data archaeology. </title> <booktitle> In Proc. of AAAI-94 Knowledge Discovery in Databases Workshop, </booktitle> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: It also provides an interface to bind data variables to the several elements of the glyphs. This binding makes data characteristics be displayed through the visual aspects of glyphs. Visualization Needs of Data Mining have been explored by few researchers. IMACS <ref> [BST + 94] </ref> uses conventional graphs and plots as an interface for the analyst to segment data with mouse clicks. The data segements appear as breaks in a graph to indicate segment boundaries.
Reference: [Car90] <author> J. G. Carbonell. </author> <title> Introduction: Paradigms for machine learning. </title> <editor> In J. G. Carbonell, editor, </editor> <booktitle> Machine Learning: Paradigms and Methods, </booktitle> <pages> pages 1-9. </pages> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Examples include classification rules, association rules, temporal sequences, causal graphs, etc. [AIS93]. In addition, this categorization helps in developing efficient algorithms for the specific categories of knowledge. The focus of traditional machine-learning research <ref> [Car90] </ref> was on the accuracy of the learned knowledge. Given the huge volume of data in databases and the computational complexity of the learning process, the scope of the research program has been expanded to address efficiency in addition to accuracy.
Reference: [com94] <institution> Special issue on visualization. IEEE Computer, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: Any visualization system focuses on the following four issues: (i) the conceptual model of visualization data, (ii) the control interface, (iii) the control methods, and (iv) the visualization representation. A detailed survey of these is beyond the scope of this paper and can be found in <ref> [NS90, REE + 94, com94] </ref>. In the following, we provide a brief overview of each of these. Conceptual Data Model: Almost all work in visualization has used some variation of a model where (point) datum is represented as a vector with values for each component/dimension.
Reference: [Dav93] <author> C. Davidson. </author> <title> What your database hides away. </title> <journal> New Scientist, </journal> <pages> pages 28-31, </pages> <month> 9 January </month> <year> 1993. </year>
Reference-contexts: The data segements appear as breaks in a graph to indicate segment boundaries. MVV [MTS91] uses bar charts and slider bars to locate clusters in multidimensional space, allowing the display of multiple views of a given dataset. The nested histograms and the group bars in WinViz [LHLQ95] and Netmap <ref> [Dav93] </ref> are line-based visualization tools that use a circle as the basic graphical device. Its circumference is divided into several groups, one for each attribute of interest. Individuals are represented by nodes within the group. Lines drawn across circles indicate relationships between subgroups or individuals linking their nodes.
Reference: [EN94] <author> R. Elmasri and S. Navathe. </author> <title> Fundamentals of Database Systems. </title> <address> Benjamin/Cummings, Redwood City, CA, </address> <note> second edition, </note> <year> 1994. </year>
Reference-contexts: First, we believe that the vector-type data models are too low level to appropriately 6 capture the rich semantics found in most business data. We believe there is a need to use semantically rich data models, e.g. the entity relationship model <ref> [EN94] </ref>, to model the concepts. Some initial efforts in this direction include [ABN92, KKS94, LHLQ95]. Next, we need the ability to visualize database concepts like schemas, queries, indices, etc. in addition to the data. <p> Several associations between pairs of concepts from the two domains need to be specified. These include the association between query results and their visual representations, as well as the association between external events and implied queries on the visual representations. This paper uses the Entity-Relationship Diagram (ERD) <ref> [EN94] </ref>, a well-known conceptual data-model, to specify visual representations just like other data in a database.
Reference: [Fis95] <author> D. Fisher. </author> <title> Optimization and simplification of hierarchical clusterings. </title> <booktitle> In Proc. of the First Int'l Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pages 118-123, </pages> <address> Montreal, Quebec, </address> <year> 1995. </year>
Reference-contexts: 1 Introduction Data mining [SAD + 93] is the efficient and possibly unsupervised discovery of interesting, useful and previously unknown patterns in a data warehouse, which is a historical database designed to facilitate analysis and knowledge discovery. Common patterns of interest include classification [Qui86], associations [AS94, HS95], clustering <ref> [Fis95] </ref>, and sequential patterns [MTV95]. The process is often very slow, particularly when databases are large. The success of the data mining process is critically dependent upon the availability of user insights and biases [Mit77], even though the process may use unsupervised learning algorithms [Lan96].
Reference: [FPSM91] <author> W. J. Frawley, G. Piatetsky-Shapiro, and C. J. Matheus. </author> <title> Knowledge discovery in databases: An overview. </title> <editor> In G. Piatetsky-Shapiro and W. J. Frawley, editors, </editor> <booktitle> Knowledge Discovery in Databases, </booktitle> <pages> pages 1-27. </pages> <publisher> The AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1991. </year>
Reference-contexts: first briefly survey techniques in data mining and visualization and then evaluate the potential of visualization techniques for enhancing the effectiveness of data mining. 3 2.1 Data Mining: A Brief Survey Data mining is an active research area with the promise of high payoffs in many business and scientific domains <ref> [FPSM91, MCPS93, AIS93, AP95] </ref>. Industry, government, and scientific communities are being inundated with huge volumes of data that is routinely stored in online databases. Analyzing this data and extracting meaningful patterns from it is almost impossible without computer assistance to the human analyst. <p> Analyzing this data and extracting meaningful patterns from it is almost impossible without computer assistance to the human analyst. Much of the data-mining research to date has focused on approaches to applying traditional machine learning and discovery methods to data stored in relational databases <ref> [FPSM91] </ref>. Recent years have seen more of a "systems" approach to the process [MCPS93, AP95, HS95], where knowledge discovery and machine-learning techniques are components of an entire data mining system.
Reference: [Gro94] <author> M.H. Gross. </author> <title> Subspace methods for the visualization of multidimensional data sets. </title> <editor> In L. Rosen-blum, R.A. Earnshaw, J. Encarnacao, H. Hagen, A. Kaufman, S. Klimenko, G. Nielson, F. Post, and D. Thalmann, editors, </editor> <booktitle> Scientific Visualization, </booktitle> <pages> pages 171-186. </pages> <publisher> Academic Press Inc., </publisher> <address> San Diego, CA, </address> <year> 1994. </year>
Reference-contexts: Specific examples include querying, dimension reduction, aggregation, setting of orientation/perspective/hierarchy, animation, and slider control. Current visualization systems provide some of these. Subspace methods find significant features and subspaces of high-dimensional data sets that can be visualized <ref> [Gro94] </ref>. Cluster-analysis techniques are used to find an optimal representation of the density distribution of the multidimensional data sets. The problem of finding a low dimensional representation of these clusters that preserves their most important features is solved by an analysis of the principal components.
Reference: [GSR96] <author> M. Ganesh, J. Srivastava, and T. Richardson. </author> <title> Rule learning for instance-level database integration. </title> <type> Technical Report TR-96-??, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, </institution> <year> 1996. </year>
Reference-contexts: We would also like to explore whether a search framework can help in developing new insights and algorithms for discovering other patterns such as association rules, clusterings and sequences. Another area of interest is in exploring specific data mining application domains such as database integration <ref> [GSR96] </ref>, semantic query optimization [SHKC93] and generalization [AS92]. 7 Acknowledgments We would like to thank Dr. Arun Swami from Silicon Graphics Inc. and Dr. Bamshad Mobasher for their valuable contributions in the various stages of the project.
Reference: [GSSW92] <author> G. Grinstein, J. Seig, S. Smith, and M. Williams. </author> <title> Visualization for knowledge discovery. </title> <journal> Int'l Journal of Intelligent Systems, </journal> <volume> 7 </volume> <pages> 637-648, </pages> <year> 1992. </year>
Reference-contexts: Each primitive object has a location with respect to the enclosing visual representation. Visual representations include user-defined and system-defined diagrams and pictures to visualize the inputs, products and process of data mining. Different diagrams already proposed in the literature <ref> [GSSW92, LHLQ95, KKS94, KK94, RAEM94] </ref> can be thought of as concrete instances of visual representation for data mining. We believe that newer visual representations will be forthcoming based on the needs of the application domains and data mining life-cycles in the future.
Reference: [HS95] <author> M. A. W. Houtsma and A. N. Swami. </author> <title> Set-oriented mining for association rules in relational databases. </title> <booktitle> In Proc. of the 11th Int'l Conf. on Data Engg., </booktitle> <pages> pages 25-33, </pages> <address> Taipei, Taiwan, </address> <year> 1995. </year> <month> 25 </month>
Reference-contexts: 1 Introduction Data mining [SAD + 93] is the efficient and possibly unsupervised discovery of interesting, useful and previously unknown patterns in a data warehouse, which is a historical database designed to facilitate analysis and knowledge discovery. Common patterns of interest include classification [Qui86], associations <ref> [AS94, HS95] </ref>, clustering [Fis95], and sequential patterns [MTV95]. The process is often very slow, particularly when databases are large. The success of the data mining process is critically dependent upon the availability of user insights and biases [Mit77], even though the process may use unsupervised learning algorithms [Lan96]. <p> Much of the data-mining research to date has focused on approaches to applying traditional machine learning and discovery methods to data stored in relational databases [FPSM91]. Recent years have seen more of a "systems" approach to the process <ref> [MCPS93, AP95, HS95] </ref>, where knowledge discovery and machine-learning techniques are components of an entire data mining system. Knowledge extracted during the mining process can be of various kinds, depending on the nature of the knowledge, its complexity, its uses, etc.
Reference: [IH94] <author> W. H. Inmon and R. D. Hackathorn. </author> <title> Using the Data Warehouse. </title> <address> Wiley-QED, </address> <year> 1994. </year>
Reference-contexts: The data preparation stage deals with improving the data quality and summarizing the data to facilitate the analysis and discovery process. Data mining can be done on either operational databases or on a data warehouse <ref> [IH94] </ref>, which is usually a summary database of the various businesses of an enterprise. The quality of the data in the data warehouse is constantly monitored by data analysts. <p> The quality of the data in the data warehouse is constantly monitored by data analysts. Due to the heterogeneity and non-standard policies enforced on data quality at the different source databases, the warehouse data is usually cleaned or standardized via data scrubbing <ref> [Inm92, IH94] </ref>. The model derivation stage focuses on choosing learning samples, testing samples and learning algorithms. Due to the large volume of available data, data mining may be done 1 on subsets of the data from the data warehouse.
Reference: [Inm92] <author> W. H. Inmon. </author> <title> Building the Data Warehouse. </title> <address> Wiley-QED, </address> <year> 1992. </year>
Reference-contexts: The quality of the data in the data warehouse is constantly monitored by data analysts. Due to the heterogeneity and non-standard policies enforced on data quality at the different source databases, the warehouse data is usually cleaned or standardized via data scrubbing <ref> [Inm92, IH94] </ref>. The model derivation stage focuses on choosing learning samples, testing samples and learning algorithms. Due to the large volume of available data, data mining may be done 1 on subsets of the data from the data warehouse.
Reference: [Kau94a] <author> A. Kaufman. </author> <title> Guest editor's introduction: Visualization. </title> <journal> IEEE Computer, </journal> <volume> 27(7) </volume> <pages> 18-19, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: any of these data-mining techniques can be used as the engine in the "model derivation algorithm" component of our system. 2.2 Visualization Techniques: A Brief Survey Visualization has been an active research area for some time now, and it has shown its power in helping us better understand scientific phenomena <ref> [REE + 94, Kau94a] </ref>. Any visualization system focuses on the following four issues: (i) the conceptual model of visualization data, (ii) the control interface, (iii) the control methods, and (iv) the visualization representation.
Reference: [Kau94b] <author> A. Kaufman. </author> <title> Trends in volume visualization and volume graphics. </title> <editor> In L. Rosenblum, R.A. Earn-shaw, J. Encarnacao, H. Hagen, A. Kaufman, S. Klimenko, G. Nielson, F. Post, and D. Thal-mann, editors, </editor> <booktitle> Scientific Visualization, </booktitle> <pages> pages 3-19. </pages> <publisher> Academic Press Inc., </publisher> <address> San Diego, CA, </address> <year> 1994. </year>
Reference-contexts: Visualization Representations: Volume visualization is a method of extracting information from volumetric datasets and is concerned with the representation, manipulation and rendering of these datasets <ref> [Kau94b] </ref>. The volumetric dataset is usually represented as a 3D discrete regular grid of volume elements called voxels. Each voxel has values associated with it which represent properties of the object residing in the voxel. Volume graphics [Kau94b] provides a mechanism for synthesis, manipulation and rendering of volumetric objects stored in <p> datasets and is concerned with the representation, manipulation and rendering of these datasets <ref> [Kau94b] </ref>. The volumetric dataset is usually represented as a 3D discrete regular grid of volume elements called voxels. Each voxel has values associated with it which represent properties of the object residing in the voxel. Volume graphics [Kau94b] provides a mechanism for synthesis, manipulation and rendering of volumetric objects stored in a volume buffer of voxels. Volume graphics has several advantages over conventional surface graphics. <p> Volume graphics has several advantages over conventional surface graphics. These are viewpoint independence, insensitivity to object and scene complexity, support for block operations and the capability of representing the inner structure of objects <ref> [Kau94b] </ref>. The major disadvantage of volume graphics based on the voxel model is that the method is approximate and requires a very large amount of 5 memory. <p> However, octree representations, filtering schemes and transformation schemes have been proposed to reduce the memory requirement of the voxel model by compressing the information <ref> [Kau94b] </ref>. AutoVisual [BF94] designs visualizations for the n-Vision visualization system that use worlds within worlds, an interactive method of representing multivariate relations with a hierarchy of nested heterogeneous coordinate systems (worlds). Each world may contain a graph encoding a subset of the relation encoded by its parent world.
Reference: [KGGK94] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Algorithm Design and Analysis. </title> <publisher> Benjamin Cummings/ Addison Wesley, </publisher> <address> Redwod City, </address> <year> 1994. </year>
Reference-contexts: Window systems may need to use hierarchical management of such large datasets by viewing visual representations as indices rather than as collections of actual objects. We would like to explore the parallel implementation <ref> [KGGK94, KSA94] </ref> of search algorithms, which is more complex than sequential algorithms. We will use the VQLBCI framework as the front-end interface and will provide users with different ways to run data mining algorithms: in parallel or distributed over available computing resources.
Reference: [KK94] <author> D. A. Keim and H.-P. Kriegel. VisDB: </author> <title> Database exploration using multidimensional visualization. </title> <journal> IEEE Computer Graphics and Applications, </journal> <pages> pages 40-49, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Given the roots of visualization in graphics, this is very natural. While often adequate for representing information about physical phenomena such as convective and laminar flows, vortex formation, etc., this approach may not be appropriate for repre 4 senting the complex relationships found in business data [Mac86]. The VisDB <ref> [KK94] </ref> system demonstrates one example of conceptual data modeling of complex business data. The VisDB system uses each pixel of the screen to visualize the data items resulting from a query on whole data. The resulting data items are sorted according to their relevance to the query. <p> Each primitive object has a location with respect to the enclosing visual representation. Visual representations include user-defined and system-defined diagrams and pictures to visualize the inputs, products and process of data mining. Different diagrams already proposed in the literature <ref> [GSSW92, LHLQ95, KKS94, KK94, RAEM94] </ref> can be thought of as concrete instances of visual representation for data mining. We believe that newer visual representations will be forthcoming based on the needs of the application domains and data mining life-cycles in the future.
Reference: [KKS94] <author> D. A. Keim, H.-P. Kriegel, and T. Seidl. </author> <title> Supporting data mining of large databases by visual feedback queries. </title> <booktitle> In Proc. of the 10th Int'l Conf. on Data Engg., </booktitle> <pages> pages 302-313, </pages> <address> Houston, TX, </address> <year> 1994. </year>
Reference-contexts: Second, user feedback can improve the selection of appropriate learning algorithms based on the application domain. Third, visual inspection of datasets can provide direct clues towards interesting patterns in the data <ref> [KKS94] </ref>. <p> We believe there is a need to use semantically rich data models, e.g. the entity relationship model [EN94], to model the concepts. Some initial efforts in this direction include <ref> [ABN92, KKS94, LHLQ95] </ref>. Next, we need the ability to visualize database concepts like schemas, queries, indices, etc. in addition to the data. <p> Each primitive object has a location with respect to the enclosing visual representation. Visual representations include user-defined and system-defined diagrams and pictures to visualize the inputs, products and process of data mining. Different diagrams already proposed in the literature <ref> [GSSW92, LHLQ95, KKS94, KK94, RAEM94] </ref> can be thought of as concrete instances of visual representation for data mining. We believe that newer visual representations will be forthcoming based on the needs of the application domains and data mining life-cycles in the future.
Reference: [Kor90] <author> R. E. Korf. </author> <title> Search. </title> <editor> In S. C. Shapiro, editor, </editor> <booktitle> Encyclopedia of Artificial Intelligence, </booktitle> <pages> pages 994-998. </pages> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1990. </year>
Reference-contexts: Poor decisions made by the data mining systems can be detected and corrected via a visual query 11 language-based control interface. 4.1 General Framework We have modeled the problem of classification-rule-learning as a search <ref> [Kor90] </ref> process in the state space of different models. Figure 5 shows the ER diagram for learning decision trees. Such a model allows the user to monitor the quality and impact of decisions made by the learning procedure.
Reference: [KSA94] <author> V. Kumar, S. Shekhar, and M. B. Amin. </author> <title> A scalable parallel formulation of backpropagation algorithm for hypercubes and related architectures. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(10) </volume> <pages> 1073-1090, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Window systems may need to use hierarchical management of such large datasets by viewing visual representations as indices rather than as collections of actual objects. We would like to explore the parallel implementation <ref> [KGGK94, KSA94] </ref> of search algorithms, which is more complex than sequential algorithms. We will use the VQLBCI framework as the front-end interface and will provide users with different ways to run data mining algorithms: in parallel or distributed over available computing resources.
Reference: [Lan96] <author> P. Langley. </author> <title> Elements of Machine Learning. </title> <address> Morgan-Kaufman, San Francisco, CA, </address> <year> 1996. </year>
Reference-contexts: The process is often very slow, particularly when databases are large. The success of the data mining process is critically dependent upon the availability of user insights and biases [Mit77], even though the process may use unsupervised learning algorithms <ref> [Lan96] </ref>. User insights and biases includes abstract preferences for attributes and attribute sets that reflect the user's interests and purposes. It could also include more detailed guidance in terms of preferences on the partial patterns being selected for further growth and exploration during the mining process.
Reference: [LHLQ95] <author> H.-Y. Lee, H.-L.Ong, and L.-H. Quek. </author> <title> Exploiting visualization in knowledge discovery. </title> <booktitle> In Proc. of the First Int'l Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pages 198-203, </pages> <address> Montreal, Quebec, </address> <year> 1995. </year>
Reference-contexts: The data segements appear as breaks in a graph to indicate segment boundaries. MVV [MTS91] uses bar charts and slider bars to locate clusters in multidimensional space, allowing the display of multiple views of a given dataset. The nested histograms and the group bars in WinViz <ref> [LHLQ95] </ref> and Netmap [Dav93] are line-based visualization tools that use a circle as the basic graphical device. Its circumference is divided into several groups, one for each attribute of interest. Individuals are represented by nodes within the group. <p> We believe there is a need to use semantically rich data models, e.g. the entity relationship model [EN94], to model the concepts. Some initial efforts in this direction include <ref> [ABN92, KKS94, LHLQ95] </ref>. Next, we need the ability to visualize database concepts like schemas, queries, indices, etc. in addition to the data. <p> Each primitive object has a location with respect to the enclosing visual representation. Visual representations include user-defined and system-defined diagrams and pictures to visualize the inputs, products and process of data mining. Different diagrams already proposed in the literature <ref> [GSSW92, LHLQ95, KKS94, KK94, RAEM94] </ref> can be thought of as concrete instances of visual representation for data mining. We believe that newer visual representations will be forthcoming based on the needs of the application domains and data mining life-cycles in the future.
Reference: [Mac86] <author> J. Mackinlay. </author> <title> Automating the design of graphical presentations of relational information. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 5(2) </volume> <pages> 110-141, </pages> <month> April </month> <year> 1986. </year>
Reference-contexts: Given the roots of visualization in graphics, this is very natural. While often adequate for representing information about physical phenomena such as convective and laminar flows, vortex formation, etc., this approach may not be appropriate for repre 4 senting the complex relationships found in business data <ref> [Mac86] </ref>. The VisDB [KK94] system demonstrates one example of conceptual data modeling of complex business data. The VisDB system uses each pixel of the screen to visualize the data items resulting from a query on whole data. The resulting data items are sorted according to their relevance to the query. <p> Given an association between a query and a visual representation, the results of traditional queries can be converted to visual representations. Default procedures can be provided to convert a database object (e.g. a relational table) to a set of system-defined diagrams along the lines of <ref> [Mac86] </ref>. The conversion procedures are not natural in traditional ERDs; however, we will take the liberty of viewing these procedures as composite attributes in ERDs. These composite attributes are not too far from modern databases, since they support procedure-valued fields and triggers.
Reference: [MCPS93] <author> C. J. Matheus, P. K. Chan, and G. Piatetsky-Shapiro. </author> <title> Systems for knowledge discovery in databases. </title> <journal> IEEE Transactions on Knowledge and Data Engg., </journal> <volume> 5(6) </volume> <pages> 903-913, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: first briefly survey techniques in data mining and visualization and then evaluate the potential of visualization techniques for enhancing the effectiveness of data mining. 3 2.1 Data Mining: A Brief Survey Data mining is an active research area with the promise of high payoffs in many business and scientific domains <ref> [FPSM91, MCPS93, AIS93, AP95] </ref>. Industry, government, and scientific communities are being inundated with huge volumes of data that is routinely stored in online databases. Analyzing this data and extracting meaningful patterns from it is almost impossible without computer assistance to the human analyst. <p> Much of the data-mining research to date has focused on approaches to applying traditional machine learning and discovery methods to data stored in relational databases [FPSM91]. Recent years have seen more of a "systems" approach to the process <ref> [MCPS93, AP95, HS95] </ref>, where knowledge discovery and machine-learning techniques are components of an entire data mining system. Knowledge extracted during the mining process can be of various kinds, depending on the nature of the knowledge, its complexity, its uses, etc. <p> In recent years substantial advances have been made in developing data-mining techniques that provide high efficiency in addition to improved accuracy. Since a detailed survey of data mining research is beyond the scope of the present paper, we point readers to the following references <ref> [MCPS93, AIS93, AP95] </ref>.
Reference: [Mit77] <author> T. M. Mitchell. </author> <title> Version spaces: A candidate elimination approach to rule learning. </title> <booktitle> In Proc. of IJCAI 77, </booktitle> <year> 1977. </year>
Reference-contexts: Common patterns of interest include classification [Qui86], associations [AS94, HS95], clustering [Fis95], and sequential patterns [MTV95]. The process is often very slow, particularly when databases are large. The success of the data mining process is critically dependent upon the availability of user insights and biases <ref> [Mit77] </ref>, even though the process may use unsupervised learning algorithms [Lan96]. User insights and biases includes abstract preferences for attributes and attribute sets that reflect the user's interests and purposes.
Reference: [MTS91] <author> T. Mihalisin, J. Timlim, and J. Schwegler. </author> <title> Visualization and analysis of multi-variate data: A technique for all fields. </title> <booktitle> In Proc. of Visualization 91, </booktitle> <year> 1991. </year>
Reference-contexts: Visualization Needs of Data Mining have been explored by few researchers. IMACS [BST + 94] uses conventional graphs and plots as an interface for the analyst to segment data with mouse clicks. The data segements appear as breaks in a graph to indicate segment boundaries. MVV <ref> [MTS91] </ref> uses bar charts and slider bars to locate clusters in multidimensional space, allowing the display of multiple views of a given dataset. The nested histograms and the group bars in WinViz [LHLQ95] and Netmap [Dav93] are line-based visualization tools that use a circle as the basic graphical device.
Reference: [MTV95] <author> H. Mannila, H. Toivonen, and A. I. Verkamo. </author> <title> Discovering frequent episodes in sequences. </title> <booktitle> In Proc. of the First Int'l Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pages 210-215, </pages> <address> Montreal, Quebec, </address> <year> 1995. </year>
Reference-contexts: Common patterns of interest include classification [Qui86], associations [AS94, HS95], clustering [Fis95], and sequential patterns <ref> [MTV95] </ref>. The process is often very slow, particularly when databases are large. The success of the data mining process is critically dependent upon the availability of user insights and biases [Mit77], even though the process may use unsupervised learning algorithms [Lan96].
Reference: [NS90] <editor> G. M. Nielson and B. Shriver, editors. </editor> <booktitle> Visualization in Scientific Computing. </booktitle> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1990. </year>
Reference-contexts: Any visualization system focuses on the following four issues: (i) the conceptual model of visualization data, (ii) the control interface, (iii) the control methods, and (iv) the visualization representation. A detailed survey of these is beyond the scope of this paper and can be found in <ref> [NS90, REE + 94, com94] </ref>. In the following, we provide a brief overview of each of these. Conceptual Data Model: Almost all work in visualization has used some variation of a model where (point) datum is represented as a vector with values for each component/dimension.
Reference: [Qui86] <author> J. Ross Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: 1 Introduction Data mining [SAD + 93] is the efficient and possibly unsupervised discovery of interesting, useful and previously unknown patterns in a data warehouse, which is a historical database designed to facilitate analysis and knowledge discovery. Common patterns of interest include classification <ref> [Qui86] </ref>, associations [AS94, HS95], clustering [Fis95], and sequential patterns [MTV95]. The process is often very slow, particularly when databases are large. The success of the data mining process is critically dependent upon the availability of user insights and biases [Mit77], even though the process may use unsupervised learning algorithms [Lan96]. <p> This paper proposes a loose-coupling of existing conceptual data models and visual interfaces as a tool for supporting visual data mining. It illustrates the tool in the context of the problem of learning decision trees for classification problems, e.g., visualizing the progress of ID3-like <ref> [Qui86] </ref> algorithms. It presents and evaluates two new algorithms designed interactively via the tool. The rest of the paper is organized as follows. In section 2 we provide brief surveys of visualization and data mining and summarize our contributions. <p> The data-entropy-calculation function provides a mechanism for calculating the entropy of training cases with respect to classes. Some examples of the entropy-calculation 16 function are based on information theory <ref> [Qui86] </ref>, and other user-provided functions such as the Gini function [WK91]. Post-processing modifies the final model candidate generated. It usually involves removing the model atoms from the model candidate. One example of post-processing is C4:5 error-based pruning on a decision tree generated from the C4:5 algorithm.
Reference: [Qui93] <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: The problem space of this search process consists of Model Candidates, a Model Candidate Generator, and Model Constraints. Many existing classification-learning algorithms like C4:5 <ref> [Qui93] </ref> and CDP [AIS93] fit nicely within this search framework. New learning algorithms that fit users' requirements can be developed by defining the components of the problem 12 based interface for the manipulation of search parameters space. <p> Play overcast 83 78 false Play overcast 64 65 true Play overcast 81 75 false Play rain 71 80 true Don't Play rain 65 70 true Don't Play rain 75 80 false Play rain 68 80 false Play rain 70 96 false Play Table 1: A small training data set <ref> [Qui93] </ref> 14 model candidate by selecting one model atom to expand from the expandable leaf model atoms. The model candidate generator first checks to see whether the current model candidate satisfies the acceptability constraints. <p> It also allows the definition of new visual representations for domain-specific diagrams and pictures. We provide a generic search-based interface with VQLBCI to visualize the quality and nature of decisions made by decision tree learning algorithms such as C4:5 <ref> [Qui93] </ref>. We have developed two new algorithms, namely BF and CDP+, and evaluated their performance with 10 datasets from the literature. BF uses best-first ordering to expand the frontier nodes of the decision trees instead of the conventional depth-first or breadth-first criteria.
Reference: [RAEM94] <author> W. Ribarsky, E. Ayers, J. Eble, and S. Mukherjea. Glyphmaker: </author> <title> Creating customized visualizations of complex data. </title> <journal> IEEE Computer, </journal> <volume> 27(7) </volume> <pages> 57-64, </pages> <month> July </month> <year> 1994. </year> <month> 26 </month>
Reference-contexts: The subset is determined by the position of the world's origin relative to its parent. The user can grab each world using a DataGlove and move it throughout the space defined by its parent, thereby interactively exploring the data space. Glyphmaker is a tool for data visualization/analysis <ref> [RAEM94] </ref> that allows users to build customized representations of multivariate data easily and also provides interactive tools to explore the patterns in and relations between the data. <p> Each primitive object has a location with respect to the enclosing visual representation. Visual representations include user-defined and system-defined diagrams and pictures to visualize the inputs, products and process of data mining. Different diagrams already proposed in the literature <ref> [GSSW92, LHLQ95, KKS94, KK94, RAEM94] </ref> can be thought of as concrete instances of visual representation for data mining. We believe that newer visual representations will be forthcoming based on the needs of the application domains and data mining life-cycles in the future.
Reference: [REE + 94] <author> L. Rosenblum, R.A. Earnshaw, J. Encarnacao, H. Hagen, A. Kaufman, S. Klimenko, G. Nielson, F. Post, and D. Thalmann, </author> <title> editors. Scientific Visualization. </title> <publisher> Academic Press Inc., </publisher> <year> 1994. </year>
Reference-contexts: any of these data-mining techniques can be used as the engine in the "model derivation algorithm" component of our system. 2.2 Visualization Techniques: A Brief Survey Visualization has been an active research area for some time now, and it has shown its power in helping us better understand scientific phenomena <ref> [REE + 94, Kau94a] </ref>. Any visualization system focuses on the following four issues: (i) the conceptual model of visualization data, (ii) the control interface, (iii) the control methods, and (iv) the visualization representation. <p> Any visualization system focuses on the following four issues: (i) the conceptual model of visualization data, (ii) the control interface, (iii) the control methods, and (iv) the visualization representation. A detailed survey of these is beyond the scope of this paper and can be found in <ref> [NS90, REE + 94, com94] </ref>. In the following, we provide a brief overview of each of these. Conceptual Data Model: Almost all work in visualization has used some variation of a model where (point) datum is represented as a vector with values for each component/dimension.
Reference: [SAD + 93] <author> M. Stonebraker, R. Agrawal, U. Dayal, E. J. Neuhold, and A. Reuter. </author> <title> Dbms research at a crossroads: The vienna update. </title> <booktitle> In Proc. of the 19th VLDB Conference, </booktitle> <pages> pages 688-692, </pages> <address> Dublin, Ireland, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Data mining <ref> [SAD + 93] </ref> is the efficient and possibly unsupervised discovery of interesting, useful and previously unknown patterns in a data warehouse, which is a historical database designed to facilitate analysis and knowledge discovery. Common patterns of interest include classification [Qui86], associations [AS94, HS95], clustering [Fis95], and sequential patterns [MTV95].
Reference: [SHKC93] <author> S. Shekhar, B. Hamidzadeh, A. Kohli, and M. Coyle. </author> <title> Learning transformation rules for semantic query optimization: A data-driven approach. </title> <journal> IEEE Transactions on Knowledge and Data Engg., </journal> <volume> 5(6) </volume> <pages> 950-964, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: We would also like to explore whether a search framework can help in developing new insights and algorithms for discovering other patterns such as association rules, clusterings and sequences. Another area of interest is in exploring specific data mining application domains such as database integration [GSR96], semantic query optimization <ref> [SHKC93] </ref> and generalization [AS92]. 7 Acknowledgments We would like to thank Dr. Arun Swami from Silicon Graphics Inc. and Dr. Bamshad Mobasher for their valuable contributions in the various stages of the project.
Reference: [WK91] <author> S. M. Weiss and C. A. </author> <title> Kulikowski. Computer Systems That Learn. </title> <address> Morgan-Kaufman, San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: The data-entropy-calculation function provides a mechanism for calculating the entropy of training cases with respect to classes. Some examples of the entropy-calculation 16 function are based on information theory [Qui86], and other user-provided functions such as the Gini function <ref> [WK91] </ref>. Post-processing modifies the final model candidate generated. It usually involves removing the model atoms from the model candidate. One example of post-processing is C4:5 error-based pruning on a decision tree generated from the C4:5 algorithm.
References-found: 41

