URL: ftp://ftp.csd.abdn.ac.uk/pub/apreece/ECAI96/Zlatareva.ps
Refering-URL: http://www.csd.abdn.ac.uk/~apreece/ECAI96/workshop.html
Root-URL: 
Title: Explaining Anomalies as a Basis for Knowledge Base Refinement  
Author: Neli P. Zlatareva 
Address: New Britain, CT 06050  
Affiliation: Department of Computer Science Central Connecticut State University  
Abstract: Explanations play a key role in operationalization-based anomaly detection techniques. In this paper we show that their role is not limited to anomaly detection; they can also be used for guiding automated knowledge base refinement. We introduce a refinement procedure which takes: (i) a small number of refinement rules (rather than test cases), and (ii) explanations constructed in an attempt to reveal the cause (or causes) for inconsistencies detected during the verification process, and returns rule revisions aiming to recover the consistency of the KB-theory. Inconsistencies caused by more than one anomaly are handled at the same time, which improves the efficiency of the refinement process. 
Abstract-found: 1
Intro-found: 1
Reference: [DeJong and Mooney, 1986] <author> DeJong, G. and Mooney, R. </author> <year> (1986). </year> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2) </volume> <pages> 145-176. </pages>
Reference-contexts: 1 Introduction We consider knowledge base (KB) refinement in the context of Knowledge-Based System (KBS) validation. The greatest advantage of this approach is that we can use the outcome of other validation activities to detect anomalies in the KB-theory. Similar to some machine learning techniques <ref> [Wilkins, 1988, Ourston and Mooney, 1994, DeJong and Mooney, 1986] </ref>, the one presented here uses explanations of detected anomalies in its attempt to reveal the culprit (or culprits) for each of them.
Reference: [Mesenguer, 1993] <author> Mesenguer, P. </author> <year> (1993). </year> <title> Expert system validation through knowledge base refinement. </title> <booktitle> In Proc. 13-th International Joint Conferences on Artificial Intelligence (IJCAI'93), </booktitle> <pages> pages 477-482. </pages> <publisher> Morgan Kaufmann Publ.,Inc. </publisher>
Reference-contexts: However, contrary to the situation in explanation-based learning, where explanations are constructed for each of the successfully solved test cases, our procedure generates and evaluates only explanations related to detected anomalies. Compared to other refinement methods designed to support KBS validation <ref> [Mesenguer, 1993, Zlatareva, 1994, Palmer and Craw, 1995] </ref>, the one presented here is different in that it does not require test cases. Instead, the refinement procedure makes use of a small number of refinement rules for guiding the refine ment process. The paper is organized as follows.
Reference: [Ourston and Mooney, 1994] <author> Ourston, D. and Mooney, R. </author> <year> (1994). </year> <title> Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66 </volume> <pages> 273-309. </pages>
Reference-contexts: 1 Introduction We consider knowledge base (KB) refinement in the context of Knowledge-Based System (KBS) validation. The greatest advantage of this approach is that we can use the outcome of other validation activities to detect anomalies in the KB-theory. Similar to some machine learning techniques <ref> [Wilkins, 1988, Ourston and Mooney, 1994, DeJong and Mooney, 1986] </ref>, the one presented here uses explanations of detected anomalies in its attempt to reveal the culprit (or culprits) for each of them. <p> Inductive (or empirical) learning [Quinlan, 1983] can be used if a significant number of real world test cases is available. For example, the EITHER system required 80 test cases to improve the accuracy of the knowledge base by 35 percentage point <ref> [Ourston and Mooney, 1994] </ref>. Such an extensive number of test cases is typically not available during KBS development. Explanation-based learning (EBL) does not require an extensive number of test cases, but it assumes that the KB-theory is correct.
Reference: [Palmer and Craw, 1995] <author> Palmer, D. and Craw, S. </author> <year> (1995). </year> <title> Utilising explanation to assist the refinement of knowledge-based systems. </title> <booktitle> In Proc. EUROVAV-95, </booktitle> <pages> pages 201-211. </pages>
Reference-contexts: However, contrary to the situation in explanation-based learning, where explanations are constructed for each of the successfully solved test cases, our procedure generates and evaluates only explanations related to detected anomalies. Compared to other refinement methods designed to support KBS validation <ref> [Mesenguer, 1993, Zlatareva, 1994, Palmer and Craw, 1995] </ref>, the one presented here is different in that it does not require test cases. Instead, the refinement procedure makes use of a small number of refinement rules for guiding the refine ment process. The paper is organized as follows. <p> To fix it, the apprenticeship learning program builds modifications of the KB-theory that allow a successful explanation of the presented test case to be constructed. A similar approach to KB refinement is implemented in the KRUST system <ref> [Palmer and Craw, 1995] </ref>, which supports validation of rule-based KBSs. In both frameworks, the availability of test cases is crucial for the success of the refinement process. As it is well known, test cases are rarely available during KBS development, which limits the applicability of these methods.
Reference: [Pazzani and Brunk, 1991] <author> Pazzani, M. and Brunk, C. </author> <year> (1991). </year> <title> Detecting and correcting rule-based expert systems: an integration of empirical and explanation-based learning. </title> <journal> Knowledge Acquisition, </journal> <volume> 3 </volume> <pages> 157-173. </pages>
Reference-contexts: R 11 : honors (Student) ! eligible for def erment (Student). R 12 : :eligible for def erment (Student) ! :no payment due (Student). To simplify the representation, assume the follow ing abbreviations: 2 The original version of this example was introduced in <ref> [Pazzani and Brunk, 1991] </ref>; here we use a modified version of it.
Reference: [Quinlan, 1983] <author> Quinlan, J. </author> <year> (1983). </year> <title> Learning efficient classification procedures and their application to chess and games. </title> <booktitle> In Machine Learning - An Artificial Intelligence Approach. </booktitle> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: Inductive (or empirical) learning <ref> [Quinlan, 1983] </ref> can be used if a significant number of real world test cases is available. For example, the EITHER system required 80 test cases to improve the accuracy of the knowledge base by 35 percentage point [Ourston and Mooney, 1994].
Reference: [Wilkins, 1988] <author> Wilkins, D. </author> <year> (1988). </year> <title> Knowledge base refinement using apprenticeship learning techniques. </title> <booktitle> In Proc. AAAI'88, </booktitle> <pages> pages 646-651. </pages>
Reference-contexts: 1 Introduction We consider knowledge base (KB) refinement in the context of Knowledge-Based System (KBS) validation. The greatest advantage of this approach is that we can use the outcome of other validation activities to detect anomalies in the KB-theory. Similar to some machine learning techniques <ref> [Wilkins, 1988, Ourston and Mooney, 1994, DeJong and Mooney, 1986] </ref>, the one presented here uses explanations of detected anomalies in its attempt to reveal the culprit (or culprits) for each of them. <p> But it can only take place if the following two conditions are met: * Real-world test cases with known solutions are available during KBS development. * The efficiency of knowledge is more important that its accessibility. Similar to EBL, apprenticeship learning <ref> [Wilkins, 1988] </ref> involves building explanations and using them as a component of learning. The difference between them is that in apprenticeship learning, learning occurs when the KB-theory is unable to correctly explain the presented test case.
Reference: [Zlatareva, 1994] <author> Zlatareva, N. </author> <year> (1994). </year> <title> A framework for verification, validation, and refinement of knowledge bases: The VVR system. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 9(8) </volume> <pages> 703-738. </pages>
Reference-contexts: However, contrary to the situation in explanation-based learning, where explanations are constructed for each of the successfully solved test cases, our procedure generates and evaluates only explanations related to detected anomalies. Compared to other refinement methods designed to support KBS validation <ref> [Mesenguer, 1993, Zlatareva, 1994, Palmer and Craw, 1995] </ref>, the one presented here is different in that it does not require test cases. Instead, the refinement procedure makes use of a small number of refinement rules for guiding the refine ment process. The paper is organized as follows. <p> For anomalies caused by the incompleteness of the KB-theory, only partial explanations can be constructed. To complete these explanations, the refinement procedure performs a search for unusable components and incomplete specifications, provided that test cases are available. We have discussed this aspect of KB refinement in <ref> [Zlatareva, 1994] </ref>. Thus we shall assume that the KB-theory is complete, and all of the detected errors are caused by data or rules inconsistencies.
Reference: [Zlatareva and Preece, 1994] <author> Zlatareva, N. and Preece, A. </author> <year> (1994). </year> <title> An effective logical framework for knowledge-based systems verification. </title> <journal> International Journal of Expert Systems: Research and Applications, </journal> <volume> 7. </volume>
Reference-contexts: The ultimate goal of the refinement process is to free the KB-theory from all of the errors detected during its validation. Next, we discuss the refinement process in its connection with other validation activities. We assume that the reader is familiar with operationalization-based verification techniques. The DIVER tool <ref> [Zlatareva and Preece, 1994] </ref>, which implements such a technique, is used to detect anomalies in the KB-theory. Anomaly detection Using DIVER, the KB-theory is first tested for potential structural anomalies.
References-found: 9

