URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-321.ps.Z
Refering-URL: http://www.cs.gatech.edu/classes/cs8113g_97_fall/schedule.html
Root-URL: 
Email: picard@media.mit.edu,  
Author: R. W. Picard 
Web: http://www.media.mit.edu/~picard/  
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: Affective Computing  MIT Media Laboratory; Perceptual Computing;  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 321 Revised November 26, 1995; Submitted for publication. Abstract Recent neurological studies indicate that the role of emotion in human cognition is essential; emotions are not a luxury. Instead, emotions play a critical role in rational decision-making, in perception, in human interaction, and in human intelligence. These facts, combined with abilities computers are acquiring in expressing and recognizing affect, open new areas for research. This paper defines key issues in "affective computing," computing that relates to, arises from, or deliberately influences emotions. New models are suggested for computer recognition of human emotion, and both theoretical and practical applications are described for learning, human-computer interaction, perceptual information retrieval, creative arts and entertainment, human health, and machine intelligence. Significant potential advances in emotion and cognition theory hinge on the development of affective computing, especially in the form of wearable computers. This paper establishes challenges and fu - ture directions for this emerging field. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. S. Lazarus, </author> <title> Emotion & Adaptation. </title> <address> New York, NY: </address> <publisher> Oxford University Press, </publisher> <year> 1991. </year>
Reference-contexts: levers of our lives, whether it is love that 1 The making of small wounds in the ridge of the limbic system known as the cingulate gyrus, a surgical procedure to aid severely depressed patients. 2 For a list of twelve open questions in the theory of emotion, see Lazarus <ref> [1] </ref>. 1 leads to forgiveness, or curiosity that drives scientific inquiry. As humans, our behavior is greatly influenced by the "songs" in our hearts. <p> fact that we are not all experts at reading faces, and comedians and actors can excel at feigning emotions, it is claimed that the attentive observer is always able to recognize a false smile [21]. 7 This is consistent with the findings of 7 This view is debated, e.g., by <ref> [1] </ref> who claims that all phenomena that change with emotion also change for other reasons, Duchenne over a century ago: The muscle that produces this depression on the lower eyelid does not obey the will; it is only brought into play by a genuine feeling, by an agreeable emotion. <p> Although inducement of emotions may be deliberate, it seems we, the receiver, often enjoy its effects. Certainly, we enjoy selecting a stimulus such as music that will affect our mood in 11 A discussion of numerous affect-memory experiments, as well as some controversy surrounding them, appears in <ref> [1] </ref>. 8 a particular way. We tend to believe that we are also free to choose our response to the stimulus.
Reference: [2] <author> R. E. Cytowic, </author> <title> The Man Who Tasted Shapes. </title> <address> New York, </address> <publisher> NY: </publisher> <editor> G. P. </editor> <publisher> Putnam's Sons, </publisher> <year> 1993. </year>
Reference-contexts: Let's consider briefly these two activities, beginning with some evidence regarding perception, as illustrated in the next scenario. 1.2 Limbic perception "Oh, dear," he said, slurping a spoonful, "there are not enough points on the chicken." - Michael Watson <ref> [2] </ref>. Synesthetes may feel shapes on their palms as they taste, or see colors as they hear music. Synesthetic experiences behave as if the senses are cross-wired, as if there are no walls between what is seen, felt, touched, smelled, and tasted.
Reference: [3] <author> R. E. Cytowic, </author> <title> Synesthesia : a union of the senses. </title> <address> New York: </address> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Synesthetic experiences behave as if the senses are cross-wired, as if there are no walls between what is seen, felt, touched, smelled, and tasted. How- ever, the neurological explanation for this heightened perceptual phenomenon is not "crossed-wires." The neurologist Cytowic has studied the neurophysiology of synesthetic experience <ref> [3] </ref>. Because the cortex is typically regarded as the home of sensory perception, it is expected to show increased activity during synesthetic experiences, where a person experiences external and involuntary sensations somewhat like a cross-wiring of the senses for example certain sounds may elicit seeing strong colors.
Reference: [4] <author> C. E. Izard, </author> <title> "Four systems for emotion activation: </title> <journal> Cognitive and noncognitive processes," Psychological Review, </journal> <volume> vol. 100, no. 1, </volume> <pages> pp. 68-90, </pages> <year> 1993. </year>
Reference-contexts: The limbic system is the seat of emotion, memory, and attention. Its activity during synesthesia indicates that the limbic system plays a significant role in perception. In a recent treatise on emotion theory, Izard <ref> [4] </ref> describes emotion as both a motivating and guiding force in perception and attention. One does not need a blood-flow scan or theory of emotion, however, to recognize that emotion greatly influences perception. <p> Consequently, some prominent scientists have argued that cognitive appraisal is a necessary precondition for emotion. Although it is hard to "prove" that any human experience exists independent of cognitive events, there seems to be ample evidence that emotions can occur without prior cognitive appraisal <ref> [4] </ref>, [7], [28]. In particular, the recent neurological evidence seems to support that emotions can "hijack" the cognitive centers of the brain [12]. Additionally, noncognitive biochemical events can strongly influence mood [4]. <p> exists independent of cognitive events, there seems to be ample evidence that emotions can occur without prior cognitive appraisal <ref> [4] </ref>, [7], [28]. In particular, the recent neurological evidence seems to support that emotions can "hijack" the cognitive centers of the brain [12]. Additionally, noncognitive biochemical events can strongly influence mood [4]. Only recently have scientists begun to unlock the secrets of hormonal chemistry, the role of neurotransmitters in depression, and other significant noncognitive contributors to human emotion. It seems safe to conclude that both cognitive and physiological events can contribute to emotion, and vice-versa. <p> For example, Laird [32] divides people into "cueing" categories based on whether or not posturing themselves in a particular expression induces the corresponding emotional experience. Izard overviews some of the evidence for and against various sensorimotor claims <ref> [4] </ref>. Whether or not such sensorimotor inputs can induce emotion, they appear to at least be effective in maintaining and expressing emotion. Posture is correlated with expressions of self-esteem [4], [18]. <p> Izard overviews some of the evidence for and against various sensorimotor claims <ref> [4] </ref>. Whether or not such sensorimotor inputs can induce emotion, they appear to at least be effective in maintaining and expressing emotion. Posture is correlated with expressions of self-esteem [4], [18]. A successful school of acting (after Michael Chekhov, student of Stanislavsky) is based on imagining emotive scenarios, and adjusting ones body position in accord with that emotion [36], [37]. Actors who excel at this method strengthen their association with their character's emotional state.
Reference: [5] <author> O. Kroeger and J. M. Thuesen, </author> <title> Type Talk at Work. </title> <address> New York: </address> <publisher> Delacorte Press, Bantam Doubleday Dell Publishing Group, Inc., </publisher> <year> 1992. </year>
Reference-contexts: In fact, the Myers-Briggs type indicator reveals a gender bias along this axis, indicating that two-thirds of men tend to lie closer to the "thinking" side and two-thirds of women tend to lie closer to the "feeling" side <ref> [5] </ref>. This bias sometimes appears in male-female stereotypes, and many books have appeared on its implications for human interaction. Although I do not wish to pursue the male-female distinctions further here, it is worth noting that such differences might also extend to human-computer interaction.
Reference: [6] <author> R. E. Cytowic, </author> <title> The Neurological Side of Neuropsychology. </title> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1995. </year> <note> To Appear. </note>
Reference-contexts: All sensory inputs, external and visceral, must pass through the emotional limbic brain before being redistributed to the cortex for analysis, after which they return to the limbic system for a determination of whether the highly-transformed, multi-sensory input is salient or not. <ref> [6] </ref>. The limbic brain is the "home base" of emotion, but it is not the only part of the brain engaged in the experience of emotion. Extensive research by Damasio and his colleagues has identified several non-limbic regions which affect emotion. <p> Cytowic, talking about how the limbic system efficiently shares components such as attention, memory, and emotion, notes: Its ability to determine valence and salience yields a more flexible and intelligent creature, one whose behavior is unpredictable and even creative. <ref> [6] </ref> Today, with the ever-increasing information available to machines (and computer software agents), it is more important than ever for a computer to be given the ability to determine valence and salience. It is also commonly agreed that creativity and flexibility are necessary components of intelligence [60].
Reference: [7] <author> A. R. Damasio, </author> <title> Descartes' Error: Emotion, Reason, and the Human Brain. </title> <address> New York, NY: </address> <publisher> Gosset/Putnam Press, </publisher> <year> 1994. </year>
Reference-contexts: Extensive research by Damasio and his colleagues has identified several non-limbic regions which affect emotion. These findings have been recently summarized in the provocative book <ref> [7] </ref>. But there is a much bigger surprise in his findings. 1.3.2 Too little emotion impairs decision-making We all know that too much emotion can wreak havoc on reasoning, but now there is evidence that too little emotion can also wreak havoc. <p> This evidence requires a shift from the usual paradigm of how people separate emotions and rationality. I refer the reader to the careful arguments and references collected by Damasio <ref> [7] </ref> for the justification such a far-reaching paradigm-shift demands, and here provide but a brief explanation of the findings to support the need for affective computers. Damasio's patients have frontal-lobe disorders, affecting a part of the cortex that communicates with the limbic system. <p> Otherwise, the patients appear to be intelligent, and unusually rational. However, these same patients suffer from an impaired ability to make decisions. Years of studies with frontal-lobe patients indicate that they spend inordinate amounts of time trying to make decisions that those without frontal-lobe damage can make quite easily <ref> [7] </ref>. For example, the mere task of choosing a date to schedule an appointment can lead these patients through abnormally long chains of decisions, perhaps without ever reaching a decision, until a date is imposed upon them by someone who is tired of waiting for their response. <p> Damasio's findings provide neurological support that there is no "pure reason" in the healthy human brain emotions are vital for healthy rational human thinking and behavior <ref> [7] </ref>. His patients are abnormally rational, not too unlike the rule-based programs that comprise today's models of decision-making. It must be emphasized at this point that by no means should anyone conclude that logic or reason are irrelevant; they are as essential as the "laws" described earlier. <p> Treating the body and mind separately can lead to errors, as captured by the title of <ref> [7] </ref>. <p> Consequently, some prominent scientists have argued that cognitive appraisal is a necessary precondition for emotion. Although it is hard to "prove" that any human experience exists independent of cognitive events, there seems to be ample evidence that emotions can occur without prior cognitive appraisal [4], <ref> [7] </ref>, [28]. In particular, the recent neurological evidence seems to support that emotions can "hijack" the cognitive centers of the brain [12]. Additionally, noncognitive biochemical events can strongly influence mood [4]. <p> A helpful distinction for sorting the "noncognitively- generated" and "cognitively-generated" emotions is made by Damasio <ref> [7] </ref> who distinguishes between "primary" and "secondary" emotions. 10 Damasio's idea, which is also supported in much of the emotion theory literature, is that there are certain features of stimuli in the world that we respond to emotionally first, and which activate a corresponding set of emotions (and cognitive state) secondarily.
Reference: [8] <author> P. N. Johnson-Laird and E. Shafir, </author> <title> "The interaction be-tween reasoning and decision making: an introduction," </title> <journal> Cognition, </journal> <volume> vol. 49, </volume> <pages> pp. 1-9, </pages> <year> 1993. </year>
Reference-contexts: Damasio's findings support independent scientific arguments for the essential role of emotion. Johnson-Laird and Shafir have recently reminded the cognition community of the inability of logic to determine which of an infinite number of possible conclusions are sensible to draw, given a set of premises <ref> [8] </ref>. Con- sider: how do you decide which path to take given some evidence? There is not time to consider every possible logical constraint and associated path.
Reference: [9] <author> A. M. </author> <title> Turing, </title> <journal> "Computing machinery and intelligence," Mind, </journal> <volume> vol. LIX, </volume> <pages> pp. 433-460, </pages> <month> October </month> <year> 1950. </year>
Reference-contexts: Although the test cannot prove that a machine does or does not think, it is a terrific exercise in thinking about thinking. 5 With slight modifications from the original proposed by Turing <ref> [9] </ref>. 3 The Turing test is considered a test of whether or not a ma-chine can think in the truest sense of duplicating mental activity. Since mental activity involves a close coupling between cortical and limbic activity, a test of true thinking must involve a test of emotion. <p> Objection to development of "emotional computers," based on fear of the consequences, parallels the "Heads in the Sand" objection, one of nine objections playfully proposed and refuted by Turing in <ref> [9] </ref> to the question "Can machines think?" But fear of the consequences is to be balanced against the practical benefits that should appear, given the importance of the limbic (emotional brain) role in thinking.
Reference: [10] <editor> Aristotle, </editor> <booktitle> The Rhetoric of Aristotle. </booktitle> <address> New York, NY: Appleton-Century-Crofts, </address> <year> 1960. </year> <title> An expanded translation with supplementary examples for students of composition and public speaking, by L. </title> <type> Cooper. </type>
Reference-contexts: Although the Turing test is usually performed with text-only communication, so that sensory expression, viz., voice intonation and facial expression, do not play a role, emotions are still communicated through the written word. This power and importance of influencing emotion through language was a primary tenet of Aristotle's Rhetoric <ref> [10] </ref>. A machine, even limited to text communication, will be a more effective communicator if given the ability to perceive and express emotions. Of course the crux of the Turing test is what comprises the questions. <p> Aristotle devoted much of his teachings on rhetoric to instructing speakers how to arouse the right emotions in their audience <ref> [10] </ref>. Although inducement of emotions may be deliberate, it seems we, the receiver, often enjoy its effects.
Reference: [11] <author> D. R. Hofstadter and D. C. Dennett, </author> <title> The Mind's I. </title> <publisher> Bantam Books, </publisher> <year> 1981. </year>
Reference-contexts: Of course the crux of the Turing test is what comprises the questions. Hofstadter has suggested that "humor, especially emotion," would comprise the acid test of intelligence for a "thinking machine" <ref> [11] </ref>. But the argument for emotion as necessary for intelligence goes far beyond its interplay with humor. Goleman has recently argued that emotion is a hallmark of human intelligence [12], and that "emotional intelligence" can be more important for predicting success in life than traditional IQ tests.
Reference: [12] <author> D. Goleman, </author> <title> Emotional Intelligence. </title> <publisher> Bantam Books, </publisher> <year> 1995. </year>
Reference-contexts: Hofstadter has suggested that "humor, especially emotion," would comprise the acid test of intelligence for a "thinking machine" [11]. But the argument for emotion as necessary for intelligence goes far beyond its interplay with humor. Goleman has recently argued that emotion is a hallmark of human intelligence <ref> [12] </ref>, and that "emotional intelligence" can be more important for predicting success in life than traditional IQ tests. <p> In particular, the recent neurological evidence seems to support that emotions can "hijack" the cognitive centers of the brain <ref> [12] </ref>. Additionally, noncognitive biochemical events can strongly influence mood [4]. Only recently have scientists begun to unlock the secrets of hormonal chemistry, the role of neurotransmitters in depression, and other significant noncognitive contributors to human emotion. <p> Hence the system becomes a test-bed for new strategies or games involving affective communication. More importantly, perhaps, such a testbed provides a safe and controllable environment for exploring the nature and development of emotional intelligence, which, according to Goleman, can be learned <ref> [12] </ref>. Another important example of coupling synthesis and analysis is in the case of a speaking-impaired human relying on a speech synthesizer. Such people are usually limited to one inflection-less digital voice. Control over affect in synthetic speech is particularly important for these people [56]. <p> A later episode focused on the maturity process needed for Data to deal with the replaced emotion chip. The process parallels what we expect with the development of emotional intelligence in humans <ref> [12] </ref>. One might argue that computers should not be given the ability to kill. But it is too late for this, as anyone who has flown in a commercial airplane acknowledges.
Reference: [13] <author> C. I. Nass, J. S. Steuer, and E. Tauber, </author> <title> "Computers are social actors," </title> <booktitle> in Proceeding of the CHI '94 Proceedings, </booktitle> <address> (Boston, MA), </address> <pages> pp. 72-78, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: This particular set of studies was recently conducted by Nass and his colleagues at Stanford <ref> [13] </ref>. They performed a number of classical studies of human social interaction, substituting computers into a role usually occupied by humans. Hence, a test that would ordinarily study a human-human interaction is used to study a human-computer interaction. <p> Nu- merous other experiments were done in this vein, revealing that the classic results of the human-human studies were maintained in the human-computer studies. After accounting for potential biasing factors, Nass et al. concluded that individuals' interactions with computers are inherently natural and social <ref> [13] </ref>, [14]. Because affective communication occurs naturally between people, it is expected by people when they interact with computers. In fact, we often see people attribute emotion to things that clearly do not have emotion a wind-up dog that wags its tail, for example.
Reference: [14] <author> C. Nass and S. S. Sundar, </author> <title> "Is human-computer interac-tion social or parasocial?," </title> <note> Submitted for Publication, 1994. Stanford SRCT Paper #110. </note>
Reference-contexts: Nu- merous other experiments were done in this vein, revealing that the classic results of the human-human studies were maintained in the human-computer studies. After accounting for potential biasing factors, Nass et al. concluded that individuals' interactions with computers are inherently natural and social [13], <ref> [14] </ref>. Because affective communication occurs naturally between people, it is expected by people when they interact with computers. In fact, we often see people attribute emotion to things that clearly do not have emotion a wind-up dog that wags its tail, for example.
Reference: [15] <author> S. R. Covey, </author> <title> The Seven Habits of Highly Effective People. </title> <address> New York: Fireside, </address> <publisher> Simon and Schuster, </publisher> <year> 1989. </year>
Reference-contexts: Affect recognition and expression is also necessary for sympathy and communication of understanding, the latter of which is considered one of man's greatest psychological needs <ref> [15] </ref>. Ne- groponte, in Being Digital, reminds us that even a puppy can tell when you are angry with it [16]. Basic affect recognition and expression is expected by humans in communication. Computer-based communication to date has largely removed or ignored affective bits.
Reference: [16] <author> N. Negroponte, </author> <title> Being Digital. </title> <address> New York: </address> <publisher> Alfred A. </publisher> <address> Knopf, </address> <year> 1995. </year>
Reference-contexts: Affect recognition and expression is also necessary for sympathy and communication of understanding, the latter of which is considered one of man's greatest psychological needs [15]. Ne- groponte, in Being Digital, reminds us that even a puppy can tell when you are angry with it <ref> [16] </ref>. Basic affect recognition and expression is expected by humans in communication. Computer-based communication to date has largely removed or ignored affective bits.
Reference: [17] <author> E. D. Scheirer, </author> <year> 1994. </year> <type> Personal Communication. </type>
Reference-contexts: One of the interests in the Media Lab is the building of better piano- teaching computer systems; in particular, systems that can grade some aspects of a student's expressive timing, dynamics, phrasing, etc. <ref> [17] </ref>. This goal contains many challenges, one of the hardest of which involves expression recognition, distilling the essential pitches of the music from its expression. Recogniz- ing and interpreting affect in musical expression is important, and I'll return to it again later.
Reference: [18] <author> M. Lewis, </author> <title> "Self-conscious emotions," </title> <journal> American Scientist, </journal> <volume> vol. 83, </volume> <pages> pp. 68-78, </pages> <address> Jan.-Feb. </address> <year> 1995. </year>
Reference-contexts: In other words, it not only interprets your musical expression, but also your facial expression and perhaps other physical changes corresponding to your emotional feelings. Assume it has the ability to distinguish the three emotions we all appear to have at birth distress, interest, and pleasure <ref> [18] </ref>. 6 Given affect recognition, the computer teacher might find you are doing well with the music and you are pleased with your progress. "Am I holding your interest?" it would consider. In the affirmative, it might nudge you with more challenging exercises. <p> The piano-teacher scenario raises the issue of observing not just someone's emotional expression, but also their underlying emotional state. How do we detect a person's emotions? Is 6 This view of <ref> [18] </ref> is not unchallenged; facial expression in the womb and on newborns has no broadly accepted explanation. 4 it via some metaphysical sixth sense? Whether or not such a sense might exist or play a role exceeds the scientific scope of this paper; consequently, this possibility will not be further addressed. <p> In contrast, given feelings of joy, the voice might go up in pitch, the face reveal a smile, and the finger pressure have a slight bounce-like character. Even the more difficult-to-analyze "self-conscious" emotions, such as guilt and shame, exhibit marked postural differences <ref> [18] </ref> which might be observed in how you stand, walk, gesture, or otherwise behave. <p> Izard overviews some of the evidence for and against various sensorimotor claims [4]. Whether or not such sensorimotor inputs can induce emotion, they appear to at least be effective in maintaining and expressing emotion. Posture is correlated with expressions of self-esteem [4], <ref> [18] </ref>. A successful school of acting (after Michael Chekhov, student of Stanislavsky) is based on imagining emotive scenarios, and adjusting ones body position in accord with that emotion [36], [37]. Actors who excel at this method strengthen their association with their character's emotional state.
Reference: [19] <editor> R. Plutchik and H. Kellerman, eds., </editor> <title> Emotion Theory, </title> <journal> Research, and Experience, </journal> <volume> vol. </volume> <pages> 1-5. </pages> <publisher> Academic Press, </publisher> <address> 19801990. </address> <booktitle> Series of selected papers. </booktitle>
Reference-contexts: I will also clarify some terminology, and highlight ways in which emotion is both expressed and induced. It is beyond the scope of this paper to overview the literature with its many theories of emotion; I will refer the reader instead to the collections gathered by Plutchik and Kellerman <ref> [19] </ref> and to the references at the end of this paper which themselves contain many excellent surveys.
Reference: [20] <author> M. Clynes, </author> <year> 1995. </year> <type> Personal Communication. 24 </type>
Reference-contexts: Beethoven, after he became deaf, wrote in his conversation books that he could judge from the performer's facial expression whether or not the performer was interpreting his music in the right spirit <ref> [20] </ref>. <p> This "emotional biofeedback," through measuring es- sentic form, perhaps via finger pressure, foot pressure, or functions of inspiration and expiration as you breathe, could help you compare aspects of your performance that have never been measured or understood before. Recently, Clynes <ref> [20] </ref> has made significant progress in this area, giving a user control over such expressive aspects as pulse, note shaping, vibrato, and timbre. Clynes recently conducted a "Musical Turing test" 17 to demonstrate the ability of his new "superconductor" tools.
Reference: [21] <author> G. Duchenne, </author> <title> The Mechanism of Human Facial Expres-sion. </title> <address> New York, NY: </address> <publisher> Cambridge University Press, </publisher> <year> 1990. </year> <note> Reprinting of original 1862 dissertation. </note>
Reference-contexts: Despite the fact that we are not all experts at reading faces, and comedians and actors can excel at feigning emotions, it is claimed that the attentive observer is always able to recognize a false smile <ref> [21] </ref>. 7 This is consistent with the findings of 7 This view is debated, e.g., by [1] who claims that all phenomena that change with emotion also change for other reasons, Duchenne over a century ago: The muscle that produces this depression on the lower eyelid does not obey the will; <p> Its inertia in smiling unmasks a false friend. <ref> [21] </ref> Neurological studies also indicate that emotions travel their own special path to the motor system. If the neurologist asks a patient who is paralyzed on one side to smile, then only one side of the patient's mouth raises. <p> Lesions in the nonpyramidal areas produce the reverse pattern; patients can smile on request, but will not smile when they feel a positive emotion. - Paul Ekman in <ref> [21] </ref>. In other words, a faked smile travels a different path than a genuine one. Not only does this imply that, physiologically, false and sincere smiles may be discriminated, but it illustrates the existence of multiple paths for emotional expression. <p> Facial expressions are one of the two most widely acknowledged forms of sentic modulation. Duchenne, in his 1862 thesis (republished in <ref> [21] </ref>) identified independent expressive face muscles, such as the muscle of attention, muscle of lust, muscle of disdain or doubt, and muscle of joy.
Reference: [22] <author> R. E. Cytowic, </author> <year> 1994. </year> <type> Personal Communication. </type>
Reference-contexts: If the neurologist asks a patient who is paralyzed on one side to smile, then only one side of the patient's mouth raises. But when the neurologist cracks a funny joke, then a natural two-sided smile appears <ref> [22] </ref>. For facial expression, it is widely accepted in the neurological literature that the will and the emotions control separate paths: If the lesion is in the pyramidal system, the patients cannot smile deliberately but will do so when they feel happy.
Reference: [23] <author> D. M. Clynes, Sentics: </author> <title> The Touch of the Emotions. </title> <address> Anchor Press/Doubleday, </address> <year> 1977. </year>
Reference-contexts: Treating the body and mind separately can lead to errors, as captured by the title of [7]. The separation will be used here primarily to distinguish arguments from the literature. 9 "Sentic" is from the Latin sentire, the root of the words "sentiment" and "sensation" <ref> [23] </ref>. 5 Finally, "mood" tends to refer to a longer-term emotional state, although duration might be difficult to quantify given that moods can "swing" abruptly. 2.3 Physiological aspects of emotion: sentic modulation There is a class of qualities which is inherently linked to the motor system ... it is because of <p> This class of qualities is referred to commonly as emotions. In each mode, the emotional character is expressed by a specific subtle modulation of the motor action involved which corresponds precisely to the demands of the sentic state. - Manfred Clynes <ref> [23] </ref> The body usually responds physically to an emotion, although James's 1890 view of this response being the emotion is not accepted today. Nonetheless, the motor system acts as a carrier for communicating emotional state, what I call "sen- tic modulation" after the foundational principles Clynes established in this area [23]. <p> <ref> [23] </ref> The body usually responds physically to an emotion, although James's 1890 view of this response being the emotion is not accepted today. Nonetheless, the motor system acts as a carrier for communicating emotional state, what I call "sen- tic modulation" after the foundational principles Clynes established in this area [23]. Sentic modulation (e.g. voice inflection, facial expression, posture) is how an emotional state is typically expressed; it is the primary means of communicating human emotion. When computers learn to recognize human emotion, they will rely primarily on sentic modulation. <p> Voice, of course, is why the phone has so much more bandwidth than email or a written letter. Spoken communication transcends the message of the words. Other forms of sentic modulation have been explored by Clynes in his pioneering book, Sentics <ref> [23] </ref>. One of his principles, that of "sentic equivalence," allows one to select an arbitrary motor output of sufficient degrees of freedom for the measurement of "essentic form," a precise spatiotemporal dynamic form produced and sensed by the nervous system, which carries the emotional message. <p> The finger-pressure response has been measured for thousands of people, and found to be not only repeatable for an individual, but to reveal distinct traces for states such as no emotion, anger, hate, grief, love, joy, sex, and reverence <ref> [23] </ref> across groups of individuals, and to some extent, cultures. Clynes suggests that these traces are indicative of the underlying essentic form. Other forms of motor output such as chin pressure (for a patient who was paralyzed from the neck down) and foot pressure have yielded comparable characteristic essentic forms. <p> Analytic tools can subsequently be used to search for universal patterns in the data. 3.1.3 Pure or mixed? The debate in the literature about the purity of emotional states is another debate where experiments could be conducted with affective computers. For example, Clynes's exclusivity principle of emotional states <ref> [23] </ref> suggests that we cannot express one emotion when we are feeling another, e.g., we cannot express anger when we are feeling hope. <p> character it changed into) vs. the predictable errors the submarine would make when we did not steer correctly? What makes one experience pleasurably more engaging than another? Clynes's "self-generating principle" indicates that the intensity of an emotional state is increased, within limits, by the repeated, arrhythmic generation of essentic form <ref> [23] </ref>. Clynes has carried this principle forward and developed a process of "sentic cycles" whereby people (in a controlled and voluntary manner) may experience a spectrum of emotions arising from within. <p> Seventh Principle of Sentic Commu <br>- nication <ref> [23] </ref> Clynes [23] argues that music can be used to express emotion more finely than any language. <p> Seventh Principle of Sentic Commu <br>- nication <ref> [23] </ref> Clynes [23] argues that music can be used to express emotion more finely than any language. <p> with his familiar, definite gesture, "That must be graceful!" And then he played the same few bars and it was graceful as though one had never heard grace before ahundred times more graceful so 17 that the cynicism melted in the hearts of the people who sat there and listened. <ref> [23] </ref> Clynes attributes the power of Casals's performance to the purity and preciseness of the essentic form. The purer the emotional state, the purer its expression and communication. In expression, teaches Clynes, faithfulness to the purest inner form produces the best results.
Reference: [24] <author> R. S. Lazarus, A. D. Kanner, and S. Folkman, </author> <title> "Emotions: A cognitive-phenomenological analysis," in Emotion Theory, Research, </title> <editor> and Experience (R. Plutchik and H. Kellerman, eds.), </editor> <volume> vol. 1, </volume> <booktitle> Theories of Emotion, </booktitle> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: When computers learn to recognize human emotion, they will rely primarily on sentic modulation. To give computers affect recognition requires understanding the physical manifestations of emotion. A number of emotion and cognition theorists have studied the physiological correlates of emotions. Lazarus et al. <ref> [24] </ref> argue that each emotion probably has its own unique somatic response pattern, and cite other theorists who argue that each has its own set of unique facial muscle movement patterns. Facial expressions are one of the two most widely acknowledged forms of sentic modulation.
Reference: [25] <author> P. Ekman and W. Friesen, </author> <title> Facial Action Coding System. </title> <publisher> Consulting Psychologists Press, </publisher> <year> 1977. </year>
Reference-contexts: Most present attempts to automate recognition of facial expression are based on the subsequent Facial Action Coding System of psychologist Paul Ekman <ref> [25] </ref>, which provides mappings between muscles and an emotion space. The second widely acknowledged form of sentic modulation is via voice intonation: you can hear love in her voice, anxiety in his.
Reference: [26] <author> I. R. Murray and J. L. Arnott, </author> <title> "Toward the simulation of emotion in synthetic speech: A review of the literature on human vocal emotion," </title> <journal> J. Acoust. Soc. Am., </journal> <volume> vol. 93, </volume> <pages> pp. 1097-1108, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: The second widely acknowledged form of sentic modulation is via voice intonation: you can hear love in her voice, anxiety in his. Vocal emotions can be understood by young children before they can understand what is being said <ref> [26] </ref> and by dogs, which we assume can not understand what is being said. Voice, of course, is why the phone has so much more bandwidth than email or a written letter. Spoken communication transcends the message of the words. <p> Even in telling a joke, everyone knows it's how you tell it that determines its success. A variety of features of speech are modulated by emotion; these may be divided into the three categories of voice quality, utterance timing, and utterance pitch contour. (Murray and Arnott <ref> [26] </ref> provide a recent review of these features.) Although virtually no work seems to have been done on computer analysis of affect in voices, several features have been demonstrated for synthesizing intonation in computer-generated speech [66], [26]. <p> three categories of voice quality, utterance timing, and utterance pitch contour. (Murray and Arnott <ref> [26] </ref> provide a recent review of these features.) Although virtually no work seems to have been done on computer analysis of affect in voices, several features have been demonstrated for synthesizing intonation in computer-generated speech [66], [26]. With a suitable affective voice, computers can communicate in a more natural and social way with humans. Monotonous voice mail recordings and voice-reminder systems could vary their voices from day-to-day, like a human voice varies.
Reference: [27] <author> K. Leidelmeijer, </author> <title> Emotions: An experimental approach. </title> <publisher> Tilburg University Press, </publisher> <year> 1991. </year>
Reference-contexts: For example, in our current research with a wearable wireless affective head-mounted camera (for augmenting visual memory), we have found it more relevant to associate frame-rate not with just heart-rate, but with a function that combines heart-rate and step-rate. Leidelmeijer overviews several conflicting studies in <ref> [27] </ref>, reminding us that a specific situation is not equally emotional for all people and an individual will not be equally emotional in 6 all situations. <p> Leidelmeijer <ref> [27] </ref> discusses the evidence both for and against universal autonomic patterning. The difficulties in finding consistent universal patterning mechanisms appear to make the outlook grim for constructing computers that can recognize affect. <p> In contrast, for emotion recognition, a relatively small number of simplifying categories for emotions have been commonly proposed. 3.1 Basic or prototype emotions: key issues 3.1.1 Categories or continuum? Diverse writers have proposed that there are from two to twenty basic or prototype emotions. (See for example, [38], p. 8, <ref> [27] </ref>, p. 10). The most common four appearing on these lists are: fear, anger, sadness, and joy. Plutchik [38] distinguished among eight basic emotions: fear, anger, sorrow, joy, disgust, acceptance, anticipation, and surprise. Ortony et al. provide a helpful summary of lists of basic emotions in their book [39]. <p> Sometimes these "basic" emotions are defined to be essentially innate like Damasio's primary emotions, but there is no consensus on their definition. The actual existence of basic emotional states is disputed by some authors. Leidelmeijer <ref> [27] </ref> and Stein and Oatley [40] bring together evidence for and against the existence of basic emotions, especially universally, although I distinguish universality as a separate issue, addressed below.
Reference: [28] <author> R. B. Zajonc, </author> <title> "On the primacy of affect," </title> <journal> American Psychologist, </journal> <volume> vol. 39, </volume> <pages> pp. 117-123, </pages> <month> Feb. </month> <year> 1984. </year>
Reference-contexts: Consequently, some prominent scientists have argued that cognitive appraisal is a necessary precondition for emotion. Although it is hard to "prove" that any human experience exists independent of cognitive events, there seems to be ample evidence that emotions can occur without prior cognitive appraisal [4], [7], <ref> [28] </ref>. In particular, the recent neurological evidence seems to support that emotions can "hijack" the cognitive centers of the brain [12]. Additionally, noncognitive biochemical events can strongly influence mood [4].
Reference: [29] <author> M. Lewis, </author> <title> "Ch 16: The emergence of human emotions," in Handbook of Emotions (M. </title> <editor> Lewis and J. Haviland, eds.), </editor> <address> (New York, NY), </address> <pages> pp. 223-235, </pages> <publisher> Guilford Press, </publisher> <year> 1993. </year>
Reference-contexts: The complex cortical activities available to humans probably also account for their ability to construct "self-conscious" cognitive emotions such as shame and guilt, which are not present in infants, but develop later in life <ref> [29] </ref>. Babies demonstrate a less complicated repertoire of emotions than cogitating adults, despite the fact that babies have not learned the social rules of suppressing emotions. 2.4.1 Complicating conditions A number of factors confound "purely cognitive" attempts to understand emotion.
Reference: [30] <author> H. G. Wallbott and K. R. Scherer, </author> <title> "Assessing emotion by questionnaire," in Emotion Theory, Research, </title> <editor> and Experience (R. Plutchik and H. Kellerman, eds.), </editor> <volume> vol. 4, </volume> <booktitle> The Measurement of Emotions, </booktitle> <publisher> Academic Press, </publisher> <year> 1989. </year>
Reference-contexts: In cognitive studies of emotion, subjects are usually asked to verbalize their emotional state, as opposed to (or in addition to) its being physically measured. However, the problem of attaching adjectives to emotions is immense <ref> [30] </ref>. Wierzbicka [31] has made one of the most comprehensive attempts to define emotion concepts in terms of universal semantic primitives such as "good" "bad" and "want," resulting in a distinct script for each emotion concept in terms of a set of primitives. <p> Problems with studies of emotion in a lab setting (especially with interference from cognitive social rules) are well documented. The ideal study to aid the development of the theory of emotions is real-life observation, recently believed to be impossible <ref> [30] </ref>. However, as in the examples above, a wearable affective computer that attends to you during your waking hours could potentially notice what emotions you express, as well as a variety of conditioning factors such as what you eat, what you do, what you see, hear, etc.
Reference: [31] <author> A. Wierzbicka, </author> <title> "Defining emotion concepts," </title> <journal> Cognitive Science, </journal> <volume> vol. 16, </volume> <pages> pp. 539-581, </pages> <address> Oct.-Dec. </address> <year> 1992. </year>
Reference-contexts: In cognitive studies of emotion, subjects are usually asked to verbalize their emotional state, as opposed to (or in addition to) its being physically measured. However, the problem of attaching adjectives to emotions is immense [30]. Wierzbicka <ref> [31] </ref> has made one of the most comprehensive attempts to define emotion concepts in terms of universal semantic primitives such as "good" "bad" and "want," resulting in a distinct script for each emotion concept in terms of a set of primitives. <p> In either case, it will still be important to use some of the techniques described above. Therefore, the models of Pfeifer and other cognitive- motivational generators of emotion (such as the proposed scripts of Wierzbicka in <ref> [31] </ref> which could be programmed) potentially not only could run a script to generate a cognitive- emotional state, but also could identify which components of the script are satisfied by a set of observations of a human.
Reference: [32] <author> J. D. Laird, J. J. Wagener, M. Halal, and M. Szegda, </author> <title> "Remembering what you feel: Effects of emotion on mem-ory," </title> <journal> Journal of Personality and Social Psychology, </journal> <volume> vol. 42, no. 4, </volume> <pages> pp. 646-657, </pages> <year> 1982. </year>
Reference-contexts: Improvement in memory retrieval has been found to occur when a person is in the same emotional state associated with the memory being retrieved <ref> [32] </ref>. 11 Memory retrieval is a key activity in making free associations, which are important for analogical thinking and creativity. Hence, it is natural to expect to find relations between emotional states and creativity. <p> For example, Laird <ref> [32] </ref> divides people into "cueing" categories based on whether or not posturing themselves in a particular expression induces the corresponding emotional experience. Izard overviews some of the evidence for and against various sensorimotor claims [4].
Reference: [33] <editor> D. Gelernter, </editor> <booktitle> The Muse in the Machine. </booktitle> <address> Ontario: </address> <publisher> The Free Press, Macmillan, Inc., </publisher> <year> 1994. </year>
Reference-contexts: Damasio's findings linked cortical constructs to primary emotions; consequently, we might expect cortical constructs for creative thinking and memory retrieval to also develop emotion links. The mechanism Damasio describes may therefore account for a separate idea, recently proposed by the computer scientist Gelernter <ref> [33] </ref>. Gelernter has suggested a phenomenon he calls "affect linking" which might play an important role in creativity. However, Gelernter suggested that this phenomenon arises primarily during what he termed "low focus" thinking, and not during what he termed "high focus" reasoning.
Reference: [34] <author> M. Minsky, </author> <booktitle> The Society of Mind. </booktitle> <address> New York, NY: </address> <publisher> Simon & Schuster, </publisher> <year> 1985. </year>
Reference-contexts: in higher-level decision making; it is therefore not restricted to "low-focus" thinking as Gelernter muses. 2.5 A note on inducement of emotion Certain physical acts are peculiarly effective, especially the facial expressions involved in social com <p>- munication; they affect the sender as much as the recipient. - Marvin Minsky <ref> [34] </ref> There is emotional inducement ever at work around us a good marketing professional, playwright, actor, or politician knows the importance of appealing to your emotions. Aristotle devoted much of his teachings on rhetoric to instructing speakers how to arouse the right emotions in their audience [10].
Reference: [35] <author> W. R. Hess, </author> <booktitle> The functional organization of the diencephalon. </booktitle> <address> New York: Grune & Stratton, </address> <year> 1957. </year>
Reference-contexts: These and many other hurdles must be overcome to give computers the ability to recognize affective states. 12 External, in contrast with direct stimulation of the brain which is known to elicit various emotions <ref> [35] </ref>. 13 Perhaps this willingness may also be induced, ad infinitum. However, computer recognition of affective states appears doable in many cases, via the measurement of sentic modulation. Note that I am not proposing one could measure affective state directly, but rather measure observable functions of such states.
Reference: [36] <author> K. Levitt, </author> <year> 1995. </year> <type> Personal Communication. </type>
Reference-contexts: Posture is correlated with expressions of self-esteem [4], [18]. A successful school of acting (after Michael Chekhov, student of Stanislavsky) is based on imagining emotive scenarios, and adjusting ones body position in accord with that emotion <ref> [36] </ref>, [37]. Actors who excel at this method strengthen their association with their character's emotional state.
Reference: [37] <author> M. Chekhov, </author> <title> On the Technique of Acting. </title> <address> New York: </address> <note> HarperCollins Pub., 1991. Chekhov, (1891-1955), Preface and Afterword by M. Powers. </note>
Reference-contexts: Posture is correlated with expressions of self-esteem [4], [18]. A successful school of acting (after Michael Chekhov, student of Stanislavsky) is based on imagining emotive scenarios, and adjusting ones body position in accord with that emotion [36], <ref> [37] </ref>. Actors who excel at this method strengthen their association with their character's emotional state.
Reference: [38] <author> R. Plutchik, </author> <title> "A general psychoevolutionary theory of emotion," in Emotion Theory, Research, </title> <editor> and Experience (R. Plutchik and H. Kellerman, eds.), </editor> <volume> vol. 1, </volume> <booktitle> Theories of Emotion, </booktitle> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: In contrast, for emotion recognition, a relatively small number of simplifying categories for emotions have been commonly proposed. 3.1 Basic or prototype emotions: key issues 3.1.1 Categories or continuum? Diverse writers have proposed that there are from two to twenty basic or prototype emotions. (See for example, <ref> [38] </ref>, p. 8, [27], p. 10). The most common four appearing on these lists are: fear, anger, sadness, and joy. Plutchik [38] distinguished among eight basic emotions: fear, anger, sorrow, joy, disgust, acceptance, anticipation, and surprise. <p> 3.1 Basic or prototype emotions: key issues 3.1.1 Categories or continuum? Diverse writers have proposed that there are from two to twenty basic or prototype emotions. (See for example, <ref> [38] </ref>, p. 8, [27], p. 10). The most common four appearing on these lists are: fear, anger, sadness, and joy. Plutchik [38] distinguished among eight basic emotions: fear, anger, sorrow, joy, disgust, acceptance, anticipation, and surprise. Ortony et al. provide a helpful summary of lists of basic emotions in their book [39]. <p> Plutchik said that one can account for any emotion by a mixture of the principal emotions <ref> [38] </ref>, and that emotions are rarely perceived in a pure state.
Reference: [39] <author> A. Ortony, G. L. Clore, and A. Collins, </author> <title> The Cognitive Structure of Emotions. </title> <address> Cambridge, MA: </address> <publisher> Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: The most common four appearing on these lists are: fear, anger, sadness, and joy. Plutchik [38] distinguished among eight basic emotions: fear, anger, sorrow, joy, disgust, acceptance, anticipation, and surprise. Ortony et al. provide a helpful summary of lists of basic emotions in their book <ref> [39] </ref>. Sometimes these "basic" emotions are defined to be essentially innate like Damasio's primary emotions, but there is no consensus on their definition. The actual existence of basic emotional states is disputed by some authors. <p> Plutchik said that one can account for any emotion by a mixture of the principal emotions [38], and that emotions are rarely perceived in a pure state. This idea was captured by cartoonist Johnny Hart (and reprinted in <ref> [39] </ref>) in his "B.C." cartoon illustrating an example of a mixed emotion: "seeing your long-lost dog come bounding up your freshly poured front sidewalk." The distinctions between the views of Plutchik and Clynes appear to be a matter of intensity and deliberate expression.
Reference: [40] <author> N. L. Stein and K. Oatley, eds., </author> <title> Basic Emotions. </title> <address> Hove, UK: </address> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1992. </year> <journal> Book is a special double issue of the journal Cognition and Emotion, </journal> <volume> Vol. 6, No. 3 & 4, </volume> <year> 1992. </year>
Reference-contexts: Sometimes these "basic" emotions are defined to be essentially innate like Damasio's primary emotions, but there is no consensus on their definition. The actual existence of basic emotional states is disputed by some authors. Leidelmeijer [27] and Stein and Oatley <ref> [40] </ref> bring together evidence for and against the existence of basic emotions, especially universally, although I distinguish universality as a separate issue, addressed below.
Reference: [41] <author> L. R. Rabiner and B. H. Juang, </author> <title> "An introduction to hidden Markov models," </title> <journal> IEEE ASSP Magazine, </journal> <pages> pp. 4-16, </pages> <month> Jan. </month> <year> 1986. </year>
Reference-contexts: The Hidden Markov Model shown here characterizes probabilities of transitions among three "hidden" states, (I,D,J), as well as probabilities of observations (measurable essentic forms, such as features of voice inflection, V) given a state. Given a series of observations over time, an algorithm such as Viterbi's <ref> [41] </ref> can be used to decide which sequence of states best explains the observations. the HMM states do not have to correspond to pure emotional states as illustrated in Fig. 1, but may correspond to even more fundamental building blocks, perhaps identified by the computer as it works to fit the
Reference: [42] <author> K. Popat and R. W. </author> <title> Picard, "Novel cluster-based proba-bility models for texture synthesis, classification, </title> <booktitle> and com-pression," in Proc. SPIE Visual Communication and Image Proc., vol. 2094, (Boston), </booktitle> <pages> pp. 756-768, </pages> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: The choice of states could be made by clustering physiological variables, and assigning each cluster its own state. Static mixtures may also be modeled (and tailored to an individual, and to their context) by explicit "mixture models" such as the cluster-based probability model of Popat and Picard <ref> [42] </ref>. In such a case, high-dimensional probability distributions are learned for emotional states or their mixtures based on the values of or functions of the values of the physiological variables. The input would be a set of observations, the output a set of probabilities for each possible emotional state.
Reference: [43] <author> A. Sherstinsky and R. W. </author> <title> Picard, "Orientation-sensitive image processing with M-Lattice: A novel non-linear dy-namical system," </title> <booktitle> in IEEE First Int. Conf. on Image Proc., </booktitle> <volume> vol. III, </volume> <pages> pp. 152-156, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: Numerous other tools from pattern recognition are also likely to be useful in affect recognition. Artificial neural nets can perform a variety of recognition tasks and can function like mixture models; hence, they should be useful for emotional state modeling. Neural nets and related models such as the M-Lattice <ref> [43] </ref> can also model certain nonlinear dynamical systems. Camras [44] has proposed that dynamical systems theory be considered for explaining some of the variable physiological responses observed during basic emotions, but has not suggested any models.
Reference: [44] <author> L. A. Camras, </author> <title> "Expressive development and basic emo-tions," </title> <journal> Cognition and Emotion, </journal> <volume> vol. 6, no. 3 and 4, </volume> <year> 1992. </year>
Reference-contexts: Artificial neural nets can perform a variety of recognition tasks and can function like mixture models; hence, they should be useful for emotional state modeling. Neural nets and related models such as the M-Lattice [43] can also model certain nonlinear dynamical systems. Camras <ref> [44] </ref> has proposed that dynamical systems theory be considered for explaining some of the variable physiological responses observed during basic emotions, but has not suggested any models.
Reference: [45] <author> W. J. Freeman, </author> <title> Societies of Brains. A Study in the Neuroscience of Love and Hate. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates, Publishers, </publisher> <year> 1995. </year>
Reference-contexts: Freeman has modeled olfaction with dynamical systems and proposes the importance of this approach for modeling limbic influences on intention and motivation in his book Societies of Brains <ref> [45] </ref>, but he has not proposed any computational models for the latter. 3.2.2 Continuous affect models and "eigenmoods" Instead of assuming discrete states, sometimes it is more appropriate to start with the data and perform factor analysis or an eigenvector decomposition to discover its underlying dimensions.
Reference: [46] <author> P. J. Lang, </author> <title> "The emotion probe: Studies of motivation and attention," </title> <journal> American Psychologist, </journal> <volume> vol. 50, no. 5, </volume> <pages> pp. 372385, </pages> <year> 1995. </year>
Reference-contexts: Note that in modeling, any signal can be decomposed into basis components; therefore, one can always find sub-components 11 locate the affective response of certain photo contents, as per the studies of Lang <ref> [46] </ref>. a so-called mixture, even if the signal is "purely" of one kind. Consequently, from a modeling perspective, the theoretical issue of "pure" vs. "impure" emotional states is not problematic. <p> Subject and action content, which were most frequently requested for editorial purposes, can also be a powerful contributor to mood in a photo <ref> [46] </ref>. We have recently built some of the first computer vision tools that enable computers to assist humans in annotating video, attaching descriptions to images that the person and computer both "see" [74].
Reference: [47] <author> R. O. Duda and P. E. Hart, </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley-Interscience, </publisher> <year> 1973. </year>
Reference-contexts: Because the recognition of emotional state can be set up as a pattern recognition problem, a variety of techniques are available for its solution <ref> [47] </ref>, [48]. 3.2.3 Cathexis in computing Although most computer models for imitating mental activity do not explicitly consider the limbic response, a surprisingly large number implicitly consider it.
Reference: [48] <author> C. W. Therrien, </author> <title> Decision Estimation and Classification. </title> <address> New York: </address> <publisher> John Wiley and Sons, Inc., </publisher> <year> 1989. </year>
Reference-contexts: Because the recognition of emotional state can be set up as a pattern recognition problem, a variety of techniques are available for its solution [47], <ref> [48] </ref>. 3.2.3 Cathexis in computing Although most computer models for imitating mental activity do not explicitly consider the limbic response, a surprisingly large number implicitly consider it.
Reference: [49] <author> P. Werbos, </author> <title> "The brain as a neurocontroller: New hy-potheses and new experimental possibilities," in Origins: </title> <editor> Brain and Self-Organization (K. H. Pribram, ed.), </editor> <publisher> Erlbaum, </publisher> <year> 1994. </year>
Reference-contexts: Werbos <ref> [49] </ref> writes that his original inspiration for the backpropagation algorithm, extensively used in training artificial neural networks, came from trying to mathematically translate an idea of Freud. <p> Freud's model began with the idea that human behavior is governed by emotions, and people attach cathexis (emotional energy) to things Freud called "objects." Quoting from Werbos <ref> [49] </ref>: According to his [Freud's] theory, people first of all learn cause-and-effect associations; for example, they may learn that "object" A is associated with "object" B at a later time. And his theory was that there is a backwards flow of emotional energy.
Reference: [50] <author> E. J. Sondik, </author> <title> "The optimal control of partially observable Markov processes over the infinite horizon: Discounted costs," </title> <journal> Operations Research, </journal> <volume> vol. 26, </volume> <pages> pp. 282-304, </pages> <month> MarchApril </month> <year> 1978. </year>
Reference-contexts: A variation on the HMM above could also be used to incorporate affective feedback. The recent Partially Observable Markov Decision Processes are set up to give a "reward" associated with executing a particular action in a given state <ref> [50] </ref>, [51], [52].
Reference: [51] <author> W. S. Lovejoy, </author> <title> "A survey of algorithmic methods for par-tially observed Markov decision processes," </title> <journal> Annals of Operations Research, </journal> <volume> vol. 28, </volume> <pages> pp. 47-66, </pages> <year> 1991. </year>
Reference-contexts: A variation on the HMM above could also be used to incorporate affective feedback. The recent Partially Observable Markov Decision Processes are set up to give a "reward" associated with executing a particular action in a given state [50], <ref> [51] </ref>, [52].
Reference: [52] <author> C. C. White, III, </author> <title> "A survey of solution techniques for the partially observed Markov decision process," </title> <journal> Annals of Operations Research, </journal> <volume> vol. 32, </volume> <pages> pp. 215-230, </pages> <year> 1991. </year>
Reference-contexts: A variation on the HMM above could also be used to incorporate affective feedback. The recent Partially Observable Markov Decision Processes are set up to give a "reward" associated with executing a particular action in a given state [50], [51], <ref> [52] </ref>.
Reference: [53] <author> T. Darrell, </author> <title> "Interactive vision using hidden state decision processes." </title> <type> PhD Thesis Proposal, </type> <year> 1995. </year>
Reference-contexts: The recent Partially Observable Markov Decision Processes are set up to give a "reward" associated with executing a particular action in a given state [50], [51], [52]. These models permit observations at each state which are actions <ref> [53] </ref>; hence, they could incorporate not only autonomic measures, but also observations of your behavior. 3.2.4 Rule-based emotion models and their limitations The focus in the previous section was affect recognition using mathematical models, which, in some cases, can also be used for emotion synthesis and prediction.
Reference: [54] <author> R. Pfeifer, </author> <title> "Artificial intelligence models of emotion," in Cognitive Perspectives on Emotion and Motivation (V. Hamilton, </title> <editor> G. H. Bower, and N. H. Frijda, eds.), </editor> <title> vol. 44 of Series D: Behavioural and Social Sciences, </title> <publisher> (Netherlands), </publisher> <pages> pp. 287-320, </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: Alternatively, non- mathematical rule-based models may be used. Some work on rule-based models of emotion has been done in the AI community, where the emphasis has been on writing scripts to produce states that are labeled with various emotions (See Pfeifer <ref> [54] </ref> for a nice overview.) The AI emphasis has been on rule-based synthesis of cognitive states in the computer, which receive emotional names for example, if the computer has the goal of getting you to fill out a form, and you do not fill it out after it repeatedly asks you
Reference: [55] <author> P. Maes, T. Darrell, B. Blumburg, and A. Pentland, </author> <title> "The ALIVE system: Full-body interaction with autonomous agents," </title> <booktitle> Proceedings of Computer Animation, </booktitle> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: Coupling between synthesis and analysis models has some imminent practical applications. For example, in an existing environment such as ALIVE <ref> [55] </ref>, a synthesis model could adjust each software agent's posture, facial expression, and gestures to reflect its (synthesized) emotional state. The state itself could also be re-synthesized (via the cognitive scripts mentioned earlier) as the agent recognizes the states of humans interacting with it in this virtual world.
Reference: [56] <author> N. Alm, I. R. Murray, J. L. Arnott, and A. F. Newell, </author> <title> "Pragmatics and affect in a communication system for non-speakers," </title> <journal> Journal of the American Voice, </journal> <volume> vol. 13, </volume> <pages> pp. 1-15, </pages> <month> March </month> <year> 1993. </year> <note> I/O Society Special Issue: People with Disabilities. </note>
Reference-contexts: Another important example of coupling synthesis and analysis is in the case of a speaking-impaired human relying on a speech synthesizer. Such people are usually limited to one inflection-less digital voice. Control over affect in synthetic speech is particularly important for these people <ref> [56] </ref>. With an affective wearable computer that senses sentic modulation, and couples it to a synthesis model, parameters for voice inflection could be synthesized and fed directly into their speech synthesizer. The result would allow a speaking-impaired individual to, for example, express anger with her voice by merely feeling angry.
Reference: [57] <author> D. Dennett, </author> <title> "Where am I?," </title> <booktitle> in Brainstorms: Philosophic Essays on Mind and Psychology, </booktitle> <address> (Montgomery, VT), </address> <publisher> Bradford Books, </publisher> <year> 1978. </year>
Reference-contexts: If sentic modulation synthesis is coupled to the "inverse problem" of sentic modulation analysis (recognition), then in the ultimate modeling scenario, the emotion synthesis model could synthesize the affective responses of a body separated from its brain, as in Dennett's fantastic story "Where am I" <ref> [57] </ref>. Like- wise, to the extent that sensorimotor stimuli affect and reinforce the cognitive state of emotion, a body's sentic modulation could 13 (after analysis) drive the brain into a corresponding cognitive state.
Reference: [58] <author> I. Asimov, </author> <title> The Bicentennial Man and Other Stories. </title> <institution> Garden City, NY: Doubleday Science Fiction, </institution> <year> 1976. </year>
Reference-contexts: Subsequently, I will discuss more imminent concerns. The first scenario comes from Asimov's "The Bicentennial Man" <ref> [58] </ref>. Asimov subjects his affective robots to three laws of behavior to prevent them from bringing harm to people. His laws put human life above the self-preservation of the robot.
Reference: [59] <author> A. C. Clarke, </author> <title> 2001 A Space Odyssey. </title> <address> New York, NY: New American Library, </address> <publisher> Inc., </publisher> <year> 1968. </year> <title> based on the 1965 screenplay by S. </title> <editor> Kubrick and A. C. Clarke. </editor> <volume> 25 </volume>
Reference-contexts: somewhat more sinister scenario of an emotional machine occurs in the science fiction classic "2001: A Space Odyssey." 14 A HAL 9000 computer, "born" January 12, 1997 (in the novel) 14 The film was based on the 1965 screenplay by Kubrick and Clarke; Clarke's novel came out afterward in 1968 <ref> [59] </ref>. is the brain and central nervous system of the spaceship Dis- covery. The computer, who prefers to be called "Hal," has perceptual abilities which emulate those of a human. Hal is a true "thinking machine," in the sense of mimicking both cognitive and emotional functions.
Reference: [60] <author> D. R. Hofstadter, </author> <title> Godel, Escher, Bach: an Eternal Golden Braid. </title> <address> New York, NY: </address> <publisher> Basic Books, Inc. Publishers, </publisher> <year> 1979. </year>
Reference-contexts: It is also commonly agreed that creativity and flexibility are necessary components of intelligence <ref> [60] </ref>. However, how to construct such qualities based on AI-style rules or without gratuitous randomness has so far eluded scientists. I think that the construction of such qualities will require mechanisms that duplicate both limbic abilities and cortical abilities.
Reference: [61] <author> G. W. V. </author> <title> Leibniz, </title> <booktitle> Monadology and Other Philosophical Essays. </booktitle> <address> Indianapolis: </address> <publisher> The Bobbs-Merrill Company, Inc., </publisher> <year> 1965. </year> <title> Essay: Critical Remarks Concerning the General Part of Descartes' Principles (1692), Translated by: </title> <editor> P. Schrecker and A. M. </editor> <publisher> Schrecker. </publisher>
Reference-contexts: but affective computers Man's greatest perfection is to act reasonably no less than to act freely; or rather, the two are one and the same, since he is the more free the less the use of his reason is troubled by the influence of passion. - Gottfried Wilhelm Von Leibniz <ref> [61] </ref> Although expressing and recognizing affect are important for computer-human interaction, building emotion into the motivational behavior of the computer is a different issue. In fact the word "emotional" when it refers to people or to computers, usually connotes an undesirable reduction in rationality.
Reference: [62] <author> A. H. </author> <year> (1894-1963), </year> <title> Brave new world & Brave new world revisited. </title> <address> New York, NY: </address> <publisher> Harper & Row, </publisher> <year> 1965. </year>
Reference-contexts: the computer respond when you make an error the first time? The Nth time? When you do something well? How should it adapt its responses to optimize your learning experience? Merely adapting to "always please" the user is naive, and conjures up the soma-dependent society of Huxley's Brave New World <ref> [62] </ref>. Indeed, the answers to these questions go beyond affective computing, into questions of learning, epistemology, and more. In some cases, this third issue opens up social and ethical questions.
Reference: [63] <author> S. Tucker, </author> <year> 1995. </year> <title> Media Lab Spring Colloquium. </title>
Reference-contexts: However, the hurdle has already been leaped in some of the cases described below. 5.1 Entertainment Why I do so well is I induce emotion. - Sean D. Tucker, American aviation artist <ref> [63] </ref> One of the world's most popular forms of entertainment is large sporting events whether it is an outdoor air show, the Olympics, the World Series, Super Bowl, or any number of other large gatherings, there is an excitement in the air when fans come together to watch athletes perform.
Reference: [64] <author> T. Machover, "Hyperinstruments: </author> <title> A composer's approach to the evolution of intelligent musical instruments," </title> <booktitle> CyberArts, </booktitle> <pages> pp. 67-76, </pages> <month> Jan. </month> <year> 1992. </year>
Reference-contexts: For example, the floors in the intermission gathering spaces might be live compositions, waiting to sense the mood of the audience and amplify it with music. The environment itself might become a new musical instrument, perhaps like one of Machover's hyperinstruments <ref> [64] </ref>, but equipped to sense affect directly, augmenting the modes of expression available to the performer.
Reference: [65] <author> S. Mann, </author> <title> "`See the world through my eyes,' a wearable wireless camera," </title> <note> 1995. http://www-white.media.mit.edu/~steve/netcam.html. </note>
Reference-contexts: If the affective sensors were wearable, and perhaps seeing everything you see (See <ref> [65] </ref> for examples of these sensors), then they might correlate visual experiences with heart rate, respiration, and other forms of sentic modulation.
Reference: [66] <author> J. E. Cahn, </author> <title> "The generation of affect in synthesized speech," </title> <journal> Journal of the American Voice I/O Society, </journal> <volume> vol. 8, </volume> <month> July </month> <year> 1990. </year>
Reference-contexts: the three categories of voice quality, utterance timing, and utterance pitch contour. (Murray and Arnott [26] provide a recent review of these features.) Although virtually no work seems to have been done on computer analysis of affect in voices, several features have been demonstrated for synthesizing intonation in computer-generated speech <ref> [66] </ref>, [26]. With a suitable affective voice, computers can communicate in a more natural and social way with humans. Monotonous voice mail recordings and voice-reminder systems could vary their voices from day-to-day, like a human voice varies.
Reference: [67] <author> I. A. Essa, </author> <title> Analysis, Interpretation and Synthesis of Facial Expressions. </title> <type> PhD thesis, </type> <institution> MIT Media Lab, </institution> <address> Cambridge, MA, </address> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: Another form of affective computing that has already met with some success involves facial expression recognition. Faces appear to be the most important means for visual communication of emotion. Emotion-modeled faces can be used to give computers graphical faces which mimic the emotive expressions identified by Ekman <ref> [67] </ref>, making the computer faces seem more 18 human. Several categories of human facial expression can be recognized by computers, both from still images [68] and from motion images [69], [67], the latter which is more reliable. The encoding of facial expression parameters [67], [70] may also provide a simultaneously efficient <p> Emotion-modeled faces can be used to give computers graphical faces which mimic the emotive expressions identified by Ekman <ref> [67] </ref>, making the computer faces seem more 18 human. Several categories of human facial expression can be recognized by computers, both from still images [68] and from motion images [69], [67], the latter which is more reliable. The encoding of facial expression parameters [67], [70] may also provide a simultaneously efficient and meaningful description for video compression, two attributes that satisfy important criteria for future coding systems [71]. <p> mimic the emotive expressions identified by Ekman <ref> [67] </ref>, making the computer faces seem more 18 human. Several categories of human facial expression can be recognized by computers, both from still images [68] and from motion images [69], [67], the latter which is more reliable. The encoding of facial expression parameters [67], [70] may also provide a simultaneously efficient and meaningful description for video compression, two attributes that satisfy important criteria for future coding systems [71].
Reference: [68] <author> G. W. Cottrell and J. Metcalfe, "EMPATH: </author> <title> Face, emotion, and gender recognition using holons," in Neural Information Processing Systems (R. </title> <editor> P. Lippmann, J. E. Moody, D. S. Touretzky, and B. M. Spatz, eds.), </editor> <volume> vol. </volume> <pages> 3, </pages> <address> (San Mateo, CA), </address> <pages> pp. 564-571, </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1991. </year>
Reference-contexts: Emotion-modeled faces can be used to give computers graphical faces which mimic the emotive expressions identified by Ekman [67], making the computer faces seem more 18 human. Several categories of human facial expression can be recognized by computers, both from still images <ref> [68] </ref> and from motion images [69], [67], the latter which is more reliable. The encoding of facial expression parameters [67], [70] may also provide a simultaneously efficient and meaningful description for video compression, two attributes that satisfy important criteria for future coding systems [71].
Reference: [69] <author> Y. Yacoob and L. Davis, </author> <title> "Computing spatio-temporal rep-resentations of human faces," </title> <booktitle> in Computer Vision and Pattern Recognition Conference, </booktitle> <pages> pp. 70-75, </pages> <publisher> IEEE Computer Society, </publisher> <year> 1994. </year>
Reference-contexts: Emotion-modeled faces can be used to give computers graphical faces which mimic the emotive expressions identified by Ekman [67], making the computer faces seem more 18 human. Several categories of human facial expression can be recognized by computers, both from still images [68] and from motion images <ref> [69] </ref>, [67], the latter which is more reliable. The encoding of facial expression parameters [67], [70] may also provide a simultaneously efficient and meaningful description for video compression, two attributes that satisfy important criteria for future coding systems [71].
Reference: [70] <author> S. Morishima, </author> <title> "Emotion model A criterion for recogni-tion, synthesis and compression of face and emotion." 1995 Int. Workshop on Face and Gesture Recognition, </title> <note> to Appear. </note>
Reference-contexts: Several categories of human facial expression can be recognized by computers, both from still images [68] and from motion images [69], [67], the latter which is more reliable. The encoding of facial expression parameters [67], <ref> [70] </ref> may also provide a simultaneously efficient and meaningful description for video compression, two attributes that satisfy important criteria for future coding systems [71].
Reference: [71] <author> R. W. </author> <title> Picard, "Content access for image/video coding: `The Fourth Criterion'," </title> <type> Tech. Rep. 295, </type> <institution> MIT Media Lab, Perceptual Computing, </institution> <address> Cambridge, MA, </address> <year> 1994. </year> <title> MPEG Doc. </title> <type> 127, </type> <institution> Lausanne, </institution> <year> 1995. </year>
Reference-contexts: The encoding of facial expression parameters [67], [70] may also provide a simultaneously efficient and meaningful description for video compression, two attributes that satisfy important criteria for future coding systems <ref> [71] </ref>.
Reference: [72] <author> B. Reeves, </author> <type> "Personal communication, </type> <institution> MIT Media Lab Colloquium," </institution> <year> 1995. </year>
Reference-contexts: The problem of locating a remembered scene, or an image with particularly interesting content, is also the problem of un <p>- derstanding causes of arousal, one of the key dimensions of affect. Arousal (excited/calm) has been found to be a better predictor of memory retention than valence (pleasure/displeasure) <ref> [72] </ref>. Image descriptions given in Fig. 2 indicate associations of arousal with image content. In fact, finding digital photographs having a particular "mood" was the most frequent request of advertising customers in a study of image retrieval made with the Kodak Picture Ex- change [73].
Reference: [73] <author> D. Romer, </author> <title> "The Kodak picture exchange," </title> <month> April </month> <year> 1995. </year> <institution> seminar at MIT Media Lab. </institution>
Reference-contexts: Image descriptions given in Fig. 2 indicate associations of arousal with image content. In fact, finding digital photographs having a particular "mood" was the most frequent request of advertising customers in a study of image retrieval made with the Kodak Picture Ex- change <ref> [73] </ref>. Subject and action content, which were most frequently requested for editorial purposes, can also be a powerful contributor to mood in a photo [46].
Reference: [74] <author> R. W. Picard and T. P. Minka, </author> <title> "Vision texture for anno-tation," </title> <journal> Journal of Multimedia Systems, </journal> <volume> vol. 3, </volume> <pages> pp. 3-14, </pages> <year> 1995. </year>
Reference-contexts: We have recently built some of the first computer vision tools that enable computers to assist humans in annotating video, attaching descriptions to images that the person and computer both "see" <ref> [74] </ref>.
Reference: [75] <author> T. P. Minka and R. W. </author> <title> Picard, "Interactive learning us-ing a `society of models'," </title> <note> Submitted for Publication, 1995. Also appears as MIT Media Lab Perceptual Computing TR#349. </note>
Reference-contexts: Instead of the user tediously entering all the descriptions by hand, our algorithms learn which user-generated descriptions correspond to which image features, and then try to identify and label other "similar" content. 18 Affective computing can be coupled with learning systems such as that of Minka and Picard <ref> [75] </ref>, to begin to identify not only which content is most salient or interesting, but also which emotions tend to be evoked by the content. Successful learning algorithms for content-based similarity may also be able to learn examples of affect or mood similarity.
Reference: [76] <author> B. W. Kort, </author> <year> 1995. </year> <type> Personal Communication. </type>
Reference-contexts: Barry Kort, a mentor of children exploring and constructing scientific worlds on the MUSE 19 and a volunteer for nearly a decade in the Discovery Room of the Boston Museum of Sci- ence, says that learning is the quintessential emotional experience <ref> [76] </ref>. Kort says his goal is to maximize intrigue the fascination stage and to minimize anxiety. Whatever her strategy, the good teacher detects important affective cues from the student and responds differently because of them.
Reference: [77] <author> D. O. Hebb, </author> <title> A Textbook of Psychology. Philadelphia: </title> <editor> W. B. </editor> <publisher> Saunders Co., </publisher> <year> 1966. </year>
Reference-contexts: Affect has been largely ignored in theories of learning, perhaps because it is hard to measure. Like in all activities that demand mental performance, we know emotion is a determining factor. Hebb showed the classic inverted-U curve in <ref> [77] </ref> relating performance to arousal. Performance is lowest when the subject is awaking or when the subject is aroused to the point of emotional disturbance; performance is optimized at an intermediate state of arousal.
Reference: [78] <author> K. Hooper, </author> <title> "Perceptual aspects of architecture," in Handbook of Perception: </title> <editor> Perceptual Ecology (E. C. Carterette and M. P. Friedman, eds.), </editor> <volume> vol. </volume> <pages> X, </pages> <address> (New York, NY), </address> <publisher> Academic Press, </publisher> <year> 1978. </year>
Reference-contexts: These responses apply to all environments not just your building, home, or office, but also your computer software environment with its "look and feel," the interior of your automobile, and all the appliances with which you surround and augment yourself. What makes you prefer one environment to another? Hooper <ref> [78] </ref> identified three kinds of responses to architecture, which I think hold true for all environments: (1) cognitive and perceptual - "hear/see," (2) symbolic and inferential - "think/know," and (3) affective and evaluative - "feel/like." Perceptual computing (primarily computer vision and audition) and artificial intelligence have been largely concerned with measuring
Reference: [79] <author> S. Brand, </author> <title> How buildings learn: what happens after they're built. </title> <address> New York, NY: </address> <publisher> Viking Press, </publisher> <year> 1994. </year>
Reference-contexts: Affective computing addresses the third. In trying to understand what designs bring long-term satisfaction in his recent book Buildings that Learn <ref> [79] </ref>, Stewart Brand emphasizes not the role of buildings as space, but their role in time. Brand applauds the architect who listens to and learns from post-occupancy surveys.
Reference: [80] <author> A. Tarkovsky, </author> <title> Sculpting in Time: Reflections on the Cinema. London: Faber and Faber, 1989. </title> <editor> ed. by K. </editor> <publisher> HunterBlair. </publisher>
Reference-contexts: impossible to convince anyone that you are right if the created images have left him cold, if they have failed to win him with a newly discovered truth about the world and about man, if in fact, face to face with the work, he was simply bored. - Andrey Tarkovsky <ref> [80] </ref> As creation is related to the creator, so is the work of art related to the law inherent in it. The work grows in its own way, on the basis of common, universal rules, but it is not the rule, not universal a priori.
Reference: [81] <author> P. Klee, </author> <title> The Thinking Eye. </title> <address> New York, NY: George Wittenborn, </address> <year> 1961. </year> <note> Edited by Jurg Spiller, Translated by Ralph Manheim from the German `Das bildnerische Denken'. </note>
Reference-contexts: The work grows in its own way, on the basis of common, universal rules, but it is not the rule, not universal a priori. The work is not law, it is above the law. - Paul Klee <ref> [81] </ref> Psychology, sociology, ethnology, history, and other sciences have attempted to describe and explain artistic phenomena. Many have attempted to understand what constitutes beauty, and what leads to an aesthetic judgement. The elusiveness and complexity of aesthetics is due, in part, to the fact that affect plays a primary role.
Reference: [82] <author> S. K. Langer, </author> <title> Mind: </title> <booktitle> An Essay on Human Feeling, </booktitle> <volume> vol. </volume> <pages> 1. </pages> <address> Baltimore: </address> <publisher> The Johns Hopkins Press, </publisher> <year> 1967. </year>
Reference-contexts: have taken a hard stance in seeking to understand projective feeling in art: There is, however, no basic vocabulary of lines and colors, or elementary tonal structures, or poetic phrases, with conventional emotive meanings, from which complex expressive forms, i.e., works of art, can be composed by rules of manipulation. <ref> [82] </ref> Despite Langer's claim, neither do we experience aesthetic pleasure without the pixels, lines, notes and rhythms.
Reference: [83] <author> M. Clynes, </author> <title> "Microstructural musical linguistics: com-posers' pulses are liked most by the best musicians," </title> <journal> Cognition, </journal> <volume> vol. 55, </volume> <pages> pp. 269-310, </pages> <year> 1995. </year>
Reference-contexts: Moreover, Clynes does seem to have found a set of mechanisms from which complex expressive forms can be produced, as evidenced in his musical Turing test; this is further collaborated with his recent studies indicating the significant role of composer's pulses in appreciation of music <ref> [83] </ref>. Just thinking of a magnificent painting or piece of music does not usually arouse the same emotions as when one is actually experiencing the work, but it may arouse similar, fainter emotions. Beethoven still composed some of the greatest music in the world after he could no longer hear.
Reference: [84] <author> X. Yang, </author> <title> "Visual balance: The tightrope of computer gen-erated layout," </title> <type> Master's thesis, </type> <institution> MIT, </institution> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Design is not solely a rule-based process, and computer tools to assist with design only help explore a space of possibilities. Today's tools, e.g., in graphic design, incorporate principles of physics and computer vision to both judge and modify qualities such as balance, symmetry and disorder <ref> [84] </ref>. But the key missing objective of these systems is the goal of arousing an experience in the user arousing to provoke attention, interest, memory, and new experiences.
Reference: [85] <author> M. Clynes and N. S. Kline, </author> <title> "Cyborgs and space," </title> <journal> Astronautics, </journal> <volume> vol. 14, </volume> <pages> pp. 26-27 and 74-76, </pages> <month> Sept. </month> <year> 1960. </year>
Reference: [86] <author> T. E. Starner, </author> <title> "Wearable computing," Perceptual Computing Group, Media Lab 318, </title> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: Wearable computers can augment your memory (any computer accessible information available as you need it) <ref> [86] </ref> or your reality (zooms in when you need to see from the back of the room). Your wearable camera could recognize the face of the person walking up to you, and remind you of his or her name and where you last met.
Reference: [87] <author> N. Gershenfeld and M. Hawley, </author> <year> 1994. </year> <type> Personal Communication. </type>
Reference-contexts: Your wearable camera could recognize the face of the person walking up to you, and remind you of his or her name and where you last met. Signals can be passed from one wearable to the other through your conductive "BodyNet" <ref> [87] </ref>. A handshake could instantly pass to my online memory the information on your business card. 20 Note that these examples are not science fiction; all of these functions or their basic technologies have been realized in present research in the MIT Media Laboratory.
Reference: [88] <author> O. S. Card, </author> <title> Speaker for the Dead. </title> <address> New York, NY: </address> <publisher> Tom Doherty Associates, Inc., </publisher> <year> 1986. </year>
Reference-contexts: An Orson Scott Card science fiction novel <ref> [88] </ref> features a sentient being named Jane that speaks from a jewel in the ear of Ender, the hero of the story. To Jane, Ender is her brother, as well as dearest friend, lover, husband, father, and child.
Reference: [89] <author> J. J. Wurtman, </author> <title> Managing your mind and mood through food. </title> <address> New York: </address> <publisher> Rawson Associates, </publisher> <year> 1986. </year>
Reference-contexts: The mood recognition might trigger an offer of information, such as the news (via the network) that the local florist just received a delivery of your spouse's favorite protea. A mood detector might make suggestions about what foods to eat, so called "mood foods" <ref> [89] </ref>, and collect information continuously through the diet, contributing to our ongoing understanding of biochemical influences on mood. Affective wearables offer possibilities of new health and medical research opportunities and applications. Medical studies could move from measuring controlled situations in labs, to measuring more realistic situations in life.
Reference: [90] <author> G. Mandler, </author> <title> Mind and Body: Psychology of Emotion and Stress. </title> <address> New York, NY: </address> <publisher> W. W. Norton & Company, </publisher> <year> 1984. </year>
Reference-contexts: In this paper I have argued that emotions can no longer be considered a luxury when studying essential rational cognitive processes; 21 See <ref> [90] </ref> for a discussion of emotions and stress. 23 instead, recent neurological evidence indicates they are neces-sary not only in human creativity and intelligence, but also in rational human thinking and decision-making.
Reference: [91] <author> D. A. Norman, </author> <title> "Twelve issues for cognitive science," </title> <booktitle> in Perspectives on Cognitive Science (D. </booktitle> <editor> A. Norman, ed.), </editor> <address> (Hillsdale, NJ), </address> <pages> pp. 265-295, </pages> <publisher> Erlbaum, </publisher> <year> 1981. </year> <month> 26 </month>
Reference-contexts: the wearer to share this information with researchers, a wealth of important data could be gathered for furthering theories of learning, intelligence, perception, diet, exercise, communication, mental health, and more. 6 Summary Emotion was identified by Donald Norman in 1981 as one of the twelve major challenges for cognitive science <ref> [91] </ref>.
References-found: 91

