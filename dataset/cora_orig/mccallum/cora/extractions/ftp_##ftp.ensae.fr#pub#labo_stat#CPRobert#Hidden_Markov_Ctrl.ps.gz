URL: ftp://ftp.ensae.fr/pub/labo_stat/CPRobert/Hidden_Markov_Ctrl.ps.gz
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Convergence controls for MCMC algorithms, with applications to hidden Markov chains  
Author: Christian P. Robert, Tobias Ryd en, and D.M. Titterington 
Keyword: allocation; backward formula; Kolmogorov-Smirnov tests; mixture model; normality test; Spearman independence test; stationarity; subsampling.  
Affiliation: CREST-INSEE, Paris, Lund University, and University of Glasgow  
Abstract: In complex models like hidden Markov chains, the convergence of the MCMC algorithms used to approximate the posterior distribution and the Bayes estimates of the parameters of interest must be controlled in a robust manner. We propose in this paper a series of on-line controls, which rely on classical non-parametric tests, to evaluate independence from the start-up distribution, stability of the Markov chain, and asymptotic normality. These tests lead to graphical control spreadsheets which are presented in the set-up of normal mixture hidden Markov chains to compare the full Gibbs sampler with an aggregated Gibbs sampler based on the forward-backward formulae. 
Abstract-found: 1
Intro-found: 1
Reference: <editor> Aldous, D. & Thorisson, H. </editor> <booktitle> (1993) Shift-coupling. Stochastic Processes and Their Applications 44, </booktitle> <pages> 1-14. </pages>
Reference-contexts: Since both processes are ergodic, we can construct them on a common probability space in such a way that there are two a.s. finite random times t and ~t with the property (t+t) = (t+~t) for all t 0 <ref> (Aldous and Thorisson, 1993, Theorem 3) </ref>. This construction is called a shift-coupling.
Reference: <author> Baum, L.E., Petrie, T., Soules, G. & Weiss, N. </author> <title> (1970) A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains. </title> <journal> Annals of Mathematical Statistics 41, </journal> <pages> 164-171. </pages>
Reference: <author> Billingsley, P. </author> <title> (1968) Convergence of Probability Measures. </title> <editor> J. </editor> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: Moreover, the expectations j = IE [z j ] and variances ! j = var (z j ) can be approximated by Rao-Blackwellization, i.e. by conditioning on the parameters. Another advantage of such settings is that geometric ff-mixing holds naturally, given that the z j 's have finite support <ref> (Billingsley, 1968, Diebolt and Robert, 1994) </ref>.
Reference: <author> Brooks, S. & Roberts, G. </author> <title> (1995) Diagnosing convergence of Markov chain Monte Carlo algorithms. </title> <type> Tech. report 95-12, </type> <institution> Stats. Lab., U. of Cambridge. </institution>
Reference: <author> Casella, G. & Robert, </author> <title> C.P. (1996) Rao-Blackwellisation of sampling schemes. </title> <journal> Biometrika 83, </journal> <pages> 81-94. </pages>
Reference: <author> Chauveau, D. & Diebolt, J. </author> <title> (1997) MCMC convergence diagnosis via the Central Limit Theorem. </title> <type> Tech. report no. 22/97, </type> <institution> U. Marne-la-Vallee. </institution>
Reference: <author> Cowles, </author> <title> M.K. & Carlin, B.P. (1996) Markov Chain Monte-Carlo convergence diagnostics: a comparative study. </title> <journal> Journal of the American Statistical Association 91, </journal> <pages> 883-904. </pages>
Reference: <author> Damien, P., Wakefield, J. & Walker, S. </author> <title> (1997) Gibbs sampling for Bayesian nonconjugate and hierarchical models using auxiliary variables. </title> <type> Tech. report, </type> <institution> Business School, University of Michigan. </institution>
Reference: <author> Diebolt, J. & Robert, </author> <title> C.P. (1993) Discussion of "Bayesian computations via the Gibbs sampler" by A.F.M. </title> <editor> Smith and G. </editor> <title> Roberts. </title> <journal> Journal of the Royal Statistical Society (Series B) 55(1), </journal> <month> 71-72 </month> <year> (1993). </year>
Reference-contexts: For instance, mixing and mixing rates transfer from one chain to the other <ref> (see 5 also, Diebolt and Robert, 1993) </ref>. The above result shows that the convergence control can also be operated on the dual chain (z (t) ). 3. An application to hidden Markov chains 3.1. Model and parameter simulation.
Reference: <author> Diebolt, J. & Robert, </author> <title> C.P. (1994) Estimation of finite mixture distributions by Bayesian sampling. </title> <journal> Journal of the Royal Statistical Society (Series B) 56, </journal> <pages> 363-375. </pages>
Reference: <author> Gelfand, A.E. & Smith, A.F.M. </author> <title> (1990) Sampling based approaches to calculating marginal densities. </title> <journal> Journal of the American Statistical Association 85, </journal> <pages> 398-409. </pages>
Reference-contexts: Moreover, the standard estimates b T and b V T can be replaced by other convergent estimates such as Rao-Blackwellized versions <ref> (see Gelfand and Smith, 1990, or Casella and Robert, 1996) </ref>.
Reference: <author> Gelman, A. & Rubin, </author> <title> D.B. (1992) Inference from iterative simulation using multiple sequences (with discussion). </title> <booktitle> Statistical Science 7, </booktitle> <pages> 457-511. </pages>
Reference: <author> Geyer, C.J. </author> <title> (1992) Practical Monte Carlo Markov Chain (with discussion). </title> <booktitle> Statistical Science 7, </booktitle> <pages> 473-511. </pages>
Reference-contexts: The third stage of convergence control is to decide whether or not empirical averages of the quantities of interest, 1 T X h ( (t) ); (1:1) have properly converged to the Bayes estimate IE [h ()]. Since most MCMC algorithms produce chains which satisfy the Central Limit Theorem <ref> (see Geyer, 1992, or Roberts and Rosenthal, 1997, for theoretical issues) </ref>, we link our assessment to a normality check for the standardised version of (1.1).
Reference: <author> Gut, A. </author> <title> (1988) Stopped Random Walks. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference: <author> Ibragimov, I.A. & Linnik, Y.V. </author> <title> (1971) Independent and Stationary Sequences of Random Variables. </title> <address> Wolters-Noordhoff, Groningen. </address>
Reference: <author> Leadbetter, M.R. & Rootzen, H. </author> <title> (1993) On central limit theory for families of strongly mixing additive random functions. In Stochastic Processes. A Festschrift in Honour of Gopinath Kallian-pur, </title> <editor> S. Cambanis, J.K. Ghosh, R.L. Karandikar and P.K. Sen, (Eds.), </editor> <address> 221-223, </address> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference: <author> Levene, H. </author> <title> (1960) In Contributions to Probability and Statistics: </title> <editor> Essays in Honor of Harold Hotelling (I. Olkin et al., eds.). </editor> <publisher> Stanford University Press, Stanford, </publisher> <pages> 278-292. </pages>
Reference-contexts: The second test aims at comparing the variances and, given the lack of normality of most samples, we opted for Levene's test, which is reputed to be robust to departures from normality <ref> (Levene, 1960) </ref>, and is based on the comparison of intra- and inter-variations of the absolute 14 errors jx i xj and jy i yj.
Reference: <author> Mengersen, K. & Robert, </author> <title> C.P. (1996) Testing for mixtures: a Bayesian entropic approach. In Bayesian Statistics 5, J.O. Berger, J.M. </title> <type> Bernardo, A.P. Dawid, </type> <institution> D.V. Lindley and A.F.M. </institution>
Reference-contexts: The scale parameter has a limited influence on the resulting inference when chosen in the range 0.1-10 <ref> (see Mengersen and Robert, 1996, and Robert and Titterington, 1998) </ref>. The associated Gibbs sampler is then straightforward.
Reference: <editor> Smith (Eds.), </editor> <address> 255-276. </address> <publisher> Oxford University Press, London. </publisher>
Reference: <author> Meyn, S.P. & Tweedie, </author> <title> R.L. (1993) Markov Chains and Stochastic Stability. </title> <publisher> Springer-Verlag, London. </publisher>
Reference-contexts: Then S T converges weakly to the standard normal distribution. The proof is given in the appendix. We remark that the condition of geometrically decaying mixing coefficients is quite mild <ref> (see Meyn and Tweedie, 1993, Chapter 16) </ref>. In fact, every positive recurrent aperiodic Markov chain is strongly mixing (Rosenblatt, 1971). Note also that the Lyapounov condition on h () is a sufficient condition for the regular CLT to hold on %-mixing (Rosenblatt, 1971).
Reference: <author> Oodaira, H. & Yoshihara, K.-I. </author> <title> (1971) The law of the iterated logarithm for stationary processes satisfying mixing conditions. </title> <booktitle> Kodai Mathematical Seminar Reports 23, </booktitle> <pages> 311-334. </pages>
Reference-contexts: We now turn to the estimation of the mean = IE [h ()]. First note that (h ( e (t) )) satisfies the law of the iterated logarithm <ref> (Oodaira and Yoshihara, 1971, Theorem 5) </ref>, i.e., with R T = P T T being the variance of this sum, lim sup jR T j= r 2 T = 1 T = O (T ) (this follows from the mixing condition), whence lim sup jR T j= T log log T
Reference: <author> Raftery, A.E. & Lewis, S. </author> <title> (1996) Implementing MCMC. In Markov chain Monte-Carlo in Practice (Ed. W.R. Gilks, S.T. Richardson and D.J. </title> <booktitle> Spiegelhalter), </booktitle> <pages> 115-130. </pages> <publisher> Chapman and Hall, </publisher> <address> 22 London. </address>
Reference: <author> Rio, E. </author> <title> (1993) A maximal inequality and dependent Marcinkiewicz-Zygmund strong laws. </title> <journal> Annals of Probability 23, </journal> <pages> 918-937. </pages>
Reference: <author> Robert, </author> <title> C.P. (1995a) Convergence control techniques for MCMC algorithms. </title> <booktitle> Statistical Science 10, </booktitle> <pages> 231-253. </pages>
Reference-contexts: Central Limit test. In most set-ups, the ultimate goal of an MCMC algorithm is to derive approximations of posterior expectations of interest IE [h ()] by empirical averages (1.1) or equivalent estimates <ref> (see, e.g., Robert, 1995a) </ref>.
Reference: <author> Robert, </author> <title> C.P. (1995b) Simulation of truncated normal variables. </title> <journal> Statistics and Computing 5, </journal> <pages> 121-125. </pages>
Reference: <author> Robert, </author> <title> C.P. (1996) Methodes de Monte-Carlo par cha^nes de Markov. </title> <address> Economica, Paris. </address>
Reference-contexts: This set-up is thus a further illustration of the Duality Principle introduced by Diebolt and Robert (1994) to show that, in cases where the chain of interest ( (t) ) is generated conditionally on a secondary and simple chain (z (t) ), as in mixtures or capture-recapture models <ref> (see Robert, 1996) </ref>, most properties of the simple chain transfer to the chain of interest. For instance, mixing and mixing rates transfer from one chain to the other (see 5 also, Diebolt and Robert, 1993). <p> The scale parameter has a limited influence on the resulting inference when chosen in the range 0.1-10 <ref> (see Mengersen and Robert, 1996, and Robert and Titterington, 1998) </ref>. The associated Gibbs sampler is then straightforward.
Reference: <author> Robert, C.P., Celeux, G. & Diebolt, J. </author> <title> (1993) Bayesian estimation of Hidden Markov Models: a stochastic implementation. </title> <journal> Statistics & Probability Letters 16, </journal> <pages> 77-83. </pages>
Reference-contexts: For instance, mixing and mixing rates transfer from one chain to the other <ref> (see 5 also, Diebolt and Robert, 1993) </ref>. The above result shows that the convergence control can also be operated on the dual chain (z (t) ). 3. An application to hidden Markov chains 3.1. Model and parameter simulation.
Reference: <author> Robert, C.P., Chauveau, D., Diebolt, J., Gruet, M., Guihenneuc, C., Philippe, A. & Richardson, S. </author> <title> (1997) Control of MCMC algorithms via finite state spaces Markov chains. </title> <booktitle> Lecture Notes in Statistics, </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York (in preparation). </address>
Reference-contexts: While Chauveau and Diebolt (1997) need discretized versions of parallel chains to run their assessment <ref> (see also Robert et al., 1997) </ref>, we propose here a simpler version based on a subchain of ( (t) ).
Reference: <author> Robert, </author> <title> C.P. & Titterington, D.M. (1998) Reparameterisation strategies for hidden Markov models and Bayesian approaches to maximum likelihood estimation. </title> <note> Statistics and Computing (to appear). </note>
Reference-contexts: A reparameterization strategy introduced in Mengersen and Robert (1996) justifies the prior modelling (; ; P) / 1 1 k1 X 2 ! which moreover leads to a proper posterior distribution <ref> (see Robert and Titterington, 1998) </ref>.
Reference: <author> Roberts, </author> <title> G.O. & Rosenthal, J.S. (1997) Markov chain Monte Carlo: some practical implications of theoretical results. </title> <type> Tech. report, </type> <institution> Stats. Lab., U. of Cambridge. </institution>
Reference: <author> Rosenblatt, M. </author> <title> (1971) Markov Processes. Structure and Asymptotic Behavior. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address> <month> 23 </month>
Reference-contexts: Then S T converges weakly to the standard normal distribution. The proof is given in the appendix. We remark that the condition of geometrically decaying mixing coefficients is quite mild (see Meyn and Tweedie, 1993, Chapter 16). In fact, every positive recurrent aperiodic Markov chain is strongly mixing <ref> (Rosenblatt, 1971) </ref>. Note also that the Lyapounov condition on h () is a sufficient condition for the regular CLT to hold on %-mixing (Rosenblatt, 1971). <p> In fact, every positive recurrent aperiodic Markov chain is strongly mixing <ref> (Rosenblatt, 1971) </ref>. Note also that the Lyapounov condition on h () is a sufficient condition for the regular CLT to hold on %-mixing (Rosenblatt, 1971). If the mixing coefficients of ( (t) ) decay slower than geometrically, the conclusion of Theorem 2.1 still holds true if -k grows sufficiently fast and/or the Poisson distribution is replaced by a different one.
References-found: 31

