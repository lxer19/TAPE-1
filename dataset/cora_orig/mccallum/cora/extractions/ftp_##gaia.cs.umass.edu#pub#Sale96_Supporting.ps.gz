URL: ftp://gaia.cs.umass.edu/pub/Sale96:Supporting.ps.gz
Refering-URL: http://www-net.cs.umass.edu/papers/papers.html
Root-URL: 
Email: fsalehi,zhzhang,kurose,towsleyg@cs.umass.edu  
Title: Supporting Stored Video: Reducing Rate Variability and End-to-End Resource Requirements through Optimal Smoothing  
Author: James D. Salehi, Zhi-Li Zhang, James F. Kurose, and Don Towsley 
Address: Amherst, MA, 01003 USA  
Affiliation: Department of Computer Science, University of Massachusetts,  
Date: May 1996  
Note: To appear in Proc. ACM SIGMETRICS,  
Abstract: VBR compressed video is known to exhibit significant, multiple-time-scale bit rate variability. In this paper, we consider the transmission of stored video from a server to a client across a high speed network, and explore how the client buffer space can be used most effectively toward reducing the variability of the transmitted bit rate. We present two basic results. First, we present an optimal smoothing algorithm for achieving the greatest possible reduction in rate variability when transmitting stored video to a client with given buffer size. We provide a formal proof of optimality, and demonstrate the performance of the algorithm on a set of long MPEG-1 encoded video traces. Second, we evaluate the impact of optimal smoothing on the network resources needed for video transport, under two network service models: Deterministic Guaranteed service [1, 9] and Renegotiated CBR (RCBR) service [8, 7]. Under both models, we find the impact of optimal smoothing to be dramatic. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. S. Chang. </author> <title> Stability, Queue Length, and Delay of Deterministic and Stochastic Queueing Networks. </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> 39(5) </volume> <pages> 913-931, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: These benefits can be realized by small, uniprocessor servers as well as large, scalably-parallel ones. We then evaluate the impact on network performance when streams are optimally smoothed, considering two network service models: Deterministic Guaranteed service <ref> [1, 9] </ref>, which provides hard guarantees, and Renegotiated CBR (RCBR) [8, 7], which adds a renegotiation mechanism to traditional CBR service. We find that optimal smoothing yields dramatic improvement in performance 1 under both models. The paper is organized as follows. <p> Data is consumed from the buffer after any arrivals at t. D (t) : Cumulative data consumed by the client over <ref> [1; t] </ref>: P t a (t) : Amount of data sent by the server at time t. A (t) : Cumulative data sent by the server over [1; t]: P t B (t) : Maximum cumulative data that can be received by the client over [1; t], without buffer overflow: B <p> Data is consumed from the buffer after any arrivals at t. D (t) : Cumulative data consumed by the client over <ref> [1; t] </ref>: P t a (t) : Amount of data sent by the server at time t. A (t) : Cumulative data sent by the server over [1; t]: P t B (t) : Maximum cumulative data that can be received by the client over [1; t], without buffer overflow: B (t) = minfD (t 1) + b; D (N )g for t = 2; : : : ; N , B (1) = b, B (0) = <p> consumed by the client over <ref> [1; t] </ref>: P t a (t) : Amount of data sent by the server at time t. A (t) : Cumulative data sent by the server over [1; t]: P t B (t) : Maximum cumulative data that can be received by the client over [1; t], without buffer overflow: B (t) = minfD (t 1) + b; D (N )g for t = 2; : : : ; N , B (1) = b, B (0) = 0. (B (t) need not lie at a fixed offset above D (t); see text.) Table 1: Notation <p> Table 1 summarizes the relevant notation. We say the N -dimensional real vector S = [a (1); : : : ; a (N )] represents a feasible server transmission schedule over <ref> [1; N ] </ref> if 1) the server sends exactly the amount of data required by the client, or t=1 a (t) = D (N ), and 2) the client buffer neither starves nor overflows during stream playback, or D (t) A (t) B (t) for all t (see Table 1). <p> the transmission schedule for a 1024 KB buffer consisting of a relatively small number of CBR segments. 1 Specifically, set N 0 = N + s, d 0 (t) = d (t s) for t 2 [s + 1; N 0 ], d 0 (t) = 0 for t 2 <ref> [1; s] </ref>, and define D (t) = P t d 0 (t) and B (t) over [1; N 0 ]. Note that the introduction of startup latency is optional. with 500ms startup delay, across client buffer sizes ranging from 64-4096 KB. smoothing (500ms startup delay). <p> segments. 1 Specifically, set N 0 = N + s, d 0 (t) = d (t s) for t 2 [s + 1; N 0 ], d 0 (t) = 0 for t 2 [1; s], and define D (t) = P t d 0 (t) and B (t) over <ref> [1; N 0 ] </ref>. Note that the introduction of startup latency is optional. with 500ms startup delay, across client buffer sizes ranging from 64-4096 KB. smoothing (500ms startup delay). <p> Definition 1 Given n-dimensional real vectors X = [x 1 ; : : : ; x n ] and Y = [y 1 ; : : : ; y n ], let x <ref> [1] </ref> ; : : : ; x [n] and y [1] ; : : : ; y [n] denote the non-increasing orderings (i.e., arrangement of vector elements from largest to smallest) of X and Y , respectively. <p> Definition 1 Given n-dimensional real vectors X = [x 1 ; : : : ; x n ] and Y = [y 1 ; : : : ; y n ], let x <ref> [1] </ref> ; : : : ; x [n] and y [1] ; : : : ; y [n] denote the non-increasing orderings (i.e., arrangement of vector elements from largest to smallest) of X and Y , respectively. <p> X is said to be majorized by Y , or X Y , if P t P t 1; 2; : : : n 1, and i=1 x [i] = i=1 y [i] . For example, if X = [2; 3; 3; 2] and Y = <ref> [1; 8; 1; 0] </ref>, then X Y . X does appear to be smoother than Y . If X = [12; 3; 7] and Y = [2; 10; 10], neither X Y nor Y X. <p> Thus, we consider a transmission schedule S 1 to be smoother than schedule S 2 if S 1 S 2 . While variance and peak are commonly-used comparative measures of smoothness, such metrics are in fact subsumed by majorization. Since x <ref> [1] </ref> is by definition max (X), it follows that X Y implies max (X) max (Y ). <p> IR ! IR. 3 Specifically, set N 0 = N + !, d (t) = d (N) for t 2 [N + 1; N 0 ], d 0 (t) = d (t !) for t 2 [! + 1; N 0 ] d 0 (t) = 0 for t 2 <ref> [1; !] </ref>, and define D (t) = P t i=1 d (t) and B (t) = i=1 d 0 (t) + b over [1; N 0 ]. 4 A continuous function is convex if, for all x, y, 0 ff 1; (ffx + (1 ff)y) ff (x) + (1 ff)(y). <p> N 0 ], d 0 (t) = d (t !) for t 2 [! + 1; N 0 ] d 0 (t) = 0 for t 2 [1; !], and define D (t) = P t i=1 d (t) and B (t) = i=1 d 0 (t) + b over <ref> [1; N 0 ] </ref>. 4 A continuous function is convex if, for all x, y, 0 ff 1; (ffx + (1 ff)y) ff (x) + (1 ff)(y). <p> We begin with an overview of the service model, and then turn to performance results. 5.1 Overview Under Guaranteed service, the network provides hard guarantees. Suppose the user requires bounded delay service <ref> [1] </ref>: for each packet sent, the end-to-end delay through the network must not exceed some a priori bound. (This implies that no packets are lost). A call admission algorithm admits the stream into the network only if it can guarantee that the delay bound will never be exceeded. <p> The least upper bound, E (t), is known as the minimum envelope process <ref> [1] </ref> (or empirical envelope [9]). Computed at the frame level for a stored video with N frames, E (t) is given by: E (t) = max k+t X f (j); (1) where f (j) is the size of the j th frame. <p> To address the reduction in network resources required under optimal smoothing, we have considered two important network service models: Guaranteed service (e.g., <ref> [1, 9] </ref>) and Renegotiated CBR service [8]. The impact of work-ahead smoothing (optimal or otherwise) has not previously been evaluated under either model. We find performance of Guaranteed service improves dramatically under optimal smoothing, with network utilizations increasing by as much as a factor of 3 for bursty VBR streams.
Reference: [2] <author> E. Chang and A. Zakhor. </author> <title> Scalable Video Data Placement on Parallel Disk Arrays. </title> <booktitle> IS&T/SPIE Symposium on Electronic Imaging Science and Technology, </booktitle> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: X is said to be majorized by Y , or X Y , if P t P t 1; 2; : : : n 1, and i=1 x [i] = i=1 y [i] . For example, if X = <ref> [2; 3; 3; 2] </ref> and Y = [1; 8; 1; 0], then X Y . X does appear to be smoother than Y . If X = [12; 3; 7] and Y = [2; 10; 10], neither X Y nor Y X. <p> For example, if X = [2; 3; 3; 2] and Y = [1; 8; 1; 0], then X Y . X does appear to be smoother than Y . If X = [12; 3; 7] and Y = <ref> [2; 10; 10] </ref>, neither X Y nor Y X. Thus, we consider a transmission schedule S 1 to be smoother than schedule S 2 if S 1 S 2 . While variance and peak are commonly-used comparative measures of smoothness, such metrics are in fact subsumed by majorization. <p> The call admission algorithm must ensure that the probability of rejection is acceptably low. On a renegotiation failure, the server must adapt to the allocated bandwidth. For stored video, one alternative is to transmit a subset of the stream if it has been scalably compressed <ref> [2] </ref> ; MPEG-2 contains support for limited scalable compression. Another possibility is to dynamically requantize the stream at a lower bit rate. See [8] for references and further discussion.
Reference: [3] <author> R. Cruz. </author> <title> A Calculus for Network Delay, Part I: Network Elements in Isolation. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 37(1) </volume> <pages> 114-131, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: X is said to be majorized by Y , or X Y , if P t P t 1; 2; : : : n 1, and i=1 x [i] = i=1 y [i] . For example, if X = <ref> [2; 3; 3; 2] </ref> and Y = [1; 8; 1; 0], then X Y . X does appear to be smoother than Y . If X = [12; 3; 7] and Y = [2; 10; 10], neither X Y nor Y X. <p> For example, if X = [2; 3; 3; 2] and Y = [1; 8; 1; 0], then X Y . X does appear to be smoother than Y . If X = <ref> [12; 3; 7] </ref> and Y = [2; 10; 10], neither X Y nor Y X. Thus, we consider a transmission schedule S 1 to be smoother than schedule S 2 if S 1 S 2 . <p> In this section, we use A i (t) = E i (t); in [22], we also consider concave upper bounds to E i (t), each specified by a set of (; ) pairs. For FIFO, SP, and EDF link scheduling policies, exact admission control tests are known <ref> [3, 9] </ref>. Assume the n streams are homogeneous (i.e., for all i, A i (t) = A (t)) and require common delay bound d. In this case, FIFO, SP and EDF behave identically, and the admission control test is as follows.
Reference: [4] <author> W. Feng and S. Sechrest. </author> <title> Smoothing and Buffering for Delivery of Prerecorded Compressed Video. </title> <booktitle> IS&T/SPIE Multimedia Computing and Networking, p. </booktitle> <pages> 234-232, </pages> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: See [20] for a precise formulation of these constraints. Work-ahead smoothing does not introduce delay. These techniques are not mutually exclusive, and can be applied in combination and at various points along the end-to-end path from the server to the client <ref> [4, 8, 9, 11, 17, 19, 20, 23] </ref>. In general, network service models may permit only temporal multiplexing [9], only statistical multiplexing [8], or both, as is the case whenever FIFO scheduling with shared buffers is employed at a network switch. <p> Several other papers have examined smoothing of delay-sensitive, online compressed video (e.g., [11, 17, 23]). These approaches always involve the introduction of delay to enable smoothing; see [22] for discussion. For stored video, Feng and Sechrest <ref> [4] </ref> have also considered work-ahead smoothing into client buffer space. They do not, however, consider the problem of optimally-reducing stream variability. Instead, they focus on reducing the number of rate increases required during stream transmission.
Reference: [5] <author> M. Garrett and W. Willinger. </author> <title> Analysis, Modeling and Generation of Self-Similar VBR Video Traffic. </title> <booktitle> Proc. ACM SIGCOMM, p. </booktitle> <pages> 269-280, </pages> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: For continuous playback at the client, strict quality-of-service (QOS) must be provided in an end-to-end manner. Complicating the situation is the fact that variable-bit-rate (VBR) compressed video exhibits significant rate variability, often spanning time scales as coarse as several minutes <ref> [5, 8] </ref>. This burstiness is inherently at odds with the goal of designing efficient real-time storage, retrieval and transport mechanisms capable of achieving high resource utilization. As a general real-time design principle, less bursty (i.e., smoother) workloads are easier to manage. <p> The algorithm has low complexity, is easy to implement, and can be used in a manner that accommodates network jitter. We evaluate its performance on a diverse set of VBR-encoded MPEG-1 traces (one of which has been shown to exhibit self-similarity in its bit rate variation <ref> [5] </ref>), demonstrating reduction in peak rate of 75-87% and in standard deviation of 72-84% for a 1 MB client buffer. These benefits can be realized by small, uniprocessor servers as well as large, scalably-parallel ones. <p> We use traces captured by a number of other researchers <ref> [5, 9, 10, 21] </ref>, who were kind enough to share them with us. <p> In A, this is accomplished by extending the video length by s frames, and shifting both D (t) and B (t) by s units to the right. 1 We begin by optimally smoothing a 2-hour MPEG-1 encoding of Star Wars <ref> [5] </ref>, with 500 ms startup latency. Figure 6 demonstrates the transmission sizes, over the entire video, for the unsmoothed transmission schedule (which has a (t) = d (t)), as well as optimally-smoothed schedules for client buffer sizes of 64 KB and 1024 KB. <p> Acknowledgements We would like to thank the researchers who generously shared their MPEG traces. In particular, the contributions of Ed Knightly [9], Marwan Krunz [10], Mark Garrett <ref> [5] </ref> and Oliver Rose [21] are gratefully acknowledged.
Reference: [6] <author> M. Grossglauser and S. Keshav. </author> <title> On CBR Service, </title> <booktitle> Proc. IEEE IN-FOCOM, </booktitle> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: We begin with an overview of the service model. 6.1 Overview Under CBR network service, the server reserves network resources at the stream's peak rate. While CBR service offers many advantages (e.g., call admission and switch scheduling are simplified <ref> [6] </ref>), static CBRin which the server provides a one-time specification of the peak rate over the duration of the sessiondoes not perform well for VBR-compressed video, since the peak can be much higher than the mean. RCBR adds a bandwidth renegotiation mechanism to static CBR [8, 7]. <p> This corresponds to a mean renegotiation time ranging from 23 minutes down to 14 seconds. The maximum number of unsmoothed streams which can be admitted is also shown. Since network jitter is a much less of an issue under CBR service <ref> [6] </ref>, we assume it is zero.
Reference: [7] <author> M. Grossglauser, S. Keshav and D. Tse. </author> <title> The Case Against Variable Bit Rate Services. </title> <booktitle> Proc. 5 th Workshop on Network and Operating Systems Support for Digital Audio and Video, p. </booktitle> <pages> 307-310, </pages> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: These benefits can be realized by small, uniprocessor servers as well as large, scalably-parallel ones. We then evaluate the impact on network performance when streams are optimally smoothed, considering two network service models: Deterministic Guaranteed service [1, 9], which provides hard guarantees, and Renegotiated CBR (RCBR) <ref> [8, 7] </ref>, which adds a renegotiation mechanism to traditional CBR service. We find that optimal smoothing yields dramatic improvement in performance 1 under both models. The paper is organized as follows. We present the optimal smoothing algorithm in Section 2, and formally establish its optimality in Section 3. <p> For example, if X = [2; 3; 3; 2] and Y = [1; 8; 1; 0], then X Y . X does appear to be smoother than Y . If X = <ref> [12; 3; 7] </ref> and Y = [2; 10; 10], neither X Y nor Y X. Thus, we consider a transmission schedule S 1 to be smoother than schedule S 2 if S 1 S 2 . <p> RCBR adds a bandwidth renegotiation mechanism to static CBR <ref> [8, 7] </ref>. Under RCBR, the server reserves bandwidth at peak rate over intervals of time, and at the end of each interval, renegotiates a new bandwidth reservation. The renegotiation is actually a signaling request to adjust the reserved bandwidth along the end-to-end path. <p> In light of the multiple-time-scale variability of VBR video, there is a growing interest in renegotiated services (e.g., <ref> [8, 7, 24] </ref>). While our study of renegotiated CBR is based directly on the work of Grossglauser, Keshav and Tse [8, 7], our formulation is somewhat different. They simultaneously consider both stored video and video generated online. <p> In light of the multiple-time-scale variability of VBR video, there is a growing interest in renegotiated services (e.g., [8, 7, 24]). While our study of renegotiated CBR is based directly on the work of Grossglauser, Keshav and Tse <ref> [8, 7] </ref>, our formulation is somewhat different. They simultaneously consider both stored video and video generated online. To accommodate the online case, they assume that a fixed amount of per-stream buffering is available, at the server, to smooth the outgoing network transmissions.
Reference: [8] <author> M. Grossglauser, S. Keshav and D. Tse. RCBR: </author> <title> A Simple and Efficient Service for Multiple Time-Scale Traffic. </title> <booktitle> Proc. ACM SIG-COMM, p. </booktitle> <pages> 219-230, </pages> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: For continuous playback at the client, strict quality-of-service (QOS) must be provided in an end-to-end manner. Complicating the situation is the fact that variable-bit-rate (VBR) compressed video exhibits significant rate variability, often spanning time scales as coarse as several minutes <ref> [5, 8] </ref>. This burstiness is inherently at odds with the goal of designing efficient real-time storage, retrieval and transport mechanisms capable of achieving high resource utilization. As a general real-time design principle, less bursty (i.e., smoother) workloads are easier to manage. <p> See [20] for a precise formulation of these constraints. Work-ahead smoothing does not introduce delay. These techniques are not mutually exclusive, and can be applied in combination and at various points along the end-to-end path from the server to the client <ref> [4, 8, 9, 11, 17, 19, 20, 23] </ref>. In general, network service models may permit only temporal multiplexing [9], only statistical multiplexing [8], or both, as is the case whenever FIFO scheduling with shared buffers is employed at a network switch. <p> These techniques are not mutually exclusive, and can be applied in combination and at various points along the end-to-end path from the server to the client [4, 8, 9, 11, 17, 19, 20, 23]. In general, network service models may permit only temporal multiplexing [9], only statistical multiplexing <ref> [8] </ref>, or both, as is the case whenever FIFO scheduling with shared buffers is employed at a network switch. <p> These benefits can be realized by small, uniprocessor servers as well as large, scalably-parallel ones. We then evaluate the impact on network performance when streams are optimally smoothed, considering two network service models: Deterministic Guaranteed service [1, 9], which provides hard guarantees, and Renegotiated CBR (RCBR) <ref> [8, 7] </ref>, which adds a renegotiation mechanism to traditional CBR service. We find that optimal smoothing yields dramatic improvement in performance 1 under both models. The paper is organized as follows. We present the optimal smoothing algorithm in Section 2, and formally establish its optimality in Section 3. <p> X is said to be majorized by Y , or X Y , if P t P t 1; 2; : : : n 1, and i=1 x [i] = i=1 y [i] . For example, if X = [2; 3; 3; 2] and Y = <ref> [1; 8; 1; 0] </ref>, then X Y . X does appear to be smoother than Y . If X = [12; 3; 7] and Y = [2; 10; 10], neither X Y nor Y X. <p> In the following sections, we consider two network service models: Deterministic Guaranteed service (or simply Guaranteed service) as formulated in [9], and Renegotiated CBR (RCBR) service, as formulated in <ref> [8] </ref>. Guaranteed and CBR service models have been widely studied, and are of particular interest for the transport of compressed video. The benefits of work-ahead smoothing have not been previously evaluated under either model. <p> RCBR adds a bandwidth renegotiation mechanism to static CBR <ref> [8, 7] </ref>. Under RCBR, the server reserves bandwidth at peak rate over intervals of time, and at the end of each interval, renegotiates a new bandwidth reservation. The renegotiation is actually a signaling request to adjust the reserved bandwidth along the end-to-end path. <p> For stored video, one alternative is to transmit a subset of the stream if it has been scalably compressed [2] ; MPEG-2 contains support for limited scalable compression. Another possibility is to dynamically requantize the stream at a lower bit rate. See <ref> [8] </ref> for references and further discussion. To evaluate the impact of optimal smoothing under RCBR, we assume a discrete-time model at the frame level, and a network pricing function (indicating the cost to the server/client a given reservation schedule [8]) of the form: = i=1 N1 X ffi c i ;c <p> See <ref> [8] </ref> for references and further discussion. To evaluate the impact of optimal smoothing under RCBR, we assume a discrete-time model at the frame level, and a network pricing function (indicating the cost to the server/client a given reservation schedule [8]) of the form: = i=1 N1 X ffi c i ;c i+1 (3) where N is the length of the session, c i is the bandwidth reserved at time i, (x) is the cost of reserving bandwidth x over one time interval, fl is the fixed renegotiation cost, and ffi <p> Renegotiations incur signaling overhead at each switch along the end-to-end path. The network can limit the renegotiation frequency indirectly, through pricing (i.e., by making the cost of renegotiations high) <ref> [8] </ref>, or directly, by imposing a bound R on the number of allowable renegotiations over the length of the session. We will assume the latter scenario. To avoid any a priori assumptions about the feasible range of renegotiation frequency, we treat R as an independent parameter. <p> In light of the multiple-time-scale variability of VBR video, there is a growing interest in renegotiated services (e.g., <ref> [8, 7, 24] </ref>). While our study of renegotiated CBR is based directly on the work of Grossglauser, Keshav and Tse [8, 7], our formulation is somewhat different. They simultaneously consider both stored video and video generated online. <p> In light of the multiple-time-scale variability of VBR video, there is a growing interest in renegotiated services (e.g., [8, 7, 24]). While our study of renegotiated CBR is based directly on the work of Grossglauser, Keshav and Tse <ref> [8, 7] </ref>, our formulation is somewhat different. They simultaneously consider both stored video and video generated online. To accommodate the online case, they assume that a fixed amount of per-stream buffering is available, at the server, to smooth the outgoing network transmissions. <p> Algorithm D explicitly considers both the client timing constraints and any constraint on server work-ahead, unlike the algorithm in <ref> [8] </ref>. 8 Summary In this paper, we have considered the problem of transmitting stored video from a server to a client across a high-speed network. <p> To address the reduction in network resources required under optimal smoothing, we have considered two important network service models: Guaranteed service (e.g., [1, 9]) and Renegotiated CBR service <ref> [8] </ref>. The impact of work-ahead smoothing (optimal or otherwise) has not previously been evaluated under either model. We find performance of Guaranteed service improves dramatically under optimal smoothing, with network utilizations increasing by as much as a factor of 3 for bursty VBR streams.
Reference: [9] <author> E. W. Knightly, D. E. Wrege, J. Liebeherr and H. Zhang. </author> <title> Fundamental Limits and Tradeoffs of Providing Deterministic Guarantees to VBR Video Traffic. </title> <booktitle> Proc. ACM SIGMETRICS, p. </booktitle> <pages> 98-107, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: See [20] for a precise formulation of these constraints. Work-ahead smoothing does not introduce delay. These techniques are not mutually exclusive, and can be applied in combination and at various points along the end-to-end path from the server to the client <ref> [4, 8, 9, 11, 17, 19, 20, 23] </ref>. In general, network service models may permit only temporal multiplexing [9], only statistical multiplexing [8], or both, as is the case whenever FIFO scheduling with shared buffers is employed at a network switch. <p> These techniques are not mutually exclusive, and can be applied in combination and at various points along the end-to-end path from the server to the client [4, 8, 9, 11, 17, 19, 20, 23]. In general, network service models may permit only temporal multiplexing <ref> [9] </ref>, only statistical multiplexing [8], or both, as is the case whenever FIFO scheduling with shared buffers is employed at a network switch. <p> These benefits can be realized by small, uniprocessor servers as well as large, scalably-parallel ones. We then evaluate the impact on network performance when streams are optimally smoothed, considering two network service models: Deterministic Guaranteed service <ref> [1, 9] </ref>, which provides hard guarantees, and Renegotiated CBR (RCBR) [8, 7], which adds a renegotiation mechanism to traditional CBR service. We find that optimal smoothing yields dramatic improvement in performance 1 under both models. The paper is organized as follows. <p> We use traces captured by a number of other researchers <ref> [5, 9, 10, 21] </ref>, who were kind enough to share them with us. <p> The Wizard of Oz trace [10] is 23 minutes in length and has mean rate 1.25 Mb/s. MTV and Jurassic Park [21] are each 28 minutes in length, and have mean rates of 0.737 Mb/s and 0.392 Mb/s, respectively. Advertisements <ref> [9] </ref> is 9 minutes in length and has mean rate 0.457 Mb/s. based algorithm. <p> In the following sections, we consider two network service models: Deterministic Guaranteed service (or simply Guaranteed service) as formulated in <ref> [9] </ref>, and Renegotiated CBR (RCBR) service, as formulated in [8]. Guaranteed and CBR service models have been widely studied, and are of particular interest for the transport of compressed video. The benefits of work-ahead smoothing have not been previously evaluated under either model. <p> It permits no statistical multiplexing, since statistical performance is incompatible with hard guarantees. The advantage is guaranteed performance; the disadvantages are added delay and potentially low utilization for bursty VBR streams under moderate delay bounds <ref> [9] </ref>. * RCBR is closely related to traditional CBR service, and employs no temporal multiplexing within the network. Instead, performance gains are achieved strictly through statistical multiplexing of network resources via a bandwidth renegotiation mechanism. <p> A call admission algorithm admits the stream into the network only if it can guarantee that the delay bound will never be exceeded. We use the formulation of bounded-delay Guaranteed service given in <ref> [9] </ref>. Consider a single network switch, as depicted in Figure 9. Suppose the n incoming streams are routed to the K th output port and that delay through the switch fabric is constant. Let the capacity of the outgoing link be C bits/s. <p> The least upper bound, E (t), is known as the minimum envelope process [1] (or empirical envelope <ref> [9] </ref>). Computed at the frame level for a stored video with N frames, E (t) is given by: E (t) = max k+t X f (j); (1) where f (j) is the size of the j th frame. <p> In this section, we use A i (t) = E i (t); in [22], we also consider concave upper bounds to E i (t), each specified by a set of (; ) pairs. For FIFO, SP, and EDF link scheduling policies, exact admission control tests are known <ref> [3, 9] </ref>. Assume the n streams are homogeneous (i.e., for all i, A i (t) = A (t)) and require common delay bound d. In this case, FIFO, SP and EDF behave identically, and the admission control test is as follows. <p> See discussion in Section 2.3. Second, to determine the maximum number of admissible streams for a given transmission schedule and delay bound, we compute a traffic constraint function for the schedule, and apply the admission control test (Equation 2 for homogeneous streams with identical delay bounds; see <ref> [13, 9] </ref> for other cases). Consider the case of homogeneous streams, with E (t) as the traffic constraint function. <p> Here, this translates to assuming the client has a nominal buffer capacity of E (500 ms) = 135 KB. The figure demonstrates the benefit of optimal smoothing in comparison to the case in which the server follows an unsmoothed transmission schedule (as in <ref> [9] </ref>). 5 With optimal smoothing into the nominal buffer space, the number of admissible streams increases by as much as 100%. With an additional 256 KB at the client, performance improves even further, with network utilization rising above 70%. <p> Further performance results can be found in [22]. There, we also explore the impact of optimal smoothing for a practical traffic constraint function (the empirical envelope E is difficult to police <ref> [9] </ref>), finding that optimal smoothing enables simple, policable constraint functions to achieve near-comparable performance. In addition, we consider the case of heterogeneous streams with distinct delay bounds, as well as practical switch scheduling policies and call admission algorithms. <p> To address the reduction in network resources required under optimal smoothing, we have considered two important network service models: Guaranteed service (e.g., <ref> [1, 9] </ref>) and Renegotiated CBR service [8]. The impact of work-ahead smoothing (optimal or otherwise) has not previously been evaluated under either model. We find performance of Guaranteed service improves dramatically under optimal smoothing, with network utilizations increasing by as much as a factor of 3 for bursty VBR streams. <p> Given the projected growth in applications which store, processes and transmit compressed video, the issue of reducing rate variability is likely to be remain central for some time. Acknowledgements We would like to thank the researchers who generously shared their MPEG traces. In particular, the contributions of Ed Knightly <ref> [9] </ref>, Marwan Krunz [10], Mark Garrett [5] and Oliver Rose [21] are gratefully acknowledged.
Reference: [10] <author> M. Krunz and H. Hughes. </author> <title> A Traffic Model for MPEG-Coded VBR Streams. </title> <booktitle> Proc. ACM SIGMETRICS, p. </booktitle> <pages> 47-55, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: We use traces captured by a number of other researchers <ref> [5, 9, 10, 21] </ref>, who were kind enough to share them with us. <p> For hard-guaranteed service, max would be specified at call admission; alternatively, max might be determined via a measurement 2 All traces were VBR-encoded using an MPEG-1 software encoder. The Wizard of Oz trace <ref> [10] </ref> is 23 minutes in length and has mean rate 1.25 Mb/s. MTV and Jurassic Park [21] are each 28 minutes in length, and have mean rates of 0.737 Mb/s and 0.392 Mb/s, respectively. Advertisements [9] is 9 minutes in length and has mean rate 0.457 Mb/s. based algorithm. <p> For example, if X = [2; 3; 3; 2] and Y = [1; 8; 1; 0], then X Y . X does appear to be smoother than Y . If X = [12; 3; 7] and Y = <ref> [2; 10; 10] </ref>, neither X Y nor Y X. Thus, we consider a transmission schedule S 1 to be smoother than schedule S 2 if S 1 S 2 . While variance and peak are commonly-used comparative measures of smoothness, such metrics are in fact subsumed by majorization. <p> Acknowledgements We would like to thank the researchers who generously shared their MPEG traces. In particular, the contributions of Ed Knightly [9], Marwan Krunz <ref> [10] </ref>, Mark Garrett [5] and Oliver Rose [21] are gratefully acknowledged.
Reference: [11] <author> S. S. Lam, S. Chow and D. K. Y. Yau. </author> <title> An Algorithm for Lossless Smoothing of MPEG Video. </title> <booktitle> Proc. ACM SIGCOMM, </booktitle> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: See [20] for a precise formulation of these constraints. Work-ahead smoothing does not introduce delay. These techniques are not mutually exclusive, and can be applied in combination and at various points along the end-to-end path from the server to the client <ref> [4, 8, 9, 11, 17, 19, 20, 23] </ref>. In general, network service models may permit only temporal multiplexing [9], only statistical multiplexing [8], or both, as is the case whenever FIFO scheduling with shared buffers is employed at a network switch. <p> Thus, with respect to reducing rate variability, the results in [19] can be viewed as establishing an upper bound on the performance of any online smoothing algorithm. Several other papers have examined smoothing of delay-sensitive, online compressed video (e.g., <ref> [11, 17, 23] </ref>). These approaches always involve the introduction of delay to enable smoothing; see [22] for discussion. For stored video, Feng and Sechrest [4] have also considered work-ahead smoothing into client buffer space. They do not, however, consider the problem of optimally-reducing stream variability.
Reference: [12] <author> D. T. Lee and F. P. Preparata. </author> <title> Euclidean Shortest Path in the Presence of Rectilinear Barriers. </title> <journal> Networks, </journal> <volume> 14 </volume> <pages> 393-410, </pages> <year> 1984. </year>
Reference-contexts: For example, if X = [2; 3; 3; 2] and Y = [1; 8; 1; 0], then X Y . X does appear to be smoother than Y . If X = <ref> [12; 3; 7] </ref> and Y = [2; 10; 10], neither X Y nor Y X. Thus, we consider a transmission schedule S 1 to be smoother than schedule S 2 if S 1 S 2 . <p> In [19], Reibman and Berger assume for the sake of analysis that the stream frame sizes are known a priori. They then apply Lee and Preparata's shortest path algorithm <ref> [12] </ref> in the context of the encoder and decoder buffer timing constraints [20] to derive a schedule which reduces the peak rate at which frames are drained from the encoder buffer. 8 While they suggest as motivation that the shortest-path schedule should maximize the effectiveness of the allowable delay, they state <p> In (b), costs have been normalized by the cost of sending an unsmoothed video without renegotiations. <ref> [12] </ref>), it follows as a direct consequence of Theorem 1 (Section 3) that the smoothest schedule S fl has the shortest length path among all feasible schedules. 9 By appropriately defining D (t) and B (t) to reflect the encoder/decoder timing constraints, 10 Algorithm A can be used to identify the
Reference: [13] <author> J. Liebeherr, D. Wrege and D. Ferrari. </author> <title> Exact Admission Control in Networks with Bounded Delay Services, </title> <type> Tech. Report CS-94-29, </type> <institution> University of Virginia, </institution> <month> Jul. </month> <year> 1994. </year>
Reference-contexts: See discussion in Section 2.3. Second, to determine the maximum number of admissible streams for a given transmission schedule and delay bound, we compute a traffic constraint function for the schedule, and apply the admission control test (Equation 2 for homogeneous streams with identical delay bounds; see <ref> [13, 9] </ref> for other cases). Consider the case of homogeneous streams, with E (t) as the traffic constraint function.
Reference: [14] <author> A. W. Marshall and I. Olkin. </author> <title> Inequalities: Theory of Majorization and its Applications. </title> <address> New York, </address> <publisher> Academic Press, </publisher> <year> 1979. </year>
Reference-contexts: study two fundamental questions. 1) Given a client buffer of size b, how can a given video be sent from the server such that the transmitted bit rate is as smooth as possible, while ensuring that the buffer neither starves nor overflows? We will turn to the theory of majorization <ref> [14] </ref> for precise definitions of smooth and as smooth as possible. <p> For a precisely-defined comparative measure of smoothness, we turn to the theory of majorization <ref> [14] </ref>, which formalizes the intuitive notion that the elements of one vector are more evenly distributed than those of another. Majorization techniques have been applied in a wide variety of problem domains. In our context, we use majorization to compare the smoothness of N -dimensional vectors representing server transmission schedules. <p> To see that X Y implies var (X) var (Y ) (where var (X) = P x) =n, with x = P i x=n), consider the following fundamental result, the proof of which is given in <ref> [14] </ref>, p. 108.
Reference: [15] <author> J. M. McManus and K. W. Ross. </author> <title> Prerecorded VBR Sources in ATM Networks: Piecewise-Constant-Rate Transmission and Transport. </title> <note> Submitted for publication, </note> <month> Sep. </month> <year> 1995. </year>
Reference-contexts: Instead, our strategy is to keep the transmitted bit rate as smooth as possible, minimizing the peak rate and burstiness of the stream for which resources are allocated. McManus and Ross have also considered work-ahead smoothing of stored video <ref> [16, 15] </ref>. They do not consider the problem of optimally-reducing rate variability. In [16], they consider a client startup latency during which the server transmits the first d frames of the video. <p> They also consider piecewise-CBR transmissions of a VBR stream, in <ref> [15] </ref> identifying the transmission schedule which minimizes the client buffer requirements for a constraint K on the number of CBR transmission segments over the length of the video. In light of the multiple-time-scale variability of VBR video, there is a growing interest in renegotiated services (e.g., [8, 7, 24]).
Reference: [16] <author> J. M. McManus and K. W. Ross. </author> <title> Video on Demand over ATM: Constant-Rate Transmission and Transport. </title> <booktitle> Proc. IEEE INFOCOM, </booktitle> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: Instead, our strategy is to keep the transmitted bit rate as smooth as possible, minimizing the peak rate and burstiness of the stream for which resources are allocated. McManus and Ross have also considered work-ahead smoothing of stored video <ref> [16, 15] </ref>. They do not consider the problem of optimally-reducing rate variability. In [16], they consider a client startup latency during which the server transmits the first d frames of the video. <p> McManus and Ross have also considered work-ahead smoothing of stored video [16, 15]. They do not consider the problem of optimally-reducing rate variability. In <ref> [16] </ref>, they consider a client startup latency during which the server transmits the first d frames of the video.
Reference: [17] <author> T. Ott, T. V. Lakshman and A. Tabatabai. </author> <title> A Scheme for Smoothing Delay-Sensitive Traffic Offered to ATM Networks. </title> <booktitle> Proc. IEEE IN-FOCOM, p. </booktitle> <pages> 776-785, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: See [20] for a precise formulation of these constraints. Work-ahead smoothing does not introduce delay. These techniques are not mutually exclusive, and can be applied in combination and at various points along the end-to-end path from the server to the client <ref> [4, 8, 9, 11, 17, 19, 20, 23] </ref>. In general, network service models may permit only temporal multiplexing [9], only statistical multiplexing [8], or both, as is the case whenever FIFO scheduling with shared buffers is employed at a network switch. <p> Thus, with respect to reducing rate variability, the results in [19] can be viewed as establishing an upper bound on the performance of any online smoothing algorithm. Several other papers have examined smoothing of delay-sensitive, online compressed video (e.g., <ref> [11, 17, 23] </ref>). These approaches always involve the introduction of delay to enable smoothing; see [22] for discussion. For stored video, Feng and Sechrest [4] have also considered work-ahead smoothing into client buffer space. They do not, however, consider the problem of optimally-reducing stream variability.
Reference: [18] <author> A. R. Reibman and A. W. Berger. </author> <title> On VBR Video Teleconferencing over ATM Networks. </title> <booktitle> Proc. IEEE GLOBECOM, p. </booktitle> <pages> 314-319, </pages> <year> 1992. </year>
Reference-contexts: The second is that when streams are optimally smoothed, relatively infrequent renegotiations (on the order of once a minute) yield high performance. 7 Related work Reibman and Berger <ref> [19, 18] </ref> have conducted an extensive study of compressed video transport over ATM, for video generated online by delay-sensitive applications such as teleconferencing.
Reference: [19] <author> A. R. Reibman and A. W. Berger. </author> <title> Traffic Descriptors for VBR Video Teleconferencing over ATM Networks. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 3(3) </volume> <pages> 329-339, </pages> <month> Jun. </month> <year> 1995. </year>
Reference-contexts: See [20] for a precise formulation of these constraints. Work-ahead smoothing does not introduce delay. These techniques are not mutually exclusive, and can be applied in combination and at various points along the end-to-end path from the server to the client <ref> [4, 8, 9, 11, 17, 19, 20, 23] </ref>. In general, network service models may permit only temporal multiplexing [9], only statistical multiplexing [8], or both, as is the case whenever FIFO scheduling with shared buffers is employed at a network switch. <p> Figure 10a shows the number of admissible Advertisements streams as a function of the negotiated delay bound d, over the range 0-500 ms, for an OC-3 link providing 127.155 Mb/s for video data transport (i.e., at the ATM AAL layer <ref> [19] </ref>). Each stream has a mean bit rate of 0.457 Mb/s. We assume the client is equipped with sufficient buffer space to accommodate the worst-case jitter over the range of delay bounds that may be negotiated with the network. <p> The second is that when streams are optimally smoothed, relatively infrequent renegotiations (on the order of once a minute) yield high performance. 7 Related work Reibman and Berger <ref> [19, 18] </ref> have conducted an extensive study of compressed video transport over ATM, for video generated online by delay-sensitive applications such as teleconferencing. <p> By contrast, since we consider stored video and much larger buffer capacity at the client, we can perform smoothing on a much broader time scale, thereby achieving more effective reduction in the stream's slow time-scale rate variability. In <ref> [19] </ref>, Reibman and Berger assume for the sake of analysis that the stream frame sizes are known a priori. <p> Since S fl is unique (Section 3), we conclude that they are in fact using the smoothest possible transmission schedule. Thus, with respect to reducing rate variability, the results in <ref> [19] </ref> can be viewed as establishing an upper bound on the performance of any online smoothing algorithm. Several other papers have examined smoothing of delay-sensitive, online compressed video (e.g., [11, 17, 23]). These approaches always involve the introduction of delay to enable smoothing; see [22] for discussion.
Reference: [20] <author> A. R. Reibman and B. G. </author> <title> Haskell. Constraints on Variable Bit-Rate Video for ATM Networks. </title> <journal> IEEE Transactions on Circuits and Systems for Video Technology, </journal> <volume> 2(4) </volume> <pages> 361-372, </pages> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: See <ref> [20] </ref> for a precise formulation of these constraints. Work-ahead smoothing does not introduce delay. These techniques are not mutually exclusive, and can be applied in combination and at various points along the end-to-end path from the server to the client [4, 8, 9, 11, 17, 19, 20, 23]. <p> See [20] for a precise formulation of these constraints. Work-ahead smoothing does not introduce delay. These techniques are not mutually exclusive, and can be applied in combination and at various points along the end-to-end path from the server to the client <ref> [4, 8, 9, 11, 17, 19, 20, 23] </ref>. In general, network service models may permit only temporal multiplexing [9], only statistical multiplexing [8], or both, as is the case whenever FIFO scheduling with shared buffers is employed at a network switch. <p> In [19], Reibman and Berger assume for the sake of analysis that the stream frame sizes are known a priori. They then apply Lee and Preparata's shortest path algorithm [12] in the context of the encoder and decoder buffer timing constraints <ref> [20] </ref> to derive a schedule which reduces the peak rate at which frames are drained from the encoder buffer. 8 While they suggest as motivation that the shortest-path schedule should maximize the effectiveness of the allowable delay, they state without proof that it minimizes the peak transmission rate.
Reference: [21] <author> O. Rose. </author> <title> Statistical Properties of MPEG Video Traffic and their Impact on Traffic Modeling in ATM Systems. </title> <type> Tech. Report 101, </type> <institution> Univ. Wurzburg Institute of Computer Science, </institution> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: We use traces captured by a number of other researchers <ref> [5, 9, 10, 21] </ref>, who were kind enough to share them with us. <p> For hard-guaranteed service, max would be specified at call admission; alternatively, max might be determined via a measurement 2 All traces were VBR-encoded using an MPEG-1 software encoder. The Wizard of Oz trace [10] is 23 minutes in length and has mean rate 1.25 Mb/s. MTV and Jurassic Park <ref> [21] </ref> are each 28 minutes in length, and have mean rates of 0.737 Mb/s and 0.392 Mb/s, respectively. Advertisements [9] is 9 minutes in length and has mean rate 0.457 Mb/s. based algorithm. <p> Acknowledgements We would like to thank the researchers who generously shared their MPEG traces. In particular, the contributions of Ed Knightly [9], Marwan Krunz [10], Mark Garrett [5] and Oliver Rose <ref> [21] </ref> are gratefully acknowledged.
Reference: [22] <author> J. Salehi, Zhi-Li Zhang, J. Kurose and D. Towsley. </author> <title> Supporting Stored Video: Reducing Rate Variability and End-to-End Resource Requirements through Optimal Smoothing. </title> <type> Tech. Report 95-98, </type> <institution> Department of Computer Science, U. Mas-sachusetts at Amherst, </institution> <address> Nov. 1995 (http://www.cs.umass.edu/salehi or ftp://gaia.cs.umass.edu/pub/Sale95:Supporting.ps.Z). </address>
Reference-contexts: First, A can be easily quantized (i.e., modified to produce an S fl which sends only integral numbers of bytes at each time t); see <ref> [22] </ref> for details. Second, A does not depend on B (t) lying at a fixed offset above D (t). Minimally, the client needs only sufficient buffer space to store the next frame at any given time (i.e., the constraint is B (t) D (t1)+d (t), for all t). <p> Theorem 1 Let S fl fl fl (N )] denote the transmission schedule generated by A for a given video and client buffer size. If S = [a (1); : : : ; a (N )] is any arbitrary feasible schedule for the video, then S fl S. See <ref> [22] </ref> for proof. Theorem 1 establishes that, with respect to ma-jorization, S fl is optimally smooth. <p> In addition, we can easily show that S fl is unique; see <ref> [22] </ref> for details. 4 Impact on network resource requirements We have established an optimal smoothing technique which, through work-ahead, enables the server to maximally reduce stream rate variability when sending stored video to a client across a high-speed network. <p> For space considerations, we restrict attention to a sampling of the representative behavior. For a performance comparison of Guaranteed and RCBR services under optimal smoothing, see <ref> [22] </ref>. 5 Guaranteed service In this section, we evaluate the benefit of optimal smoothing under Guaranteed service. We begin with an overview of the service model, and then turn to performance results. 5.1 Overview Under Guaranteed service, the network provides hard guarantees. <p> Toward the other extreme is peak rate allocation, which captures only the worst-case behavior over a single frame time, i.e., A i (t) = tE i (1). In this section, we use A i (t) = E i (t); in <ref> [22] </ref>, we also consider concave upper bounds to E i (t), each specified by a set of (; ) pairs. For FIFO, SP, and EDF link scheduling policies, exact admission control tests are known [3, 9]. <p> Note the performance dip at low delay bounds. Under optimal smoothing, the transmission of the very first frame of the video which is typically large for MPEG streamscannot be smoothed without a startup latency (Section 2). In <ref> [22] </ref>, we show that when a 100 ms (3-frame) startup latency is added, the low-delay anomaly disappears. The implication is that under optimal smoothing with sufficient client buffer space, Guaranteed service need not introduce delay in order to achieve high utilization. Further performance results can be found in [22]. <p> In <ref> [22] </ref>, we show that when a 100 ms (3-frame) startup latency is added, the low-delay anomaly disappears. The implication is that under optimal smoothing with sufficient client buffer space, Guaranteed service need not introduce delay in order to achieve high utilization. Further performance results can be found in [22]. There, we also explore the impact of optimal smoothing for a practical traffic constraint function (the empirical envelope E is difficult to police [9]), finding that optimal smoothing enables simple, policable constraint functions to achieve near-comparable performance. <p> Assume a network pricing function of the form (3), and that the maximum number of allowable renegotiations is R. In <ref> [22] </ref>, we present Algorithm B for identifying the minimum-cost reservation schedule for S with R or fewer renegotiations. The algorithm has time complexity O (Rn 2 ), where n is the number of segments in the transmission schedule. <p> While we use B in the evaluation of optimal smoothing under RCBR throughout the remainder of this section, in <ref> [22] </ref> we discuss and present several extensions to the algorithm. First, the additional constraint of a minimum time between renegotiations is easily incorporated, while retaining the O (Rn 2 ) time complexity. <p> If the network does not impose a bound on the number of renegotiations, the time complexity can be reduced from O (Rn 2 ) to O (n 2 ) (see Algorithm C in <ref> [22] </ref>). Finally, note that B finds the minimum-cost reservation schedule for a given transmission schedule. In [22] we present Algorithm D, which finds the minimum-cost reservation schedule over all feasible transmission schedules for the given video and client buffer size. 6.3 Performance under optimal smoothing We now turn to an empirical <p> If the network does not impose a bound on the number of renegotiations, the time complexity can be reduced from O (Rn 2 ) to O (n 2 ) (see Algorithm C in <ref> [22] </ref>). Finally, note that B finds the minimum-cost reservation schedule for a given transmission schedule. In [22] we present Algorithm D, which finds the minimum-cost reservation schedule over all feasible transmission schedules for the given video and client buffer size. 6.3 Performance under optimal smoothing We now turn to an empirical evaluation of optimal smoothing under RCBR. <p> Across all experimental data presented below, this bound is on the order of 10 5 . Finally, a binary search yields N max , i.e., the largest N such that C (N ) &lt; L. (For additional discussion of the simulation, see <ref> [22] </ref>.) supportable streams over an OC-3 link for R ranging from 0 up to 100. This corresponds to a mean renegotiation time ranging from 23 minutes down to 14 seconds. The maximum number of unsmoothed streams which can be admitted is also shown. <p> Several other papers have examined smoothing of delay-sensitive, online compressed video (e.g., [11, 17, 23]). These approaches always involve the introduction of delay to enable smoothing; see <ref> [22] </ref> for discussion. For stored video, Feng and Sechrest [4] have also considered work-ahead smoothing into client buffer space. They do not, however, consider the problem of optimally-reducing stream variability. Instead, they focus on reducing the number of rate increases required during stream transmission. <p> The same setup is used for the stored video case. One limitation of this formulation is that it does not explicitly consider the client's timing constraint; see <ref> [22] </ref> for discussion. By contrast, under our formulation of RCBR, we consider only work-ahead smoothing of stored video, which can be performed without introducing delay in client playback.
Reference: [23] <author> N. Shroff and M. Schwartz. </author> <title> Video Modeling within Networks using Deterministic Smoothing at the Source. </title> <booktitle> Proc. IEEE INFOCOM, p. </booktitle> <pages> 342-349, </pages> <year> 1994. </year>
Reference-contexts: See [20] for a precise formulation of these constraints. Work-ahead smoothing does not introduce delay. These techniques are not mutually exclusive, and can be applied in combination and at various points along the end-to-end path from the server to the client <ref> [4, 8, 9, 11, 17, 19, 20, 23] </ref>. In general, network service models may permit only temporal multiplexing [9], only statistical multiplexing [8], or both, as is the case whenever FIFO scheduling with shared buffers is employed at a network switch. <p> Thus, with respect to reducing rate variability, the results in [19] can be viewed as establishing an upper bound on the performance of any online smoothing algorithm. Several other papers have examined smoothing of delay-sensitive, online compressed video (e.g., <ref> [11, 17, 23] </ref>). These approaches always involve the introduction of delay to enable smoothing; see [22] for discussion. For stored video, Feng and Sechrest [4] have also considered work-ahead smoothing into client buffer space. They do not, however, consider the problem of optimally-reducing stream variability.
Reference: [24] <author> H. Zhang and E. W. Knightly. </author> <title> A New Approach to Support Delay-Sensitive VBR Video in Packet-Switched Networks. </title> <booktitle> Proc. 5 th Workshop on Network and Operating Systems Support for Digital Audio and Video, </booktitle> <address> p. 275286, </address> <month> Apr. </month> <year> 1995. </year> <month> 10 </month>
Reference-contexts: In light of the multiple-time-scale variability of VBR video, there is a growing interest in renegotiated services (e.g., <ref> [8, 7, 24] </ref>). While our study of renegotiated CBR is based directly on the work of Grossglauser, Keshav and Tse [8, 7], our formulation is somewhat different. They simultaneously consider both stored video and video generated online.
References-found: 24

