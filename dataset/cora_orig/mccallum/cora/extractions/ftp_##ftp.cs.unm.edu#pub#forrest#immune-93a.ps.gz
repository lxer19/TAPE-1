URL: ftp://ftp.cs.unm.edu/pub/forrest/immune-93a.ps.gz
Refering-URL: http://www.cs.unm.edu/~forrest/projects.html
Root-URL: http://www.cs.unm.edu
Email: resmith@ua1ix.ua.edu  forrest@cs.unm.edu  asp@receptor.lanl.gov  
Phone: (205) 348-1618  (505) 277-7104  (505) 667-6829  
Title: Searching for Diverse, Cooperative Populations with Genetic Algorithms  
Author: Robert E. Smith Stephanie Forrest Alan S. Perelson 
Keyword: Running Head: Cooperative Populations with GAs Keywords: genetic algorithms, classifier systems, fitness sharing, computational immunology, multi-modal search  
Address: Tuscaloosa, AL 35487  Albuquerque, NM 87131  Los Alamos, NM 87545  
Affiliation: Dept. of Engin. Mechanics University of Alabama  Dept. of Computer Science University of New Mexico  Theoretical Division Los Alamos National Laboratory  
Abstract: In typical applications, genetic algorithms (GAs) process populations of potential problem solutions to evolve a single population member that specifies an optimized solution. The majority of GA analysis has focused on these optimization applications. In other applications (notably learning classifier systems and certain connectionist learning systems), a GA searches for a population of cooperative structures that jointly perform a computational task. This paper presents an analysis of this type of GA problem. The analysis considers a simplified genetics-based machine learning system: a model of an immune system. In this model, a GA must discover a set of pattern-matching antibodies that effectively match a set of antigen patterns. Analysis shows how a GA can automatically evolve and sustain a diverse, cooperative population. The cooperation emerges as a natural part of the antigen-antibody matching procedure. This emergent effect is shown to be similar to fitness sharing, an explicit technique for multi-modal GA optimization. Further analysis shows how the GA population can adapt to express various degrees of generalization. The results show how GAs can automatically and simultaneously discover effective groups of cooperative computational structures. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Booker, L. B. </author> <year> (1982). </year> <title> Intelligent behavior as an adaptation to the task environment. </title> <type> PhD thesis, </type> <institution> The University of Michigan, </institution> <address> Ann Arbor, MI. </address>
Reference: <author> Booker, L. B. </author> <year> (1985). </year> <title> Improving the performance of genetic algorithms in classifier systems. </title> <editor> In J. J. Grefenstette (Ed.), </editor> <booktitle> Proceedings of an International Conference on Genetic Algorithms and their Applications, </booktitle> <pages> 80-92, </pages> <address> Pittsburg, PA. </address> <publisher> Lawrence Erlbaum. </publisher> <address> 26 Cohoon, </address> <note> J., </note> <author> Hegde, U., Martin, W., & Richards, D. </author> <year> (1987). </year> <title> Punctuated equilibria: A parallel genetic algorithm. </title> <booktitle> In Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> 148-154, </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Collins, R. J., & Jefferson, D. R. </author> <year> (1991). </year> <title> Selection in massively parallel genetic algorithms. </title> <editor> In R. K. Belew, & L. B. Booker (Eds.), </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> 249-256, </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Davidor, Y. </author> <year> (1991). </year> <title> A naturally occurring niche and species phenomenon: the model and first results. </title> <editor> In R. K. Belew, & L. B. Booker (Eds.), </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> 257-263, </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Deb, K. </author> <year> (1989a). </year> <title> Genetic algorithms in multimodal function optimization (Tech. </title> <institution> Rep.). Department of Engineering Mechanics, University of Alabama, </institution> <note> Tuscaloosa, </note> <editor> AL: </editor> <title> The Clearinghouse for Genetic Algorithms. </title> <type> (Master's Thesis) Deb, K. </type> <year> (1989b). </year> <title> Genetic algorithms in multimodal function optimization (TCGA Report No. </title> <type> 89002). </type> <institution> Tuscaloosa: The University of Alabama, </institution> <note> The Clearinghouse for Genetic Algorithms. </note>
Reference: <author> Deb, K., & Goldberg, D. E. </author> <year> (1989, </year> <title> Junea). An investigation of niche and species formation in genetic function optimization. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> 42-50, </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Deb, K., & Goldberg, D. E. </author> <year> (1989b). </year> <title> An investigation of niche and species formation in genetic function optimization. </title> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> 42-50. </pages>
Reference-contexts: well, but has several important limitations: * It requires a comparison of every population member to every other population member in each generation (N 2 comparisons where N is the size of the population). * Setting the critical parameter oe s requires knowledge about the number peaks in the space <ref> (Deb, 1989b) </ref>. * Setting oe s is also dependent on a uniform distribution of peaks in the search space. Although Deb (1989b) shows experiments where sharing succeeds on a problem with mildly non-uniform peak separation, it is likely fitness sharing would overlook peaks that were distributed with less uniformity (K. <p> It is included here to clarify the limiting case where oe s = 0. 8 wishes the GA to find and maintain, and these peaks are equidistant (in terms of the given distance metric) from one another in the search space <ref> (Deb, 1989b) </ref>. He also shows how to set oe s such that q hyperspheres of radius oe s fill the search space. Then, under Deb's assumptions, one and only one peak lies in each hypersphere of radius oe s . <p> Its value essentially implies a cutoff beyond which no sharing can occur. However, there is an important distinction to be drawn between fitness sharing and the implicit sharing in the immune system simulations. In fitness sharing, oe s is a strict cutoff based on d ij , which Deb <ref> (Deb, 1989b) </ref> recommends setting based on the volume of a hypersphere around a given peak. In the immune system algorithm, oe dictates a cutoff based on V j (m), which is the proportion of the population within a hypersphere of radius m 1 around a given antigen. <p> However, previous algorithms have been limited by the fact that the number of peaks or high fitness areas had to be known to correctly set oe s , the peaks had to be (nearly) equidistant <ref> (Deb, 1989b) </ref>, and N 2 comparisons are required. Here we have shown that an algorithm developed by Forrest et al. (in preparation) to study pattern recognition in the immune system has emergent properties that are similar to those of explicit fitness sharing.
Reference: <author> DeJong, K. A. </author> <year> (1975). </year> <title> An analysis of the behavior of a class of genetic adaptive systems. </title> <type> PhD thesis, </type> <institution> The University of Michigan, </institution> <address> Ann Arbor, MI. </address>
Reference-contexts: Crowding induces niches by forcing new individuals to replace those that are similar genotypically <ref> (DeJong, 1975) </ref>. This is accomplished by using a steady-state GA which creates new individuals one at a time, inserting them into the population by replacement of existing individuals.
Reference: <author> DeJong, K. A. </author> <year> (1988). </year> <title> Learning with genetic algorithms: An overview. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 121-138. </pages>
Reference-contexts: These methods can slow down convergence time dramatically, but by themselves cannot maintain stable separate subpopulations (McInerney, 1992). Another method for maintaining diversity in a classifier system is called the Pitt approach <ref> (DeJong, 1988) </ref>. First used by Smith (1980), this method concatenates a population of classifiers to form a single individual for the genetic algorithm to manipulate. Thus, the genetic algorithm is acting on populations of rule sets.
Reference: <author> Farmer, J. D., Packard, N. H., & Perelson, A. S. </author> <year> (1986). </year> <title> The immune system, adaptation, and machine learning. </title> <editor> In D. Farmer, A. Lapedes, N. Packard, & B. Wendroff (Eds.), </editor> <title> Evolution, games and learning. </title> <journal> North-Holland. </journal> <note> (Reprinted from Physica, 22D, 187-204) 27 Forrest, </note> <author> S., Javornik, B., Smith, R., & Perelson, A. S. </author> <title> (in preparation). Using genetic algorithms to explore pattern recognition in the immune system. </title>
Reference-contexts: is based on a universe in which both antigens and receptors on B cells and T cells are 10 Antigens 1001100001110001 0101010101010011 0000111100010001 1100001010100110 0111110011100101 Antibodies 1010001110000111 0000110100011000 1100110010010100 AU 1100100100010010)=1 + 2 + 1 + 5 + 3 = 12 Antibodies 0101110100011011 1001010101000110 1100110010010100 GA represented by binary strings <ref> (Farmer, Packard, & Perelson, 1986) </ref>. This is certainly a simplification from the real biology in which genes are specified by a four-letter alphabet and recognition between receptors and antigens is based on their three-dimensional shapes and physical properties.
Reference: <author> Forrest, S., & Perelson, A. </author> <year> (1991). </year> <title> Genetic algorithms and the immune system. </title> <editor> In H. Schwefel, & R. Maenner (Eds.), </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> 320-325, </pages> <address> Berlin. </address> <publisher> Springer-Verlag (Lecture Notes in Computer Science). </publisher>
Reference-contexts: As a second example, consider a computational model of the immune system in which a population of antibodies is evolving to cover a set of antigens <ref> (Forrest & Perelson, 1991) </ref>. If the antibody population is sufficiently large, it clearly makes sense to evolve antibodies that are specialized to recognize different classes of antigens instead of evolving one generalist antibody that weakly matches all antigens.
Reference: <author> Freund, J. E. </author> <year> (1962). </year> <institution> Mathematical statistics. </institution> <address> Englewood Cliffs, NJ.: </address> <publisher> Prentice-Hall. </publisher>
Reference-contexts: This latter event occurs with probability 1=w. Events (i) and (ii) are not independent. Thus to compute the probability that events (i) and (ii) are both true, we use the well known formula <ref> (Freund, 1962) </ref>: P (E 1 " E 2 ) = P (E 2 jE 1 )P (E 1 ) ; (7) where E i denotes event (i). To compute P (E 1 ), the probability of event (i), we again use the hypergeometric distribution.
Reference: <author> Goldberg, D., & Richardson, J. </author> <year> (1987). </year> <title> Genetic algorithms with sharing for multimodal function optimization. </title> <booktitle> In Proceedings of the second international conference on genetic algorithms (148-154). </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In practice, genetic drift tends to drive a GA population to a population comprised entirely of one type of individual from S fl . This effect has been discussed extensively in population genetics and in the GA literature <ref> (Goldberg & Segrest, 1987) </ref>. For example, consider a population composed of two types of individuals, 1 and 0, each present at 50 copies and having equal fitness.
Reference: <author> Goldberg, D. E. </author> <year> (1989). </year> <title> Genetic algorithms in search, optimization, </title> <booktitle> and machine learning. </booktitle> <address> Reading, MA: </address> <publisher> Addison Wesley. </publisher>
Reference: <author> Goldberg, D. E., & Deb, K. </author> <year> (1990). </year> <title> A comparative analysis of selection schemes used in genetic algorithms (TCGA Report No. </title> <type> 90007). </type> <institution> Tuscaloosa: The University of Alabama, </institution> <note> The Clearinghouse for Genetic Algorithms. </note>
Reference-contexts: The reproduction and survival of an individual into the next generation depends on the individual's fitness. The exact details of how fitness affects reproduction varies among different implementations of the GA <ref> (Goldberg & Deb, 1990) </ref>.
Reference: <author> Goldberg, D. E., & Segrest, P. </author> <year> (1987). </year> <title> Finite Markov chain analysis of genetic algorithms. </title> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> 1-8. </pages>
Reference-contexts: In practice, genetic drift tends to drive a GA population to a population comprised entirely of one type of individual from S fl . This effect has been discussed extensively in population genetics and in the GA literature <ref> (Goldberg & Segrest, 1987) </ref>. For example, consider a population composed of two types of individuals, 1 and 0, each present at 50 copies and having equal fitness.
Reference: <author> Gorges-Schleuter, M. </author> <year> (1989, </year> <month> June). </month> <title> ASPARAGOS: An asynchronous parallel genetic optimization strategy. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> 422-427, </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Grosso, P. B. </author> <year> (1985). </year> <title> Computer simulations of genetic adaptation: Parallel subcomponent interaction in a multilocus model. </title> <type> PhD thesis, </type> <institution> The University of Michigan, </institution> <address> Ann Arbor, MI. </address>
Reference-contexts: This method can make the algorithm more efficient at discovering global optima, but even a very small amount of migration results in the subpopulations eventually converging on one solution, so in the end diversity is lost <ref> (Grosso, 1985) </ref>. Local mating algorithms (Collins & Jefferson, 1991; Davidor, 1991; Hillis, 1990; Muhlenbein, 1989; Spiessens & Manderick, 1991) attempt to move away from explicitly subdividing the population (explicit subdivision implies some prior knowledge about how many niches are in the environment, and their relative size).
Reference: <author> Hillis, W. D. </author> <year> (1990). </year> <title> Co-evolving parasites improve simulated evolution as an optimization procedure. </title> <journal> Physica D, </journal> <volume> 42, </volume> <pages> 228-234. </pages>
Reference: <author> Hines, W. W., & Montgomery, D. C. </author> <year> (1980). </year> <booktitle> Probability and statistics in engineering and management science (2nd ed.). </booktitle> <address> New York: </address> <publisher> Wiley. </publisher>
Reference: <author> Holland, J. </author> <year> (1975). </year> <booktitle> Adaptation in natural and artificial systems. </booktitle> <address> Ann Arbor, MI: </address> <institution> The University of Michigan Press. </institution> <note> 28 Holland, </note> <author> J., Holyoak, K., Nisbett, R., & Thagard, P. </author> <year> (1986). </year> <title> Induction: Processes of inference, learning, and discovery. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: In genetic algorithms (GAs), it is difficult to maintain diversity because the algorithm assigns exponentially increasing numbers of trials to the observed best parts of the search space (cf. Schema Theorem <ref> (Holland, 1975) </ref>). As a result, the standard GA has strong convergence properties. For optimization problems, convergence can be an advantage, but in other environments it can be detrimental. Further, even in optimization, strong convergence can be problematic if it prematurely restricts the search space.
Reference: <author> Kargupta, H., & Smith, R. E. </author> <year> (1991). </year> <title> System identification with evolving polynomial networks (TCGA Report No. </title> <type> 91001). </type> <institution> Tuscaloosa: University of Alabama, </institution> <note> The Clearinghouse for Genetic Algorithms. </note>
Reference-contexts: Although the mechanisms are different, the emergent effects in these systems are similar to those in the immune system simulations. The techniques may also prove useful in other systems that form computational networks via genetic learning. A particular instance is in the development of polynomial networks for system modeling <ref> (Kargupta & Smith, 1991) </ref>, where explicit fitness sharing was previously required. Whether or not the techniques used in the immune system simulations can be explicitly transferred to more prescriptive applications, analysis of the type used in this paper can aid in understanding GA behavior in settings that require diversity.
Reference: <author> Levin, S. A. </author> <year> (1981). </year> <title> Mechanisms for the generation and maintence of diversity in ecological communities. </title> <editor> In R. W. Hiorns, & D. Cooke (Eds.), </editor> <booktitle> The mathematical theory of dynamics of biological populations ii (pp. </booktitle> <pages> 173-194). </pages> <publisher> Academic Press. </publisher>
Reference-contexts: In ecological theory such strategies are called negative frequency-dependent selection <ref> (Levin, 1981) </ref>. Fitness sharing is based on the idea of environmental niches with finite resources available for each niche.
Reference: <author> McInerney, J. </author> <year> (1992). </year> <title> Biologically influenced algorithms and parallelism in non-linear optimization. </title> <type> PhD thesis, </type> <institution> Unviersity of California, </institution> <address> San Diego, La Jolla, CA. </address>
Reference-contexts: Once again, the idea is that random genetic variation will lead to subgroups of individuals, each exploring different regions of the search space. These methods can slow down convergence time dramatically, but by themselves cannot maintain stable separate subpopulations <ref> (McInerney, 1992) </ref>. Another method for maintaining diversity in a classifier system is called the Pitt approach (DeJong, 1988). First used by Smith (1980), this method concatenates a population of classifiers to form a single individual for the genetic algorithm to manipulate.
Reference: <author> Muhlenbein, H. </author> <year> (1989). </year> <title> Parallel genetic algorithms, population genetics and combinatorial optimization. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> 416-421, </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Perelson, A. S. </author> <year> (1989). </year> <title> Immune network theory. </title> <journal> Immunol. Rev., </journal> <volume> 110, </volume> <pages> 5-36. </pages>
Reference-contexts: A receptor, or antibody, is said to match an antigen if their bit strings are complementary (maximally different). Since each antibody may have to match against several different antigens simultaneously, we do not require perfect bit-wise matching. There are many possible match rules that are plausible physiologically <ref> (Perelson, 1989) </ref>. The degree of match is quantified by a match score function M : Antigen fi Antibody ! &lt;.
Reference: <author> Pettey, C., Leuze, M., & Grefenstette, J. </author> <year> (1987). </year> <title> A parallel genetic algorithm. </title> <booktitle> In Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> 155-161, </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Smith, S. F. </author> <year> (1980). </year> <title> A learning system based on genetic adaptive algorithms. </title> <type> PhD thesis, </type> <institution> University of Pittsburgh, </institution> <address> Pittsburgh, PA. </address>
Reference: <author> Spiessens, P., & Manderick, B. </author> <year> (1991). </year> <title> A massively parallel genetic algorithm: implementation and first analysis. </title> <editor> In R. K. Belew, & L. B. Booker (Eds.), </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> 257-263, </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Tanese, R. </author> <year> (1989a). </year> <title> Distributed genetic algorithms. </title> <editor> In J. D. Schaffer (Ed.), </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Tanese, R. </author> <year> (1989b). </year> <title> Distributed genetic algorithms for function optimization. </title> <type> PhD thesis, </type> <institution> The University of Michigan, </institution> <address> Ann Arbor, MI. </address>
Reference: <author> Whitley, D., & Starkweather, T. </author> <year> (1990). </year> <title> Genitor II: A distributed genetic algorithm. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 2(3), </volume> <pages> 189-214. 29 </pages>
References-found: 32

