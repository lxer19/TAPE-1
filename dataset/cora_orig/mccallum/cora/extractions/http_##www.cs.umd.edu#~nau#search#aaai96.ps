URL: http://www.cs.umd.edu/~nau/search/aaai96.ps
Refering-URL: http://www.cs.umd.edu/~nau/publications.html
Root-URL: 
Email: sjsmith@cs.umd.edu nau@cs.umd.edu  bridgebaron@mcimail.com  
Title: Total-Order Multi-Agent Task-Network Planning for Contract Bridge  
Author: S. J. J. Smith and D. S. Nau T. A. Throop 
Note: Great Game Products  
Address: College Park, MD 20742, USA  8804 Chalon Drive Bethesda, MD 20817, USA  
Affiliation: Computer Science Department and Institute for Systems Research University of Maryland  
Abstract: This paper describes the results of applying a modified version of hierarchical task-network (HTN) planning to the problem of declarer play in contract bridge. We represent information about bridge in a task network that is extended to represent multi-agency and uncertainty. Our game-playing procedure uses this task network to generate game trees in which the set of alternative choices is determined not by the set of possible actions, but by the set of available tactical and strategic schemes. This approach avoids the difficulties that traditional game-tree search techniques have with imperfect-information games such as bridgebut it also differs in several significant ways from the planning techniques used in typical HTN planners. We describe why these modifications were needed in order to build a successful planner for bridge. This same modified HTN planning strategy appears to be useful in a variety of application domainsfor example, we have used the same planning techniques in a process-planning system for the manufacture of complex electromechanical devices (Hebbar et al. 1996). We discuss why the same technique has been successful in two such diverse domains. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ballard, B. W. </author> <year> 1983. </year> <title> The *-minimax search procedure for trees containing chance nodes. </title> <booktitle> Artificial Intelligence 21 </booktitle> <pages> 327-350. </pages>
Reference: <author> Berlin, D. L. </author> <year> 1985. </year> <title> SPAN: integrating problem solving tactics. </title> <booktitle> In Proc. 9th International Joint Conference on Artificial Intelligence, </booktitle> <pages> 1047-1051. </pages>
Reference: <author> Berliner, H. J.; Goetsch, G.; Campbell, M. S.; and Ebeling, C. </author> <year> 1990. </year> <title> Measuring the performance potential of chess programs. </title> <booktitle> Artificial Intelligence 43 </booktitle> <pages> 7-20. </pages>
Reference: <author> Biermann, A. W. </author> <year> 1978. </year> <title> Theoretical issues related to computer game playing programs. </title> <type> Personal Computing, </type> <month> September </month> 1978 86-88. 
Reference: <author> Boutilier, C.; Dearden, R.; and Goldszmidt, M. </author> <year> 1995. </year> <title> Exploiting structure in policy construction. </title> <booktitle> In Proc. 14th International Joint Conference on Artificial Intelligence. </booktitle>
Reference: <author> Collins, G. and Pryor, L. </author> <year> 1995. </year> <title> Planning under uncertainty: some key issues. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence, </booktitle> <pages> 1670-1676. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address>
Reference: <author> Currie, K. and Tate, A. </author> <year> 1985. </year> <title> O-Plancontrol in the open planner architecture. </title> <booktitle> BCS Expert Systems Conference, </booktitle> <publisher> Cambridge University Press, </publisher> <address> UK. </address>
Reference-contexts: To represent the tactical and strategic schemes of card-playing in bridge, we use multi-agent methodsstructures similar to the action schemas or methods used in hierarchical single-agent planning systems such as Nonlin (Tate 1977), NOAH (Sacerdoti 1977), O-Plan <ref> (Currie & Tate 1985) </ref>, and SIPE (Wilkins 1984; Wilkins 1988), but modified to represent multi-agency and uncertainty. To generate game trees, we use a procedure similar to task decomposition. The methods that perform our tasks correspond to the various tactical and strategic schemes for playing the game of bridge.
Reference: <author> Dean, T.; Kaelbling, L. P.; Kirman, J.; and Nichol-son, A. </author> <year> 1993. </year> <title> Planning with deadlines in stochastic domains. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> 574-579. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference-contexts: Encouragingly, problems on a grander scale are starting to be studied (Haddawy, Doan, & Goodwin 1995; Boutilier, Dearden, & Goldszmidt 1995; Lin & Dean 1995). Multi-Agent Planning. Much of the previous research on multi-agent planning has dealt with different issues than those that concern us here. In reactive planning <ref> (Dean et al. 1993) </ref>, the agent must respond in real time to externally-caused eventsand the necessity of making quick decisions largely precludes the possibility of reasoning far into the future.
Reference: <author> Draper, D.; Hanks, S., and Weld, D. </author> <year> 1994. </year> <title> Probabilistic planning with information gathering and contingent execution. </title> <booktitle> In Proceedings of the 2nd International Conference on AI Planning Systems, </booktitle> <editor> Kristian Hammond, editor. </editor> <publisher> AAAI Press, </publisher> <address> Menlo Park, California. </address>
Reference: <author> Erol, K.; Hendler, J.; and Nau, D.S. </author> <year> 1994. </year> <title> UMCP: A sound and complete procedure for hierarchical task-network planning. </title> <booktitle> In Proc. Second International Conf. on AI Planning Systems (AIPS-94), </booktitle> <pages> pages 249-254. </pages>
Reference: <author> Erol, K.; Nau, D. S.; and Subrahmanian, V. S. </author> <year> 1995. </year> <title> Complexity, decidability and undecidability results for domain-independent planning. </title> <booktitle> Artificial Intelligence 76 </booktitle> <pages> 75-88. </pages>
Reference: <author> Frank, I.; Basin, D.; and Bundy, A. </author> <year> 1992. </year> <title> An adaptation of proof-planning to declarer play in bridge. </title> <booktitle> In European Conference on Artificial Intelligence. </booktitle>
Reference: <author> Frank, I. and Basin, D. </author> <year> 1996. </year> <title> Search in games with incomplete information: a case study using bridge card play. Under review. </title>
Reference: <author> Gamback, B.; Rayner, M.; and Pell, B. </author> <year> 1990. </year> <title> An architecture for a sophisticated mechanical bridge player. </title> <editor> In Beal, D. F. and Levy, D.N.L., editors, </editor> <booktitle> Heuristic Programming in Artificial IntelligenceThe Second Computer Olympiad. </booktitle> <publisher> Ellis Horwood, </publisher> <address> Chichester, UK. </address>
Reference: <author> Gamback, B.; Rayner, M.; and Pell, B. </author> <year> 1993. </year> <title> Pragmatic reasoning in bridge. </title> <type> Tech. Report 299, </type> <institution> Computer Laboratory, University of Cambridge. </institution>
Reference: <author> Ginsberg, M. </author> <year> 1996. </year> <title> How computers will play bridge. Bridge World, </title> <note> to appear. </note>
Reference: <author> Gmytrasiewicz, P. J. and Durfee, E. H. </author> <year> 1992. </year> <title> Decision-theoretic recursive modeling and the coordinated attack problem. </title> <booktitle> In Proceedings of the 1st International Conference on AI Planning Systems, </booktitle> <editor> James Hendler, editor. </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, Cali-fornia. </address>
Reference: <author> Haddawy, P.; Doan, A.; and Goodwin, R. </author> <year> 1995. </year> <title> Efficient decision-theoretic planning: techniques and empirical analysis. </title> <booktitle> In Proceedings UAI95, </booktitle> <pages> 229-236. </pages>
Reference: <author> Hebbar, K.; Smith, S. J. J.; Minis, I.; and Nau, D. S. </author> <year> 1996. </year> <title> Plan-based evaluation of designs for microwave modules. ASME Design for Manufacturing conference, </title> <note> to appear. </note>
Reference-contexts: We describe why these modifications were needed in order to build a successful planner for the game of bridge. * This same modified HTN planning strategy appears to be useful in a variety of application domains. For example, as described in <ref> (Hebbar et al. 1996) </ref>, the same planning techniques (and some of the same code!) used in Tignum 2 have been used to build a process-planning system for the manufacture of complex electro-mechanical devices. We discuss why the same kind of planning technique has been successful in two such diverse domains. <p> have been quite successful in applying Tignum 2's total-order HTN planning technique (as well as some of the same code used in Tignum 2!) to another application domain very different from bridge: the task of generating process plans for the manufacture of complex electro-mechanical devices such as microwave transmit-receive modules <ref> (Hebbar et al. 1996) </ref>. That this same set of techniques should occur in two such widely varying areas is quite striking.
Reference: <author> Horacek, H. </author> <year> 1990. </year> <title> Reasoning with uncertainty in computer chess. </title> <booktitle> Artificial Intelligence 43 </booktitle> <pages> 37-56. </pages>
Reference: <author> Khemani, D. </author> <year> 1994. </year> <title> Planning with thematic actions. </title> <booktitle> In Proceedings of the 2nd International Conference on AI Planning Systems, </booktitle> <editor> Kristian Hammond, editor. </editor> <publisher> AAAI Press, </publisher> <address> Menlo Park, California. </address>
Reference: <author> Kushmerick, N.; Hanks, S.; and Weld, D. </author> <year> 1994. </year> <title> An algorithm for probabilistic least-commitment planning. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> 1123-1128. </pages> <publisher> AAAI, </publisher> <address> Menlo Park, California. </address>
Reference: <author> Lee, K.-F. and Mahajan, S. </author> <year> 1990. </year> <title> The development of a world class othello program. </title> <booktitle> Artificial Intelligence 43 </booktitle> <pages> 21-36. </pages>
Reference-contexts: Background Although game-tree search works well in perfect-information games (such as chess (Levy & Newborn 1982; Berliner et al. 1990), checkers (Samuel 1967; Schaeffer et al. 1992), and othello <ref> (Lee & Maha-jan 1990) </ref>), it does not always work as well in other games. One example is the game of bridge. Bridge is an imperfect-information game, in which no player has complete knowledge about the state of the world, the possible actions, and their effects.
Reference: <author> Levy, D. and Newborn, M. </author> <year> 1982. </year> <title> All About Chess and Computers. </title> <publisher> Computer Science Press. </publisher>
Reference: <author> Lin, S.-H. and Dean, T. </author> <year> 1995. </year> <title> Generating optimal policies for Markov decision processes formulated as plans with conditional branches and loops. </title> <booktitle> In Third European Workshop on Planning. </booktitle>
Reference: <author> Lindelof, E. </author> <year> 1983. </year> <title> COBRA: the computer-designed bidding system. </title> <publisher> Victor Gollancz Ltd, </publisher> <address> London, UK. </address>
Reference: <author> Lopatin, A. </author> <year> 1992. </year> <title> Two combinatorial problems in programming bridge game. </title> <note> Computer Olympiad, unpublished. </note>
Reference-contexts: One approach is to make assumptions about the placement of the opponents' cards based on information from the bidding and prior play, and then search the game tree resulting from these assumptions. This approach was taken in the Alpha Bridge program <ref> (Lopatin 1992) </ref>, with a 20-ply (5-trick) search. However, this approach didn't work very well: at the 1992 Computer Olympiad, Alpha Bridge placed last. Game-Tree Search with Uncertainty.
Reference: <author> Manley, B. </author> <year> 1993. </year> <title> Software `judges' rate bridge-playing products. </title> <journal> The Bulletin (published monthly by the American Contract Bridge League), </journal> <volume> 59(11), Novem-ber </volume> 1993 51-54. 
Reference-contexts: We discuss why the same kind of planning technique has been successful in two such diverse domains. In this paper, we present only a sketch of our approach. Full details of our approach are in (Smith, Nau, & Throop 1996). and in their review of seven commercially available programs <ref> (Manley 1993) </ref>, the ACBL rated the Bridge Baron to be the best of the seven, and the skill of the Bridge Baron to be the best of the five that do declarer play without peeking at the opponents' cards.
Reference: <author> Pednault, E. P. D. </author> <year> 1987. </year> <title> Solving multiagent dynamic world problems in the classical planning framework. </title> <booktitle> In Reasoning about Actions and Plans: Proceedings of the 1986 Workshop, </booktitle> <pages> 42-82. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, California. </address>
Reference: <author> Peot, M. and Smith, D. </author> <year> 1992. </year> <title> Conditional nonlinear planning. </title> <booktitle> In Proc. First Internat. Conf. AI Planning Systems, </booktitle> <pages> 189-197. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, Cal-ifornia. </address>
Reference: <author> Quinlan, J. R. </author> <year> 1979. </year> <title> A knowledge-based system for locating missing high cards in bridge. </title> <booktitle> In Proc. 6th International Joint Conf. Artificial Intelligence, </booktitle> <pages> pp. 705-707. </pages>
Reference: <author> Sacerdoti, E. D. </author> <year> 1977. </year> <title> A Structure for Plans and Behavior. </title> <publisher> American Elsevier Publishing Company. </publisher>
Reference-contexts: To represent the tactical and strategic schemes of card-playing in bridge, we use multi-agent methodsstructures similar to the action schemas or methods used in hierarchical single-agent planning systems such as Nonlin (Tate 1977), NOAH <ref> (Sacerdoti 1977) </ref>, O-Plan (Currie & Tate 1985), and SIPE (Wilkins 1984; Wilkins 1988), but modified to represent multi-agency and uncertainty. To generate game trees, we use a procedure similar to task decomposition.
Reference: <author> Samuel, A. L. </author> <year> 1967. </year> <title> Some studies in machine learning using the game of checkers. </title> <journal> ii-recent progress. IBM Journal of Research and Development 2 </journal> <pages> 601-617. </pages>
Reference: <author> Schaeffer, J.; Culberson, J.; Treloar, N.; Knight, B.; Lu, P.; and Szafron, D. </author> <year> 1992. </year> <title> A world championship caliber checkers program. </title> <booktitle> Artificial Intelligence 53 </booktitle> <pages> 273-290. </pages>
Reference: <author> Smith, S. J. J. and Nau, D. S. </author> <year> 1994. </year> <title> An analysis of forward pruning. </title> <booktitle> In Proc. 12th National Conference on Artificial Intelligence, </booktitle> <pages> pp. 1386-1391. </pages>
Reference-contexts: Although forward pruning has not worked very well in games such as chess (Biermann 1978; Truscott 1981), our recent study of forward pruning <ref> (Smith & Nau 1994) </ref> suggests that forward pruning works best in situations where there is a high correlation among the minimax values of sibling nodes. Part of our motivation for the development of Tignum 2 is our belief that bridge has this correlation.
Reference: <author> Smith, S. J. J.; Nau, D. S.; and Throop, T. </author> <year> 1996. </year> <title> A planning approach to declarer play in contract bridge. </title> <booktitle> Computational Intelligence, </booktitle> <address> 12:1, </address> <month> February </month> <year> 1996, </year> <pages> 106-130. </pages>
Reference-contexts: We discuss why the same kind of planning technique has been successful in two such diverse domains. In this paper, we present only a sketch of our approach. Full details of our approach are in <ref> (Smith, Nau, & Throop 1996) </ref>. and in their review of seven commercially available programs (Manley 1993), the ACBL rated the Bridge Baron to be the best of the seven, and the skill of the Bridge Baron to be the best of the five that do declarer play without peeking at the
Reference: <author> Stanier, A. </author> <year> 1975. </year> <title> Bribip: a bridge bidding program. </title> <booktitle> In Proc. 4th International Joint Conf. Artificial Intelligence. </booktitle>
Reference: <author> Sterling, L. and Nygate, Y. </author> <year> 1990. </year> <title> Python: an expert squeezer. </title> <journal> Journal of Logic Programming 8 </journal> <pages> 21-39. </pages>
Reference: <author> Tate, A. </author> <year> 1977. </year> <title> Generating project networks. </title> <booktitle> In Proc. 5th International Joint Conf. Artificial Intelligence. </booktitle>
Reference-contexts: To represent the tactical and strategic schemes of card-playing in bridge, we use multi-agent methodsstructures similar to the action schemas or methods used in hierarchical single-agent planning systems such as Nonlin <ref> (Tate 1977) </ref>, NOAH (Sacerdoti 1977), O-Plan (Currie & Tate 1985), and SIPE (Wilkins 1984; Wilkins 1988), but modified to represent multi-agency and uncertainty. To generate game trees, we use a procedure similar to task decomposition.
Reference: <author> Truscott, T. R. </author> <year> 1981. </year> <title> Techniques used in minimax game-playing programs. </title> <type> Master's thesis, </type> <institution> Duke University, Durham, NC. </institution>
Reference: <author> Wilkins, D. E. </author> <year> 1980. </year> <title> Using patterns and plans in chess. </title> <booktitle> Artificial Intelligence 14 </booktitle> <pages> 165-203. </pages>
Reference: <author> Wilkins, D. E. </author> <year> 1982. </year> <title> Using knowledge to control tree searching. </title> <booktitle> Artificial Intelligence 18 </booktitle> <pages> 1-51. </pages>
Reference: <author> Wilkins, D. E. </author> <year> 1984. </year> <title> Domain independent planning: representation and plan generation. </title> <booktitle> Artificial Intelligence 22 </booktitle> <pages> 269-301. </pages>
Reference: <author> Wilkins, D. E. </author> <year> 1988. </year> <title> Practical Planning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address>
Reference-contexts: That this same set of techniques should occur in two such widely varying areas is quite striking. In particular, we can make the following observations: * HTN planning has long been thought to be more useful in practical planning domains than planning with STRIPS-style operators <ref> (Wilkins 1988) </ref>, and our experience confirms this opinion. Bridge has a natural element of hierarchical planning. Humans use hierarchies of schemes to create plans to play bridge deals. The bridge literature describes many such schemes.
References-found: 44

