URL: ftp://speech.cse.ogi.edu/pub/docs/nips93orr.ps.Z
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Title: Optimal Stochastic Search and Adaptive Momentum  
Author: Todd K. Leen and Genevieve B. Orr 
Address: P.O.Box 91000, Portland, Oregon 97291-1000  
Affiliation: Oregon Graduate Institute of Science and Technology Department of Computer Science and Engineering  
Abstract: Stochastic optimization algorithms typically use learning rate schedules that behave asymptotically as (t) = 0 =t. The ensemble dynamics (Leen and Moody, 1993) for such algorithms provides an easy path to results on mean squared weight error and asymptotic normality. We apply this approach to stochastic gradient algorithms with momentum. We show that at late times, learning is governed by an effective learning rate eff = 0 =(1 fi) where fi is the momentum parameter. We describe the behavior of the asymptotic weight error and give conditions on eff that insure optimal convergence speed. Finally, we use the results to develop an adaptive form of momentum that achieves optimal convergence speed independent of 0 .
Abstract-found: 1
Intro-found: 1
Reference: <author> D. Bedeaux, K. Laktos-Lindenberg, and K. Shuler. </author> <title> (1971) On the Relation Between Master Equations and Random Walks and their Solutions. </title> <journal> Journal of Mathematical Physics, </journal> <volume> 12 </volume> <pages> 2116-2123. </pages>
Reference: <author> Christian Darken and John Moody. </author> <title> (1992) Towards Faster Stochastic Gradient Search. </title> <editor> In J.E. Moody, S.J. Hanson, and R.P. Lipmann (eds.) </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> vol. 4. </volume> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <pages> 1009-1016. </pages>
Reference: <author> Larry Goldstein. </author> <title> (1987) Mean Square Optimality in the Continuous Time Robbins Monro Procedure. </title> <type> Technical Report DRB-306, </type> <institution> Dept. of Mathematics, University of Southern California, LA. </institution>
Reference: <author> H.J. Kushner and D.S. Clark. </author> <title> (1978) Stochastic Approximation Methods for Constrained and Unconstrained Systems. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference: <author> Tom M. Heskes, Eddy T.P. Slijpen, and Bert Kappen. </author> <title> (1992) Learning in Neural Networks with Local Minima. </title> <journal> Physical Review A, </journal> <volume> 46(8) </volume> <pages> 5221-5231. </pages>
Reference: <author> Todd K. Leen and John E. Moody. </author> <title> (1993) Weight Space Probability Densities in Stochastic Learning: I. Dynamics and Equilibria. </title> <editor> In Giles, Hanson, and Cowan (eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> vol. 5, </volume> <publisher> Morgan Kauf-mann Publishers, </publisher> <address> San Mateo, CA, </address> <pages> 451-458. </pages>
Reference: <author> G. B. Orr and T. K. Leen. </author> <title> (1993) Weight Space Probability Densities in Stochastic Learning: II. Transients and Basin Hopping Times. </title> <editor> In Giles, Hanson, and Cowan (eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> vol. 5, </volume> <publisher> Morgan Kauf-mann Publishers, </publisher> <address> San Mateo, CA, </address> <pages> 507-514. </pages>
Reference: <author> G. B. Orr and T. K. Leen. </author> <title> (1994) Momentum and Optimal Stochastic Search. </title> <editor> In M. C. Mozer, P. Smolensky, D. S. Touretzky, J. L. Elman, and A. S. Weigend (eds.), </editor> <booktitle> Proceedings of the 1993 Connectionist Models Summer School, </booktitle> <pages> 351-357. </pages>
Reference-contexts: Curves correspond to (top to bottom) 0 = 0.2, 0.4, 0.6, 0.8, 1.0, 1.5 . By minimizing the coefficient of 1=t in (9), the optimal learning rate is found to be opt = 1= min . This formalism also yields asymptotic normality rather simply <ref> (Orr and Leen, 1994) </ref>. These conditions for "optimal" (i.e. 1=t) convergence of the weight error correlation and the related results on asymptotic normality have been previously discussed in the stochastic approximation literature (Darken and Moody, 1992; Goldstein, 1987; White, 1989; and references therein) . <p> The upper three curves (dotted) show the behavior of E [jvj 2 ] for eff &lt; crit . The solid curves show the behavior for eff &gt; crit . The derivation of asymptotic normality proceeds similarly to the case without momentum. Again the reader is referred to <ref> (Orr and Leen, 1994) </ref> for details. Fig.2: LEFT Simulation results from an ensemble of 2000 one-dimensional LMS algorithms with momentum with R = 1:0, 2 = 1:0, and 0 = 0:2. RIGHT - Theoretical predictions from equation (19).
Reference: <author> John J. Shynk and Sumit Roy. </author> <title> (1988) The LMS Algorithm with Momentum Updating. </title> <booktitle> Proceedings of the IEEE International Symposium on Circuits and Systems, </booktitle> <pages> 2651-2654. </pages>
Reference: <author> Mehmet Ali Tugay and Yal~cin Tanik. </author> <title> (1989) Properties of the Momentum LMS Algorithm. </title> <booktitle> Signal Processing, </booktitle> <volume> 18 </volume> <pages> 117-127. </pages>
Reference: <author> J. H. Venter. </author> <title> (1967) An Extension of the Robbins-Monro Procedure. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 38 </volume> <pages> 181-190. </pages>
Reference-contexts: These results suggest a new algorithm that automatically adjusts the momentum coefficient to achieve the optimal convergence rate. This algorithm is simpler than previous approaches that either estimate the curvature directly during the descent <ref> (Venter, 1967) </ref> or measure an auxilliary statistic not directly involved in the optimization (Darken and Moody, 1992). 2 Density Evolution and Asymptotics We consider stochastic optimization algorithms with weight ! 2 R N .
Reference: <author> Halbert White. </author> <title> (1989) Learning in Artificial Neural Networks: A Statistical Perspective. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 425-464. </pages>
References-found: 12

