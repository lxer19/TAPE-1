URL: ftp://speech.cse.ogi.edu/pub/docs/autolangid_euros93.ps.Z
Refering-URL: http://www.cse.ogi.edu/~berkling/vitae.html
Root-URL: http://www.cse.ogi.edu
Title: A COMPARISON OF APPROACHES TO AUTOMATIC LANGUAGE IDENTIFICATION USING TELEPHONE SPEECH  
Author: Yeshwant Muthusamy Kay Berkling Takayuki Arai Ronald Cole Etienne Barnard 
Address: 20000 N.W. Walker Road, P.O. Box 91000, Portland, OR 97291-1000 USA  
Affiliation: Center for Spoken Language Understanding, Oregon Graduate Institute of Science and Technology,  
Abstract: A variety of approaches to language identification, based on (a) acoustic features, (b) broad-category segmentation, and (c) fine phonetic classification, are introduced. These approaches are evaluated in terms of their ability to distinguish between English and Japanese utterances spoken over a telephone channel. It is found that the best performance (86.3 % accurate classification of utterances with a mean length of 13.4 sec) is obtained when fine phonetic features are employed. In addition, the results show the importance of discriminatory training rather than likelihood estimation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Barnard and R. Cole. </author> <title> A neural-net training program based on conjugate-gradient optimization. </title> <type> Technical Report CSE 89-014, </type> <institution> Oregon Graduate Institution, </institution> <year> 1989. </year>
Reference-contexts: All neural network classifiers used here are fully-connected, feed-forward networks trained using backpropagation with conjugate gradient optimization <ref> [1] </ref>. The number of hidden nodes was derived experimentally for each case. In all cases the acoustic representation used is a seventh order Perceptual Linear Predictive (PLP) model [4], yielding 8 coefficients (including one for energy).
Reference: [2] <author> Mark Fanty, Ronald A. Cole, and Krist Roginski. </author> <title> English alphabet recognition with telephone speech. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 199-206, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: The input to the segmenter consists of 120 spectral features derived from a PLP analysis [4] of the waveform. The features were empirically derived to capture the contextual information in the vicinity of each frame <ref> [2] </ref>. A Viterbi search, which incorporates duration and bigram probabilities from ten languages, uses these frame-based output activations to find the best scoring sequence of broad phonetic category labels spanning the utterance. Several networks were trained and evaluated on the development set.
Reference: [3] <author> Mark Fanty, Philipp Schmid, and Ronald Cole. </author> <title> City name recognition over the telephone. </title> <booktitle> In International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 549-552, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Phoneme Classification For each sampled frame, 56 (= 8fi7) PLP coefficients within a 174 msec window, centered on the frame to be classified, were computed and served as input to each of the phonetic classifiers <ref> [3] </ref>. The English classifier assigns 39 phonemic category scores to each 6 msec time frame. The 39 labels provide a quasi-phonemic level of description, in which most allophonic variations are ignored. Similarly a Japanese network is trained with 25 output nodes representing each of the phoneme categories.
Reference: [4] <author> H. Hermansky. </author> <title> Perceptual Linear Predictive (PLP) analysis of speech. </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 87(4) </volume> <pages> 1738-1752, </pages> <year> 1990. </year>
Reference-contexts: All neural network classifiers used here are fully-connected, feed-forward networks trained using backpropagation with conjugate gradient optimization [1]. The number of hidden nodes was derived experimentally for each case. In all cases the acoustic representation used is a seventh order Perceptual Linear Predictive (PLP) model <ref> [4] </ref>, yielding 8 coefficients (including one for energy). This is computed on a 10 msec interval of speech, time shifted every 3 msec for the approaches based on acoustic features and broad-category segmentation, and every 6 msec for the fine-phonetic approach. 2.1. <p> The broad phonetic categories are: vowel (VOC), fricative (FRIC), stop (STOP), pre-vocalic sonorant (PRVS), inter-vocalic sonorant (PRVS), post-vocalic sonorant (POVS), and closure or silence or background noise (CLOS). The input to the segmenter consists of 120 spectral features derived from a PLP analysis <ref> [4] </ref> of the waveform. The features were empirically derived to capture the contextual information in the vicinity of each frame [2].
Reference: [5] <author> Y. K. Muthusamy. </author> <title> A Segmental Approach to Automatic Language Identification. </title> <type> PhD thesis, </type> <institution> Oregon Graduate Institute, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: Section 3 describes the results obtained with these approaches, and a discussion is contained in Section 4. 2. THREE APPROACHES TO LANGUAGE IDENTIFICATION This section describes (a) a one-stage approach based on raw acoustic features, (b) a two-stage approach broad phonetic segmentation <ref> [5] </ref> is performed in a first stage before extracting features for language classification in a second stage -, and (c) another two-stage approach, in which the broad-category segmentation in (b) is replaced by a fine phonetic classifier.
Reference: [6] <author> Y. K. Muthusamy and R. A. Cole. </author> <title> Automatic segmentation and identification of ten languages using telephone speech. </title> <booktitle> In Proceedings International Conference on Spoken Language Processing 92, </booktitle> <address> Banff, Alberta, Canada, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: Dashed boxes indicate intervals that are skipped. 2.2. Identification using broad phonetic categories 2.2.1. Broad-Category Segmenter Broad-category segmentation is performed by a fully-connected, feed-forward, three-layer neural network that assigns 7 broad phonetic category scores to each 3 ms time frame of the utterance <ref> [6] </ref>. The broad phonetic categories are: vowel (VOC), fricative (FRIC), stop (STOP), pre-vocalic sonorant (PRVS), inter-vocalic sonorant (PRVS), post-vocalic sonorant (POVS), and closure or silence or background noise (CLOS). The input to the segmenter consists of 120 spectral features derived from a PLP analysis [4] of the waveform.
Reference: [7] <author> Y. K. Muthusamy, R. A. Cole, and B. T. Oshika. </author> <title> The OGI multi-language telephone speech corpus. </title> <booktitle> In Proceedings International Conference on Spoken Language Processing 92, </booktitle> <pages> pages 895-898, </pages> <address> Banff, Alberta, Canada, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: Also, our focus is on telephone speech, since this is likely to be the most important application of automatic language identification in the near future. The data employed are taken from the OGI-TS corpus <ref> [7] </ref>, and are described in more detail in Section 3. In section 2 we describe the three approaches to automatic language identification (LID) studied here. Section 3 describes the results obtained with these approaches, and a discussion is contained in Section 4. 2. <p> This scaling factor was chosen to give optimal training-set performance.) 3. RESULTS 3.1. Training and test data 3.1.1. Multi-Language Telephone Speech Corpus The segmentation and classification algorithms were developed and evaluated using the OGI Multi-language Telephone Speech Corpus, described in <ref> [7] </ref>. Both the training and test utterances were hand-labeled with the seven broad phonetic category or phoneme labels as necessary. 3.1.2. <p> Several extensions of this work are now being investigated. As was mentioned above, it is necessary to study the generality of our results with respect to other languages; we are therefore also comparing various approaches on the full ten-language set in the OGI Corpus <ref> [7] </ref>. In addition, the successes of the fine-phonetic approach have prompted us to design methods which perform even more detailed classifications in the first stage. These methods are now being evaluated. 5. ACKNOWLEDGEMENTS We thank Beatrice T.
References-found: 7

