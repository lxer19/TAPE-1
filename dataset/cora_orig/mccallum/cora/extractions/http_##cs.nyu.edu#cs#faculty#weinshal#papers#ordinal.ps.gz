URL: http://cs.nyu.edu/cs/faculty/weinshal/papers/ordinal.ps.gz
Refering-URL: http://cs.nyu.edu/cs/faculty/weinshal/papers.html
Root-URL: http://www.cs.nyu.edu
Email: daphna@cs.huji.ac.il  anandan@microsoft.com  irani@wisdom.weizmann.ac.il  
Title: From Ordinal to Euclidean Reconstruction with Partial Scene Calibration  
Author: Daphna Weinshall P. Anandan Micahl Irani 
Keyword: projective reconstruction, affine reconstruction, partial calibration, qualitative depth  
Address: 91904 Jerusalem, Israel  One Microsoft Way Redmond, WA 98052  Rehovot, Israel  
Affiliation: Inst. of Computer Sci. Hebrew University  Microsoft Research  Dept. of Appl. Math and CS The Weizmann Inst. of Sci.  
Abstract: Since uncalibrated images permit only projective reconstruction, metric information requires either camera or scene calibration. We propose a stratified approach to projective reconstruction, in which gradual increase in domain information for scene calibration leads to gradual increase in 3D information. Our scheme includes the following steps: (1) Register the images with respect to a reference plane; this can be done using limited scene information, e.g., the knowledge that two pairs of lines on the plane are parallel. We show that this calibration is sufficient for ordinal reconstruction sorting the points by their height over the reference plane. (2) If available, use the relative height of two additional out-of-plane points to compute the height of the remaining points up to constant scaling. Our scheme is based on the dual epipolar geometry in the reference frame, which we develop below. We show good results with five sequences of real images, using mostly scene calibration that can be inferred directly from the images themselves.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Irani, P. Anandan, and D. Weinshall. </author> <title> From Reference Frames to Reference Planes: </title> <booktitle> Multi-view Parallax Geometry and Applications In Proc. 5th ECCV, </booktitle> <address> Freiburg, Germany, </address> <month> June </month> <year> 1998. </year>
Reference-contexts: The "Height" (Z) of each scene point is determined by analyzing the disparity between the positions of each scene point on the multiple reference plane images 1 . The basic relationships associated with multi-view parallax geometry (with respect to a reference plane) are described in our recent paper <ref> [1] </ref>. However, while [1] focuses on the geometric relationships and elaborated on one application (namely "new view synthesis"), the present paper focuses on the use of this framework for stratified reconstruction, based on partial scene calibration. <p> The basic relationships associated with multi-view parallax geometry (with respect to a reference plane) are described in our recent paper <ref> [1] </ref>. However, while [1] focuses on the geometric relationships and elaborated on one application (namely "new view synthesis"), the present paper focuses on the use of this framework for stratified reconstruction, based on partial scene calibration. The specification of the geometric information about the reference plane amounts to "registering" the reference plane.
Reference: [2] <author> B. Boufama, D. Weinshall, and M. Werman. </author> <title> Shape from motion algorithms: a comparative analysis of scaled orthography and perspective. </title> <booktitle> In Proc. 3rd ECCV, </booktitle> <pages> pages 199-204, </pages> <address> Stockholm, Sweden, </address> <year> 1994. </year>
Reference-contexts: For example, the scene calibration needed by the reconstruction algorithm described in [15] includes the specification of the 3D coordinates of 5 reference points (supplied by an oracle) - 15 d.o.f. We used this method in <ref> [2] </ref> to accomplish reconstruction with the first two sequences described above. <p> In Springer LNCS: 3D Structure from Multiple Images of Large Scale Environments, 6/98. 11 a) b) c) rug); c) ordinal height. non-linear algorithm, the reconstruction results in <ref> [2] </ref> are no better than our results here (e.g., a relative error of about 5% 10% per datapoint using the second sequence). 5 Summary Since uncalibrated images only permit projective reconstruction, no metric information (such as relative depth) can be deduced without some calibration, either camera calibration (external and internal parameters
Reference: [3] <author> S. Carlsson. </author> <title> Duality of reconstruction and positioning from projective views. In Workshop on Representations of Visual Scenes, </title> <year> 1995. </year>
Reference-contexts: These dual relations are similar to those previously described in <ref> [3, 21, 4] </ref>, where they were derived with respect to the quantities from the actual image points; here the dual relations are derived in the context of the reference-plane images.
Reference: [4] <author> S. Carlsson and D. Weinshall. </author> <title> Dual Computation of Projective Shape and Camera Positions from Multiple Images. </title> <journal> IJCV, </journal> <volume> 27(3), </volume> <year> 1998. </year>
Reference-contexts: These dual relations are similar to those previously described in <ref> [3, 21, 4] </ref>, where they were derived with respect to the quantities from the actual image points; here the dual relations are derived in the context of the reference-plane images.
Reference: [5] <author> A. Criminisi, I. Reid, and A. Zisserman. </author> <title> Duality, rigidity, and planar parallax. </title> <booktitle> In Proc. 5th ECCV, </booktitle> <address> Freiburg, Germany, </address> <month> June </month> <year> 1998. </year>
Reference-contexts: Unlike the case with camera calibration and active vision, there are no results on partial scene calibration which could give partial metric information. Our approach fills in this gap (a related approach is independently described in <ref> [5] </ref>); we investigate partial scene calibration which can be used to obtain some metric information from uncalibrated images.
Reference: [6] <author> O.D. Faugeras. </author> <title> What can be seen in three dimensions with an uncalibrated stereo rig? In Proc. </title> <booktitle> 1st ECCV, </booktitle> <pages> pages 563-578, </pages> <address> Santa Margarita Ligure, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Given multiple images, stratified 3D reconstruction can be obtained depending on the available camera and scene calibration. In general uncalibrated images permit only projective reconstruction <ref> [6] </ref>, which is of limited use; for example, we cannot determine from projective structure which part of the object is in front of the other. Its topological nature makes this representation useful primarily for verification, e.g., object recognition; for most other applications some scene or camera calibration is needed.
Reference: [7] <author> O.D. Faugeras. </author> <title> Stratification of three-dimensional vision:projective, affine and metric representations. </title> <journal> JOSA, </journal> <volume> 12(3) </volume> <pages> 465-484, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: This research was done while DW was on sabbatical at NECI Princeton. 1 In Springer LNCS: 3D Structure from Multiple Images of Large Scale Environments, 6/98. 2 by invariance to increasingly smaller groups of transformations in R 3 : projective, affine and similarity (scaled Euclidean) <ref> [7] </ref>. The usefulness of techniques using scene calibration is limited to cases when the needed 3D information is available. Unlike the case with camera calibration and active vision, there are no results on partial scene calibration which could give partial metric information.
Reference: [8] <author> O. Faugeras and B. Mourrain. </author> <title> On the geometry and algebra of the point and line correspondences between N images. </title> <booktitle> In Proc. </booktitle> <address> ECW. </address> <publisher> Xidian University Press, </publisher> <year> 1995. </year> <title> In Springer LNCS: 3D Structure from Multiple Images of Large Scale Environments, </title> <type> 6/98. 12 </type>
Reference-contexts: From (3) we get the epipolar and dual-epipolar geometry on the reference plane. 2.3 Epipolar Geometry on the Reference Plane: The epipolar geometry is obtained by the elimination of the 3D point coordinates from (3). In the following derivation we follow the method described in <ref> [8] </ref>.
Reference: [9] <author> C. Fermuller and Y. Aloimonos. </author> <title> Ordinal Representations of Visual Space. </title> <booktitle> In Proc. DARPA Image Understand Workshop. </booktitle> <year> 1996. </year>
Reference-contexts: show that ordinal information about the 3D scene can be obtained even with very little scene calibration data, e.g., we can compute height ordering with respect to a plane from knowing (or guessing) the existence of two pairs of parallel lines on the plane; we call this ordinal reconstruction (cf. <ref> [22, 13, 9] </ref>). By providing additional domain-information (e.g., heights of one or two out-of-plane points), we can gradually obtain more metric 3D information, achieving affine and Euclidean reconstruction.
Reference: [10] <author> Richard Hartley. </author> <title> Euclidean Reconstruction from Uncalibrated Views. In Applications of Invariance in Computer Vision, </title> <editor> J.L. Mundy, D. Forsyth, and A. Zisserman (Eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: With calibrated cameras, or if self calibration is possible (when the same camera with partially fixed internal parameters is used to obtain all the images), Euclidean reconstruction can be obtained <ref> [10, 18] </ref>. Alternatively, active vision techniques, based on imposing constraints on the viewing geometry and/or the camera motion, can be used. Such externally imposed constraints may simplify the problem enough to permit affine or Euclidean reconstruction, e.g., [23] (see also [24]).
Reference: [11] <author> M. Irani and P. Anandan. </author> <title> Parallax geometry of pairs of points for 3D scene analysis. </title> <booktitle> In Proc. 3rd ECCV, </booktitle> <address> Cambridge, UK, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: Similar to the case of the fundamental matrix F , the dual fundamental Matrix G is determined by the coordinates of the dual epipole p ij <ref> [11] </ref>, which is obtained by projecting the scene point P i through P j onto the reference plane. <p> In the last two sequences, a reference plane in the scene was stabilized first, then a dense parallax flow field was recovered <ref> [11, 14] </ref>. The reconstruction was then based on this parallax data. In this case, the images were obtained using a hand-held video camera in a casual manner, without making controled measurements of the camera or scene parameters.
Reference: [12] <author> M. Irani and P. Anandan. </author> <title> A unified approach to moving object detection in 2D and 3D scenes. </title> <journal> IEEE Trans. on PAMI, </journal> <note> in press. </note>
Reference-contexts: The residual parallax displacements between the points were then computed using the method described in [14]. These displacements were used as input for the stratified reconstruction of the scene. The first example uses the "Toys" image sequence previously used in <ref> [12] </ref>, see Figure 2a. The scene consists of a few toys standing on a rug. In order to register the images to the reference plane (upto 2D affine transformation), we used the following approach.
Reference: [13] <author> J. J. Koenderink and A. J. van Doorn. </author> <title> Affine structure from motion. </title> <journal> JOSA, </journal> <volume> 8(2) </volume> <pages> 377-385, </pages> <year> 1991. </year>
Reference-contexts: show that ordinal information about the 3D scene can be obtained even with very little scene calibration data, e.g., we can compute height ordering with respect to a plane from knowing (or guessing) the existence of two pairs of parallel lines on the plane; we call this ordinal reconstruction (cf. <ref> [22, 13, 9] </ref>). By providing additional domain-information (e.g., heights of one or two out-of-plane points), we can gradually obtain more metric 3D information, achieving affine and Euclidean reconstruction.
Reference: [14] <author> R. Kumar, P. Anandan, and K. Hanna. </author> <title> Direct recovery of shape from multiple views: a parallax based approach. </title> <booktitle> In Proc 12th ICPR, </booktitle> <year> 1994. </year>
Reference-contexts: Section 3 describes how we use these relations for the stratified reconstruction of the 3D scene. Section 4 illustrates our approach with real-image examples. 1 A related approach called "plane+parallax" was taken in <ref> [14, 19] </ref>, but there 3D reconstruction was relative to the coordinate systems of both the reference plane and a reference image. <p> In the last two sequences, a reference plane in the scene was stabilized first, then a dense parallax flow field was recovered <ref> [11, 14] </ref>. The reconstruction was then based on this parallax data. In this case, the images were obtained using a hand-held video camera in a casual manner, without making controled measurements of the camera or scene parameters. <p> Given two input images, we used the method described in [20] to first estimate the homography that aligns a dominant planar surface in the scene between the two images. The residual parallax displacements between the points were then computed using the method described in <ref> [14] </ref>. These displacements were used as input for the stratified reconstruction of the scene. The first example uses the "Toys" image sequence previously used in [12], see Figure 2a. The scene consists of a few toys standing on a rug.
Reference: [15] <author> R. Mohr, , L. Quan, F. Veillon, and B. Boufama. </author> <title> Relative 3D reconstruction using multiple uncalibrated images. RT 84-IMAG-12 LIFIA, </title> <type> Uni. </type> <institution> of Grenoble, </institution> <year> 1992. </year>
Reference-contexts: The alternative to active vision and self camera calibration is to use scene calibration. Thus projective reconstruction can be turned into Euclidean reconstruction if the 3D coordinates of five points are given <ref> [15] </ref>. Computing Euclidean reconstruction from affine reconstruction requires that the 3D coordinates of four points are given. These results were used to formulate a stratified approach to reconstruction, characterized fl MI and DW are supported in part by DARPA through ARL Contract DAAL01-97-K-0101. <p> This information only permits ordinal reconstruction in our scheme. In addition, in order to achieve affine reconstruction we need to know the relative height of one 3D point; this requirement still seems easier to meet than the knowledge of the 3D coordinates of five 3D points, as required in <ref> [15] </ref>. More specifically, we compute non-invariant reconstruction in a special coordinate system. This coordinate system is defined relative to a physical (real or virtual) planar surface in the scene. <p> Thus we used 2-4 d.o.f. of scene calibration information, much less than required by other reconstruction algorithms which use scene calibration. For example, the scene calibration needed by the reconstruction algorithm described in <ref> [15] </ref> includes the specification of the 3D coordinates of 5 reference points (supplied by an oracle) - 15 d.o.f. We used this method in [2] to accomplish reconstruction with the first two sequences described above.
Reference: [16] <author> H. S. Sawhney, J. Oliensis, and A. R. Hanson. </author> <title> Description and reconstruction from image trajectories of rotational motion. </title> <booktitle> In Proc. 3rd ICCV, </booktitle> <address> Osaka, Japan, </address> <year> 1990. </year>
Reference: [17] <author> L. Robert and O.D. Faugeras. </author> <title> Relative 3D Positioning and 3D Convex Hull Computation from a Weakly Calibrated Stereo Pair. </title> <journal> J. Imaging and Vision Compting, </journal> <volume> 13(3), </volume> <year> 1995. </year>
Reference-contexts: The specification of the geometric information about the reference plane amounts to "registering" the reference plane. Such registration, with no 3D calibration, is sufficient to determine whether points lie on the same side of the plane <ref> [17] </ref>.
Reference: [18] <author> M. Pollyfeys, R. Koch, and L. van Gool. </author> <title> Self-calibration and Metric Reconstruction in Spite of Varying and Unknown Internal Camera Parameters. </title> <booktitle> In Proc. 6th ICCV, </booktitle> <address> Mumbai, India, </address> <month> January </month> <year> 1998. </year>
Reference-contexts: With calibrated cameras, or if self calibration is possible (when the same camera with partially fixed internal parameters is used to obtain all the images), Euclidean reconstruction can be obtained <ref> [10, 18] </ref>. Alternatively, active vision techniques, based on imposing constraints on the viewing geometry and/or the camera motion, can be used. Such externally imposed constraints may simplify the problem enough to permit affine or Euclidean reconstruction, e.g., [23] (see also [24]).
Reference: [19] <author> A. Shashua and N. Navab. </author> <title> Relative affine structure: Theory and application to 3D reconstruction from perspective views. </title> <booktitle> In Proc. </booktitle> <address> CVPR:483-489, Seattle, </address> <year> 1994. </year>
Reference-contexts: Section 3 describes how we use these relations for the stratified reconstruction of the 3D scene. Section 4 illustrates our approach with real-image examples. 1 A related approach called "plane+parallax" was taken in <ref> [14, 19] </ref>, but there 3D reconstruction was relative to the coordinate systems of both the reference plane and a reference image.
Reference: [20] <author> R. Szeliski and H. Shum. </author> <title> Creating full view panoramic mosaics and texture-mapped models. </title> <booktitle> In Proc. SIGGRAPH 97, </booktitle> <pages> pp. 251-258, </pages> <address> Los Angels, </address> <year> 1997. </year>
Reference-contexts: Here we include two examples of dense reconstruction of ordinal heights. In both cases, the images were acquired using a hand-held video camera. No quantitative information about the scene structure, the camera imaging parameters, or its motion were available. Given two input images, we used the method described in <ref> [20] </ref> to first estimate the homography that aligns a dominant planar surface in the scene between the two images. The residual parallax displacements between the points were then computed using the method described in [14]. These displacements were used as input for the stratified reconstruction of the scene.
Reference: [21] <author> D. Weinshall, M.Werman, and A. Shashua. </author> <title> Shape Tensors for Efficient and Learnable Indexing. In Workshop on Representations of Visual Scenes, </title> <year> 1995. </year>
Reference-contexts: These dual relations are similar to those previously described in <ref> [3, 21, 4] </ref>, where they were derived with respect to the quantities from the actual image points; here the dual relations are derived in the context of the reference-plane images.
Reference: [22] <author> D. Weinshall. </author> <title> Qualitative depth from stereo, with applications. Computer Vision, Graphics, </title> <booktitle> and Image Processing:49(222-241), </booktitle> <year> 1990. </year>
Reference-contexts: show that ordinal information about the 3D scene can be obtained even with very little scene calibration data, e.g., we can compute height ordering with respect to a plane from knowing (or guessing) the existence of two pairs of parallel lines on the plane; we call this ordinal reconstruction (cf. <ref> [22, 13, 9] </ref>). By providing additional domain-information (e.g., heights of one or two out-of-plane points), we can gradually obtain more metric 3D information, achieving affine and Euclidean reconstruction.
Reference: [23] <author> A. Zisserman. </author> <title> Active Visual Navigation using Non-Metric Structure. </title> <booktitle> In Proc. 5th ICCV, </booktitle> <address> Boston, USA, </address> <year> 1995. </year>
Reference-contexts: Alternatively, active vision techniques, based on imposing constraints on the viewing geometry and/or the camera motion, can be used. Such externally imposed constraints may simplify the problem enough to permit affine or Euclidean reconstruction, e.g., <ref> [23] </ref> (see also [24]). However, active vision techniques cannot be universally applied, and in particular they are of little help when the sequence of images is already given (such as the case with video analysis).
Reference: [24] <author> Z. Zhang, R. Weiss and A. Hanson. </author> <title> Obstacle Detection Using Qualitative and Quantitative 3D Reconstruction. </title> <journal> In IEEE PAMI, </journal> <volume> 19(2) </volume> <pages> 15-26, </pages> <month> January </month> <year> 1997. </year>
Reference-contexts: Alternatively, active vision techniques, based on imposing constraints on the viewing geometry and/or the camera motion, can be used. Such externally imposed constraints may simplify the problem enough to permit affine or Euclidean reconstruction, e.g., [23] (see also <ref> [24] </ref>). However, active vision techniques cannot be universally applied, and in particular they are of little help when the sequence of images is already given (such as the case with video analysis).
References-found: 24

