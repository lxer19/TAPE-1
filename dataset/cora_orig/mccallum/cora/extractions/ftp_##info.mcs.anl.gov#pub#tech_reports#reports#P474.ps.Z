URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P474.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts94.htm
Root-URL: http://www.mcs.anl.gov
Title: On the Influence of Partitioning Schemes on the Efficiency of Overlapping Domain Decomposition Methods  
Author: P. Ciarlet, Jr. F. Lamour B. F. Smith 
Address: 9700 South Cass Avenue 94195 Villeneuve-St-Georges Cedex BP 28, 91192 Gif-sur-Yvette Cedex Argonne, IL 60439-4844 France France USA  
Affiliation: CEA Cisi Argonne National Laboratory CEL-V, D.MA, MCN Branche CEA et Defense  
Abstract: One level overlapping Schwarz domain decomposition preconditioners can be viewed as a generalization of block Jacobi preconditioning. The effect of the number of blocks and the amount of overlapping between blocks on the convergence rate is well understood. This paper considers the related issue of the effect of the scheme used to partition the matrix into blocks on the convergence rate of the preconditioned iterative method. Numerical results for Laplace and linear elasticity problems in two and three dimensions are presented. The tentative conclusion is that using overlap tends to decrease the differences between the rates of convergence for different partitioning schemes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S.T. Barnard and H.D. Simon. </author> <title> A fast multilevel implementation of recursive spectral bisection for partitioning unstructured problems. </title> <type> Technical report, </type> <institution> NASA Ames Research Center, RNR-092-033, </institution> <year> 1992. </year>
Reference-contexts: Moreover, as the computation of the Fiedler vector is time consuming, many studies have been devoted to speeding up the calculation of this particular vector. Barnard and Simon, <ref> [1] </ref>, have accelerated the RSB algorithm by approximating the Fiedler vector. For this, they contract some edges in the graph in order to obtain a smaller graph and repeat this operation a certain number of times until the contracted graph is small enough.
Reference: [2] <author> P. Ciarlet. </author> <title> The finite element method for elliptic problems. </title> <publisher> North Holland, </publisher> <year> 1978. </year>
Reference-contexts: = f in ; u = g on 0 ; @n 1 + 1 r r ug = f in ; u = g on : In order to derive a discretization of these problems, the equations are replaced by a suitable variational formulation and then the finite element method <ref> [2] </ref> with the P1 finite element is used on the triangulations. Even though the value of the solution is known on 0 via the Dirichlet boundary condition, we have chosen to keep these (trivial) equations in the linear system.
Reference: [3] <author> P. Ciarlet, Jr, T.F. Chan, </author> <title> and W.K. Szeto. On the optimality of the median cut spectral bisec tion graph partitioning method. </title> <type> Technical report, UCLA, CAM 93-14, </type> <year> 1993. </year>
Reference-contexts: Briefly, if there are exactly N 2 strictly positive components and N 2 strictly negative components then both balanced subsets of the partition are connected. Regardless, the connectivity of one of the subsets is always guaranteed. Secondly, it have been proved by Ciarlet, Chan and Szeto in <ref> [3] </ref> that for all p 2 Q, jj x 2 p jj jj x 2 q jj.
Reference: [4] <author> P. Ciarlet, Jr and F. Lamour. </author> <title> A front-oriented approach to partitioning sparse graphs. </title> <type> Technical report, </type> <note> in preparation. </note>
Reference-contexts: This method is then invoked in step 3.(c) for refining the partition. Finally, the authors of GP have designed, what they call a retrofitting method which has been suggested by the experiments conducted on their partitioning heuristic <ref> [4] </ref>. The first step tries to reshape the outlines of the subsets by deleting some excrescences. Generally these occur during the accumulation step of the partitioning process when some of the chosen nodes encounter prematurely another subset.
Reference: [5] <author> P. Ciarlet, Jr and F. Lamour. </author> <title> An efficient low cost greedy graph partitioning heuristic. </title> <type> Technical report, UCLA, CAM 94-1, </type> <year> 1994. </year>
Reference-contexts: Neither are there results on how good a tie-break strategy is. For those two points only intuitive guesses help to design p partitioning problem heuristics. However, an obvious justification of using greedy heuristics for solving the p partitioning problem is that they are inexpensive. We have shown in <ref> [5] </ref>, that for the general case the overall complexity of such an algorithm is O (N max (p; d; log 2 ( N p ))). <p> Note that the greedy algorithm was first proposed specifically for partitioning meshes (and for parallel processing) by Farhat [10]. 3.2.2 Front oriented algorithm The next algorithm, presented in detail in <ref> [5] </ref>, implements the principles of a greedy method as well as some other original features. First, this algorithm builds connected subsets. On the other hand, it does not always provide well balanced subsets. The subsets are constructed in a concentric way around the boundary of the graph.
Reference: [6] <author> P. Ciarlet, Jr and F. Lamour. </author> <title> Recursive partitioning methods and greedy partitioning methods: a comparison on finite element graphs. </title> <type> Technical report, UCLA, CAM 94-9, </type> <year> 1994. </year>
Reference-contexts: The heuristic methods proposed in the literature for finite element graphs can be roughly arranged in two categories: the greedy methods and the recursive methods. A detailed study of the heuristics presented here as well as a fair comparison of the corresponding partitions are given in <ref> [6] </ref>. Let us first introduce some definitions and notations about graphs that will be used in the following. Let N =j V j and M =j E j be the number of nodes and edges respectively. <p> The second one measures the percentage of intersubset edges (m=M ). From extensive numerical experiments <ref> [6] </ref>, [7], we can see that oe=n is very small in all cases (and optimal by definition for the recursive heuristics). But this is not enough to ensure the load balancing [7]. Further comments are made in the next Section. <p> The ratio m=M measures the communication volume between the subdomains, where M is given while m is the parameter to be minimized by the heuristics. In general we can see that this volume is smallest for RP 2, followed closely by RP 1. Nevertheless, GP gives reasonably close values <ref> [6] </ref>, [7].
Reference: [7] <author> P. Ciarlet, Jr, F. Lamour, and B.F. Smith. </author> <title> On the influence of the partitioning schemes on the efficiency of overlapping domain decomposition methods. </title> <type> Technical report, UCLA, CAM 94-23, </type> <year> 1994. </year>
Reference-contexts: The second one measures the percentage of intersubset edges (m=M ). From extensive numerical experiments [6], <ref> [7] </ref>, we can see that oe=n is very small in all cases (and optimal by definition for the recursive heuristics). But this is not enough to ensure the load balancing [7]. Further comments are made in the next Section. <p> The second one measures the percentage of intersubset edges (m=M ). From extensive numerical experiments [6], <ref> [7] </ref>, we can see that oe=n is very small in all cases (and optimal by definition for the recursive heuristics). But this is not enough to ensure the load balancing [7]. Further comments are made in the next Section. The ratio m=M measures the communication volume between the subdomains, where M is given while m is the parameter to be minimized by the heuristics. <p> In general we can see that this volume is smallest for RP 2, followed closely by RP 1. Nevertheless, GP gives reasonably close values [6], <ref> [7] </ref>. <p> Concerning the average fills, GP gives generally better results than the recursive heuristics (for numerical results, we refer the reader to <ref> [7] </ref>). This can be 2 simon@nas.nasa.gov or barnard@nas.nasa.gov. 3 bahendr@cs.sandia.gov or rwlelan@cs.sandia.gov. explained in part by the average fill of the local matrices before factorization. It is equal to (M+N)m therefore smaller for GP. The reordering and factorization process does not seem to reduce these original differences. <p> The most important values are the minimum and the maximum fills for a given partition. In most cases, there is a great imbalance <ref> [7] </ref>. The maximum value is representative of the largest amount of work on a processor, in the case of a parallel experiment. Generally, these are very close for the three heuristics. <p> Generally, these are very close for the three heuristics. As a function of the number of partitions p, RP 1 gives the best results for small p whereas GP performs best for large p, both for overlapping and nonoverlapping subdomains <ref> [7] </ref>. Let us now investigate the possible origins of the imbalance. It can be caused by some original imbalance, i.e. the discrepancy in fill of the local matrices before they are factored. It can also be caused by the structure of these matrices which affects the reordering and factorization process.
Reference: [8] <author> M. Dryja. </author> <title> An additive Schwarz algorithm for two- and three-dimensional finite element elliptic problems. </title> <editor> In T. Chan, R. Glowinsky, J. Periaux, and O. Widlund, editors, </editor> <title> Domain Decomposition Methods. </title> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <year> 1989. </year>
Reference-contexts: One of the main reasons for this renewed interest is the emergence of parallel and massively parallel computers. This is because many domain decomposition methods are naturally parallel. The additive Schwarz method we consider in this paper is very representative. This method was introduced by Dryja in <ref> [8] </ref> and Dryja and Widlund in [9]. For some results obtained on parallel architectures with this method, we refer the reader to [17]. Here, we consider the case of the one-level additive Schwarz preconditioner, that is local problems are solved without a coarse problem.
Reference: [9] <author> M. Dryja and O. B. Widlund. </author> <title> An additive variant of the Schwarz alternating method for the case of many subregions. </title> <type> Technical report, 339, </type> <institution> Dept of Computer Science, Courant Institute, </institution> <year> 1987. </year>
Reference-contexts: This is because many domain decomposition methods are naturally parallel. The additive Schwarz method we consider in this paper is very representative. This method was introduced by Dryja in [8] and Dryja and Widlund in <ref> [9] </ref>. For some results obtained on parallel architectures with this method, we refer the reader to [17]. Here, we consider the case of the one-level additive Schwarz preconditioner, that is local problems are solved without a coarse problem.
Reference: [10] <author> C. Farhat. </author> <title> A simple and efficient automatic FEM domain decomposer. </title> <journal> Computers and structures, </journal> <volume> vol 28, </volume> <booktitle> n o 5, </booktitle> <pages> pp 579-602, </pages> <year> 1988. </year>
Reference-contexts: We have shown in [5], that for the general case the overall complexity of such an algorithm is O (N max (p; d; log 2 ( N p ))). Note that the greedy algorithm was first proposed specifically for partitioning meshes (and for parallel processing) by Farhat <ref> [10] </ref>. 3.2.2 Front oriented algorithm The next algorithm, presented in detail in [5], implements the principles of a greedy method as well as some other original features. First, this algorithm builds connected subsets. On the other hand, it does not always provide well balanced subsets. <p> More precisely, in the partitioning process, the starting node of each iteration i is chosen in order to belong simultaneously to the boundary of G, to be an unmarked neighbor of a node of V i1 and to have a minimal positive current degree (in <ref> [10] </ref>, the starting node is chosen among those which do not belong to the boundary of G). Here, the current degree of a node is the number of nodes connected to it which have not yet been selected, i.e. marked, during the accumulation step.
Reference: [11] <author> C. Farhat and M. Lesoinne. </author> <title> Automatic partitioning of unstructured meshes for the parallel solution of problems in computational mechanics. </title> <journal> International Journal for Numerical Methods in Engineering, </journal> <volume> vol 36, </volume> <booktitle> n o 5, </booktitle> <pages> pp 745-764, </pages> <year> 1993. </year>
Reference-contexts: To apply these methods efficiently in parallel, one must partition the unknowns among the processors to achieve both load balancing and reduce required interproces-sor communication. However, for block Jacobi methods the particular partition used can have a large effect on the numerical convergence rate. Farhat and Lesoinne <ref> [11] </ref> and Farhat and Simon [12] addressed the problem of load balancing and communications between processors on a parallel architecture, and have run some experiments on parallel machines in order to compare the execution times.
Reference: [12] <author> C. Farhat and H.D. Simon. </author> <title> TOP/DOMDEC- a software tool for mesh partitioning and parallel processing. </title> <type> Technical report, </type> <institution> NASA Ames Research Center, RNR-93-011, </institution> <year> 1993. </year>
Reference-contexts: However, for block Jacobi methods the particular partition used can have a large effect on the numerical convergence rate. Farhat and Lesoinne [11] and Farhat and Simon <ref> [12] </ref> addressed the problem of load balancing and communications between processors on a parallel architecture, and have run some experiments on parallel machines in order to compare the execution times.
Reference: [13] <author> C.M. Fiduccia and R.M. Mattheyses. </author> <title> A linear-time heuristic for improving network partitions. </title> <booktitle> Proceedings of the 19th IEEE Design Automation Conference, IEEE, </booktitle> <pages> pp 175-181, </pages> <year> 1982. </year>
Reference-contexts: Nevertheless, as the complexity of the KL method is in the order of O (N 2 log N ), the KL method is actually invoked only when the number of nodes in each subset is less than 300. Because of the complexity of the KL algorithm, Fiduccia and Mattheyses <ref> [13] </ref> slightly modified the algorithm, and reduced the overall complexity to O (M ). Principally, the FM algorithm chooses to move one node after another instead of directly exchanging a pair of nodes.
Reference: [14] <author> M. Fiedler. </author> <title> Algebraic connectivity of graphs. </title> <journal> Czechoslovak Mathematical Journal, </journal> <volume> 23, (98), </volume> <pages> pp 298-305, </pages> <year> 1973. </year>
Reference-contexts: search of a vector x such that jj x jj 2 2 = N and x i = 0, one finds that the minimum of (x; L (G)x) is obtained for x = x 2 , where x 2 is the eigenvector associated with 2 , named the Fiedler vector, <ref> [14] </ref>. Knowing this, the idea is to compute a vector q 2 Q by using x 2 in the following way. Let x l be the median value of the components of x 2 . <p> Of course this is not an optimal partition. Although we cannot say how close to the optimal the median cut is, there are still some interesting properties about it. First, there is an important result about the connectivity of a median cut partition which has been stated by Fiedler <ref> [14] </ref>. Briefly, if there are exactly N 2 strictly positive components and N 2 strictly negative components then both balanced subsets of the partition are connected. Regardless, the connectivity of one of the subsets is always guaranteed.
Reference: [15] <author> A. George and J. Liu. </author> <title> Computer solution of large sparse positive definite systems. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1981. </year>
Reference-contexts: To minimize the fill (number of non-zero entries) during the factorization, the matrix columns and rows are reordered with nested dissection following George and Liu's Sparsepack <ref> [15] </ref>. 3 The partitioning heuristics In order to partition the domain, the triangulation can be considered as a graph by identifying the notions of vertices and edges. We call this graph a finite element graph.
Reference: [16] <author> W.D. Gropp and B.F. Smith. </author> <title> Portable, Extensible Toolkit for Scientific Computation (PETSc). </title> <note> Available at info.mcs.anl.gov in the directory pub/pdetools via anonymous ftp. </note>
Reference-contexts: The numerical experiments including both the partitioning heuristics and the iterative solver are tested through a common tool: the Portable Extensible Tools for Scientific computation (PETSc) developed by Gropp and Smith <ref> [16] </ref>, [18]. PETSc is a software library for parallel and serial scientific computations. It provides a variety of packages and in particular the iterative solver. In addition to these existing packages, PETSc makes it easy to include any software written either in C or Fortran.
Reference: [17] <author> W.D. Gropp and B.F. Smith. </author> <title> Experiences with domain decomposition in three dimensions: overlapping Schwarz methods. </title> <editor> In A. Quarteroni, Y.A. Kuznetsov, J. Periaux, and O. Widlund, editors, </editor> <title> Domain Decomposition Methods in Science and Engineering. </title> <journal> AMS contemporary mathematics, </journal> <volume> vol 157, </volume> <year> 1993. </year>
Reference-contexts: The additive Schwarz method we consider in this paper is very representative. This method was introduced by Dryja in [8] and Dryja and Widlund in [9]. For some results obtained on parallel architectures with this method, we refer the reader to <ref> [17] </ref>. Here, we consider the case of the one-level additive Schwarz preconditioner, that is local problems are solved without a coarse problem.
Reference: [18] <author> W.D. Gropp and B.F. Smith. </author> <title> Scalable, extensible, and portable numerical libraries. </title> <booktitle> Proceedings of the Scalable Parallel Libraries Conference, IEEE, </booktitle> <pages> pp 87-93, </pages> <year> 1993. </year>
Reference-contexts: The numerical experiments including both the partitioning heuristics and the iterative solver are tested through a common tool: the Portable Extensible Tools for Scientific computation (PETSc) developed by Gropp and Smith [16], <ref> [18] </ref>. PETSc is a software library for parallel and serial scientific computations. It provides a variety of packages and in particular the iterative solver. In addition to these existing packages, PETSc makes it easy to include any software written either in C or Fortran.
Reference: [19] <author> B. Hendrickson and R. Leland. </author> <title> Multidimensional spectral load balancing. </title> <type> Technical report, SAND 93-0074, </type> <year> 1993. </year>
Reference-contexts: Principally, the FM algorithm chooses to move one node after another instead of directly exchanging a pair of nodes. The authors of RP 2 generalized the FM method to an arbitrary number of subsets, <ref> [19] </ref> and [20]. In this case, the overall complexity is estimated to O ((p 1)M ). This method is then invoked in step 3.(c) for refining the partition.
Reference: [20] <author> B. Hendrickson and R. Leland. </author> <title> A multilevel algorithm for partitioning graphs. </title> <type> Technical report, SAND 93-1301, </type> <year> 1993. </year>
Reference-contexts: Assign half of the vertices to each subdomain. 4. Repeat recursively (divide and conquer). The complexity of RP 1 is estimated to O (M log 2 p). 3.1.3 Recursive multilevel algorithm In a similar manner, Hendrickson and Leland in <ref> [20] </ref> used a multilevel technique to partition a graph. They first reduce the size of the graph, and derive a series of smaller graphs by contracting the edges of the original graph until the size of the last graph is small enough. <p> Principally, the FM algorithm chooses to move one node after another instead of directly exchanging a pair of nodes. The authors of RP 2 generalized the FM method to an arbitrary number of subsets, [19] and <ref> [20] </ref>. In this case, the overall complexity is estimated to O ((p 1)M ). This method is then invoked in step 3.(c) for refining the partition.
Reference: [21] <author> B.W. Kernighan and S. Lin. </author> <title> An efficient heuristic for partitioning graphs. </title> <journal> The Bell System Technical Journal, </journal> <volume> vol 49, </volume> <booktitle> n o 2, </booktitle> <pages> pp 291-307, </pages> <year> 1970. </year>
Reference-contexts: One of the most well known optimization methods for improving a given partition is due to Kernighan and Lin <ref> [21] </ref>. Fundamentally the method is based on a given 2 edge-partition (V 1 ; V 2 ) of the node set V of a graph and tries to improve it by exchanging a subset of V 1 with one of V 2 .
Reference: [22] <author> H.D. Simon. </author> <title> Partitioning of unstructured problems for parallel processing. </title> <journal> Computing Systems in Engineering, </journal> <volume> vol 2, </volume> <booktitle> n o 2/3, </booktitle> <pages> pp 135-148, </pages> <year> 1991. </year>
Reference-contexts: 3.1.2 Recursive spectral bisection In order to partition a given graph into any number of subsets that is a power of two, the median cut partitioning method has been used as a step in a divide and conquer process, as in the Recursive Spectral Bisection algorithm (RSB) due to Simon <ref> [22] </ref>. There the median cut algorithm is recursively applied to each subgraph induced by the bisection previously computed until the required number of subsets is obtained.
Reference: [23] <author> H. A. van der Vorst. </author> <title> Bi-cgstab: a fast and smoothly converging variant of bi-cg for the solution of nonsymmetric linear systems. </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <volume> vol 13, </volume> <booktitle> n o 2, </booktitle> <pages> pp 631-644, </pages> <year> 1992. </year>
Reference-contexts: of this, the unknowns are the approximations of the value of the true solution at all vertices of the triangulation, and the matrix is nonsymmetric. 2.2 Iterative and DD methods The resulting nonsymmetric linear system is solved using the preconditioned bi-conjugate gradient stabilized method (Bi-CGSTAB), due to van der Vorst <ref> [23] </ref>. The preconditioner considered in this paper is designed with the help of domain decomposition principles. In recent years, many papers have been devoted to the study of new domain decomposition methods. One of the main reasons for this renewed interest is the emergence of parallel and massively parallel computers.
Reference: [24] <author> D. Vanderstraeten, O. Zone, R. Keunings, and L. A. Wolsey. </author> <title> Non-deterministic heuristics for automatic domain decomposition in direct parallel finite element calculations. In R.F. </title> <editor> Sincovec, editor, </editor> <booktitle> in Parallel Processing for Scientific Computing. </booktitle> <publisher> SIAM, </publisher> <year> 1993. </year>
Reference-contexts: In 3D, however, there is no such relationship between the number of tetrahedra and edges in a region. Finally, let us mention that Vanderstraeten, Zone, Keunings and Wolsey have proposed in <ref> [24] </ref> a postpro-cessing strategy to balance a quantity that approximates the actual fill. Now, we consider the number of iterations as a function of both the number of subdomains p and the overlap.
References-found: 24

