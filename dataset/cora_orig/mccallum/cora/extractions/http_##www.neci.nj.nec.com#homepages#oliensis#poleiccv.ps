URL: http://www.neci.nj.nec.com/homepages/oliensis/poleiccv.ps
Refering-URL: http://www.neci.nj.nec.com/homepages/oliensis/Critique.html
Root-URL: 
Email: (oliensis@research.nj.nec.com)  
Title: A Critique of Structure-from-Motion Algorithms  
Author: John Oliensis 
Address: 4 Independence Way Princeton, N.J. 08540  
Affiliation: NEC Research Institute  
Abstract: I critique current approaches to structure from motion and describe a new framework for algorithms. Keywords Structure from motion, multi-frame structure from motion, projective methods, invariants, self-calibration, Kalman filtering, optimization, trilinear reconstruction, Bayesian methods, experimental evaluation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Azarbayejani and A. Pentland, </author> <title> "Recursive estimation of motion, structure and focal length", </title> <journal> PAMI, </journal> <pages> pp. 562-575, </pages> <year> 1995. </year>
Reference-contexts: It is important to determine how nearly "Kalman filtering" algorithms can approach "optimal" performance when they are designed specifically for the cases where they should work. By the same token, if "Kalman filtering" algorithms 4 The reliability of other algorithms such as <ref> [1] </ref> should be explored in more detail.
Reference: [2] <author> P. Belhumeur, D. Kriegman, and A. </author> <title> Yuille "The Bas-Relief Ambiguity," </title> <address> CVPR 1060-1066, </address> <year> 1997. </year>
Reference-contexts: Finally, it is important to remember that, due to the bas-relief effect, few-frame algorithms often succeed partially: they can accurately recover most but not all structure components <ref> [2] </ref> [23] [37]. Thus, though "Kalman filtering" techniques may be unable to compute the whole structure reliably, the discussion above suggests that they may be capable of fusing and recovering the part of structure that is accurately recoverable by few-frame methods.
Reference: [3] <author> S. Bougnoux, </author> <title> "From Projective to Euclidean Space Under any Practical Situation, a Criticism of Self-Calibration," </title> <address> ICCV 790-795, </address> <year> 1998. </year>
Reference-contexts: It seems almost tautological that errors in the difficult-to-recover calibration parameters are likely to have little effect on structure recovery, while the parameters that have strong effects are probably easy to calibrate accurately (see also <ref> [3] </ref>). The difficult calibration parameters are difficult to recover even with a precisely measured 3D calibration object. This implies that altering these calibration parameters, and perhaps compensating by changing the motion, does not much affect the images of a fixed 3D structure.
Reference: [4] <author> S. Christy and R. Horaud, </author> <title> "Euclidean shape and motion from multiple perspective views by affine iteration," </title> <type> PAMI 1098-1104, </type> <year> 1996. </year>
Reference-contexts: How can these mixed cases be handled? First, it does appear experimentally that the algorithms described above apply broadly <ref> [26, 24, 4] </ref>: often cases intermediate between two domains can be handled by approaches specialized for either. For instance, the algorithms of [30] and [27] (respectively, domain-3-style and domain-1-style approaches) have both worked on the Martin-Marietta rocket-field sequence [6] 33 . <p> Similarly, if an approximate algorithm gives a reasonable initial reconstruction, an iterative technique can use this as a starting guess to correct the approximation and produce a full reconstruction 31 exploiting all the information, with no approximation. For instance, Tomasi's algorithm neglects perspective effects, but an iterative procedure <ref> [4] </ref> starting from this algorithm's reconstruction can include these effects. [24][23] describe a similar tactic for domain 1. On the other hand, it is crucial that the initial reconstruction be adequate|with a poor initial guess an iterative-improvement technique can fail.
Reference: [5] <author> J. E. Cutting, M. Fluckiger, B. Baumberger, J.D. Gerndt, </author> <title> "Local Heading Information and Layout from Full-Cue, Simulated Pursuit-Fixation Displays," </title> <booktitle> ARVO Abstract 2069, </booktitle> <year> 1996. </year>
Reference-contexts: For example, the scene may be dominated by the ground plane, or (for an interior scene) it may contain mostly planar surfaces and rectangular solids. Psychophysical evidence indicates that humans do use recognized objects in judging ego- and independent-object motion <ref> [5] </ref>. However, below I will only discuss the generic constraints 1-3, since adapting algorithms to specific scenes depends too specifically on the scenes. 26 All the cited constraints can be exploited by appropriately designed algorithms. For example, [25, 24] describe how to exploit the small translational motion in robot navigation.
Reference: [6] <author> R. Dutta, R. Manmatha, </author> <title> L.R. Williams, and E.M. Riseman, "A data set for quantitative motion analysis," </title> <booktitle> CVPR, </booktitle> <pages> 159-164, </pages> <year> 1989. </year>
Reference-contexts: For instance, the algorithms of [30] and [27] (respectively, domain-3-style and domain-1-style approaches) have both worked on the Martin-Marietta rocket-field sequence <ref> [6] </ref> 33 . Second, if a sequence spans the extremes of different domains, admittedly none of the algorithms suggested above may work on the entire sequence. But it is always possible to select parts of the sequence that do belong to single domains 34 .
Reference: [7] <author> O. Faugeras and B. Mourrain, </author> <title> "On the geometry and algebra of the point and line correspondences between N images," </title> <booktitle> ICCV, </booktitle> <pages> 951-956, </pages> <year> 1995. </year>
Reference-contexts: Also, modeling the errors in establishing correspondence over three or more images may be more difficult than for just two. 22 Using a large number of images is impossible in practice, but not in principle. The result of [43] <ref> [7] </ref> does not rule out invariants algorithm based on more than four images: one can always derive polynomial constraints on the image data for arbitrary numbers of images and solve for the coefficients of the polynomial constraints using all image data. 21 More importantly, for SFM from point features, two-image reconstruction
Reference: [8] <author> R. I. </author> <title> Hartley, "Lines and Points in Three Views and the Trifocal Tensor," </title> <booktitle> IJCV 22, </booktitle> <pages> 125-140, </pages> <year> 1997. </year>
Reference-contexts: As discussed in Section 2.2.7, under some conditions projective optimization may be a good approach even for calibrated sequences, but its usefulness is probably quite limited. Section 2.3 critiques non-optimal invariants-based algorithms such as in [33, 35] <ref> [13, 9, 8] </ref>. <p> Thus, for general sequences of three or more images, one must choose between a slow optimization approach or a simpler, faster, but far-from-optimal algorithm such as [33, 35] <ref> [13, 9, 8] </ref>. Since recent experimental work [23] [46] has shown that two-frame optimization is quite robust and accurate as well as fast, it may actually be preferable to these three-frame algorithms. The algorithms [33, 35] [13, 9, 8] may actually be more fragile than two-frame optimization on difficult sequences. <p> slow optimization approach or a simpler, faster, but far-from-optimal algorithm such as [33, 35] <ref> [13, 9, 8] </ref>. Since recent experimental work [23] [46] has shown that two-frame optimization is quite robust and accurate as well as fast, it may actually be preferable to these three-frame algorithms. The algorithms [33, 35] [13, 9, 8] may actually be more fragile than two-frame optimization on difficult sequences. Even if not, they may do less well on three frames than comparing and adjusting optimized reconstructions from different image pairs 21 . <p> In addition, since more images are more difficult to use in domain 3, it may actually turn out that two-frame optimization 32 gives better results than multi-frame, non-optimal algorithms such as [33, 35] <ref> [13, 9, 8] </ref>, especially if one appropriately combines results from different image pairs 21 . (Recall that this should also hold for difficult sequences, see Section 2.3.) Again, the extent to which this is true must be determined by experiment. These arguments have implications for the testing of multi-frame algorithms.
Reference: [9] <author> R. I. </author> <title> Hartley, "A linear method for reconstruction from lines and points," </title> <address> ICCV 882--887, </address> <year> 1995. </year>
Reference-contexts: As discussed in Section 2.2.7, under some conditions projective optimization may be a good approach even for calibrated sequences, but its usefulness is probably quite limited. Section 2.3 critiques non-optimal invariants-based algorithms such as in [33, 35] <ref> [13, 9, 8] </ref>. <p> Similarly for three images, the coefficients of the trilinear constraints depend just on the motion <ref> [9, 33] </ref>. Invariants-based algorithms typically begin by fitting the derived polynomial constraints to the data, producing estimates of the constraint coefficients. For example, a two-frame algorithm would begin by estimating the essential matrix. <p> In SFM, large errors in the constraint coefficients are likely to cause large errors in the recovered motion or structure. Indeed, many researchers have pointed out the noise-sensitivity of invariants-based algorithms (e.g., <ref> [9, 19] </ref>). The simplest such algorithm|the "8-point" algorithm for two images|is known to be inaccurate 18 19 . The motion-recovery technique in the second stage of this algorithm is non-algebraic and nearly "optimal" [15]|it is the first, polynomial-fitting stage that causes the algorithm's inaccuracy. <p> In fact, Hartley states in [13] that an algorithm based on the trilinear constraints is "very unstable." This is an algorithm strictly following the invariants approach: it solves for the trilinear coefficients by fitting the data and then uses them to determine the motion by explicit algebra. Hartley <ref> [9, 13] </ref> obtains a more stable algorithm by partly abandoning the results of the initial polynomial fitting. The improved algorithm uses the trilinear coefficients to determine just a subset of the motion parameters. <p> Thus, for general sequences of three or more images, one must choose between a slow optimization approach or a simpler, faster, but far-from-optimal algorithm such as [33, 35] <ref> [13, 9, 8] </ref>. Since recent experimental work [23] [46] has shown that two-frame optimization is quite robust and accurate as well as fast, it may actually be preferable to these three-frame algorithms. The algorithms [33, 35] [13, 9, 8] may actually be more fragile than two-frame optimization on difficult sequences. <p> slow optimization approach or a simpler, faster, but far-from-optimal algorithm such as [33, 35] <ref> [13, 9, 8] </ref>. Since recent experimental work [23] [46] has shown that two-frame optimization is quite robust and accurate as well as fast, it may actually be preferable to these three-frame algorithms. The algorithms [33, 35] [13, 9, 8] may actually be more fragile than two-frame optimization on difficult sequences. Even if not, they may do less well on three frames than comparing and adjusting optimized reconstructions from different image pairs 21 . <p> In addition, since more images are more difficult to use in domain 3, it may actually turn out that two-frame optimization 32 gives better results than multi-frame, non-optimal algorithms such as [33, 35] <ref> [13, 9, 8] </ref>, especially if one appropriately combines results from different image pairs 21 . (Recall that this should also hold for difficult sequences, see Section 2.3.) Again, the extent to which this is true must be determined by experiment. These arguments have implications for the testing of multi-frame algorithms.
Reference: [10] <author> R. I. </author> <title> Hartley, "In Defense of the 8-point Algorithm," </title> <address> ICCV 1064-1070, </address> <year> 1995. </year>
Reference-contexts: and demonstrated experimentally e.g. in [26], when the camera translation is large and the 3D scene extended, two-frame SFM is easy, and most algorithms work well, even the "8-point" algorithm [18]. 19 Hartley has pointed out that "balancing" in the projective framework makes the "8-point" algorithm more accurate and reliable <ref> [10] </ref>. In this technique, the homogeneous image coordinates are transformed so that all three components are of roughly the same magnitude before the "8-point" algorithm is applied.
Reference: [11] <author> R. </author> <title> Hartley, "Euclidean Reconstruction from Uncalibrated Views," </title> <booktitle> in fnem Second Workshop on Invariantsg, </booktitle> <address> Azores, </address> <year> 1993, </year> <pages> 187-202. </pages>
Reference-contexts: In addition, since optimization minimizes a complex objective function in a large number of unknowns, it is typically slow 2 . This is true even when each iteration step has a computational cost linear in the number of 3D points (as in <ref> [15, 11] </ref>), since the computation of each step per point is still significant and convergence often requires a large number of iterative steps (particularly starting from bad initial guesses). Thus optimization may not be an effective way of dealing with dense image data.
Reference: [12] <author> R. I. </author> <title> Hartley, "Self-Calibration from Multiple Views with a Rotating Camera," </title> <address> ECCV 471-478, </address> <year> 1994. </year>
Reference-contexts: But for standard single-camera sequences, separating these two tasks probably makes more sense: the situations that are best for self-calibrating are quite different from those that facilitate reconstruction. Self-calibrating is easiest when the camera only rotates and does not translate <ref> [12] </ref>, since then the unknown structure is completely factored out 8 . But structure recovery works best when the translations are large, since the translational image displacements contain the structure information.
Reference: [13] <author> R. I. </author> <title> Hartley, "Lines and points in three views | a unified approach," </title> <address> IUW 1009-1016, </address> <year> 1994. </year>
Reference-contexts: As discussed in Section 2.2.7, under some conditions projective optimization may be a good approach even for calibrated sequences, but its usefulness is probably quite limited. Section 2.3 critiques non-optimal invariants-based algorithms such as in [33, 35] <ref> [13, 9, 8] </ref>. <p> In fact, Hartley states in <ref> [13] </ref> that an algorithm based on the trilinear constraints is "very unstable." This is an algorithm strictly following the invariants approach: it solves for the trilinear coefficients by fitting the data and then uses them to determine the motion by explicit algebra. <p> In fact, Hartley states in [13] that an algorithm based on the trilinear constraints is "very unstable." This is an algorithm strictly following the invariants approach: it solves for the trilinear coefficients by fitting the data and then uses them to determine the motion by explicit algebra. Hartley <ref> [9, 13] </ref> obtains a more stable algorithm by partly abandoning the results of the initial polynomial fitting. The improved algorithm uses the trilinear coefficients to determine just a subset of the motion parameters. <p> Thus, for general sequences of three or more images, one must choose between a slow optimization approach or a simpler, faster, but far-from-optimal algorithm such as [33, 35] <ref> [13, 9, 8] </ref>. Since recent experimental work [23] [46] has shown that two-frame optimization is quite robust and accurate as well as fast, it may actually be preferable to these three-frame algorithms. The algorithms [33, 35] [13, 9, 8] may actually be more fragile than two-frame optimization on difficult sequences. <p> slow optimization approach or a simpler, faster, but far-from-optimal algorithm such as [33, 35] <ref> [13, 9, 8] </ref>. Since recent experimental work [23] [46] has shown that two-frame optimization is quite robust and accurate as well as fast, it may actually be preferable to these three-frame algorithms. The algorithms [33, 35] [13, 9, 8] may actually be more fragile than two-frame optimization on difficult sequences. Even if not, they may do less well on three frames than comparing and adjusting optimized reconstructions from different image pairs 21 . <p> In addition, since more images are more difficult to use in domain 3, it may actually turn out that two-frame optimization 32 gives better results than multi-frame, non-optimal algorithms such as [33, 35] <ref> [13, 9, 8] </ref>, especially if one appropriately combines results from different image pairs 21 . (Recall that this should also hold for difficult sequences, see Section 2.3.) Again, the extent to which this is true must be determined by experiment. These arguments have implications for the testing of multi-frame algorithms.
Reference: [14] <author> R.I. Hartley and P. Sturm, </author> <title> "Triangulation," </title> <address> IUW, (Monterey, CA, </address> <month> November 13-16, </month> <title> 1994), </title> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA, </address> <year> 1994, </year> <pages> 957-966. </pages>
Reference-contexts: Moreover, given the two-frame motion, one can exactly recover the optimal structure by algebraic methods <ref> [14] </ref>. On the other hand, for more than two images, the rigidity constraint (that the 3D points remain fixed and static over the sequence) applies in addition to coplanarity, and exploiting this constraint requires representing the structure explicitly or implicitly.
Reference: [15] <author> R. I. </author> <title> Hartley, "Estimation of Relative Camera Positions for Uncalibrated Cameras," </title> <address> ECCV 579-587, </address> <year> 1992. </year>
Reference-contexts: In addition, since optimization minimizes a complex objective function in a large number of unknowns, it is typically slow 2 . This is true even when each iteration step has a computational cost linear in the number of 3D points (as in <ref> [15, 11] </ref>), since the computation of each step per point is still significant and convergence often requires a large number of iterative steps (particularly starting from bad initial guesses). Thus optimization may not be an effective way of dealing with dense image data. <p> Of course, in the Euclidean framework the rotation matrix constraints need to be restored eventually|the recovered rotation matrices must be converted into orthogonal ones. This is straightforward and techniques already exist, e.g., Hartley's method for recovering the rotation matrix from an inexact essential matrix <ref> [15] </ref>, or Tomasi and Kanade's technique [42]. 2.2.6 Alternatives to Projective Reconstruction The projective approach to dealing with uncalibrated cameras is flawed|are there reasonable Euclidean alternatives? Certainly there are for single-camera sequences|even, as I have already implied, when the calibration is completely unknown.
Reference: [16] <author> R. Kumar, P. Anandan, and K. Hanna, </author> <title> "Direct recovery of shape from multiple views: A parallax based approach," </title> <booktitle> 12th IAPR International Conference on Pattern Recognition, Conference A, </booktitle> <address> (Jerusalem, Israel, </address> <month> October 9-13, </month> <title> 1994), </title> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1994, </year> <pages> 685-688. </pages>
Reference-contexts: Determining correspondence is important also, but it is not the whole of SFM: establishing correspondence can be relatively easy, for instance when the motions are small and all the information in the image is used <ref> [16] </ref>, and computing a good reconstruction can be difficult even for known correspondences. Moreover, an understanding of the reconstruction problem is likely to help with correspondence; a better reconstruction algorithm, with more robustness to image noise, will also be less affected by correspondence errors. <p> However, surely Gaussian or uniform noise is a reasonable model for much of the uncertainty in localizing image features. (When the motion is small and the entire image is used to establish correspondence, it can be a good model <ref> [16] </ref>.) For a strongly overconstrained problem like MFSFM, reconstruction should not depend sensitively on the detailed distribution of image errors when the errors are small, and even occasional large errors should not affect it much.
Reference: [17] <author> S. Lawrence, A.C. Tsoi, and C. L. Giles, </author> <title> "Local Minima and Generalization," </title> <booktitle> Int. Conf. on Neural Networks, </booktitle> <pages> 371-376, </pages> <year> 1996. </year>
Reference-contexts: This may be partly because the extra unknowns in the "projective" approach destabilize some of the Euclidean local minima, as researchers have found in other contexts. (For example, using extra artificial modeling parameters in neural-network learning can avoid local minima <ref> [17] </ref>.) It may also be because "projective" optimization imposes no constraints on the rotation matrices and thus avoids some of the nonlinearities of purely Euclidean optimization 17 . This result does not imply that the projective framework gives better results than the Euclidean one.
Reference: [18] <author> H. C. Longuet-Higgins, </author> <title> "A computer algorithm for reconstructing a scene from two projections," </title> <journal> Nature, </journal> <volume> 293: </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: Neglecting the rotation matrix constraints is standard in many Euclidean algorithms, for instance, in the "8-point" computation of the essential matrix <ref> [18] </ref>, or Tomasi and Kanade's SVD approach to orthographic SFM [42]. The projective approach therefore does not lead to new SFM algorithms; all so-called projective algorithms translate directly into Euclidean ones|just as the "8-point" algorithm determining the fundamental matrix translates into the familiar "8-point" algorithm for the essential matrix. <p> Assuming fixed calibration, the second stage would compute the motions from the camera matrices M by finding the projective transform making the first three columns 16 Using LM. 17 The "8-point" algorithm <ref> [18] </ref> may be a good analogy. This "projective" algorithm relaxes the rotation-matrix constraints and thus in effect minimizes a quadratic error function with a single minimum; it has no local-minimum problem. <p> As argued and demonstrated experimentally e.g. in [26], when the camera translation is large and the 3D scene extended, two-frame SFM is easy, and most algorithms work well, even the "8-point" algorithm <ref> [18] </ref>. 19 Hartley has pointed out that "balancing" in the projective framework makes the "8-point" algorithm more accurate and reliable [10]. In this technique, the homogeneous image coordinates are transformed so that all three components are of roughly the same magnitude before the "8-point" algorithm is applied.
Reference: [19] <author> Q. T. Luong, O. Faugeras, </author> <title> "On the direct determination of epipoles: a case study in algebraic methods for geometric problems," </title> <address> IAPR 243-247, </address> <year> 1994. </year>
Reference-contexts: In SFM, large errors in the constraint coefficients are likely to cause large errors in the recovered motion or structure. Indeed, many researchers have pointed out the noise-sensitivity of invariants-based algorithms (e.g., <ref> [9, 19] </ref>). The simplest such algorithm|the "8-point" algorithm for two images|is known to be inaccurate 18 19 . The motion-recovery technique in the second stage of this algorithm is non-algebraic and nearly "optimal" [15]|it is the first, polynomial-fitting stage that causes the algorithm's inaccuracy.
Reference: [20] <author> S. Maybank, </author> <title> Theory of Reconstruction from Image Motion, </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1992. </year>
Reference-contexts: In any case, an experimental study of two-image reconstruction is feasible; [26] contains the beginnings of such a study. The singular structure configurations that cause difficulties for two-image algorithms are well understood (quadric surfaces <ref> [20] </ref>). Away from these singular configurations, the quality of an algorithm's performance probably depends straightforwardly on the motion [22]. Mapping this dependence experimentally should be relatively easy.
Reference: [21] <author> J. Oliensis, </author> <title> "A New Structure from Motion Ambiguity," </title> <note> NECI TR 1997. </note>
Reference-contexts: Due to the small noise-to-signal ratio, this could require little more than a local curvature analysis of the error around the minimum. Indeed, <ref> [21] </ref> demonstrates that two-frame SFM is simple enough that it is possible to understand many of the important properties of the maximum-likelihood error theoretically. In any case, an experimental study of two-image reconstruction is feasible; [26] contains the beginnings of such a study. <p> Even when optimization is the preferred method, it is still important to have a tech nique for computing a good initial reconstruction quickly. 7. For multi-frame sequences, getting a good initial reconstruction requires discarding data or introducing approximations. 8. Error analysis is crucial to developing reliable SFM algorithms (e.g., <ref> [21] </ref>). 9. Experimentally evaluating SFM algorithms requires accumulating performance statistics on large numbers of sequences. It also requires a theoretical understanding of the conditions under which algorithms perform well or badly.
Reference: [22] <author> J. Oliensis, </author> " <title> Recovering Heading and Structure for Constant-Direction Motion," </title> <note> NEC TR 1997. </note>
Reference-contexts: Also, the recovered values of the two errors at the global minimums are essentially the same. 25 In fact, it may be possible to compute the motion to a good approximation just by minimizing in the two parameters describing the translation direction <ref> [22] </ref>. 22 ambiguous for special scenes (e.g., planes). But, for three or more images, in general one can easily resolve these ambiguities by comparing reconstructions from different image pairs. <p> The singular structure configurations that cause difficulties for two-image algorithms are well understood (quadric surfaces [20]). Away from these singular configurations, the quality of an algorithm's performance probably depends straightforwardly on the motion <ref> [22] </ref>. Mapping this dependence experimentally should be relatively easy. The rotation is unimportant [24, 39], so the performance needs to be measured just as a function of the two parameters describing the translation direction.
Reference: [23] <author> J. Oliensis, </author> <title> "A Multi-frame Structure from Motion Algorithm Under Perspective," </title> <type> NEC TR, </type> <month> April </month> <year> 1997. </year> <note> (http:nnwww.neci.nj.nec.comnhomepagesnoliensis.) </note>
Reference-contexts: Finally, it is important to remember that, due to the bas-relief effect, few-frame algorithms often succeed partially: they can accurately recover most but not all structure components [2] <ref> [23] </ref> [37]. Thus, though "Kalman filtering" techniques may be unable to compute the whole structure reliably, the discussion above suggests that they may be capable of fusing and recovering the part of structure that is accurately recoverable by few-frame methods. <p> The image center, the relative scaling of the x and y axes, or the focal length are often known approximately. This approximate information can be useful, especially since errors in the image center or focal length are known to have little effect on depth recovery <ref> [23] </ref>. <p> Experimental 6 Including the projective structure and camera matrices. 7 Again, with the possible exception of the focal length (changes in which are often relatively easy to handle by Euclidean methods <ref> [23] </ref>) and covarying parameters. 8 results on synthetic single-camera sequences [28] confirm that a standard Euclidean approach simultaneously computing the reconstruction and calibration gives more accurate results than does projective reconstruction|even for the projective structure. <p> Also, restricting to the projective structure probably does not give more reliability than computing the full Euclidean structure. Though the full Euclidean structure is often noise-sensitive, typically this sensitivity affects just a few components|most of the structure can be recovered robustly <ref> [23, 27, 29] </ref>. Moreover, one can identify the reliable part 11 of the recovered structure from the data, by estimating the expected errors in each structure component [23, 27, 29]. <p> Though the full Euclidean structure is often noise-sensitive, typically this sensitivity affects just a few components|most of the structure can be recovered robustly <ref> [23, 27, 29] </ref>. Moreover, one can identify the reliable part 11 of the recovered structure from the data, by estimating the expected errors in each structure component [23, 27, 29]. The Euclidean structure plus these error estimates clearly gives more information than the projective structure alone, with no loss in robustness. Also, the part of the Euclidean structure that can be recovered robustly is usually bigger than the part corresponding to the projective structure. <p> But, for typical calibration errors, I have argued and demonstrated ex-perimentally in [28] <ref> [23] </ref> that Euclidean algorithms do produce reasonable reconstructions. Researchers often emphasize the difficulty of calibrating accurately. But measured calibrations may actually be reasonably good in practice, at least in terms of their effects on structure recovery. <p> If the measured calibration does suffice for a reasonable initial reconstruction of at least part of the structure and motion, as the experiments of <ref> [28, 23] </ref> indeed suggest, then using these results for a second-stage correction of the calibration and reconstruction should be easy. This perturbative strategy exploits the fact that the calibration errors are typically small, especially in their effects on structure recovery. <p> This perturbative strategy exploits the fact that the calibration errors are typically small, especially in their effects on structure recovery. In contrast, the projective approach 15 For example, it often happens that the inverse depths are accurately recoverable apart from the constant inverse-depth component (due to the bas-relief ambiguity) <ref> [23] </ref>. Recovering the parameters that are robust to calibration error can still give a useful starting point for the second, perturbative stage of recovery [23]. 14 treats these errors as potentially arbitrarily large, essentially assuming an incorrect Bayesian prior. <p> projective approach 15 For example, it often happens that the inverse depths are accurately recoverable apart from the constant inverse-depth component (due to the bas-relief ambiguity) <ref> [23] </ref>. Recovering the parameters that are robust to calibration error can still give a useful starting point for the second, perturbative stage of recovery [23]. 14 treats these errors as potentially arbitrarily large, essentially assuming an incorrect Bayesian prior. Past experience with other motion problems indicates that it is important to exploit some information about the prior, i.e., our expectations for parameter values, even at the cost of introducing approximations. <p> Thus good performance of the Euclidean approach is easier to guarantee, and its performance limits are easier to understand. Note that one can extend the staged approach to deal with cases where the calibration known only partially|e.g., where the focal length is unknown and varying <ref> [23] </ref>. Finally, recall the discussion at the end of Section 2.2.4. <p> In the Euclidean approach, the image coordinates are already relatively "balanced." On the other hand, for small field of view, "balancing" does help to redress what would otherwise be a bias toward reconstructing the translation as parallel to the viewing direction <ref> [23] </ref>. Nevertheless, "balancing" does not cure completely the inaccuracy widely reported for the Euclidean 8-point algorithm [23]. <p> are already relatively "balanced." On the other hand, for small field of view, "balancing" does help to redress what would otherwise be a bias toward reconstructing the translation as parallel to the viewing direction <ref> [23] </ref>. Nevertheless, "balancing" does not cure completely the inaccuracy widely reported for the Euclidean 8-point algorithm [23]. <p> For accurate fusing, it is crucial to have good error models for the intermediate reconstructions. For two-frame reconstruction, at least for the easy cases when few-frame reconstruction is reliable and "Kalman filtering" is likely to work, the structure errors are fairly well understood and easy to model <ref> [23] </ref> [27]; the main effect come from the bas-relief ambiguity due to the confounding of rotational and translational motions. On the other hand, reconstructing from three or more images gives errors that depend in a complex way on the several different motions. <p> Thus, for general sequences of three or more images, one must choose between a slow optimization approach or a simpler, faster, but far-from-optimal algorithm such as [33, 35] [13, 9, 8]. Since recent experimental work <ref> [23] </ref> [46] has shown that two-frame optimization is quite robust and accurate as well as fast, it may actually be preferable to these three-frame algorithms. The algorithms [33, 35] [13, 9, 8] may actually be more fragile than two-frame optimization on difficult sequences. <p> Unless the motion is very small, this constraint typically has force only for a small number of points and does not significantly affect the reconstruction. I know of no implementation of two-frame optimization that fully exploits the positive-depth constraint as well as the coplanarity constraint. 24 Our experiments <ref> [23] </ref> show that the typical difference between the translation direction recovered by minimizing the approximate error and that recovered by minimizing the "optimal" MLE least squares error is less than :005 ffi . <p> we need to know that it is globally correct, which no local analysis can determine; if we compute a first-order analysis around a reconstruction that is not approximately right to 26 In comparing two-frame and three-frame algorithms experimentally, it is important to separate out the effect of the bas-relief ambiguity <ref> [23] </ref>. 27 Optimization algorithms are not necessarily robust even if the goal they attempt to compute is. 23 begin with, it is irrelevant. (Also, a first-order analysis around a specific reconstruction is tied to that reconstruction; it is useless for designing algorithms since we design for a range of problems, not <p> This discussion illustrates the general principle that to evaluate an algorithm experimentally 32 The approximate two-frame optimization technique discussed in Section 2.3 is accurate and quick even in domain 3 <ref> [23] </ref>. 29 one first needs some theoretical understanding of its expected behavior. 3.1.2 Distinguishing Domains The three domains cited above require three quite different algorithms. Clearly, the SFM problem changes significantly depending on the domain; algorithms specialized for one domain will not work throughout another.
Reference: [24] <author> J. Oliensis, </author> <title> "Multiframe Structure from Motion in Perspective," </title> <booktitle> Workshop on the Representations of Visual Scenes, </booktitle> <pages> 77-84, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: such a complex function|since it depends on the image data so differently in different domains|no one technique is likely to always approximate it well even in practice. (For example, an algorithm that works well for large camera translations can fail completely when the translations are small; see Section 3.1 and <ref> [27, 24] </ref>.) Similarly, since the problem domain strongly determines how noise affects the "optimal" estimate, probably no single error analysis applies to all domains. But if no algorithm works in all domains, then in different domains we must use different algorithms 30 . <p> But for moderate numbers of tracked feature points a variety of algorithms is necessary. 24 performance are domain-dependent this means that we should design algorithms specifically for their problem domains. Finally, by exploiting the special characteristics of each domain we can get more reliable and accurate algorithms <ref> [24, 25] </ref>. (For instance, an algorithm will give better results when the translations are large if it has been designed specifically to deal with this case.) As with many complex functions, the "optimal" estimate can be best approximated piecewise, using different local approximations over different small domain patches, rather than by <p> However, below I will only discuss the generic constraints 1-3, since adapting algorithms to specific scenes depends too specifically on the scenes. 26 All the cited constraints can be exploited by appropriately designed algorithms. For example, <ref> [25, 24] </ref> describe how to exploit the small translational motion in robot navigation. Crudely, this approach initially disregards small, higher-order corrections in the translation size relative to the distance of the scene from the camera. <p> The singular structure configurations that cause difficulties for two-image algorithms are well understood (quadric surfaces [20]). Away from these singular configurations, the quality of an algorithm's performance probably depends straightforwardly on the motion [22]. Mapping this dependence experimentally should be relatively easy. The rotation is unimportant <ref> [24, 39] </ref>, so the performance needs to be measured just as a function of the two parameters describing the translation direction. Demonstrating the reliability of algorithms based on three or more images is also possible but more difficult. <p> How can these mixed cases be handled? First, it does appear experimentally that the algorithms described above apply broadly <ref> [26, 24, 4] </ref>: often cases intermediate between two domains can be handled by approaches specialized for either. For instance, the algorithms of [30] and [27] (respectively, domain-3-style and domain-1-style approaches) have both worked on the Martin-Marietta rocket-field sequence [6] 33 .
Reference: [25] <author> J. Oliensis, </author> <title> "A Linear Solution for Multiframe Structure from Motion," </title> <booktitle> IUW, </booktitle> <pages> 1225-1231. </pages> <year> 1994. </year>
Reference-contexts: But for moderate numbers of tracked feature points a variety of algorithms is necessary. 24 performance are domain-dependent this means that we should design algorithms specifically for their problem domains. Finally, by exploiting the special characteristics of each domain we can get more reliable and accurate algorithms <ref> [24, 25] </ref>. (For instance, an algorithm will give better results when the translations are large if it has been designed specifically to deal with this case.) As with many complex functions, the "optimal" estimate can be best approximated piecewise, using different local approximations over different small domain patches, rather than by <p> However, below I will only discuss the generic constraints 1-3, since adapting algorithms to specific scenes depends too specifically on the scenes. 26 All the cited constraints can be exploited by appropriately designed algorithms. For example, <ref> [25, 24] </ref> describe how to exploit the small translational motion in robot navigation. Crudely, this approach initially disregards small, higher-order corrections in the translation size relative to the distance of the scene from the camera.
Reference: [26] <author> J. Oliensis, </author> <title> "Rigorous Bounds for Two-Frame Structure from Motion," </title> <note> ECCV 1996 and NECI TR, October 1995 (expanded version). </note>
Reference-contexts: For more than two images the problem 18 This is experimentally true for difficult problems where the camera translation is relatively small, as in traditional robot navigation. As argued and demonstrated experimentally e.g. in <ref> [26] </ref>, when the camera translation is large and the 3D scene extended, two-frame SFM is easy, and most algorithms work well, even the "8-point" algorithm [18]. 19 Hartley has pointed out that "balancing" in the projective framework makes the "8-point" algorithm more accurate and reliable [10]. <p> Though this new algorithm is more stable than the previous one, it apparently has been tested mostly on relatively easy sequences where the camera translations are large <ref> [26] </ref>. Such sequences don't give a stringent test of the trilinear algorithm's reliability, since the inaccurate "8-point" algorithm can also work well on these 18 . On more difficult sequences with small translations [26], the fact that polynomial fitting still plays a role in the revised algorithm in computing some of <p> one, it apparently has been tested mostly on relatively easy sequences where the camera translations are large <ref> [26] </ref>. Such sequences don't give a stringent test of the trilinear algorithm's reliability, since the inaccurate "8-point" algorithm can also work well on these 18 . On more difficult sequences with small translations [26], the fact that polynomial fitting still plays a role in the revised algorithm in computing some of the motion parameters may well cause instabilities 20 . It is important to test this experimentally. <p> Inverting this dependence to get the "optimal" estimate is a fully nonlinear problem, implying that the "optimal" estimate's dependence on the image data will be extremely complex. Despite this, <ref> [26] </ref> has argued and shown experimentally that SFM in domain 3 is relatively easy. The image data typically determine the reconstruction strongly and unambiguously| just two (or a few) images are typically enough to get a good reconstruction, and any standard algorithm for few-frame reconstruction is likely to work well [26]. <p> <ref> [26] </ref> has argued and shown experimentally that SFM in domain 3 is relatively easy. The image data typically determine the reconstruction strongly and unambiguously| just two (or a few) images are typically enough to get a good reconstruction, and any standard algorithm for few-frame reconstruction is likely to work well [26]. Moreover, since the few-frame reconstructions are reliable, "Kalman filtering" should be able to combine them into a reliable and more accurate multi-frame reconstruction (as discussed in Section 2.1). The reason for SFM's tractability in domain 3 is that the noise-to-signal ratio is small even for image pairs. <p> The reason for SFM's tractability in domain 3 is that the noise-to-signal ratio is small even for image pairs. Since the translational motion and scene depth variation are both large, the translational image displacements|the signal|are larger than the typical noise size and also clearly distinguishable from rotational displacements <ref> [26] </ref>. It may actually be possible to use this to show theoretically that two-frame optimization is reliable. First, one may be able to show that the "8-point" method gives good results. <p> Second, it may be possible to show that the maximum-likelihood error has a deep well around the global minimum that is broad compared to the scale of the "8-point" estimate's error <ref> [26] </ref>. Due to the small noise-to-signal ratio, this could require little more than a local curvature analysis of the error around the minimum. Indeed, [21] demonstrates that two-frame SFM is simple enough that it is possible to understand many of the important properties of the maximum-likelihood error theoretically. <p> Indeed, [21] demonstrates that two-frame SFM is simple enough that it is possible to understand many of the important properties of the maximum-likelihood error theoretically. In any case, an experimental study of two-image reconstruction is feasible; <ref> [26] </ref> contains the beginnings of such a study. The singular structure configurations that cause difficulties for two-image algorithms are well understood (quadric surfaces [20]). Away from these singular configurations, the quality of an algorithm's performance probably depends straightforwardly on the motion [22]. Mapping this dependence experimentally should be relatively easy. <p> For increasing numbers of images, the nonlinearity of SFM in domain 3 makes any analysis increasingly difficult. Correspondingly, there is probably no direct way to fully exploit multiple images for reconstruction. Two images already determine the "optimal" estimate accurately <ref> [26] </ref>, so the estimate's dependence on each additional image becomes increasingly subtle. 28 Thus a non-iterative algorithm clearly cannot compute the "optimal" estimate exactly. The more images such an algorithm attempts to use, the more its biases|its deviations from the "optimal" estimate|will predominate over the information in the additional images. <p> How can these mixed cases be handled? First, it does appear experimentally that the algorithms described above apply broadly <ref> [26, 24, 4] </ref>: often cases intermediate between two domains can be handled by approaches specialized for either. For instance, the algorithms of [30] and [27] (respectively, domain-3-style and domain-1-style approaches) have both worked on the Martin-Marietta rocket-field sequence [6] 33 . <p> But it is always possible to select parts of the sequence that do belong to single domains 34 . One can apply specialized algorithms to compute initial reconstructions from these parts|though different algorithms 33 In a related result, <ref> [26] </ref> has shown that, for two images with a moderate camera translation, the camera rotation can be approximately recovered using techniques specialized either for large or small translations. 34 For example, Section 3.1.2 suggests how to select image pairs with large camera translations. 30 may be needed to handle parts from
Reference: [27] <author> J. Oliensis, </author> <title> "Structure from Linear and Planar Motions," </title> <booktitle> CVPR 1996. </booktitle> <pages> 38 </pages>
Reference-contexts: Also, restricting to the projective structure probably does not give more reliability than computing the full Euclidean structure. Though the full Euclidean structure is often noise-sensitive, typically this sensitivity affects just a few components|most of the structure can be recovered robustly <ref> [23, 27, 29] </ref>. Moreover, one can identify the reliable part 11 of the recovered structure from the data, by estimating the expected errors in each structure component [23, 27, 29]. <p> Though the full Euclidean structure is often noise-sensitive, typically this sensitivity affects just a few components|most of the structure can be recovered robustly <ref> [23, 27, 29] </ref>. Moreover, one can identify the reliable part 11 of the recovered structure from the data, by estimating the expected errors in each structure component [23, 27, 29]. The Euclidean structure plus these error estimates clearly gives more information than the projective structure alone, with no loss in robustness. Also, the part of the Euclidean structure that can be recovered robustly is usually bigger than the part corresponding to the projective structure. <p> For accurate fusing, it is crucial to have good error models for the intermediate reconstructions. For two-frame reconstruction, at least for the easy cases when few-frame reconstruction is reliable and "Kalman filtering" is likely to work, the structure errors are fairly well understood and easy to model [23] <ref> [27] </ref>; the main effect come from the bas-relief ambiguity due to the confounding of rotational and translational motions. On the other hand, reconstructing from three or more images gives errors that depend in a complex way on the several different motions. <p> such a complex function|since it depends on the image data so differently in different domains|no one technique is likely to always approximate it well even in practice. (For example, an algorithm that works well for large camera translations can fail completely when the translations are small; see Section 3.1 and <ref> [27, 24] </ref>.) Similarly, since the problem domain strongly determines how noise affects the "optimal" estimate, probably no single error analysis applies to all domains. But if no algorithm works in all domains, then in different domains we must use different algorithms 30 . <p> How can these mixed cases be handled? First, it does appear experimentally that the algorithms described above apply broadly [26, 24, 4]: often cases intermediate between two domains can be handled by approaches specialized for either. For instance, the algorithms of [30] and <ref> [27] </ref> (respectively, domain-3-style and domain-1-style approaches) have both worked on the Martin-Marietta rocket-field sequence [6] 33 . Second, if a sequence spans the extremes of different domains, admittedly none of the algorithms suggested above may work on the entire sequence.
Reference: [28] <author> J. Oliensis and Venu Govindu, </author> <title> "Experimental Evaluation of Projective Reconstruction in Structure from Motion," </title> <note> NECI TR October 1995. </note>
Reference-contexts: Experimental 6 Including the projective structure and camera matrices. 7 Again, with the possible exception of the focal length (changes in which are often relatively easy to handle by Euclidean methods [23]) and covarying parameters. 8 results on synthetic single-camera sequences <ref> [28] </ref> confirm that a standard Euclidean approach simultaneously computing the reconstruction and calibration gives more accurate results than does projective reconstruction|even for the projective structure. <p> All the preceding arguments apply. For known calibration, a Euclidean approach will compute the projective structure more accurately than a projective one <ref> [28] </ref>. With a rough calibration, a Euclidean technique can still be better, as I discuss in Section 2.2.6. In fact, 8 Unless the FOV is very small. <p> In fact, 8 Unless the FOV is very small. Even then, it makes sense to calibrate the relative scaling and skew of the x,y axes using pure rotations. 9 Again, unless the projective approach concludes with a full Euclidean self-calibration, abandoning the initial projective computation. 10 experiments 10 show <ref> [28] </ref> that the Euclidean-recovered projective structure is as accurate as the projective result even with significant errors in the assumed calibration and even for "optimal" algorithms. This means that non-optimal projective algorithms would probably do much worse than the corresponding Euclidean ones. <p> It follows from Section 2.2.1 that the Euclidean version of optimization will give more accurate results 13 , since it is based on a more faithful model of image formation. Because it involves fewer unknowns, it may also be faster than the projective optimization, as <ref> [28] </ref> has verified experimentally for small SFM problems (but see [38]). In any case, since getting the most accurate Euclidean reconstruction requires doing Euclidean optimization eventually, one can get a faster computation by doing so at the start rather than after an extra stage of projective optimization. <p> At least on the grounds of accuracy or speed, there is little current justification for applying projective rather than Euclidean optimization to single-camera sequences. However, "projective" 14 optimization is more robust than its Euclidean counterpart <ref> [28] </ref>. This is one of the few compelling motivations for the projective approach, and I discuss it further in Section 2.2.7. If one chooses not to use optimization (or needs to compute a starting point for it), then a Euclidean approach can still be preferable to a projective one. <p> But, for typical calibration errors, I have argued and demonstrated ex-perimentally in <ref> [28] </ref> [23] that Euclidean algorithms do produce reasonable reconstructions. Researchers often emphasize the difficulty of calibrating accurately. But measured calibrations may actually be reasonably good in practice, at least in terms of their effects on structure recovery. <p> If the measured calibration does suffice for a reasonable initial reconstruction of at least part of the structure and motion, as the experiments of <ref> [28, 23] </ref> indeed suggest, then using these results for a second-stage correction of the calibration and reconstruction should be easy. This perturbative strategy exploits the fact that the calibration errors are typically small, especially in their effects on structure recovery. <p> reconstruction reliably gives all unknowns that are determinable short of calibrating, and if theoretical 15 analysis can correctly single out these unknowns, then the Euclidean approach has little disadvantage compared to a projective one even for uncalibrated sequences. 2.2.7 Robustness of "Projective" Optimization In recent experiments on calibrated single-camera sequences, <ref> [28] </ref> found that "projective" optimization had less of a local minimum problem than a pure Euclidean approach|i.e., steepest descent 16 minimizing over the structure and unconstrained camera matrices tended to converge to the global minimum from a wider range of initial guesses than if the camera matrices were constrained according to
Reference: [29] <author> J. Oliensis, </author> <note> in preparation. </note>
Reference-contexts: Also, restricting to the projective structure probably does not give more reliability than computing the full Euclidean structure. Though the full Euclidean structure is often noise-sensitive, typically this sensitivity affects just a few components|most of the structure can be recovered robustly <ref> [23, 27, 29] </ref>. Moreover, one can identify the reliable part 11 of the recovered structure from the data, by estimating the expected errors in each structure component [23, 27, 29]. <p> Though the full Euclidean structure is often noise-sensitive, typically this sensitivity affects just a few components|most of the structure can be recovered robustly <ref> [23, 27, 29] </ref>. Moreover, one can identify the reliable part 11 of the recovered structure from the data, by estimating the expected errors in each structure component [23, 27, 29]. The Euclidean structure plus these error estimates clearly gives more information than the projective structure alone, with no loss in robustness. Also, the part of the Euclidean structure that can be recovered robustly is usually bigger than the part corresponding to the projective structure.
Reference: [30] <author> J. Oliensis and J. I. Thomas, </author> <title> "Incorporating Motion Error in Multi-Frame Structure from Motion," </title> <booktitle> Motion Workshop, </booktitle> <address> Princeton, N.J., </address> <year> 1991. </year>
Reference-contexts: It works because combining Gaussian likelihoods is easy. The reason that "Kalman filtering" is nevertheless often useful is that likelihood functions 3 More precisely, the shape <ref> [42, 30] </ref>. 4 often have good Gaussian approximations. Typically this happens when there is enough data so that the subestimates have small uncertainties. If large errors are unlikely, the measurement functions can be linearized around the true values of the unknowns. This makes it easier to approximate the subestimate likelihoods. <p> Improvements such as the Extended Kalman Filter may help the algorithm to lock onto the correct estimate after accumulating some number of images|but whether this happens reliably must be settled by experiment. Experimental results confirm that fusing accurate two-frame reconstructions leads to increased accuracy <ref> [30, 41, 40] </ref>. On the other hand, when the two-frame reconstructions are sometimes very inaccurate, this strongly affects the fused reconstruction, and it can become less accurate as more images are acquired [30, 41, 40] 4 . <p> Experimental results confirm that fusing accurate two-frame reconstructions leads to increased accuracy <ref> [30, 41, 40] </ref>. On the other hand, when the two-frame reconstructions are sometimes very inaccurate, this strongly affects the fused reconstruction, and it can become less accurate as more images are acquired [30, 41, 40] 4 . <p> How can these mixed cases be handled? First, it does appear experimentally that the algorithms described above apply broadly [26, 24, 4]: often cases intermediate between two domains can be handled by approaches specialized for either. For instance, the algorithms of <ref> [30] </ref> and [27] (respectively, domain-3-style and domain-1-style approaches) have both worked on the Martin-Marietta rocket-field sequence [6] 33 . Second, if a sequence spans the extremes of different domains, admittedly none of the algorithms suggested above may work on the entire sequence.
Reference: [31] <author> V. S. Ramachadran, </author> <title> "Interaction Between Motion, Depth, Color and Form: The Utilitarian Theory of Perception," in Vision: Coding and Efficiency, </title> <editor> ed. Colin Blakemore, </editor> <address> Cambridge, </address> <year> 1990. </year>
Reference-contexts: Moreover, the type of approach that I have advocated, involving the opportunistic application of a small number of algorithms and segmentation (or approximation) based on informed guesswork, more resembles Ramachandran's "bag of tricks" approach <ref> [31] </ref> than traditional statistical inference.
Reference: [32] <author> H. S. Sawhney and R. Kumar, </author> <title> "True Multi-Image Alignment and its Application to Mosaicing and Lens Distortion Correction," </title> <note> to appear in CVPR 1997. </note>
Reference-contexts: Similarly, in registering two images taken by a moving camera, it is effective to register first based on an affine transform, then assuming a planar scene, and only at the end to allow general motion/structure <ref> [32] </ref>. In both cases, the advantage of solving for a smaller number of parameters outweighs the disadvantage of initially computing an approximate reconstruction. This staged approach is also likely to be effective in coping with calibration inaccuracies in MFSFM, and it deserves more study as an alternative to projective reconstruction.
Reference: [33] <author> A. Shashua, </author> <title> "Trilinearity in visual recognition by alignment," </title> <booktitle> in ECCV Vol. </booktitle> <pages> 1 479-484, </pages> <year> 1994. </year>
Reference-contexts: Sections 2.2.4, 2.2.7, and 2.3 discuss and critique various motivations for this strategy. As discussed in Section 2.2.7, under some conditions projective optimization may be a good approach even for calibrated sequences, but its usefulness is probably quite limited. Section 2.3 critiques non-optimal invariants-based algorithms such as in <ref> [33, 35] </ref> [13, 9, 8]. <p> Similarly for three images, the coefficients of the trilinear constraints depend just on the motion <ref> [9, 33] </ref>. Invariants-based algorithms typically begin by fitting the derived polynomial constraints to the data, producing estimates of the constraint coefficients. For example, a two-frame algorithm would begin by estimating the essential matrix. <p> Thus, for general sequences of three or more images, one must choose between a slow optimization approach or a simpler, faster, but far-from-optimal algorithm such as <ref> [33, 35] </ref> [13, 9, 8]. Since recent experimental work [23] [46] has shown that two-frame optimization is quite robust and accurate as well as fast, it may actually be preferable to these three-frame algorithms. The algorithms [33, 35] [13, 9, 8] may actually be more fragile than two-frame optimization on difficult <p> between a slow optimization approach or a simpler, faster, but far-from-optimal algorithm such as <ref> [33, 35] </ref> [13, 9, 8]. Since recent experimental work [23] [46] has shown that two-frame optimization is quite robust and accurate as well as fast, it may actually be preferable to these three-frame algorithms. The algorithms [33, 35] [13, 9, 8] may actually be more fragile than two-frame optimization on difficult sequences. Even if not, they may do less well on three frames than comparing and adjusting optimized reconstructions from different image pairs 21 . <p> In addition, since more images are more difficult to use in domain 3, it may actually turn out that two-frame optimization 32 gives better results than multi-frame, non-optimal algorithms such as <ref> [33, 35] </ref> [13, 9, 8], especially if one appropriately combines results from different image pairs 21 . (Recall that this should also hold for difficult sequences, see Section 2.3.) Again, the extent to which this is true must be determined by experiment.
Reference: [34] <author> A. Shashua and S. Avidan, </author> <title> "The Rank 4 Constraint in Multiple ( 3) View Geometry," </title> <address> ECCV 196-206, </address> <year> 1996. </year>
Reference-contexts: Second, this number must be small, because the constraints involving large numbers of images or points quickly become too complicated and high order to be useful 22 . Thus the invariants approach does not lead to direct multi-frame algorithms. Recently, some researchers (e.g., <ref> [34] </ref>) have proposed techniques for combining intermediate few-frame (especially trilinear) reconstructions computed in an invariants approach to build a multi-frame reconstruction. But as already argued in the discussion of "Kalman filtering," fusing typically fails unless the intermediate reconstructions are already accurate and reliable.
Reference: [35] <author> A. Shashua, </author> <title> "Algebraic functions for recognition," </title> <type> PAMI 17, </type> <pages> 779-789, </pages> <year> 1995. </year>
Reference-contexts: Sections 2.2.4, 2.2.7, and 2.3 discuss and critique various motivations for this strategy. As discussed in Section 2.2.7, under some conditions projective optimization may be a good approach even for calibrated sequences, but its usefulness is probably quite limited. Section 2.3 critiques non-optimal invariants-based algorithms such as in <ref> [33, 35] </ref> [13, 9, 8]. <p> Thus, for general sequences of three or more images, one must choose between a slow optimization approach or a simpler, faster, but far-from-optimal algorithm such as <ref> [33, 35] </ref> [13, 9, 8]. Since recent experimental work [23] [46] has shown that two-frame optimization is quite robust and accurate as well as fast, it may actually be preferable to these three-frame algorithms. The algorithms [33, 35] [13, 9, 8] may actually be more fragile than two-frame optimization on difficult <p> between a slow optimization approach or a simpler, faster, but far-from-optimal algorithm such as <ref> [33, 35] </ref> [13, 9, 8]. Since recent experimental work [23] [46] has shown that two-frame optimization is quite robust and accurate as well as fast, it may actually be preferable to these three-frame algorithms. The algorithms [33, 35] [13, 9, 8] may actually be more fragile than two-frame optimization on difficult sequences. Even if not, they may do less well on three frames than comparing and adjusting optimized reconstructions from different image pairs 21 . <p> In addition, since more images are more difficult to use in domain 3, it may actually turn out that two-frame optimization 32 gives better results than multi-frame, non-optimal algorithms such as <ref> [33, 35] </ref> [13, 9, 8], especially if one appropriately combines results from different image pairs 21 . (Recall that this should also hold for difficult sequences, see Section 2.3.) Again, the extent to which this is true must be determined by experiment.
Reference: [36] <author> T. Svoboda and P. </author> <title> Sturm,"Badly Calibrated Camera in Ego-Motion Estimation Propagation of Uncertainty," </title> <address> CAIP 183-190, </address> <year> 1997. </year>
Reference: [37] <author> R. Szeliski and S.B. Kang, </author> <title> "Shape ambiguities in structure from motion," </title> <type> PAMI 19, </type> <pages> 506-512, </pages> <year> 1997. </year>
Reference-contexts: Finally, it is important to remember that, due to the bas-relief effect, few-frame algorithms often succeed partially: they can accurately recover most but not all structure components [2] [23] <ref> [37] </ref>. Thus, though "Kalman filtering" techniques may be unable to compute the whole structure reliably, the discussion above suggests that they may be capable of fusing and recovering the part of structure that is accurately recoverable by few-frame methods.
Reference: [38] <author> R. Szeliski and S. B. Kang, </author> <title> "Recovering 3D shape and motion from image streams using nonlinear least squares," </title> <journal> Journal of Visual Communication and Image Representation, </journal> <volume> 5(1) </volume> <pages> 10-28, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Because it involves fewer unknowns, it may also be faster than the projective optimization, as [28] has verified experimentally for small SFM problems (but see <ref> [38] </ref>). In any case, since getting the most accurate Euclidean reconstruction requires doing Euclidean optimization eventually, one can get a faster computation by doing so at the start rather than after an extra stage of projective optimization.
Reference: [39] <author> T. Y. Tian, C. Tomasi, and D. J. </author> <title> Heeger, </title> <booktitle> "Comparison of Approaches to Egomotion Computation" CVPR, </booktitle> <pages> pp. 315-320, </pages> <year> 1996. </year>
Reference-contexts: The singular structure configurations that cause difficulties for two-image algorithms are well understood (quadric surfaces [20]). Away from these singular configurations, the quality of an algorithm's performance probably depends straightforwardly on the motion [22]. Mapping this dependence experimentally should be relatively easy. The rotation is unimportant <ref> [24, 39] </ref>, so the performance needs to be measured just as a function of the two parameters describing the translation direction. Demonstrating the reliability of algorithms based on three or more images is also possible but more difficult.
Reference: [40] <author> J. I. Thomas and J. Oliensis, </author> <title> "Isolation and Correction of Noise in Multi-Frame Structure from Motion," </title> <type> NECI/UMASS Technical Report, </type> <month> October, </month> <year> 1994. </year>
Reference-contexts: Improvements such as the Extended Kalman Filter may help the algorithm to lock onto the correct estimate after accumulating some number of images|but whether this happens reliably must be settled by experiment. Experimental results confirm that fusing accurate two-frame reconstructions leads to increased accuracy <ref> [30, 41, 40] </ref>. On the other hand, when the two-frame reconstructions are sometimes very inaccurate, this strongly affects the fused reconstruction, and it can become less accurate as more images are acquired [30, 41, 40] 4 . <p> Experimental results confirm that fusing accurate two-frame reconstructions leads to increased accuracy <ref> [30, 41, 40] </ref>. On the other hand, when the two-frame reconstructions are sometimes very inaccurate, this strongly affects the fused reconstruction, and it can become less accurate as more images are acquired [30, 41, 40] 4 .
Reference: [41] <author> J. I. Thomas, A. Hanson, and J. Oliensis, </author> <title> "Refining 3D reconstructions: A theoretical and experimental study of the effect of cross-correlations", </title> <journal> CVGIP:IU, </journal> <volume> Vol. 60, </volume> <pages> 359-370, </pages> <year> 1994. </year>
Reference-contexts: Improvements such as the Extended Kalman Filter may help the algorithm to lock onto the correct estimate after accumulating some number of images|but whether this happens reliably must be settled by experiment. Experimental results confirm that fusing accurate two-frame reconstructions leads to increased accuracy <ref> [30, 41, 40] </ref>. On the other hand, when the two-frame reconstructions are sometimes very inaccurate, this strongly affects the fused reconstruction, and it can become less accurate as more images are acquired [30, 41, 40] 4 . <p> Experimental results confirm that fusing accurate two-frame reconstructions leads to increased accuracy <ref> [30, 41, 40] </ref>. On the other hand, when the two-frame reconstructions are sometimes very inaccurate, this strongly affects the fused reconstruction, and it can become less accurate as more images are acquired [30, 41, 40] 4 .
Reference: [42] <author> C. Tomasi and T. Kanade, </author> <title> "Shape and motion from image streams under orthography: A factorization method," </title> <booktitle> IJCV 9, </booktitle> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: It works because combining Gaussian likelihoods is easy. The reason that "Kalman filtering" is nevertheless often useful is that likelihood functions 3 More precisely, the shape <ref> [42, 30] </ref>. 4 often have good Gaussian approximations. Typically this happens when there is enough data so that the subestimates have small uncertainties. If large errors are unlikely, the measurement functions can be linearized around the true values of the unknowns. This makes it easier to approximate the subestimate likelihoods. <p> Neglecting the rotation matrix constraints is standard in many Euclidean algorithms, for instance, in the "8-point" computation of the essential matrix [18], or Tomasi and Kanade's SVD approach to orthographic SFM <ref> [42] </ref>. The projective approach therefore does not lead to new SFM algorithms; all so-called projective algorithms translate directly into Euclidean ones|just as the "8-point" algorithm determining the fundamental matrix translates into the familiar "8-point" algorithm for the essential matrix. <p> This is straightforward and techniques already exist, e.g., Hartley's method for recovering the rotation matrix from an inexact essential matrix [15], or Tomasi and Kanade's technique <ref> [42] </ref>. 2.2.6 Alternatives to Projective Reconstruction The projective approach to dealing with uncalibrated cameras is flawed|are there reasonable Euclidean alternatives? Certainly there are for single-camera sequences|even, as I have already implied, when the calibration is completely unknown. <p> For example, an algorithm might initially omit some points because they are occluded in many of the images of a sequence and thus are more difficult to use. Similarly, Tomasi and 25 Kanade's approach <ref> [42] </ref> neglects the higher-order (and thus small and difficult-to-exploit) perspective effects and utilizes just the first-order image displacements, from which the structure and motion can be determined simply. <p> Often a distinction is drawn between two types of approximate algorithms: those that compute the exact answer for zero noise, for example the "8-point" algorithm, and those that do not, for example the Tomasi/Kanade approach <ref> [42] </ref>. But this distinction has no real importance, since all sequences have noise: both types simplify the problem by deviating from the "optimal" estimate, and for both the deviations are usefully small only for certain types of sequences. <p> For example, [25, 24] describe how to exploit the small translational motion in robot navigation. Crudely, this approach initially disregards small, higher-order corrections in the translation size relative to the distance of the scene from the camera. The strategy resembles that of Tomasi and Kanade <ref> [42] </ref>, but the algorithms differ characteristically because they are adapted to different domains; in each case the domain determines what image information is most easily exploited 31 . 3.1.1 Domain 3: Nonlinear SFM The domains 1, 2 are associated with a small physical parameter; algorithms can exploit this by linearizing in <p> It may actually be possible to use this to show theoretically that two-frame optimization is reliable. First, one may be able to show that the "8-point" method gives good results. Even though this 31 The algorithm of <ref> [42] </ref> is targeted for domain 2 and, accordingly, it neglects corrections in the ratio of the scene size to the scene distance. 27 algorithm weights the information in the data incorrectly, the data determine the correct reconstruction so strongly over domain 3 that the resulting bias may be unimportant. <p> To guess well we must take advantage of our prior knowledge about the typical properties of motion sequences, i.e., use a Bayesian strategy. Most work on SFM implicitly incorporates some expectation for what the data will look like. For example, the Tomasi/Kanade algorithm <ref> [42] </ref> assumes that the 3D scene is compact compared to its distance to the camera. For a difficult task like segmentation, using these expectations is essential. Fortunately, given that we do know a lot about the constraints on real-world sequences, making reasonable guesses is often not difficult.
Reference: [43] <author> B. Triggs, </author> <title> "Matching Constraints and the Joint Image," </title> <booktitle> ICCV, </booktitle> <pages> pp. 338-343, </pages> <year> 1995. </year>
Reference-contexts: Also, modeling the errors in establishing correspondence over three or more images may be more difficult than for just two. 22 Using a large number of images is impossible in practice, but not in principle. The result of <ref> [43] </ref> [7] does not rule out invariants algorithm based on more than four images: one can always derive polynomial constraints on the image data for arbitrary numbers of images and solve for the coefficients of the polynomial constraints using all image data. 21 More importantly, for SFM from point features, two-image
Reference: [44] <author> T. Vieville and O. Faugeras, </author> <title> "The First Order Expansion of Motion Equations in the Uncalibrated Case," </title> <booktitle> CVIU 64, </booktitle> <pages> 128-146, </pages> <year> 1996. </year>
Reference: [45] <author> D. Weinshall, M. Werman, A. Shashua, </author> <title> "Duality of Multi-Point and Multi-Frame Geometry: Fundamental Shape Matrices and Tensors," </title> <address> ECCV 217-227, </address> <year> 1996. </year>
Reference: [46] <author> Zhengyou Zhang, </author> <title> "Understanding the Relationship Between the Optimization Criteria in Two-View Motion Analysis," </title> <address> ICCV 772-777, </address> <year> 1998. </year> <month> 39 </month>
Reference-contexts: Thus, for general sequences of three or more images, one must choose between a slow optimization approach or a simpler, faster, but far-from-optimal algorithm such as [33, 35] [13, 9, 8]. Since recent experimental work [23] <ref> [46] </ref> has shown that two-frame optimization is quite robust and accurate as well as fast, it may actually be preferable to these three-frame algorithms. The algorithms [33, 35] [13, 9, 8] may actually be more fragile than two-frame optimization on difficult sequences.
References-found: 46

