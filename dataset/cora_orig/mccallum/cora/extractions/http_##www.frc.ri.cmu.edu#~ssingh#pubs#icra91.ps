URL: http://www.frc.ri.cmu.edu/~ssingh/pubs/icra91.ps
Refering-URL: http://www.frc.ri.cmu.edu/~ssingh/pubs_conf.html
Root-URL: 
Title: Abstract  
Abstract: We present several schemes for Obstacle Detection for autonomous vehicles traveling at high speeds (above 5m/s). In particular, we discuss schemes that make a globallyat-world assumption and ignore vehicle pitch motion. Next, we examine methods that relax the above assumptions. In each case we discuss the strengths and weakness of the solutions proposed. Experimental and simulation results are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Singh, D. H. Shin, </author> <title> Position Based Path Tracking for Wheeled Mobile Robots, </title> <booktitle> in Proceedings IEEE/RSJ International Workshop on Intelligent Robot Systems, </booktitle> <month> September </month> <year> 1989, </year> <note> Tskuba, Japan. </note>
Reference: [2] <author> D. H. Shin, S. Singh, </author> <title> Vehicle and Path Models for Autonomous Navigation, In Vision and Navigation: </title> <note> The Carnegie Mellon NavLab, </note> <editor> Editor Chuck Thorpe, </editor> <publisher> Kluwer Press, </publisher> <year> 1990. </year>
Reference: [3] <author> R. T. Dunlay, </author> <title> Obstacle Avoidance Perception Processing for the Autonomous Land Vehicle, </title> <booktitle> Proceedings IEEE ICRA, </booktitle> <address> Philadelphia, </address> <year> 1988. </year>
Reference-contexts: The other method explores the scenario where a dense range map is available but must be processed very rapidly. To this end, we have designed schemes similar to those proposed by Dunlay <ref> [3] </ref>, but, are more efficient, in the amount of computation required. 2. Obstacle Detection in a Flat World We chose to begin the investigation in a two-dimensional world. Two techniques were designed with the simplification that the vehicle travels in a 2-D world.
Reference: [4] <author> M. J. Daily, J. G. Harris, K. Reiser, </author> <title> Detecting Obstacles in Range Imagery, </title> <booktitle> Proceedings DARPA Image Understanding Workshop, </booktitle> <month> February, </month> <year> 1987. </year>
Reference-contexts: By projecting the path onto the image, a large portion of the image can be ignored, and many needless computations avoided. Note that this is contrary to standard methods of using range data e.g., as in <ref> [4] </ref>. Assuming that the vehicle path is specified at regular intervals, the current vehicle position can be used to locate the path segment lying in front of the scanner.
Reference: [5] <author> M. Hebert, </author> <title> Building and Navigating maps of Road Scenes Using an Active Sensor, </title> <booktitle> Proceedings IEEE ICRA, </booktitle> <year> 1989. </year>
Reference: [6] <author> U. Regensburger, V. Graefe, </author> <title> Object Classification for Obstacle Avoidance, </title> <booktitle> Proceedings SPIE Symposium on Advances in Intelligent Systems, </booktitle> <year> 1990. </year>
Reference-contexts: More recently, some researchers have demonstrated obstacle detection using passsive vision along with special purpose hardware at speeds up to 14m/s on straight stretches of at highway <ref> [6] </ref>. Passive vision, however, is limited in scope because it is prone to poor illunination and low contrast conditions. Our approach has been two fold. Firstly, we use accurate position estimation to determine the location of the autonomous vehicle on the path it is to follow.
Reference: [7] <author> K. Dowling, R. Guzikowski, H. Pangels, S. Singh, W. Whittaker, NavLab: </author> <title> An Autonomous Vehicle, </title> <type> Technical Report, </type> <institution> CMU-RI-TR-87-24, Robotic Institute, Carnegie Mellon University, </institution> <year> 1987. </year>
Reference: [8] <author> S. Singh, J. West, Cyclone: </author> <title> A Laser Scanner for Autonomous Vehicle Navigation, </title> <note> Technical Report to be published, </note> <institution> Robotics Institute, Carnegie Mellon University, </institution> <year> 1991. </year>
Reference: [9] <author> S. Singh, D. Feng, P. Keller, G. Shafer, D. H. Shin, W. Shi, J. West, B. Wu, FastNav: </author> <title> A System for Fast Navigation, </title> <note> Technical Report to be published, </note> <institution> Robotics Institute, Carnegie Mellon University, </institution> <year> 1991. </year>
Reference-contexts: The second method checks a bounded region around the path to be traversed for range data corresponding to objects. We present a condensed version of these techniques. A more complete description can be found in <ref> [9] </ref>. Figure 1 shows the range scanner mounted on the front of the vehicle. 2.1. Profile Matching. Profile matching is based on the notion of matching a hypothesized range profile using vehicle position and a world model, with a range profile inferred from range data obtained while in motion.
References-found: 9

