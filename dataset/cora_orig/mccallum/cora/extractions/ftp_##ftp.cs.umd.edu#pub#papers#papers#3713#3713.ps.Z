URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3713/3713.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Title: Latent Semantic Indexing via a Semi-Discrete Matrix Decomposition  
Author: Tamara G. Kolda and Dianne P. O'Leary 
Date: November 20, 1996  
Abstract: With the electronic storage of documents comes the possibility of building search engines that can automatically choose documents relevant to a given set of topics. In information retrieval, we wish to match queries with relevant documents. Documents can be represented by the terms that appear within them, but literal matching of terms does not necessarily retrieve all relevant documents. There are a number of information retrieval systems based on inexact matches. Latent Semantic Indexing represents documents by approximations and tends to cluster documents on similar topics even if their term profiles are somewhat different. This approximate representation is usually accomplished using a low-rank singular value decomposition (SVD) approximation. In this paper, we use an alternate decomposition, the semi-discrete decomposition (SDD). For equal query times, the SDD does as well as the SVD and uses less than one-tenth the storage for the MEDLINE test set.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Michael W. Berry, Susan T. Dumais, and Gavin W. O'Brien. </author> <title> Using linear algebra for intelligent information retrieval. </title> <journal> SIAM Review, </journal> <volume> 37 </volume> <pages> 573-595, </pages> <year> 1995. </year>
Reference-contexts: The SVD has been used quite effectively for information retrieval, as documented in numerous reports. We recommend the original LSI paper [3], a paper by Dumais reporting the effectiveness of the LSI approach on the TREC-3 dataset [4], and a more mathematical paper by Berry, Dumais and O'Brien <ref> [1] </ref> for further information. 4 LSI via a Semi-Discrete Decomposition The SVD contains a lot of information, probably more than is necessary for this application. To save storage, we propose replacing the SVD by a semi-discrete decomposition. The decomposition we propose is not new.
Reference: [2] <author> James P. Callan, Bruce Croft, and Stephen M. Harding. </author> <title> The INQUERY retrieval system. </title> <booktitle> In Proceedings of the Third International Conference on Database and Expert Systems Applications, </booktitle> <pages> pages 78-83. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: An example is the INQUERY system, which ranks documents according to the probability that they are relevant, determining the probability via an inference net <ref> [2] </ref>. The framework we are interested in here is the vector space framework such as that used in the SMART system [8]. In the vector space framework, indexing terms and documents are represented in a matrix one row per term and one column per document.
Reference: [3] <author> Scott Deerwester, Susan T. Dumais, George W. Furnas, Thomas K. Lan-dauer, and Richard Harshman. </author> <title> Indexing by latent semantic analysis. </title> <journal> Journal of the Society for Information Science, </journal> <volume> 41 </volume> <pages> 391-407, </pages> <year> 1990. </year>
Reference-contexts: The SVD has been used quite effectively for information retrieval, as documented in numerous reports. We recommend the original LSI paper <ref> [3] </ref>, a paper by Dumais reporting the effectiveness of the LSI approach on the TREC-3 dataset [4], and a more mathematical paper by Berry, Dumais and O'Brien [1] for further information. 4 LSI via a Semi-Discrete Decomposition The SVD contains a lot of information, probably more than is necessary for this
Reference: [4] <author> Susan Dumais. </author> <title> Improving the retrieval of infomation from external sources. Behavior Research Methods, Instruments, </title> & <journal> Computers, </journal> <volume> 23 </volume> <pages> 229-236, </pages> <year> 1991. </year>
Reference-contexts: The SVD has been used quite effectively for information retrieval, as documented in numerous reports. We recommend the original LSI paper [3], a paper by Dumais reporting the effectiveness of the LSI approach on the TREC-3 dataset <ref> [4] </ref>, and a more mathematical paper by Berry, Dumais and O'Brien [1] for further information. 4 LSI via a Semi-Discrete Decomposition The SVD contains a lot of information, probably more than is necessary for this application. To save storage, we propose replacing the SVD by a semi-discrete decomposition.
Reference: [5] <author> William B. Frakes and Ricardo Baeza-Yates. </author> <title> Information Retrieval: Data Structures and Algorithms. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1992. </year>
Reference-contexts: Information requests, or queries, are formatted according to the rules of the particular information retrieval (IR) system. For example, library catalogs are typically searched using a Boolean framework that connects key words using logical constructs such as and, or, and not <ref> [5] </ref>. Somewhat more complicated text pattern searches are used in systems such as the grep tool in UNIX [5]. Both the Boolean and text pattern search systems are based on exact matches: a fl Applied Mathematics Program, University of Maryland, College Park, MD 20742. <p> For example, library catalogs are typically searched using a Boolean framework that connects key words using logical constructs such as and, or, and not <ref> [5] </ref>. Somewhat more complicated text pattern searches are used in systems such as the grep tool in UNIX [5]. Both the Boolean and text pattern search systems are based on exact matches: a fl Applied Mathematics Program, University of Maryland, College Park, MD 20742. <p> The MEDLINE test set comes with a document file, a query file and a relevancy judgment file. We first removed all the stop words (common words such as "the" or "because") from the document and query files using the stop word removal program described in <ref> [5] </ref>. Any word that appears in two different documents after stop word removal was used as an indexing term. Then we determined the entries in A and q as described in Section 4. In Figure 1, we present the results of our tests.
Reference: [6] <author> Gene H. Golub and Charles F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins Press, </publisher> <address> 2nd edition, </address> <year> 1989. </year>
Reference-contexts: In matrix form, this is written as A A k U k k V T It can be shown that A k is the best rank-k approximation to A in the Frobenius norm and in the Euclidean norm <ref> [6] </ref>.
Reference: [7] <author> Dianne P. O'Leary and Shmuel Peleg. </author> <title> Digital image compression by outer product expansion. </title> <journal> IEEE Transactions on Communications, </journal> <volume> 31 </volume> <pages> 441-444, </pages> <year> 1983. </year>
Reference-contexts: To save storage, we propose replacing the SVD by a semi-discrete decomposition. The decomposition we propose is not new. It was introduced by O'Leary and Peleg <ref> [7] </ref> in 1983 for digital image compression. We will briefly describe the decomposition but refer the reader to [7] for more detailed information. <p> To save storage, we propose replacing the SVD by a semi-discrete decomposition. The decomposition we propose is not new. It was introduced by O'Leary and Peleg <ref> [7] </ref> in 1983 for digital image compression. We will briefly describe the decomposition but refer the reader to [7] for more detailed information.
Reference: [8] <author> Gerald Salton and Michael J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year> <month> 10 </month>
Reference-contexts: An example is the INQUERY system, which ranks documents according to the probability that they are relevant, determining the probability via an inference net [2]. The framework we are interested in here is the vector space framework such as that used in the SMART system <ref> [8] </ref>. In the vector space framework, indexing terms and documents are represented in a matrix one row per term and one column per document. The (i; j)th entry in the matrix represents the importance of term i in document j.
References-found: 8

