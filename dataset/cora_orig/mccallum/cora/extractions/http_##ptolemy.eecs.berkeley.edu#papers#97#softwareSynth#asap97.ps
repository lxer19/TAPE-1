URL: http://ptolemy.eecs.berkeley.edu/papers/97/softwareSynth/asap97.ps
Refering-URL: http://ptolemy.eecs.berkeley.edu/papers/97/softwareSynth/
Root-URL: 
Title: Abstract developed for the synchronous dataflow model of computation, a model that has found widespread
Author: Shuvra S. Bhattacharyya, Hitachi America Praveen K. Murthy, Edward A. Lee, 
Date: July 1997.  
Address: 1/21/1997  
Affiliation: University of California at Berkeley  University of California at Berkeley  
Note: The compiling techniques described in the paper ar e  A key problem that arises in this strate gy is codesize explosion since if an actor appears 20  Proceedings of the ASAP 97 conference in Zurich, Switzerland,  
Abstract: This paper reviews a set of tec hniques for compiling dataflow-based, graphical programs for embedded signal processing applications into efficient implementations on programmable digital signal processors. This is a critical problem because programmable digital signal processors have very limited amounts of on-c hip memory, and the speed and power penalties for using of f-chip memory are often prohibitively high for the types of applications, typically embedded systems, where these processors are used. Moreover, off-chip memory typically needs to be static, increasing the system cost considerably. Rapid prototyping en vironments such as those described in [6], [12], [19], and [18] support code-generation for programmable digital signal processors (PDSP) used in embedded systems. T raditionally, PDSPs have been programmed manually, in assembly language, and this is a tedious, error-prone process at best. Hence, generating code automatically is a desirable goal. Since the amount of on-chip memory on such a PDSP is se verely limited, it is imperative that the generated code be parsimonious in its memory usage. Adding off-chip memory is often infeasible due to increased cost, increased po wer requirements, and a speed penalty that will affect the feasibility of real-time implementations. One approach to automatic code generation is to specify the program in an imperative language such as C, C++, or FOR TRAN and use a good compiler. However, even the best compilers today produce inefficient code [25]. In addition, specifications in imperative languages are difficult to parallelize, are difficult to change due to side ef fects, and offer few chances for any formal verification of program properties. An alternative is to use a block diagram language based on a model of computation with strong formal properties such as synchronous dataow (SDF) [15] to specify the system, and to do code-generation starting from this specif ication. One reason that a compiler for a block diagram language is likely to give better performance than a compiler for an imperative language is because the underlying model of computation often imposes restrictions on the control ow of the specification, and this can be profitably exploited by the compiler. SDF [15] is a special case of dataf low. In SDF, a program is represented by a directed graph in which each vertex (actor) represents a computation, an edge specif ies a FIFO buffer, and each actor produces (consumes) a f ixed number of data values (tokens) onto (from) each output (input) edge per invocation. A parameter on each edge specifies the number of initial tok ens residing on that arc (called delays). The code-generation strategy followed in many block diagram environments is called threading; in this method, the underlying model (in this case, SDF) is scheduled to generate a sequence of actor invocations (provided that the model can be scheduled at compile time of-course). A code generator then steps through this schedule and inserts the machine instructions necessary for the computation specified by each actor it encounters; these instructions are obtained from a predefined library of actor code blocks. We assume that the code-generator generates inline code; this is because the alternative of using subroutine calls can have unacceptable overhead, especially if there are man y small tasks. By compile an SDF graph, we mean exactly the strategy described above for generating a softw are implementation from an SDF graph specif ication of the system in the block diagram environment. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ade, R. Lauwereins, and J. A. Peperstraete, </author> <title> Buffer Memory Requirements in DSP Applications, presented at IEEE Workshop on Rapid System Prototyping, </title> <address> Grenoble, </address> <month> June, </month> <year> 1994. </year>
Reference-contexts: We believe that this will be more ef ficient than constructing naive schedules, and relying solely on loop transformations to achieve adequate data locality. In <ref> [1] </ref>, Ade, Lauwereins, and Peperstraete de velop upper bounds on the minimum b uffer memory requirement for certain classes of SDF graphs.
Reference: [2] <author> S. S. Bhattacharyya, P. K. Murthy, and E. A. Lee, APGAN and RPMC: </author> <title> Complementary Heuristics for T ranslating DSP Block Diagrams into Efficient Software Implementations, Journal of Design Automation for Embedded Systems, </title> <note> to appear. </note>
Reference-contexts: The postprocessing step can be accomplished optimally by using a dynamic programming algorithm [17]. The running time of this algorithm on sparse SDF graphs is , where is the set of vertices. We refer to this post-processing algorithm as DPPO. 7.1 The Buffer Memory Lower Bound I n <ref> [ 2 ] </ref> t h e f o l l o w i n g l o w e r b o u n d o n is derived, given a consistent SDF graph , an edge in , and a valid single appearance schedule . <p> Thus, an APGAN instance is any algorithm that takes a consistent, acyclic SDF graph, repeatedly clusters APGAN candidates, and then outputs the schedule corresponding to a recursive traversal of the resulting cluster hierarchy. It is shown in <ref> [2] </ref> that APGAN is optimal for a class of acyclic SDF graphs in the following way: Theorem 2: [2] If is a connected, acyclic SDF graph that has a BMLB schedule; for all ; and is an APGAN instance, then the schedule obtained by applying to is a BMLB schedule for <p> It is shown in <ref> [2] </ref> that APGAN is optimal for a class of acyclic SDF graphs in the following way: Theorem 2: [2] If is a connected, acyclic SDF graph that has a BMLB schedule; for all ; and is an APGAN instance, then the schedule obtained by applying to is a BMLB schedule for . <p> It is interesting to note that on nonuniform filterbank structures, the BMLB cannot be achieved, and on such structures, RPMC gi ves better schedules than APGAN. RPMC outperforms APGAN by almost 2 to 1 on random SDF graphs. Details of this study can be found in <ref> [2, 17] </ref>. 8: Alternative Approaches for Scheduling SDF Graphs The techniques in this paper focus on compiling SDF graphs to minimize the code size and data memory size.
Reference: [3] <author> S. S. Bhattacharyya, J. T. Buck, S. Ha, and E. A. Lee, </author> <title> Generating Compact Code from Dataflow Specifications of Multirate Signal Processing Algorithms, </title> <journal> IEEE Transactions on Circuits 9 and Systems I: Fundamental Theory and Applications , Vol. </journal> <volume> 42, No. 3, </volume> <pages> pp. 138-150, </pages> <month> March, </month> <year> 1995. </year>
Reference-contexts: If such a partition e xists, the strongly connected SDF graph is loosely interdependent, otherwise it is tightly interdependent. The following theorem relates loose interdependence to single appearance schedules <ref> [3] </ref>: Theorem 1: A strongly connected, consistent SDF graph has a single appearance schedule if and only if every strongly connected subgraph of is loosely interdependent. Thus, partitioning loosely interdependent SDF graphs defines a decomposition process for hierarchically scheduling SDF graphs that leads to single appearances schedules whenever they exist. <p> The precise manner in which the three component sub-algorithms interact to define a loose interdependence algorithm is specif ied in <ref> [3] </ref>. The following useful properties of loose interdependence algorithms are established in [3]. Any loose interdependence algorithm constructs a single appearance schedule when one exists. <p> The precise manner in which the three component sub-algorithms interact to define a loose interdependence algorithm is specif ied in <ref> [3] </ref>. The following useful properties of loose interdependence algorithms are established in [3]. Any loose interdependence algorithm constructs a single appearance schedule when one exists.
Reference: [4] <author> S. S. Bhattacharyya and E. A. Lee, </author> <title> Looped Schedules for Dataflow Descriptions of Multirate Signal Processing Algorithms, </title> <journal> Journal of Formal Methods in System Design , Vol. </journal> <volume> 5, No. 3, </volume> <month> December, </month> <year> 1994. </year>
Reference-contexts: If is a subset of actors in a connected, consistent SDF graph , , 1 and we refer to this quantity as the repetition count of . 5: Subindependence The following useful facts have been established concerning the existence of a single appearance schedule for a given SDF graph <ref> [4] </ref>. An SDF graph has a single appearance schedule if and only if each strongly connected component has a single appearance schedule.
Reference: [5] <author> S. S. Bhattacharyya, P. K. Murthy, and E. A. Lee, </author> <title> Software Synthesis from Dataflow Graphs, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Norwell Ma, </address> <year> 1996. </year>
Reference-contexts: These techniques have all been implemented in the Ptolemy software environment [6]. A detailed, comprehensive treatment of the techniques discussed in this paper, including complete pseudocode specifications of the algorithms, can be found in <ref> [5] </ref>.
Reference: [6] <author> J. T. Buck, S. Ha, E. A. Lee, and D. G. Messerschmitt, Ptolemy: </author> <title> A Framework for Simulating and Prototyping Heterogeneous Systems, </title> <journal> International Journal of Computer Simulation, </journal> <volume> Vol. 4, </volume> <month> April, </month> <year> 1994. </year>
Reference-contexts: 1: Introduction Rapid prototyping en vironments such as those described in <ref> [6] </ref>, [12], [19], and [18] support code-generation for programmable digital signal processors (PDSP) used in embedded systems. T raditionally, PDSPs have been programmed manually, in assembly language, and this is a tedious, error-prone process at best. Hence, generating code automatically is a desirable goal. <p> Note that this model of b uffering maintaining a separate memory buffer for each data ow arc is convenient and natural for code generation, and it is the model used, for example, in the SDF-based code generation described in <ref> [6] </ref>, [12], [19]. More technical adv antages of this buffering model are elaborated on in [17]. There are tw o natural angles for approaching the problem of joint minimization of code size and b uffer memory requirements. <p> These complimentary algorithms can easily be incorporated into the scheduling framework to handle the ac yclic graphs that result from the decomposition process. These techniques have all been implemented in the Ptolemy software environment <ref> [6] </ref>. A detailed, comprehensive treatment of the techniques discussed in this paper, including complete pseudocode specifications of the algorithms, can be found in [5].
Reference: [7] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest, </author> <title> Introduction to Algorithms, </title> <publisher> McGraw-Hill, </publisher> <year> 1990. </year>
Reference-contexts: This problem is believed to be NP-complete, although a proof has not been disco vered [17]. Kernighan and Lin [10] devised a heuristic procedure for computing cuts into bounded sets but they considered only undirected graphs. Methods based on network flows <ref> [7] </ref> do not w ork because the minimum cut given by the max-flow-min-cut theorem may not be legal and may not be bounded [17]. Hence, a heuristic solution is needed for finding legal minimum cuts into bounded sets.
Reference: [8] <author> M. R. Garey and D. S. Johnson, </author> <title> Computers and Intractability-A guide to the theory of NP-completeness, </title> <publisher> Freeman, </publisher> <year> 1979. </year>
Reference: [9] <author> S. R. Govindarajan, G. R. Gao, and P. Desai, </author> <title> Minimizing Memory Requirements in Rate-Optimal Schedules, </title> <booktitle> Proceedings of the International Conference on Application Specific Array Processors, </booktitle> <month> August, </month> <year> 1994. </year>
Reference-contexts: A linear programming framework for minimizing the memory requirement of a synchronous dataow graph in a parallel processing context is explored by Govindarajan and Gao in <ref> [9] </ref>.
Reference: [10] <author> B. W. Kernighan and S. Lin, </author> <title> An Efficient Heuristic Procedure for Partitioning Graphs, </title> <journal> Bell System Technical Journal, vol.49, </journal> <volume> (no.2):291-308, </volume> <month> February </month> <year> 1970. </year>
Reference-contexts: The problem then is to f ind the minimum weight legal cut into bounded sets for the graph. This problem is believed to be NP-complete, although a proof has not been disco vered [17]. Kernighan and Lin <ref> [10] </ref> devised a heuristic procedure for computing cuts into bounded sets but they considered only undirected graphs. Methods based on network flows [7] do not w ork because the minimum cut given by the max-flow-min-cut theorem may not be legal and may not be bounded [17]. <p> Consider a cut produced by setting for some actor , and let be the set of independent, boundary actors of in . A boundary actor in is an actor that is not the predecessor of an y other actor in . Following Kernighan and Lin <ref> [10] </ref>, for each of these actors, we can compute the cost dif ference that results if the actor is mo ved into .
Reference: [11] <author> R. Lauwereins, P. Wauters, M. Ade, and J. A. Pererstraete, </author> <title> Geometric Parallelism and Cyclo-Static Dataflow in GRAPEII, </title> <booktitle> IEEE Workshop on Rapid System Prototyping, </booktitle> <month> June, </month> <year> 1994. </year>
Reference-contexts: In <ref> [11] </ref>, Lauwereins, Wauters, Ade, and Peperstraete present a generalization of SDF called cyclo-static data- flow. A major advantage of cyclo-static dataflow is that it can eliminate large amounts of token traffic arising from the need to generate dummy tok ens in corresponding (pure) SDF representations.
Reference: [12] <author> R. Lauwereins, M. Engels, J. A. Peperstraete, E. Steegmans, and J. Van Ginderdeuren, </author> <title> GRAPE: A CASE Tool for Digital Signal Parallel Processing, </title> <journal> IEEE ASSP Ma gazine, vol.7, </journal> <volume> (no.2):32-43, </volume> <month> April, </month> <year> 1990. </year>
Reference-contexts: 1: Introduction Rapid prototyping en vironments such as those described in [6], <ref> [12] </ref>, [19], and [18] support code-generation for programmable digital signal processors (PDSP) used in embedded systems. T raditionally, PDSPs have been programmed manually, in assembly language, and this is a tedious, error-prone process at best. Hence, generating code automatically is a desirable goal. <p> Note that this model of b uffering maintaining a separate memory buffer for each data ow arc is convenient and natural for code generation, and it is the model used, for example, in the SDF-based code generation described in [6], <ref> [12] </ref>, [19]. More technical adv antages of this buffering model are elaborated on in [17]. There are tw o natural angles for approaching the problem of joint minimization of code size and b uffer memory requirements.
Reference: [13] <author> E. A. Lee and T. M. Parks, </author> <title> Dataflow Process Networks, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> Vol. 83, No. 5, </volume> <month> May, </month> <year> 1995. </year>
Reference: [14] <author> E. A. Lee, W. H. Ho, E. Goei, J. Bier , and S. S. Bhattacharyya, Gabriel: </author> <title> A Design Environment for DSP, </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, vol.37, </journal> <volume> (no.11):1751-62, </volume> <month> November, </month> <year> 1989. </year>
Reference: [15] <author> E. A. Lee and D. G. Messerschmitt, </author> <title> Static Scheduling of Synchronous Dataflow Programs for Digital Signal Processing, </title> <journal> IEEE Transactions on Computers, vol.C-36, </journal> <volume> (no.1):24-35, </volume> <month> January, </month> <year> 1987. </year>
Reference-contexts: An alternative is to use a block diagram language based on a model of computation with strong formal properties such as synchronous dataow (SDF) <ref> [15] </ref> to specify the system, and to do code-generation starting from this specif ication. <p> SDF <ref> [15] </ref> is a special case of dataf low. <p> The resulting sequence of code blocks is encapsulated within an inf inite loop to generate a softw are implementation of the SDF graph. SDF graphs for which valid schedules exist are called consistent SDF graphs. In <ref> [15] </ref>, efficient algorithms are presented to determine whether or not a gi ven SDF graph is consistent, and to determine the minimum number of times that each actor must be fired in a valid schedule.
Reference: [16] <author> D. R. OHallaron, </author> <title> The Assign Parallel Program Generator, </title> <institution> Memorandum CMU-CS-91-141, School of Computer Science, Carnegie Mellon University, </institution> <month> May, </month> <year> 1991. </year>
Reference: [17] <author> P. K. Murthy, S. S. Bhattacharyya, and E. A. Lee, </author> <title> Combined Code and Data Minimization for Synchronous Dataf low Programs, to appear, Journal of Formal Methods in System Design, </title> <month> July </month> <year> 1997. </year>
Reference-contexts: More technical adv antages of this buffering model are elaborated on in <ref> [17] </ref>. There are tw o natural angles for approaching the problem of joint minimization of code size and b uffer memory requirements. <p> In this section, we assume that the SDF graph is acyclic; the non-acyclic case will be dealt with later. It was shown in <ref> [17] </ref> that the b uffer-memory minimization problem is NP-complete, even for arbitrary, acyclic homogenous 1 SDF graphs. Hence, heuristic techniques have to be used. <p> The f lat schedule corresponding to the topological sort , when nested optimally, gives the schedule , with a buffer memory requirement of 120. The postprocessing step can be accomplished optimally by using a dynamic programming algorithm <ref> [17] </ref>. The running time of this algorithm on sparse SDF graphs is , where is the set of vertices. <p> A constraint that the partition be f airly evenly sized is also imposed. This is to increase the possibility of ha ving gcds that are greater than unity for the repetitions of the actors in the subsets produced by the partition, thus reducing the buffer memory requirement <ref> [17] </ref>. Suppose that is a connected, consistent SDF graph. A cut of is a partition of the actor set into two disjoint sets and . <p> The weight of the cut is the total weight of all the edges crossing the cut. The problem then is to f ind the minimum weight legal cut into bounded sets for the graph. This problem is believed to be NP-complete, although a proof has not been disco vered <ref> [17] </ref>. Kernighan and Lin [10] devised a heuristic procedure for computing cuts into bounded sets but they considered only undirected graphs. Methods based on network flows [7] do not w ork because the minimum cut given by the max-flow-min-cut theorem may not be legal and may not be bounded [17]. <p> vered <ref> [17] </ref>. Kernighan and Lin [10] devised a heuristic procedure for computing cuts into bounded sets but they considered only undirected graphs. Methods based on network flows [7] do not w ork because the minimum cut given by the max-flow-min-cut theorem may not be legal and may not be bounded [17]. Hence, a heuristic solution is needed for finding legal minimum cuts into bounded sets. <p> It can be shown that the running time of RPMC for sparse SDF graphs, including post-optimization by DPPO, is <ref> [17] </ref>. 7.4 Non-acyclic SDF graphs The above algorithms work on acyclic SDF graphs, and thus are suitable for use as the ac yclic scheduling component in the scheduling framework described in Sec- tion 6. <p> It is interesting to note that on nonuniform filterbank structures, the BMLB cannot be achieved, and on such structures, RPMC gi ves better schedules than APGAN. RPMC outperforms APGAN by almost 2 to 1 on random SDF graphs. Details of this study can be found in <ref> [2, 17] </ref>. 8: Alternative Approaches for Scheduling SDF Graphs The techniques in this paper focus on compiling SDF graphs to minimize the code size and data memory size.
Reference: [18] <author> J. Pino, S. Ha, E. A. Lee, and J. T. Buck, </author> <title> Software Synthesis for DSP Using Ptolemy, invited paper in Journal of VLSI Signal Processing, </title> <month> January, </month> <year> 1995. </year>
Reference-contexts: 1: Introduction Rapid prototyping en vironments such as those described in [6], [12], [19], and <ref> [18] </ref> support code-generation for programmable digital signal processors (PDSP) used in embedded systems. T raditionally, PDSPs have been programmed manually, in assembly language, and this is a tedious, error-prone process at best. Hence, generating code automatically is a desirable goal.
Reference: [19] <author> S. Ritz, S. Pankert, and H. Meyr, </author> <title> High Level Software Synthesis for Signal Processing Systems, </title> <booktitle> Proceedings of the International Conference on Application Specific Array Processors, Berkeley, </booktitle> <pages> pp. 679-93, </pages> <month> August, </month> <year> 1992. </year>
Reference-contexts: 1: Introduction Rapid prototyping en vironments such as those described in [6], [12], <ref> [19] </ref>, and [18] support code-generation for programmable digital signal processors (PDSP) used in embedded systems. T raditionally, PDSPs have been programmed manually, in assembly language, and this is a tedious, error-prone process at best. Hence, generating code automatically is a desirable goal. <p> Note that this model of b uffering maintaining a separate memory buffer for each data ow arc is convenient and natural for code generation, and it is the model used, for example, in the SDF-based code generation described in [6], [12], <ref> [19] </ref>. More technical adv antages of this buffering model are elaborated on in [17]. There are tw o natural angles for approaching the problem of joint minimization of code size and b uffer memory requirements.
Reference: [20] <author> S. Ritz, S. Pankert, and H. Meyr, </author> <title> Optimum Vectorization of Scalable Synchronous Dataflow Graphs, </title> <type> Technical Report IS2/ DSP93.1a, </type> <institution> Aachen University of Technology, Germany, </institution> <month> January, </month> <year> 1993. </year>
Reference: [21] <author> M. Veiga, J. Parera, and J. Santos, </author> <title> Programming DSP Systems on Multiprocessor Architectures, </title> <booktitle> Proceedings of the International Conference on Acoustics, Speec h, and Signal Processing, Albuquerque, </booktitle> <pages> pp. 965-8 vol.2, </pages> <month> April, </month> <year> 1990. </year>
Reference: [22] <author> M. E. Wolf and M. S. Lam, </author> <title> A Data Locality Optimizing Algorithm, </title> <booktitle> ACM Conference on Programming Language Design and Implementation, </booktitle> <address> San Francisco, California, </address> <month> June, </month> <year> 1991. </year>
Reference-contexts: Loop distribution and loop fusion [23] can be used to improve data locality for looped schedules of SDF graphs. Also, the use of iteration space tiling, as discussed in <ref> [22, 23] </ref>, can be used to impro ve locality for code synthesized for a looped schedule of an SDF graph. Ho wever, each loop transformation and schedule rearrangement applies to a localized section of the tar get code.
Reference: [23] <author> M. Wolfe, </author> <title> Optimizing Supercompilers for Supercomputers, </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: We would like to detect the opportunity to construct multiple in vocations of the same f iring sequence, and we wish to group these in vocations successively in time so that the y form successive iterations of a single loop. Loop distribution and loop fusion <ref> [23] </ref> can be used to improve data locality for looped schedules of SDF graphs. Also, the use of iteration space tiling, as discussed in [22, 23], can be used to impro ve locality for code synthesized for a looped schedule of an SDF graph. <p> Loop distribution and loop fusion [23] can be used to improve data locality for looped schedules of SDF graphs. Also, the use of iteration space tiling, as discussed in <ref> [22, 23] </ref>, can be used to impro ve locality for code synthesized for a looped schedule of an SDF graph. Ho wever, each loop transformation and schedule rearrangement applies to a localized section of the tar get code.
Reference: [24] <author> H. Zima and B. Chapman, </author> <title> Supercompilers for Parallel and Vector Computers, </title> <publisher> ACM Press, </publisher> <year> 1990. </year>
Reference: [25] <author> V. Zivojnovic, H. Schraut, M. Willems, and R. Schoenen, </author> <title> DSPs, GPPs, and Multimedia Applications An Ev aluation Using DSPStone, </title> <booktitle> Proceedings of ICSPAT, </booktitle> <month> November, </month> <year> 1995. </year>
Reference-contexts: One approach to automatic code generation is to specify the program in an imperative language such as C, C++, or FOR TRAN and use a good compiler. However, even the best compilers today produce inefficient code <ref> [25] </ref>. In addition, specifications in imperative languages are difficult to parallelize, are difficult to change due to side ef fects, and offer few chances for any formal verification of program properties.
References-found: 25

