URL: http://www.bell-labs.com/user/seung/papers/pattern.ps.gz
Refering-URL: http://www.ph.tn.tudelft.nl/PRInfo/reports/msg00428.html
Root-URL: 
Email: seung@bell-labs.com  
Title: Pattern analysis and synthesis in attractor neural networks  
Author: H. Sebastian Seung 
Date: October, 1997  
Address: Murray Hill, NJ 07974 USA  
Affiliation: Bell Laboratories Lucent Technologies  
Abstract: The representation of hidden variable models by attractor neural networks is studied. Memories are stored in a dynamical attractor that is a continuous manifold of fixed points, as illustrated by linear and nonlinear networks with hidden neurons. Pattern analysis and synthesis are forms of pattern completion by recall of a stored memory. Analysis and synthesis in the linear network are performed by bottom-up and top-down connections. In the nonlinear network, the analysis computation additionally requires rectification nonlinearity and inner product inhibition between hidden neurons. One popular approach to sensory processing is based on generative models, which assume that sensory input patterns are synthesized from some underlying hidden variables. For example, the sounds of speech can be synthesized from a sequence of phonemes, and images of a face can be synthesized from pose and lighting variables. Hidden variables are useful because they constitute a simpler representation of the variables that are visible in the sensory input. Using a generative model for sensory processing requires a method of pattern analysis. Given a sensory input pattern, analysis is the recovery of the hidden variables from which it was synthesized. In other words, analysis and synthesis are inverses of each other. There are a number of approaches to pattern analysis. In analysis-by-synthesis, the synthetic model is embedded inside a negative feedback loop[1]. Another approach is to construct a separate analysis model[2]. This paper explores a third approach, in which visible-hidden pairs are embedded as attractive fixed points, or attractors, in the state space of a recurrent neural network. The attractors can be regarded as memories stored in the network, and analysis and synthesis as forms of pattern completion by recall of a memory. The approach is illustrated with linear and nonlinear network architectures. In both networks, the synthetic model is linear, as in principal 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.-H. Oh and H. S. Seung. </author> <title> Learning generative models with the up-propagation algorithm. </title> <journal> Adv. Neural Info. Proc. Syst., </journal> <volume> 10, </volume> <year> 1998. </year>
Reference: [2] <author> G. E. Hinton, P. Dayan, B. J. Frey, and R. M. Neal. </author> <title> The "wake-sleep" algorithm for unsupervised neural networks. </title> <journal> Science, </journal> <volume> 268 </volume> <pages> 1158-1161, </pages> <year> 1995. </year>
Reference: [3] <author> D. D. Lee and H. S. Seung. </author> <title> Unsupervised learning by convex and conic coding. </title> <journal> Adv. Neural Info. Proc. Syst., </journal> <volume> 9, </volume> <year> 1997. </year>
Reference-contexts: The problem of learning continuous attractors from examples is discussed elsewhere [5]. The linear network is suitable for learning PCA and its variants. The nonlinear network is suitable for the Conic algorithm, in which the hidden variables are constrained to be nonnegative <ref> [3] </ref>. 7 Acknowledgments I am indebted to Dan Lee for extensive discussions on all the topics in this paper. I have also benefited from discussions with L. Saul.
Reference: [4] <author> J. J. </author> <title> Hopfield. Neural networks and physical systems with emergent collective computational abilities. </title> <booktitle> Proc. </booktitle> <institution> Nat. Acad. Sci. USA, </institution> <month> 79 </month> <pages> 2554-2558, </pages> <year> 1982. </year>
Reference: [5] <author> H. S. Seung. </author> <title> Learning continuous attractors in recurrent networks. </title> <journal> Adv. Neural Info. Proc. Syst., </journal> <volume> 10, </volume> <year> 1998. </year>
Reference-contexts: In the nonlinear network, it involves lateral inhibitory feedback, in addition to bottom-up input. This paper has focused on the problem of representing hidden variable models as attractor neural networks. The problem of learning continuous attractors from examples is discussed elsewhere <ref> [5] </ref>. The linear network is suitable for learning PCA and its variants. The nonlinear network is suitable for the Conic algorithm, in which the hidden variables are constrained to be nonnegative [3]. 7 Acknowledgments I am indebted to Dan Lee for extensive discussions on all the topics in this paper.
Reference: [6] <author> H. S. Seung. </author> <title> How the brain keeps the eyes still. </title> <booktitle> Proc. </booktitle> <institution> Natl. Acad. Sci. USA, </institution> <month> 93 </month> <pages> 13339-13344, </pages> <year> 1996. </year>
Reference: [7] <author> R. Ben-Yishai, R. L. Bar-Or, and H. Sompolinsky. </author> <title> Theory of orientation tuning in visual cortex. </title> <booktitle> Proc. </booktitle> <institution> Nat. Acad. Sci. USA, </institution> <month> 92 </month> <pages> 3844-3848, </pages> <year> 1995. </year>
Reference-contexts: So saturation nonlinearity may not be so important for normal brain function, which is one reason why rectification nonlinearity was used in (8) instead of the conventional sigmoid. The intensity invariance seen here is related to the contrast invariance exhibited by recent models of visual cortex <ref> [7] </ref>. As will be explained in detail elsewhere, proportional response is a general property of neural networks with rectification nonlinearity, as long as the neurons lack fixed thresholds. 5 Conclusion Two networks, linear and nonlinear, have illustrated the use of hidden variables in attractor neural networks.
Reference: [8] <author> S. Amari and M. A. Arbib. </author> <booktitle> Competition and cooperation in neural nets, </booktitle> <pages> pages 119-165. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: The graded inhibition mediates competitive interactions, but still allows more than one hidden neuron to be active. This is in contrast to global inhibition, which is uniform in strength. Global inhibition causes so much competition between neurons that winner-take-all behavior tends to result <ref> [8] </ref>, in which just one neuron is active and all the rest are silent. This is a localized representation, quite different from the distributed representation needed in feature decomposition. In topographic feature maps, the lateral interactions are excitatory at short-range, inhibitory at long-range, and eventually vanish at large distances [9].
Reference: [9] <author> T. Kohonen. </author> <title> The self-organizing map. </title> <journal> Proc. IEEE, </journal> <volume> 78 </volume> <pages> 1464-1480, </pages> <year> 1990. </year>
Reference-contexts: This is a localized representation, quite different from the distributed representation needed in feature decomposition. In topographic feature maps, the lateral interactions are excitatory at short-range, inhibitory at long-range, and eventually vanish at large distances <ref> [9] </ref>. Since neurons with similar features are found close together in the map, the gradation of lateral interactions correlates with feature similarity. However, inner product inhibition has a clearer computational interpretation in terms of the cost function (12). Competitive interactions between hidden variables also arise in probabilistic reasoning [10].
Reference: [10] <author> G. E. Hinton and Z. Ghahramani. </author> <title> Generative models for discovering sparse distributed representations. </title> <journal> Phil. Trans. Roy. Soc., </journal> <volume> B352:1177-1190, </volume> <year> 1997. </year> <month> 8 </month>
Reference-contexts: Since neurons with similar features are found close together in the map, the gradation of lateral interactions correlates with feature similarity. However, inner product inhibition has a clearer computational interpretation in terms of the cost function (12). Competitive interactions between hidden variables also arise in probabilistic reasoning <ref> [10] </ref>. Since hidden variables are "hidden causes" of the visible variables, they have an inhibitory influence on each other. If one cause adequately explains the data, then there is no need to invoke another cause.
References-found: 10

