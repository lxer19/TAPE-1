URL: ftp://ftp.cim.mcgill.ca/pub/techrep/1996/CIM-96-09.ps.gz
Refering-URL: ftp://ftp.cim.mcgill.ca/pub/techrep/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: MONOCULAR OPTICAL FLOW FOR REAL-TIME VISION SYSTEMS  
Author: Stephen M. Benoit and Frank P. Ferrie 
Note: Submitted to 14th International Conf. on Pattern Recognition,  
Address: Montreal, Quebec, Canada  Address: 3480 University Street, Montreal, Quebec, Canada H3A 2A7  
Affiliation: Artificial Perception Laboratory Centre for Intelligent Machines McGill University  Postal  
Pubnum: TR-CIM-96-09  
Email: Email: cim@cim.mcgill.ca  
Phone: Telephone: (514) 398-6319 Telex: 05 268510 FAX: (514) 398-7348  
Date: October 1996  Feb. 1996  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. Allman and S. Zucker. </author> <title> Cytochrome oxidase and functional coding in primate striate cortex: An hypothesis. </title> <booktitle> Cold Spring Harbor Symp. Quant. Biology, </booktitle> <volume> 55 </volume> <pages> 979-982, </pages> <year> 1990. </year> <title> 16 MONOCULAR OPTICAL FLOW FOR REAL-TIME VISION SYSTEMS (a) the image sequence is shown in (a). The magnitude of the flow field is rendered in (b) as a relief map. Note how the physical edges of the cube are present in the relief map. 17 MONOCULAR OPTICAL FLOW FOR REAL-TIME VISION SYSTEMS field between frames 19 and 20. </title>
Reference-contexts: For the purposes of this paper, we will consider the optical flow field to be a coarse field of image point correspondences between the two sequential images. Our algorithm makes use of the suggested organization of scalar and geometric tasks in the hypercolumns of the primate visual cortex <ref> [1] </ref>. Image correspondences are performed by specialized clusters of scalar intensity-processing hypercolumns, but these hypercolumns are surrounded by orientation-detecting, or flow geometry hypercolumns.
Reference: [2] <author> P. Anandan. </author> <title> Measuring Visual Motion from Image Sequences. </title> <type> PhD thesis, </type> <institution> Univ. of Mas-sachusetts, </institution> <address> Amherst, MA, </address> <year> 1987. </year> <type> COINS TR 87-21. </type>
Reference: [3] <author> P. Anandan. </author> <title> A computational framework and an algorithm for the measurement of visual motion. </title> <journal> International Journal of Computer Vision, </journal> (2):283-310, 1989. 
Reference: [4] <author> J. L. Barron, D. J. Fleet, and S. S. Beauchemin. </author> <title> Performance of optical flow techniques. </title> <type> Technical report, </type> <institution> Robotics and Perception Laboratory, Department of Computing and Information Science, Queen's University, Kingston, </institution> <address> Ontario, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Translating Sinusoids. This data set was obtained from the Barron et al. archive, and consists of the superposition of sinusoids. Error here is reported using the same error metric as reported in <ref> [4] </ref> and [5], namely the angular deviation from the correct flow direction. <p> Results of Sinusoid1 test data. Experimental results for Anandan and Singh are taken from <ref> [4] </ref> and [5]. class of input can be explained by the flow field consistency enforcement. The local information provided by region matching is propagated to neighbors who improve their estimates with the new information. With weighted averaging of neighbors, non-integer displacements can be obtained despite the integer-based region-matching. 4.2. <p> With weighted averaging of neighbors, non-integer displacements can be obtained despite the integer-based region-matching. 4.2. Yosemite Fly-Through Sequence. The Yosemite sequence, created by Lynn Quam, was chosen as a complex text case with a range of velocities, occluding edges and severe aliasing <ref> [4] </ref>. A frame of the sequence and the measured flow field for our algorithm is shown with the results from Anandan and Singh in Figure 5. This experiment used a grid size of 80 fi 60 tiles, each tile consisting of 8 fi 8 pixels. <p> Results of Yosemite test data. Mean and standard deviation experimental results for Anandan and Singh are taken from [5], while the low angular error distribution were obtained from <ref> [4] </ref>. 11 MONOCULAR OPTICAL FLOW FOR REAL-TIME VISION SYSTEMS image (a) (b) (c) for Anandan's algorithm is shown in (a). Singh's algorithm produced the flow field shown in (b). Both plots were obtained from [4]. Our results were resampled and are shown in a similar format in (c). <p> Anandan and Singh are taken from [5], while the low angular error distribution were obtained from <ref> [4] </ref>. 11 MONOCULAR OPTICAL FLOW FOR REAL-TIME VISION SYSTEMS image (a) (b) (c) for Anandan's algorithm is shown in (a). Singh's algorithm produced the flow field shown in (b). Both plots were obtained from [4]. Our results were resampled and are shown in a similar format in (c). The correct flow field can be obtained from [5], but the measured flow field is shown in Figure 5. Note that our algorithm is competitive with the algorithms of Anandan and Singh.
Reference: [5] <author> J. L. Barron, D. J. Fleet, and S. S. Beauchemin. </author> <title> Performance of optical flow techniques. </title> <journal> International Journal of Computer Vision, </journal> <volume> 12(1) </volume> <pages> 43-77, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: Experimental results presented in Section 4 demonstrate the performance of the algorithm on both synthetic and real data using some of the well-known data sets cited in the literature <ref> [5] </ref>, and show that it it comparable to some of the best results obtained. The paper concludes in Section 5 with some final observations and pointers to future work. 2. <p> To borrow from their terminology, a region-based matching algorithm defines the velocity ~v as the shift d that yields the best fit between image regions at different times <ref> [5] </ref>. <p> Translating Sinusoids. This data set was obtained from the Barron et al. archive, and consists of the superposition of sinusoids. Error here is reported using the same error metric as reported in [4] and <ref> [5] </ref>, namely the angular deviation from the correct flow direction. <p> Results of Sinusoid1 test data. Experimental results for Anandan and Singh are taken from [4] and <ref> [5] </ref>. class of input can be explained by the flow field consistency enforcement. The local information provided by region matching is propagated to neighbors who improve their estimates with the new information. With weighted averaging of neighbors, non-integer displacements can be obtained despite the integer-based region-matching. 4.2. Yosemite Fly-Through Sequence. <p> Results of Yosemite test data. Mean and standard deviation experimental results for Anandan and Singh are taken from <ref> [5] </ref>, while the low angular error distribution were obtained from [4]. 11 MONOCULAR OPTICAL FLOW FOR REAL-TIME VISION SYSTEMS image (a) (b) (c) for Anandan's algorithm is shown in (a). Singh's algorithm produced the flow field shown in (b). Both plots were obtained from [4]. <p> Singh's algorithm produced the flow field shown in (b). Both plots were obtained from [4]. Our results were resampled and are shown in a similar format in (c). The correct flow field can be obtained from <ref> [5] </ref>, but the measured flow field is shown in Figure 5. Note that our algorithm is competitive with the algorithms of Anandan and Singh. <p> The flow field by Singh is shown in (b). Both of these diagrams appear in Barron et al. <ref> [5] </ref>. Our results were resampled and are shown in a similar format in (c). 4.5. Hand-held target. This scene is typical of the events we wish to measure. <p> The flow field by Singh is shown in (b). Both of these diagrams appear in Barron et al. <ref> [5] </ref>. Our results were resampled and are shown in a similar format in (c). 5.
Reference: [6] <author> P. Parent and S. Zucker. </author> <title> Curvature consistency and curve detection. </title> <journal> J. Opt. Soc. Amer., Ser. A, </journal> <volume> 2(13), </volume> <year> 1985. </year>
Reference-contexts: Flow field consistency is the behaviour of a flow field that obeys the constraints suggested by psychophysical experiments in motion 7 MONOCULAR OPTICAL FLOW FOR REAL-TIME VISION SYSTEMS perception. For example, texture flow fields are improved when the measurement process includes a texture flow curvature consistency constraint <ref> [6] </ref>. The issue of how to measure or enforce optical flow field consistency now deserves attention. Applying curvature consistency would probably improve the optical flow field, but due to the coarse sampling of tile alignments and equally coarse directional encoding, a linear flow consistency is more appropriate.
Reference: [7] <author> A. Singh. </author> <title> An estimation-theoretic framework for image-flow computation. </title> <booktitle> In Proceedings of ICCV, </booktitle> <pages> pages 168-177. </pages> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference: [8] <author> A. Singh. </author> <title> Optic flow computation: a unified perspective. </title> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference: [9] <author> P. Singh, A. amd Allen. </author> <title> Image -flow computation: An estimation-theoretic framework and a unified perspective. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 56 </volume> <pages> 152-177, </pages> <year> 1992. </year>
Reference-contexts: Integrating Region Matching and Flow Field Consistency. Singh and Allen proposed a novel framework to unify many contemporary optical flow algorithms that could take directional errors into account for later processing <ref> [9] </ref>. A key notion that is used in this paper is how velocity must be propagated from "regions of full information, such as corners, to regions of partial or no information." [9] They propose the conceptual separation of the region matching and flow diffusion stages in order to evaluate the constraints, <p> novel framework to unify many contemporary optical flow algorithms that could take directional errors into account for later processing <ref> [9] </ref>. A key notion that is used in this paper is how velocity must be propagated from "regions of full information, such as corners, to regions of partial or no information." [9] They propose the conceptual separation of the region matching and flow diffusion stages in order to evaluate the constraints, but combine the two operations into one minimization step.
Reference: [10] <author> H. Yeshurun. </author> <title> Size limits on stereo and motion perception: Back to the hypercolumn? Lecture, </title> <month> October </month> <year> 1995. </year> <note> E-mail address: fbenoits,ferrieg@cim.mcgill.ca 18 </note>
Reference-contexts: We suggest that the flow geometry, computed from the image correspondences, feeds back to steer the image correspondences. We also adhere to the observation of Yeshurun <ref> [10] </ref>, that the useful output of the biological optical flow processing is very sparse compared to the input visual field density. An overview of our algorithm is presented in the block diagram of Figure 1.
References-found: 10

