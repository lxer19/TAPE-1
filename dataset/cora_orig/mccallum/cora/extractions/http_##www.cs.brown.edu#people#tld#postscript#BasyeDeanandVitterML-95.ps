URL: http://www.cs.brown.edu/people/tld/postscript/BasyeDeanandVitterML-95.ps
Refering-URL: http://www.cs.brown.edu/people/tld/
Root-URL: 
Title: Coping With Uncertainty in Map Learning  
Author: Kenneth Basye Thomas Dean Jeffrey Scott Vitter 
Note: This work was supported in part by a National Science Foundation Presidential Young Investigator Award CCR-8846714 with matching funds from IBM, by National Science Foundation research grant CCR-8403613, and by ONR grant N00014-83-K-0146, ARPA Order No. 4786.  
Address: Box 1910, Providence, RI 02912  
Affiliation: Department of Computer Science, Brown University  
Abstract: In many applications in mobile robotics, it is important for a robot to explore its environment in order to construct a representation of space useful for guiding movement. We refer to such a representation as a map, and the process of constructing a map from a set of measurements as map learning. In this paper, we develop a framework for describing map-learning problems in which the measurements taken by the robot are subject to known errors. We investigate approaches to learning maps under such conditions based on Valiant's probably approximately correct learning model. We focus on the problem of coping with accumulated error in combining local measurements to make global inferences. In one approach, the effects of accumulated error are eliminated by the use of local sensing methods that never mislead but occasionally fail to produce an answer. In another approach, the effects of accumulated error are reduced to acceptable levels by repeated exploration of the area to be learned. We also suggest some insights into why certain existing techniques for map learning perform as well as they do. The learning problems explored in this paper are quite different from most of the classification and boolean-function learning problems appearing in the literature. The methods described, while specific to map learning, suggest directions to take in tackling other learning problems. fl This work was supported in part by a National Science Foundation Presidential Young Investigator Award IRI-8957601 with matching funds from IBM, and by the Advanced Research Projects Agency of the Department of Defense and was monitored by the Air Force Office of Scientific Research under Contract No. F49620-88-C-0132. 
Abstract-found: 1
Intro-found: 1
Reference: [ Aleliunas et al., 1979 ] <author> Aleliunas, Romas; Karp, Richard M.; Lipton, Richard J.; Lovasz, Laszlo; and Rackoff, </author> <title> Charles 1979. Random walks, universal traversal sequences, and the complexity of maze problems. </title> <booktitle> In Proceedings of the 20th Symposium on the Foundations of Computer Science. </booktitle> <pages> 218-223. </pages>
Reference-contexts: Other properties may include regularity or bounded degree. In what follows, we will always assume that the graphs induced are connected and undirected; any other properties will be explicitly noted. Following <ref> [ Aleliunas et al., 1979 ] </ref> , a graph model consists of a graph, G = (V; E), a set L of labels, and a labeling, : fV fi Eg ! L, where we may assume that L has a null element ? which is the label of any pair (v <p> Proof: We rely on a result due to Aleliunas, et al. <ref> [ Aleliunas et al., 1979 ] </ref> that establishes that the expected number of steps for an unbiased random walk to traverse every undirected edge in E is less than or equal to 2djV j (jV j 1).
Reference: [ Basye and Dean, 1989 ] <author> Basye, Kenneth and Dean, </author> <title> Thomas 1989. Map learning with indistinguishable locations. </title> <booktitle> In Proceedings of the Fifth Workshop on Uncertainty in AI. </booktitle> <pages> 7-13. </pages>
Reference-contexts: In this case, the graph can be reliably navigated by the same agent that did the map learning. We note that the purpose of either certainty requirement is to allow the robot to filter out paths reported by sensors that aren't really in the graph. In <ref> [ Basye and Dean, 1989 ] </ref> , we treat the problem of map learning given a probabilistic oracle which, for any given traversal, provides an answer to the question "was that traversal free of error" which is correct with probability greater than f rac12.
Reference: [ Brooks, 1984 ] <author> Brooks, Rodney A. </author> <year> 1984. </year> <title> Aspects of mobile robot visual map making. </title> <editor> In Hanafusa, H. and Inoue, H., editors 1984, </editor> <booktitle> Second International Symposium on Robotics Research, </booktitle> <address> Cambridge, Massachusetts. </address> <publisher> MIT Press. </publisher> <pages> 325-331. </pages>
Reference: [ Davis, 1986 ] <author> Davis, </author> <title> Ernest 1986. Representing and Acquiring Geographic Knowledge. </title> <publisher> Morgan-Kaufmann, </publisher> <address> Los Altos, California. </address>
Reference: [ Dean, 1988 ] <author> Dean, </author> <title> Thomas 1988. On the complexity of integrating spatial measurements. </title> <booktitle> In Proceedings of the SPIE Conference on Advances in Intelligent Robotic Systems. SPIE. </booktitle> <pages> 29 </pages>
Reference-contexts: In this paper, we explore a number of problems involved in constructing useful maps from measurements taken with sensors subject to known errors. In previous work <ref> [ Dean, 1988 ] </ref> , we have looked at various optimization problems related to constructing maps (e.g., construct the most accurate map consistent with a set of measurements). Even in cases involving only a single dimension, such optimization problems can turn out to be NP-hard [ Yemini, 1979 ] .
Reference: [ Dudek et al., 1988 ] <author> Dudek, Gregory; Jenkins, Michael; Milios, Evangelos; and Wilkes, David 1988. </author> <title> Robotic exploration as graph construction. </title> <type> Technical Report RBCV-TR-88-23, </type> <institution> University of Toronto. </institution>
Reference-contexts: Another way around this restriction is to allow the exploring agent to drop pebbles or beacons to remember where it has been <ref> [ Dudek et al., 1988 ] </ref> . We can make map learning somewhat easier and more realistic by assuming that the robot can do more work or take more time to get better measurements.
Reference: [ Durrant-Whyte, 1988 ] <author> Durrant-Whyte, Hugh F. </author> <year> 1988. </year> <title> Integration, Coordination and Control of Multi-Sensor Robot Systems. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, Massachusetts. </address>
Reference: [ Graham et al., 1989 ] <author> Graham, Ronald L.; Knuth, Donald E.; and Oren, </author> <title> Patashnik 1989. Concrete Mathematics. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts. </address>
Reference-contexts: Proof: This is a variation on the Coupon Collector's problem (see <ref> [ Graham et al., 1989 ] </ref> ). We consider only the traversals resulting from leaving the vertex, thus each visit to the vertex results in the traversal of one edge chosen at random. <p> (see <ref> [ Graham et al., 1989 ] </ref> ). We consider only the traversals resulting from leaving the vertex, thus each visit to the vertex results in the traversal of one edge chosen at random. The expected number of visits required for traversing all edges at least once is shown in [ Graham et al., 1989 ] to be dH d &lt; d log d + d, where H d is the value of the harmonic function at d.
Reference: [ Hoeffding, 1963 ] <author> Hoeffding, W. </author> <year> 1963. </year> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association 58 </journal> <pages> 13-30. </pages>
Reference-contexts: The quantity count (P ) is a Bernoulli distributed random variable corresponding to n trials, each with probability fl true of success; it has mean nfl true and standard deviation (nfl true (1 fl true )) 1=2 . By Hoeffding's inequality <ref> [ Hoeffding, 1963 ] </ref> we have Pr (error on P ) = Pr (count (P ) nfl true n (fl true t )) e 2n (fl true t ) 2 : Substituting fl true t ff k1 (ff 1 2 ) ff cr1 (ff 1 2 ), we find that Pr
Reference: [ Kuipers and Byun, 1988 ] <author> Kuipers, Benjamin J. and Byun, </author> <month> Yung-Tai </month> <year> 1988. </year> <title> A robust, qualitative method for robot spatial reasoning. </title> <booktitle> In Proceedings AAAI-88. AAAI. </booktitle> <pages> 774-779. </pages>
Reference-contexts: In this paper, we are concerned with strategies which, with high probability, provide local certainty. Most existing map-learning schemes exploit this sort of certainty in one way or another (see Section 4). The rehearsal strategies of Kuipers <ref> [ Kuipers and Byun, 1988 ] </ref> are one example of how a robot might plan to eliminate uncertainty. Once we have a method for eliminating uncertainty, the problem then reduces to one of planning out and executing the necessary experiments to extract certain information about the environment. <p> In this section, we consider three related approaches. Kuipers defines the notion of "place" in terms of a set of related visual events [ Kuipers, 1978 ] . This notion provides a basis for inducing graphs from measurements. In Kuipers' framework <ref> [ Kuipers and Byun, 1988 ] </ref> , locations are arranged in an unrestricted planar graph.
Reference: [ Kuipers, 1978 ] <author> Kuipers, </author> <title> Benjamin 1978. Modeling spatial knowledge. </title> <booktitle> Cognitive Science 2 </booktitle> <pages> 129-153. </pages>
Reference-contexts: In this section, we consider three related approaches. Kuipers defines the notion of "place" in terms of a set of related visual events <ref> [ Kuipers, 1978 ] </ref> . This notion provides a basis for inducing graphs from measurements. In Kuipers' framework [ Kuipers and Byun, 1988 ] , locations are arranged in an unrestricted planar graph.
Reference: [ Levitt et al., 1987 ] <author> Levitt, Tod S.; Lawton, Daryl T.; Chelberg, David M.; and Nelson, Philip C. </author> <year> 1987. </year> <title> Qualitative landmark-based path planning and following. </title> <booktitle> In Proceedings AAAI-87. AAAI. </booktitle> <pages> 689-694. </pages>
Reference-contexts: Given a procedure that is guaranteed to uniquely identify a location if it succeeds, and succeeds with high probability, we can show that a Kuipers-style map can be reliably probably almost always usefully learned using an analysis similar to that of Section 3. Levitt et al <ref> [ Levitt et al., 1987 ] </ref> describe an approach to spatial reasoning that avoids 27 multiplicative error by introducing local coordinate systems based on landmarks. Land--marks correspond to environmental features that can be acquired and, more importantly, reacquired in exploring the environment.
Reference: [ McDermott and Davis, 1982 ] <author> McDermott, Drew V. and Davis, </author> <title> Ernest 1982. Planning routes through uncertain territory. </title> <booktitle> Artificial Intelligence 22 </booktitle> <pages> 107-156. </pages>
Reference: [ Moravec and Elfes, 1985 ] <author> Moravec, H. P. and Elfes, A. </author> <year> 1985. </year> <title> High resolution maps from wide angle sonar. </title> <booktitle> In IEEE International Conference on Robotics and Automation. </booktitle> <pages> 138-145. </pages>
Reference: [ Rivest and Sloan, 1988 ] <author> Rivest, Ronald L. and Sloan, Robert 1988. </author> <title> Learning complicated concepts reliably and usefully. </title> <booktitle> In Proceedings AAAI-88. AAAI. </booktitle> <pages> 635-640. </pages>
Reference-contexts: We have found, however, that some existing models for learning are applicable to map learning. In particular, we consider forms of probabilistic learning such as probably approximately correct learning [ Valiant, 1984 ] and reliable and probably almost always useful learning <ref> [ Rivest and Sloan, 1988 ] </ref> in which the robot gathers information to ensure that it nearly always (with probability 1 ffi) can provide a probably good or guaranteed perfect path from one location to another. <p> The above approach to map learning was inspired by Rivest's model of learning <ref> [ Rivest and Sloan, 1988 ] </ref> , in which complex problems are broken down into simple subproblems that can be learned independently.
Reference: [ Smith and Cheeseman, 1986 ] <author> Smith, Randall and Cheeseman, </author> <title> Peter 1986. On the representation and estimation of spatial uncertainty. </title> <journal> The International Journal of Robotics Research 5 </journal> <pages> 56-68. </pages>
Reference: [ Valiant, 1984 ] <author> Valiant, L. G. </author> <year> 1984. </year> <title> A theory of the learnable. </title> <journal> Communications of the ACM 27 </journal> <pages> 1134-1142. 30 </pages>
Reference-contexts: We have found, however, that some existing models for learning are applicable to map learning. In particular, we consider forms of probabilistic learning such as probably approximately correct learning <ref> [ Valiant, 1984 ] </ref> and reliable and probably almost always useful learning [ Rivest and Sloan, 1988 ] in which the robot gathers information to ensure that it nearly always (with probability 1 ffi) can provide a probably good or guaranteed perfect path from one location to another.
Reference: [ Yemini, 1979 ] <author> Yemini, </author> <title> Yechiam 1979. Some theoretical aspects of position-location prob-lems. </title> <booktitle> In Proceedings of the 20th Symposium on the Foundations of Computer Science. </booktitle> <pages> 1-7. </pages>
Reference-contexts: In previous work [ Dean, 1988 ] , we have looked at various optimization problems related to constructing maps (e.g., construct the most accurate map consistent with a set of measurements). Even in cases involving only a single dimension, such optimization problems can turn out to be NP-hard <ref> [ Yemini, 1979 ] </ref> . In this paper, rather than look at problems that involve doing the best with what you have, we consider problems that involve going out and getting what you need to generate useful representations.
References-found: 18

