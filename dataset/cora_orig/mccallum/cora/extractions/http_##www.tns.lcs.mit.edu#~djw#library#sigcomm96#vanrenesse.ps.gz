URL: http://www.tns.lcs.mit.edu/~djw/library/sigcomm96/vanrenesse.ps.gz
Refering-URL: http://www.tns.lcs.mit.edu/~djw/library/sigcomm96/program.html
Root-URL: 
Email: rvr@cs.cornell.edu  
Title: Masking the Overhead of Protocol Layering  
Author: Robbert van Renesse 
Address: Ithaca, NY 14853  
Affiliation: Dept. of Computer Science Cornell University  
Abstract: Protocol layering has been advocated as a way of dealing with the complexity of computer communication. It has also been criticized for its performance overhead. In this paper, we present some insights in the design of protocols, and how these insights can be used to mask the overhead of layering, in a way similar to client caching in a file system. With our techniques, we achieve an order of magnitude improvement in end-to-end message latency in the Horus communication framework. Over an ATM network, we are able to do a round-trip message exchange, of varying levels of semantics, in about 170 seconds, using a protocol stack of four layers that were written in ML, a high-level functional language. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anindya Basu, Vineet Buch, Werner Vogels, and Thorsten von Eicken. U-Net: </author> <title> A user-level network interface for parallel and distributed computing. </title> <booktitle> In Proc. of the Fifteenth ACM Symp. on Operating Systems Principles, </booktitle> <pages> pages 40-53, </pages> <address> Copper Mountain Resort, CO, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Modern network technology supports very low latency communication. For example, the U-Net <ref> [1] </ref> interface to ATM allows for 75 second round-trip communication as long as the message is 40 bytes or smaller. For larger messages, the latency is at least twice as long. <p> We used two Sun Sparc-Station 20s, each running SunOS 4.1.3. The workstations were connected by a Fore 140 Mbit/sec ATM network. The firmware and driver used are not by Fore; instead we used the U-Net software <ref> [1] </ref>. The messages in our experiments contained 8 bytes of user data, unless noted otherwise. The raw U-Net one-way latency in this configuration is about 35 secs. U-Net provides unreliable communication, but in our experiments no message loss was detected.
Reference: [2] <author> Edoardo Biagioni. </author> <title> A structured TCP in Standard ML. </title> <booktitle> In Proc. of the '94 Symp. on Communications Architectures & Protocols, </booktitle> <pages> pages 36-45, </pages> <address> University College London, UK, </address> <month> August </month> <year> 1994. </year> <note> ACM SIGCOMM. </note>
Reference-contexts: Within our group of C aficionados, this result came as a surprise. The reason we set out to use the O'Caml version of Horus was as a reference implementation for the use of verification and documentation. Previous work over ML, such as the CMU FOX project <ref> [2] </ref> that uses New Jersey Standard ML, reports a round-trip time of 36 milliseconds over an Ethernet, a cost of a factor of 9.4 compared to the same protocol (TCP/IP) implemented in C.
Reference: [3] <author> David D. Clark and David L. Tennenhouse. </author> <title> Architectural considerations for a new generation of protocols. </title> <booktitle> In Proc. of the '90 Symp. on Communications Architectures & Protocols, </booktitle> <pages> pages 200-208, </pages> <address> Philadelphia, PA, </address> <month> September </month> <year> 1990. </year> <note> ACM SIGCOMM. </note>
Reference-contexts: The message passes through the layers, and only the state of the current layer can be inspected and updated. Without layers, the protocol implementor would be free to reorder the protocol processing arbitrarily to reduce the length of the critical path <ref> [3] </ref>. Furthermore, the processor's instruction cache is likely to be less effective if the critical path is divided over many software modules. The PA uses three approaches to deal with this.
Reference: [4] <author> Dawson R. Engler, M. Frans Kaashoek, and James O'Toole. Exokernel: </author> <title> An operating system architecture for application-level resource management. </title> <booktitle> In Proc. of the Fifteenth ACM Symp. on Operating Systems Principles, </booktitle> <pages> pages 251-266, </pages> <address> Copper Mountain Resort, CO, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: In case fields are conveniently aligned, the packet filter is optimized automatically using some customized instructions. Packet filter programs are currently interpreted. We note that in the Exokernel project, a significant performance improvement was obtained by compiling packet filter programs into machine code <ref> [4] </ref>. We intend to adopt this approach eventually. The packet filters are constructed by the layers themselves, at run-time. Each layer adds instructions to both packet filters for their particular message-specific fields. Typically, the packet filters only need be programmed once (at protocol stack initialization time).
Reference: [5] <author> Roy Friedman and Robbert van Renesse. </author> <title> Packing Messages as a Tool for Boosting the Performance of Total Ordering Protocols. </title> <type> Technical Report 94-1527, </type> <institution> Cornell University, Dept. of Computer Science, </institution> <month> July </month> <year> 1995. </year> <note> Submitted to IEEE Transactions on Networking. </note>
Reference-contexts: If not, messages will have to wait until the post-processing of every previous message completes. To reduce this overhead, the PA uses message packing <ref> [5] </ref> to deal with backlogs. After the post-processing of a send operation completes, the PA checks to see if there are messages waiting. If there are more than one, the PA will pack these messages together into a single message.
Reference: [6] <author> Van Jacobson. </author> <title> Compressing TCP/IP headers for low-speed serial links. </title> <type> RFC 1144, </type> <institution> Network Working Group, </institution> <month> February </month> <year> 1990. </year>
Reference-contexts: Currently, although not technically necessary, Gossip information is also always included, since it is usually small. However, since the Connection Identification fields never change, they are only included occasionally because they tend to be large. The idea is similar to Van Jacobson's TCP/IP header compression technique for point-to-point links <ref> [6] </ref>, but generalized for arbitrary protocols. A PA message starts out with an 8-byte header, called the Preamble (see Figure 1). The Preamble contains three fields: 1. Connection Identification Present Bit | a single bit that is set if and only if the Connection Identification is included. <p> Field Type Purpose mode IDLE, PRE, or POST state of operation predict msg header <ref> [6] </ref> all six headers disable integer predicted header disabled pre msg message message to post-process packet filter packet filter packet filter to apply backlog list of messages waiting for processing Table 3: Each Protocol Accelerator maintains two tables of this information, one for sending and one for delivery. application, network driver,
Reference: [7] <author> Jonathan S. Kay. PathIDs: </author> <title> A Mechanism for Reducing Network Software Latency. </title> <type> PhD thesis, </type> <institution> Univ. of California, </institution> <address> San Diego, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Since the Connection Identification tends to include very large identifiers, this mechanism reduces the amount of header space in the normal case significantly. For example, in Ho-rus, the connection identification typically occupies about 76 bytes. Cookies also reduce connection lookup time for delivery of messages. In <ref> [7] </ref>, a similar idea was exploited for TCP/IP over an FDDI network of DEC Alphas, and resulted in a 31% latency improvement. There is a problem with this approach.
Reference: [8] <author> Xavier Leroy. </author> <title> The Caml Special Light system release 1.10. </title> <institution> INRIA, France, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: The PA eliminates both overheads almost entirely, and has resulted in one to fl This work was supported by ARPA/ONR grant N00014-92-J-1866 three orders of magnitude of latency improvement over existing protocol implementations. For example, we are using it on an Objective Caml (O'Caml) <ref> [8] </ref> implementation of Horus [13, 12]|a software framework that supports the layering of general group communication protocols 1 . O'Caml is an object-oriented dialect of ML [9], a high-level, concise, garbage-collected language, that allows to develop complex protocols quickly and relatively error-free. <p> U-Net provides unreliable communication, but in our experiments no message loss was detected. In spite of this, we used a protocol stack that implements a basic sliding window protocol, with a window size of 16 entries, written in O'Caml <ref> [8] </ref>. For predictable results without hiccups, we triggered garbage collection after every message reception unless noted otherwise. The basic performance results are listed in Table 4. about 25 secs before the message is handed to U-Net. The message is received 35 secs later. It is delivered in another 25 secs.
Reference: [9] <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: For example, we are using it on an Objective Caml (O'Caml) [8] implementation of Horus [13, 12]|a software framework that supports the layering of general group communication protocols 1 . O'Caml is an object-oriented dialect of ML <ref> [9] </ref>, a high-level, concise, garbage-collected language, that allows to develop complex protocols quickly and relatively error-free. Furthermore, the O'Caml code is suitable for automatic verification. Unfortunately, the code is slow compared to corresponding C code.
Reference: [10] <author> Jeffrey C. Mogul, Richard F. Rashid, and Michael J. Accetta. </author> <title> The Packet Filter: An efficient mechanism for user-level network code. </title> <booktitle> In Proc. of the Eleventh ACM Symp. on Operating Systems Principles, </booktitle> <pages> pages 39-51, </pages> <address> Austin, TX, </address> <month> November </month> <year> 1987. </year>
Reference-contexts: A good example is the checksum of a message. Another example is when a message arrives out of order. To deal with these situations, the PA employs packet filters not only in the delivery path, such as done in other systems (e.g., <ref> [10] </ref>), but also in the send path. The send filter is unusual in that it can update headers. <p> As in <ref> [10] </ref>, the packet filter is a stack machine. The operations are listed in Table 2. A packet filter program is a series of such operations that operate on a message header.
Reference: [11] <author> Scott Nettles and James O'Toole. </author> <title> Real-time replication garbage collection. </title> <booktitle> In Proceedings of the ACM Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 217-226, </pages> <address> Albuquerque, New Mexico, </address> <month> June 23-25 </month> <year> 1993. </year> <journal> SIGPLAN Notices, </journal> <volume> 28(6). </volume>
Reference-contexts: Doing this, the number of garbage collections reduce dramatically (exact measurements are not available at this time). The hiccups could be eliminated entirely by developing a "real-time" garbage collector that executes in parallel with the rest of the system (see, for example, <ref> [11] </ref>). 7 Conclusion The Protocol Accelerator (PA) eliminates most of the overhead associated with layering of protocols, allowing for clean, efficient, and flexible protocol implementations. The PA achieves this using a variety of techniques, including header compression, header prediction, moving code of the critical path, and message packing.
Reference: [12] <author> Robbert Van Renesse, Kenneth P. Birman, Roy Fried-man, Mark Hayden, and David A. Karr. </author> <title> A Framework for Protocol Composition in Horus. </title> <booktitle> In Proc. of the Fourteenth ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pages 80-89, </pages> <address> Ottawa, Ontario, </address> <month> August </month> <year> 1995. </year> <note> ACM SIGOPS-SIGACT. </note>
Reference-contexts: The PA eliminates both overheads almost entirely, and has resulted in one to fl This work was supported by ARPA/ONR grant N00014-92-J-1866 three orders of magnitude of latency improvement over existing protocol implementations. For example, we are using it on an Objective Caml (O'Caml) [8] implementation of Horus <ref> [13, 12] </ref>|a software framework that supports the layering of general group communication protocols 1 . O'Caml is an object-oriented dialect of ML [9], a high-level, concise, garbage-collected language, that allows to develop complex protocols quickly and relatively error-free. Furthermore, the O'Caml code is suitable for automatic verification. <p> Nevertheless, between two SunOS user processes on two Sparc 20s connected by a 140 Mbit/sec ATM network, we achieve a roundtrip latency of 170 seconds using the PA, down from about 1.5 milliseconds in the original C version of Horus <ref> [12] </ref>. Within our group of C aficionados, this result came as a surprise. The reason we set out to use the O'Caml version of Horus was as a reference implementation for the use of verification and documentation.
Reference: [13] <author> Robbert van Renesse, Kenneth P. Birman, and Silvano Maffeis. Horus: </author> <title> A flexible group communication system. </title> <journal> Communications of the ACM, </journal> <volume> 39(4) </volume> <pages> 76-83, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: The PA eliminates both overheads almost entirely, and has resulted in one to fl This work was supported by ARPA/ONR grant N00014-92-J-1866 three orders of magnitude of latency improvement over existing protocol implementations. For example, we are using it on an Objective Caml (O'Caml) [8] implementation of Horus <ref> [13, 12] </ref>|a software framework that supports the layering of general group communication protocols 1 . O'Caml is an object-oriented dialect of ML [9], a high-level, concise, garbage-collected language, that allows to develop complex protocols quickly and relatively error-free. Furthermore, the O'Caml code is suitable for automatic verification.
References-found: 13

