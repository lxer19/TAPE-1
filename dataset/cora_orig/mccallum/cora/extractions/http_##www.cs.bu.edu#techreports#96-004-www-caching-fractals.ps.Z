URL: http://www.cs.bu.edu/techreports/96-004-www-caching-fractals.ps.Z
Refering-URL: http://cs-www.bu.edu/techreports/Home.html
Root-URL: 
Email: virgilio@cs.bu.edu  dri@dcc.ufmg.br  
Title: On the Fractal Nature of WWW and Its Application to Cache Modeling  
Author: Virglio Almeida Adriana de Oliveira Depto. de Ciencia da Computac~ao 
Address: 111 Cummington St, Boston, MA 02215  Belo Horizonte, MG 30161 Brazil  
Affiliation: Computer Science Department Boston University  Universidade Federal de Minas Gerais  
Abstract: The World Wide Web (WWW or Web) is growing rapidly on the Internet. Web users want fast response time and easy access to a enormous variety of information across the world. Thus, performance is becoming a main issue in the Web. Fractals have been used to study fluctuating phenomena in many different disciplines, from the distribution of galaxies in astronomy to complex physiological control systems. The Web is also a complex, irregular, and random system. In this paper, we look at the document reference pattern at Internet Web servers and use fractal-based models to understand aspects (e.g. caching schemes) that affect the Web performance.
Abstract-found: 1
Intro-found: 1
Reference: [ASAW95] <author> Abrams, M., Standridge, C. R., Abdulla, G., Williams, S. and Fox, E. A., </author> <title> "Caching Proxies: Limitations and Potentials", </title> <type> Technical Report TR-95-12, </type> <institution> Department of Computer Science, Virginia Polytechnic Institute and State University, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: The Hypertext Transfer Protocol (HTTP) is the primary protocol used for sharing information [BLCL94]. A Web server is a system on a network that can process HTTP requests. Thus, Web server performance is becoming increasingly important <ref> [ASAW95, BrCl94, KwMR95] </ref>. To analyze the performance of WWW servers, one must construct a model of HTTP requests that arrive at a server. Many recent studies have used simulation models to analyze cache behavior for servers and proxies [PiRe94, ASAW95]. <p> Thus, Web server performance is becoming increasingly important [ASAW95, BrCl94, KwMR95]. To analyze the performance of WWW servers, one must construct a model of HTTP requests that arrive at a server. Many recent studies have used simulation models to analyze cache behavior for servers and proxies <ref> [PiRe94, ASAW95] </ref>. Simulation models of WWW requests have largely relied on traces of actual requests to servers. Such traces are indoubtedly more accurate than mathematical models, but they also have drawbacks.
Reference: [BLCL94] <author> Berners-Lee, T., Cailliau, R., Luotoneu, A., Nielsen, H. F. and Secret, A., </author> <title> "The World Wide Web", </title> <journal> Communications of the ACM , pp 76-82, </journal> <volume> Vol. 37, No. 8, </volume> <month> August </month> <year> 1994. </year>
Reference-contexts: 1 Introduction The World Wide Web (WWW or Web) is growing rapidly on the Internet. Web users want fast response time and easy access to a enormous variety of information across the world. The Hypertext Transfer Protocol (HTTP) is the primary protocol used for sharing information <ref> [BLCL94] </ref>. A Web server is a system on a network that can process HTTP requests. Thus, Web server performance is becoming increasingly important [ASAW95, BrCl94, KwMR95]. To analyze the performance of WWW servers, one must construct a model of HTTP requests that arrive at a server.
Reference: [BCCC95] <author> Bestavros, A., Carter, R., Crovella, M., Cunha, Carlos, Heddaya, A. and Mirdad, S., </author> <title> "Application level document caching in the internet", </title> <booktitle> IEEE SDN E96: The Second International Workshop on Services in Distributed and Networked Environments, </booktitle> <address> Whistler, British Columbia, </address> <month> June </month> <year> 1995. </year>
Reference: [BrCl94] <author> Braun, H.-W. and Claffy, K., </author> <title> "Web Traffic Characterization: an Assessment of the Impact of Caching Documents from NCSA's Web Server", </title> <booktitle> Proccedings of the Second International WWW Conference, </booktitle> <address> Chicago, Illinois, </address> <month> October </month> <year> 1994, </year> <pages> pp. 1007-1027. </pages>
Reference-contexts: The Hypertext Transfer Protocol (HTTP) is the primary protocol used for sharing information [BLCL94]. A Web server is a system on a network that can process HTTP requests. Thus, Web server performance is becoming increasingly important <ref> [ASAW95, BrCl94, KwMR95] </ref>. To analyze the performance of WWW servers, one must construct a model of HTTP requests that arrive at a server. Many recent studies have used simulation models to analyze cache behavior for servers and proxies [PiRe94, ASAW95].
Reference: [CrBe95] <author> Crovella, M. E. and Bestavros, A., </author> <title> "Explaining World Wide Web Traffic Self-Similarity", </title> <institution> Technical Report TR-95-015 , Computer Science Department, Boston University, </institution> <address> Boston, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: Objects are said to be self-similar in a statistical sense, when parts of the whole fit the whole in distributions, rather than being exact copies. Hyperbolic distributions are shown to satisfy the requirements of self-similarity <ref> [CrBe95, VMHK83] </ref>. Fractals and self-similarity are intimately related. Traditional performance models based on Markov characteristics have been extensively used to analyze computer systems [Klei76, MeAD94]. Poisson distributions have been successfully used to construct performance models of computer systems [MeAD94]. <p> The authors point out that analytical results show a clear distinction between predicted performance of certain queueing models with traditional Poisson streams and the same queuing models with self-similar inputs. Recent work by Crovella and Azer <ref> [CrBe95] </ref> shows evidences that the World Wide Web traffic may be self-similar. The authors also explain that the self-similarity in a wide area network traffic stems from factors such as the underlying distribution of of WWW document sizes and user think times. <p> For instance, simple analytical models can be used to investigate new caching schemes (e.g., separate caches for text, graphics, and videos or geographical caches) that would improve performance of the Web. The work by Crovella and Azer <ref> [CrBe95, CuBC95] </ref> found evidences of self-similarity in the Web traffic. In this paper, we took a different approach. We defined a distance-based model for document references and found evidences of the fractal nature in the document reference pattern, described by logs of Web servers at NCSA and BU.
Reference: [CuBC95] <author> Cunha, C., Bestavros, A. and Crovella, M., </author> <title> "Characteristics of WWW Client-based Traces", </title> <institution> Technical Report TR-95-010 Computer Science Department, Boston University, </institution> <address> Boston, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: For instance, simple analytical models can be used to investigate new caching schemes (e.g., separate caches for text, graphics, and videos or geographical caches) that would improve performance of the Web. The work by Crovella and Azer <ref> [CrBe95, CuBC95] </ref> found evidences of self-similarity in the Web traffic. In this paper, we took a different approach. We defined a distance-based model for document references and found evidences of the fractal nature in the document reference pattern, described by logs of Web servers at NCSA and BU.
Reference: [GiWe70] <author> Gillis, J. E. and Weiss, G. H., </author> <title> "Expected Number of Distinct Sites Visited by a Random Walk With an Infinite Variance", </title> <journal> J. Math. Phys., </journal> <volume> Vol. 11, No. 4, </volume> <pages> pp. 1307-1312, </pages> <month> April </month> <year> 1970. </year>
Reference-contexts: A recurrent walk tends to stay in a neighborhood for a long time. A recurrent HTTP stream would tend to visit the same documents several times before jumping to a new neighborhood. Gillis and Weiss <ref> [GiWe70, Thie89] </ref> show that the number of lattice-cells visited as the number of total cells visited grows asymptotically toward a power function, given by: Number of unique cells = u (n) = An 1=(1) (3) where A is a constant and is the locality parameter.
Reference: [Klei76] <author> Kleinrock, </author> <title> L, Queuing Systems: Volume I, </title> <publisher> John Wiley and Sons, </publisher> <year> 1976. </year>
Reference-contexts: Hyperbolic distributions are shown to satisfy the requirements of self-similarity [CrBe95, VMHK83]. Fractals and self-similarity are intimately related. Traditional performance models based on Markov characteristics have been extensively used to analyze computer systems <ref> [Klei76, MeAD94] </ref>. Poisson distributions have been successfully used to construct performance models of computer systems [MeAD94]. The exponential distribution has been used to represent service time and interarrival time. Its memoryless property simplifies the mathematical analysis even for complex system topolo gies. <p> The exponential distribution has been used to represent service time and interarrival time. Its memoryless property simplifies the mathematical analysis even for complex system topolo gies. Most of the performance modeling studies of computers and networks have relied on the exponential assumption, because of its memoryless property <ref> [Klei76] </ref>. However, measurement data has been suggesting with increasing emphasis that new models are needed for describing distributed computing systems with more accuracy, as pointed out by Leland et al. [LTWW94]. There is little work exploring fractals and self-similarity in the context of computer systems and networks.
Reference: [KwMR95] <author> Kwan, T. T., McGrath, R. E. and Reed, D. A., </author> <title> "NCSA's World Wide Web Server: Design and Performance". </title> <journal> IEEE Computer , November 1995. </journal>
Reference-contexts: The Hypertext Transfer Protocol (HTTP) is the primary protocol used for sharing information [BLCL94]. A Web server is a system on a network that can process HTTP requests. Thus, Web server performance is becoming increasingly important <ref> [ASAW95, BrCl94, KwMR95] </ref>. To analyze the performance of WWW servers, one must construct a model of HTTP requests that arrive at a server. Many recent studies have used simulation models to analyze cache behavior for servers and proxies [PiRe94, ASAW95]. <p> In order to develop good caching strategies, one need to know the document access patterns. There are various types of documents in a Web server, such as HTML, gif, postscript, and MPLG. As pointed out in <ref> [KwMR95] </ref>, effective document caching is one of the key principles in a server architecture, allowing a WWW server to respond quickly to requests for frequently accessed documents. Our model is influenced by the Spirn's work on paging [Spir76].
Reference: [MeAD94] <author> Menasce D., Almeida V., and Dowdy L., </author> <title> Capacity Planning and Performance Modeling, </title> <publisher> Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1994. </year>
Reference-contexts: Hyperbolic distributions are shown to satisfy the requirements of self-similarity [CrBe95, VMHK83]. Fractals and self-similarity are intimately related. Traditional performance models based on Markov characteristics have been extensively used to analyze computer systems <ref> [Klei76, MeAD94] </ref>. Poisson distributions have been successfully used to construct performance models of computer systems [MeAD94]. The exponential distribution has been used to represent service time and interarrival time. Its memoryless property simplifies the mathematical analysis even for complex system topolo gies. <p> Hyperbolic distributions are shown to satisfy the requirements of self-similarity [CrBe95, VMHK83]. Fractals and self-similarity are intimately related. Traditional performance models based on Markov characteristics have been extensively used to analyze computer systems [Klei76, MeAD94]. Poisson distributions have been successfully used to construct performance models of computer systems <ref> [MeAD94] </ref>. The exponential distribution has been used to represent service time and interarrival time. Its memoryless property simplifies the mathematical analysis even for complex system topolo gies. Most of the performance modeling studies of computers and networks have relied on the exponential assumption, because of its memoryless property [Klei76].
Reference: [LTWW94] <author> Leland, W. E., Taqqu, M. S., Willinger, W. and Wilson, D. V. </author> , <title> "On the Self-Similar Nature of Ethernet Traffic (Extended Version)", </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> Vol. 2, No. 1, </volume> <month> February </month> <year> 1994. </year>
Reference-contexts: However, measurement data has been suggesting with increasing emphasis that new models are needed for describing distributed computing systems with more accuracy, as pointed out by Leland et al. <ref> [LTWW94] </ref>. There is little work exploring fractals and self-similarity in the context of computer systems and networks. <p> Recently, Peterson and Grossman [PeGr95] showed that the frequency distributions of measured parameters of disk I/O activity were observed to obey power laws indicating self-similarity over orders of magnitude of time. Based on a study on actual Ethernet traffic data, over several years, Leland et al. <ref> [LTWW94] </ref> demonstrated that Ethernet LAN traffic is statistically self-similar. They also show that none of the used traffic models is able to capture the fractal-like behavior of Ethernet LANs.
Reference: [Mand83] <author> Mandelbrot, B. B., </author> <title> The Fractal Geometry of Nature, </title> <editor> W. H. </editor> <publisher> Freedman and Co., </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: In section 5, we use logs from the WWW servers at Boston University and NCSA to validate the proposed model. A summary of our observations and comparisons with related work is provided in the conclusions. 2 The Fractal Nature of Computing and Networking As defined by Mandelbrot <ref> [Mand83] </ref>, fractal geometry is a mathematical theory conceived and developed to provide a model for irregularity and fragmentation in nature. Fractals have been used to describe spiky, irregular or variegated objects, such as coastlines, mountains, and crystals. Fractals are said to be self-similar structures. <p> Using regression, we calculated the slope of R/S plot, which yielded an estimate for the Hurst parameter of 0.78. According to Mandelbrot <ref> [Mand83] </ref>, self-similar processes exhibit a Hurst parameter value in the range (0:5; 1:0). For the purpose of comparison of the estimated H parameter with the asymptotic slopes, Figure 2 shows the R/S plot with two lines of slopes 0.5 and 1.0.
Reference: [PiRe94] <author> Pitkow, J. G., and Recker, M. M., </author> <title> "A Simple Yet Robust Caching Algorithm Based on Dynamic Access Patterns", </title> <booktitle> Proccedings of the Second International WWW Conference, </booktitle> <address> Chicago, Illinois, </address> <month> October </month> <year> 1994, </year> <pages> pp 1039-1046. </pages>
Reference-contexts: Thus, Web server performance is becoming increasingly important [ASAW95, BrCl94, KwMR95]. To analyze the performance of WWW servers, one must construct a model of HTTP requests that arrive at a server. Many recent studies have used simulation models to analyze cache behavior for servers and proxies <ref> [PiRe94, ASAW95] </ref>. Simulation models of WWW requests have largely relied on traces of actual requests to servers. Such traces are indoubtedly more accurate than mathematical models, but they also have drawbacks.
Reference: [PeGr95] <author> Peterson D. and Grossman R., </author> <title> "Power laws in large shop DASD I/O activity", </title> <booktitle> in Proceedings of CMG95 International Conference, Computer Measurement Group Inc., </booktitle> <address> Nashville, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: Thiebault also proposed and validated a simple fractal model of fully associative caches. In fact, the paper by Thiebault introduced fractal geometry to the field of computer performance evaluation and prediction. Recently, Peterson and Grossman <ref> [PeGr95] </ref> showed that the frequency distributions of measured parameters of disk I/O activity were observed to obey power laws indicating self-similarity over orders of magnitude of time.
Reference: [Spir76] <author> Spirn, J., </author> <title> "Distance String Models for Program Behavior", </title> <journal> IEEE Computer , November 1976. </journal>
Reference-contexts: As pointed out in [KwMR95], effective document caching is one of the key principles in a server architecture, allowing a WWW server to respond quickly to requests for frequently accessed documents. Our model is influenced by the Spirn's work on paging <ref> [Spir76] </ref>. The properties of program behavior in a paging environment, using a Least Recently Used (LRU) replacement policy, have been covered by Spirn. Those properties and a hyperbolic relation defined by Spirn are central to the document reference model proposed in this paper.
Reference: [Thie89] <author> Thiebaut, D., </author> <title> "On the Fractal Dimension of Computer Programs and its Application to the Prediction of the Cache Miss Ratio", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 38, </volume> <month> July </month> <year> 1989. </year>
Reference-contexts: The authors looked at memory traces of different software environments and found out that the distribution of the intermiss gaps is fractal. Thiebault <ref> [Thie89, ThWS92] </ref> noticed in several traces that the number of unique memory locations accessed by a program, as a function of the total number of memory accesses, converges toward a hyperbola, showing the fractal nature of programs. Thiebault also proposed and validated a simple fractal model of fully associative caches. <p> It is like the movement of a walker as it jumps from cell to cell <ref> [Thie89] </ref>. The walker is not constrained to only jump to a neighboring cell, but can indeed jump to a cell at any distance away. Requests would move from one document to another in a WWW server, resembling the walker movement. <p> A recurrent walk tends to stay in a neighborhood for a long time. A recurrent HTTP stream would tend to visit the same documents several times before jumping to a new neighborhood. Gillis and Weiss <ref> [GiWe70, Thie89] </ref> show that the number of lattice-cells visited as the number of total cells visited grows asymptotically toward a power function, given by: Number of unique cells = u (n) = An 1=(1) (3) where A is a constant and is the locality parameter. <p> Using equation (3) and considering a cache of size C, Thiebault <ref> [Thie89] </ref> shows that the probability of hit index of a selected document is greater than C is given by: P [hit index &gt; C] = A C 1 (4) where hit index of a document is defined by document position in the LRU document stack.
Reference: [ThWS92] <author> Thiebaut, D., Wolf, J. L. and Stone, H. S., </author> <title> "Synthetic Traces for Trace-Driven Simulation of Cache Memories ", IEEE Transactions on Computers, </title> <journal> Vol. </journal> <volume> 41, No. 4, </volume> <pages> pp. 388-410, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: The authors looked at memory traces of different software environments and found out that the distribution of the intermiss gaps is fractal. Thiebault <ref> [Thie89, ThWS92] </ref> noticed in several traces that the number of unique memory locations accessed by a program, as a function of the total number of memory accesses, converges toward a hyperbola, showing the fractal nature of programs. Thiebault also proposed and validated a simple fractal model of fully associative caches.
Reference: [VMHK83] <author> Voldman, J., Mandelbrot, B., Hoevel, L. W., Knight, J. and Rosenfeld, P. L., </author> <title> "Fractal Nature of Software-Cache Interaction", </title> <journal> IBM Journal of Research and Development, </journal> <volume> Vol. 27, No. 2, </volume> <year> 1983. </year>
Reference-contexts: Objects are said to be self-similar in a statistical sense, when parts of the whole fit the whole in distributions, rather than being exact copies. Hyperbolic distributions are shown to satisfy the requirements of self-similarity <ref> [CrBe95, VMHK83] </ref>. Fractals and self-similarity are intimately related. Traditional performance models based on Markov characteristics have been extensively used to analyze computer systems [Klei76, MeAD94]. Poisson distributions have been successfully used to construct performance models of computer systems [MeAD94]. <p> There is little work exploring fractals and self-similarity in the context of computer systems and networks. A pioneering paper is that by Voldman et al. <ref> [VMHK83] </ref>, where they noted that the interaction of software with memory hierarchies is naturally modeled by a stochastic process having a larger than usual amount of irregularity. The authors looked at memory traces of different software environments and found out that the distribution of the intermiss gaps is fractal.
References-found: 18

