URL: http://www-rali.iro.umontreal.ca/Publications/bi_textual_aids.ps
Refering-URL: http://www-rali.iro.umontreal.ca/Publications.en.html
Root-URL: http://www.iro.umontreal.ca
Email: e-mail: isabelle@citi.doc.ca  
Title: Bi-Textual Aids for Translators  
Author: Pierre Isabelle 
Address: 1575 Chomedey Blvd, Laval, Quebec, H7V 2X2  
Affiliation: CITI  
Abstract: While machine translation can successfully tackle some highly restricted sublanguages, it is in most cases more productive to turn to support tools for human translators. The functions taken over by existing translators workstations are rather peripheral with respect to the core aspects of the translation task. However, recent developments show that it is possible to automatically produce explicit (partial) representations of the translation correspondences that link pairs of source and target texts. These representations called bi-texts provide the foundation required for the design of support tools that delve deeper into the realm of translation proper, such as: a) a translation memory that can be accessed by various means, including bilingual concordancing; b) translation critiquing tools capable of detecting correspondence errors such as omissions or deceptive cognates; and c) translator-oriented speech recognition systems capable of taking advantage of correspondence contraints with respect to source texts. The outlook for translation support tools is thus highly promising. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bar-Hillel Y., </author> <title> The State of Machine Translation in 1951, </title> <journal> in American Documentation, </journal> <volume> vol. 2, </volume> <year> 1951, </year> <pages> pp. 229-237 </pages> . 
Reference-contexts: Thus, with the exception of a handful of cases, the current situation is no different from what it was back in 1951, when Bar-Hillel <ref> [1] </ref> wrote: 2 For those targets in which high accuracy is a conditio sine qua non, pure MT has to be given up in favor of mixed MT, i.e., a translation process in which a human brain inter venes.
Reference: [2] <author> Brown P., Cocke J., Della Pietra S., Della Pietra V., Jelinek F., Lafferty J., Mercer R., Roosin P., </author> <title> A Statistical Approach to Machine Translation, </title> <journal> Computational Linguistics, </journal> <volume> 16:2, </volume> <pages> 79-85, </pages> <year> 1990. </year>
Reference-contexts: Brown, Lai & Mercers sentence alignment mechanism is only the first step of a procedure aimed a estimating the parameters of the stochastic MT system described in Brown & al. <ref> [2] </ref>. In order to estimate the parameters of a probabilistic transfer dictionary for this system, they then need to make explicit the word correspondences found in their corpus of sentence pairs (a portion of the Hansard data).
Reference: [3] <author> Brown P., Lai C., Mercer R., </author> <title> Aligning Sentences in Parallel Corpora, </title> <booktitle> Proceedings of the 29th Meeting of the ACL, </booktitle> <address> Berkely, </address> <year> 1991. </year>
Reference-contexts: Crossing alignments are prohibited and many-to-many alignments are only permitted provided many does not exceed some small n. 7 Debili & Sammouda [9] propose an alignment algorithm which is different but also based on word correspondences established with the help of a bilingual dictionary. Brown, Lai & Mercer <ref> [3] </ref> and Gale & Church [12] address in a different way the same problem of aligning the sentences of parallel texts. They both propose methods which are based on the simple observation that the length of a text and the length of its translation are highly correlated.
Reference: [4] <author> Brown P., Chen S., Della Pietra S, Della Pietra V., Kehler A., Mercer R., </author> <title> Automatic Speech Recognition in Machine Aided Translation, </title> <type> unpublished ms., </type> <institution> IBM T. J. Watson Research Center, </institution> <year> 1992. </year>
Reference-contexts: Clearly, such a scheme should make the speech recognition task much more tractable. Brown & al. <ref> [4] </ref> independently arrived at the same conclusion. They report on an experiment in which they compared the per-word perplexity of an unaided target-language model with the per-word perplexity of the same target-language model once combined with a translation model.
Reference: [5] <author> Catizone R., Russell G., Warwick S., </author> <title> Deriving Translation Data from Bilingual Texts, in Zernick (ed.) Lexical Acquisition: Using on-line Resources to Build a Lexicon, </title> <publisher> Lawrence Erlbaum, </publisher> <year> 1992. </year>
Reference-contexts: One interesting feature of this approach is that it does not appeal to any evidence external to the texts themselves, such as for example a bilingual dictionary. However, Catizone & al. <ref> [5] </ref> claim that when Kay & Rscheisens method is extended so as to include the use a bilingual dictionary for guiding the initial hypotheses on word correspondences, the search space is drastically reduced. 1. Side-by-side translation layouts typically link whole paragraphs only. 2. <p> It has already been suggested by several authors that a tool capable of producing bilingual concordances would be useful to bilingual lexicographers (see Klavans & Tzoukermann [20], Catizone, Russell & Warwick <ref> [5] </ref>, Church [7]). It is rather obvious that bilingual concordancing would also be useful to translators.
Reference: [6] <author> Church K., </author> <title> A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text, </title> <booktitle> Proceedings of the 2nd ACL Conference on Applied Natural Processing, </booktitle> <address> Austin, </address> <year> 1988. </year>
Reference-contexts: In all cases, the use of a part-of-speech tagger such as the one described in Church <ref> [6] </ref> would be likely to improve precision, since the correct characterization of some deceptive cognates (whether complete or partial) requires part-of-speech information. We suspect that there are many other properties of translation correspondences which could be verified by means of bi-textual representations. 6.
Reference: [7] <author> Church K., Gale W., </author> <title> Concordances for Parallel Texts, </title> <booktitle> in Proceedings of the 7th Annual Conference the UW Centre for the NOED and Text Research, </booktitle> <address> Oxford, </address> <year> 1991. </year>
Reference-contexts: It has already been suggested by several authors that a tool capable of producing bilingual concordances would be useful to bilingual lexicographers (see Klavans & Tzoukermann [20], Catizone, Russell & Warwick [5], Church <ref> [7] </ref>). It is rather obvious that bilingual concordancing would also be useful to translators.
Reference: [8] <author> Cochard J.L., Isabelle P., Simard M., </author> <title> IRMA : an Agricultural Market Report Interpreter, </title> <type> Tech. rep. </type> <institution> no. Co28-1/49-1990E, CWARC, Laval, </institution> <year> 1990. </year>
Reference-contexts: Typical set-ups resort to one or many of the following constraints: limited vocabulary and syntax, isolated word input (as opposed to continuous speech), user-specific system training, low background noise, etc. Back in 1989, an experiment that we conducted on speech-to-speech translation (Cochard, Isabelle & Simard <ref> [8] </ref>) convinced us that current technology was not suitable for real-life applications: the input needed to be constrained in an overly artificial way.
Reference: [9] <editor> Debili F., Sammouda E., Appariement des phrases de textes bilingues franais-anglais et franais-arabes, </editor> <booktitle> Proceedings of COLING-92, </booktitle> <address> Nantes, </address> <year> 1992. </year>
Reference-contexts: Side-by-side translation layouts typically link whole paragraphs only. 2. The range of possible alignments is constrained from the start. Crossing alignments are prohibited and many-to-many alignments are only permitted provided many does not exceed some small n. 7 Debili & Sammouda <ref> [9] </ref> propose an alignment algorithm which is different but also based on word correspondences established with the help of a bilingual dictionary. Brown, Lai & Mercer [3] and Gale & Church [12] address in a different way the same problem of aligning the sentences of parallel texts.
Reference: [10] <author> Dempster A., Laird N., Rubin D., </author> <title> Maximum Likelihood from Incomplete Data via the EM Algorithm, </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> 39(B), </volume> <year> 1977. </year>
Reference-contexts: They do this by means of a particular version of the EM algorithm (Demp-ster & al. <ref> [10] </ref>), which should allow them to obtain complete coverage. However, the authors do not discuss the level of precision of their results. Gale & Church [13] introduce a method for identifying some of the word correspondences in texts that have already been aligned at the sentence level.
Reference: [11] <author> Dymetman M., Foster G., Isabelle P., </author> <title> Towards Automatic Dictation Systems for the Professional Translator, </title> <type> Technical Note, </type> <institution> CWARC, Laval, </institution> <year> 1992. </year> <month> 14 </month>
Reference-contexts: high accuracy recognition of uent speech is possible with present day speech technology when the text is constrained to be the translation of a known source language sequence. (p. 10) A project is currently underway at the CWARC to explore some aspects of this very interesting possibility (Dymetman & al. <ref> [11] </ref>). This project is closely connected with our work on bi-textuality, in that it encompasses the development of a probabilistic translation model whose parameters are extracted from a large bi-textual database. 7.
Reference: [12] <author> Gale W., Church K., </author> <title> A Program for Aligning Sentences in Bilingual Corpora, </title> <booktitle> Proceedings of the 29th Meeting of the ACL, </booktitle> <address> Berkely, </address> <year> 1991. </year>
Reference-contexts: Brown, Lai & Mercer [3] and Gale & Church <ref> [12] </ref> address in a different way the same problem of aligning the sentences of parallel texts. They both propose methods which are based on the simple observation that the length of a text and the length of its translation are highly correlated.
Reference: [13] <author> Gale W., Church K., </author> <title> Identifying Word Correspondences in Parallel Texts, </title> <booktitle> Proceedings of DARPA SLS Workshop, </booktitle> <year> 1991. </year>
Reference-contexts: They do this by means of a particular version of the EM algorithm (Demp-ster & al. [10]), which should allow them to obtain complete coverage. However, the authors do not discuss the level of precision of their results. Gale & Church <ref> [13] </ref> introduce a method for identifying some of the word correspondences in texts that have already been aligned at the sentence level. They first determine a set word pairs that are strongly associated in the sentence pairs.
Reference: [14] <author> Gale W., Church K., Yarowski D., </author> <title> Using Bilingual Materials to Develop Word Sense Disambiguation Methods, </title> <booktitle> Proceedings of the 4th International Conference on Theoretical and Methodological Issues in Machine Translation, </booktitle> <address> Montreal, </address> <year> 1992. </year>
Reference-contexts: The problem of partial deceptive cognates is of course harder. However, it seems reasonable to believe that, at least for a subset of them, the kind of probabilistic sense disambiguation methods proposed by Gale, Church & Yarowski <ref> [14] </ref> could provide a suitable discrimination mechanism. In all cases, the use of a part-of-speech tagger such as the one described in Church [6] would be likely to improve precision, since the correct characterization of some deceptive cognates (whether complete or partial) requires part-of-speech information.
Reference: [15] <author> Harris B., </author> <title> Are you Bi-Textual?, </title> <booktitle> Language Technology, </booktitle> <volume> #7, </volume> <editor> p. </editor> <volume> 41, </volume> <year> 1988. </year>
Reference-contexts: Thanks to the compositionality principle, the global correspondence between a text ST and it translation TT is normally analyzable into sets of finer correspondences between particular segments of ST and particular segments of TT. As noted by Harris <ref> [15] </ref>, the traditional side-by-side or interlinear layouts commonly used for translations do presuppose a straightforward analyzability of translational correspondences (paragraph-to-paragraph, sentence-to-sentence, etc.). <p> When asked to, any bilingual speaker will be able to 4 point out many if not all of the correspondences between the elements of a source and its translation. Harris <ref> [15] </ref>, [16] suggests the term bi-text to designate any scheme which makes such correspondences explicit.
Reference: [16] <author> Harris B., Bi-text, </author> <title> a New Concept in Translation Theory, </title> <journal> Language Monthly, </journal> <volume> #54, </volume> <pages> p. 8-10, </pages> <year> 1988. </year>
Reference-contexts: When asked to, any bilingual speaker will be able to 4 point out many if not all of the correspondences between the elements of a source and its translation. Harris [15], <ref> [16] </ref> suggests the term bi-text to designate any scheme which makes such correspondences explicit.
Reference: [17] <author> Isabelle P., </author> <title> Machine Translation at the TAUM Group, </title> <editor> in Margaret King (ed.), </editor> <booktitle> Machine Translation Today: The State of the Art, </booktitle> <publisher> Edinburgh University Press, </publisher> <year> 1987. </year>
Reference-contexts: 1. Introduction Despite several decades of massive efforts, high-quality machine translation (MT) is still only possible in the case of some very restricted sublanguages such as the one tackled by the TAUM-MTO system (Isabelle <ref> [17] </ref>). Moreover, the fact that the resounding success of this system has not been systematically cloned seems to indicate that there are very few simple sublanguages around for which there exists a significant translation volume.
Reference: [18] <author> Kay M., </author> <title> The Proper Place of Men and Machines in Translation, </title> <journal> CSL-80-11, </journal> <note> Xerox PARC, </note> <year> 1980. </year>
Reference-contexts: It is therefore only natural that most translation services consider current MT technology as useless, and that MT accounts for only a very marginal share of the translation market. There is no evidence that this situation is about to change. More than ten years ago, Martin Kay <ref> [18] </ref> proposed his translators amanuensis, which constitutes a very different answer to Bar-Hillels question about the optimal division of labor between man and machine: I want to advocate a view of the problem in which machines are gradually, almost imperceptibly, allowed to take over certain functions in the overall translation process.
Reference: [19] <author> Kay M., Rscheisen M., </author> <title> Text-Translation Alignment, </title> <journal> unpublished ms., </journal> <note> Xerox PARC, </note> <year> 1988. </year>
Reference-contexts: It was back in 1984 that I first heard Kay informally outline an algorithm which was later systematically described in Kay & Rscheisen <ref> [19] </ref>. This algorithm does not aim at discovering all correspondences, but only at producing a correct alignment at the sentence level.
Reference: [20] <author> Klavans J., Tzoukermann E., </author> <title> Linking Bilingual Corpora and Machine Readable Dictionaries with the BICORD System, </title> <booktitle> Proceedings of the 6th Annual Conference of the UW Centre for the NOED and Text Research, </booktitle> <institution> University of Waterloo, </institution> <year> 1990. </year>
Reference-contexts: It has already been suggested by several authors that a tool capable of producing bilingual concordances would be useful to bilingual lexicographers (see Klavans & Tzoukermann <ref> [20] </ref>, Catizone, Russell & Warwick [5], Church [7]). It is rather obvious that bilingual concordancing would also be useful to translators.
Reference: [21] <author> Macklovitch E., </author> <title> An Off-the-shelf Workstation for Translators, </title> <editor> dans D. Hammond (ed.) </editor> <booktitle> Proceedings of the 30th Annual Conference of the ATA, </booktitle> <address> Washington DC, </address> <month> October 11-14, </month> <year> 1989, </year> <pages> pp. 4891-498. </pages>
Reference-contexts: It is this down-to-earth approach that the Canadian Workplace Automation Research Center (CWARC) chose to pursue when it started its translators workstation project, back in 1987 (Macklovitch <ref> [21] </ref>, [22]). In its most recent incarnation, the CWARCs workstation provides the translator with a windowing environment where he/she has simultaneous access to a number of tools such as split screen word processing, spelling correction, terminology and dictionary lookup, file comparison, word counting, etc.
Reference: [22] <author> Macklovitch E., </author> <title> A Second Version of the CWARCs Workstation for Translators, </title> <type> tech. report, </type> <institution> CWARC, </institution> <year> 1991. </year>
Reference-contexts: It is this down-to-earth approach that the Canadian Workplace Automation Research Center (CWARC) chose to pursue when it started its translators workstation project, back in 1987 (Macklovitch [21], <ref> [22] </ref>). In its most recent incarnation, the CWARCs workstation provides the translator with a windowing environment where he/she has simultaneous access to a number of tools such as split screen word processing, spelling correction, terminology and dictionary lookup, file comparison, word counting, etc.
Reference: [23] <author> Macklovitch E., </author> <title> Evaluating Commercial MT Systems, paper presented at the Evaluators Forum on MT Systems, </title> <address> Ste-Croix, Switzerland, </address> <year> 1991. </year>
Reference-contexts: On the other hand, it has repeatedly been demonstrated that it is not cost-effective to resort to human post-editors to salvage the kind of low quality output that current MT systems produce in most situations (see for example Macklovitch <ref> [23] </ref>). It is therefore only natural that most translation services consider current MT technology as useless, and that MT accounts for only a very marginal share of the translation market. There is no evidence that this situation is about to change.
Reference: [24] <author> Macklovitch E., </author> <title> Corpus-Based Tools for Translators, </title> <booktitle> to appear in the Proceedings of the ? Conference of the ATA, </booktitle> <address> San Diego, </address> <year> 1992. </year>
Reference-contexts: He/she might also find out that conventional bilingual dictionaries do not provide satisfactory answers. With a bilingual concordancing tool, he/she could then search a bi-textual database in order to retrieve examples of these expressions together with their translations. See Macklovitch <ref> [24] </ref> for a more detailed discussion of this issue. Appendix A contains a screendump of the results produced by OCTA, the CWARCs prototype bilingual concordancing system, of a search for English segments containing the discontinuous sequence insult...injury in a database consisting of a sentence-level alignment of the 1986 Hansard data.
Reference: [25] <author> Sato S., Nagao M., </author> <title> Toward Memory-Based Translation, </title> <booktitle> Proceedings of COLING-90, </booktitle> <pages> 247-252, </pages> <year> 1990. </year>
Reference-contexts: There are many possible ways to exploit such a corporate memory. In a long-term perspective, some researchers have started exploring the idea that bi-textual databases would provide the foundation for memory-based or analogy-based or example-based approaches to the MT problem (see for example Sato & Nagao <ref> [25] </ref>). A less ambitious approach would be to develop systems that, during a manual translation, will automatically retrieve relevant examples in the database, and let the translator decide whether or not he/she will use them.
Reference: [26] <author> Simard M., Foster G., Isabelle P. </author> <title> Using Cognates to Align Sentences in Parallel Corpora, </title> <booktitle> Proceedings of the 4th International Conference on Theoretical and Methodological Issues in Machine Translation, </booktitle> <address> Montreal, </address> <year> 1992. </year>
Reference-contexts: However, since they do not look at the contents of the sentences that they pair, these methods appear to be less reliable and less robust. Once a length-based algorithm has accidentally misaligned two sentences, it tends to misalign the remainder of the paragraph. Simard, Foster & Isabelle <ref> [26] </ref> look at yet another criterion on which to base sentence alignments. They observe that cognateness, that is, the proportion of cognate words, is highly correlated with translation.
Reference: [27] <author> Van Roey J., Granger S., Swallow H., Dictionnaire des faux-amis franais-anglais, Paris, Duculot, </author> <year> 1988. </year> <month> 15 </month>
Reference-contexts: Tools capable of agging potential errors could therefore prove extremely useful. This notion of deceptive cognate is not perfectly well-defined. There exists some useful reference works (see for example Van Roey, Granger & Swallow <ref> [27] </ref>), but 11 their exhaustivity is doubtful. Moreover, in the case of partial deceptive cognates, the range of disallowed correspondences is often fuzzy and subject to dialectal variation. The sensible thing to do, of course, is to start with the clearer cases.
References-found: 27

