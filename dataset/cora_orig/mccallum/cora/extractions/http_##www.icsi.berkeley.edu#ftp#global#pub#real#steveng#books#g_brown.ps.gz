URL: http://www.icsi.berkeley.edu/ftp/global/pub/real/steveng/books/g_brown.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/ftp/global/pub/real/steveng/books/
Root-URL: http://www.icsi.berkeley.edu
Email: Email: -g.brown,m.cooke-@dcs.shef.ac.uk, mousset@ingenia.fr  
Title: ARE NEURAL OSCILLATIONS THE SUBSTRATE OF AUDITORY GROUPING?  
Author: Guy J. Brown Martin Cooke and Eric Mousset , 
Address: Regent Court, 211 Portobello Street, Sheffield S1 4DP, United Kingdom 2 INGENIA, 92 bis, Avenue Victor Cresson, 92130 Issy-les-Moulineaux, France  
Affiliation: 1 Department of Computer Science, University of Sheffield,  
Abstract: How are acoustic features that are extracted in remote regions of the auditory system bound together to form a perceptual whole? We consider the evidence for a solution to this so-called binding problem, which proposes that the responses of feature detecting cells are bound together by the synchronisation of oscillatory firing activity. Four models of auditory grouping based on neural oscillators are reviewed, and issues arising from these models are discussed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Abeles, M. </author> <year> (1991) </year> <month> Corticonics: </month> <title> Neural circuits of the Cerebral Cortex. </title> <publisher> Cambridge University Press. </publisher>
Reference-contexts: In order to obtain the temporal resolution required for auditory organisation, a delay-line scheme of the form proposed by Wang would involve several hundred synapses. Transmission in simple chains of neurons of this length is unlikely to be precisely timed, due to jitter in conduction time and synaptic processes <ref> [1] </ref>. Another reason for hypothesising an auditory time axis is that it allows acoustic stimuli to be treated as two-dimensional spatial patterns; this is advantageous, since the architecture of Wangs model is closely related to that of his earlier models of visual processing [27].
Reference: [2] <author> Abeles, M., Prut, Y., Bergman, H. & Vaadia, E. </author> <title> (1994) Synchronisation in neuronal transmission and its importance for information processing. </title> <booktitle> Progress in Brain Research, </booktitle> <volume> 102, </volume> <pages> 395-404. </pages>
Reference-contexts: During perception and recall, convergence zones achieve synchronisation of these features through recurrent feedback interactions. Hence, processing is distributed and does not occur in a single direction, nor does it require integration in a single area; it involves phase-locking amongst neural groups in multiple regions (see also <ref> [2] </ref>). 4.3. Evidence against the neural oscillator theory Aspects of the neural oscillator theory are controversial. In particular, it has been suggested that neural oscillations are induced by anaesthesia, and that oscillations therefore reect state of sleep rather than feature binding [14]. <p> In other words, although neural oscillations and synchronisation often occur together, they do not necessarily depend on one another. For example, it has been demonstrated that synchronous transmission in chains of neurons with diverging and converging links (so-called synfire chains) can lead to oscillations <ref> [2] </ref>. In such networks, oscillations do not occur because of periodic activation of the same cells; rather, they are due to the interaction of positive (excitatory) feedback and negative (inhibitory) feedback. Hence, oscillations may occur as a consequence of synchronisation, rather than vice versa.
Reference: [3] <author> Barlow, H. </author> <title> (1972) Single units and sensation: A neuron doctrine for perceptual psychology? Perception, </title> <booktitle> 1, </booktitle> <pages> 371-94. </pages>
Reference-contexts: The traditional solution to the binding problem invokes a hierarchy of increasingly specialised feature detecting cells. It has been hypothesised that cardinal cells at the highest level of this hierarchy might be tuned to detect the appearance of particular visual objects <ref> [3] </ref>. However, neuroanatomical and neuropsychological studies have raised so many objections to this approach that it must now be regarded as untenable (see [9] for a review).
Reference: [4] <author> Bauer, M. & Martienssen, W. </author> <title> (1991) Coupled circle maps as a tool to model synchronisation in neural networks. </title> <journal> Network, </journal> <volume> 2, </volume> <pages> 345-51. </pages>
Reference-contexts: Thirdly, activity in the onset map is used to modify the coupling strengths between neurons in a fully connected neural network. Specifically, the neural network model proposed by Bauer & Martienssen <ref> [4] </ref> is adopted, in which the phase dynamics of each neural oscillator is represented by a sine circle map. The sine circle map j (x) is given by (5) where h is a noise term. <p> However, the formulation of Malsburg & Schneiders oscillator model is perhaps rather ad hoc; Wangs has a similar structure, but with dynamics that are closely based on those of biological neurons. The model of Brown & Cooke, based on Bauer & Martienssens chaotic oscillators <ref> [4] </ref>, differs significantly from the other approaches; rather than creating oscillations through the interaction of excitatory and inhibitory mechanisms, it models each oscillator with a single phase variable. <p> It should be noted that such capacity limitations are not present in the Bauer & Martienssen model <ref> [4] </ref> on which the Brown & Cooke scheme [6] is based; whilst this has engineering advantages, their model is not in accord with human performance. 4.2.
Reference: [5] <author> Bregman, A. </author> <title> (1990) Auditory scene analysis. </title> <publisher> MIT Press. </publisher>
Reference-contexts: Oscillators of this type are the building blocks of two of the auditory models described in the following section. 2. NEURAL OSCILLATOR MODELS OF AUDITORY GROUPING There is a close relationship between the binding problem and so-called auditory grouping <ref> [5] </ref>; the latter concerns the issue of why particular features are combined to form perceptual wholes, whereas the binding problem concerns the issue of how such groups of features are represented in the brain. <p> The model is able to replicate several auditory grouping phenomena that occur in the perception of repeating tone sequences, such as sequential capturing and the competition between alternative organisations (see <ref> [5] </ref>). 2.3. Brown & Cooke A four-stage neural oscillator model of auditory grouping has been proposed by Brown & Cooke [6]. In the first stage of their model, peripheral auditory processing is simulated by a bank of bandpass filters and a model of inner hair cell function. <p> Liu, Yamaguchi and Shimizu Strictly, the model described by Liu et al. [18] addresses vowel recognition rather than auditory grouping. However, it is considered here because it employs neural oscillators, and also because its recognition architecture may be interpreted as a mechanism of top-down (schema-driven) auditory grouping <ref> [5] </ref>. The model consists of an input layer and three neural layers, which are referred to as the A, B and C centres. The input is a time series of mel-scaled linear prediction coefficients (LPC). <p> However, there are many exceptions to this rule, such as in the duplex perception of speech and the perception of harmonic complexes with a mistuned component <ref> [5] </ref>. Such violations of the principle of exclusive allocation have a clear implication for neural oscillator theories; neurons coding shared acoustic features should be permitted to synchronise with two (otherwise desynchronised) groups of oscillations. Of the models described in Section 2, only Wangs scheme meets this criterion. <p> The number of concurrent auditory streams What limitations does the neural oscillator theory place on the number of concurrent auditory streams? It has been argued that listeners maintain multiple auditory streams, even though they are not the subject of conscious attention <ref> [5] </ref>. However, the maximum number of concurrent streams is probably no more than three. Hence, neural oscillator architectures should permit three synchronised blocks of oscillations to exist concurrently. <p> Based on this idea, Wang et al. [25] have described an associative memory which consists of coupled oscillators. Their network is able to perform segregation of simultaneously presented patterns which have previously been stored in the network. Segregation in this model is therefore schema-driven <ref> [5] </ref>; primitive (data-driven) mechanisms are not included. Regarding short-term memory (STM), Horn & Usher [15] describe an oscillatory model which accounts for the limited (7+/-2) capacity of STM in terms of competition between oscillations.
Reference: [6] <author> Brown, G. & Cooke, M. </author> <title> (1995) Temporal synchronisation in a neural oscillator model of primitive auditory stream segregation. </title> <booktitle> Proceedings of the IJCAI Workshop on Computational Auditory Scene Analysis, Montreal, </booktitle> <pages> 40-47. </pages>
Reference-contexts: Brown & Cooke A four-stage neural oscillator model of auditory grouping has been proposed by Brown & Cooke <ref> [6] </ref>. In the first stage of their model, peripheral auditory processing is simulated by a bank of bandpass filters and a model of inner hair cell function. In the second stage, simulated auditory nerve firing patterns, derived from the hair cell model, are processed by an array of onset cells. <p> The chaotic oscillations produced by this model allow a large number of groups to be represented, but have a considerable disadvantage; a cross-correlation analysis is needed in order to evaluate the synchronisation of the network <ref> [6] </ref>. In contrast, relaxation oscillators exhibit rapid transitions between active and refractory phases (see Figure 2), and groups of simultaneously active neurons can therefore be identified by applying a simple threshold. A common feature in the oscillator models of Section 2 is the inclusion of a noise term. <p> It should be noted that such capacity limitations are not present in the Bauer & Martienssen model [4] on which the Brown & Cooke scheme <ref> [6] </ref> is based; whilst this has engineering advantages, their model is not in accord with human performance. 4.2. Binding of features in multiple maps It was noted in the introduction that the binding problem may operate both within processing nuclei and between such regions.
Reference: [7] <author> Cairns, D., Baddeley, R. & Smith, L. </author> <title> (1993) Constraints on synchronising oscillator networks. </title> <journal> Neural Computation, </journal> <volume> 5, </volume> <pages> 260-66. </pages>
Reference-contexts: Hence, neural oscillator architectures should permit three synchronised blocks of oscillations to exist concurrently. It has been noted that certain classes of laterally-coupled neural oscillator networks are only able to represent a very small number of simultaneous patterns <ref> [7] </ref>. However, at least two of the approaches discussed in Section 2 do not suffer from this problem. A detailed mathematical analysis of Wangs oscillator network has shown that it is able to represent n concurrent patterns in the input as n blocks of synchronised oscillations [26].
Reference: [8] <author> Crick, F. </author> <title> (1984) Function of the thalamic reticular complex: The searchlight hypothesis. </title> <booktitle> Proceedings of the National Academy of the Sciences USA, </booktitle> <volume> 81, </volume> <pages> 4586-90. </pages>
Reference-contexts: The final stage of the model is an attentional mechanism, motivated by Cricks <ref> [8] </ref> hypothesis that an attentional searchlight is located in the thalamus. Despite its simplicity, the model closely matches the performance of human listeners in two-tone streaming studies. In particular, it is able to account for grouping by temporal and frequency proximity, common onset and good continuation. 2.4. <p> The global inhibitor approach has two advantages. First, the activity of the global inhibitor is a good indicator of the state of synchronisation in an oscillator network. Second, the behaviour of the H-cell/global inhibitor may correspond to that of a neural group in the thalamus <ref> [8] </ref>; the approach therefore has some physiological justification. 3.3. The representation of time None of the models reviewed in Section 2 adequately addresses the representation of time in the auditory system.
Reference: [9] <author> Damasio, A. </author> <title> (1989) The brain binds entities and events by multiregional activation from convergence zones. </title> <journal> Neural Computation, </journal> <volume> 1, </volume> <pages> 123-132. </pages>
Reference-contexts: It has been hypothesised that cardinal cells at the highest level of this hierarchy might be tuned to detect the appearance of particular visual objects [3]. However, neuroanatomical and neuropsychological studies have raised so many objections to this approach that it must now be regarded as untenable (see <ref> [9] </ref> for a review). In particular, the theory requires the existence of cortical sites which receive projections from all the neural regions specialised for processing the different sensory attributes of a stimulus. Despite intensive study of cortical structure, such sites have not been identified. <p> Indeed, memory should be considered an integral part of the binding problem: not only must we bind together a combination of features at one moment, but we must also store that combination of features for future reference <ref> [9] </ref>. Further, there appears to be an intimate connection between oscillations, synchronisation and memory. Synchronous bursts converging on a postsynaptic cell produce large depolarisations that are optimal for activating NDMA receptors, which in turn lead to long-term potentiation. Hence, neural plasticity may require temporal synchronisation of synaptic inputs [23]. <p> In the latter case, it might refer to the binding of properties processed separated (e.g., pitch and loudness). The formulation of the binding problem usually implies the latter interpretation, but, oddly, most modelling studies including those reviewed in Section 2 only address within-region binding. Damasio <ref> [9] </ref> describes an architecture for binding information from multiple brain regions. He hypothesises a hierarchy of neural groups called convergence zones, which trigger and synchronise neural activity patterns in lower centres. Convergence zones store binding codes, which describe the combination of features that describe entities.
Reference: [10] <author> Eckhorn, R., Bauer, R., Jordan, W., Brosch, M., Kruse, W., Munk, M. & Reitboecj, H. </author> <title> (1988) Coherent oscillations: A mechanism of feature linking in the visual cortex. </title> <journal> Biological Cybernetics, </journal> <volume> 60, </volume> <pages> 121-130. </pages>
Reference-contexts: Evidence supporting this so-called correlation theory has come from studies of the visual and olfactory systems, which report that stimuli evoke synchronised neural oscillations in functionally related (but remote) areas of the cortex <ref> [10] </ref>. Additionally, synchronised oscillations evoked by acoustic stimuli have been observed in the auditory cortex [16]. These experimental findings have led to more specific formulations of von der Malsburgs scheme, which propose that feature binding is signalled by the phase of neural oscillations (e.g., [10,20,26]).
Reference: [11] <author> FitzHugh, R. </author> <title> (1961) Impulses and physiological states in theoretical models of nerve membrane. </title> <journal> Biophysical Journal, </journal> <volume> 1, </volume> <pages> 445-66. </pages>
Reference-contexts: Considerable insight into the origin of neural oscillations can be gained by viewing neurons (and neural networks) as dynamical systems. For example, consider the caricature of the Hodgkin-Huxley equations proposed by FitzHugh <ref> [11] </ref> (the so-called Bonhoeffer-van der Pol model), which is described by the following coupled nonlinear differential equations: (1a) Here, x and y are the dynamical variables, I is the external input and a, b and c are constants.
Reference: [12] <author> Frisina, R., Smith, R. & Chamberlain, S. </author> <title> (1990) Encoding of amplitude modulation in the gerbil cochlear nucleus: A hierarchy of enhancement. </title> <journal> Hearing Research, </journal> <volume> 44, </volume> <pages> 99-122. </pages>
Reference-contexts: They should therefore be distinguished from other oscillatory responses in the auditory system, such as those of chopper cells in the dorsal cochlear nucleus. Chopper cells oscillate at a much higher frequency (up to 500 Hz) and tend to phase-lock to the envelope of amplitude modulated stimuli <ref> [12] </ref>. 1.2. The origin of neural oscillations: A dynamical systems perspective Oscillatory firing activity usually originates from the interaction of mutually connected excitatory and inhibitory processes.
Reference: [13] <author> Galambos, R., Makeig, S. & Talmachoff, P. </author> <title> (1981) A 40 Hz auditory potential recorded from the human scalp. </title> <booktitle> Proceedings of the National Academy of the Sciences USA, </booktitle> <volume> 78, </volume> <pages> 2643-47. </pages>
Reference-contexts: These oscillations usually lie in the b and g range of the EEG (15-60 Hz), and are referred to as 40 Hz oscillations. In the auditory domain, 40 Hz oscillations have been observed in EEGs evoked by tonal stimuli <ref> [13] </ref>. Also, a recent study in which alert human subjects were presented with pairs of clicks has provided direct evidence for the role of neural oscillations in auditory grouping [16].
Reference: [14] <author> Horikawa, J., Tanahashi, A. & Suga, N. </author> <title> (1994) After-discharges in the auditory cortex of the moustached bat - no oscillatory discharges for binding auditory information. </title> <journal> Hearing Research, </journal> <volume> 76, </volume> <pages> 45-52. </pages>
Reference-contexts: Evidence against the neural oscillator theory Aspects of the neural oscillator theory are controversial. In particular, it has been suggested that neural oscillations are induced by anaesthesia, and that oscillations therefore reect state of sleep rather than feature binding <ref> [14] </ref>. There is some justification for this view, since many studies reporting cortical oscillations have been conducted on animals using anaesthetics that are known to induce rhythmic neural firing activity. Equally, however, studies have reported coherent neural oscillations in awake animals [23].
Reference: [15] <author> Horn, D. & Usher, M. </author> <title> (1991) Parallel activation of memories in an oscillatory neural network. </title> <journal> Neural Computation, </journal> <volume> 3, </volume> <pages> 31-43. </pages>
Reference-contexts: Their network is able to perform segregation of simultaneously presented patterns which have previously been stored in the network. Segregation in this model is therefore schema-driven [5]; primitive (data-driven) mechanisms are not included. Regarding short-term memory (STM), Horn & Usher <ref> [15] </ref> describe an oscillatory model which accounts for the limited (7+/-2) capacity of STM in terms of competition between oscillations. This is achieved through a short-term potentiation mechanism, which lowers the threshold of oscillating cells after stimulation has ceased, causing oscillations to persist without input.
Reference: [16] <author> Joliot, M., Ribary, U. & Llinas, R. </author> <title> (1994) Human oscillatory brain activity near to 40 Hz coexists with cognitive temporal binding. </title> <booktitle> Proceedings of the National Academy of the Sciences of the USA, </booktitle> <volume> 91, </volume> <pages> 11748-51. </pages>
Reference-contexts: Evidence supporting this so-called correlation theory has come from studies of the visual and olfactory systems, which report that stimuli evoke synchronised neural oscillations in functionally related (but remote) areas of the cortex [10]. Additionally, synchronised oscillations evoked by acoustic stimuli have been observed in the auditory cortex <ref> [16] </ref>. These experimental findings have led to more specific formulations of von der Malsburgs scheme, which propose that feature binding is signalled by the phase of neural oscillations (e.g., [10,20,26]). Until recently, the role of neural oscillations in feature binding had been studied predominantly in the visual and olfactory systems. <p> In the auditory domain, 40 Hz oscillations have been observed in EEGs evoked by tonal stimuli [13]. Also, a recent study in which alert human subjects were presented with pairs of clicks has provided direct evidence for the role of neural oscillations in auditory grouping <ref> [16] </ref>. For click pairs presented less than 12-15 ms apart, subjects reported a single source and simultaneous magneto-encephalography (MEG) recordings from the auditory cortex showed a single 40 Hz oscillation.
Reference: [17] <author> Lisman, J. & Idiart, M. </author> <title> (1995) Storage of 7+/-2 short-term memories in oscillatory subcycles. </title> <journal> Science, </journal> <volume> 267, </volume> <pages> 1512-15. </pages>
Reference-contexts: This is achieved through a short-term potentiation mechanism, which lowers the threshold of oscillating cells after stimulation has ceased, causing oscillations to persist without input. Lisman & Idiart <ref> [17] </ref> elaborate a compatible physiologically-motivated scheme based on the storage of memories in different high frequency (40 Hz) subcycles of a low frequency (5-12 Hz) oscillation, resulting in the 7+/-2 constraint.
Reference: [18] <author> Liu, F., Yamaguchi, Y. & Shimizu, H. </author> <title> (1994) Flexible vowel recognition by the generation of dynamic coherence in oscillator neural networks: speaker-independent vowel recognition. </title> <journal> Biological Cybernetics, </journal> <volume> 7, </volume> <month> 105-114. </month> <title> [19] von der Malsburg, C. (1981) The correlation theory of brain function. </title> <type> Internal report 81-2, </type> <institution> Max Planck Institute for Biophysical Chemistry, Gttingen, </institution> <note> FRG. </note> <author> [20] von der Malsburg, C. & Schneider, W. </author> <title> (1986) A neural cocktail-party processor. </title> <journal> Biological Cybernetics, </journal> <volume> 54, </volume> <pages> 29-40. </pages>
Reference-contexts: Despite its simplicity, the model closely matches the performance of human listeners in two-tone streaming studies. In particular, it is able to account for grouping by temporal and frequency proximity, common onset and good continuation. 2.4. Liu, Yamaguchi and Shimizu Strictly, the model described by Liu et al. <ref> [18] </ref> addresses vowel recognition rather than auditory grouping. However, it is considered here because it employs neural oscillators, and also because its recognition architecture may be interpreted as a mechanism of top-down (schema-driven) auditory grouping [5].
Reference: [21] <author> McGurk, H. & McDonald, J. </author> <title> (1976) Hearing lips and seeing voices. </title> <journal> Nature, </journal> <volume> 264, </volume> <pages> 746-48. </pages>
Reference-contexts: Other sensory channels, such as the visual system, must also combine fragmentary representations of stimuli from separate neural structures. Further, features must be integrated across different sensory and motor systems, both in perception and recall. For example, audiovisual integration is apparent in the well-known McGurk effect <ref> [21] </ref>, in which the perception of speech sounds is inuenced by the image of the speakers face. Such integration of information from different sensory modalities suggests that the brain employs a universal neural mechanism for feature binding.
Reference: [22] <author> Moore, D. </author> <title> (1987) Physiology of higher auditory system. </title> <journal> British Medical Bulletin, </journal> <volume> 43, </volume> <pages> 856-70. </pages>
Reference-contexts: 1. INTRODUCTION Recent advances in auditory neuroscience support the notion that different properties of acoustic events (such as periodicity, spatial location and spectral shape) are extracted at separate locations in the auditory system <ref> [22] </ref>. Nonetheless, we perceive auditory events as meaningful wholes, not as parts. In other words, the auditory system is able to bind together features represented in remote neural structures to form perceptual wholes. The mechanism of this binding process is the subject of our paper. <p> It is generally assumed that place-coded maps of features in the auditory system provide probabilistic information, such that the firing rate of a cell in the map indicates the likelihood that a particular feature is present <ref> [22] </ref>. However, if the dynamics of neural oscillator models accurately reect the mechanisms of feature binding in the auditory system, they imply that the representation of features in maps is discrete rather than probabilistic.
Reference: [23] <author> Singer, W. </author> <title> (1993) Synchronisation of cortical activity and its putative role in information processing and learning. </title> <journal> Annual Review of Physiology, </journal> <volume> 55, </volume> <pages> 349-74. </pages>
Reference-contexts: Finally, we discuss some outstanding challenges that theories of feature binding must address. 1.1. Evidence for oscillations in the auditory system Evidence for synchronised neural oscillations in the neocortex has come from studies of the electroencephalogram (EEG), and from field potentials recorded with intracerebral electrodes (see <ref> [23] </ref> for a review). These oscillations usually lie in the b and g range of the EEG (15-60 Hz), and are referred to as 40 Hz oscillations. In the auditory domain, 40 Hz oscillations have been observed in EEGs evoked by tonal stimuli [13]. <p> Further, there appears to be an intimate connection between oscillations, synchronisation and memory. Synchronous bursts converging on a postsynaptic cell produce large depolarisations that are optimal for activating NDMA receptors, which in turn lead to long-term potentiation. Hence, neural plasticity may require temporal synchronisation of synaptic inputs <ref> [23] </ref>. If neural oscillations are involved in long-term memory and learning, then they must in some way account for perceptual invariance: the problem that many different sensory experiences must be mapped onto the same internal representation. <p> There is some justification for this view, since many studies reporting cortical oscillations have been conducted on animals using anaesthetics that are known to induce rhythmic neural firing activity. Equally, however, studies have reported coherent neural oscillations in awake animals <ref> [23] </ref>. It seems unlikely, therefore, that oscillations are simply an epiphenomenon. It should be noted that evidence for coherent oscillations in the auditory system currently comes only from imaging techniques such as the EEG (e.g., [13,16]).
Reference: [24] <author> Sutter, M. & Schreiner, C. </author> <title> (1995) Topography of intensity tuning in cat primary auditory cortex - single-neuron versus multiple-neuron recordings. </title> <journal> Journal of Neurophysiology, </journal> <volume> 73, </volume> <pages> 190-204. </pages>
Reference-contexts: A further implication is that sound intensity would then need to be coded and bound in a separate map. Recent physiological studies of the cortex suggest that this is a possibility <ref> [24] </ref>. 3.6. The number of concurrent auditory streams What limitations does the neural oscillator theory place on the number of concurrent auditory streams? It has been argued that listeners maintain multiple auditory streams, even though they are not the subject of conscious attention [5].
Reference: [25] <author> Wang, D., Buhmann, J. & von der Malsburg, C. </author> <title> (1990) Pattern segmentation in associative memory. </title> <journal> Neural Computation, </journal> <volume> 2, </volume> <pages> 94-106. </pages>
Reference-contexts: Malsburgs correlation theory [19] proposes a solution to perceptual invariance in terms of a mechanism of associative memory, in which independent sets of correlations lead to independent associative mappings. Based on this idea, Wang et al. <ref> [25] </ref> have described an associative memory which consists of coupled oscillators. Their network is able to perform segregation of simultaneously presented patterns which have previously been stored in the network. Segregation in this model is therefore schema-driven [5]; primitive (data-driven) mechanisms are not included.
Reference: [26] <author> Wang, D. </author> <title> (1996) Primitive auditory segmentation based on oscillatory correlation. </title> <journal> Cognitive Science, </journal> <note> in press. </note>
Reference-contexts: However, the model is limited to this single grouping principle; no information about the distance between acoustic components in time and frequency is preserved, and hence the model is unable to reproduce other well-known aspects of auditory organisation such as grouping by temporal and frequency proximity. 2.2. Wang Wang <ref> [26] </ref> has recently described a model of auditory grouping in which time-frequency patterns are represented on a two-dimensional grid of relaxation oscillators. It is hypothesised that the time axis of this grid is created by a system of delay lines. <p> For example, the parameter g in the Wang model (equation 4b) allows the relative time that an oscillator spends in the active phase and refractory phase to be determined <ref> [26] </ref>. The dynamics of the Malsburg & Schneider model cannot be directly compared with relaxation oscillator models because it is presented as a system of difference equations, rather than differential equations. <p> The purpose of the noise is to assist the desynchronisation of groups of oscillators which happen to start from very similar initial conditions (so-called symmetry breaking [20,26]). Also, the addition of noise allows the robustness of a model to be evaluated <ref> [26] </ref>. 3.2. Local connectivity vs. global connectivity The models described in Section 2 differ in the connectivity of their oscillator networks; two models employ global (all-to-all) connectivity (Malsburg & Schneider, Brown & Cooke), whereas two employ lateral coupling over a limited range of frequencies (Wang, Liu et al.). <p> However, at least two of the approaches discussed in Section 2 do not suffer from this problem. A detailed mathematical analysis of Wangs oscillator network has shown that it is able to represent n concurrent patterns in the input as n blocks of synchronised oscillations <ref> [26] </ref>. The sine circle maps employed in Brown & Cookes model exhibit chaotic oscillations, which allow a large number of groups to be represented; the number of possible groups is limited only by the resolution of the phase variable q in equation (6).
Reference: [27] <author> Wang, D. </author> <title> (1995) Image segmentation based on oscillatory correlation. </title> <booktitle> Proceedings of the World Congress on Neural Networks, </booktitle> <publisher> in press. </publisher>
Reference-contexts: The use of lateral connections suggests an inuence of earlier neural oscillator models of visual processing <ref> [27] </ref>. In vision, objects tend to occupy spatially compact regions of the visual field. Long range connections are therefore inappropriate, since they could lead to the synchronisation of neural oscillators that represent features of different objects. <p> Another reason for hypothesising an auditory time axis is that it allows acoustic stimuli to be treated as two-dimensional spatial patterns; this is advantageous, since the architecture of Wangs model is closely related to that of his earlier models of visual processing <ref> [27] </ref>. However, caution is needed when drawing analogies between the auditory and visual modalities. In vision, time and space are two separate characteristic of a stimulus arriving at the retina, whereas in audition temporal and spatial (frequency) dimensions are intrinsically linked.
References-found: 25

