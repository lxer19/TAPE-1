URL: ftp://ftp.cs.man.ac.uk/pub/cnc/os-trends.ps.gz
Refering-URL: http://www.cs.man.ac.uk/cnc/arena/publication.html
Root-URL: http://www.cs.man.ac.uk
Title: Trends in Operating Systems Towards Dynamic User-level Policy Provision  
Author: K.R. Mayes 
Date: September, 1993  
Affiliation: Department of Computer Science  University of Manchester.  
Pubnum: Technical Report UMCS-93-9-1  
Abstract: It is possible to distinguish between policy and mechanism in operating system design. There is a trend to move policy out of the operating system kernel and into the user-level. This trend is described with respect to example operating system types. A system is proposed which takes this policy/mechanism split to the extreme of having the operating system kernel reduced to a hardware object which provides a low-level but abstract view of the actual hardware. Such a system would be flexible enough to allow investigation of dynamic, user-level, provision of policy. 
Abstract-found: 1
Intro-found: 1
Reference: <editor> Amoeba (1992) Amoeba Reference Manual. </editor> <title> User Guide. </title> <publisher> Vrije Universiteit. </publisher>
Reference-contexts: The designers of the Hydra system felt that, in retrospect, they should not have chosen 24 However, there are differences to UNIX; the default file and directory servers, for example, have non-UNIX semantics <ref> (Amoeba, 1992) </ref>. 14 to implement a general-purpose, time-shared system (Wulf et al., 1981). The time to build the additional software for such a system, and their lack of provision of a well thought out user interface command language, impaired the acceptance of Hydra by the user community. 3.
Reference: <author> Abrossimov, V., M. Rozier and M. </author> <title> Shapiro (1989) Generic virtual memory management for operating system kernels. </title> <booktitle> Proc. 12th ACM Symp. on Operating System Principles, </booktitle> <pages> 123-136. </pages>
Reference: <author> Anderson, T.E., B.N. Bershad, E.D. Lazowska and H.M. </author> <title> Levy (1992) Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <journal> ACM Transactions on Computer Systems 10(1), </journal> <pages> 53-79. </pages>
Reference-contexts: However, it has been argued that none of these existing systems provide sufficient flexibility for library and language implementors (Scott et al., 1990; Lazowska, 1992). New work on Psyche (Marsh et al., 1991) and on scheduler activations <ref> (Anderson et al. 1992) </ref> take thread scheduling out of the kernel by enabling the kernel to make `upcalls' to the user level. The argument here is that the operating system interface should allow each user to define precisely the runtime system to be used to run a particular program.
Reference: <author> Armand, F., M. Gien, M. Guillemont and P. </author> <title> Leonard (1986) Towards a distributed UNIX system The CHORUS approach. </title> <booktitle> EUUG Conference Procedings (Autumn), </booktitle> <pages> 413-431. </pages> <note> 32 Bacon, </note> <author> J. </author> <title> (1989) Evolution of operating system structures. </title> <institution> Univ. of Cambridge Com--puter Lab. </institution> <type> Technical Report 166. </type>
Reference: <author> Banach, R., J. Sargeant, I. Watson, P. Watson and V. </author> <title> Woods (1988) The Flagship Project. IEE/BCS UK IT 88, </title> <booktitle> Conference Publication, </booktitle> <address> University College Swansea (July), </address> <pages> 242-245. </pages>
Reference-contexts: However, the example of this approach which will be dealt with in this section is the Flagship system. The Flagship system is a parallel packet-based graph reduction multicomputer machine 29 <ref> (Banach et al., 1988) </ref>. The European Declarative System (EDS) multicomputer system (Skelton et al., 1992) provides an example of the second approach. These systems have basically similar hardware 30 , and both are intended to run declarative paradigm languages in a parallel environment.
Reference: <author> Barrera III, J.S. </author> <title> (1991) A fast Mach network IPC implementation. </title> <booktitle> Proc. Usenix Mach Symp. </booktitle> <month> (November), </month> <pages> 1-11. </pages>
Reference-contexts: The existence of this gradation indicates that fast communications requires kernel implementation. This view is supported by the subsequent incorporation of the network component of IPC into the Mach kernel. This provided the performance nec essary for IPC on a multicomputer, at the cost of flexibility <ref> (Barrera, 1991) </ref>. (d) Naming A gradation can be seen amongst these systems in the use of capabilities for naming and protection. These capabilities are different to the capabilities of classical capability systems. Mach capabilities only refer to ports and are managed by the kernel.
Reference: <author> Barton-Davis, P., D. McNamee, R. Vaswani and E.D. </author> <note> Lazowska (1993) Adding scheduler activations to Mach 3.0. </note> <institution> Univ. of Washington Technical Report 92-08-03. </institution>
Reference: <author> Black, D. </author> <title> (1990) Scheduling support for concurrency and parallelism in the Mach operating system. </title> <booktitle> IEEE Computer 23(5), </booktitle> <pages> 35-43. </pages>
Reference-contexts: In these systems, services are provided by server processes; thus IPC tends to replace the system call as a means of accessing the operating system services. Obviously system performance is improved if IPC is fast. So, for example, handoff scheduling <ref> (Black, 1990) </ref> has been implemented in Mach to enhance message exchange. Mach, Chorus and Amoeba are described here as being typical of microkernel systems. <p> This equivalence of process with address space is one of the conventional properties of these microkernels. Scheduling policies are fixed by the kernel, though Mach allows `user-level hints' to modify the scheduler's behaviour <ref> (Black, 1990) </ref>. These are of two kinds: discouragement (the current thread should not run) and handoff (a specific thread should run) 25 . Mach 3.0 uses continuations to improve performance of the scheduler 26 . <p> Mach's message passing subsystem uses handoff scheduling inside the kernel, immediately suspending a sender and scheduling a blocked receiver. This avoids the run queue entirely and "aids performance" <ref> (Black, 1990) </ref>. <p> The kernel provides the mechanism only. This placing of policy in the server provides more flexibility, and allows implementation of various policies, for example gang scheduling <ref> (Black, 1990) </ref>. In Amoeba, processor allocation is determined by a user-level `run server' which has access to CPU loading (and other) information (Tanenbaum, 1992).
Reference: <author> Black, D., D.B. Golub, D.P. Julin, R.F. Rashid, R.P. Draves, R.W. Dean, A. Forin, </author> <note> J. </note>
Reference: <author> Barrera, H. Tokuda, G. Malan and D. </author> <title> Bohman (1992) Microkernel operating system architecture and Mach. </title> <booktitle> Proc. Usenix Workshop on Microkernels and Other Kernel Architectures (April), </booktitle> <pages> 11-30. </pages>
Reference: <author> Bryant, R., H. Chang and B. </author> <title> Rosenburg (1991) Experience developing the RP3 operating system. </title> <booktitle> Usenix Association Distributed and Multiprocessor Systems (Summer), </booktitle> <pages> 1-18. </pages>
Reference: <author> Buckle, J.K. </author> <title> (1978) The ICL 2900 series. </title> <publisher> Macmillan Press. </publisher>
Reference-contexts: The linkage segment serves as an indirection from the shared code virtual addresses to the private, process-local segment to be substituted for the virtual address (possibly via the process segment table entry). Linkages of this basic type are procedure linkage table of VME <ref> (Buckle, 1978) </ref> and linkage section of Multics (Daley and Dennis, 1968). 2. capability-based systems These systems basically rely on segmentation-based hardware, though there may be a special set of registers to hold the capabilities. Capabilities are essentially segment descriptors which can be freely passed between processes.
Reference: <author> Campbell, M., R. Barton, J. Browning, D. Cervenka, B. Curry, T. Davis, T. Edmonds, R. Holt, J. Slice, T. Smith and R. </author> <title> Wescott (1991) The parallelization of UNIX System V Release 4.0. </title> <booktitle> Proc. Conference of Usenix Association (Winter), </booktitle> <pages> 307-323. </pages>
Reference-contexts: Parallelisation of the Unix kernel consists of locking critical sections of the standard Unix kernel. For example, in an SVR4/MP version, the dispatcher queue is shared by all processors; a processor runs code which acquires a lock and takes the highest priority process off the queue <ref> (Campbell et al., 1991) </ref>. In the same SVR4/MP system, a lock hierarchy was necessary to parallelise the virtual memory system. A lock was first obtained for the address space structure, which also locked the segment structures. Various lower-level structures beneath this are potentially shared and must be locked.
Reference: <author> Carriero, N. </author> <title> and Gelernter (1989) Linda in context. </title> <booktitle> Comms ACM 32(4). </booktitle> <pages> 444-458. </pages>
Reference-contexts: This common layer implemented common policies and so supported interoperability. Other examples of this kind of approach are languages supporting parallel semantics such as Strand and PCN (Foster and Taylor, 1989; Foster and Tuecke, 1993), and communication paradigm abstract machines such as Linda <ref> (Carriero and Gelernter, 1989) </ref>.
Reference: <author> Carter, J.B., D.B. Johnson, A.L. Cox and W. </author> <title> Zwaenepoel (1992) Distributed operating systems based on a protected global virtual address space. </title> <institution> Rice COMP TR92-186. </institution>
Reference-contexts: A capability-based machine, the IBM/38 supported a flat, single-level 64-bit virtual address space 41 . Other operating system work is starting to focus on the large address space model associated with the advent of 64-bit addressing. In such systems the standard process equals address space association can break down <ref> (Carter et al., 1992) </ref>. Process virtual address spaces will be regions in the single address space, and protection mechanisms based on the protection domain model will be required (Lazowska, 1992). However, virtual address translations will be the same in all protection domains, facilitating sharing. <p> However, virtual address translations will be the same in all protection domains, facilitating sharing. The three systems discussed here are the Opal system (Koldinger et al., 1992), the Rice system <ref> (Carter et al., 1992) </ref> and the Toshiba system (Okamoto et al., 1992). 9.1 Single-level store The Opal system (Koldinger et al., 1992) is an operating system design which supports a single global virtual address space that maps all primary and secondary store in a 41 The hardware supported only a 48-bit <p> Here cross-protection domain calls are detected at bind-time by a name server. The name server plants a stub into the code. If the call is to cross a protection domain, then the stub causes a trap for access checking <ref> (Carter et al., 1992) </ref>. 9.3 Distributed implementation The single global address space provides the ability to map all primary and secondary store entities into the same address space on all nodes of a distributed machine. The conventional RPC client-server model tends to be used to support distribution of computation.
Reference: <author> Castro Dutra, I. </author> <title> de (1991) A flexible scheduler for the Andorra-I system. </title> <publisher> LNCS 569, </publisher> <month> 70-82. </month> <title> Chorus (1990) CHORUS kernel v3.2 Specification and interface. </title> <institution> Chorus Systemes CS/TR-89-60. </institution>
Reference-contexts: The most obvious applications relate to process management, specifically to scheduling. The run-time systems for parallel prologs can have schedulers for both and- and or- parallelism. Thus the overall runtime-level scheduling system must be flexible enough for applications where the kind of parallelism varies along the course of execution <ref> (Castro Dutra, 1991) </ref>. With parallel Lisp, schedul 4 ing strategy is naturally two-phased, creating parallel tasks until the machine is fully utilised, then running sequentially with each task (Halstead, 1989).
Reference: <author> Corsini, P., G. Frosini and L. </author> <title> Lopriore (1984) The implementation of abstract objects in a capability based addressing architecture. </title> <journal> Computer J. </journal> <volume> 27, </volume> <pages> 127-134. </pages>
Reference-contexts: A caller on the abstract object has an `enter' capability for the BCS <ref> (Corsini et al, 1984) </ref>. Using this enter capability switches the caller into the context provided by the BCS the object representation may only be accessed by procedures referenced by virtual addresses within that context 9 .
Reference: <author> Culler, D.E., A. Sah, K.E. Schauser, T. von Eicken and J. </author> <title> Wawrzynek (1991) Fine-grained parallelism with minimal hardware support: a compiler-controlled threaded abstract machine. </title> <booktitle> 4th Int. Conf. on Architectural Support for Programmming Languages and 33 Operating SYstems (April), </booktitle> <pages> 164-175. </pages> <note> Cypress (1990) Sparc Risc user's guide. Cypress Semiconductor. </note>
Reference-contexts: As was noted with a thread-based implementation of Id, "exposing scheduling to the compiler allows it to synthesise particular scheduling policies in specific portions of the program" <ref> (Culler et al., 1991) </ref>. Parallel database performance is also influenced by scheduling policy. Franaszek and Robinson (1985) noted that scheduling policies which take into account the state of transactions 5 could increase the level of concurrency.
Reference: <author> Daley, </author> <title> R.C. and J.B. Dennis (1968) Virtual memory, processes, and sharing in MULTICS. </title> <booktitle> Comms ACM 11, </booktitle> <pages> 306-312. </pages>
Reference-contexts: Linkages of this basic type are procedure linkage table of VME (Buckle, 1978) and linkage section of Multics <ref> (Daley and Dennis, 1968) </ref>. 2. capability-based systems These systems basically rely on segmentation-based hardware, though there may be a special set of registers to hold the capabilities. Capabilities are essentially segment descriptors which can be freely passed between processes. The address space of a process is not static.
Reference: <author> Dennis, J.B. </author> <title> and E.C. Van Horn (1966) Programming semantics for multiprogrammed computations. Comms. </title> <booktitle> ACM 9, </booktitle> <pages> 143-155. </pages>
Reference: <author> Draves, R. </author> <title> (1990) A revised IPC interface. </title> <booktitle> Proc. Usenix Mach Symp., </booktitle> <pages> 101-121. </pages>
Reference-contexts: Mach perhaps shows its multiprocessor origins (where there is no requirement for the network component) by originally having only the local IPC implemented in the kernel. Networking runs as a user-level `netmsg' server on each node of a distributed Mach installation. This server implements the network protocols <ref> (Draves, 1990) </ref>. Similarly, Chorus local IPC is implemented in the kernel, the network protocols reside in network servers. However, unlike Mach, these servers work in close cooperation with the kernel and share message buffers with it.
Reference: <author> Draves, R., R. Dean, B. Bershad and R. </author> <title> Rashid (1991) Continuations: Unifying thread management and communications in operating systems. </title> <booktitle> Proc. 13th ACM Symp. on operating systems principles (October), </booktitle> <pages> 122-136. </pages>
Reference-contexts: A continuation is a routine which the rescheduled thread should enter, plus a data structure representing the saved thread context state. This local state would normally be saved in a process control block and thread kernel stack, and so less store is needed by the kernel <ref> (Draves et al., 1991) </ref>. Chorus implements preemptive scheduling on thread absolute priority 27 (Chorus, 1992).
Reference: <author> Duchamp, D. </author> <title> (1991) Experience with threads and RPC in Mach. </title> <booktitle> Usenix Association, Distributed and Multiprocessor Systems (Summer), </booktitle> <pages> 87-104. </pages>
Reference: <author> Faust, J.E. and H.M. </author> <title> Levy (1990) The performance of an object-oriented threads package. </title> <booktitle> ECOOP/OOPSLA Proceedings (October), </booktitle> <pages> 278-288. </pages>
Reference-contexts: Given the advantages of an object-based approach to operating system structure (Bacon, 1989; Hofmann et al., 1991), it may be appropriate to investigate various aspects of object-oriented techniques to provide for code reuse from libraries. Systems such as Presto <ref> (Faust and Levy, 1990) </ref>, and particularly Choices (Johnson and Russo, 1991), achieve code reuse by inheritance. The essence of this paper is to suggest that all policy could be implemented in user-level object-based libraries giving support, and code-reuse, for a variety of RTSs.
Reference: <author> Foster, I., C. Kesselman, and S. </author> <title> Taylor (1990) Concurrency: Simple concepts and powerful tools. </title> <journal> Computer J. </journal> <volume> 33(6), </volume> <pages> 501-507. </pages>
Reference: <author> Foster, I and S. </author> <title> Tuecke (1993) Parallel Programming with PCN. </title> <institution> Argonne National Laboratory ANL-91/32. </institution>
Reference: <author> Foster, I and S. </author> <title> Taylor (1989) Strand: New concepts in parallel programming. </title> <publisher> Prentice Hall. </publisher>
Reference: <author> Franaszek, P. and J.T. </author> <title> Robinson (1985) Limitations of concurrency in transaction processing. </title> <journal> ACM Transactions on Database Systems 10(1), </journal> <pages> 1-28. </pages>
Reference: <author> Gingell, R.A., J.P. </author> <title> Moran and W.A. Shannon (1987) Virtual memory architecture in SunOS. </title> <booktitle> Usenix Association Conference Proceedings (Summer), </booktitle> <pages> 81-94. </pages>
Reference-contexts: Unix is taken as an example. Traditionally, the address space of a Unix process consisted of three segments: code, data and stack. More recently a Unix process, exemplified by SunOS <ref> (Gingell et al., 1987) </ref> has an address space which consists of a vector of pages. Access control is at the page level. However, the implementation of virtual memory in the SunOS kernel has the concept of a mapped object.
Reference: <author> Golub, D., R. Dean, A. Forin and R. </author> <title> Rashid (1990) Unix as an application program. </title> <booktitle> Usenix Association Conference Proceedings (Summer), </booktitle> <pages> 87-95. </pages>
Reference-contexts: Mach originally (version 2.5) provided UNIX by having a `unix compatibility layer' of BSD code within the Mach kernel. This was removed for Release 3.0, leaving a pure Mach microkernel <ref> (Golub et al., 1990) </ref>. Similarly the Chorus kernel (version 2), whilst not actually containing any UNIX software, did contain code which was specifically intended to support UNIX emulation (Armand et al., 1986; Rozier et al., 1988).
Reference: <author> Guillemont, M., J. Lipkis, D. Orr and M. </author> <title> Rozzier (1991) A second-generation micro-kernel based UNIX; lessons in performance and compatibility. </title> <booktitle> Usenix Association Conference Procedings (Winter), </booktitle> <pages> 13-21. </pages>
Reference-contexts: Similarly the Chorus kernel (version 2), whilst not actually containing any UNIX software, did contain code which was specifically intended to support UNIX emulation (Armand et al., 1986; Rozier et al., 1988). Chorus version 3 changed Chorus from being a UNIX-compatible distributed operating system to being a distributed microkernel <ref> (Guillemont et al., 1991) </ref>. Both Mach and Chorus now provide full UNIX emulation as user-level servers. Unlike Mach and Chorus, Amoeba was not intended to provide UNIX binary compatibility (Tanenbaum et al., 1990).
Reference: <author> Gurd, J.R. </author> <title> (1988) A taxonomy of parallel computer architectures. The Design and Application of Parallel Digital Processors, </title> <booktitle> IEE International Specialist Seminar, Conference Publication No. 298, </booktitle> <address> Lisbon, Portugal, </address> <month> April, 57-61. </month> <title> 34 Halstead, R.H. (1989) New ideas in parallel List: </title> <booktitle> Language design, implementation and programming tools. </booktitle> <volume> LNCS 441, </volume> <pages> 2-57. </pages>
Reference: <author> Herrmann, B., M.I. Ortega, L. </author> <title> Philippe (1991) UNIX on a multicomputer: The benefits of the CHORUS architecture. </title> <note> Chorus Systems Technical Report CS/TR-91-46. </note>
Reference: <author> Holdsworth, S., J.A. Keane and K.R. </author> <title> Mayes (1989) Aspects of protection on the Flagship machine: binding, context and environment. </title> <type> ICL Technical Journal 6, </type> <pages> 757-777. </pages>
Reference-contexts: Thus protection is afforded by the MMU addressing context. Flagship has a global address space and so had protection based on protection domains. Accesses between protection domains was to be via capability packets <ref> (Holdsworth et al. 1989) </ref>. The execution of code associated with a subgraph occurs in the context of an environment.
Reference: <author> Holt, N. </author> <title> (1992) Virtual shared memory in commercial applications. Univ. of Manchester Centre for Novel Computing Virtual Shared Memory Symposium. </title>
Reference-contexts: Such VSM-mapped, shared data structures are protected by locks. Co-ordination between multiple nodes is via the controllers of the Series 39 machine optical fibre ring, so that kernel co-ordination is not normally required <ref> (Holt, 1992) </ref>. The aim is to minimise interaction between nodal kernels by maximising local activity. Where global activity does occur, the message-passing involved is hidden by the hardware VSM mechanism.
Reference: <author> Hofmann, F., P. Schlenk and T. </author> <title> Eirich (1991) Encapsulation and interaction in future operating systems. </title> <publisher> LNCS 563, </publisher> <pages> 241-246. </pages>
Reference: <author> Hutchinson, </author> <title> N.C. and L.L. </title> <booktitle> Peterson (1988) Design of the x-kernel. Proc. of the SIG-COMM 1988 Symp. </booktitle> <month> (August), </month> <pages> 65-75. </pages>
Reference-contexts: This customisation may be for a particular hardware port, or may be change the behaviour of the kernel to specialise it for a particular purpose. These systems exhibit the `operating system family' approach. Three systems will be discussed: MU5 (Morris and Ibbett, 1979), x-kernel <ref> (Hutchinson and Peterson, 1988) </ref> and Choices (Russo and Campbell, 1989). The MU5 operating system, intended to run on a range of systems from single processor to a network of several processors, is reminiscent of the Mach/Chorus approach. <p> The x-kernel has a fixed process manager and store manager, whose designs support the needs of communications. The primary feature of the x-kernel is to allow the construction of kernels with different communication protocols using an object-oriented infrastructure <ref> (Hutchinson and Peterson, 1988) </ref>. The x-kernel views everything as a protocol, including user processes and devices. Choices is an operating system for multiprocessor architectures, based on the idea of using object-oriented programming and inheritance to build a kernel from layers that are collections of objects (Russo et al., 1988). <p> The intention of the designers of the x-kernel is to decompose conventional protocols so as to define a collection of `library protocols' from which programmers can build new protocols that provide exactly the communication support they need <ref> (Hutchinson and Peterson, 1988) </ref>. The version of x-kernel described in 1990 statically loaded all protocols to be configured into a given kernel.
Reference: <author> Istavrinos, P. </author> <title> (1989) Specification of the Process Control Language (PCL). </title> <booktitle> ESPRIT EP 2025 Deliverable, </booktitle> <address> EDS.DD.1S.0007. </address>
Reference-contexts: In particular, store coherency and virtually-shared store is required for the parallel implementation of the languages. Interestingly, the PCL primitives included (in the final version of the interface) an `unbundled' set of store primitives which allowed each paradigm to define its own coherency protocols <ref> (Istavrinos, 1989) </ref>. Earlier versions of PCL had sought to provide primitives in which coherency schemes were `bundled'. This provides a specific example of the trend to `unbundle' kernel interfaces to remove policy.
Reference: <author> Istavrinos, P., and L. </author> <title> Borrmann (1990) A process and memory model for a parallel distributed-memory machine. </title> <publisher> LNCS 457, </publisher> <pages> 479-488. </pages>
Reference-contexts: Both machines have an internal Delta network. 18 interface of the kernel provides the Process Control Language (PCL) primitives which are basically similar to those of Mach and Chorus. Indeed, EDS kernel uses Chorus as an implementation `starting point' <ref> (Istavrinos and Borrmann, 1990) </ref>. The EDS microkernel interface has basically two components. The major part of the interface (PCL) provides mechanisms for supporting non-numeric applications in parallel: relational database and declarative-paradigm languages 31 . The requirements of the execution models for the languages are provided by the PCL interface. <p> Thus, regions of the virtual address space can be shared irrespective of nodal distribution. Special hardware on each node allows copying of 128 byte `sectors' rather than entire 4K pages (Ward and Townsend, 1990). Thus, remote store access is supported at three levels in the EDS machine <ref> (Istavrinos and Borrmann, 1990) </ref>: 1. Page copying and remote update is provided in the processor architecture. 2. Virtual memory management is provided by the kernel, including management of the address space of a distributed task. 3.
Reference: <author> Johnson, R.E. </author> <title> and V.F. Russo (1991) Reusing object-oriented designs. </title> <institution> Univ. of Illinois Technical Report UIUCDCS 91-1696. </institution>
Reference-contexts: Given the advantages of an object-based approach to operating system structure (Bacon, 1989; Hofmann et al., 1991), it may be appropriate to investigate various aspects of object-oriented techniques to provide for code reuse from libraries. Systems such as Presto (Faust and Levy, 1990), and particularly Choices <ref> (Johnson and Russo, 1991) </ref>, achieve code reuse by inheritance. The essence of this paper is to suggest that all policy could be implemented in user-level object-based libraries giving support, and code-reuse, for a variety of RTSs. <p> A particular system component can be specialised for a particular requirement by deriving a subclass from a class representing an abstraction of that component. In addition to inheritance, Choices also reuses code by structuring subsystems as collections of connected objects <ref> (Johnson and Russo 1991) </ref>. . 2. Whether the configuration of the operating system occurs statically at build time, or can occur dynamically at run-time.
Reference: <author> Kahn, K.C., W.M. Corwin, T.D. Dennis, H. D'Hooge, D.E. Hubka, L.A. Hutchins, </author> <month> J.T. </month>
Reference: <author> Montague, F.J. Pollack and M.R. </author> <month> Gifkins </month> <year> (1981) </year> <month> iMax: </month> <title> A multiprocessor operating system for an object-based computer. </title> <booktitle> Proc. 8th Symp. on Operating System Principles, </booktitle> <pages> 127-136. </pages>
Reference: <author> Keane, J.A. and K.R. </author> <title> Mayes (1992) Resource management on a packet-based parallel graph reduction machine. </title> <publisher> LNCS 634, </publisher> <pages> 417-422. </pages>
Reference-contexts: Each subsystem was constructed to maximise the amount of local, as opposed to global, activity and so reduce bottlenecks and increase parallelism <ref> (Keane and Mayes, 1992) </ref>. The amount of parallel activity within the operating system was however reduced because of serialisability constraints imposed on access to the state of the manager ADT instances. Although Flagship has many specialised features, it also shares many features with systems such as Psyche.
Reference: <author> Koldinger, E.J., H.M. Levy, J.S. Chase and S.J. </author> <title> Eggers (1991) The protection lookaside buffer: efficient protection for single address-space computers. </title>
Reference-contexts: Single address space proposals seek similar support for protection. In Opal, the hardware basis of protection is at the level of the MMU TLB. A protection lookaside buffer has been proposed <ref> (Koldinger et al., 1991) </ref> which allows a separation of protection information from issues of address translation. In the Toshiba micro-kernel, protection between virtual address space sections is via access control lists associated with the memory sections and with threads accessing them.
Reference: <author> Koldinger, E.J., J.S. Chase and S.J. </author> <title> Eggers (1992) Architectural support for single address space operating systems. </title> <institution> Dept of Comp. Sci. and Eng. Univ. of Washington Technical Report 92-03-10. </institution>
Reference-contexts: Process virtual address spaces will be regions in the single address space, and protection mechanisms based on the protection domain model will be required (Lazowska, 1992). However, virtual address translations will be the same in all protection domains, facilitating sharing. The three systems discussed here are the Opal system <ref> (Koldinger et al., 1992) </ref>, the Rice system (Carter et al., 1992) and the Toshiba system (Okamoto et al., 1992). 9.1 Single-level store The Opal system (Koldinger et al., 1992) is an operating system design which supports a single global virtual address space that maps all primary and secondary store in a <p> However, virtual address translations will be the same in all protection domains, facilitating sharing. The three systems discussed here are the Opal system <ref> (Koldinger et al., 1992) </ref>, the Rice system (Carter et al., 1992) and the Toshiba system (Okamoto et al., 1992). 9.1 Single-level store The Opal system (Koldinger et al., 1992) is an operating system design which supports a single global virtual address space that maps all primary and secondary store in a 41 The hardware supported only a 48-bit physical address but when an object is created, microcode extends the address by adding an additional 16-bit field
Reference: <author> Kurtz, T.E. and K.M. </author> <title> Lochner (1965) Supervisory systems for the Dartmouth timesharing system. </title> <journal> Computers and Automation 14(10), </journal> <volume> 25. </volume>
Reference-contexts: Such supervisors were resident in core, and were small; the supervisor code for the Dartmouth Time-Sharing Computer System was 9.5K in size, some running on the master and some on the slave machine. <ref> (Kurtz and Lochner, 1965) </ref>. These supervisors were essentially device driver routines and a simple scheduler, plus some command interpretation. Supervisor code ran in privileged mode and was accessed via trap and interrupt.
Reference: <author> Lazowska, E.D. </author> <title> (1992) System Support for high performance multiprocessing. </title> <booktitle> Usenix 35 Association Proc. Symp. on Experiences with Distributed and Multiprocessor Systems (March), </booktitle> <pages> 1-11. </pages>
Reference-contexts: Such systems can be termed language paradigm-specific and are dealt with in Section 6. Other systems allow users to determine the interface: Customisable kernels, dating back to MU5 (Morris and Ibbett, 1979), can provide for static customisa-tion at build-time (Section 7). In Section 8, the so-called `nanokernels' <ref> (Lazowska, 1992) </ref> are described. Here, the further development of the policy/mechanism split is intended to support language run-time libraries and to allow language interworking (these systems are termed here `language paradigm general') and, at least potentially, to support dynamic changes in resource management policy. <p> In such systems the standard process equals address space association can break down (Carter et al., 1992). Process virtual address spaces will be regions in the single address space, and protection mechanisms based on the protection domain model will be required <ref> (Lazowska, 1992) </ref>. However, virtual address translations will be the same in all protection domains, facilitating sharing. <p> Access to the servers is via Amoeba and Chorus-like capabilities which are interpreted by the server and not by the kernel (Mach capabilities require kernel verification). These capabilities are associated with the server ports <ref> (Lazowska, 1992) </ref>.
Reference: <author> Leunig, </author> <title> S.R. (1987) Abstract Data Types in the Flagship System Software. Flagship Document FLAG/DD/303, ICL. </title>
Reference-contexts: EDS, with its conventional equality of process and address space, is a server-based system. The Flagship operating system took a different approach. The units of functionality were not server processes, but rather passive objects; instances of FADTs. The Flagship process was the unit of resource allocation <ref> (Leunig, 1987) </ref>; not of execution or of virtual addressing. The schedulable entities in Flagship were active subgraphs, rather than explicit threads of control. 6.3 Inter-node activity The EDS system is optimised for fast message passing.
Reference: <author> Levy, H.M. </author> <title> (1984) Capability-based computer systems. </title> <publisher> Digital Press. </publisher>
Reference-contexts: 11 represent kernel and 00 represent user address spaces. 8 systems, which had support for capabilities in hardware, used protection domains to protect all the operating system, for example the iMAX operating system of the Intel iAPX 432 11 (Kahn et al., 1981) and the CAP capability machine operating system <ref> (Levy, 1984) </ref>. 3. page-based systems These systems are based on the modern paging hardware represented by the MMU. Unix is taken as an example. Traditionally, the address space of a Unix process consisted of three segments: code, data and stack.
Reference: <author> Li, K. and P. </author> <title> Hudak (1986) Memory coherence in shared virtual memory systems. </title> <booktitle> Proc. 5th ACM Symp. Principles of Distributed Computing, </booktitle> <pages> 229-239. </pages>
Reference: <author> Marsh, </author> <title> B.D., M.L. Scott, T.J. LeBlanc and E.P. Markatos (1991) First-class user-level threads. </title> <booktitle> ACM operating system Review 25(5) (Proc 13th ACM Symp on operating system Principles (Oct, </booktitle> <year> 1991)), </year> <pages> 110-121. </pages>
Reference-contexts: Existing microkernels support user-provision of store, file and network management by user-level servers. However, it has been argued that none of these existing systems provide sufficient flexibility for library and language implementors (Scott et al., 1990; Lazowska, 1992). New work on Psyche <ref> (Marsh et al., 1991) </ref> and on scheduler activations (Anderson et al. 1992) take thread scheduling out of the kernel by enabling the kernel to make `upcalls' to the user level.
Reference: <author> Mayes, K.R. and J.A. </author> <title> Keane (1993) Levels of atomic action in the Flagship parallel system. </title> <journal> Concurrency: Practice and Experience 5(3), </journal> <pages> 193-212. </pages>
Reference-contexts: From these graph reduction computations it was able to call the imperatively-implemented hardware ADT operations. Flagship operating system did not provide the abstract machine for the languages, but rather ran on the same GR abstract machine <ref> (Mayes and Keane, 1993) </ref>.
Reference: <author> Micallef, J. </author> <title> (1988) Encapsulation, </title> <booktitle> reusability and extensibility in object-oriented programming languages. Journal of Object Oriented Programming 1(1), </booktitle> <pages> 12-35. </pages>
Reference-contexts: However, inheritance fixes the be-haviour of an object at creation time <ref> (Micallef, 1988) </ref> and is essentially static. In contrast, the polymorphism provided by recombining collections of objects gives late binding of procedure calls, and is a dynamic mechanism.
Reference: <author> Moran, J.P. </author> <title> (1988) SunOS virtual memory implementation. </title> <booktitle> Conf. Proc. of European Unix User Group (April), </booktitle> <pages> 285-300. </pages>
Reference-contexts: Access control is at the page level. However, the implementation of virtual memory in the SunOS kernel has the concept of a mapped object. This kernel-implemented mapping is actually called a segment: "a segment describes a contiguous mapping of virtual addresses onto some underlying entity" <ref> (Moran, 1988) </ref> 12 . The segment has become a means of logically grouping pages together. Its major role is to provide a mechanism for accessing the mapped object (usually a file) when a page fault occurs on an address within the segment.
Reference: <author> Morris, D. and Ibbett, R.N. </author> <title> (1979) The MU5 Computer System. </title> <publisher> MacMillan Press. </publisher>
Reference-contexts: Such systems can be termed language paradigm-specific and are dealt with in Section 6. Other systems allow users to determine the interface: Customisable kernels, dating back to MU5 <ref> (Morris and Ibbett, 1979) </ref>, can provide for static customisa-tion at build-time (Section 7). In Section 8, the so-called `nanokernels' (Lazowska, 1992) are described. <p> This customisation may be for a particular hardware port, or may be change the behaviour of the kernel to specialise it for a particular purpose. These systems exhibit the `operating system family' approach. Three systems will be discussed: MU5 <ref> (Morris and Ibbett, 1979) </ref>, x-kernel (Hutchinson and Peterson, 1988) and Choices (Russo and Campbell, 1989). The MU5 operating system, intended to run on a range of systems from single processor to a network of several processors, is reminiscent of the Mach/Chorus approach.
Reference: <author> Mullender, S.J., G. van Rossum, A.S. Tanenbaum, R. van Renesse and H. </author> <title> van Staveren (1990) Amoeba A distributed operating system for the 1990s. </title> <booktitle> IEEE Computer 23, </booktitle> <pages> 44-53. </pages>
Reference-contexts: Rather it was aimed at experimenting with new operating system facilities for distributed computing (Douglis et al., 1991). However, Amoeba does have a UNIX emulation library and a session server which handles state information when necessary <ref> (Mullender et al., 1990) </ref> 24 . Mach and Chorus are intended to support existing operating system interfaces which can reside together as collections of user-level servers (`subsystems' in Chorus terminology).
Reference: <author> Okamoto, T., H. Segawa, S.H. Shin, H. Nozue, K. Maeda, M. </author> <title> Saito (1992) A micro kernel architecture for next generation processors. </title> <booktitle> Proc. of Usenix Workshop on Micro-kernels and Other Kernel Architectures (April), </booktitle> <pages> 83-94. </pages>
Reference-contexts: However, virtual address translations will be the same in all protection domains, facilitating sharing. The three systems discussed here are the Opal system (Koldinger et al., 1992), the Rice system (Carter et al., 1992) and the Toshiba system <ref> (Okamoto et al., 1992) </ref>. 9.1 Single-level store The Opal system (Koldinger et al., 1992) is an operating system design which supports a single global virtual address space that maps all primary and secondary store in a 41 The hardware supported only a 48-bit physical address but when an object is created,
Reference: <author> Organick, E.I. </author> <title> (1972) The Multics system: An examination of its structure. </title> <publisher> The MIT Press. </publisher>
Reference-contexts: There arise protection problems: (a) May a particular process share a particular segment? Permissions may be associated with a named segment; where this is a file, for example in Multics <ref> (Organick, 1972) </ref>, those permissions will be the file permissions. (b) Given that a segment is part of the address space of a process, how may it be accessed? Descriptor-based systems, such as Multics and VME (Warboys, 1980), implement a hierarchy of protection rings. <p> If a system call descriptor is involved, then the indirection between the currency and the referenced PLT is via the virtual machine-local System Call Table and access rights checking mechanism. It is interesting that the original two-ring supervisor intended for Multics was abandoned on the grounds of efficiency <ref> (Organick, 1972) </ref>. The advantages of some kind of vertical modularity within the kernel did not apparently outweigh the overheads of boundary-crossing 16 . <p> If the call is allowed, the Gatekeeper calls a master-mode descriptor base register switching routine to point to the segment in the target ring. 16 The round-trip ring crossing during a procedure call on Multics was of the order of 2 to 3 milliseconds <ref> (Organick, 1972) </ref>.
Reference: <author> Paciorek, N., S. Lo Verso, A. </author> <title> Langerman (1991) Debugging multiprocessor operating system kernels. </title> <booktitle> Usenix Association Proc. Summer Symp. on Experiences with Distributed and Multiprocessor Systems (SEDMSII), </booktitle> <pages> 185-201. </pages>
Reference-contexts: Either all interrupt-handling work can be passed to a dedicated kernel process which acquires locks in the usual way, or locks are associated with interrupt levels, so that interrupt handling can synchronise directly with process activity <ref> (Paciorek et al., 1991) </ref>. The capability-based Hydra kernel ran on a multiprocessor machine with one copy of the kernel so that many processors could be executing kernel code simultaneously. The designers decided to have fine-grain locks, by locking data items rather than code, and have a large number of locks.
Reference: <author> Perry, N. </author> <title> (1987) Hope+. Internal Document. </title> <institution> IC/FPR/LANG/2.5.1/7, Department of Computing, Imperial College, </institution> <address> London. </address>
Reference-contexts: Scheduling, for example, was based on the root packets of active computational subgraphs. Store allocation was based on pages and packets. Much of the functionality associated with conventional operating system kernels resided in this hardware ADT. The hardware-independent part of the operating system kernel was written in Hope+ <ref> (Perry, 1987) </ref>, with annotations to handle state, and so ran on the graph reduction abstract machine. This part of the operating system (called the Flagship `kernel') could potentially benefit from implicit parallelism in the Hope+ program.
Reference: <author> Peterson, L., N. Hutchinson, S. O'Malley and H. </author> <title> Rao (1990) The x-kernel: A platform for accessing internet resources. </title> <booktitle> IEEE Computer 23(5), </booktitle> <pages> 23-33. </pages> <booktitle> 36 Pierson, D.L. (1989) Integrating parallel Lisp with modern UNIX-based operating sys-tems. </booktitle> <volume> LNCS 441, </volume> <pages> 312-315. </pages>
Reference-contexts: The x-kernel is an operating system kernel for networks of machines <ref> (Peterson et al., 1990) </ref>. It supports a library of protocols so that it can access different network resources (such as RPC and file access) with different protocol combinations. The x-kernel has a fixed process manager and store manager, whose designs support the needs of communications. <p> The version of x-kernel described in 1990 statically loaded all protocols to be configured into a given kernel. Howver, it was intended to enhance the system for dynamic loading of protocols <ref> (Peterson et al., 1990) </ref>. 39 18K, half of which was paged, and half resident. 22 Choices achieves code reuse and customisation using both inheritance and by build-ing new object collections from existing classes. However, inheritance fixes the be-haviour of an object at creation time (Micallef, 1988) and is essentially static.
Reference: <author> Pike, R., D. Presotto, K. Thompson and H. </author> <title> Trickey (1991) Designing Plan 9. </title> <journal> Dr. Dobb's J. </journal> <volume> 172, </volume> <pages> 49-60. </pages>
Reference-contexts: et al, 1981). 17 The cost of system calls is similar to the domain call in the iAPX 432, varying from a minimum of 70 microseconds on Sprite on a Sun 3/60 (Douglis et al., 1991), to 7 microseconds for a null system call on Plan 9 on a MIPS <ref> (Pike et al., 1991) </ref>. 18 Remote store access involves activity over some internal network. 10 1. single multi-threaded kernel with locks on shared data structures. 2. multiple kernels with communication. Variations of these exist: 1. On a conventional shared-store multiprocessor machine, the single kernel with locks is generally used. 2.
Reference: <author> Rashid, R. </author> <title> (1987) Designs for parallel architectures. Unix Review (April), </title> <type> 36-43. </type>
Reference: <author> Rashid, R., A. Tevanian Jr., M. Young, D. Golub, R. Baron, D. Black, W.J. Bolosky and J. </author> <title> Chew (1988) Machine-independent virtual memory management for paged uniprocessor and multiprocessor architectures. </title> <journal> IEEE Transactions on Computers 37(8), </journal> <pages> 896-908. </pages>
Reference-contexts: All three systems view an operating system as a set of servers running on top of a small microkernel. 23 Sprite has a multi-threaded kernel. 13 1. background and system image Mach was first ported to uniprocessors and multiprocessors <ref> (Rashid et al., 1988) </ref>, and because of this history, is generally regarded as a multiprocessor, rather than a multicomputer, operating system.
Reference: <author> Rothnie, J. </author> <title> (1992) Kendall Square Research introduction to the KSR1. </title> <booktitle> Proc. of the 1992 DAGS/PC Symp. </booktitle> <month> (June), </month> <pages> 200-210. </pages>
Reference-contexts: The aim is to minimise interaction between nodal kernels by maximising local activity. Where global activity does occur, the message-passing involved is hidden by the hardware VSM mechanism. There is an interesting comparison with the KSR machine <ref> (Rothnie, 1992) </ref> which is physically a multicomputer, but supports VSM in hardware. Whereas the multicomputer VME emphasises multiple nodal kernel instances with some shared data, KSR emphasises a single kernel instance with some private nodal data. There is a single instance of the OSF/1 kernel 22 .
Reference: <author> Rozier, M., V. Abrossimov, F. Armand, I. Boule, M. Gien, M. Guillemont, F. Herrmann, C. Kaiser, S. Langlois, P. Leonard and W. </author> <title> Neuhauser (1988) CHORUS distributed operating systems. </title> <type> Chorus Systemes Technical Report CS/TR-88-7.6. </type>
Reference: <author> Russo, </author> <title> V.F., and R.H. Campbell (1989) Virtual memory and backing store management in multiprocessor operating systems using object-oriented design techniques. </title> <booktitle> OOPSLA '89 Proceedings (October), </booktitle> <pages> 267-278. </pages>
Reference-contexts: These systems exhibit the `operating system family' approach. Three systems will be discussed: MU5 (Morris and Ibbett, 1979), x-kernel (Hutchinson and Peterson, 1988) and Choices <ref> (Russo and Campbell, 1989) </ref>. The MU5 operating system, intended to run on a range of systems from single processor to a network of several processors, is reminiscent of the Mach/Chorus approach. <p> Johnson and Russo (1991) reported that Choices consisted of process mangement, VM management, file systems and networking. Choices was being ported to a distributed store machine <ref> (Russo and Campbell, 1989) </ref>. There are two important issues when considering customisation: 1. Whether the way in which the customisable components of the operating system are implemented facilitates reuse of code. In MU5, the modules which make up the operating system are source files.
Reference: <author> Russo, V., G. Johnston and R. </author> <title> Campbell (1988) Process management and exception handling in multiprocessor operating systems using object-oriented design techniques. </title> <booktitle> OOPSLA '88 Proceeedings (September), </booktitle> <pages> 248-258. </pages>
Reference-contexts: The x-kernel views everything as a protocol, including user processes and devices. Choices is an operating system for multiprocessor architectures, based on the idea of using object-oriented programming and inheritance to build a kernel from layers that are collections of objects <ref> (Russo et al., 1988) </ref>. Johnson and Russo (1991) reported that Choices consisted of process mangement, VM management, file systems and networking. Choices was being ported to a distributed store machine (Russo and Campbell, 1989). There are two important issues when considering customisation: 1. <p> In contrast, in Choices, the implementation language is C++. Thus Choices achieves a policy and mechanism split (orthogonally to the user/kernel division) by defining behaviour using abstract classes, and implementation using concrete classes, a technique which depends on inheritance <ref> (Russo et al., 1988) </ref>. A particular system component can be specialised for a particular requirement by deriving a subclass from a class representing an abstraction of that component. In addition to inheritance, Choices also reuses code by structuring subsystems as collections of connected objects (Johnson and Russo 1991). . 2.
Reference: <author> Saltzer, J.H. </author> <title> (1978) Naming and binding of objects. </title> <publisher> LNCS 60, </publisher> <pages> 99-208. </pages>
Reference-contexts: Sharing of segments by more than one process may be facilitated by an indirection mechanism at each invocation of a shared code segment, a process-specific linkage segment is produced. All linkage segments for a given procedure have the same layout (as determined by the compiler <ref> (Saltzer, 1978) </ref>) but the bindings to other segments may differ from process to process. The linkage segment serves as an indirection from the shared code virtual addresses to the private, process-local segment to be substituted for the virtual address (possibly via the process segment table entry).
Reference: <author> Scott, </author> <title> M.L., T.J. LeBlanc, and B.D. Marsh (1989) Design Rationale for Psyche, a general-purpose multiprocessor operating system. </title> <institution> University of Rochester Computer Science and Engineering Research Review 1988-1989, </institution> <month> 5-13. </month>
Reference-contexts: The point is that the operating system should provide mechanism routines only, allowing all policy into the runtime systems. An approach like this is found in the Psyche operating system for multiprocessor systems <ref> (Scott et al., 1989) </ref>. This is a minimal kernel specifically designed to support multiple programming models. Psyche provides a single address space, protection, and, as mentioned above, support for user-level scheduling. The single address space abstraction provided by Psyche provides for sharing. <p> Whilst this is acceptable for a NUMA architecture, Psyche needs to be extended to support multicomputers. Networks could be incorporated by either using a shared virtual memory approach or by having special network interface realms to support cross-machine operations <ref> (Scott et al., 1989) </ref>. 9 Single address space Several systems have been constructed with a single, global address space. Flagship and Psyche have already been mentioned. A capability-based machine, the IBM/38 supported a flat, single-level 64-bit virtual address space 41 .
Reference: <author> Scott, </author> <title> M.L., T.J. LeBlanc, and B.D. </title> <booktitle> Marsh (1990) Multi-model parallel programming in Psyche. Proc 2nd ACM SIGPLAN Symp on Principles and Practice of Parallel Programming (March, </booktitle> <year> 1990), </year> <pages> 70-78. </pages>
Reference-contexts: However, in Psyche, which runs on a multiprocessor NUMA architecture, the kernel issues a warning to the thread package that it is about to be preempted. In line with Psyche's aim of providing multimodel interworking <ref> (Scott et al., 1990) </ref>, Psyche allows for the coexistence and interaction of different thread packages. The designer of Psyche intended for the provision of policy by the writers of libraries and language runtime systems. <p> The limitations of Psyche are related to its NUMA design, in contrast to Mach, Chorus and Amoeba which will operate on loosely-coupled machines transparently. For example, IPC in Psyche is via invocation of operations of realms shared between more than one protection domain <ref> (Scott et al., 1990) </ref>. Whilst this is acceptable for a NUMA architecture, Psyche needs to be extended to support multicomputers.
Reference: <author> Sechrest S. and Y. </author> <title> Park (1991) User-level physical memory management for Mach. </title> <booktitle> Usenix Association Mach Symp., </booktitle> <month> Nov, </month> <year> 1991 </year> <month> 189-199. </month>
Reference-contexts: The operating system may not provide the user with sufficient control of the hardware. A general-purpose operating system such as Unix has facilities such as file system and process management designed to serve time-sharing users. Data management and persistent object stores need sophisticated use of caching for performance <ref> (Sechrest and Park, 1991) </ref>. The caching activities and physical memory management of the operating system may be too inflexible to support these. There is a mismatch between the file organisa-tions provided by an operating system and those needed by a database system (Unwalla and Kerridge, 1992).
Reference: <author> Skelton, C.J., C. Hammer, M. Lopez, M.J. Reeve, P. Townsend and K.F. Wong (1992) EDS: </author> <title> A parallel computer system for advanced information processing. </title> <publisher> LNCS 605, </publisher> <pages> 3-20. </pages>
Reference-contexts: However, the example of this approach which will be dealt with in this section is the Flagship system. The Flagship system is a parallel packet-based graph reduction multicomputer machine 29 (Banach et al., 1988). The European Declarative System (EDS) multicomputer system <ref> (Skelton et al., 1992) </ref> provides an example of the second approach. These systems have basically similar hardware 30 , and both are intended to run declarative paradigm languages in a parallel environment.
Reference: <author> Stevens, W.R. </author> <title> (1992) Advanced programming in the Unix environment. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: These correspond to NORMA architectures of Rashid (1987). There are two basic implementations: 14 The number of system calls in Version 7 Unix was about 50; there are around 120 system calls in SVR4 <ref> (Stevens, 1992) </ref>. 15 Access to an address of a segment in another ring may cause a fault. The `Fault Interceptor' calls a ring-0 module, the `Gatekeeper' to check rights.
Reference: <author> Stonebraker, M. </author> <title> (1981) Operating system support for database management. </title> <booktitle> Comms ACM 24(7), </booktitle> <pages> 412-418. </pages> <note> 37 Stonebraker, </note> <author> M., J. Woodfill, J. Ranstrom, M. Murphy, M. Meyer and E. </author> <title> Allman (1983) Performance enhancements to a relational database system. </title> <journal> ACM Transactions on Database Systems 8(2), </journal> <pages> 167-185. </pages>
Reference: <author> Tam, M., J.M. Smith and D.J. </author> <title> Farber (1990) A taxonomy-based comparison of several distributed shared memory systems. </title> <booktitle> ACM Operating System Review 24(3), </booktitle> <pages> 40-67. </pages>
Reference: <author> Tanenbaum, A.S., R. van Renesse, H. van Staveren, G.J. Sharp, S.J. Mullender, J. Jan-son and G. </author> <title> van Rossum (1990) Experiences with the AMOEBA distributed operating system. </title> <booktitle> Comms ACM 33(12), </booktitle> <pages> 46-63. </pages>
Reference-contexts: Chorus version 3 changed Chorus from being a UNIX-compatible distributed operating system to being a distributed microkernel (Guillemont et al., 1991). Both Mach and Chorus now provide full UNIX emulation as user-level servers. Unlike Mach and Chorus, Amoeba was not intended to provide UNIX binary compatibility <ref> (Tanenbaum et al., 1990) </ref>. Rather it was aimed at experimenting with new operating system facilities for distributed computing (Douglis et al., 1991). However, Amoeba does have a UNIX emulation library and a session server which handles state information when necessary (Mullender et al., 1990) 24 . <p> These servers cooperate to provide UNIX semantics. Similarly, the Amoeba operating system is provided by user-level servers running on a microkernel. Though Amoeba provides default servers, it is intended that these are user-replaceable <ref> (Tanenbaum et al., 1990) </ref>. The provision of a standard operating system interface obviously makes the system more acceptable to users because of the reuse of utility software this allows. <p> This local state would normally be saved in a process control block and thread kernel stack, and so less store is needed by the kernel (Draves et al., 1991). Chorus implements preemptive scheduling on thread absolute priority 27 (Chorus, 1992). Thread scheduling within a process in Amoeba is cooperative <ref> (Tanenbaum et al., 1990) </ref>, with round-robin time sharing between processes (Douglis et al., 1991). (b) Virtual memory The valid regions of an address space of processes of the three systems are those which have been mapped to objects. <p> Segments in Amoeba are managed by the kernel, though a segment identifier (actually a capability) can be passed between processes and the segment mapped and unmapped by passing this capability to the kernel <ref> (Tanenbaum et al., 1990) </ref>. (c) IPC Threads communicate via messages sent to ports identified by global identifiers. Servers are identified by their port. Amoeba kernel provides only RPC for point-to-point communication on the grounds that send and receive primitives lead to `spaghetti' (Tanenbaum, 1992).
Reference: <author> Tanenbaum, </author> <title> A.S. </title> <booktitle> (1992) Modern operating systems. </booktitle> <publisher> Prentice Hall. </publisher>
Reference-contexts: Servers are identified by their port. Amoeba kernel provides only RPC for point-to-point communication on the grounds that send and receive primitives lead to `spaghetti' <ref> (Tanenbaum, 1992) </ref>. There are two components to IPC: a local, strictly IPC, component, and a remote, networking, component. The three microkernels being considered show a gradation of kernel involvement with these components. <p> The kernel provides the mechanism only. This placing of policy in the server provides more flexibility, and allows implementation of various policies, for example gang scheduling (Black, 1990). In Amoeba, processor allocation is determined by a user-level `run server' which has access to CPU loading (and other) information <ref> (Tanenbaum, 1992) </ref>. Chorus allows servers to set the creation sites of new processes, and so could support the provision of user-level processor allocation. (f) Access to operating system facilities There are two possible approaches to the provision of an interface to the operating system largely implemented as user-level servers.
Reference: <author> Unwalla, M. and J. </author> <title> Kerridge (1992) Control of a large massively parallel database machine using SQL catalogue extensions, and a DSDL in preference to an operating system. </title> <publisher> LNCS 618, </publisher> <pages> 138-155. </pages>
Reference-contexts: The caching activities and physical memory management of the operating system may be too inflexible to support these. There is a mismatch between the file organisa-tions provided by an operating system and those needed by a database system <ref> (Unwalla and Kerridge, 1992) </ref>. For example, building INGRES on top of the existing UNIX file system caused problems (Stonebraker et al., 1983) 3 . <p> sequential access, random allocation is undesirable; Unix uses indirect blocks which must be read on access to a file, presenting an overhead; Unix block size may be inappropriate for a database. 2 implement their own storage access mechanism synchronously with the system calls us-ing low level operating system interface routines <ref> (Unwalla and Kerridge, 1992) </ref>. Process scheduling and inter-process communication can also cause problems for databases due to the overheads associated with task switching and message passing. There is also the problem caused by the operating system descheduling a process holding a short-term lock which will be required by other processes.
Reference: <author> Warboys, </author> <title> B.C. (1980) VME/B a model for the realisation of a total system concept. </title> <journal> ICL Technical Journal, </journal> <pages> 132-146. </pages>
Reference-contexts: be associated with a named segment; where this is a file, for example in Multics (Organick, 1972), those permissions will be the file permissions. (b) Given that a segment is part of the address space of a process, how may it be accessed? Descriptor-based systems, such as Multics and VME <ref> (Warboys, 1980) </ref>, implement a hierarchy of protection rings. Procedure calls across ring 6 `Operating system' in the sense of `routines which a user-program can use to control the hardware' 6 boundaries are validated by the kernel.
Reference: <author> Ward, M. and P. </author> <title> Townsend (1990) EDS hardware architecture. </title> <publisher> LNCS 457, </publisher> <pages> 816-827. </pages>
Reference-contexts: However, the approach to system software is very different in the two systems. 6.1 Operating system implementation The lowest level of the EDS system software, the Primitive Machine Interface, presents an abstraction of the hardware to the kernel <ref> (Ward and Townsend, 1990) </ref>. The upper 29 In such a graph reduction machine, a computational expression is represented as a graph whose nodes are packets (linear chunks of store). A packet can contain code, base values, or pointers to other packets. The pointers form the arcs of the graph. <p> As noted above, a virtual address space can be distributed over several nodes, using software-implemented VSM. Thus, regions of the virtual address space can be shared irrespective of nodal distribution. Special hardware on each node allows copying of 128 byte `sectors' rather than entire 4K pages <ref> (Ward and Townsend, 1990) </ref>. Thus, remote store access is supported at three levels in the EDS machine (Istavrinos and Borrmann, 1990): 1. Page copying and remote update is provided in the processor architecture. 2.
Reference: <author> Watson, P. </author> <title> (1987) The Flagship Basic Execution Mechanism. Flagship Document FS/MU/PW/018-87, </title> <institution> Department of Computer Science, University of Manchester. </institution>
Reference-contexts: In contrast to EDS, Flagship kernel had a novel design. At a low level in the system, a Basic Execution Mechanism provided a graph reduction (GR) abstract machine. Particular actions were associated with different packet types 32 <ref> (Watson, 1987) </ref>. As in EDS, there is a hardware-dependent layer. The low-level, hardware-dependent resource allocation routines 33 were implemented imperatively as a `hardware ADT' on each node. The operations of this hardware object provided access to the resources of the packet-based graph reduction abstract machine.
Reference: <author> Watson, P. </author> <title> (1990) The FLAGSHIP parallel machine. In Multiprocessor Parallel Architectures, </title> <editor> eds T.J. Fountain and M.J. </editor> <booktitle> Shute, </booktitle> <pages> 57-82. </pages>
Reference-contexts: The interpretation of the address was done by the Basic Execution Mechanism of the system. If the address referred to the store of a remote node, then the computation on that subgraph is suspended, and a request for a copy is sent to the remote node <ref> (Watson, 1990) </ref>. During message latencies, the processor does other work. This type of access to global addresses represents data shipping. Flagship also implemented function shipping for computational graphs involving access to state 35 .
Reference: <author> Weiser, M., A. Demers, and C. </author> <title> Hauser (1989) The Portable Common Runtime Approach to Interoperability. </title> <booktitle> Proc. 12th ACM Symp. on Operating System Principles, </booktitle> <pages> 114-122. </pages>
Reference-contexts: Language runtime system (RTS) implementations are necessary because operating system abstractions are generally too low level for direct use by a language. The requirements on the operating system abstractions vary with the richness of the language <ref> (Weiser et al., 1989) </ref>, so that it is difficult for a single set of abstractions to support all languages. In general, an RTS specialises the operating system abstract machine for use by a language.
Reference: <author> Wilkes, </author> <title> M.V. (1968) Time-sharing computer systems. </title> <publisher> MacDonald. </publisher>
Reference-contexts: It was 1K 48 bit words long (Warboys, personal communication). In early time-sharing systems the programs that performed various administrative or switching functions were known collectively as the supervisor <ref> (Wilkes, 1968) </ref>. Such supervisors were resident in core, and were small; the supervisor code for the Dartmouth Time-Sharing Computer System was 9.5K in size, some running on the master and some on the slave machine. (Kurtz and Lochner, 1965). <p> Interestingly, it was recognised early that a scheduling algorithm designed to suit the needs of one community of users would not necessarily be suitable for another community <ref> (Wilkes, 1968) </ref>. The complexity and size of the supervisor code increased with multi-programming. Hardware with base-limit registers for addressing with relocation gave the facility for segmentation; segmentation facilitated sharing and required protection mechanisms.
Reference: <author> Wong, K-F and M. </author> <title> Paci (1992) Performance evaluation of an OLTP application on the EDS database server using a behavioural simulation model. In Parallel Processing and Data Management Ed P. Valduriez, </title> <publisher> Chapman and Hall, </publisher> <pages> 317-350. </pages>
Reference-contexts: This provides a specific example of the trend to `unbundle' kernel interfaces to remove policy. The second component of the EDS kernel interface is a set of primitives which support a UNIX operating system interface <ref> (Wong and Paci, 1992) </ref>. Thus the EDS kernel is intended to support directly both a general-purpose operating system and specific language RTSs. In contrast to EDS, Flagship kernel had a novel design. At a low level in the system, a Basic Execution Mechanism provided a graph reduction (GR) abstract machine. <p> The implicit parallelism obtained from the GR machine was able to be utilised by the operating system kernel itself 34 . 31 The languages are able to interwork <ref> (Wong and Paci, 1992) </ref>. 32 New computational models could be implemented by adding new packet types and defining the behaviour of the system when reducing a graph involving packets of those types. 33 These routines deal with node-local activity and would not benefit from parallel execution. 34 There is a nomenclature
Reference: <author> Wulf, W., E. Cohen, W. Corwin, A. Jones, R. Levin, C. Pierson and F. </author> <title> Pollack (1974) HYDRA: The kernel of a multiprocessor operating system. </title> <booktitle> Comms ACM 17(6), </booktitle> <pages> 337-345. </pages>
Reference-contexts: Thus the descriptor-based PLT is equivalent to the capability-based BCS in representing an object. However, in capability systems, for example Hydra <ref> (Wulf et al, 1974) </ref>, it is possible to create new types of object and to incorporate them into the system. Descriptor-based systems place kernel in the most privileged protection ring, whereas capability-based systems have a single privilege level.
Reference: <author> Wulf, W.A., R. Levin and S.P. </author> <title> Harbison (1981) HYDRA/C.mmp, an experimental computer system. </title> <publisher> McGraw-Hill. </publisher> <pages> 38 </pages>
Reference-contexts: Descriptor-based systems place kernel in the most privileged protection ring, whereas capability-based systems have a single privilege level. Thus capability-based systems facilitate the addition of user-level policy to the operating system. Indeed it was one of the main aims of the Hydra project to support this policy/mechanism split <ref> (Wulf et al., 1981) </ref>. The protection of operating system code in capability systems uses the same mechanisms as user code protected procedures. There is no system call in capability systems. <p> This contrasts to the 20 to 30 millisecond cross-domain call on Hydra <ref> (Wulf et al., 1981) </ref> and, at the other extreme, to a hardware-implemented domain switch on the Intel iAPX 432 of 65 microseconds (Kahn et al, 1981). 17 The cost of system calls is similar to the domain call in the iAPX 432, varying from a minimum of 70 microseconds on Sprite <p> The designers decided to have fine-grain locks, by locking data items rather than code, and have a large number of locks. There were `literally thousands of lock cells' in Hydra <ref> (Wulf et al., 1981) </ref>. Other synchronisation mechanisms, semaphores and ports, were also provided. The iMax operating system of the iAPX 432 multiprocessor similarly relies on explicit synchronisation within the system (Kahn et al., 1981). Descriptor-based VME has operated on the multiprocessor 2900 hardware and on the multicomputer Series 39 hardware. <p> These microkernels are intended to support policy provided by user-level libraries. The Hydra system, mentioned above, was an early system which was concerned with presenting a policy/mechanism split and so will be discussed first. The Hydra kernel provided mechanisms for protection and minimal policy <ref> (Wulf et al., 1981) </ref>. It supported the creation and manipulation of new object types, and instances of types, so that the operating system could be extended by user-level objects that implement policy. The kernel provided low-level dispatching mechanisms only. <p> The designers of the Hydra system felt that, in retrospect, they should not have chosen 24 However, there are differences to UNIX; the default file and directory servers, for example, have non-UNIX semantics (Amoeba, 1992). 14 to implement a general-purpose, time-shared system <ref> (Wulf et al., 1981) </ref>. The time to build the additional software for such a system, and their lack of provision of a well thought out user interface command language, impaired the acceptance of Hydra by the user community. 3.
References-found: 88

