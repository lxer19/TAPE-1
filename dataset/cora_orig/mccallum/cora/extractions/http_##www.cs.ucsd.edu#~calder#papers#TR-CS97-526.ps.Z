URL: http://www.cs.ucsd.edu/~calder/papers/TR-CS97-526.ps.Z
Refering-URL: http://www.cs.ucsd.edu/~calder/papers.html
Root-URL: http://www.cs.ucsd.edu
Email: calder@cs.ucsd.edu grunwald@cs.colorado.edu  
Title: The Precomputed Branch Architecture  
Author: Brad Calder Dirk Grunwald 
Address: 9500 Gilman Drive Campus Box 430 La Jolla, CA 92093-0114 Boulder, CO 80309-0430  
Affiliation: Dept. of Computer Science and Engineering Dept. of Computer Science University of California, San Diego University of Colorado  
Abstract: UCSD Technical Report CS97-526, March 1997 Abstract Accurate instruction fetch and branch prediction is increasingly important on today's superscalar architectures. Fetch prediction is the process of determining the next instruction to request from the memory subsystem. Branch prediction is the process of predicting the likely out-come of branch instructions. A branch target buffer (BTB) is often used to provide target addresses for taken branches and to predict the destination of indirect jumps. Using a BTB avoids the delay needed to recalculate the destination address and reduces the misfetch penalty. However, an effective branch target buffer can be large and can possibly increase the cycle time of a processor. We propose that a design used in older computers, such as the PDP-8, be used in modern architectures instead of a BTB design. The compiler would pre-compute the branch destination for most branch instructions, allowing the branch information to be stored with the instruction. We consider computing branch destinations at link time and as instructions are fetched into the instruction cache; both alternatives offer similar performance with different advantages. A very small branch target buffer is still useful to predict indirect branches, which can not be pre-computed. Our results show that the Precomputed-Branch architecture performs better than an architecture using only a branch target buffer, and has significant hardware savings. This is particularly true for larger programs more representative of modern applications.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. A. Abu-Sufah, D. J. Kuck, and D. H. Lawrie. </author> <title> On the performance enhancement of paging systems through program analysis and transformation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30(5):341-356, </volume> <month> May </month> <year> 1981. </year>
Reference-contexts: Therefore, all intra-procedural branches will be compiled as pre-computed branches. There are myriad ways to partition programs, and a number of alternatives have been examined in the effort to reduce page faults <ref> [1, 2, 15, 13] </ref>, and instruction cache conflicts [16, 25, 30]. The goals of our study are different than these other studies; we are more interested in reducing the number of indirect jumps than reducing cache conflicts and paging.
Reference: [2] <author> Jean Loup Baer and R. Caughey. </author> <title> Segmentation and optimization of programs from Cyclic Structure Analysis. </title> <booktitle> In Proc. AFIPS, </booktitle> <pages> pages 23-36, </pages> <year> 1972. </year>
Reference-contexts: Therefore, all intra-procedural branches will be compiled as pre-computed branches. There are myriad ways to partition programs, and a number of alternatives have been examined in the effort to reduce page faults <ref> [1, 2, 15, 13] </ref>, and instruction cache conflicts [16, 25, 30]. The goals of our study are different than these other studies; we are more interested in reducing the number of indirect jumps than reducing cache conflicts and paging.
Reference: [3] <author> Thomas Ball and James R. Larus. </author> <title> Branch prediction for free. </title> <booktitle> In 1993 SIGPLAN Confernce on Programming Language Design and Implementation, </booktitle> <pages> pages 300-313. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time heuristics <ref> [3, 9, 21, 24, 32] </ref> to profile-based methods [10, 14, 24, 37, 43]. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use heuristics based on the direction of the branch target (forward or backward) or instruction opcode.
Reference: [4] <author> M. Berry. </author> <title> The Perfect Club Benchmarks: Effective performance evaluation of supercomputers. </title> <journal> The International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall </month> <year> 1989. </year>
Reference-contexts: We instrumented the programs from the SPEC92 benchmark suite, the Perfect-Club <ref> [4] </ref>, and object-oriented programs written in C++. We used ATOM [34] to instrument the programs; due to the structure of ATOM, we did not need to record traces and could trace the complete execution of all the programs.
Reference: [5] <author> Brad Calder and Dirk Grunwald. </author> <title> Fast & accurate instruction fetch and branch prediction. </title> <booktitle> In 21st Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 2-11. </pages> <publisher> ACM, </publisher> <month> April </month> <year> 1994. </year>
Reference-contexts: This is especially true for object-oriented programs containing a large number of indirect jumps. We originally proposed the use of a Precomputed-Branch architecture in <ref> [5] </ref>. In this previous study we focused on improving the performance of the BTB design by examining different BTB configurations and update policies, and in addition we proposed the Precomputed-Branch architecture as an alternative to the BTB. <p> We call designs that associate branch prediction information with the branch target buffer a coupled branch architecture, since the conditional branch prediction information is associated with the BTB and can only be used if a branch hits in the BTB. In a related paper <ref> [5] </ref>, we showed that decoupled branch architectures can provide slightly better performance than coupled branch architectures. A decoupled architecture separates the conditional branch prediction information from the branch target buffer, so that it can be used to correctly predict a branch even when that branch is not in the BTB. <p> In the remainder of this paper, we only consider decoupled branch architectures. 3 The Design of Two Branch Architectures We used trace-driven simulation to compare the Precomputed-Branch architecture to a design that makes aggressive use of branch target buffers. We simulated the decoupled branch architecture proposed in <ref> [5] </ref>, because this architecture provides better overall branch performance than the coupled models proposed in [41] for the design space considered in this paper.
Reference: [6] <author> Brad Calder and Dirk Grunwald. </author> <title> Reducing branch costs via branch alignment. </title> <booktitle> In 6th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 242-251. </pages> <publisher> ACM, </publisher> <year> 1994. </year>
Reference-contexts: Other programs, such as cfront and gcc contain a great number of conditional branches, and many of those branches are difficult to predict. The prediction accuracy for these programs can be improved by using larger pattern history tables, or by various compiler transformations <ref> [6, 25, 43] </ref>. One advantage of the Precomputed-Branch architecture, particularly for larger programs representative of actual applications, is that it is less susceptible to capacity misses for fetch prediction.
Reference: [7] <author> Brad Calder and Dirk Grunwald. </author> <title> Reducing indirect function call overhead in C++ programs. </title> <booktitle> In Proceedings of the 21st Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 397-408, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Alternatively, we can use profile-based prediction of indirect function calls, which has been shown to be effective and important for the C++ programming language <ref> [7] </ref>, where such branches occur frequently. 7 (a) Traditional Sign-Extended PC-Relative Branch (b) Compiler-Assisted Sign-Extended Branch (c) Precomputed-Branch (Not Sign-Extended) 8 3.3 Computing the Branch Target Traditional branch architectures use a PC-relative displacement; Figure 3 (a), modeled after the diagrams in [20], schematically illustrates the process. <p> This program contains a large number of indirect jumps, as shown by the detailed program information in Table 1, but those indirect jumps are fairly predictable. The predictability of indirect jumps in C++ programs was shown in an earlier study <ref> [7] </ref>, and has been demonstrated for many C++ programs.
Reference: [8] <author> Brad Calder and Dirk Grunwald. </author> <title> Next cache line and set prediction. </title> <booktitle> In 22nd Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 287-296. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1995. </year>
Reference-contexts: architectures [33, 40, 42] combine branch target buffers and other branch prediction mechanisms to reduce both misfetch and mispredict penalties. 3 2.1 Branch Target Buffers Misfetch penalties can be reduced in a number of ways, such as using branch delay slots [24], a table of cache indices for fetch prediction <ref> [8] </ref>, or branch target buffers [21, 22, 29, 32]. A BTB can eliminate misfetch stalls by storing the branch destination. For unconditional branches, indirect jumps or functions calls, this destination can be immediately fetched. For conditional branches, either the fall-through or the destination stored in the BTB is fetched.
Reference: [9] <author> Brad Calder, Dirk Grunwald, Michael Jones, Donald Lindsay, Jim Martin, Michael Mozer, and Benjamin Zorn. </author> <title> Evidence-based static branch prediction using machine learning. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 19(1), </volume> <year> 1997. </year>
Reference-contexts: Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time heuristics <ref> [3, 9, 21, 24, 32] </ref> to profile-based methods [10, 14, 24, 37, 43]. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use heuristics based on the direction of the branch target (forward or backward) or instruction opcode.
Reference: [10] <author> Brad Calder, Dirk Grunwald, and Amitabh Srivastava. </author> <title> The predictability of branches in libraries. </title> <booktitle> In 28th International Symposium on Microarchitecture, </booktitle> <pages> pages 24-34, </pages> <address> Ann Arbor, MI, </address> <month> November </month> <year> 1995. </year> <note> IEEE. </note>
Reference-contexts: Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time heuristics [3, 9, 21, 24, 32] to profile-based methods <ref> [10, 14, 24, 37, 43] </ref>. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use heuristics based on the direction of the branch target (forward or backward) or instruction opcode.
Reference: [11] <author> Brad Calder, Dirk Grunwald, and Benjamin Zorn. </author> <title> Quantifying behavioral differences between C and C++ programs. </title> <journal> Journal of Programming Languages, </journal> <volume> 2(4), </volume> <year> 1994. </year>
Reference-contexts: We selected these programs because we found that the SPECint92 suite did not typify the behavior seen in C++ programs <ref> [11] </ref>, and our original goal was to understand the impact of branch architectures on C++ programs. For these alternate programs, we used sizable inputs that exercised a large part of the program. Table 1 shows the basic statistics for the programs we instrumented.
Reference: [12] <author> David R. Ditzel and Hubert R. McLellan. </author> <title> Branch folding in the CRISP microprocessor: Reducing branch delay to zero. </title> <booktitle> In 14th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 2-9. </pages> <publisher> ACM, ACM, </publisher> <month> June </month> <year> 1987. </year> <month> 27 </month>
Reference-contexts: Branches within the same page were pre-computed, and all other branches required an indirect reference. In the Crisp processor <ref> [12] </ref>, a branch destination is included in every decoded instruction in the instruction cache, resulting in very large instructions - 192 bits. This technique consumes a considerable amount of space and may limit the processor cycle time.
Reference: [13] <author> Domenico Ferrari. </author> <title> Improving locality by critical working sets. </title> <journal> Communications of the ACM, </journal> <volume> 17(11) </volume> <pages> 614-620, </pages> <year> 1974. </year>
Reference-contexts: Therefore, all intra-procedural branches will be compiled as pre-computed branches. There are myriad ways to partition programs, and a number of alternatives have been examined in the effort to reduce page faults <ref> [1, 2, 15, 13] </ref>, and instruction cache conflicts [16, 25, 30]. The goals of our study are different than these other studies; we are more interested in reducing the number of indirect jumps than reducing cache conflicts and paging.
Reference: [14] <author> J. A. Fisher and S. M. Freudenberger. </author> <title> Predicting conditional branch directions from previous runs of a program. </title> <booktitle> In Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 85-95, </pages> <address> Boston, Mass., </address> <month> October </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time heuristics [3, 9, 21, 24, 32] to profile-based methods <ref> [10, 14, 24, 37, 43] </ref>. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use heuristics based on the direction of the branch target (forward or backward) or instruction opcode.
Reference: [15] <author> S. J. </author> <title> Hartley. Compile-time program restructuring in multiprogrammed virtual memory systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 14(11) </volume> <pages> 1640-1644, </pages> <year> 1988. </year>
Reference-contexts: Therefore, all intra-procedural branches will be compiled as pre-computed branches. There are myriad ways to partition programs, and a number of alternatives have been examined in the effort to reduce page faults <ref> [1, 2, 15, 13] </ref>, and instruction cache conflicts [16, 25, 30]. The goals of our study are different than these other studies; we are more interested in reducing the number of indirect jumps than reducing cache conflicts and paging.
Reference: [16] <author> Amir Hashemi, David R. Kaeli, and Brad Calder. </author> <title> Efficient procedure mapping using cache line coloring. </title> <booktitle> In Proceedings of the ACM SIGPLAN '97 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: Therefore, all intra-procedural branches will be compiled as pre-computed branches. There are myriad ways to partition programs, and a number of alternatives have been examined in the effort to reduce page faults [1, 2, 15, 13], and instruction cache conflicts <ref> [16, 25, 30] </ref>. The goals of our study are different than these other studies; we are more interested in reducing the number of indirect jumps than reducing cache conflicts and paging.
Reference: [17] <author> Mark Hill. </author> <title> A case for direct-mapped caches. </title> <journal> IEEE Computer, </journal> <volume> 21(12) </volume> <pages> 25-40, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: Access times are shown for a 128 and 512 entry BTB and a 8K and 32K instruction cache with 32 byte lines. 6.2.2 Impact on Cycle Time The access time for a cache (or a BTB) depends both on the size and the associativity of the design <ref> [17, 31] </ref>. Recall that the branch target buffer requires considerable resources, and is organized as a 4-way associative cache, while the Precomputed-Branch architecture uses information recorded in the instructions.
Reference: [18] <author> Peter Yan-Tek Hsu. </author> <title> Designing the TFP microprocessor. </title> <journal> IEEE Micro, </journal> <volume> 14(2) </volume> <pages> 23-33, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Since the instruction fetch cycle often limits processor performance, designs using a large, associative BTBs may lengthen the cycle time, affecting the performance of the entire processor. In <ref> [18] </ref>, the designers of the TFP (MIPS R8000) microprocessor stated: We evaluated several well-known branch prediction algorithms for layout size, speed, and prediction accuracy.
Reference: [19] <author> David R. Kaeli and Philip G. Emma. </author> <title> Branch history table prediction of moving target branches due to subroutine returns. </title> <booktitle> In 18th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 34-42. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: Other researchers have described inexpensive mechanisms to predict the destination of procedure returns <ref> [19] </ref>. The only remaining branch type requiring a predicted target address for the Precomputed-Branch architecture is an indirect jump, where the destination may be specified by values computed during execution. <p> For function calls (either direct or indirect), the previous function address is stored in the `destination' field of the BTB. This can also be done for return instructions, but a return stack is much more accurate <ref> [19] </ref>. <p> This separates the branch targets that can be pre-computed prior to execution from those that actually need dynamic prediction, such as indirect jumps with multiple targets using an indirect jump buffer and return instructions using the return-stack <ref> [19] </ref>. 26 Acknowledgments We would like to thank Alan Eustace and Amitabh Srivastava for providing ATOM, which greatly simplified our work. We would also like to thank Cliff Young for providing helpful comments. This work was funded in part by NSF grant No.
Reference: [20] <author> Manolis G. H. Katevenis. </author> <title> Reduced Instruction Set Computer Architecture for VLSI. ACM Doctoral Dissertation Award Series. </title> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference-contexts: be effective and important for the C++ programming language [7], where such branches occur frequently. 7 (a) Traditional Sign-Extended PC-Relative Branch (b) Compiler-Assisted Sign-Extended Branch (c) Precomputed-Branch (Not Sign-Extended) 8 3.3 Computing the Branch Target Traditional branch architectures use a PC-relative displacement; Figure 3 (a), modeled after the diagrams in <ref> [20] </ref>, schematically illustrates the process. In the encodings, information in lightly outlined boxes is provided or computed at execution time; for example, in Figure 3 (a), the PC is available during execution. <p> Each branch can directly address instructions at address P C 2 n1 1 : : : P C + 2 n1 . For simplicity, we assume the program counter is always aligned on instruction boundaries, since we are chiefly concerned with architectures with fixed-width instructions. Katevenis <ref> [20] </ref> proposed several branch encodings where the branch displacement field contains the least significant bits of the branch target address. Figure 3 (b), shows one such encoding.
Reference: [21] <author> Johnny K. F. Lee and Alan Jay Smith. </author> <title> Branch prediction strategies and branch target buffer design. </title> <journal> IEEE Computer, </journal> <volume> 21(7) </volume> <pages> 6-22, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: branch target buffers and other branch prediction mechanisms to reduce both misfetch and mispredict penalties. 3 2.1 Branch Target Buffers Misfetch penalties can be reduced in a number of ways, such as using branch delay slots [24], a table of cache indices for fetch prediction [8], or branch target buffers <ref> [21, 22, 29, 32] </ref>. A BTB can eliminate misfetch stalls by storing the branch destination. For unconditional branches, indirect jumps or functions calls, this destination can be immediately fetched. For conditional branches, either the fall-through or the destination stored in the BTB is fetched. <p> Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time heuristics <ref> [3, 9, 21, 24, 32] </ref> to profile-based methods [10, 14, 24, 37, 43]. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use heuristics based on the direction of the branch target (forward or backward) or instruction opcode. <p> The most common variants of this design are 1-bit counter techniques that indicate the direction of the most recent branch mapping to a given prediction bit, and 2-bit counter techniques that yield much better performance for programs with loops <ref> [21, 24, 32] </ref>. These designs use the branch site address as an index into the PHT. Since different branch addresses can index into the same table entry, several conditional branches may share the same prediction information. <p> example, McFarling [23] used an exclusive-or of the program counter and the global history register to scatter the table references, improving the PHT's performance. 2.3 Combining Branch Target Buffers and Branch Prediction Originally, BTB's were used as a mechanism for branch prediction, effectively predicting the prior outcome of a branch <ref> [21, 29, 32] </ref> and providing the target address. Researchers have proposed associating additional branch prediction information with each BTB entry to improve branch prediction [41], and a variation of this technique has been implemented in the Intel Pentium and PentiumPro architectures. <p> This technique consumes a considerable amount of space and may limit the processor cycle time. A mechanism similar to that used in the PDP-8 was used in Control Data and IBM processors, where instructions were optimized to execute within an instruction buffer Lee and Smith <ref> [21] </ref> provide a good survey. By comparison, we rely on the program linker to compensate for the limited branching by pre-computing branch destinations and reducing the number of complex operations (indirect branches).
Reference: [22] <author> David J. Lilja. </author> <title> Reducing the branch penalty in pipelined processors. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 47-55, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: branch target buffers and other branch prediction mechanisms to reduce both misfetch and mispredict penalties. 3 2.1 Branch Target Buffers Misfetch penalties can be reduced in a number of ways, such as using branch delay slots [24], a table of cache indices for fetch prediction [8], or branch target buffers <ref> [21, 22, 29, 32] </ref>. A BTB can eliminate misfetch stalls by storing the branch destination. For unconditional branches, indirect jumps or functions calls, this destination can be immediately fetched. For conditional branches, either the fall-through or the destination stored in the BTB is fetched.
Reference: [23] <author> Scott McFarling. </author> <title> Combining branch predictors. </title> <address> TN 36, DEC-WRL, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: This is used as an index into the 4096-entry table, much as the program counter is used in the prediction history table method. This provides contextual information about particular patterns of branches. Some methods combine the history register with other information. For example, McFarling <ref> [23] </ref> used an exclusive-or of the program counter and the global history register to scatter the table references, improving the PHT's performance. 2.3 Combining Branch Target Buffers and Branch Prediction Originally, BTB's were used as a mechanism for branch prediction, effectively predicting the prior outcome of a branch [21, 29, 32] <p> In this design, the global history register is combined with the program counter using an exclusive-or, and the result is used as the index into the PHT <ref> [23] </ref>. In both the BTB and Precomputed-Branch architecture, we assume the branch type is encoded in the instruction, or pre-decoded and stored in the instruction cache. A 32-entry return address stack is used to predict the outcome of return instructions. 5 Pattern History Table and a Branch Target Buffer. <p> We use the branch execution penalty to compare performance, but also report the misfetch and misprediction penalty. 16 Both architectures used a 4096-entry decoupled 2-level pattern history table, using the extension pro-posed by McFarling <ref> [23] </ref>, where the program counter is XOR-ed with the global history register to form an index into the PHT. In the BTB architecture, we simulated branch target buffers with 4, 16, 32, 64, 128, 256, 512 and an infinite number of entries.
Reference: [24] <author> Scott McFarling and John Hennessy. </author> <title> Reducing the cost of branches. </title> <booktitle> In 13th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 396-403. </pages> <publisher> ACM, </publisher> <year> 1986. </year>
Reference-contexts: Many architectures [33, 40, 42] combine branch target buffers and other branch prediction mechanisms to reduce both misfetch and mispredict penalties. 3 2.1 Branch Target Buffers Misfetch penalties can be reduced in a number of ways, such as using branch delay slots <ref> [24] </ref>, a table of cache indices for fetch prediction [8], or branch target buffers [21, 22, 29, 32]. A BTB can eliminate misfetch stalls by storing the branch destination. For unconditional branches, indirect jumps or functions calls, this destination can be immediately fetched. <p> Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time heuristics <ref> [3, 9, 21, 24, 32] </ref> to profile-based methods [10, 14, 24, 37, 43]. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use heuristics based on the direction of the branch target (forward or backward) or instruction opcode. <p> Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time heuristics [3, 9, 21, 24, 32] to profile-based methods <ref> [10, 14, 24, 37, 43] </ref>. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use heuristics based on the direction of the branch target (forward or backward) or instruction opcode. <p> The most common variants of this design are 1-bit counter techniques that indicate the direction of the most recent branch mapping to a given prediction bit, and 2-bit counter techniques that yield much better performance for programs with loops <ref> [21, 24, 32] </ref>. These designs use the branch site address as an index into the PHT. Since different branch addresses can index into the same table entry, several conditional branches may share the same prediction information.
Reference: [25] <author> Wen mei W. Hwu and Pohua P. Chang. </author> <title> Achieving high instruction cache performance with an optimizing compiler. </title> <booktitle> In 168th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 242-251. </pages> <publisher> ACM, ACM, </publisher> <year> 1989. </year>
Reference-contexts: Therefore, all intra-procedural branches will be compiled as pre-computed branches. There are myriad ways to partition programs, and a number of alternatives have been examined in the effort to reduce page faults [1, 2, 15, 13], and instruction cache conflicts <ref> [16, 25, 30] </ref>. The goals of our study are different than these other studies; we are more interested in reducing the number of indirect jumps than reducing cache conflicts and paging. <p> A similar technique is used in the Depth-First Profile method; a depth-first search orders the nodes, always visiting the out-going edge with the highest call frequency. This Depth-First Profile algorithm is very similar to the procedure layout algorithm proposed by Hwu and Chang <ref> [25] </ref>. The MaxCut partitioning uses a greedy max-cut algorithm to partition the graph using the call frequency to guide the partitioning. This algorithm is very similar to the greedy approach for procedure mapping proposed by Pettis and Hansen [30]. <p> Other programs, such as cfront and gcc contain a great number of conditional branches, and many of those branches are difficult to predict. The prediction accuracy for these programs can be improved by using larger pattern history tables, or by various compiler transformations <ref> [6, 25, 43] </ref>. One advantage of the Precomputed-Branch architecture, particularly for larger programs representative of actual applications, is that it is less susceptible to capacity misses for fetch prediction. <p> These partitioning algorithms are simple, work well without profile information, and work better with real or estimated profile information. Also, these same partitioning algorithms are already used in existing compilers to map procedures and basic blocks to improve page utilization and to improve instruction cache performance <ref> [25, 30] </ref>. We have shown that combining a small indirect jump buffer with the Precomputed-Branch architecture results in a branch architecture that uses few resources and has excellent performance, particularly for programs with a large number of branches.
Reference: [26] <author> MIPS Technologies, Incorperated. </author> <title> R10000 microprocessor product overview. </title> <type> Technical report, </type> <institution> MIPS Technologies, Incorperated, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: This can either be made explicit in the instruction encoding, or the instruction can be partially decoded when it is brought into the instruction cache; a similar mechanism has been used in several architectures, such as the MIPS R10000 <ref> [26] </ref>. The only remaining function provided by the BTB is the pre-computed destination address for taken branches. The BTB is needed because the destination address specified by a branch instruction can not be fetched from the instruction cache and computed all in a single cycle when using PC-relative destinations. spaces.
Reference: [27] <author> Johannes M. Mulder, Nhon T. Quach, and Michael J. Flynn. </author> <title> An area model for on-chip memories and its application. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> 26(2) </volume> <pages> 98-105, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: must use the BTB to avoid misfetching for all PC-relative branches and to predict the destination for indirect jumps. 6.2.1 Impact on Chip Area To evaluate the area implementation costs for these architectures we used the register bit equivalent (RBE) cost model for on-chip memories proposed by Mulder et al. <ref> [27] </ref>, where one RBE equals the area cost of a single bit storage cell.
Reference: [28] <author> S.-T. Pan, K. So, and J. T. Rahmeh. </author> <title> Improving the accuracy of dynamic branch prediction using branch correlation. </title> <booktitle> In Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 76-84, </pages> <address> Boston, Mass., </address> <month> October </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: The advantage of the pattern history tables is that they keep track of very little information per conditional branch site and are very effective in practice. More recently Pan et al <ref> [28] </ref> and Yeh and Patt [40, 42] have proposed branch-correlation or two-level branch prediction mechanisms. Although there are a number of variants, these mechanisms generally 4 combine the history of several recent branches to predict the outcome of an incipient branch.
Reference: [29] <author> Chris Perleberg and Alan Jay Smith. </author> <title> Branch target buffer design and optimization. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 42(4) </volume> <pages> 396-412, </pages> <month> April </month> <year> 1993. </year> <month> 28 </month>
Reference-contexts: branch target buffers and other branch prediction mechanisms to reduce both misfetch and mispredict penalties. 3 2.1 Branch Target Buffers Misfetch penalties can be reduced in a number of ways, such as using branch delay slots [24], a table of cache indices for fetch prediction [8], or branch target buffers <ref> [21, 22, 29, 32] </ref>. A BTB can eliminate misfetch stalls by storing the branch destination. For unconditional branches, indirect jumps or functions calls, this destination can be immediately fetched. For conditional branches, either the fall-through or the destination stored in the BTB is fetched. <p> example, McFarling [23] used an exclusive-or of the program counter and the global history register to scatter the table references, improving the PHT's performance. 2.3 Combining Branch Target Buffers and Branch Prediction Originally, BTB's were used as a mechanism for branch prediction, effectively predicting the prior outcome of a branch <ref> [21, 29, 32] </ref> and providing the target address. Researchers have proposed associating additional branch prediction information with each BTB entry to improve branch prediction [41], and a variation of this technique has been implemented in the Intel Pentium and PentiumPro architectures.
Reference: [30] <author> Karl Pettis and Robert C. Hansen. </author> <title> Profile guided code positioning. </title> <booktitle> In Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 16-27. </pages> <publisher> ACM, ACM, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Therefore, all intra-procedural branches will be compiled as pre-computed branches. There are myriad ways to partition programs, and a number of alternatives have been examined in the effort to reduce page faults [1, 2, 15, 13], and instruction cache conflicts <ref> [16, 25, 30] </ref>. The goals of our study are different than these other studies; we are more interested in reducing the number of indirect jumps than reducing cache conflicts and paging. <p> None the less, the best performing algorithm we examined (MaxCut) for code partitioning is very similar to the greedy layout algorithm of Pettis and Hansen <ref> [30] </ref>. Therefore, partitioning the program into branch spaces using the MaxCut algorithm would result in a layout that also reduces cache conflicts and paging. We used two metrics to compare the program partitioning heuristics. <p> The MaxCut partitioning uses a greedy max-cut algorithm to partition the graph using the call frequency to guide the partitioning. This algorithm is very similar to the greedy approach for procedure mapping proposed by Pettis and Hansen <ref> [30] </ref>. The MaxCut partitioning algorithm processes the edges in the call graph, starting with the most frequently executed call edge and ending with the least executed edge. For this algorithm we group procedures together into branch-spaces until each branch-space is full. <p> These partitioning algorithms are simple, work well without profile information, and work better with real or estimated profile information. Also, these same partitioning algorithms are already used in existing compilers to map procedures and basic blocks to improve page utilization and to improve instruction cache performance <ref> [25, 30] </ref>. We have shown that combining a small indirect jump buffer with the Precomputed-Branch architecture results in a branch architecture that uses few resources and has excellent performance, particularly for programs with a large number of branches.
Reference: [31] <author> Steven Przybylski, Mark Horowitz, and John Hennesy. </author> <title> Characteristics of performance-optimal multilevel cache hierarchy. </title> <booktitle> In 168th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 114-121. </pages> <publisher> IEEE, </publisher> <year> 1989. </year>
Reference-contexts: Access times are shown for a 128 and 512 entry BTB and a 8K and 32K instruction cache with 32 byte lines. 6.2.2 Impact on Cycle Time The access time for a cache (or a BTB) depends both on the size and the associativity of the design <ref> [17, 31] </ref>. Recall that the branch target buffer requires considerable resources, and is organized as a 4-way associative cache, while the Precomputed-Branch architecture uses information recorded in the instructions.
Reference: [32] <author> J. E. Smith. </author> <title> A study of branch prediction strategies. </title> <booktitle> In 8th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 135-148. </pages> <publisher> ACM, </publisher> <year> 1981. </year>
Reference-contexts: branch target buffers and other branch prediction mechanisms to reduce both misfetch and mispredict penalties. 3 2.1 Branch Target Buffers Misfetch penalties can be reduced in a number of ways, such as using branch delay slots [24], a table of cache indices for fetch prediction [8], or branch target buffers <ref> [21, 22, 29, 32] </ref>. A BTB can eliminate misfetch stalls by storing the branch destination. For unconditional branches, indirect jumps or functions calls, this destination can be immediately fetched. For conditional branches, either the fall-through or the destination stored in the BTB is fetched. <p> Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time heuristics <ref> [3, 9, 21, 24, 32] </ref> to profile-based methods [10, 14, 24, 37, 43]. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use heuristics based on the direction of the branch target (forward or backward) or instruction opcode. <p> The most common variants of this design are 1-bit counter techniques that indicate the direction of the most recent branch mapping to a given prediction bit, and 2-bit counter techniques that yield much better performance for programs with loops <ref> [21, 24, 32] </ref>. These designs use the branch site address as an index into the PHT. Since different branch addresses can index into the same table entry, several conditional branches may share the same prediction information. <p> example, McFarling [23] used an exclusive-or of the program counter and the global history register to scatter the table references, improving the PHT's performance. 2.3 Combining Branch Target Buffers and Branch Prediction Originally, BTB's were used as a mechanism for branch prediction, effectively predicting the prior outcome of a branch <ref> [21, 29, 32] </ref> and providing the target address. Researchers have proposed associating additional branch prediction information with each BTB entry to improve branch prediction [41], and a variation of this technique has been implemented in the Intel Pentium and PentiumPro architectures.
Reference: [33] <author> S. Peter Song, Marvin Denman, and Joe Chang. </author> <title> The PowerPC 604 RISC microprocessor. </title> <journal> IEEE Micro, </journal> <volume> 14(5) </volume> <pages> 8-17, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: When an instruction is fetched, the same address is offered to the BTB; if there is a match in the BTB, the next instruction is fetched using the target address specified in the BTB if the branch is predicted as taken. In this design, exemplified by the PowerPC 604 <ref> [33] </ref>, the BTB identifies the instruction as a branch and only records the destination for taken branches. 1.1 The Branch Target Address Problem and the Precomputed-Branch Solution Architectures using BTB's can issue a large number of instructions per cycle because of accurate branch and fetch prediction. <p> A branch target buffer can be used to reduce the misfetch penalty and can be used as a simple branch prediction mechanism. Other branch prediction methods can reduce mispredict penalties, but not misfetch penalties. Many architectures <ref> [33, 40, 42] </ref> combine branch target buffers and other branch prediction mechanisms to reduce both misfetch and mispredict penalties. 3 2.1 Branch Target Buffers Misfetch penalties can be reduced in a number of ways, such as using branch delay slots [24], a table of cache indices for fetch prediction [8], or
Reference: [34] <author> Amitabh Srivastava and Alan Eustace. </author> <title> ATOM: A system for building customized program analysis tools. </title> <booktitle> In 1994 Programming Language Design and Implementation, </booktitle> <pages> pages 196-205. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: We instrumented the programs from the SPEC92 benchmark suite, the Perfect-Club [4], and object-oriented programs written in C++. We used ATOM <ref> [34] </ref> to instrument the programs; due to the structure of ATOM, we did not need to record traces and could trace the complete execution of all the programs. The programs were compiled on a DEC 3000-400 using either the DEC FORTRAN, C, or C++ compiler.
Reference: [35] <author> Amitabh Srivastava and David W. Wall. </author> <title> A practical system for intermodule code optimizations at link-time. </title> <journal> Journal of Programming Languages, </journal> <month> March </month> <year> 1992. </year> <note> (Also available as DEC-WRL TR-92-6). </note>
Reference-contexts: Branches between branch spaces are computed and performed as indirect jumps. This design assumes the program linker or compiler can partition the program into a number of segments and modify the program's structure to select between intra-space and inter-space branches <ref> [35] </ref>. We also describe how existing architectures using PC-relative branches can be extended to benefit from pre-computed branches. 2 The Precomputed-Branch architecture provides area-efficient support for conditional, unconditional and procedural branches, where the branch destination is explicitly specified.
Reference: [36] <author> Tim A. Wagner, Vance Maverick, Susan Graham, and Michael Harrison. </author> <title> Accurate static estimators for program optimization. </title> <booktitle> In Proceedings of the SIGPLAN'94 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 85-96, </pages> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: We considered a number of partitioning algorithms. Some methods use profiles, or information about previous executions of the program. Many optimizations require such information, either from previous executions of the program or from estimates using static analysis <ref> [36, 39] </ref>. We examined depth-first, breadth-first, pre-order, post-order, greedy and max-cut partitioning algorithms. Most of the methods had similar performance, and we present the performance of three of these algorithms. The partitioning algorithms are illustrated in Figure 4.
Reference: [37] <author> D. W. Wall. </author> <title> Limits of instruction-level parallelism. </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 176-188, </pages> <address> Boston, Mass., </address> <year> 1991. </year>
Reference-contexts: Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time heuristics [3, 9, 21, 24, 32] to profile-based methods <ref> [10, 14, 24, 37, 43] </ref>. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use heuristics based on the direction of the branch target (forward or backward) or instruction opcode.
Reference: [38] <author> Steven J. E. Wilton and Norman P. Jouppi. </author> <title> An enhanced access and cycle time model for on-chip caches. </title> <type> Report 93/5, </type> <institution> DEC Western Research Lab, </institution> <year> 1993. </year>
Reference-contexts: Figure 7 shows the access time of the BTB in comparison to the access time for an instruction cache using an accurate timing analysis tool by Wilton and Jouppi <ref> [38] </ref>. The Figure shows that the access time of a 4-way associative 128 entry BTB is larger than the access time for a direct mapped 8K and 32K instruction cache with 32 byte lines.
Reference: [39] <author> Youfeng Wu and James R. Larus. </author> <title> Static branch frequency and program profile analysis. </title> <booktitle> In 27th International Symposium on Microarchitecture, </booktitle> <address> San Jose, Ca, </address> <month> November </month> <year> 1994. </year> <note> IEEE. </note>
Reference-contexts: We considered a number of partitioning algorithms. Some methods use profiles, or information about previous executions of the program. Many optimizations require such information, either from previous executions of the program or from estimates using static analysis <ref> [36, 39] </ref>. We examined depth-first, breadth-first, pre-order, post-order, greedy and max-cut partitioning algorithms. Most of the methods had similar performance, and we present the performance of three of these algorithms. The partitioning algorithms are illustrated in Figure 4.
Reference: [40] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> Alternative implementations of two-level adaptive branch predictions. </title> <booktitle> In 19th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 124-134, </pages> <address> Gold Coast, Australia, </address> <month> May </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: A branch target buffer can be used to reduce the misfetch penalty and can be used as a simple branch prediction mechanism. Other branch prediction methods can reduce mispredict penalties, but not misfetch penalties. Many architectures <ref> [33, 40, 42] </ref> combine branch target buffers and other branch prediction mechanisms to reduce both misfetch and mispredict penalties. 3 2.1 Branch Target Buffers Misfetch penalties can be reduced in a number of ways, such as using branch delay slots [24], a table of cache indices for fetch prediction [8], or <p> The advantage of the pattern history tables is that they keep track of very little information per conditional branch site and are very effective in practice. More recently Pan et al [28] and Yeh and Patt <ref> [40, 42] </ref> have proposed branch-correlation or two-level branch prediction mechanisms. Although there are a number of variants, these mechanisms generally 4 combine the history of several recent branches to predict the outcome of an incipient branch. The simplest example is the so-called degenerate method of Pan et al.
Reference: [41] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> A comprehensive instruction fetch mechanism for a processor supporting speculative execution. </title> <booktitle> In 25th International Symposium on Microarchitecture, </booktitle> <pages> pages 129-139, </pages> <address> Portland, Or, </address> <month> December </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: Researchers have proposed associating additional branch prediction information with each BTB entry to improve branch prediction <ref> [41] </ref>, and a variation of this technique has been implemented in the Intel Pentium and PentiumPro architectures. The problem with this technique is the branch prediction information can only be used on a BTB hit, or when when a branch address is found in the BTB. <p> We simulated the decoupled branch architecture proposed in [5], because this architecture provides better overall branch performance than the coupled models proposed in <ref> [41] </ref> for the design space considered in this paper. In this section, we describe this architecture and follow that with a detailed description of the Precomputed-Branch architecture. 3.1 A BTB-based Instruction Fetch Architecture using a branch target buffer. <p> Dynamic information is recorded from a particular execution of the application, while static information is a property of the program binary. 11 mispredicted branches (%MpB), but it is often difficult to understand how these metrics influence processor performance. Yeh & Patt <ref> [41] </ref> defined the branch execution penalty to be: BEP = %MfB fi misfetch penalty + %MpB fi misprediction penalty 100 which reflects the average penalty suffered by a branch due to misfetch and misprediction. <p> Despite the advantages of direct mapped caches, many BTB designs, such as the BTB used in the Intel Pentium and PentiumPro and those proposed by Yeh et al <ref> [41] </ref> use a large, multi-associative BTBs to reduce the misfetch penalty. Though, for processors like the DEC Alpha 21064 and 21164, which have a direct mapped first level instruction cache, an associative BTB design is not practical because of the access times shown in Figure 7.
Reference: [42] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> A comparison of dynamic branch predictors that use two levels of branch history. </title> <booktitle> In 20th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 257-266, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: A branch target buffer can be used to reduce the misfetch penalty and can be used as a simple branch prediction mechanism. Other branch prediction methods can reduce mispredict penalties, but not misfetch penalties. Many architectures <ref> [33, 40, 42] </ref> combine branch target buffers and other branch prediction mechanisms to reduce both misfetch and mispredict penalties. 3 2.1 Branch Target Buffers Misfetch penalties can be reduced in a number of ways, such as using branch delay slots [24], a table of cache indices for fetch prediction [8], or <p> The advantage of the pattern history tables is that they keep track of very little information per conditional branch site and are very effective in practice. More recently Pan et al [28] and Yeh and Patt <ref> [40, 42] </ref> have proposed branch-correlation or two-level branch prediction mechanisms. Although there are a number of variants, these mechanisms generally 4 combine the history of several recent branches to predict the outcome of an incipient branch. The simplest example is the so-called degenerate method of Pan et al.
Reference: [43] <author> Cliff Young and Michael D. Smith. </author> <title> Improving the accuracy of static branch prediction using branch correlation. </title> <booktitle> In 6th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 232-241, </pages> <month> October </month> <year> 1994. </year> <month> 29 </month>
Reference-contexts: Branch prediction techniques are classified as static or dynamic. Static branch prediction information does not change during the execution of a program, while dynamic prediction may change, reflecting the time-varying activity of the program. Static methods range from compile-time heuristics [3, 9, 21, 24, 32] to profile-based methods <ref> [10, 14, 24, 37, 43] </ref>. In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use heuristics based on the direction of the branch target (forward or backward) or instruction opcode. <p> Other programs, such as cfront and gcc contain a great number of conditional branches, and many of those branches are difficult to predict. The prediction accuracy for these programs can be improved by using larger pattern history tables, or by various compiler transformations <ref> [6, 25, 43] </ref>. One advantage of the Precomputed-Branch architecture, particularly for larger programs representative of actual applications, is that it is less susceptible to capacity misses for fetch prediction.
References-found: 43

