URL: http://scotch.cs.yale.edu/saha/papers/nspap.ps
Refering-URL: http://scotch.cs.yale.edu/saha/papers/index.html
Root-URL: http://www.cs.yale.edu
Email: email: deedee,ppdas@cse.iitkgp.ernet.in  
Title: A PARALLELIZING COMPILER FOR A NETWORK OF PROCESSORS  
Author: J. Mazumdar D. Das B. Saha, P. P. Das and S. C. DeSarkar 
Address: Kharagpur 721302.  
Affiliation: Dept. of Computer Science and Engineering, Indian Institute of Technology,  
Abstract: We present a working parallelizing compiler for a loosely coupled network of processors. The current compiler has been patched to a F77 front-end and a back-end generating code for a network of machines running PVM ( The Parallel Virtual Machine). We present the performance of some well-known kernels using our compiler in such an environment. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Banerjee and et al. </author> <title> The PARADIGM compiler for distributed memory message passing multicomputers. </title> <booktitle> In Ist International Workshop on Parallel Processing, </booktitle> <address> Bangalore, India, </address> <pages> pages 123-128, </pages> <month> Dec </month> <year> 1994. </year>
Reference: [2] <author> U. Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, Mass., </address> <year> 1988. </year>
Reference: [3] <author> C. D. Polychronopoulos. </author> <title> Parallel Programming and Compilers. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, Mass., </address> <year> 1988. </year>
Reference: [4] <author> W. Pugh. </author> <title> A practical algorithm for exact array dependence analysis. </title> <journal> Commun. ACM 35,8, </journal> <pages> pages 102-115, </pages> <month> Aug </month> <year> 1992. </year>
Reference: [5] <author> V. S. Sunderam, G. A. Geist, J. Dongarra, and R. Manchek. </author> <title> The PVM Concurrent Computing System: </title> <booktitle> Evolution,Experiences and Trends. Parallel Computing, </booktitle> <month> Apr </month> <year> 1994. </year>
Reference-contexts: The input to our compiler is the source code written in Fortran 77 and the output generated are programs which run on the individual nodes/machines in a loosely synchronous manner. Data dependencies are handled with explicit send or receive calls. We have used the PVM <ref> [5] </ref> library calls for message passing and remote task creation. This approach of programming is known as the SPMD [5] approach. The rest of the paper is organized as follows: Section 2 highlights the requirements of dependence analysis and their different approaches. <p> Data dependencies are handled with explicit send or receive calls. We have used the PVM <ref> [5] </ref> library calls for message passing and remote task creation. This approach of programming is known as the SPMD [5] approach. The rest of the paper is organized as follows: Section 2 highlights the requirements of dependence analysis and their different approaches. Section 3 discusses our strategy of data distribution in depth. Section 4 describes the partitioning analysis. Section 5 presents the code generation strategy of our compiler.
Reference: [6] <author> M. J. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <booktitle> Research Monographs in Parallel and Distributed Computing. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1989b. </year>
Reference: [7] <author> M. J. Wolfe. </author> <title> Data Dependence and Program Restructuring. </title> <journal> The Journal of Supercomputing,4., </journal> <pages> pages 321-344, </pages> <year> 1990. </year>
References-found: 7

