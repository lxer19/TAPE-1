URL: http://medg.lcs.mit.edu/people/wjl/papers/eval-paper.ps
Refering-URL: http://www.medg.lcs.mit.edu/projects/hdp/hdp-intro.html
Root-URL: 
Title: Evaluation of a New Method for Cardiovascular Reasoning diagnoses and automatically generate evaluation forms. Five
Author: William J. Long, PhD Shapur Naimi, MD and M. G. Criscitiello, MD 
Date: 127-141, 1994  
Note: Reprinted from Journal of the American Medical Informatics Association,1:  Design: Tools were developed to summarize  
Address: Cambridge, MA, USA  Boston, MA, USA  
Affiliation: MIT Laboratory for Computer Science,  New England Medical Center and Tufts University School of Medicine,  
Abstract: Results: Both reviewers rated the first diagnosis correct in 25% of the cases and at least one rated it wrong in 10%. Analyzing the detailed reasoning, 137 issues were raised, about 5.3 per case. 53% of these were possible concerns raised by one reviewer. Of the 5.3 issues per case, 2.5 were attributable to controversies, misunderstandings, or mistakes; 1 was due to the overly simplistic representation of the summaries; and 1.8 were issues related to the program. Conclusion: Overall, the program is capable of providing high quality detailed diagnostic hypotheses for complex cardiovascular cases. The results highlight several issues: 1) the difficulty of effectively summarizing hypotheses, 2) the nature of a physician's causal explanation, and 3) some problems in evaluating detailed diagnostic reasoning. The mistakes the program made imply that some additional refinement is needed but that the reasoning mechanisms developed can support the appropriate reasoning. The appropriate next step is a prospective evaluation addressing the program's usefulness. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Long WJ, Naimi S, Criscitiello MG, Larsen G. </author> <title> Differential diagnosis generation from a causal network with probabilities. </title> <booktitle> In: Proceedings, Computers in Cardiology Conference. </booktitle> <address> Washington, DC, </address> <pages> 1988;185-188. </pages>
Reference-contexts: 1 Introduction The Heart Failure Program (HFP) is a computer program designed to assist physicians in reasoning about patients with cardiovascular disease <ref> [1, 2, 3] </ref>. It takes as input the description of the patient's history, physical examination findings, and test results at the level of detail one would find in the physician's description in the patient record. This information is used by the program to generate a differential diagnosis for the case.
Reference: [2] <author> Long W. </author> <title> Medical diagnosis using a probabilistic causal network. </title> <journal> Applied Artificial Intelligence. </journal> 1989;3:367-83. 
Reference-contexts: 1 Introduction The Heart Failure Program (HFP) is a computer program designed to assist physicians in reasoning about patients with cardiovascular disease <ref> [1, 2, 3] </ref>. It takes as input the description of the patient's history, physical examination findings, and test results at the level of detail one would find in the physician's description in the patient record. This information is used by the program to generate a differential diagnosis for the case.
Reference: [3] <author> Long WJ. </author> <title> Flexible reasoning about patient management using multiple models. </title> <journal> Artificial Intelligence in Medicine. </journal> 1991;3:3-20. 
Reference-contexts: 1 Introduction The Heart Failure Program (HFP) is a computer program designed to assist physicians in reasoning about patients with cardiovascular disease <ref> [1, 2, 3] </ref>. It takes as input the description of the patient's history, physical examination findings, and test results at the level of detail one would find in the physician's description in the patient record. This information is used by the program to generate a differential diagnosis for the case.
Reference: [4] <author> Kingsland LC. </author> <title> The evaluation of medical expert systems: experience with the AI/RHEUM knowledge-based consultant system in rheumatology. </title> <booktitle> In: Ninth Symposium on Computer Applications in Medical Care, </booktitle> <address> Washington, DC, </address> <pages> 1985;292-295. </pages>
Reference-contexts: To limit the differential to likely hypotheses, the list is cut off when the probabilities fall below 1% of the best hypothesis. Thus, the differential may consist of one or many hypotheses. This type of diagnostic hypothesis is much more informative than those of earlier programs, such as AI/RHEUM <ref> [4] </ref>, QMR [5], or DXplain [6], which provide hypotheses consisting of a single word or phrase. The structure of the HFP hypothesis explains the findings by showing the causal mechanisms producing them and thus provides a justification that the physician can evaluate to decide whether the conclusions are reasonable. <p> This work of incorporating temporal relations and severity constraints had progressed to the point where it was appropriate to evaluate the performance of the program. 2 Methodology A number of evaluations of medical expert systems have been reported in the literature, mostly focusing on the accuracy of diagnostic information <ref> [4, 5, 6, 9, 10] </ref>. Evaluating the accuracy the program is the first step toward establishing the clinical usefulness of the program.
Reference: [5] <author> Miller RA, Pople HE, Myers JD. INTERNIST-I, </author> <title> an experimental computer-based diagnostic consultant for general internal medicine. </title> <journal> New England Journal of Medicine. </journal> 1982;307:468-476. 
Reference-contexts: Thus, the differential may consist of one or many hypotheses. This type of diagnostic hypothesis is much more informative than those of earlier programs, such as AI/RHEUM [4], QMR <ref> [5] </ref>, or DXplain [6], which provide hypotheses consisting of a single word or phrase. The structure of the HFP hypothesis explains the findings by showing the causal mechanisms producing them and thus provides a justification that the physician can evaluate to decide whether the conclusions are reasonable. <p> This work of incorporating temporal relations and severity constraints had progressed to the point where it was appropriate to evaluate the performance of the program. 2 Methodology A number of evaluations of medical expert systems have been reported in the literature, mostly focusing on the accuracy of diagnostic information <ref> [4, 5, 6, 9, 10] </ref>. Evaluating the accuracy the program is the first step toward establishing the clinical usefulness of the program.
Reference: [6] <author> Feldman MJ, </author> <title> Barnett GO. An approach to evaluating the accuracy of DXplain. </title> <booktitle> In: Fourteenth Symposium on Computer Applications in Medical Care, </booktitle> <address> Washington, DC, </address> <pages> 1990;38-43. </pages>
Reference-contexts: Thus, the differential may consist of one or many hypotheses. This type of diagnostic hypothesis is much more informative than those of earlier programs, such as AI/RHEUM [4], QMR [5], or DXplain <ref> [6] </ref>, which provide hypotheses consisting of a single word or phrase. The structure of the HFP hypothesis explains the findings by showing the causal mechanisms producing them and thus provides a justification that the physician can evaluate to decide whether the conclusions are reasonable. <p> This work of incorporating temporal relations and severity constraints had progressed to the point where it was appropriate to evaluate the performance of the program. 2 Methodology A number of evaluations of medical expert systems have been reported in the literature, mostly focusing on the accuracy of diagnostic information <ref> [4, 5, 6, 9, 10] </ref>. Evaluating the accuracy the program is the first step toward establishing the clinical usefulness of the program.
Reference: [7] <author> Long WJ, Naimi S, Criscitiello MG. </author> <title> Development of a knowledge base for diagnostic reasoning in cardiology. </title> <journal> Computers in Biomedical Research. </journal> 1992;25:292-311. 
Reference-contexts: It is not a handicap for reasoning because this is presumably the level at which the human physician does similar reasoning and the physician is the best model we have for this kind of reasoning. We previously conducted a formative evaluation of the program <ref> [7] </ref>. This evaluation used 242 cases collected from discharge summaries and compared the program diagnoses to diagnoses collected from cardiologists using the same information. We examined the maximum potential accuracy of the program by iteratively revising the knowledge base and rerunning the cases.
Reference: [8] <author> Long WJ. </author> <title> The probability of disease. </title> <booktitle> In: Fifteenth Symposium on Computer Applications in Medical Care, </booktitle> <address> Washington, DC, </address> <pages> 1991;619-23. </pages>
Reference-contexts: As a result of this evaluation we have developed methods for reasoning with the additional constraints provided by temporal and severity relationships to deal with some of the limitations encountered. We also developed an appropriate framework for computing the probability of multiple diseases <ref> [8] </ref>. The additions to the program include both enhancements of the knowledge base and changes in the reasoning methods. In the knowledge base the diseases and pathophysiologic states (all referred to as nodes) are subdivided into levels of severity and subtypes with additional constraints on the causal links.
Reference: [9] <author> Kahn CE. </author> <title> Validation, clinical trial, and evaluation of a radiology expert system. </title> <booktitle> Methods of Information in Medicine. </booktitle> 1991;30:268-74. <volume> [10] </volume> van der Lei J, Musen MA, van der Does E, Manintveld AJ. Critiquing physician decision making using data from automated medical records: assessing the limitations. In: Fourteenth Symposium on Computer Applications in Medical Care, Washington, DC, <pages> 1990;559-63. </pages>
Reference-contexts: This work of incorporating temporal relations and severity constraints had progressed to the point where it was appropriate to evaluate the performance of the program. 2 Methodology A number of evaluations of medical expert systems have been reported in the literature, mostly focusing on the accuracy of diagnostic information <ref> [4, 5, 6, 9, 10] </ref>. Evaluating the accuracy the program is the first step toward establishing the clinical usefulness of the program.
Reference: [11] <author> Yu VL, Fagan LM, Wraith SM, et al. </author> <title> Antimicrobial selection by a computer: a blinded evaluation by infectious diseases experts. </title> <journal> Journal of the American Medical Association. </journal> 1979;242:1279-82. 
Reference-contexts: To some extent, this more extensive set of possible conclusions was also faced in the evaluation of therapeutic decision-support systems <ref> [11, 12] </ref>. However, here too there was a single decision for the evaluators to judge. The hypothesis structure presents a much more difficult challenge for evaluation. With atomic diagnoses it is relatively clear what is correct or incorrect and it is easy to compare expert diagnoses to the program's diagnosis. <p> These were all complex cases, chosen to be difficult, but otherwise representative of the case load of a tertiary care hospital. The reviewers were not asked to record or critique their own diagnoses. Having the reviewer's diagnosis evaluated as well, as has been done in earlier evaluations <ref> [11] </ref>, would make it possible to rank the program relative to the evaluators.
Reference: [12] <author> Hickam DH, Shortliffe EH, Bischoff MB, Scott AC, </author> <title> Jacobs CD. The treatment advice of a computer-based cancer chemotherapy protocol advisor. </title> <journal> Annals of Internal Medicine. </journal> 1985;103:928-36. Evaluation of Cardiovascular Reasoning : : : <volume> 17 </volume>
Reference-contexts: To some extent, this more extensive set of possible conclusions was also faced in the evaluation of therapeutic decision-support systems <ref> [11, 12] </ref>. However, here too there was a single decision for the evaluators to judge. The hypothesis structure presents a much more difficult challenge for evaluation. With atomic diagnoses it is relatively clear what is correct or incorrect and it is easy to compare expert diagnoses to the program's diagnosis. <p> Other decision classifications have been used in evaluations, such as the ideal, acceptable, suboptimal, unacceptable scale used by Hickam, et al <ref> [12] </ref>. Our scale is similar, but does not try to differentiate between acceptable and sub-optimal.
References-found: 11

