URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1993/TR29.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Title: Designing Scalable Systems with two-level k-ary n-cube Wormhole-routed Interconnections 1  
Author: Debashis Basak and Dhabaleswar K. Panda 
Keyword: parallel architectures, interconnection networks, clustered architec tures, hierarchical systems, multiprocessors, wormhole-routing.  
Address: Columbus, OH 43210-1277  
Affiliation: Department of Computer and Information Science Ohio State University  
Email: Email: basak,panda@cis.ohio-state.edu  
Phone: Tel: (614)-292-5199, Fax: (614)-292-2911  
Date: August 5, 1993  
Abstract: Recent advancements in VLSI and packaging technologies are making it cost effective to integrate multiple processing units into a chip or a board. This demonstrates attractiveness in building scalable parallel systems using clustered configurations while exploiting communication locality. Variety of clustered architectures, proposed in the past, using buses or MINs as the inter-cluster interconnection do not satisfy both the above objectives. This paper focuses on design issues in building two-level clustered systems with k-ary n-cube interconnections at both the intra-cluster and the inter-cluster levels. A new framework of composite-routing is proposed to route messages in such clustered systems in a deadlock-free manner. The interplay between various parameters such as cluster size, inter- and intra-cluster topologies, channel widths, routing schemes, message length, and locality of communication in determining system performance and cost have been analyzed under the constant bisection bandwidth constraint. Network latency in such a system is analytically modeled by taking into account demand multiplexing of multiple virtual channels on each physical channel. Predictions from this model together with channel capacity constraints and simulation experiments are used in determining optimal configurations for a given system size. Our analysis indicates that small sized clusters with a ring intra-cluster topology and a 2D/3D/4D inter-cluster network connecting these clusters offer best system performance. This provides guidelines to system designers for building large-scale parallel systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Basak D. and Panda D.K., </author> <title> "Scalable Architectures with k-ary n-cube cluster-c organization." </title> <booktitle> Submitted to the Symposium of Parallel and Distributed Processing, </booktitle> <year> 1993. </year>
Reference-contexts: Research by Dally [2] has demonstrated the attractiveness of k-ary n-cube topology with wormhole routing switching technique. It has been shown that low dimensional (n) k-ary n-cube networks have potential to build scalable systems with low average message latency under physical wiring constraint. In <ref> [1] </ref> we have proposed a general class of k-ary n-cube cluster-c scalable architectures by combining the scalability of k-ary n-cube wormhole-routed networks with the cost-effectiveness of processor cluster designs.
Reference: [2] <author> Dally William J., </author> <title> "Performance Analysis of k-ary n-cube Interconnection Networks." </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 39, No. 6, </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: The analysis in [4] dealt with fixed cluster sizes and did not consider the optimality of the network configuration, in terms of inter-cluster and intra-cluster network sizes and topologies. Research by Dally <ref> [2] </ref> has demonstrated the attractiveness of k-ary n-cube topology with wormhole routing switching technique. It has been shown that low dimensional (n) k-ary n-cube networks have potential to build scalable systems with low average message latency under physical wiring constraint. <p> In this paper, we focus on two-level clustered systems with k-ary n-cube interconnections at both intra-cluster and inter-cluster levels. For a given system size, different topolog 1 ical alternatives and their associated cost under constant bisection bandwidth constraint <ref> [2] </ref> are analyzed. We propose two minimal deadlock-free wormhole routing schemes to route messages in such two-level k-ary n-cube systems. <p> These properties depend on various parameters like cluster size, the intranet and the internet topologies, and the routing schemes used. Our objective is to select the configuration that offers best system performance. For a given hierarchical configuration, we use the constant bisection bandwidth constraint <ref> [2, 3] </ref> to determine channel widths in each network. The number of wires that need to cross the bisection of a network is called bisection width. <p> The number of wires that need to cross the bisection of a network is called bisection width. In general, this width cannot be increased arbitrarily and is limited by factors like available layout area <ref> [2] </ref>, allowable system size, cost, and power considerations. With a given set of factors, the bisection width can be held constant at some limit. This limit directly affects the channel width and indirectly determines the number of flits required for a given message. <p> We define this problem as flit mismatch problem, since it arises because of mismatch in flit sizes in the two networks. We suggest the use of virtual channels with demand multiplexing to alleviate this flit mismatch problem. Virtual channels as proposed by Dally <ref> [2] </ref> are logical channels which are time-multiplexed over a physical link. Routing is done over the virtual channel network. The NAB scheme now works like this. We use the strategy of concatenating larger flits from smaller flits and then releasing them into the internet. <p> Both AB and NAB are general strategies in the sense that they do not specify the actual routing algorithm to be used in each network. Numerous deadlock free algorithms exist in literature for minimal wormhole-routing with virtual channels for k-ary n-cubes e.g. dimension-order <ref> [2] </ref>, fully-adaptive [20], or planar [19], etc. However no such algorithm exists for (k; n; k1; n1) systems. One simple solution might be to use a composite-routing scheme e.g. use dimension order in the k-ary n-cube internet and fully adaptive in the k1-ary n1-cube cluster intranets.
Reference: [3] <author> Agarwal Anant, </author> <title> "Limits on Interconnection Network Performance." </title> <journal> IEEE Trans. on Parallel and Distributed Systems, Vol.2,No.4,Oct.91. </journal>
Reference-contexts: These properties depend on various parameters like cluster size, the intranet and the internet topologies, and the routing schemes used. Our objective is to select the configuration that offers best system performance. For a given hierarchical configuration, we use the constant bisection bandwidth constraint <ref> [2, 3] </ref> to determine channel widths in each network. The number of wires that need to cross the bisection of a network is called bisection width. <p> This limit directly affects the channel width and indirectly determines the number of flits required for a given message. Consider a k-ary n-cube with bidirectional channels each of width W bits. It has a bisection width of 4W k n1 <ref> [3] </ref>. With N being total number of nodes, this width is equal to 4W N=k. For a linear array of processors, this width is 2W . For comparison across different topologies, we normalize bisection widths to that of a 2-ary n-cube (hypercube) with unit-width bidirectional channels. <p> The effective network request rate by a CI is M = mC (1 p). 18 An analysis similar to Agrawal <ref> [3] </ref> predicts the contention delay (w) through a CIP switch for an intercluster message as w = (1 ) d 2 1 + 2n (6) where B is the message size in flits = L=W and = MBd 2 , is the channel utilization of an intercluster channel. <p> However on clustered architectures one would expect communication patterns to be more localized. There are various ways of defining locality of communication of applications. We used the locality model developed by Agarwal in <ref> [3] </ref> in which a processor generates messages with equal probability to some nearest subset of processors.
Reference: [4] <author> Hsu W. & Yew P., </author> <title> "The Performance of Hierarchical Systems with wiring constraints." </title> <booktitle> Int. Conf. on Parallel Processing, </booktitle> <address> Aug.1991. </address>
Reference-contexts: Some examples include cluster of processors with buses [8], cluster of processors with crossbar switches [9], combination of crossbar and omega networks [10], local and global meshes [7], two-level systems based on hypercube and other network topologies [11, 12], and combination of intra-cluster bus and inter-cluster mesh/hypercube networks <ref> [4] </ref>. Two desired features in parallel architectures are scalability of the system and its ability to exploit the locality of communication inherent in most applications. Most of the above architectures using buses or MINs as the inter-cluster interconnection do not satisfy both the above objectives. <p> In the architectures supporting scalable inter-cluster interconnections, the focus has been restricted to 2D meshes or hypercubes as the inter-cluster topology with packet switched or circuit switched routing. The analysis in <ref> [4] </ref> dealt with fixed cluster sizes and did not consider the optimality of the network configuration, in terms of inter-cluster and intra-cluster network sizes and topologies. Research by Dally [2] has demonstrated the attractiveness of k-ary n-cube topology with wormhole routing switching technique.
Reference: [5] <author> Hsu W. & Yew P., </author> " <title> The Impact of Wiring Constraints on Hierarchical Network Performance." </title> <booktitle> Int. Parallel Processing symp, </booktitle> <month> Mar </month> <year> 1992. </year>
Reference: [6] <author> Hsu W. & Yew P., </author> " <title> The Performance Evaluation of Wire-Limited Hierarchical Network." </title> <type> CSRD report no. 1179, </type> <month> Aug </month> <year> 1992. </year>
Reference: [7] <author> Carlson D., </author> <title> "The Mesh with a Global Mesh: a Flexible, High-speed Organization for Parallel Computation." </title> <booktitle> 1 st Int. Conf. on Supercomputer Systems, IEEE Comp. </booktitle> <publisher> Soc. Press, </publisher> <year> 1985. </year>
Reference-contexts: Some examples include cluster of processors with buses [8], cluster of processors with crossbar switches [9], combination of crossbar and omega networks [10], local and global meshes <ref> [7] </ref>, two-level systems based on hypercube and other network topologies [11, 12], and combination of intra-cluster bus and inter-cluster mesh/hypercube networks [4]. Two desired features in parallel architectures are scalability of the system and its ability to exploit the locality of communication inherent in most applications.
Reference: [8] <author> Wu S., & Liu M., </author> <title> "A Cluster Structure as an Interconnection Network for Large Multiprocessor Systems." </title> <journal> IEEE Trans. on Computers, </journal> <volume> Vol. C-30, No. </volume> <year> 4,Apr.1981. </year>
Reference-contexts: Such clusters can be interconnected together to build large-scale systems. A variety of hierarchical configurations have been proposed by researchers in the last decade to build scalable systems, using either single processor or processor cluster per node. Some examples include cluster of processors with buses <ref> [8] </ref>, cluster of processors with crossbar switches [9], combination of crossbar and omega networks [10], local and global meshes [7], two-level systems based on hypercube and other network topologies [11, 12], and combination of intra-cluster bus and inter-cluster mesh/hypercube networks [4].
Reference: [9] <author> Agrawal A., & Mahgoub I., </author> <title> "Performance Analysis of cluster-based supersystems." </title> <booktitle> 1st Int. Conf. on Supercomputer Systems, IEEE Comp. </booktitle> <publisher> Soc. Press, </publisher> <year> 1985. </year>
Reference-contexts: A variety of hierarchical configurations have been proposed by researchers in the last decade to build scalable systems, using either single processor or processor cluster per node. Some examples include cluster of processors with buses [8], cluster of processors with crossbar switches <ref> [9] </ref>, combination of crossbar and omega networks [10], local and global meshes [7], two-level systems based on hypercube and other network topologies [11, 12], and combination of intra-cluster bus and inter-cluster mesh/hypercube networks [4].
Reference: [10] <author> Kuck D.J., Kuhn R.H., Leasure B.R. and Sameh A., </author> <title> "Parallel Computing Today-the Cedar Approach." </title> <publisher> Science, Feb.1986. </publisher>
Reference-contexts: A variety of hierarchical configurations have been proposed by researchers in the last decade to build scalable systems, using either single processor or processor cluster per node. Some examples include cluster of processors with buses [8], cluster of processors with crossbar switches [9], combination of crossbar and omega networks <ref> [10] </ref>, local and global meshes [7], two-level systems based on hypercube and other network topologies [11, 12], and combination of intra-cluster bus and inter-cluster mesh/hypercube networks [4].
Reference: [11] <author> Dandamudi S. & Eager D., </author> <title> "Hierarchical Interconnection Networks for Multicomputer Systems." </title> <journal> IEEE Trans. on Computers, </journal> <volume> Vol. C-39, No.6, </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: Some examples include cluster of processors with buses [8], cluster of processors with crossbar switches [9], combination of crossbar and omega networks [10], local and global meshes [7], two-level systems based on hypercube and other network topologies <ref> [11, 12] </ref>, and combination of intra-cluster bus and inter-cluster mesh/hypercube networks [4]. Two desired features in parallel architectures are scalability of the system and its ability to exploit the locality of communication inherent in most applications.
Reference: [12] <author> Padmanabhan K., </author> <title> "Effective Architectures for Data Access in a Shared Memory Hierarchy." </title> <booktitle> Jour. of Parallel and Distributed Computing, </booktitle> <address> 11,1991. </address>
Reference-contexts: Some examples include cluster of processors with buses [8], cluster of processors with crossbar switches [9], combination of crossbar and omega networks [10], local and global meshes [7], two-level systems based on hypercube and other network topologies <ref> [11, 12] </ref>, and combination of intra-cluster bus and inter-cluster mesh/hypercube networks [4]. Two desired features in parallel architectures are scalability of the system and its ability to exploit the locality of communication inherent in most applications.
Reference: [13] <author> Mabbs S.A. </author> & <title> Forward K.E., "Performance Analysis of a Hierarchical Communication Architecture for a Shared-Memory Multiprocessor." </title> <type> Report No. </type> <month> 2 - Feb. </month> <year> 1990, </year> <institution> Dept. of Electrical and Electronic Engineering, The University of Melbourne. </institution> <month> 27 </month>
Reference: [14] <author> Intel Corporation. </author> <title> Paragon XP/S Product Overview, </title> <year> 1991. </year>
Reference-contexts: Each cluster consists of c processors and the possible intra-cluster interconnections can be either k-ary n-cube direct network or indirect networks like MIN or bus-based. Such clustered organizations, using wormhole-routing as the switching technique, are becoming the trend for building scalable parallel systems. Example commercial systems are Intel Paragon <ref> [14] </ref>, Stanford DASH [15], and the KSR system [16]. In the Paragon system, a cluster consists of 2-4 processors connected by bus and the clusters are connected through a 2D mesh. The KSR system uses a ring-ring topology. The Stanford DASH system interconnects processor clusters through a mesh network.
Reference: [15] <author> Lenoski D. et al, </author> <title> "The Stanford DASH Multiprocessor." </title> <booktitle> IEEE Computer 90, </booktitle> <pages> pages 63-79. </pages>
Reference-contexts: Such clustered organizations, using wormhole-routing as the switching technique, are becoming the trend for building scalable parallel systems. Example commercial systems are Intel Paragon [14], Stanford DASH <ref> [15] </ref>, and the KSR system [16]. In the Paragon system, a cluster consists of 2-4 processors connected by bus and the clusters are connected through a 2D mesh. The KSR system uses a ring-ring topology. The Stanford DASH system interconnects processor clusters through a mesh network.
Reference: [16] <institution> Kendall Square Research, </institution> <type> KSR Technical Summary, </type> <year> 1992. </year>
Reference-contexts: Such clustered organizations, using wormhole-routing as the switching technique, are becoming the trend for building scalable parallel systems. Example commercial systems are Intel Paragon [14], Stanford DASH [15], and the KSR system <ref> [16] </ref>. In the Paragon system, a cluster consists of 2-4 processors connected by bus and the clusters are connected through a 2D mesh. The KSR system uses a ring-ring topology. The Stanford DASH system interconnects processor clusters through a mesh network.
Reference: [17] <author> Lenoski D. et al, </author> <title> "The Directory-Based Cache Coherence Protocol for the DASH Multiprocessor." </title> <booktitle> In Proceedings of the 17th Annual Symposium on Computer Architecture, </booktitle> <pages> pp 148-159, </pages> <month> May </month> <year> 1990. </year>
Reference: [18] <author> Asthana A., Jagdish H. and Mathews B., </author> <title> "Impact of Advanced VLSI packaging on the design of a large parallel computer." </title> <booktitle> 1989 Int. Conf. on Parallel Processing, </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Traditionally, research in interconnection networks have assumed one processing element per node. However advancements in VLSI and packaging technologies are making it cost-effective to integrate multiple processing elements into a chip, multiple chips into a board, and multiple boards into a system <ref> [18] </ref>. Any of these building blocks can represent a processor cluster. Such clusters can be interconnected together to build large-scale systems. A variety of hierarchical configurations have been proposed by researchers in the last decade to build scalable systems, using either single processor or processor cluster per node.
Reference: [19] <author> Chien A. A. and Kim J.H., </author> <title> "Planar Adaptive Routing: Low cost adaptive networks for multiprocessors." </title> <booktitle> Proc. 19 th Ann.Int.Symp.on Comp.Arch,Pgs 268-277,1992. </booktitle>
Reference-contexts: Both AB and NAB are general strategies in the sense that they do not specify the actual routing algorithm to be used in each network. Numerous deadlock free algorithms exist in literature for minimal wormhole-routing with virtual channels for k-ary n-cubes e.g. dimension-order [2], fully-adaptive [20], or planar <ref> [19] </ref>, etc. However no such algorithm exists for (k; n; k1; n1) systems. One simple solution might be to use a composite-routing scheme e.g. use dimension order in the k-ary n-cube internet and fully adaptive in the k1-ary n1-cube cluster intranets.
Reference: [20] <author> Duato J. </author> <title> "On the design of deadlock-free adaptive routing algorithms for multicomput-ers: </title> <booktitle> Theoretical aspects." PARLE 91:Parallel Architectures and Languages, </booktitle> <pages> pp 234-243. </pages>
Reference-contexts: Both AB and NAB are general strategies in the sense that they do not specify the actual routing algorithm to be used in each network. Numerous deadlock free algorithms exist in literature for minimal wormhole-routing with virtual channels for k-ary n-cubes e.g. dimension-order [2], fully-adaptive <ref> [20] </ref>, or planar [19], etc. However no such algorithm exists for (k; n; k1; n1) systems. One simple solution might be to use a composite-routing scheme e.g. use dimension order in the k-ary n-cube internet and fully adaptive in the k1-ary n1-cube cluster intranets.
Reference: [21] <author> Gaughan P.T. and Yalamanchili S., </author> <title> "Analytical Models of Bandwidth Allocation in Pipelined k-ary n-cubes." </title> <booktitle> 1993 Int. Parallel Processing Symposium, </booktitle> <pages> pp 395-400. </pages>
Reference: [22] <author> Balakrishnan S. and Panda D.K., </author> <title> "Impact of Multiple Consumption Channels on Wormhole Routed k-ary n-cubes." </title> <booktitle> 1993 Int. Parallel Processing Symposium, </booktitle> <pages> pp 163-167. </pages>
Reference-contexts: This leads to serialization of all traffic going out/coming into the cluster. This problem can be solved by providing more than one injection and consumption channels at this processor <ref> [22] </ref>. Another disadvantage with this technique is that messages incur longer latencies, because they need to be absorbed fully at two intermediate places. For longer messages, the latency becomes more critical.
Reference: [23] <author> Schwetman H., "CSIM: </author> <title> A C-based process-oriented simulation language." </title> <booktitle> In Proc. of Winter Simulation Conf., </booktitle> <pages> pp. </pages> <address> 387-396,1986. </address> <month> 28 </month>
Reference-contexts: average latency of a message in the system is estimated as, T ave = T inter (1 p) + T intra p (14) 6 Simulation Experiments and Results To compare the performance of various clustered configurations, we performed simulation experiments on an event driven simulated cluster testbed, developed using CSIM <ref> [23] </ref>. The testbed uses composite-routing schemes with flexibility to choose the two components (intra and inter) from amongst dimension order/fully adaptive/planar adaptive options. It implements flit-level simulation and allows for demand multiplexing of virtual channels on physical channels, leading to better utilization of channel bandwidth.
References-found: 23

