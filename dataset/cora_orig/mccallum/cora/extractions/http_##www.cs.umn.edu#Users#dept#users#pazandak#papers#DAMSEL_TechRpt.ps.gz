URL: http://www.cs.umn.edu/Users/dept/users/pazandak/papers/DAMSEL_TechRpt.ps.gz
Refering-URL: http://www.cs.umn.edu/Users/dept/users/pazandak/papers/
Root-URL: http://www.cs.umn.edu
Title: Pazandak, Srivastava A Multimedia Temporal Specification Model and Language Page 1 A Multimedia Temporal Specification
Author: Paul Pazandak Jaideep Srivastava 
Note: 1 Introduction  such as  
Abstract: Several models support the specification of temporal relationships for the recording and presentation of multimedia. The five principal approaches used by these models include hierarchic, timeline, reference point, event, and event-based languages. Many of the current models, however, lack expressiveness, or require complex specifications. We introduce a temporal event-based model that defines three basic relations that express causality, deferment, and fine-grain synchrony; within this model we introduce the notions of deferment, and affectable and non-affectable events. The language based upon our model contains just three primitives for temporal specification of these relations. Using them we can express the temporal relations of the sixteen models studied, and we can further express several relations that cannot be specified by these models. An interesting feature of our model is that it supports both a conceptual specification as well as extensions for defining the system implementations, resulting in additional flexibility. We describe our model using a temporal specification model framework we used previously to compare several models. 1 We use variations of presentation in the abstract or typeless sense - the presentation of media objects will actually depend upon the 
Abstract-found: 1
Intro-found: 1
Reference: 10. <author> Gupta, A., T.E. Weymouth, and R. Jain. </author> <title> An Extended ObjectOriented Data Model For Large Image Bases. </title> <booktitle> in SSD 1991. 1991. </booktitle> <address> Zurich. </address>
Reference: 11. <author> Ishikawa, H. and e. al., </author> <title> The Model, Language, and Implementation of an ObjectOriented Multimedia Knowledge Base Management System. </title> <journal> ACM TODS, </journal> <note> 1993. </note> <author> 18(March): p. </author> <month> 1-50. </month>
Reference: 12. <author> Gibbs, S., C. Breiteneder, and D. Tsichritzis, ed. </author> <title> Data Modeling of Time-Based Media. Visual Objects, </title> <editor> ed. D. Tsichritzis. </editor> <year> 1993, </year> <institution> Centre Universitaire DInformatique: Universit De Genve. </institution> <month> Pazandak, </month> <title> Srivastava A Multimedia Temporal Specification Model and Language Page 38 </title>
Reference: 13. <author> Drapeau, G.D. and H. Greenfield. </author> <title> MAEstro - A Distributed Multimedia Authoring Environment. </title> <booktitle> in USENIX. 1991. </booktitle> <address> Nashville, TN. </address>
Reference: 14. <author> Gibbs, S., C. Breiteneder, and D. Tsichritzis, </author> <title> Audio/Video Databases: An Object Oriented Approach. </title> <booktitle> IEEE Proc Data Engineering, </booktitle> <year> 1993. </year>
Reference: 15. <author> Hamakawa, R., H. Sakagami, and J. Rekimoto. </author> <title> Audio and Video Extensions to Graphical Interface Toolkits. in Network and Operating Systems Support for Digital Audio and Video. </title> <booktitle> Third Intl Workshop Proceedings. 1992. </booktitle> <address> Germany. </address>
Reference: 16. <author> Little, T.D.C. and A. Ghafoor, </author> <title> Interval-based Conceptual Models for Time Dependent Multimedia Data. </title> <journal> IEEE Trans. on Knowledge and Data Engineering, 1993. </journal> <volume> 5(4): </volume> <pages> p. 551-563. </pages>
Reference-contexts: Endpoints are defined as the points that bound an interval, namely its starting point and ending point. Intervals have endpoints and an associated duration, and are used to represent the presentation (runtime execution) of media objects. Current timeline models (e.g., [13-15]) and hierarchic models (e.g., <ref> [16, 17] </ref>) use interval specification. Allens work [18] also discusses relations on intervals within his conceptual level specification. Endpoint synchronization has been used in synch point models (e.g., [2, 3, 6]), event-based models (e.g., [19, 20]), and event-based languages (e.g., [1, 8, 21]). <p> For example, one extension may indicate that a specification is conditional, based upon some specific resource availability (we view this as a behavioral implementation rather than a conceptual specification). We have not yet examined the affects of playing temporal specifications in reverse, which have been discussed in <ref> [3, 16] </ref>. Nor have we addressed spatial specification (when and where windows should be displayed for example), which have been discussed in [3], and implemented in [6].
Reference: 17. <author> Wijesekera, D., D. Kenchamanna-Hosekote, and J. Srivastava, </author> <title> Specification, Verification and Translation of Multimedia Compositions. 1993, </title> <institution> TR94-1, University of Minnesota. </institution>
Reference-contexts: Endpoints are defined as the points that bound an interval, namely its starting point and ending point. Intervals have endpoints and an associated duration, and are used to represent the presentation (runtime execution) of media objects. Current timeline models (e.g., [13-15]) and hierarchic models (e.g., <ref> [16, 17] </ref>) use interval specification. Allens work [18] also discusses relations on intervals within his conceptual level specification. Endpoint synchronization has been used in synch point models (e.g., [2, 3, 6]), event-based models (e.g., [19, 20]), and event-based languages (e.g., [1, 8, 21]). <p> Just as an example of contrast, current hierarchic models can express two of these relations: start-at-start (parallel) and start-at-end (sequential), where t=0, or t&gt;0. These models can simulate the third basic relation end-at-end, finish together, using the start-at-start relation and null objects (their form of delayed synchronization) <ref> [17] </ref>. Null objects delay the beginning of each media object so that their ending times will occur simultaneously (the length of each media object must be known). Still, current hierarchic models can only express Allens 13 relations (they include no other temporal objects to synchronize to).
Reference: 18. <author> Allen, J.F., </author> <title> Maintaining Knowledge about temporal intervals. </title> <journal> Communications of the ACM, </journal> <year> 1983. </year> <month> 26(11). </month>
Reference-contexts: Intervals have endpoints and an associated duration, and are used to represent the presentation (runtime execution) of media objects. Current timeline models (e.g., [13-15]) and hierarchic models (e.g., [16, 17]) use interval specification. Allens work <ref> [18] </ref> also discusses relations on intervals within his conceptual level specification. Endpoint synchronization has been used in synch point models (e.g., [2, 3, 6]), event-based models (e.g., [19, 20]), and event-based languages (e.g., [1, 8, 21]). At a conceptual level, endpoint relations have been defined in [22]. <p> When discussing the expressive power of temporal models, it has been Pazandak, Srivastava A Multimedia Temporal Specification Model and Language Page 11 customary to reference Allens work on interval relations <ref> [18] </ref>. Allen has identified 13 relations that can exist between two intervals. However, these relations are between intervals; and, while some of the models use interval relations, most use endpoint relations.
Reference: 19. <author> Buchanan, M.C. and P.T. Zellweger. </author> <title> Automatic Temporal Layout Mechanisms. </title> <booktitle> in ACM Multimedia 93. 1993. </booktitle> <address> California: </address> <publisher> ACM. </publisher>
Reference-contexts: Current timeline models (e.g., [13-15]) and hierarchic models (e.g., [16, 17]) use interval specification. Allens work [18] also discusses relations on intervals within his conceptual level specification. Endpoint synchronization has been used in synch point models (e.g., [2, 3, 6]), event-based models (e.g., <ref> [19, 20] </ref>), and event-based languages (e.g., [1, 8, 21]). At a conceptual level, endpoint relations have been defined in [22]. In addition, we can classify media objects as either having a predictable or unpredictable duration (e.g., [6, 19]). <p> At a conceptual level, endpoint relations have been defined in [22]. In addition, we can classify media objects as either having a predictable or unpredictable duration (e.g., <ref> [6, 19] </ref>). We define duration as the length of time it takes to complete the presentation of a media object once it has begun. <p> To assist in the understanding of this model we will define the following temporal specification scenario, which we will refer to throughout section 3 (figure 2). We have chosen to use a (slightly modified) graphical notation introduced in <ref> [19] </ref>, for this example. Using this notation, the timeline has been turned on its side, where each media object has its own timeline (its length is proportional to its optimum duration). Square nodes represent media begin and end events, while round nodes represent system or user-defined events. <p> With respect to its implementation, using a runtime temporal formatter like that described by Buchanan and Zellweger <ref> [19] </ref>, we believe that it would be possible to implement a capability to approximate the begin event of the video by approximating the end event of the slide. (Remember, that the begin event of the video is caused by the end event of the slide.) As the end event of the
Reference: 20. <author> Fujikawa, K., et al. </author> <title> Multimedia Presentation System Harmony with Temporal and Active Media. </title> <booktitle> in USENIX. 1991. </booktitle> <address> Nashville, TN. </address>
Reference-contexts: Current timeline models (e.g., [13-15]) and hierarchic models (e.g., [16, 17]) use interval specification. Allens work [18] also discusses relations on intervals within his conceptual level specification. Endpoint synchronization has been used in synch point models (e.g., [2, 3, 6]), event-based models (e.g., <ref> [19, 20] </ref>), and event-based languages (e.g., [1, 8, 21]). At a conceptual level, endpoint relations have been defined in [22]. In addition, we can classify media objects as either having a predictable or unpredictable duration (e.g., [6, 19]). <p> One could associate an event with the appearance of a red balloon, for example. This is an unaffectable event, since intuitively we cannot force the red balloon to appear in the video. Fujikawa <ref> [20] </ref> discusses the automatic generation of events corresponding to spontaneous actions within media objects, such as video. To determine whether an event is affectable or not, we define a system boundary within which we have control over events, and outside of which we do not (see figure 0).
Reference: 21. <author> Horn, F. and J.B. Stefani, </author> <title> On Programming and Supporting Multimedia Object Synchronization. </title> <journal> The Computer Journal, 1993. </journal> <volume> 36(1): </volume> <pages> p. 4-18. </pages>
Reference-contexts: Current timeline models (e.g., [13-15]) and hierarchic models (e.g., [16, 17]) use interval specification. Allens work [18] also discusses relations on intervals within his conceptual level specification. Endpoint synchronization has been used in synch point models (e.g., [2, 3, 6]), event-based models (e.g., [19, 20]), and event-based languages (e.g., <ref> [1, 8, 21] </ref>). At a conceptual level, endpoint relations have been defined in [22]. In addition, we can classify media objects as either having a predictable or unpredictable duration (e.g., [6, 19]).
Reference: 22. <author> Esch, J.W. and T.E. Nagle. </author> <title> Representing Temporal Intervals Using Conceptual Graphs. </title> <booktitle> in Proc. 5th Annual Workshop on Conceptual Structures. </booktitle> <year> 1990. </year>
Reference-contexts: Allens work [18] also discusses relations on intervals within his conceptual level specification. Endpoint synchronization has been used in synch point models (e.g., [2, 3, 6]), event-based models (e.g., [19, 20]), and event-based languages (e.g., [1, 8, 21]). At a conceptual level, endpoint relations have been defined in <ref> [22] </ref>. In addition, we can classify media objects as either having a predictable or unpredictable duration (e.g., [6, 19]). We define duration as the length of time it takes to complete the presentation of a media object once it has begun.
Reference: 23. <author> Buchanan, </author> <title> C.M. and P.T. Zellweger. Scheduling Multimedia Documents Using Temporal Constraints. in Network and Operating Systems Support for Digital Audio and Video. </title> <booktitle> Third Intl Workshop Proceedings. 1992. </booktitle> <address> Germany. </address>
Reference-contexts: To do so, we need to specify a negative delay (e.g. -1 minute). In this situation, the movies start time must be known or derivable (either during compile time or runtime). Ranges provide another dimension to specify delay specification. Range delays were discussed extensively in [2], and later in <ref> [23] </ref> as a means of supporting additional flexibility in specifying start and finish times.
Reference: 24. <author> Gibbs, S. </author> <title> Composite Multimedia and active objects. </title> <booktitle> in OOPSLA. </booktitle> <year> 1991. </year>
Reference-contexts: Finally, models can offer flexibility by supporting alternative methods for implementing synchronization for example, allowing a user to request a specific means of synchronization - as the behavioral implementation <ref> [24] </ref>. Pazandak, Srivastava A Multimedia Temporal Specification Model and Language Page 16 3.0 Temporal Assembly Language In this section, we will describe our temporal specification model and language. Our model includes three powerful and yet simple relations expressing causality, deferment and synchrony (fine-grain synchronization). <p> StartTime Sample i.musicB . StartTime c) . For high fidelity stereo, we could constrain c = 50 ms. If the media intervals were of different types, or the ratio of atoms isnt 1:1, a slight variation of this is required. Other approaches, such as timestamping (e.g. <ref> [24] </ref>) or synchronization points (e.g. [6], [2], [3]) require adding synchronization information to the media itself. Unless this information can easily be modified at runtime, changes to the rate of playback or quality of service will be problematic for these approaches.

References-found: 15

