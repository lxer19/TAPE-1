URL: http://www.neci.nj.nec.com/homepages/omlin/papers/jai.paper.ps.gz
Refering-URL: http://www.neci.nj.nec.com/homepages/omlin/
Root-URL: http://www.neci.nj.nec.com
Email: E-mail: omlin@cs.sun.ac.za fgiles,karvelg@research.nj.nec.com  
Title: Equivalence in Knowledge Representation: Automata, Recurrent Neural Networks, and Dynamical Fuzzy Systems  
Author: Christian W. Omlin a C. Lee Giles b;c K.K. Thornber b 
Address: Princeton, NJ 08540  College Park, MD 20742  
Affiliation: a Department of Computer Science, University of Stellenbosch, South Africa b NEC Research Institute,  c UMIACS, U. of Maryland,  
Abstract: Neuro-fuzzy systems the combination of artificial neural networks with fuzzy logic are becoming increasingly popular. However, neuro-fuzzy systems need to be extended for applications which require context (e.g., speech, handwriting, control). Some of these applications can be modeled in the form of finite-state automata. Previously, it was proved that deterministic finite-state automata (DFAs) can be stably synthesized or mapped into second-order recurrent neural networks with sigmoidal discriminant functions and sparse interconnection topology by programming the networks' weights to +H or H. Based on those results, this paper proposes a synthesis method for mapping fuzzy finite-state automata (FFAs) into recurrent neural networks which is suitable for implementation in VLSI, i.e. the encoding of FFAs is a generalization of the encoding of DFAs. The synthesis method requires FFAs to undergo a transformation prior to being mapped into recurrent networks. Their neurons have a slightly enriched functionality in order to accommodate a fuzzy representation of FFA states, i.e. any state can be occupied with a fuzzy membership that takes on values in the range [0; 1] and several fuzzy states can be occupied at any given time 1 . The enriched neuron functionality allows fuzzy parameters of FFAs to be directly represented as parameters of the neural network. In this paper we prove the stability of fuzzy finite-state dynamics of constructed neural networks for finite values of network weight H and through simulations give empirical validation of the proofs. 1 This is in contrast to stochastic finite-state automata where there exists no ambiguity about which is an automaton's current 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Berenji and P. Khedkar, </author> <title> "Learning and fine tuning fuzzy logic controllers through reinforcement," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 3, no. 5, </volume> <pages> pp. 724-740, </pages> <year> 1992. </year>
Reference-contexts: However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23]. Fuzzy logic [51] provides a mathematical foundation for approximate reasoning; fuzzy logic has proven very successful in a variety of applications <ref> [1, 4, 8, 10, 13, 21, 26, 30, 39, 49] </ref>. The parameters of adaptive fuzzy systems have clear physical meanings which facilitates the choice of their initial values. Furthermore, rule-based information can be incorporated into fuzzy systems in a systematic way. <p> ; : : : ; a m g is the alphabet, Q = fq 1 ; : : : ; q n g is a set of states, R 2 Q is the automaton's fuzzy start state 4 , Z is a finite output alphabet, ffi : fi Q fi <ref> [0; 1] </ref> ! Q is the fuzzy transition map, and ! : Q ! Z is the output map. Weights ijk 2 [0; 1] define the `fuzziness' of state transitions, i.e. a FFA can simultaneously be in different states with a different degree of certainty. <p> g is a set of states, R 2 Q is the automaton's fuzzy start state 4 , Z is a finite output alphabet, ffi : fi Q fi <ref> [0; 1] </ref> ! Q is the fuzzy transition map, and ! : Q ! Z is the output map. Weights ijk 2 [0; 1] define the `fuzziness' of state transitions, i.e. a FFA can simultaneously be in different states with a different degree of certainty. The particular output mapping depends on the nature of the an application. <p> Definition 4.2 Consider a FFA M that is processing some string s = oe 1 oe 2 : : : oe L with oe i 2 . As M reads each symbol oe i , it makes simultaneous weighted state transitions fi Q fi <ref> [0; 1] </ref> according to the fuzzy transition map ffi (q j ; a k ; ijk ) = q i . The set of distinct weights f ijk g of the fuzzy transition map at time t is called the active weight set. <p> We randomly assigned weights in the range <ref> [0; 1] </ref> to all transitions in increments of 0.1. The maximum indegree was D in (M ) = r = 5.
Reference: [2] <author> J. Bezdek, </author> <title> "Fuzzy logic and neural networks," </title> <journal> IEEE Trans. on Neural Networks, </journal> <volume> vol. 3, </volume> <year> 1992. </year> <note> Special Issue. </note>
Reference-contexts: 1 Introduction There has been an increased interest in hybrid systems as more applications using hybrid models emerge [5]. However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see <ref> [2, 23] </ref>. Fuzzy logic [51] provides a mathematical foundation for approximate reasoning; fuzzy logic has proven very successful in a variety of applications [1, 4, 8, 10, 13, 21, 26, 30, 39, 49].
Reference: [3] <author> A. Blanco, M. Delgado, and M. Pegalajar, </author> <title> "Fuzzy grammar inference using neural networks," </title> <type> tech. rep., </type> <institution> Department of Computer Science and Artificial Intelligence, University of Granada, Spain, </institution> <year> 1997. </year>
Reference-contexts: Based on our theoretical analysis, we know that they have the ability to represent FFAs in the form of equivalent deterministic acceptors. Recent work reported in <ref> [3] </ref> addresses these questions. Instead of augmenting a second-order network with a linear output layer for computing the fuzzy string membership as suggested in [38], the authors chose to assign the fuzzy string memberships i occurring in the training set to individual output neurons.
Reference: [4] <author> P. Bonissone, V. Badami, K. Chiang, P. Khedkar, K. Marcelle, and M. Schutten, </author> <title> "Industrial applications of fuzzy logic at General Electric," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 83, no. 3, </volume> <pages> pp. 450-465, </pages> <year> 1995. </year>
Reference-contexts: However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23]. Fuzzy logic [51] provides a mathematical foundation for approximate reasoning; fuzzy logic has proven very successful in a variety of applications <ref> [1, 4, 8, 10, 13, 21, 26, 30, 39, 49] </ref>. The parameters of adaptive fuzzy systems have clear physical meanings which facilitates the choice of their initial values. Furthermore, rule-based information can be incorporated into fuzzy systems in a systematic way.
Reference: [5] <author> L. Bookman and R. Sun, </author> <title> "Architectures for integrating symbolic and neural processes," </title> <journal> Connection Science, </journal> <volume> vol. 5, no. 3,4, </volume> <year> 1993. </year> <note> Special Issue. </note>
Reference-contexts: 1 Introduction There has been an increased interest in hybrid systems as more applications using hybrid models emerge <ref> [5] </ref>. However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23].
Reference: [6] <author> M. Casey, </author> <title> "The dynamics of discrete-time computation, with application to recurrent neural networks and finite state machine extraction," </title> <journal> Neural Computation, </journal> <volume> vol. 8, no. 6, </volume> <pages> pp. 1135-1178, </pages> <year> 1996. </year> <month> 28 </month>
Reference-contexts: Their computational capabilities [43, 44] make recurrent neural networks appropriate tools for modeling and refining through learning systems whose current state depends on previous states and inputs [16] and there has been a lot of interest in learning, synthesis, and extraction of finite-state automata in recurrent neural networks <ref> [6, 9, 12, 14, 17, 40, 48, 52] </ref>. A variety of neural network implementations of FFAs have been proposed [19, 20, 25, 47]. We have previously shown how fuzzy finite-state automata (FFAs) can be mapped into recurrent neural networks with second-order weights using a crisp representation of FFA states [38]. <p> Apart from the use of multiple classes, training networks to compute the fuzzy string membership was identical with training networks to behave like DFAs. The authors empirically verified through information extraction <ref> [6, 35] </ref> that recurrent networks trained on fuzzy strings develop a crisp internal representation of FFAs, i.e. that they represent FFAs in the form of equivalent deterministic acceptors. Thus, our theoretical analysis correctly predicted the knowledge representation of trained networks.
Reference: [7] <author> F. Cellier and Y. Pan, </author> <title> "Fuzzy adaptive recurrent counterpropagation neural networks: A tool for efficient implementation of qualitative models of dynamic processes," </title> <journal> J. Systems Engineering, </journal> <volume> vol. 5, no. 4, </volume> <pages> pp. 207-222, </pages> <year> 1995. </year>
Reference-contexts: From a control theory point of view, fuzzy finite-state automata have been shown to be useful for modeling fuzzy dynamical systems, in particular where recurrent neural networks have been used for system identification <ref> [7, 27, 28, 29] </ref>.
Reference: [8] <author> S. Chiu, S. Chand, D. Moore, and A. Chaudhary, </author> <title> "Fuzzy logic for control of roll and moment for a flexible wing aircraft," </title> <journal> IEEE Control Systems Magazine, </journal> <volume> vol. 11, no. 4, </volume> <pages> pp. 42-48, </pages> <year> 1991. </year>
Reference-contexts: However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23]. Fuzzy logic [51] provides a mathematical foundation for approximate reasoning; fuzzy logic has proven very successful in a variety of applications <ref> [1, 4, 8, 10, 13, 21, 26, 30, 39, 49] </ref>. The parameters of adaptive fuzzy systems have clear physical meanings which facilitates the choice of their initial values. Furthermore, rule-based information can be incorporated into fuzzy systems in a systematic way.
Reference: [9] <author> A. Cleeremans, D. Servan-Schreiber, and J. McClelland, </author> <title> "Finite state automata and simple recurrent recurrent networks," </title> <journal> Neural Computation, </journal> <volume> vol. 1, no. 3, </volume> <pages> pp. 372-381, </pages> <year> 1989. </year>
Reference-contexts: Their computational capabilities [43, 44] make recurrent neural networks appropriate tools for modeling and refining through learning systems whose current state depends on previous states and inputs [16] and there has been a lot of interest in learning, synthesis, and extraction of finite-state automata in recurrent neural networks <ref> [6, 9, 12, 14, 17, 40, 48, 52] </ref>. A variety of neural network implementations of FFAs have been proposed [19, 20, 25, 47]. We have previously shown how fuzzy finite-state automata (FFAs) can be mapped into recurrent neural networks with second-order weights using a crisp representation of FFA states [38].
Reference: [10] <author> J. Corbin, </author> <title> "A fuzzy logic-based financial transaction system," </title> <journal> Embedded Systems Programming, </journal> <volume> vol. 7, no. 12, </volume> <editor> p. </editor> <volume> 24, </volume> <year> 1994. </year>
Reference-contexts: However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23]. Fuzzy logic [51] provides a mathematical foundation for approximate reasoning; fuzzy logic has proven very successful in a variety of applications <ref> [1, 4, 8, 10, 13, 21, 26, 30, 39, 49] </ref>. The parameters of adaptive fuzzy systems have clear physical meanings which facilitates the choice of their initial values. Furthermore, rule-based information can be incorporated into fuzzy systems in a systematic way.
Reference: [11] <author> D. Dubois and H. Prade, </author> <title> Fuzzy sets and systems: </title> <journal> theory and applications, </journal> <volume> vol. </volume> <booktitle> 144 of Mathematics in Science and Engineering, </booktitle> <pages> pp. 220-226. </pages> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: Note that transitions from states 1 and 4 on input symbols `0' are fuzzy (ffi (1; 0; :) = f2; 3g and ffi (4; 0; :) = f2; 3g). 2 Fuzzy Finite-State Automata In this section, we give a formal definition of FFAs <ref> [11] </ref> and illustrate the definition with an example. <p> For a possible definition, see e.g. <ref> [11] </ref>. <p> It has been shown that a restricted class of FFAs whose initial state is a single crisp state is equivalent with the class of FFAs described in Definition 2.1 <ref> [11] </ref>.
Reference: [12] <author> J. Elman, </author> <title> "Finding structure in time," </title> <journal> Cognitive Science, </journal> <volume> vol. 14, </volume> <pages> pp. 179-211, </pages> <year> 1990. </year>
Reference-contexts: Their computational capabilities [43, 44] make recurrent neural networks appropriate tools for modeling and refining through learning systems whose current state depends on previous states and inputs [16] and there has been a lot of interest in learning, synthesis, and extraction of finite-state automata in recurrent neural networks <ref> [6, 9, 12, 14, 17, 40, 48, 52] </ref>. A variety of neural network implementations of FFAs have been proposed [19, 20, 25, 47]. We have previously shown how fuzzy finite-state automata (FFAs) can be mapped into recurrent neural networks with second-order weights using a crisp representation of FFA states [38].
Reference: [13] <author> L. Franquelo and J. Chavez, "Fasy: </author> <title> A fuzzy-logic based tool for analog synthesis," </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits, </journal> <volume> vol. 15, no. 7, </volume> <editor> p. </editor> <volume> 705, </volume> <year> 1996. </year>
Reference-contexts: However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23]. Fuzzy logic [51] provides a mathematical foundation for approximate reasoning; fuzzy logic has proven very successful in a variety of applications <ref> [1, 4, 8, 10, 13, 21, 26, 30, 39, 49] </ref>. The parameters of adaptive fuzzy systems have clear physical meanings which facilitates the choice of their initial values. Furthermore, rule-based information can be incorporated into fuzzy systems in a systematic way.
Reference: [14] <author> P. Frasconi, M. Gori, M. Maggini, and G. </author> <title> Soda, "Representation of finite state automata in recurrent radial basis function networks," </title> <journal> Machine Learning, </journal> <volume> vol. 23, no. 1, </volume> <pages> pp. 5-32, </pages> <year> 1996. </year>
Reference-contexts: Their computational capabilities [43, 44] make recurrent neural networks appropriate tools for modeling and refining through learning systems whose current state depends on previous states and inputs [16] and there has been a lot of interest in learning, synthesis, and extraction of finite-state automata in recurrent neural networks <ref> [6, 9, 12, 14, 17, 40, 48, 52] </ref>. A variety of neural network implementations of FFAs have been proposed [19, 20, 25, 47]. We have previously shown how fuzzy finite-state automata (FFAs) can be mapped into recurrent neural networks with second-order weights using a crisp representation of FFA states [38]. <p> of view, it may seem more natural to use radialbasis functions to represent fuzzy state membership (they are often used along with triangular and trapezoidal membership functions in the design of fuzzy systems) instead of sigmoidal discriminant functions (DFAs can be mapped 27 into recurrent neural networks with radialbasis functions <ref> [14] </ref>). It would be interesting to investigate map-pings of FFA into recurrent neural networks with radialbasis discriminant functions, and to compare the encoding algorithm to our method.
Reference: [15] <author> B. Gaines and L. Kohout, </author> <title> "The logic of automata," </title> <journal> International Journal of General Systems, </journal> <volume> vol. 2, </volume> <pages> pp. 191-208, </pages> <year> 1976. </year>
Reference-contexts: Artificial neural networks have become valuable computational tools in their own right for tasks such as pattern recognition, control, and forecasting. Fuzzy finite-state automata (FFAs) 2 automaton with FFA have a long history [41, 50]; the fundamentals of FFAs have been discussed in <ref> [15] </ref> without presenting a systematic machine synthesis method. Their potential as design tools for modeling a variety of systems is beginning to be exploited [27, 33].
Reference: [16] <author> C. Giles, G. Kuhn, and R. Williams, </author> <title> "Dynamic recurrent neural networks: </title> <journal> Theory and applications," IEEE Transactions on Neural Networks, </journal> <volume> vol. 5, no. 2, </volume> <year> 1994. </year> <note> Special Issue. </note>
Reference-contexts: Their computational capabilities [43, 44] make recurrent neural networks appropriate tools for modeling and refining through learning systems whose current state depends on previous states and inputs <ref> [16] </ref> and there has been a lot of interest in learning, synthesis, and extraction of finite-state automata in recurrent neural networks [6, 9, 12, 14, 17, 40, 48, 52]. A variety of neural network implementations of FFAs have been proposed [19, 20, 25, 47].
Reference: [17] <author> C. Giles, C. Miller, D. Chen, H. Chen, G. Sun, and Y. Lee, </author> <title> "Learning and extracting finite state automata with second-order recurrent neural networks," </title> <journal> Neural Computation, </journal> <volume> vol. 4, no. 3, </volume> <editor> p. </editor> <volume> 380, </volume> <year> 1992. </year>
Reference-contexts: Their computational capabilities [43, 44] make recurrent neural networks appropriate tools for modeling and refining through learning systems whose current state depends on previous states and inputs [16] and there has been a lot of interest in learning, synthesis, and extraction of finite-state automata in recurrent neural networks <ref> [6, 9, 12, 14, 17, 40, 48, 52] </ref>. A variety of neural network implementations of FFAs have been proposed [19, 20, 25, 47]. We have previously shown how fuzzy finite-state automata (FFAs) can be mapped into recurrent neural networks with second-order weights using a crisp representation of FFA states [38].
Reference: [18] <author> C. Giles and C. Omlin, </author> <title> "Extraction, insertion and refinement of symbolic rules in dynamically driven recurrent neural networks," </title> <journal> Connection Science, </journal> <volume> vol. 5, no. 3 & 4, </volume> <pages> pp. 307-337, </pages> <year> 1993. </year>
Reference-contexts: design, and recurrent neural networks can be directly implemented in chips, this approach could be useful for applications where FFAs are used in conjunction with recurrent networks and VLSI [42, 32] or the method could be applied to incorporate a priori knowledge into recurrent neural networks used for knowledge refinement <ref> [18] </ref>. The remainder of this paper is organized as follows: Fuzzy finite-state automata are introduced in Section 2. The fuzzy representation of FFA states and transitions in recurrent networks are discussed in Section 3.
Reference: [19] <author> J. Grantner and M. Patyra, </author> <title> "Synthesis and analysis of fuzzy logic finite state machine models," </title> <booktitle> in Proc. of the Third IEEE Conf. on Fuzzy Systems, </booktitle> <volume> vol. I, </volume> <pages> pp. 205-210, </pages> <year> 1994. </year>
Reference-contexts: This makes RNNs appropriate tools for modeling and learning many diverse dynamical problems from control to signal processing . A 2 The abbreviation `FFA' will denote a fuzzy finite-state automaton throughout the remainder of this paper. 2 variety of implementations of FFAs have been proposed <ref> [19, 25] </ref>, some in digital systems. However, this to our knowledge is the first proof that such implementations in sigmoid activation RNNs are stable, i.e. guaranteed convergence to the correct prespecified membership. <p> A variety of neural network implementations of FFAs have been proposed <ref> [19, 20, 25, 47] </ref>. We have previously shown how fuzzy finite-state automata (FFAs) can be mapped into recurrent neural networks with second-order weights using a crisp representation of FFA states [38].
Reference: [20] <author> J. Grantner and M. Patyra, </author> <title> "VLSI implementations of fuzzy logic finite state machines," </title> <booktitle> in Proceedings of the Fifth IFSA Congress, </booktitle> <pages> pp. 781-784, </pages> <year> 1993. </year> <month> 29 </month>
Reference-contexts: A variety of neural network implementations of FFAs have been proposed <ref> [19, 20, 25, 47] </ref>. We have previously shown how fuzzy finite-state automata (FFAs) can be mapped into recurrent neural networks with second-order weights using a crisp representation of FFA states [38].
Reference: [21] <author> T. L. Hardy, </author> <title> "Multi-objective decision-making under uncertainty fuzzy logic methods," </title> <type> Tech. Rep. TM 106796, </type> <institution> NASA, </institution> <address> Washington, D.C., </address> <year> 1994. </year>
Reference-contexts: However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23]. Fuzzy logic [51] provides a mathematical foundation for approximate reasoning; fuzzy logic has proven very successful in a variety of applications <ref> [1, 4, 8, 10, 13, 21, 26, 30, 39, 49] </ref>. The parameters of adaptive fuzzy systems have clear physical meanings which facilitates the choice of their initial values. Furthermore, rule-based information can be incorporated into fuzzy systems in a systematic way.
Reference: [22] <author> J. Hendler, </author> <title> "Developing hybrid symbolic/connectionist models," in Advances in Connectionist and Neural Computation Theory (J. </title> <editor> Barnden and J. Pollack, eds.), </editor> <publisher> Ablex Publishing, </publisher> <year> 1991. </year>
Reference-contexts: 1 Introduction There has been an increased interest in hybrid systems as more applications using hybrid models emerge [5]. However, there are many definitions of hybrid systems <ref> [22, 24, 45] </ref>. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23].
Reference: [23] <author> C. S. Herrmann, </author> <title> "A hybrid fuzzy-neural expert system for diagnosis," </title> <booktitle> in Proc. of the Fourteenth International Joint Conf. on Artificial Intelligence, </booktitle> <volume> vol. I, </volume> <pages> pp. 494-502, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction There has been an increased interest in hybrid systems as more applications using hybrid models emerge [5]. However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see <ref> [2, 23] </ref>. Fuzzy logic [51] provides a mathematical foundation for approximate reasoning; fuzzy logic has proven very successful in a variety of applications [1, 4, 8, 10, 13, 21, 26, 30, 39, 49].
Reference: [24] <author> V. Honavar and L. Uhr, eds., </author> <title> Artificial Intelligence and Neural Networks: Steps toward Principled Integration. </title> <address> San Diego, CA: </address> <publisher> Academic Press, </publisher> <year> 1994. </year>
Reference-contexts: 1 Introduction There has been an increased interest in hybrid systems as more applications using hybrid models emerge [5]. However, there are many definitions of hybrid systems <ref> [22, 24, 45] </ref>. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23].
Reference: [25] <author> E. Khan and F. Unal, </author> <title> "Recurrent fuzzy logic using neural networks," in Advances in fuzzy logic, neural networks, and genetic algorithms (T. Furuhashi, </title> <editor> ed.), </editor> <booktitle> Lecture Notes in AI, </booktitle> <publisher> Springer Verlag, </publisher> <year> 1995. </year>
Reference-contexts: This makes RNNs appropriate tools for modeling and learning many diverse dynamical problems from control to signal processing . A 2 The abbreviation `FFA' will denote a fuzzy finite-state automaton throughout the remainder of this paper. 2 variety of implementations of FFAs have been proposed <ref> [19, 25] </ref>, some in digital systems. However, this to our knowledge is the first proof that such implementations in sigmoid activation RNNs are stable, i.e. guaranteed convergence to the correct prespecified membership. <p> A variety of neural network implementations of FFAs have been proposed <ref> [19, 20, 25, 47] </ref>. We have previously shown how fuzzy finite-state automata (FFAs) can be mapped into recurrent neural networks with second-order weights using a crisp representation of FFA states [38].
Reference: [26] <author> W. J. M. Kickert and H. van Nauta Lemke, </author> <title> "Application of a fuzzy controller in a warm water plant," </title> <journal> Automatica, </journal> <volume> vol. 12, no. 4, </volume> <pages> pp. 301-308, </pages> <year> 1976. </year>
Reference-contexts: However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23]. Fuzzy logic [51] provides a mathematical foundation for approximate reasoning; fuzzy logic has proven very successful in a variety of applications <ref> [1, 4, 8, 10, 13, 21, 26, 30, 39, 49] </ref>. The parameters of adaptive fuzzy systems have clear physical meanings which facilitates the choice of their initial values. Furthermore, rule-based information can be incorporated into fuzzy systems in a systematic way.
Reference: [27] <author> E. Kosmatopoulos and M. Christodoulou, </author> <title> "Neural networks for identification of fuzzy dynamical systems: an application to identification of vehicle highway systems," </title> <type> tech. rep., </type> <institution> Dept. of Electronic and Computer Engineering, Technical U. of Crete, </institution> <year> 1995. </year>
Reference-contexts: Fuzzy finite-state automata (FFAs) 2 automaton with FFA have a long history [41, 50]; the fundamentals of FFAs have been discussed in [15] without presenting a systematic machine synthesis method. Their potential as design tools for modeling a variety of systems is beginning to be exploited <ref> [27, 33] </ref>. Such systems have two major characteristics: (1) the current state of the system depends on past states and current inputs, and (2) the knowledge about the system's current state is vague or uncertain. <p> From a control theory point of view, fuzzy finite-state automata have been shown to be useful for modeling fuzzy dynamical systems, in particular where recurrent neural networks have been used for system identification <ref> [7, 27, 28, 29] </ref>.
Reference: [28] <author> E. Kosmatopoulos and M. Christodoulou, </author> <title> "Structural properties of gradient recurrent high-order neural networks," </title> <journal> IEEE Transactions on Circuits and Systems, </journal> <year> 1995. </year>
Reference-contexts: From a control theory point of view, fuzzy finite-state automata have been shown to be useful for modeling fuzzy dynamical systems, in particular where recurrent neural networks have been used for system identification <ref> [7, 27, 28, 29] </ref>.
Reference: [29] <author> E. Kosmatopoulos, M. Polycarpou, M. Christodoulou, and P. Ioannou, </author> <title> "High-order neural networks for identification of dynamical systems," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 6, no. 2, </volume> <pages> pp. 422-431, </pages> <year> 1995. </year>
Reference-contexts: From a control theory point of view, fuzzy finite-state automata have been shown to be useful for modeling fuzzy dynamical systems, in particular where recurrent neural networks have been used for system identification <ref> [7, 27, 28, 29] </ref>.
Reference: [30] <author> C. Lee, </author> <title> "Fuzzy logic in control systems: fuzzy logic controller," </title> <journal> IEEE Transactions on Man, Systems, and Cybernetics, </journal> <volume> vol. SMC-20, no. 2, </volume> <pages> pp. 404-435, </pages> <year> 1990. </year>
Reference-contexts: However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23]. Fuzzy logic [51] provides a mathematical foundation for approximate reasoning; fuzzy logic has proven very successful in a variety of applications <ref> [1, 4, 8, 10, 13, 21, 26, 30, 39, 49] </ref>. The parameters of adaptive fuzzy systems have clear physical meanings which facilitates the choice of their initial values. Furthermore, rule-based information can be incorporated into fuzzy systems in a systematic way.
Reference: [31] <author> R. Maclin and J. Shavlik, </author> <title> "Using knowledge-based neural networks to improve algorithms: Refining the chou-fasman algorithm for protein folding," </title> <journal> Machine Learning, </journal> <volume> vol. 11, </volume> <pages> pp. 195-215, </pages> <year> 1993. </year>
Reference-contexts: This can lead to robustness that is noise independent. Finally, with the extraction of knowledge from trained neural networks, the methods dicussed here could potentially be applied to incorporating and refining a priori fuzzy knowledge in recurrent neural networks <ref> [31] </ref>. The computational capabilities of recurrent neural networks (RNNs) are quite powerful [43]. RNNs are also capable of modeling and learning state processes and automata [40]. This makes RNNs appropriate tools for modeling and learning many diverse dynamical problems from control to signal processing .
Reference: [32] <author> C. Mead, </author> <title> Analog VLSI and Neural Systems. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Since DFAs are used in high-level VLSI design, and recurrent neural networks can be directly implemented in chips, this approach could be useful for applications where FFAs are used in conjunction with recurrent networks and VLSI <ref> [42, 32] </ref> or the method could be applied to incorporate a priori knowledge into recurrent neural networks used for knowledge refinement [18]. The remainder of this paper is organized as follows: Fuzzy finite-state automata are introduced in Section 2.
Reference: [33] <author> S. Mensch and H. Lipp, </author> <title> "Fuzzy specification of finite state machines," </title> <booktitle> in Proceedings of the European Design Automation Conference, </booktitle> <pages> pp. 622-626, </pages> <year> 1990. </year>
Reference-contexts: Fuzzy finite-state automata (FFAs) 2 automaton with FFA have a long history [41, 50]; the fundamentals of FFAs have been discussed in [15] without presenting a systematic machine synthesis method. Their potential as design tools for modeling a variety of systems is beginning to be exploited <ref> [27, 33] </ref>. Such systems have two major characteristics: (1) the current state of the system depends on past states and current inputs, and (2) the knowledge about the system's current state is vague or uncertain.
Reference: [34] <author> C. Omlin and C. Giles, </author> <title> "Constructing deterministic finite-state automata in recurrent neural networks," </title> <journal> Journal of the ACM, </journal> <volume> vol. 43, no. 6, </volume> <pages> pp. 937-972, </pages> <year> 1996. </year> <month> 30 </month>
Reference-contexts: However, this to our knowledge is the first proof that such implementations in sigmoid activation RNNs are stable, i.e. guaranteed convergence to the correct prespecified membership. This proof is based on previous work of stably mapping deterministic finite-state automata (DFAs) in recurrent neural networks reported in <ref> [34] </ref>. In contrast to DFAs, a set of FFA states can be occupied to varying degrees at any point in time; this fuzzification of states generally reduces the size of the model, and the dynamics of the system being modeled is often more accessible to a direct interpretation. <p> The stability of the encoding is derived in Section 6. A discussion of simulation results in Section 7, and a summary of the results and possible directions for future research in Section 8 conclude this paper. 3 For reasons of completeness, we have included the main results from <ref> [34] </ref> which laid the foundations for this and other papers [37, 38]. Thus, by necessity, there is some overlap. 4 1 2 0/0.5 1/0.3 0/0.6 0/0.1 1/0.4 weighted state transitions. State 1 is the automaton's start state. <p> Since the method for encoding FFAs in recurrent neural networks is a generalization of the method for encoding DFAs, we will briefly discuss the DFA encoding algorithm. 3.2 DFA Encoding Algorithm We make use of an algorithm used for encoding deterministic finite-state automata (DFAs) <ref> [34, 37] </ref>. <p> The architecture is illustrated in Figure 2. DFAs can be encoded in discrete-time, second-order recurrent neural networks with sigmoidal discriminant functions such that the DFA and constructed network accept the same regular language <ref> [34] </ref>. <p> This is the same technique using for programming DFA state transitions in recurrent networks <ref> [34] </ref> and for encoding partial prior knowledge of a DFA for rule refinement [36]. 4 Automata Transformation 4.1 Preliminaries The above encoding algorithm leaves open the possibility for ambiguities when a FFA is encoded in a recurrent network as follows: Consider two FFA states q j and q l with transitions <p> The ideal values for low and high signals are 0 and ijk , respectively. A detailed analysis of all possible network state changes in <ref> [34] </ref> revealed that, for the purpose of demonstrating stability of internal finite-state representations, it is sufficient to consider the following two worst cases: (1) A neuron which does not correspond to a current fuzzy automaton state receives the same residual low input from all other neurons that it is connected to, <p> for u = f0:0; 0:1g, but only one fixed point for u = f0:4; 0:9g. 6.2 Fixed Point Analysis for Sigmoidal Discriminant Function Here, we summarize without proofs some of the results that we used to demonstrate stability of neural DFA encodings; details of the proofs can be found in <ref> [34] </ref>. <p> the constructed network has at most 3mn second-order weights with alphabet w = fH; 0; +Hg, n + 1 biases with alphabet b = fH=2g, and maximum fan-out 3m. 2 For min = max = 1, conditions (1)-(3) of the above theorem reduce to those found for stable DFA encodings <ref> [34] </ref>. This is consistent with a crisp representation of DFA states. 7 Simulations In order to validate our theory, we constructed a fuzzy encoding of a randomly generated FFA with 100 states (after the execution of the FFA transformation algorithm) over the input alphabet f0; 1g.
Reference: [35] <author> C. Omlin and C. Giles, </author> <title> "Extraction of rules from discrete-time recurrent neural networks," </title> <booktitle> Neural Networks, </booktitle> <volume> vol. 9, no. 1, </volume> <pages> pp. 41-52, </pages> <year> 1996. </year>
Reference-contexts: Apart from the use of multiple classes, training networks to compute the fuzzy string membership was identical with training networks to behave like DFAs. The authors empirically verified through information extraction <ref> [6, 35] </ref> that recurrent networks trained on fuzzy strings develop a crisp internal representation of FFAs, i.e. that they represent FFAs in the form of equivalent deterministic acceptors. Thus, our theoretical analysis correctly predicted the knowledge representation of trained networks.
Reference: [36] <author> C. Omlin and C. Giles, </author> <title> "Rule revision with recurrent neural networks," </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> vol. 8, no. 1, </volume> <pages> pp. 183-188, </pages> <year> 1996. </year>
Reference-contexts: This is the same technique using for programming DFA state transitions in recurrent networks [34] and for encoding partial prior knowledge of a DFA for rule refinement <ref> [36] </ref>. 4 Automata Transformation 4.1 Preliminaries The above encoding algorithm leaves open the possibility for ambiguities when a FFA is encoded in a recurrent network as follows: Consider two FFA states q j and q l with transitions ffi (q j ; a k ; ijk ) = ffi (q l
Reference: [37] <author> C. Omlin and C. Giles, </author> <title> "Stable encoding of large finite-state automata in recurrent neural networks with sigmoid discriminants," </title> <journal> Neural Computation, </journal> <volume> vol. 8, no. 7, </volume> <pages> pp. 675-696, </pages> <year> 1996. </year>
Reference-contexts: A discussion of simulation results in Section 7, and a summary of the results and possible directions for future research in Section 8 conclude this paper. 3 For reasons of completeness, we have included the main results from [34] which laid the foundations for this and other papers <ref> [37, 38] </ref>. Thus, by necessity, there is some overlap. 4 1 2 0/0.5 1/0.3 0/0.6 0/0.1 1/0.4 weighted state transitions. State 1 is the automaton's start state. <p> Since the method for encoding FFAs in recurrent neural networks is a generalization of the method for encoding DFAs, we will briefly discuss the DFA encoding algorithm. 3.2 DFA Encoding Algorithm We make use of an algorithm used for encoding deterministic finite-state automata (DFAs) <ref> [34, 37] </ref>.
Reference: [38] <author> C. Omlin, K. Thornber, and C. Giles, </author> <title> "Fuzzy finite-state automata can be deterministically encoded into recurrent neural networks," </title> <journal> IEEE Transactions on Fuzzy Systems, </journal> <volume> vol. 6, no. 1, </volume> <pages> pp. 76-89, </pages> <year> 1998. </year>
Reference-contexts: A variety of neural network implementations of FFAs have been proposed [19, 20, 25, 47]. We have previously shown how fuzzy finite-state automata (FFAs) can be mapped into recurrent neural networks with second-order weights using a crisp representation of FFA states <ref> [38] </ref>. That encoding required a transformation of a FFA into a deterministic finite-state automaton (DFA) which computes the membership functions for strings; it is only applicable to a restricted class of FFAs which have final states. <p> Recent work reported in [3] addresses these questions. Instead of augmenting a second-order network with a linear output layer for computing the fuzzy string membership as suggested in <ref> [38] </ref>, the authors chose to assign the fuzzy string memberships i occurring in the training set to individual output neurons. Thus, they transformed the fuzzy inference problem into a binary inference problem with multiple classes. <p> A discussion of simulation results in Section 7, and a summary of the results and possible directions for future research in Section 8 conclude this paper. 3 For reasons of completeness, we have included the main results from [34] which laid the foundations for this and other papers <ref> [37, 38] </ref>. Thus, by necessity, there is some overlap. 4 1 2 0/0.5 1/0.3 0/0.6 0/0.1 1/0.4 weighted state transitions. State 1 is the automaton's start state. <p> i:k ) ' 0 (note that strong low signals imply strong high signals by Lemma 6.7). 8 Conclusions We have previously shown that it is possible to deterministically encode fuzzy finite-state automata (FFA) in recurrent neural networks by transforming any given FFA into a deterministic acceptor which assign string membership <ref> [38] </ref>. In such a deterministic encoding, only the network's classification of strings is fuzzy, whereas the representation of states is crisp. The correspondence between FFA and network parameters - i.e. fuzzy transition memberships and network weights, respectively is lost in the transformation.
Reference: [39] <author> C. Pappis and E. Mamdani, </author> <title> "A fuzzy logic controller for a traffic junction," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol. SMC-7, no. 10, </volume> <pages> pp. 707-717, </pages> <year> 1977. </year>
Reference-contexts: However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23]. Fuzzy logic [51] provides a mathematical foundation for approximate reasoning; fuzzy logic has proven very successful in a variety of applications <ref> [1, 4, 8, 10, 13, 21, 26, 30, 39, 49] </ref>. The parameters of adaptive fuzzy systems have clear physical meanings which facilitates the choice of their initial values. Furthermore, rule-based information can be incorporated into fuzzy systems in a systematic way.
Reference: [40] <author> J. Pollack, </author> <title> "The induction of dynamical recognizers," </title> <journal> Machine Learning, </journal> <volume> vol. 7, </volume> <pages> pp. 227-252, </pages> <year> 1991. </year>
Reference-contexts: The computational capabilities of recurrent neural networks (RNNs) are quite powerful [43]. RNNs are also capable of modeling and learning state processes and automata <ref> [40] </ref>. This makes RNNs appropriate tools for modeling and learning many diverse dynamical problems from control to signal processing . <p> Their computational capabilities [43, 44] make recurrent neural networks appropriate tools for modeling and refining through learning systems whose current state depends on previous states and inputs [16] and there has been a lot of interest in learning, synthesis, and extraction of finite-state automata in recurrent neural networks <ref> [6, 9, 12, 14, 17, 40, 48, 52] </ref>. A variety of neural network implementations of FFAs have been proposed [19, 20, 25, 47]. We have previously shown how fuzzy finite-state automata (FFAs) can be mapped into recurrent neural networks with second-order weights using a crisp representation of FFA states [38].
Reference: [41] <author> E. Santos, </author> <title> "Maximin automata," </title> <journal> Information and Control, </journal> <volume> vol. 13, </volume> <pages> pp. 363-377, </pages> <year> 1968. </year>
Reference-contexts: Artificial neural networks have become valuable computational tools in their own right for tasks such as pattern recognition, control, and forecasting. Fuzzy finite-state automata (FFAs) 2 automaton with FFA have a long history <ref> [41, 50] </ref>; the fundamentals of FFAs have been discussed in [15] without presenting a systematic machine synthesis method. Their potential as design tools for modeling a variety of systems is beginning to be exploited [27, 33].
Reference: [42] <author> B. J. Sheu, </author> <booktitle> Neural Information Processing and VLSI. </booktitle> <address> Boston, MA: </address> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: Since DFAs are used in high-level VLSI design, and recurrent neural networks can be directly implemented in chips, this approach could be useful for applications where FFAs are used in conjunction with recurrent networks and VLSI <ref> [42, 32] </ref> or the method could be applied to incorporate a priori knowledge into recurrent neural networks used for knowledge refinement [18]. The remainder of this paper is organized as follows: Fuzzy finite-state automata are introduced in Section 2.
Reference: [43] <author> H. Siegelmann and E. Sontag, </author> <title> "On the computational power of neural nets," </title> <journal> Journal of Computer and System Sciences, </journal> <volume> vol. 50, no. 1, </volume> <pages> pp. 132-150, </pages> <year> 1995. </year>
Reference-contexts: Finally, with the extraction of knowledge from trained neural networks, the methods dicussed here could potentially be applied to incorporating and refining a priori fuzzy knowledge in recurrent neural networks [31]. The computational capabilities of recurrent neural networks (RNNs) are quite powerful <ref> [43] </ref>. RNNs are also capable of modeling and learning state processes and automata [40]. This makes RNNs appropriate tools for modeling and learning many diverse dynamical problems from control to signal processing . <p> From a control theory point of view, fuzzy finite-state automata have been shown to be useful for modeling fuzzy dynamical systems, in particular where recurrent neural networks have been used for system identification [7, 27, 28, 29]. Their computational capabilities <ref> [43, 44] </ref> make recurrent neural networks appropriate tools for modeling and refining through learning systems whose current state depends on previous states and inputs [16] and there has been a lot of interest in learning, synthesis, and extraction of finite-state automata in recurrent neural networks [6, 9, 12, 14, 17, 40,
Reference: [44] <author> A. Sperduti, </author> <title> "On the computational power of recurrent neural networks for structures," Neural Networks, </title> <note> vol. to be published, </note> <year> 1997. </year>
Reference-contexts: From a control theory point of view, fuzzy finite-state automata have been shown to be useful for modeling fuzzy dynamical systems, in particular where recurrent neural networks have been used for system identification [7, 27, 28, 29]. Their computational capabilities <ref> [43, 44] </ref> make recurrent neural networks appropriate tools for modeling and refining through learning systems whose current state depends on previous states and inputs [16] and there has been a lot of interest in learning, synthesis, and extraction of finite-state automata in recurrent neural networks [6, 9, 12, 14, 17, 40,
Reference: [45] <author> R. Sun, </author> <title> "Learning, action, and consciousness: a hybrid approach towards modeling consciousness," </title> <booktitle> Neural Networks, </booktitle> <volume> vol. 10, no. 7, </volume> <pages> pp. 1317-1332, </pages> <year> 1997. </year>
Reference-contexts: 1 Introduction There has been an increased interest in hybrid systems as more applications using hybrid models emerge [5]. However, there are many definitions of hybrid systems <ref> [22, 24, 45] </ref>. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23].
Reference: [46] <author> S. F. Thomas, </author> <title> Fuzziness and Probability. </title> <address> Wichita KS 67278: </address> <publisher> ACG Press, </publisher> <year> 1995. </year>
Reference: [47] <author> F. Unal and E. Khan, </author> <title> "A fuzzy finite state machine implementation based on a neural fuzzy system," </title> <booktitle> in Proceedings of the Third International Conference on Fuzzy Systems, </booktitle> <volume> vol. 3, </volume> <pages> pp. 1749-1754, </pages> <year> 1994. </year>
Reference-contexts: A variety of neural network implementations of FFAs have been proposed <ref> [19, 20, 25, 47] </ref>. We have previously shown how fuzzy finite-state automata (FFAs) can be mapped into recurrent neural networks with second-order weights using a crisp representation of FFA states [38].
Reference: [48] <author> R. Watrous and G. Kuhn, </author> <title> "Induction of finite-state languages using second-order recurrent networks," </title> <journal> Neural Computation, </journal> <volume> vol. 4, no. 3, </volume> <editor> p. </editor> <volume> 406, </volume> <year> 1992. </year>
Reference-contexts: Their computational capabilities [43, 44] make recurrent neural networks appropriate tools for modeling and refining through learning systems whose current state depends on previous states and inputs [16] and there has been a lot of interest in learning, synthesis, and extraction of finite-state automata in recurrent neural networks <ref> [6, 9, 12, 14, 17, 40, 48, 52] </ref>. A variety of neural network implementations of FFAs have been proposed [19, 20, 25, 47]. We have previously shown how fuzzy finite-state automata (FFAs) can be mapped into recurrent neural networks with second-order weights using a crisp representation of FFA states [38].
Reference: [49] <author> X. Yang and G. Kalambur, </author> <title> "Design for machining using expert system and fuzzy logic approach," </title> <journal> Journal of Materials Engineering and Performance, </journal> <volume> vol. 4, no. 5, </volume> <editor> p. </editor> <volume> 599, </volume> <year> 1995. </year>
Reference-contexts: However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23]. Fuzzy logic [51] provides a mathematical foundation for approximate reasoning; fuzzy logic has proven very successful in a variety of applications <ref> [1, 4, 8, 10, 13, 21, 26, 30, 39, 49] </ref>. The parameters of adaptive fuzzy systems have clear physical meanings which facilitates the choice of their initial values. Furthermore, rule-based information can be incorporated into fuzzy systems in a systematic way.
Reference: [50] <author> L. Zadeh, </author> <title> "Fuzzy languages and their relation to human and machine intelligence," </title> <type> Tech. Rep. </type> <institution> ERL-M302, Electronics Research Laboratory, University of California, Berkeley, </institution> <year> 1971. </year> <month> 31 </month>
Reference-contexts: Artificial neural networks have become valuable computational tools in their own right for tasks such as pattern recognition, control, and forecasting. Fuzzy finite-state automata (FFAs) 2 automaton with FFA have a long history <ref> [41, 50] </ref>; the fundamentals of FFAs have been discussed in [15] without presenting a systematic machine synthesis method. Their potential as design tools for modeling a variety of systems is beginning to be exploited [27, 33].
Reference: [51] <author> L. Zadeh, </author> <title> "Fuzzy sets," </title> <journal> Information and Control, </journal> <volume> vol. 8, </volume> <pages> pp. 338-353, </pages> <year> 1965. </year>
Reference-contexts: 1 Introduction There has been an increased interest in hybrid systems as more applications using hybrid models emerge [5]. However, there are many definitions of hybrid systems [22, 24, 45]. One example of hybrid systems is in combining artificial neural networks and fuzzy systems (see [2, 23]. Fuzzy logic <ref> [51] </ref> provides a mathematical foundation for approximate reasoning; fuzzy logic has proven very successful in a variety of applications [1, 4, 8, 10, 13, 21, 26, 30, 39, 49]. The parameters of adaptive fuzzy systems have clear physical meanings which facilitates the choice of their initial values.
Reference: [52] <author> Z. Zeng, R. Goodman, and P. Smyth, </author> <title> "Learning finite state machines with self-clustering recurrent networks," </title> <journal> Neural Computation, </journal> <volume> vol. 5, no. 6, </volume> <pages> pp. 976-990, </pages> <year> 1993. </year> <month> 32 </month>
Reference-contexts: Their computational capabilities [43, 44] make recurrent neural networks appropriate tools for modeling and refining through learning systems whose current state depends on previous states and inputs [16] and there has been a lot of interest in learning, synthesis, and extraction of finite-state automata in recurrent neural networks <ref> [6, 9, 12, 14, 17, 40, 48, 52] </ref>. A variety of neural network implementations of FFAs have been proposed [19, 20, 25, 47]. We have previously shown how fuzzy finite-state automata (FFAs) can be mapped into recurrent neural networks with second-order weights using a crisp representation of FFA states [38].
References-found: 52

