URL: http://www.eecs.umich.edu/PPP/IJPP96.ps
Refering-URL: http://www.eecs.umich.edu/PPP/publist.html
Root-URL: http://www.cs.umich.edu
Email: alexe,davidson@eecs.umich.edu abraham@hpl.hp.com  
Title: Minimizing Register Requirements of a Modulo Schedule via Optimum Stage Scheduling  
Author: Alexandre E. Eichenberger and Edward S. Davidson Santosh G. Abraham 
Keyword: Register-sensitive modulo scheduling, software pipelining, instruction level parallelism, VLIW, superscalar.  
Address: 1501 Page Mill Road Ann Arbor, MI 48109-2122 Palo Alto, CA 94304  
Affiliation: Advanced Computer Architecture Laboratory Hewlett Packard Laboratories EECS Department, University of Michigan  
Abstract: Modulo scheduling is an efficient technique for exploiting instruction level parallelism in a variety of loops, resulting in high performance code but increased register requirements. We present an approach that schedules the loop operations for minimum register requirements, given a modulo reservation table. Our method determines optimal register requirements for machines with finite resources and for general dependence graphs. Measurements on a benchmark suite of 1327 loops from the Perfect Club, SPEC-89, and the Livermore Fortran Kernels show that the register requirements decrease by 24.5% on average when applying the optimal stage scheduler to the MRT-schedules of a register-insensitive modulo scheduler. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. R. Rau and J. A. Fisher. </author> <title> Instruction-level parallel processing: History, overview, and perspective. </title> <journal> In The Journal of Supercomputing, </journal> <volume> volume 7, </volume> <pages> pages 9-50, </pages> <year> 1993. </year>
Reference: [2] <author> P. Y. Hsu. </author> <title> Highly Concurrent Scalar Processing. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1986. </year>
Reference-contexts: the highest steady-state throughput over the entire space of modulo schedules, jointly solving Steps 1 and 2, was first formulated by Hsu for machines with finite resources and for loop iterations with arbitrary dependence graphs, a formulation that satisfies scheduling dependences, but does not attempt to minimize the register requirements <ref> [2] </ref>. Ning and Gao proposed a polynomial-time algorithm that results in a schedule with the highest steady-state throughput over all modulo schedules, and minimum buffer requirements among such schedules [16].
Reference: [3] <author> B. R. Rau, C. D. Glaeser, and R. L. </author> <title> Picard. Efficient code generation for horizontal architectures: Compiler techniques and architecture support. </title> <booktitle> Proceedings of the Ninth Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 131-139, </pages> <year> 1982. </year>
Reference: [4] <author> M. Lam. </author> <title> Software pipelining: An effective scheduling technique for VLIW machines. </title> <booktitle> Proceedings of the ACM SIGPLAN'88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 318-328, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: The scope of modulo scheduling has been widened to a large variety of loops. Loops with conditional statements are handled using hierarchical reduction <ref> [4] </ref> or IF-conversion [5][6]. Loops with conditional exits can also be modulo scheduled [7]. Furthermore, the code expansion due to modulo scheduling can be eliminated when using special hardware such as rotating register files and predicated execution [8].
Reference: [5] <author> N. J. Warter, G. E. Haab, K. Subramanian, and J. W. Bockhaus. </author> <title> Enhanced Modulo Scheduling for loops with conditional branches. </title> <booktitle> Proceedings of the 25th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 170-179, </pages> <month> December </month> <year> 1992. </year>
Reference: [6] <author> N. J. Warter. </author> <title> Modulo Scheduling with Isomorphic Control Transformations. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1994. </year>
Reference: [7] <author> P. P. Tirumalai, M. Lee, and M. S. Schlansker. </author> <title> Parallelization of loops with exits on pipelined architectures. </title> <booktitle> Proceedings of Supercomputing '90, </booktitle> <pages> pages 200-212, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: The scope of modulo scheduling has been widened to a large variety of loops. Loops with conditional statements are handled using hierarchical reduction [4] or IF-conversion [5][6]. Loops with conditional exits can also be modulo scheduled <ref> [7] </ref>. Furthermore, the code expansion due to modulo scheduling can be eliminated when using special hardware such as rotating register files and predicated execution [8]. As modulo scheduling achieves higher throughput by overlapping the execution of several iterations, it results in higher register requirements.
Reference: [8] <author> B. R. Rau, M. Lee, P. P. Tirumalai, and M. S. Schlansker. </author> <title> Register allocation for software pipelined loops. </title> <booktitle> Proceedings of the ACM SIGPLAN'92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 283-299, </pages> <month> June </month> <year> 1992. </year> <month> 19 </month>
Reference-contexts: Loops with conditional statements are handled using hierarchical reduction [4] or IF-conversion [5][6]. Loops with conditional exits can also be modulo scheduled [7]. Furthermore, the code expansion due to modulo scheduling can be eliminated when using special hardware such as rotating register files and predicated execution <ref> [8] </ref>. As modulo scheduling achieves higher throughput by overlapping the execution of several iterations, it results in higher register requirements. In fact, register requirements generally increase as concurrency increases, whether due to using and exploiting machines with faster clocks and deeper pipelines, wider issue, or a combination of both [9]. <p> Register allocation algorithms have been investigated by Rau et al <ref> [8] </ref>. Their algorithm achieves register allocations that are within one register of the MaxLive lower bound for the vast majority of their modulo-scheduled loops on machines with rotating register files and predicated execution to support modulo-scheduling. <p> A stage-schedule for Example 1 is shown in Figure 1c. This figure is an execution trace; the MRT is replicated sufficiently to show one complete iteration. Each replication is referred to as a stage <ref> [8] </ref> of the software pipelined loop. The circles highlight the operations that belong to the iteration initiated at a time 0. The circles must be placed so as to satisfy the specified latencies. The virtual register lifetimes for this iteration are presented in Figure 1d.
Reference: [9] <author> W. Mangione-Smith, S. G. Abraham, and E. S. Davidson. </author> <title> Register requirements of pipelined processors. </title> <booktitle> Pro--ceedings of the International Conference on Supercomputing, </booktitle> <pages> pages 260-271, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: As modulo scheduling achieves higher throughput by overlapping the execution of several iterations, it results in higher register requirements. In fact, register requirements generally increase as concurrency increases, whether due to using and exploiting machines with faster clocks and deeper pipelines, wider issue, or a combination of both <ref> [9] </ref>. As a result, a scheduling algorithm that reduces the register pressure while scheduling for high throughput is increasingly important. In this paper, we treat modulo scheduling as a three step procedure. Some code generation strategies treat each step separately; e.g. <p> graph is an undirected graph formed by ignoring the direction of each arc. 2 A precise modeling of the register requirements of modulo schedules was first proposed by Mangione--Smith et al for loop iterations where each virtual register is used at most once, i.e. for forest of trees dependence graphs <ref> [9] </ref>. They also presented a linear-time stage scheduler resulting in minimum MaxLive for loop iterations with dependence graphs that are forests of trees. The work presented here extends their results in two directions. <p> The total MaxLive is the sum of the fractional and integral MaxLive. The stage-schedule presented in Figure 1 results in the minimum register requirements for this kernel, MRT, and set of functional unit latencies. Mangione-Smith et al <ref> [9] </ref> have shown that for dependence graphs with at most a single use per virtual register, as in Example 1, minimizing each skip factor individually always results in the minimum register requirements. However, this result does not apply to general dependence graphs with unrestricted common sub-expressions and loop-carried dependences.
Reference: [10] <author> C. Eisenbeis and D. Windheiser. </author> <title> Optimal software pipelining in presence of resource constraints. </title> <booktitle> Proceedings of the International Conference on Parallel Architecture and Compiler Techniques, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: As a result, a scheduling algorithm that reduces the register pressure while scheduling for high throughput is increasingly important. In this paper, we treat modulo scheduling as a three step procedure. Some code generation strategies treat each step separately; e.g. Eisenbeis's software pipelining approach <ref> [10] </ref> uses distinct heuristics for Steps 1, 2, and 3 below. Other code generation strategies combine steps to simultaneously meet distinct objectives; e.g. Huff's lifetime-sensitive modulo scheduler [11] combines Steps 1 and 2 below. fl To appear in the International Journal of Parallel Programming, February, 1996. 1 1.
Reference: [11] <author> R. A. Huff. </author> <title> Lifetime-sensitive modulo scheduling. </title> <booktitle> Proceedings of the ACM SIGPLAN'93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 258-267, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Some code generation strategies treat each step separately; e.g. Eisenbeis's software pipelining approach [10] uses distinct heuristics for Steps 1, 2, and 3 below. Other code generation strategies combine steps to simultaneously meet distinct objectives; e.g. Huff's lifetime-sensitive modulo scheduler <ref> [11] </ref> combines Steps 1 and 2 below. fl To appear in the International Journal of Parallel Programming, February, 1996. 1 1. <p> Another body of research has sought efficient register-sensitive scheduling heuristics. For example, Huff investigated a heuristic based on a bidirectional slack-scheduling method that schedules operations early or late depending on their number of stretchable input and output flow dependences <ref> [11] </ref>. Llosa et al have recently proposed a heuristic that is based on a bidirectional slack-scheduling method with a scheduling priority function tailored to minimize the register requirements [21]. Based on the optimal stage scheduler presented in this paper, we have also investigated fast stage scheduling heuristics [15]. <p> For purpose of comparison, we also present the register requirements of an efficient modulo scheduling algorithm that presently does not attempt to minimize the register requirements. Unfortunately, we are unable to provide a comparison with Huff's scheduling algorithm <ref> [11] </ref> since his machine model differs slightly from ours and his latest scheduler, presented in [11], was not available to us. MinReg Stage-Scheduler: This scheduler minimizes MaxLive over all valid modulo schedules that share a given MRT, using Algorithm 2 which was presented in Section 5. <p> Unfortunately, we are unable to provide a comparison with Huff's scheduling algorithm <ref> [11] </ref> since his machine model differs slightly from ours and his latest scheduler, presented in [11], was not available to us. MinReg Stage-Scheduler: This scheduler minimizes MaxLive over all valid modulo schedules that share a given MRT, using Algorithm 2 which was presented in Section 5. The resulting schedule has the lowest achievable register requirements for the given machine, loop iteration, and MRT. <p> In this graph, the X-axis represents MaxLive and the Y-axis represents the fraction of loops scheduled on a machine with up to MaxLive physical registers. The "Schedule Independent Lower Bound" curve corresponds to the bound presented in <ref> [11] </ref> and is representative of the register requirements of a machine with unlimited resources. There is a significant gap between the MinReg Stage Scheduler curve and the Lower Bound curve which we believe is caused by two factors.
Reference: [12] <author> J. H. Patel and E. S. Davidson. </author> <title> Improving the throughput of a pipeline by insertion of delays. </title> <booktitle> Proceedings of the Third Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 159-164, </pages> <year> 1976. </year>
Reference: [13] <author> C. Eisenbeis, W. Jalby, and A. </author> <title> Lichnewsky. Squeezing more performance out of a Cray-2 by vector block scheduling. </title> <booktitle> Proceedings of Supercomputing '88, </booktitle> <pages> pages 237-246, </pages> <month> November </month> <year> 1988. </year>
Reference: [14] <author> G. R. Beck, D. W. L. Yen, and T. L. Anderson. </author> <title> The Cydra 5 mini-supercomputer: Architecture and implementation. </title> <journal> In The Journal of Supercomputing, </journal> <volume> volume 7, </volume> <pages> pages 143-180, </pages> <year> 1993. </year>
Reference-contexts: We investigate the performance of the optimum stage scheduler and other schedulers for a benchmark suite of 1327 loops from the Perfect Club, SPEC-89, and the Livermore Fortran Kernels for a machine with complex resource usage, the Cydra 5 <ref> [14] </ref>. Our empirical findings show that the register requirements decrease by 24.5% on average in this benchmark suite when applying the optimal stage scheduler to the MRT-schedules of a register-insensitive modulo scheduler. <p> The machine model used in these experiments corresponds to the Cydra 5 machine. This choice was motivated by the availability of quality code for this machine. Also, the resource requirements of the Cydra 5 machine are complex <ref> [14] </ref>, thus stressing the importance of good and robust scheduling algorithms. In particular, the machine configuration is the one used in [25] with 7 functional units (2 memory port units, 2 address generation units, 1 FP adder unit, 1 FP multiplier unit, and 1 branch unit).
Reference: [15] <author> A. E. Eichenberger and E. S. Davidson. </author> <title> Stage scheduling: A technique to reduce the register requirements of a modulo schedule. </title> <booktitle> Proceedings of the 28th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 180-191, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: For example, we used the optimal stage scheduler as a guide to develop efficient stage scheduling heuristics <ref> [15] </ref>. This method is thus useful in assessing the effectiveness of register-sensitive stage scheduling and modulo scheduling heuristics. In this paper, we present related work in Section 2. <p> Llosa et al have recently proposed a heuristic that is based on a bidirectional slack-scheduling method with a scheduling priority function tailored to minimize the register requirements [21]. Based on the optimal stage scheduler presented in this paper, we have also investigated fast stage scheduling heuristics <ref> [15] </ref>. Our best linear-time stage scheduling heuristic decreases the register requirements by 24.4% over a register insensitive-scheduler with the same MRT, achieving on average 99.7% of the decrease in register requirements obtained by an optimal stage scheduler on the benchmark suite used in this paper. <p> In its current form, the scheduler does not attempt to minimize the register requirements of its schedules; however, the register requirements of its schedules may be reduced significantly by the simple heuristics presented in <ref> [15] </ref>.
Reference: [16] <author> Q. Ning and G. R. Gao. </author> <title> A novel framework of register allocation for software pipelining. </title> <booktitle> Twentieth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 29-42, </pages> <year> 1993. </year>
Reference-contexts: Ning and Gao proposed a polynomial-time algorithm that results in a schedule with the highest steady-state throughput over all modulo schedules, and minimum buffer requirements among such schedules <ref> [16] </ref>. In their work, and elsewhere [17][18][19], the register requirements of a schedule are approximated by conceptual FIFO buffers that are reserved for an interval of time that is a multiple of II. Their scheduling algorithm handles loop iterations with arbitrary dependence graphs.
Reference: [17] <author> R. Govindarajan, E. R. Altman, and G. R. Gao. </author> <title> Minimizing register requirements under resource-constrained rate-optimal software pipelining. </title> <booktitle> Proceedings of the 27th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 85-94, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Their scheduling algorithm handles loop iterations with arbitrary dependence graphs. Ning and Gao's results were extended for machines with finite resources by Govindarajan et al <ref> [17] </ref>. Recently, we contributed a scheduling algorithm that jointly addresses Steps 1 and 2 by combining the precise modeling of the register requirements with the complete description of the modulo scheduling space [20].
Reference: [18] <author> J. Wang, A. Krall, and M.A. Ertl. </author> <title> Decomposed software pipelining with reduced register requirement. </title> <booktitle> In Proceedings of the International Conference on Parallel Architecture and Compiler Techniques, </booktitle> <month> June </month> <year> 1995. </year>
Reference: [19] <author> Dupont de Dinechin. </author> <title> Simplex scheduling: More than lifetime-sensitive instruction scheduling. </title> <booktitle> Proceedings of the International Conference on Parallel Architecture and Compiler Techniques, </booktitle> <year> 1994. </year>
Reference: [20] <author> A. E. Eichenberger, E. S. Davidson, and S. G. Abraham. </author> <title> Optimum modulo schedules for minimum register requirements. </title> <booktitle> Proceedings of the International Conference on Supercomputing, </booktitle> <pages> pages 31-40, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Ning and Gao's results were extended for machines with finite resources by Govindarajan et al [17]. Recently, we contributed a scheduling algorithm that jointly addresses Steps 1 and 2 by combining the precise modeling of the register requirements with the complete description of the modulo scheduling space <ref> [20] </ref>. In that work, we find a schedule with the highest steady-state throughput over all modulo schedules, and the minimum register requirements among such schedules. That work handles machines with arbitrary resource requirements and loop iterations with arbitrary dependence graphs. <p> As a result, only small loops were handled using that approach, i.e. loop iterations with up to 12 operations and II up to 5 <ref> [20] </ref>. In this paper our benchmark suite contains loop iterations with up to 161 operations and II up to 165. Another body of research has sought efficient register-sensitive scheduling heuristics. <p> Techniques that remove edges in the dependence graph may result in register edges without corresponding scheduling edges, as shown in <ref> [20] </ref>. These techniques can be applied to the model presented in this paper as well. We characterize the initial MRT-schedule by its initiation interval II and by the row of the MRT in which each operation is placed. <p> Experimental evidence on a subset of this benchmark suite, consisting of all the loops with no more than 12 operations and II up to 5, for which an optimal modulo schedule was sought over all MRTs, showed, however, that the difference between the local and absolute minimum was surprisingly small <ref> [20] </ref>. This result may not hold for larger loops. 18 explained by the fact that this scheduler does attempt to minimize the length of a schedule, which generally results in a stage-schedule with low register requirements along the critical path of that schedule.
Reference: [21] <author> J. Llosa, M. Valero, E. Ayguade, and A. Gonzalez. </author> <title> Hypernode reduction modulo scheduling. </title> <booktitle> Proceedings of the 28th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 350-360, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: Llosa et al have recently proposed a heuristic that is based on a bidirectional slack-scheduling method with a scheduling priority function tailored to minimize the register requirements <ref> [21] </ref>. Based on the optimal stage scheduler presented in this paper, we have also investigated fast stage scheduling heuristics [15].
Reference: [22] <author> G. L. Nemhauser and L. A. Wolsey. </author> <title> Integer and Combinatorial Optimization. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: 1;4 + p 2;5 + p 3;6 + p 4;5 + p 5;6 + p 6;7 + 5 (11) We can now reduce the problem of finding a stage schedule that results in the minimum integral MaxLive to a well-known class of problems, solved by a linear programming (LP) solver <ref> [22] </ref>. Note, however, that (11) is not acceptable as the input to an LP-solver, because the objective function cannot contain any max functions. However, since we are minimizing the objective function, we can remove the max function by using some additional inequalities, called max constraints. <p> Our problem formulation is derived by removing their assignment constraints and by replacing their timing constraints with the underlying constraints, which are obtained by summing their timing constraints associated with the edges of an underlying cycle. Since eliminating or summing constraints preserves the integer property <ref> [22, pp 540-541] </ref>, the linear-programming formulation of the minimum integral MaxLive problem is also guaranteed to result in integer solutions. 2 Theorem 2 For a dependence graph with an acyclic underlying dependence graph, the minimum integral MaxLive for a given kernel, MRT, and set of latencies is found in a time
Reference: [23] <author> K. Paton. </author> <title> An algorithm for finding a fundamental set of cycles of a graph. </title> <journal> Communications of the ACM, </journal> <volume> 12(9) </volume> <pages> 514-518, </pages> <month> September </month> <year> 1969. </year>
Reference-contexts: Compute all s i;j using Equation (4) and search for all elementary cycles in the underlying graph of the dependence graph GfV; E sched g <ref> [23] </ref>. 2. If the underlying dependence graph is acyclic, the solution that produces the minimum integral MaxLive is obtained by setting the values of all p i;j to zero. 3. Otherwise, build an underlying-cycle constraint for each elementary cycle of the underlying dependence graph using Equations (6) and (7).
Reference: [24] <author> S. Chaudhuri, R. A. Walker, and J. E. Mitchell. </author> <title> Analysing and exploiting the structure of the constraints in the ILP approach to the scheduling problem. </title> <journal> IEEE Transactions on Very Large Scale Integration Systems, </journal> <volume> 2(4) </volume> <pages> 456-471, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: Since the solution, namely the set of p i;j values, must be integer valued, we must show that the solution of the LP-solver is guaranteed to be integer valued for any dependence graph and MRT-schedule. Chaudhuri et al. <ref> [24] </ref> have shown that the linear-programming formulation of the scheduling problem with infinite resources (Assignment and Timing Constraints in [24]) is guaranteed to result in integer solutions. <p> Chaudhuri et al. <ref> [24] </ref> have shown that the linear-programming formulation of the scheduling problem with infinite resources (Assignment and Timing Constraints in [24]) is guaranteed to result in integer solutions. Our problem formulation is derived by removing their assignment constraints and by replacing their timing constraints with the underlying constraints, which are obtained by summing their timing constraints associated with the edges of an underlying cycle.
Reference: [25] <author> B. R. Rau. </author> <title> Iterative Modulo Scheduling: An algorithm for software pipelining loops. </title> <booktitle> Proceedings of the 27th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 63-74, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Buffers must be reserved for a time interval that is a multiple of II, whereas registers may be reserved for arbitrary time periods. We derive and use in our comparisons the actual register requirements associated with these MinBuf stage schedules. Iterative Modulo Scheduler <ref> [25] </ref>: This scheduler has been designed to deal efficiently with realistic machine models while producing schedules with near optimal steady-state throughput. Experimental findings show that this algorithm requires the scheduling of only 59% more operations than does acyclic list scheduling. <p> Experimental findings show that this algorithm requires the scheduling of only 59% more operations than does acyclic list scheduling. At the same time it results in schedules that are optimal in II for 96% of the loops in their benchmark <ref> [25] </ref>. In its current form, the scheduler does not attempt to minimize the register requirements of its schedules; however, the register requirements of its schedules may be reduced significantly by the simple heuristics presented in [15]. <p> This choice was motivated by the availability of quality code for this machine. Also, the resource requirements of the Cydra 5 machine are complex [14], thus stressing the importance of good and robust scheduling algorithms. In particular, the machine configuration is the one used in <ref> [25] </ref> with 7 functional units (2 memory port units, 2 address generation units, 1 FP adder unit, 1 FP multiplier unit, and 1 branch unit). The Iterative Modulo Scheduler was also used to generate the MRT input for the MinReg and MinBuf Stage-Schedulers.
Reference: [26] <author> M. Berry et al. </author> <title> The Perfect Club Benchmarks: Effective performance evaluation of supercomputers. </title> <journal> The International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall </month> <year> 1989. </year>
Reference-contexts: Operations Operations Underlying Register Scheduling in cycles cycles edges edges minimum 2 0 0 1 1 average 17.5 10.2 3.0 21.4 22.5 maximum 161 158 66 220 232 Table 2: Characteristics of the benchmark suite. 16 We use a benchmark of loops obtained from the Perfect Club <ref> [26] </ref>, SPEC-89 [27], and the Livermore Fortran Kernels [28]. Our benchmark consists exclusively of innermost loops with no early exits, no procedure calls, and fewer than 30 basic blocks, as compiled by the Cydra 5 Fortran77 compiler [29].
Reference: [27] <author> J. Uniejewski. </author> <title> SPEC Benchmark Suite: Designed for today's advanced system. </title> <journal> SPEC Newsletter, </journal> <month> Fall </month> <year> 1989. </year>
Reference-contexts: Operations Operations Underlying Register Scheduling in cycles cycles edges edges minimum 2 0 0 1 1 average 17.5 10.2 3.0 21.4 22.5 maximum 161 158 66 220 232 Table 2: Characteristics of the benchmark suite. 16 We use a benchmark of loops obtained from the Perfect Club [26], SPEC-89 <ref> [27] </ref>, and the Livermore Fortran Kernels [28]. Our benchmark consists exclusively of innermost loops with no early exits, no procedure calls, and fewer than 30 basic blocks, as compiled by the Cydra 5 Fortran77 compiler [29].
Reference: [28] <author> F. H. McMahon. </author> <title> The Livermore Fortran Kernels: A computer test of the numerical performance range. </title> <type> Technical Report UCRL-53745, </type> <institution> Lawrence Livermore National Laboratory, Livermore, California, </institution> <year> 1986. </year>
Reference-contexts: in cycles cycles edges edges minimum 2 0 0 1 1 average 17.5 10.2 3.0 21.4 22.5 maximum 161 158 66 220 232 Table 2: Characteristics of the benchmark suite. 16 We use a benchmark of loops obtained from the Perfect Club [26], SPEC-89 [27], and the Livermore Fortran Kernels <ref> [28] </ref>. Our benchmark consists exclusively of innermost loops with no early exits, no procedure calls, and fewer than 30 basic blocks, as compiled by the Cydra 5 Fortran77 compiler [29].
Reference: [29] <author> J. C. Dehnert and R. A. Towle. </author> <title> Compiling for the Cydra 5. </title> <journal> In The Journal of Supercomputing, </journal> <volume> volume 7, </volume> <pages> pages 181-227, </pages> <year> 1993. </year>
Reference-contexts: Our benchmark consists exclusively of innermost loops with no early exits, no procedure calls, and fewer than 30 basic blocks, as compiled by the Cydra 5 Fortran77 compiler <ref> [29] </ref>. The input to the three scheduling algorithms consists of the Fortran77 compiler intermediate representation after load-store elimination, recurrence back-substitution, and IF-conversion. Our benchmark suite consists of the 1327 loops successfully modulo scheduled by the Cydra 5 Fortran77 compiler.
References-found: 29

