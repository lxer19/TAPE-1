URL: http://www.ics.uci.edu/~cmerz/mlj.pcr.ps
Refering-URL: http://www.ics.uci.edu/~cmerz/resume.html
Root-URL: 
Title: Machine Learning,  A Principal Components Approach to Combining Regression Estimates  
Author: CHRISTOPHER J. MERZ AND MICHAEL J. PAZZANI Editor: Philip Chan 
Keyword: Regression, principal components, multiple models, combining estimates.  
Address: Irvine, CA 92697-3425  
Affiliation: Department of Information and Computer Science, University of California,  
Note: c 1997 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Pubnum: 0,  
Email: fcmerz,pazzanig@uci.edu  
Date: 1-29 (1997)  Received October 1, 1997  
Abstract: The goal of combining the predictions of multiple learned models is to form an improved estimator. A combining strategy must be able to robustly handle the inherent correlation, or multicollinearity, of the learned models while identifying the unique contributions of each. A progression of existing approaches and their limitations with respect to these two issues are discussed. A new approach, PCR*, based on principal components regression is proposed to address these limitations. An evaluation of the new approach on a collection of domains reveals that 1) PCR* was the most robust combining method, 2) correlation could be handled without eliminating any of the learned models, and 3) the principal components of the learned models provided a continuum of "regularized" weights from which PCR* could choose. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> K. Ali. </author> <title> Learning Probabilistic Relational Concept Descriptions. </title> <type> PhD thesis, </type> <institution> University of California, Irvine, </institution> <year> 1996. </year>
Reference: 2. <author> K. Ali and M. Pazzani. </author> <title> Learning multiple relational rule-based models. </title> <editor> In D. Fisher and H. Lenz, editors, </editor> <title> Learning from Data: </title> <journal> Artificial Intelligence and Statistics, </journal> <volume> Vol. 5. </volume> <publisher> Springer-Verlag, </publisher> <address> Fort Lauderdale, FL, </address> <year> 1995. </year>
Reference: 3. <author> K. Ali and M.J. Pazzani. </author> <title> Error reduction through learning multiple descriptions. </title> <booktitle> Machine Learning, </booktitle> <address> 24:173, </address> <year> 1996. </year>
Reference: 4. <author> W. Baxt. </author> <title> Improving the accuracy of an artificial neural network using multiple differently trained networks. </title> <journal> Neural Computation, </journal> <volume> 4(5) </volume> <pages> 772-780, </pages> <year> 1992. </year>
Reference: 5. <author> L. Breiman. </author> <title> Heuristics of instability in model selection. </title> <type> Technical report, </type> <institution> Department of Statistics, University of California at Berkeley, </institution> <year> 1994. </year>
Reference-contexts: Each model is generated using the same algorithm, but different training data. The data for a particular model is obtained by sampling from the original training examples according to a probability distribution. The probability distribution is defined by the particular approach, "bagging" or "boosting." Bagging <ref> [5] </ref> is a method for exploiting the variance of a learning algorithm by applying it to various version of the data set, and averaging them (uniformly) for an overall reduction in variance, or prediction error.
Reference: 6. <author> L. Breiman. </author> <title> Stacked regressions. </title> <journal> Machine Learning, </journal> <volume> 24(1) </volume> <pages> 49-64, </pages> <year> 1996. </year>
Reference-contexts: 1. Introduction Combining a set of learned models 1 to improve classification and regression estimates has been an area of much research in machine learning and neural networks <ref> [50, 37, 41, 34, 6, 36, 31, 48, 8] </ref>. The challenge of this problem is to decide which models to rely on for prediction and how much weight to give each. Suppose a physician wishes to predict a person's percentage of body fat, PBF. <p> Least squares regression methods which rely on matrix inversion for finding the weighs (i.e., LR and LRC) can be made more reliable by constraining the types of weights they may produce. Ridge regression, RIDGE [9] has a parameter that may be used to restrict or "regularize" the alpha-coefficients. Breiman <ref> [6] </ref> has devised an approach based on constrained least squares regression [33] where the coefficients are required to be nonnegative. The focus of this paper is on a flexible approach to weight regularization based on principal components regression. <p> Leblanc and Tibshirani [34] have proposed several ways of constraining or regu larizing the weights to help produce estimators with lower prediction error: 1. Shrink ^ff towards (1=K; 1=K; : : :; 1=K) T where K is the number of learned models. 2. i=1 ff i = 1 Breiman <ref> [6] </ref> provides an intuitive justification for these constraints by pointing out that the more strongly they are satisfied, the more interpolative the weighting scheme is. <p> The ff-coefficients are then derived as they are in PCR*. The end result is a more restricted set of coefficients. An iterative approach is used to searching for (as discussed in [9]). A "stacked" constrained regression (SCR) procedure <ref> [6] </ref> has also been included in the evaluation. The two main components of this approach are stacking and constrained regression. Stacking [49] is simply a method of approximating the matrix of predictions, A F .
Reference: 7. <author> N. Cesa-Bianchi, Y. Freund, D. Helmbold, D. Haussler, R. Schapire, and M. K. Warmuth. </author> <title> How to use expert advice. </title> <booktitle> In Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 382-391. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year> <note> to appear in Journal of the Association for Computing Machinery. </note>
Reference: 8. <author> P. Chan and S. Stolfo. </author> <title> A comparative evaluation of voting and meta-learning on partitioned data. </title> <booktitle> In Proceedings of the 12th International Conference on Machine Learning, </booktitle> <pages> pages 90-98. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1995. </year>
Reference-contexts: 1. Introduction Combining a set of learned models 1 to improve classification and regression estimates has been an area of much research in machine learning and neural networks <ref> [50, 37, 41, 34, 6, 36, 31, 48, 8] </ref>. The challenge of this problem is to decide which models to rely on for prediction and how much weight to give each. Suppose a physician wishes to predict a person's percentage of body fat, PBF.
Reference: 9. <author> D.C.Montgomery and D.J. Friedman. </author> <title> Prediction using regression models with multicollinear predictor variables. </title> <journal> IIE Transactions, </journal> <volume> 25(3) </volume> <pages> 73-85, </pages> <year> 1993. </year>
Reference-contexts: Least squares regression methods which rely on matrix inversion for finding the weighs (i.e., LR and LRC) can be made more reliable by constraining the types of weights they may produce. Ridge regression, RIDGE <ref> [9] </ref> has a parameter that may be used to restrict or "regularize" the alpha-coefficients. Breiman [6] has devised an approach based on constrained least squares regression [33] where the coefficients are required to be nonnegative. <p> The ff-coefficients are then derived as they are in PCR*. The end result is a more restricted set of coefficients. An iterative approach is used to searching for (as discussed in <ref> [9] </ref>). A "stacked" constrained regression (SCR) procedure [6] has also been included in the evaluation. The two main components of this approach are stacking and constrained regression. Stacking [49] is simply a method of approximating the matrix of predictions, A F .
Reference: 10. <author> T. G. Dietterich, M. Kearns, and Y. Mansour. </author> <title> Applying the weak learning framework to understand and improve C4.5. </title> <booktitle> In Proceedings of the 13th International Conference on Machine Learning, </booktitle> <pages> pages 96-104. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year>
Reference: 11. <author> N.R. Draper and H. Smith. </author> <title> Applied Regression Analysis. </title> <publisher> John Wiley and Sons, </publisher> <year> 1981. </year>
Reference-contexts: An empirical evaluation of PCR* is given in Section 6. 6 CHRISTOPHER MERZ AND MICHAEL PAZZANI 4. The PCR* Algorithm 4.1. Representation and Regression "PCR*" is named partly for the modeling method at its core, "Principal Components Regression" (see <ref> [11] </ref> for a summary). This section discusses the central role PCR plays in representation and regression in PCR*. The asterisk in PCR* denotes the search associated with the representation and is discussed in section 4.2.
Reference: 12. <author> H. Drucker, R. Schapire, and P. Simard. </author> <title> Improving performance in neural networks using a boosting algorithm. </title> <editor> In Steven J. Hanson, Jack D. Cowan, and C. Lee Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 5, </volume> <pages> pages 42-49. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference: 13. <author> H. Drucker, R. Schapire, and P. Simard. </author> <title> Boosting performance in neural networks. </title> <journal> International Journal of Pattern Recognition and Artificial Intelligence, </journal> <note> [To appear]. </note>
Reference: 14. <author> Harris Drucker and Corinna Cortes. </author> <title> Boosting decision trees. </title> <editor> In David S. Touretzky, Michael C. Mozer, and Michael E. Hasselmo, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 8, </volume> <pages> pages 479-485. </pages> <publisher> The MIT Press, </publisher> <year> 1996. </year>
Reference: 15. <author> Harris Drucker, Corinna Cortes, L. D. Jackel, Yann LeCun, and Vladimir Vapnik. </author> <title> Boosting and other machine learning algorithms. </title> <booktitle> In Proc. 11th International Conference on Machine Learning, </booktitle> <pages> pages 53-61. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference: 16. <author> Harris Drucker, Corinna Cortes, L. D. Jackel, Yann LeCun, and Vladimir Vapnik. </author> <title> Boosting and other ensemble methods. </title> <journal> Neural Computation, </journal> <volume> 6(6) </volume> <pages> 1289-1301, </pages> <year> 1994. </year>
Reference: 17. <author> Y. Freund. </author> <title> Boosting a weak learning algorithm by majority. </title> <journal> Information and Computation, </journal> <volume> 121(2) </volume> <pages> 256-285, </pages> <month> September </month> <year> 1995. </year> <note> Also appeared in COLT90. </note>
Reference: 18. <author> Y. Freund and R. E. Schapire. </author> <title> A decision-theoretic generalization of on-line learning and an applicationto boosting. </title> <booktitle> In Proceedings of the Second European Conference on Computational Learning Theory, </booktitle> <pages> pages 23-37. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Boosting is based on the idea that a set of moderately inaccurate rules-of-thumb (i.e., learned models) can be generated and combined to form a very accurate prediction rule. The initial development of this research was purely theoretical, but subsequent refinements <ref> [19, 18] </ref> have produced practical implementations of the boosting approach. This technique assigns a weight to each example in the training data and adjusts it after learning each model. Initially, the examples are weighted uniformly. <p> The data sets for each learned model are resampled with replacement according to the weight distribution of the examples. 6 A common combining strategy for boosting is described in Freund and Schapire's <ref> [18] </ref> AdaBoost.M1 algorithm. The i-th model's weight is a function of its error, * i , i.e., COMBINING REGRESSION ESTIMATES 25 ff i = log * i In this scheme, learned models with less error (on the distribution of examples they see) tend to get higher weights.
Reference: 19. <author> Yoav Freund and Robert E. Schapire. </author> <title> Experiments with a new boosting algorithm. </title> <booktitle> In Proceedings of the 13th International Conference on Machine Learning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year>
Reference-contexts: Boosting is based on the idea that a set of moderately inaccurate rules-of-thumb (i.e., learned models) can be generated and combined to form a very accurate prediction rule. The initial development of this research was purely theoretical, but subsequent refinements <ref> [19, 18] </ref> have produced practical implementations of the boosting approach. This technique assigns a weight to each example in the training data and adjusts it after learning each model. Initially, the examples are weighted uniformly. <p> In boosting (and bagging), more emphasis has been placed on model generation than model combination. It's possible that a more elaborate combining scheme like that of PCR* may be a more effective method of combining the models generated. Two recent experimental evaluations of "boosting" and "bagging" are given in <ref> [19, 42] </ref>. Both approaches have proven to be quite effective, but are currently limited to a single learning algorithm. Kong and Dieterrich [30] point out that combining heterogeneous learning algorithms can reduce bias as well as variance if the bias errors of the various algorithms are different.
Reference: 20. <author> Yoav Freund, H. Sebastian Seung, Eli Shamir, and Naftali Tishby. </author> <title> Information, prediction, and query by committee. </title> <editor> In Stephen Jose Hanson, Jack D. Cowan, and C. Lee Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 5, </volume> <pages> pages 483-490. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Kong and Dieterrich [30] point out that combining heterogeneous learning algorithms can reduce bias as well as variance if the bias errors of the various algorithms are different. Krogh and Vedelsby [31] have developed a method known as "active learning" based on query by committee <ref> [47, 20, 20] </ref>. In this approach, as a collection of neural networks is trained simultaneously, patterns which have large ambiguity (i.e., the ensemble's predictions tend to vary considerably) are more likely to be included in the next round of training. 8.3.
Reference: 21. <author> J. H. Friedman. </author> <title> Multivariate adaptive regression splines. </title> <journal> Annal of Statistics, </journal> <volume> 19 </volume> <pages> 1-141, </pages> <year> 1991. </year>
Reference-contexts: The imports data set had 41 examples with missing values which were not used due to limitations in one of the learning algorithms used. 6.2. Constituent Learners The set of learned models, F, were generated using Backpropagation networks (BP) [45] and Multivariate Adaptive Regression Splines (MARS) <ref> [21] </ref>. In both experiments, preliminary BP runs were conducted to find a network topology which gave good performance for each data set so that the combining methods would have to work well to improve upon a single model. 6.3. <p> Experiment 1 This experiment aims to evaluate the combining strategies on a smaller number of learned models generated by different learning algorithms. A smaller model set was used here to make the evaluation of SCR more tractable. Twelve models were generated. Six were generated using MARS (version 3.5) <ref> [21] </ref>. In the first three models, the variables were entered in an unrestricted, restricted, and linear fashion, respectively.
Reference: 22. <author> S. Geman, E. Bienenstock, and R. Doursat. </author> <title> Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4(1) </volume> <pages> 1-58, </pages> <year> 1992. </year> <note> 28 CHRISTOPHER MERZ AND MICHAEL PAZZANI </note>
Reference-contexts: attributed to two components: that which is due to the "bias" of the model, and that which is due to the "variance" of COMBINING REGRESSION ESTIMATES 13 associated with the ff i -weights derived using the first k principal components. the model (for an elaborate decomposition of prediction error, see <ref> [22] </ref>). The bias of an algorithm measures how consistently the models it produces (for various data sets of the same size) differ from the true function, f . The variance measures how much the algorithm "bounces around" for the possible data sets.
Reference: 23. <author> J. Ghosh, K. Tumer, S. Beck, and L. Deuser. </author> <title> Integration of neural classifiers for passive sonar signals. </title> <editor> In C. T. Leondes, editor, </editor> <booktitle> In Digital Signal Processing Techniques and Applications. </booktitle> <publisher> Academic Press, </publisher> <year> 1995. </year>
Reference: 24. <author> Sherif Hashem and Bruce Schmeiser. </author> <title> Improving model accuracy using optimal linear combinations of trained neural networks. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 6(3) </volume> <pages> 792-794, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: The next three sections discuss: two more general approaches, some data resampling techniques, and some methods for assigning weights as a function of the example being predicted. 8.1. Other General Approaches Hashem and Schmeiser <ref> [24] </ref> have developed a combining scheme similar to GEM as well as a less constrained version which does not require the weights to sum to one. Like GEM, this method is susceptible to the multicollinearity problem.
Reference: 25. <author> D.A. Jackson. </author> <title> Stopping rules in principal components analysis: A comparison of heuristical and statistical approaches. </title> <journal> Ecology, </journal> <volume> 74(8) </volume> <pages> 2204-2214, </pages> <year> 1993. </year>
Reference-contexts: This section compares PCR*'s method of choosing k to other approaches to choosing the number of principal component. Now a summary is given of the various stopping criteria for choosing the number of principal components to use in the final regression. The methods are commonly used methods described by <ref> [25] </ref>: * Kaiser-Guttman: This commonly used stopping rule is based on the average value of the eigenvalues. Only those components which exceed the average are retained. * Scree Test: This rule is based on a plot of the eigenvalues.
Reference: 26. <author> R. A. Jacobs, M. I. Jordan, S. J. Nowlan, and G. E. Hinton. </author> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3(1) </volume> <pages> 79-87, </pages> <year> 1991. </year>
Reference-contexts: Non-constant Weighting Functions Some combining approaches weigh each learned model as a function of the example being predicted. The most prevalent method in the literature for dynamically deciding how to weight a collection of regressors (or classifiers) is the "mixture of experts" approach <ref> [26] </ref> which consists of several different "expert" learned models (i.e., multilayer perceptrons) plus a gating network that decides which of the experts should be used for each case. Each expert reports a target attribute probability distribution for a given example.
Reference: 27. <author> Michael I. Jordan and Robert A. Jacobs. </author> <title> Hierarchical mixtures of experts and the EM algorithm. </title> <journal> Neural Computation, </journal> <volume> 6 </volume> <pages> 181-214, </pages> <year> 1994. </year>
Reference-contexts: The weights of other experts which specialize in quite different cases are unmodified. The experts become "localized" because their weights are decoupled from the weights of other experts, and they will end up specializing on a small portion of the input space. Jordan and Jacobs <ref> [27] </ref> expanded on this approach allowing the learned models/experts to be generalized linear models. The experts are leaves in a tree-structured architecture whose internal nodes are gating functions. These gating functions make "soft" splits allowing data to lie simultaneously in multiple regions.
Reference: 28. <author> Keehoon Kim and Eric B. Bartlett. </author> <title> Error estimation by series association for neural network systems. </title> <journal> Neural Computation, </journal> <volume> 7(4) </volume> <pages> 799-808, </pages> <year> 1995. </year>
Reference: 29. <author> J. Kivinen and M. Warmuth. </author> <title> Exponentiated gradient descent versus gradient descent for linear predictors. </title> <type> Technical Report ucsc-crl-94-16, </type> <institution> Department of Computer Science, UC-Santa Cruz, </institution> <year> 1994. </year>
Reference-contexts: This approach ameliorates, but does not solve, the problem because redundancy is an inherent part of the task of combining estimators. COMBINING REGRESSION ESTIMATES 5 2. Gradient descent procedures (i.e., Widrow-Hoff learning, GD, EG and EG + <ref> [29] </ref>) search for the coefficients by making iterative multiplicative or exponentiated updates to the alpha-coefficients as a function of their performance on the training data. This avoids the matrix inversion step which is susceptible to the multicollinearity problem. <p> Now a more elaborate description is given of each of the methods briefly mentioned in Section 3. The gradient-descent procedures based on Widrow-Hoff learning <ref> [29] </ref> are gradient descent (GD), and the exponentiated gradient procedures EG and EG + . These are iterative approaches where the weights, ff, are revised with multiplicative/exponentiated updates. Each revision attempts to move the weights in a direction of lower mean squared error on the training data. <p> 7.17 bodyfat 5.73 5.8 3.13 cpu 9.23 8.27 7.767 dementia 11.27 9.97 9.13 hansch 6.13 5.83 8.37 housing 8.48 7.92 7.52 imports 6.867 6.93 7.8 servo 8.267 8.03 5.73 occasionally converge to poor local minima in spite of setting the initial weights and the learning rate as Kivinen and Warmuth <ref> [29] </ref> recommend. Another interesting result is that constrained regression (CR) tends to outperform constrained regression with stacking (SCR) with slight losses for only two data sets. This raises the issue of whether stacking is a beneficial component of the SCR algorithm for "real" data sets.
Reference: 30. <author> E. B. Kong and T. G. Dietterich. </author> <title> Error-correcting output coding corrects bias and variance. </title> <booktitle> In Proceedings of the 12th International Conference on Machine Learning, </booktitle> <pages> pages 313-321. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1995. </year>
Reference-contexts: Two recent experimental evaluations of "boosting" and "bagging" are given in [19, 42]. Both approaches have proven to be quite effective, but are currently limited to a single learning algorithm. Kong and Dieterrich <ref> [30] </ref> point out that combining heterogeneous learning algorithms can reduce bias as well as variance if the bias errors of the various algorithms are different. Krogh and Vedelsby [31] have developed a method known as "active learning" based on query by committee [47, 20, 20].
Reference: 31. <author> Anders Krogh and Jesper Vedelsby. </author> <title> Neural network ensembles, cross validation, and active learning. </title> <editor> In G. Tesauro, D. Touretzky, and T. Leen, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 7, </volume> <pages> pages 231-238. </pages> <publisher> The MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: 1. Introduction Combining a set of learned models 1 to improve classification and regression estimates has been an area of much research in machine learning and neural networks <ref> [50, 37, 41, 34, 6, 36, 31, 48, 8] </ref>. The challenge of this problem is to decide which models to rely on for prediction and how much weight to give each. Suppose a physician wishes to predict a person's percentage of body fat, PBF. <p> Both approaches have proven to be quite effective, but are currently limited to a single learning algorithm. Kong and Dieterrich [30] point out that combining heterogeneous learning algorithms can reduce bias as well as variance if the bias errors of the various algorithms are different. Krogh and Vedelsby <ref> [31] </ref> have developed a method known as "active learning" based on query by committee [47, 20, 20].
Reference: 32. <author> H. Kubinyi. </author> <title> The QSAR and modelling society home page, </title> <year> 1997. </year>
Reference-contexts: The "Source" column lists "UCI" for data sets taken from the UCI Machine Learning Repository [38], "CMU" for data sets taken from the Statistics Library at Carnegie Mellon University [39], "QSAR" for data sets taken from the QSAR Home Page <ref> [32] </ref>, and UCI-MC for a proprietary data set from the UCI Medical Center. The imports data set had 41 examples with missing values which were not used due to limitations in one of the learning algorithms used. 6.2.
Reference: 33. <author> J. Lawson and R. Hanson. </author> <title> Solving Least Squares Problems. </title> <publisher> Prentice-Hall, </publisher> <address> New Jersey, </address> <year> 1974. </year>
Reference-contexts: Ridge regression, RIDGE [9] has a parameter that may be used to restrict or "regularize" the alpha-coefficients. Breiman [6] has devised an approach based on constrained least squares regression <ref> [33] </ref> where the coefficients are required to be nonnegative. The focus of this paper is on a flexible approach to weight regularization based on principal components regression. Now the discussion turns to a more precise description of weight regularization and why it is effective at handling the multi collinearity problem.
Reference: 34. <author> M. Leblanc and R. Tibshirani. </author> <title> Combining estimates in regression and classification. </title> <type> Technical report, </type> <institution> Department of Statistics, University of Toronto, </institution> <year> 1993. </year>
Reference-contexts: 1. Introduction Combining a set of learned models 1 to improve classification and regression estimates has been an area of much research in machine learning and neural networks <ref> [50, 37, 41, 34, 6, 36, 31, 48, 8] </ref>. The challenge of this problem is to decide which models to rely on for prediction and how much weight to give each. Suppose a physician wishes to predict a person's percentage of body fat, PBF. <p> LRC is calculated the same way but with member, ^ f 0 which always predicts 1. According to <ref> [34] </ref> having the extra constant term will not be necessary (i.e., it will equal zero) because in practice, E [ ^ f i (x)] = E [f (x)]. <p> The focus of this paper is on a flexible approach to weight regularization based on principal components regression. Now the discussion turns to a more precise description of weight regularization and why it is effective at handling the multi collinearity problem. Leblanc and Tibshirani <ref> [34] </ref> have proposed several ways of constraining or regu larizing the weights to help produce estimators with lower prediction error: 1. <p> A learned model may be anything from a decision/regression tree to a neural network. 2. Optimal here refers to weights which minimize mean square error for the training data. 3. Note that the constraint, P N i=1 ff i = 1, for GEM is a form of regularization <ref> [34] </ref>. The purpose of regularizing the weights is to provide an estimate which is less biased by the training sample. Thus, one would not expect GEM and LR to produce identical weights. 4.
Reference: 35. <author> W. P. Lincoln and J. Skrzypek. </author> <title> Synergy of clustering multiple backpropagation networks. </title> <editor> In D. S. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <pages> pages 650-657, </pages> <address> San Mateo, CA, 1990. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: 36. <author> Ronny Meir. </author> <title> Bias, variance and the combination of least squares estimators. </title> <editor> In G. Tesauro, D. Touretzky, and T. Leen, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 7, </volume> <pages> pages 295-302. </pages> <publisher> The MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: 1. Introduction Combining a set of learned models 1 to improve classification and regression estimates has been an area of much research in machine learning and neural networks <ref> [50, 37, 41, 34, 6, 36, 31, 48, 8] </ref>. The challenge of this problem is to decide which models to rely on for prediction and how much weight to give each. Suppose a physician wishes to predict a person's percentage of body fat, PBF. <p> To circumvent this problem, several approaches have been developed: 1. One method for handling multicollinearity is to build models which make decor-related errors by adjusting the bias of the learning algorithm [40] or the data which it sees <ref> [36] </ref>. This approach ameliorates, but does not solve, the problem because redundancy is an inherent part of the task of combining estimators. COMBINING REGRESSION ESTIMATES 5 2.
Reference: 37. <author> C. J. Merz. </author> <title> Dynamical selection of learning algorithms. </title> <editor> In D. Fisher and H. Lenz, editors, </editor> <title> Learning from Data: </title> <journal> Artificial Intelligence and Statistics, </journal> <volume> 5. </volume> <publisher> Springer Verlag, </publisher> <year> 1995. </year>
Reference-contexts: 1. Introduction Combining a set of learned models 1 to improve classification and regression estimates has been an area of much research in machine learning and neural networks <ref> [50, 37, 41, 34, 6, 36, 31, 48, 8] </ref>. The challenge of this problem is to decide which models to rely on for prediction and how much weight to give each. Suppose a physician wishes to predict a person's percentage of body fat, PBF.
Reference: 38. <author> C.J. Merz and P.M. Murphy. </author> <title> UCI repository of machine learning databases, </title> <year> 1996. </year>
Reference-contexts: The combiners were evaluated for model sets of size 10 and 50. 6.1. Regression Data Sets Table 3 summarizes the eight data sets used. The "Source" column lists "UCI" for data sets taken from the UCI Machine Learning Repository <ref> [38] </ref>, "CMU" for data sets taken from the Statistics Library at Carnegie Mellon University [39], "QSAR" for data sets taken from the QSAR Home Page [32], and UCI-MC for a proprietary data set from the UCI Medical Center.
Reference: 39. <author> M. Meyer. </author> <note> The CMU statlib home page, </note> <year> 1997. </year>
Reference-contexts: Regression Data Sets Table 3 summarizes the eight data sets used. The "Source" column lists "UCI" for data sets taken from the UCI Machine Learning Repository [38], "CMU" for data sets taken from the Statistics Library at Carnegie Mellon University <ref> [39] </ref>, "QSAR" for data sets taken from the QSAR Home Page [32], and UCI-MC for a proprietary data set from the UCI Medical Center. The imports data set had 41 examples with missing values which were not used due to limitations in one of the learning algorithms used. 6.2.
Reference: 40. <author> David W. Opitz and Jude W. Shavlik. </author> <title> Generating accurate and diverse members of a neural-network ensemble. </title> <editor> In David S. Touretzky, Michael C. Mozer, and Michael E. Hasselmo, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 8, </volume> <pages> pages 535-541. </pages> <publisher> The MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: To circumvent this problem, several approaches have been developed: 1. One method for handling multicollinearity is to build models which make decor-related errors by adjusting the bias of the learning algorithm <ref> [40] </ref> or the data which it sees [36]. This approach ameliorates, but does not solve, the problem because redundancy is an inherent part of the task of combining estimators. COMBINING REGRESSION ESTIMATES 5 2. <p> Other General Approaches Hashem and Schmeiser [24] have developed a combining scheme similar to GEM as well as a less constrained version which does not require the weights to sum to one. Like GEM, this method is susceptible to the multicollinearity problem. Opitz and Shavlik <ref> [40] </ref> attempt to assign each model a weight according to an estimate of its accuracy, i.e., 24 CHRISTOPHER MERZ AND MICHAEL PAZZANI ff i = P N where E i the estimate of model i's accuracy based on performance on a validation set.
Reference: 41. <author> M. P. Perrone and L. N. Cooper. </author> <title> When networks disagree: Ensemble methods for hybrid neural networks. </title> <editor> In R. J. Mammone, editor, </editor> <booktitle> Artificial Neural Networks for Speech and Vision, </booktitle> <pages> pages 126-142, </pages> <address> London, 1993. </address> <publisher> Chapman & Hall. </publisher>
Reference-contexts: 1. Introduction Combining a set of learned models 1 to improve classification and regression estimates has been an area of much research in machine learning and neural networks <ref> [50, 37, 41, 34, 6, 36, 31, 48, 8] </ref>. The challenge of this problem is to decide which models to rely on for prediction and how much weight to give each. Suppose a physician wishes to predict a person's percentage of body fat, PBF. <p> Variations on PCR* are evaluated in Section 7. Related work is discussed in Section 8. Directions for future work are given in Section 9, and concluding remarks are given in Section 10. 2. Motivation The problem of combining a set of learned models is defined using the terminology of <ref> [41] </ref>. Suppose two sets of data are given: a training set D T rain = (x m ; y m ) and a test set D Test = (x l ; y l ).
Reference: 42. <author> J. Ross Quinlan. Bagging, </author> <title> boosting, </title> <booktitle> and C4.5. In Proceedings of the Fourteenth National Conference on Artificial Intelligence, </booktitle> <year> 1996. </year>
Reference-contexts: In boosting (and bagging), more emphasis has been placed on model generation than model combination. It's possible that a more elaborate combining scheme like that of PCR* may be a more effective method of combining the models generated. Two recent experimental evaluations of "boosting" and "bagging" are given in <ref> [19, 42] </ref>. Both approaches have proven to be quite effective, but are currently limited to a single learning algorithm. Kong and Dieterrich [30] point out that combining heterogeneous learning algorithms can reduce bias as well as variance if the bias errors of the various algorithms are different.
Reference: 43. <author> Y. Raviv and N. Intrator. </author> <title> Bootstrapping with noise: An effective regularization technique. </title> <booktitle> Connection Science, </booktitle> ?(?):??-??, <year> 1996. </year>
Reference: 44. <author> Galina Rogova. </author> <title> Combining the results of neural network classifiers. </title> <booktitle> Neural Networks, </booktitle> <volume> 7(5) </volume> <pages> 777-781, </pages> <year> 1994. </year>
Reference: 45. <author> David E. Rumelhart, Geoffrey E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart, J. L. McClelland, and the PDP research group., editors, </editor> <booktitle> Parallel distributed processing: Explorations in the microstructure of cognition, Volume 1: Foundations. </booktitle> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: The imports data set had 41 examples with missing values which were not used due to limitations in one of the learning algorithms used. 6.2. Constituent Learners The set of learned models, F, were generated using Backpropagation networks (BP) <ref> [45] </ref> and Multivariate Adaptive Regression Splines (MARS) [21]. In both experiments, preliminary BP runs were conducted to find a network topology which gave good performance for each data set so that the combining methods would have to work well to improve upon a single model. 6.3.
Reference: 46. <author> Robert E. Schapire. </author> <title> The strength of weak learnability. </title> <journal> Machine Learning, </journal> <volume> 5(2) </volume> <pages> 197-227, </pages> <month> June </month> <year> 1990. </year> <title> COMBINING REGRESSION ESTIMATES 29 </title>
Reference-contexts: The underlying theory of this approach indicates that the models should be weighted uniformly. Unlike PCR*, bagging is limited to a single learning algorithm. Another resampling method has its roots in what is known as "boosting," initially developed by Schapire <ref> [46] </ref>. Boosting is based on the idea that a set of moderately inaccurate rules-of-thumb (i.e., learned models) can be generated and combined to form a very accurate prediction rule.
Reference: 47. <author> H. S. Seung, M. Opper, and H. Sompolinsky. </author> <title> Query by committee. </title> <editor> In David Haussler, editor, </editor> <booktitle> Proceedings of the 5th Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> pages 287-294. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1992. </year>
Reference-contexts: Kong and Dieterrich [30] point out that combining heterogeneous learning algorithms can reduce bias as well as variance if the bias errors of the various algorithms are different. Krogh and Vedelsby [31] have developed a method known as "active learning" based on query by committee <ref> [47, 20, 20] </ref>. In this approach, as a collection of neural networks is trained simultaneously, patterns which have large ambiguity (i.e., the ensemble's predictions tend to vary considerably) are more likely to be included in the next round of training. 8.3.
Reference: 48. <author> Volker Tresp and Michiaki Taniguchi. </author> <title> Combining estimators using non-constant weighting functions. </title> <editor> In G. Tesauro, D. Touretzky, and T. Leen, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 7, </volume> <pages> pages 419-426. </pages> <publisher> The MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: 1. Introduction Combining a set of learned models 1 to improve classification and regression estimates has been an area of much research in machine learning and neural networks <ref> [50, 37, 41, 34, 6, 36, 31, 48, 8] </ref>. The challenge of this problem is to decide which models to rely on for prediction and how much weight to give each. Suppose a physician wishes to predict a person's percentage of body fat, PBF. <p> These gating functions make "soft" splits allowing data to lie simultaneously in multiple regions. Currently, the weights generated by PCR* do not change as a function of the example being predicted. A comparison between the two approaches is needed. Tresp and Taniguchi <ref> [48] </ref> derived a collection of non-constant weighting functions which can be used to combine regressors or classifiers. The proposed methods weigh a learned model according to its reliability in the region of the given example.
Reference: 49. <author> D. H. Wolpert. </author> <title> Stacked generalization. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 241-259, </pages> <year> 1992. </year>
Reference-contexts: The end result is a more restricted set of coefficients. An iterative approach is used to searching for (as discussed in [9]). A "stacked" constrained regression (SCR) procedure [6] has also been included in the evaluation. The two main components of this approach are stacking and constrained regression. Stacking <ref> [49] </ref> is simply a method of approximating the matrix of predictions, A F .
Reference: 50. <author> D. H. Wolpert. </author> <title> Combining generealizers using partitions of the learning set. </title> <editor> In L. Nadel and D. Stein, editors, </editor> <booktitle> Lectures in Complex Systems. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: 1. Introduction Combining a set of learned models 1 to improve classification and regression estimates has been an area of much research in machine learning and neural networks <ref> [50, 37, 41, 34, 6, 36, 31, 48, 8] </ref>. The challenge of this problem is to decide which models to rely on for prediction and how much weight to give each. Suppose a physician wishes to predict a person's percentage of body fat, PBF.
References-found: 50

