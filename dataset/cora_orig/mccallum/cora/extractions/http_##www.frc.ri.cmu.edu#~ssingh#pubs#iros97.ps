URL: http://www.frc.ri.cmu.edu/~ssingh/pubs/iros97.ps
Refering-URL: http://www.frc.ri.cmu.edu/~ssingh/pubs_conf.html
Root-URL: 
Title: Abstract  
Abstract: This paper reports on recent progress in the development of system to group populations of vegetative cuttings. The system is required to assign a classification to cuttings such that they appear uniform after a growing period using single two-dimensional monochrome images. We have developed a fast segmentation technique that is able to measure plant features and a supervised learning scheme that learns a mapping from the features to a scalar classification. We report results based on segmentation of over 2000 geranium cuttings. The system is able to process images at 2 Hz and has an accuracy of over 90%. Both metrics exceed human performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Calpe, J.; Pla, F.; Monfort, J.; Diaz, P.; Boada, </author> <title> J.C.; Robust low-cost vision system for fruit grading, </title> <booktitle> Proceedings of 8th Mediterranean Electrotechnical Conference on Industrial Applications in Power Systems, Computer Science and Telecommunications (MELECON 96); Part: </booktitle> <address> vol.3; Bari, Italy; May 1996; pp. </address> <pages> 1710-13. </pages>
Reference-contexts: Finally, the classification phase feeds the nine measurements into classification algorithm and generates a grade for the cutting. 2 Relationship to Other Work Grading is a common task in the agricultural industry. With an increasing need for automation, systems have been designed to grade produce such as fruit <ref> [1] </ref>, vegetables [2] and shellfish [3]. Typically such systems are based on simple criteria such as weight or size that can be measured very quickly in a production line. Grading of owering plants has been intractable until recently partly due to the lack of economical sensing and computing.
Reference: [2] <author> Heinemann, P.H.; Pathare, </author> <title> N.P.; Morrow, C.T., An automated inspection station for machine-vision grading of potatoes, Machine Vision and Applications; Mach. </title> <type> Vis. </type> <institution> Appl. </institution> <address> (USA); vol.9, </address> <publisher> no.1; Springer-Verlag; 1996; pp.14-19. </publisher>
Reference-contexts: With an increasing need for automation, systems have been designed to grade produce such as fruit [1], vegetables <ref> [2] </ref> and shellfish [3]. Typically such systems are based on simple criteria such as weight or size that can be measured very quickly in a production line. Grading of owering plants has been intractable until recently partly due to the lack of economical sensing and computing.
Reference: [3] <author> Kassler, M.; Corke, P.I.; Wong, </author> <title> P.C.; Automatic grading and packing of prawns, Computers and Electronics in Agriculture, </title> <journal> vol.9, </journal> <note> no.4; Dec. 1993; pp. 319-33. </note>
Reference-contexts: With an increasing need for automation, systems have been designed to grade produce such as fruit [1], vegetables [2] and shellfish <ref> [3] </ref>. Typically such systems are based on simple criteria such as weight or size that can be measured very quickly in a production line. Grading of owering plants has been intractable until recently partly due to the lack of economical sensing and computing.
Reference: [4] <author> Muttiah, R. S, Miles, G. E., </author> <title> System engineering of grading plants using machine vision, </title> <journal> American Society of Agricultural Engineers, </journal> <volume> Paper No. </volume> <pages> 88-1543, </pages> <year> 1988. </year>
Reference-contexts: Grading of owering plants has been intractable until recently partly due to the lack of economical sensing and computing. Researchers earlier in the decade have looked at the task of grading plants automatically and concluded that it was not cost-effective <ref> [4] </ref> and accuracy was not on par with human performance [5]. Simple grading schemes that separate plants into acceptable and cull have been developed [6] and recently some researchers have developed grading techniques to mimic human operators in the production of roses [7] and begonias [8].
Reference: [5] <author> Sistler, F. E, </author> <title> Grading agricultural products with machine vision, Grading agricultural products with machine vision Proceedings. </title> <booktitle> IROS '90. IEEE International Workshop on Intelligent Robots and Systems '90, July 1990; pp. </booktitle> <pages> 255-61. </pages>
Reference-contexts: Researchers earlier in the decade have looked at the task of grading plants automatically and concluded that it was not cost-effective [4] and accuracy was not on par with human performance <ref> [5] </ref>. Simple grading schemes that separate plants into acceptable and cull have been developed [6] and recently some researchers have developed grading techniques to mimic human operators in the production of roses [7] and begonias [8]. There is a large literature on the segmentation of images of rigid objects.
Reference: [6] <author> Kranzler, G. A., Rigney, M. P., </author> <title> Machine vision grading for tree seedlings, </title> <booktitle> Proceedings of the 11th International Congress on Agricultural Engineering. </booktitle> <pages> pp 1883-1888, </pages> <address> A.A. </address> <publisher> Balkema, </publisher> <address> Dubin, Ireland, </address> <month> September </month> <year> 1989. </year>
Reference-contexts: Researchers earlier in the decade have looked at the task of grading plants automatically and concluded that it was not cost-effective [4] and accuracy was not on par with human performance [5]. Simple grading schemes that separate plants into acceptable and cull have been developed <ref> [6] </ref> and recently some researchers have developed grading techniques to mimic human operators in the production of roses [7] and begonias [8]. There is a large literature on the segmentation of images of rigid objects. However, the morphology of plants is so varied that little of this work is relevant.
Reference: [7] <author> V. Steinmetz, M.J. Delwiche, D.K. Giles and R. Evans. </author> <year> 1994. </year> <title> Sorting cut roses with machine vision, </title> <journal> Transactions of the ASAE. </journal> <volume> Vol. 37(4) </volume> <pages> 1347-1353. </pages>
Reference-contexts: Simple grading schemes that separate plants into acceptable and cull have been developed [6] and recently some researchers have developed grading techniques to mimic human operators in the production of roses <ref> [7] </ref> and begonias [8]. There is a large literature on the segmentation of images of rigid objects. However, the morphology of plants is so varied that little of this work is relevant. A smaller literature exists on the segmentation of plant images, and usually for very specific purposes.
Reference: [8] <author> Timmermans, A. J. M, Borm, T. J. A, Meinders, M. B. J., </author> <title> Color vision for online sorting of begonias based on learning techniques, </title> <booktitle> In Proc. SPIE East 96, Optics in Agriculture, Forestry, and Biological Processing II. </booktitle> <address> Boston, </address> <month> Nov </month> <year> 1996. </year>
Reference-contexts: Simple grading schemes that separate plants into acceptable and cull have been developed [6] and recently some researchers have developed grading techniques to mimic human operators in the production of roses [7] and begonias <ref> [8] </ref>. There is a large literature on the segmentation of images of rigid objects. However, the morphology of plants is so varied that little of this work is relevant. A smaller literature exists on the segmentation of plant images, and usually for very specific purposes.
Reference: [9] <author> Simonton, W. and Pease, J., </author> <title> Orientation Independent Machine Vision Classification of Plant Parts, </title> <journal> Journal Agricultural Engineering Research, </journal> <volume> Number 54, </volume> <pages> pp. 231-243, </pages> <year> 1993. </year>
Reference-contexts: A smaller literature exists on the segmentation of plant images, and usually for very specific purposes. For example, Simonton has developed methods to identify locations on a stem where a gripper can be applied to pick up a plant cutting <ref> [9] </ref>. Other examples of segmentation techniques can be found in [10] and [11]. Our earlier research developed a segmentation method that uses erosion and dilation of images based on knowledge of the size of certain plant features [12][13].
Reference: [10] <author> Shiraishi, M.; Sumiya, H.; </author> <title> Plant identification from leaves using quasi-sensor fusion, </title> <journal> Transactions of the ASME. Journal of Manufacturing Science and Engineering; Trans. ASME, J. Manuf. Sci. Eng. (USA); vol.118, no.3; ASME; Aug. 1996; pp. </journal> <pages> 382-7. </pages>
Reference-contexts: For example, Simonton has developed methods to identify locations on a stem where a gripper can be applied to pick up a plant cutting [9]. Other examples of segmentation techniques can be found in <ref> [10] </ref> and [11]. Our earlier research developed a segmentation method that uses erosion and dilation of images based on knowledge of the size of certain plant features [12][13]. Although this method is commonly used in image processing, we found it to be both slow and brittle.
Reference: [11] <author> Peleg, K., Cohen, O, Ziv M., and Kimmel, E., </author> <title> Machine identification of buds in images of plant shoots, Machine Vision And Applications, </title> <publisher> v. </publisher> <address> 6, p224, </address> <year> 1993. </year>
Reference-contexts: For example, Simonton has developed methods to identify locations on a stem where a gripper can be applied to pick up a plant cutting [9]. Other examples of segmentation techniques can be found in [10] and <ref> [11] </ref>. Our earlier research developed a segmentation method that uses erosion and dilation of images based on knowledge of the size of certain plant features [12][13]. Although this method is commonly used in image processing, we found it to be both slow and brittle.
Reference: [12] <author> Ji, Q. and Singh, S., </author> <title> Early results in the grading of vegetative cuttings using computer vision, </title> <type> Technical Report, </type> <institution> Robotics Institute, Carnegie Mellon University, CMU-RI-TR-96-22, </institution> <month> May, </month> <year> 1996. </year>
Reference: [13] <author> Ji, Qiang and Singh, S., </author> <title> Automated visual grading of vegetative cuttings, </title> <booktitle> In Proc. SPIE East 96, Optics in Agriculture, Forestry, and Biological Processing II. </booktitle> <address> Boston, </address> <month> Nov </month> <year> 1996. </year>
Reference: [14] <author> Otsu, N., </author> <title> A threshold selection method from gray-scale histograms, </title> <journal> IEEE Transactions on System, Man, and Cybernetics, </journal> <volume> Vol. SMC-9, </volume> <year> 1979, </year> <title> p62-66. Small (Actual) Medium (Actual) Large (Actual) Total Small (Graded) 60 4 0 64 Medium (Graded) 5 147 4 156 Large (Graded) 7 14 209 230 Total 72 165 213 450 Accuracy 83.33% 89.09% 98.12% 92.44% </title>
Reference-contexts: In comparison, the second method correctly estimates the number of leaves and preserves details of features on the cutting. In addition, the new method poses less stringent requirements on the lighting of the cuttings. This provides an additional time savings because a simple global thresholding scheme <ref> [14] </ref> can be used rather than a more complicated adaptive tresholding that was necessary earlier. Finally, this algorithm is approximately an order of magnitude faster, segmenting a 480 x640 image in an average of 0.4 seconds on a Pentium 166 Mhz processor.
References-found: 14

