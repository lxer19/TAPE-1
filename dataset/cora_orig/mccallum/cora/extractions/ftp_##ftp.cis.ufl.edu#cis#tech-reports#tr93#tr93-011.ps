URL: ftp://ftp.cis.ufl.edu/cis/tech-reports/tr93/tr93-011.ps
Refering-URL: http://www.cis.ufl.edu/tech-reports/tech-reports/tr93-abstracts.html
Root-URL: http://www.cis.ufl.edu
Email: ted@cis.ufl.edu  
Title: A Concurrent Dynamic Task Graph  
Author: Theodore Johnson 
Address: Gainesville, Fl 32611-2024  
Affiliation: Dept. of Computer and Inf. Science University of Florida  
Abstract: Task graphs are used for scheduling tasks on parallel processors when the tasks have dependencies. If the execution of the program is known ahead of time, then the tasks can be statically and optimally allocated to the processors. If the tasks and task dependencies aren't known ahead of time (the case in some analysis-factor sparse matrix algorithms), then task scheduling must be performed on the fly. We present simple algorithms for a concurrent dynamic-task graph. A processor that needs to execute a new task can query the task graph for a new task, and new tasks can be added to the task graph on the fly. We present several alternatives for allocating tasks for processors and compare their performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Anani. LR-algorithm: </author> <title> Concurrent operations on priority queues. </title> <booktitle> In Proceedings of the Second IEEE Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 22-25, </pages> <year> 1990. </year>
Reference-contexts: Non-locking Algorithms A non-locking algorithm uses atomic read-modify-write instead of locking to ensure correctness in spite of concurrent accesses. Non-locking algorithms have the attractive property that they avoid busy-waiting, which can degrade performance <ref> [1, 6] </ref>. These algorithms typically use the compare and swap or the compare and swap double instruction to commit modifications [8, 16, 18, 19], although some algorithms use the fetch-and-add instruction [7]. The correctness of the DTG algorithms depends on the atomicity of the hash table operations.
Reference: [2] <author> C.D. Polychronopolous U. Bannerjee. </author> <title> Processor allocation for horizontal and vertical parallelism and related speedup bounds. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36:410-420, </volume> <year> 1987. </year>
Reference-contexts: An eligible node's priority is the weight of the heaviest weighted path to any exit node. FIFO: Schedule tasks in the order that they become available. Largecalc: Schedule the heaviest task first <ref> [2] </ref>. Scheduler 5 Proc. 8 Proc. 10 Proc. FIFO 4.297 5.311 5.632 Maxweight 4.309 5.309 5.616 Minweight 4.198 5.280 5.610 Maxdepend 4.456 5.414 5.690 Random 4.263 5.315 5.631 LIFO 4.227 5.246 5.631 Table 1: Comparison of DTG scheduler performance. <p> Scheduler speedup Max 7.072 FIFO 5.470 Largecalc 5.470 Heavy 5.456 Levelfifo 5.474 Levellarge 5.492 Maxdep 5.440 Table 2: Comparison of static-task graph scheduler performance (eight processors). Heavy: An eligible node's priority is the sum of its weight and the weight of its immediate successors <ref> [2] </ref>. Levelfifo: Assign BFS levels to tasks, and schedule the tasks within a level by FIFO. Levellarge: Assign BFS levels to tasks, and schedule the heaviest task in a level first [17]. Maxdep: Schedule the task with the greatest number of dependent tasks first [2]. <p> the weight of its immediate successors <ref> [2] </ref>. Levelfifo: Assign BFS levels to tasks, and schedule the tasks within a level by FIFO. Levellarge: Assign BFS levels to tasks, and schedule the heaviest task in a level first [17]. Maxdep: Schedule the task with the greatest number of dependent tasks first [2]. Comparing Tables 1 and 2, we note that there is little difference among most of the dynamic and static scheduling policies.
Reference: [3] <author> E.G. Coffman. </author> <title> Computer and Job-Shop Scheduling. </title> <publisher> John Wiley and Sons, </publisher> <year> 1976. </year>
Reference-contexts: If there is an edge from task T 1 to task T 2 in the task graph, then T 1 must complete before T 2 can begin. Previous work <ref> [3, 17, 11, 10, 20, 9, 12] </ref> has assumed that the task graph is specified ahead of time. <p> Since the task graph is specified ahead of time, it can be analyzed for static scheduling purposes. The scheduling can be static or dynamic. In static scheduling, the tasks are allocated to the processors before the computation starts <ref> [3, 17, 10, 20] </ref>. In dynamic scheduling, the tasks are allocated to processors on the fly [9, 12].
Reference: [4] <author> T. A. Davis and P. C. Yew. </author> <title> A nondeterministic parallel algorithm for general unsymmetric sparse LU factorization. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 11(3) </volume> <pages> 383-402, </pages> <year> 1990. </year>
Reference-contexts: A common approach is the multi-frontal method, in which portions of the matrix are gathered into fronts for factoring, and these fronts make contributions to other fronts. The tasks in the DTG represent the fronts, and the links represent the contributions passed between fronts. In some analysis-factor multifrontal algorithms <ref> [4, 5] </ref>, the tasks and their dependencies are determined during execution. In section 2, we present the basic concurrent DTG algorithm, and some extensions. In section 3, we explore algorithms for scheduling eligible tasks, and in section 4 we examine some performance issues. <p> For example, a parallel algorithm for the LU factorization of sparse asymmetric matrices might assign the task of adding pivots to frontal matrices to one set of processors, and assign the task of composing and factoring the frontal matrices to a different set <ref> [4] </ref>. Processors p and q might build frontal matrices A and B concurrently, where elements of B depend on the factorization of A. Since A and B are built concurrently, B might be added to the DTG before A.
Reference: [5] <author> T.A. Davis and I.S. Duff. </author> <title> Unsymmetric-pattern multifrontal methods for parallel sparse LU factorization. </title> <type> Technical report, </type> <institution> University of Florida, Dept. of CIS TR-91-23, </institution> <year> 1991. </year> <note> Available at anonymous ftp site cis.ufl.edu:cis/tech-reports. </note>
Reference-contexts: A common approach is the multi-frontal method, in which portions of the matrix are gathered into fronts for factoring, and these fronts make contributions to other fronts. The tasks in the DTG represent the fronts, and the links represent the contributions passed between fronts. In some analysis-factor multifrontal algorithms <ref> [4, 5] </ref>, the tasks and their dependencies are determined during execution. In section 2, we present the basic concurrent DTG algorithm, and some extensions. In section 3, we explore algorithms for scheduling eligible tasks, and in section 4 we examine some performance issues.
Reference: [6] <author> R.R. Glenn, D.V. Pryor, J.M. Conroy, and T. Johnson. </author> <title> Characterizing memory hotspots in a shared memory mimd machine. In Supercomputing '91. </title> <journal> IEEE and ACM SIGARCH, </journal> <year> 1991. </year>
Reference-contexts: Non-locking Algorithms A non-locking algorithm uses atomic read-modify-write instead of locking to ensure correctness in spite of concurrent accesses. Non-locking algorithms have the attractive property that they avoid busy-waiting, which can degrade performance <ref> [1, 6] </ref>. These algorithms typically use the compare and swap or the compare and swap double instruction to commit modifications [8, 16, 18, 19], although some algorithms use the fetch-and-add instruction [7]. The correctness of the DTG algorithms depends on the atomicity of the hash table operations.
Reference: [7] <author> A. Gottlieb, B. D. Lubachevsky, and L. Rudolph. </author> <title> Basic techniques for the efficient coordiantion of very large numbers of cooperating sequential processors. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 5(2) </volume> <pages> 164-189, </pages> <year> 1983. </year>
Reference-contexts: Non-locking algorithms have the attractive property that they avoid busy-waiting, which can degrade performance [1, 6]. These algorithms typically use the compare and swap or the compare and swap double instruction to commit modifications [8, 16, 18, 19], although some algorithms use the fetch-and-add instruction <ref> [7] </ref>. The correctness of the DTG algorithms depends on the atomicity of the hash table operations. Fortunately, many practical non-locking list and search structure algorithms exist in the literature [16, 19]. One place where care must be taken involves access to a tasks list of dependent tasks.
Reference: [8] <author> M. Herlihy. </author> <title> A methodology for implementing highly concurrent data structures. </title> <booktitle> In Proceeding of the Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 197-206. </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: Non-locking algorithms have the attractive property that they avoid busy-waiting, which can degrade performance [1, 6]. These algorithms typically use the compare and swap or the compare and swap double instruction to commit modifications <ref> [8, 16, 18, 19] </ref>, although some algorithms use the fetch-and-add instruction [7]. The correctness of the DTG algorithms depends on the atomicity of the hash table operations. Fortunately, many practical non-locking list and search structure algorithms exist in the literature [16, 19].
Reference: [9] <author> J. Ji and M. Jeng. </author> <title> Dynamic task allocation on shared memory multiprocessor systems. </title> <booktitle> In ICPP, </booktitle> <pages> pages I:17-21, </pages> <year> 1990. </year>
Reference-contexts: If there is an edge from task T 1 to task T 2 in the task graph, then T 1 must complete before T 2 can begin. Previous work <ref> [3, 17, 11, 10, 20, 9, 12] </ref> has assumed that the task graph is specified ahead of time. <p> The scheduling can be static or dynamic. In static scheduling, the tasks are allocated to the processors before the computation starts [3, 17, 10, 20]. In dynamic scheduling, the tasks are allocated to processors on the fly <ref> [9, 12] </ref>. If good task execution time estimates can be fl In the 1993 Int'l Conf. on Parallel Processing made in advance, static scheduling will outperform dynamic scheduling, but dynamic scheduling will adjust to the actual execution conditions.
Reference: [10] <author> H. Kasahara and S. Narita. </author> <title> Practical multiprocessor scheduling algorithms for efficient parallel processing. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-33:1023-1029, </volume> <year> 1984. </year>
Reference-contexts: If there is an edge from task T 1 to task T 2 in the task graph, then T 1 must complete before T 2 can begin. Previous work <ref> [3, 17, 11, 10, 20, 9, 12] </ref> has assumed that the task graph is specified ahead of time. <p> Since the task graph is specified ahead of time, it can be analyzed for static scheduling purposes. The scheduling can be static or dynamic. In static scheduling, the tasks are allocated to the processors before the computation starts <ref> [3, 17, 10, 20] </ref>. In dynamic scheduling, the tasks are allocated to processors on the fly [9, 12].
Reference: [11] <author> D. Klappholz and S. Narita. </author> <title> Practical multiprocessor scheduling algorithms for efficient parallel processing. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-33:315-321, </volume> <year> 1984. </year>
Reference-contexts: If there is an edge from task T 1 to task T 2 in the task graph, then T 1 must complete before T 2 can begin. Previous work <ref> [3, 17, 11, 10, 20, 9, 12] </ref> has assumed that the task graph is specified ahead of time.
Reference: [12] <author> D. Klappholz and H.C. Park. </author> <title> Parallelized process scheduling for a tightly-coupled mimd machine. </title> <booktitle> In Int'l Conf. on Parallel Processing, </booktitle> <pages> pages 315-321, </pages> <year> 1984. </year>
Reference-contexts: If there is an edge from task T 1 to task T 2 in the task graph, then T 1 must complete before T 2 can begin. Previous work <ref> [3, 17, 11, 10, 20, 9, 12] </ref> has assumed that the task graph is specified ahead of time. <p> The scheduling can be static or dynamic. In static scheduling, the tasks are allocated to the processors before the computation starts [3, 17, 10, 20]. In dynamic scheduling, the tasks are allocated to processors on the fly <ref> [9, 12] </ref>. If good task execution time estimates can be fl In the 1993 Int'l Conf. on Parallel Processing made in advance, static scheduling will outperform dynamic scheduling, but dynamic scheduling will adjust to the actual execution conditions.
Reference: [13] <author> L. Kleinrock. </author> <title> Queueing Systems, volume 1. </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: Therefore, the arrival rate at a bucket is: b = E + 2 ((D + 1)T a + T q ) 1 The time to execute a task access is T a , so b = 1=T a The waiting time at an M/M/1 queue is <ref> [13] </ref> W = =(1 ) where = =.
Reference: [14] <author> W. Massey. </author> <title> A probabilistic analysis of a database system. </title> <booktitle> In ACM SIGMETRICS Conference on Measuring and Modeling of Computer Systems, </booktitle> <pages> pages 141-146, </pages> <month> Aug. </month> <year> 1986. </year>
Reference-contexts: Since there is little difference in DTG scheduler performance, we recommend a simple or low-overhead method. For example, [16] presents a simple lock free FIFO queue which can serve as the eligible queue. Manber <ref> [14] </ref> has proposed concurrent pools as a low overhead method for implementing shared queues that doesn't require a FIFO ordering. 4 Performance In this section, we investigate the effect of DTG overhead on speedup. Figure 4 shows a plot of speedup versus task execution time.
Reference: [15] <author> J.M. Mellor-Crummey and M.L. Scott. </author> <title> Algorithms for scalable synchronization on shared-memory multiprocessors. </title> <journal> ACM Trans. Computer Systems, </journal> <volume> 9(1) </volume> <pages> 21-65, </pages> <year> 1991. </year>
Reference-contexts: The psuedo-code for the add task, get task, and delete task operations follows. We assume that the tasks and the hash table buckets can be locked (we later discuss a non-locking implementation). The lock can be a simple busy-wait lock, or the contention-free MCS lock <ref> [15] </ref>. Each task graph entry t has three fields: a field for the lock, a count of the number of unfinished prerequisite tasks (ND), and a list of tasks that depend on t (dependent). When a translate task operation is performed, the lock on the hash table entry is retained.
Reference: [16] <author> S. Prakash, Y.H. Lee, and T. Johnson. </author> <title> A non-blocking algorithm for shared queues using compare-and-swap. </title> <booktitle> In Proc. Int'l Conf. on Parallel Processing, </booktitle> <pages> pages II68-II75, </pages> <year> 1991. </year>
Reference-contexts: Non-locking algorithms have the attractive property that they avoid busy-waiting, which can degrade performance [1, 6]. These algorithms typically use the compare and swap or the compare and swap double instruction to commit modifications <ref> [8, 16, 18, 19] </ref>, although some algorithms use the fetch-and-add instruction [7]. The correctness of the DTG algorithms depends on the atomicity of the hash table operations. Fortunately, many practical non-locking list and search structure algorithms exist in the literature [16, 19]. <p> The correctness of the DTG algorithms depends on the atomicity of the hash table operations. Fortunately, many practical non-locking list and search structure algorithms exist in the literature <ref> [16, 19] </ref>. One place where care must be taken involves access to a tasks list of dependent tasks. The finished task operation should declare that a task is finished with a decisive operation, so that the correctness of Lemma 2 is maintained. <p> We note that the CP method requires O (n 2 ) time for processing, and may not always be reasonable. Since there is little difference in DTG scheduler performance, we recommend a simple or low-overhead method. For example, <ref> [16] </ref> presents a simple lock free FIFO queue which can serve as the eligible queue. Manber [14] has proposed concurrent pools as a low overhead method for implementing shared queues that doesn't require a FIFO ordering. 4 Performance In this section, we investigate the effect of DTG overhead on speedup.
Reference: [17] <author> Shirazi, Wang, and Pathak. </author> <title> Analysis and evaluation of heuristic methods of static task scheduling. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 10 </volume> <pages> 222-232, </pages> <year> 1990. </year>
Reference-contexts: If there is an edge from task T 1 to task T 2 in the task graph, then T 1 must complete before T 2 can begin. Previous work <ref> [3, 17, 11, 10, 20, 9, 12] </ref> has assumed that the task graph is specified ahead of time. <p> Since the task graph is specified ahead of time, it can be analyzed for static scheduling purposes. The scheduling can be static or dynamic. In static scheduling, the tasks are allocated to the processors before the computation starts <ref> [3, 17, 10, 20] </ref>. In dynamic scheduling, the tasks are allocated to processors on the fly [9, 12]. <p> A task t 0 is eligible for execution only if all tasks t i such that (t i ; t 0 ) 2 A are labeled F (similar to a mature node in <ref> [17] </ref>). There are three operations on a DTG: 1 add task (T,D): The add task operation adds task T to the DTG, and specifies that the set of tasks D = ft 1 ; : : : ; t n g must finish execution before T can start execution. <p> We collected the dynamic-task graph by recording the dependency edges, and added a dependency link from task T to all tasks that T creates. We simulated the following algorithms on the equivalent static-task graphs using eight processors: CP: Critical path method <ref> [17] </ref>. An eligible node's priority is the weight of the heaviest weighted path to any exit node. FIFO: Schedule tasks in the order that they become available. Largecalc: Schedule the heaviest task first [2]. Scheduler 5 Proc. 8 Proc. 10 Proc. <p> Heavy: An eligible node's priority is the sum of its weight and the weight of its immediate successors [2]. Levelfifo: Assign BFS levels to tasks, and schedule the tasks within a level by FIFO. Levellarge: Assign BFS levels to tasks, and schedule the heaviest task in a level first <ref> [17] </ref>. Maxdep: Schedule the task with the greatest number of dependent tasks first [2]. Comparing Tables 1 and 2, we note that there is little difference among most of the dynamic and static scheduling policies.
Reference: [18] <author> J. Turek, D. Shasha, and S. Prakash. </author> <title> Locking without blocking: Making lock based concurrent data structure algorithms nonblocking. </title> <booktitle> In ACM Symp. on Principles of Database Systems, </booktitle> <pages> pages 212-222, </pages> <year> 1992. </year>
Reference-contexts: Non-locking algorithms have the attractive property that they avoid busy-waiting, which can degrade performance [1, 6]. These algorithms typically use the compare and swap or the compare and swap double instruction to commit modifications <ref> [8, 16, 18, 19] </ref>, although some algorithms use the fetch-and-add instruction [7]. The correctness of the DTG algorithms depends on the atomicity of the hash table operations. Fortunately, many practical non-locking list and search structure algorithms exist in the literature [16, 19].
Reference: [19] <author> J.D. Valois. </author> <title> Towards Practical Lock-free Data Structures. </title> <note> Submitted for publication, </note> <year> 1993. </year>
Reference-contexts: Non-locking algorithms have the attractive property that they avoid busy-waiting, which can degrade performance [1, 6]. These algorithms typically use the compare and swap or the compare and swap double instruction to commit modifications <ref> [8, 16, 18, 19] </ref>, although some algorithms use the fetch-and-add instruction [7]. The correctness of the DTG algorithms depends on the atomicity of the hash table operations. Fortunately, many practical non-locking list and search structure algorithms exist in the literature [16, 19]. <p> The correctness of the DTG algorithms depends on the atomicity of the hash table operations. Fortunately, many practical non-locking list and search structure algorithms exist in the literature <ref> [16, 19] </ref>. One place where care must be taken involves access to a tasks list of dependent tasks. The finished task operation should declare that a task is finished with a decisive operation, so that the correctness of Lemma 2 is maintained.
Reference: [20] <author> Z. Yin, C. Chui, R. Shu, and K. Huang. </author> <title> Two precedence-related task-scheduling algorithms. </title> <journal> Int'l Journal of High Speed Computing, </journal> <volume> 3(3) </volume> <pages> 223-240, </pages> <year> 1991. </year>
Reference-contexts: If there is an edge from task T 1 to task T 2 in the task graph, then T 1 must complete before T 2 can begin. Previous work <ref> [3, 17, 11, 10, 20, 9, 12] </ref> has assumed that the task graph is specified ahead of time. <p> Since the task graph is specified ahead of time, it can be analyzed for static scheduling purposes. The scheduling can be static or dynamic. In static scheduling, the tasks are allocated to the processors before the computation starts <ref> [3, 17, 10, 20] </ref>. In dynamic scheduling, the tasks are allocated to processors on the fly [9, 12].
References-found: 20

