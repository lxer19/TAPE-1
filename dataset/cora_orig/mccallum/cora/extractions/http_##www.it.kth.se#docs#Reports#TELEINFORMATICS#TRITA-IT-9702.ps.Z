URL: http://www.it.kth.se/docs/Reports/TELEINFORMATICS/TRITA-IT-9702.ps.Z
Refering-URL: http://www.it.kth.se/docs/Reports/TELEINFORMATICS/
Root-URL: http://www.it.kth.se
Email: joacim@nada.kth.se, perham@nada.kth.se  lisper@it.kth.se  
Title: A  An Experimental Implementation of a Highly Abstract Model of Data Parallel Programming  
Author: Kungl Tekniska H ogskolan Joacim Halen and Per Hammarlund Bjorn Lisper 
Date: March 12, 1997  
Address: S-100 44 Stockholm, Sweden  204, S-164 40 Kista, Sweden  
Affiliation: Royal Institute of Technology Department of Teleinformatics  NADA|Department of Numerical Analysis and Computing Science Royal Institute of Technology,  Department of Teleinformatics Royal Institute of Technology, Electrum  
Pubnum: TRITA-IT-9702 ISSN 1103-534X ISRN KTH/IT/R-97/02-SE  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Harold Abelson, Jay Sussman, and Julie Sussman. </author> <title> Structure and Interpretation of Computer Programs. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1985. </year>
Reference-contexts: Then Z has the range 1 . . . 18, Z <ref> [1] </ref> = X [1], and Z [18] = Y [1]. But this solution relies on zero being the identity element of addition, and it does not generalize to operators without identity elements. <p> Then Z has the range 1 . . . 18, Z <ref> [1] </ref> = X [1], and Z [18] = Y [1]. But this solution relies on zero being the identity element of addition, and it does not generalize to operators without identity elements. <p> Then Z has the range 1 . . . 18, Z <ref> [1] </ref> = X [1], and Z [18] = Y [1]. But this solution relies on zero being the identity element of addition, and it does not generalize to operators without identity elements. <p> In Fortran 90, if Z is an array variable being assigned, it will have a predefined range (which must be conformable with X and Y ). So if Z has the range 5 . . . 21, then Z [5] = X <ref> [1] </ref> + Y [2]. In the functional language Sisal, on the other hand, the array value of X + Y will always have a range starting on 1, regardless of the ranges of X and Y . So in Sisal we would have Z [1] = X [1] + Y [2]. <p> 21, then Z [5] = X <ref> [1] </ref> + Y [2]. In the functional language Sisal, on the other hand, the array value of X + Y will always have a range starting on 1, regardless of the ranges of X and Y . So in Sisal we would have Z [1] = X [1] + Y [2]. Clearly the concept of conformance leaves some room for arbitrary language design decisions. Another problem with conformance-based semantics is that it relies on the concept of length (or shape for multidimensional arrays), which is specific for arrays. <p> [5] = X <ref> [1] </ref> + Y [2]. In the functional language Sisal, on the other hand, the array value of X + Y will always have a range starting on 1, regardless of the ranges of X and Y . So in Sisal we would have Z [1] = X [1] + Y [2]. Clearly the concept of conformance leaves some room for arbitrary language design decisions. Another problem with conformance-based semantics is that it relies on the concept of length (or shape for multidimensional arrays), which is specific for arrays. <p> The current implementation of Hampa is based on a standard dispatch on type evaluator of the kind described by Abelson & Sussman <ref> [1, chapter 4] </ref>.
Reference: [2] <author> John Backus. </author> <title> Can Programming Be Liberated from the von Neuman Style? A Functional Style and Its Algebra of Programs. </title> <journal> Comm. ACM, </journal> <volume> 21(8) </volume> <pages> 613-641, </pages> <month> August </month> <year> 1978. </year>
Reference-contexts: In Fortran 90, if Z is an array variable being assigned, it will have a predefined range (which must be conformable with X and Y ). So if Z has the range 5 . . . 21, then Z [5] = X [1] + Y <ref> [2] </ref>. In the functional language Sisal, on the other hand, the array value of X + Y will always have a range starting on 1, regardless of the ranges of X and Y . So in Sisal we would have Z [1] = X [1] + Y [2]. <p> [1] + Y <ref> [2] </ref>. In the functional language Sisal, on the other hand, the array value of X + Y will always have a range starting on 1, regardless of the ranges of X and Y . So in Sisal we would have Z [1] = X [1] + Y [2]. Clearly the concept of conformance leaves some room for arbitrary language design decisions. Another problem with conformance-based semantics is that it relies on the concept of length (or shape for multidimensional arrays), which is specific for arrays. <p> Also Haskell [19] can be brought into this category, due to its array comprehensions. An extension of Haskell, DPHaskell, has "PODs", lazy, possibly sparse arrays supporting parallel operations [16]. Both Backus' FP <ref> [2] </ref> and NESL [5] support nested sequences for parallel data. In this context it is also appropriate to 3 mention the Bird-Meertens formalism [4], an algebra for operations on lists which has been proposed as a basis for data parallel programming [30].
Reference: [3] <author> Jonas Barklund and Johan Bevemyr. </author> <title> Prolog with arrays and bounded quantifications. </title> <editor> In Andrei Voronkov, editor, </editor> <booktitle> Proc. 4th Intl. Conf. on Logic Programming and Automated Reasoning, Volume 698 of Lecture Notes in Comput. Sci., </booktitle> <pages> pages 28-39. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Closest to our own model are Crystal [7], Alpha [22, 28] and CM Lisp [32], which all model parallel data as functions over finite domains. Related is also the work on bounded quantification in Prolog <ref> [3] </ref>. 2 An Abstract Model of Data Parallelism The Hampa language builds on a previously developed semantical model for data parallelism [23, 14], where aggregate data are functions and can be operated on as such. Accessing an element, for instance, is simply function application.
Reference: [4] <author> Richard Bird. </author> <title> Constructive functional programming. </title> <editor> In M. Broy, editor, </editor> <booktitle> Mark-toberdorf International Summer school on Constructive Methods in Computer Science, NATO Advanced Science Institute Series. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1989. </year>
Reference-contexts: An extension of Haskell, DPHaskell, has "PODs", lazy, possibly sparse arrays supporting parallel operations [16]. Both Backus' FP [2] and NESL [5] support nested sequences for parallel data. In this context it is also appropriate to 3 mention the Bird-Meertens formalism <ref> [4] </ref>, an algebra for operations on lists which has been proposed as a basis for data parallel programming [30]. Closest to our own model are Crystal [7], Alpha [22, 28] and CM Lisp [32], which all model parallel data as functions over finite domains.
Reference: [5] <author> Guy E. Blelloch, Siddhartha Chatterjee, Jonathan C. Hardwick, Jay Sipelstein, and Marco Zagha. </author> <title> Implementation of a portable nested data-parallel language. </title> <booktitle> In Proceedings 4th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 102-111, </pages> <address> San Diego, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: In Fortran 90, if Z is an array variable being assigned, it will have a predefined range (which must be conformable with X and Y ). So if Z has the range 5 . . . 21, then Z <ref> [5] </ref> = X [1] + Y [2]. In the functional language Sisal, on the other hand, the array value of X + Y will always have a range starting on 1, regardless of the ranges of X and Y . <p> Also Haskell [19] can be brought into this category, due to its array comprehensions. An extension of Haskell, DPHaskell, has "PODs", lazy, possibly sparse arrays supporting parallel operations [16]. Both Backus' FP [2] and NESL <ref> [5] </ref> support nested sequences for parallel data. In this context it is also appropriate to 3 mention the Bird-Meertens formalism [4], an algebra for operations on lists which has been proposed as a basis for data parallel programming [30].
Reference: [6] <author> Walter S. Brainerd, Charles H. Goldberg, and Jeanne C. Adams. </author> <title> Programmer's Guide to FORTRAN 90. Programming Languages. </title> <publisher> McGraw-Hill, </publisher> <year> 1990. </year>
Reference-contexts: Examples of languages with this kind of syntax are Fortran 90 <ref> [6] </ref> and Sisal [10]. Both these languages use arrays, but this kind of syntax could well be used for operations on other kinds of data fields. Later versions of *Lisp [34], for instance, use it for the "pvar" data type.
Reference: [7] <author> Marina C. Chen, Young-Il Choo, and Jingke Li. </author> <title> Crystal: Theory and pragmatics of generating efficient parallel code. </title> <editor> In Boleslaw K. Szymanski, editor, </editor> <booktitle> Parallel Functional Languages and Compilers, chapter 7, </booktitle> <pages> pages 255-308. </pages> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: In this context it is also appropriate to 3 mention the Bird-Meertens formalism [4], an algebra for operations on lists which has been proposed as a basis for data parallel programming [30]. Closest to our own model are Crystal <ref> [7] </ref>, Alpha [22, 28] and CM Lisp [32], which all model parallel data as functions over finite domains.
Reference: [8] <author> William Clinger and Jonathan Rees (ed.). </author> <title> Revised 4 report on the algorithmic language scheme, </title> <year> 1991. </year>
Reference-contexts: Advanced request evaluators can also make use of them to derive restrictions for function-typed expressions whose restrictions are given implicitly by the arguments. 3 A Language that Implements the Model Hampa is a Lisp-based data parallel higher-order functional language with lazy semantics. Like the Lisp dialect Scheme <ref> [8] </ref>, Hampa is a statically scoped, higher order programming language, but unlike Scheme it has manifest types. It has a the simple types integer, real, boolean, pair types, function types, and it supports -abstractions and recursive definitions.
Reference: [9] <author> Kattamuri Ekanadham. </author> <title> A perspective on Id. </title> <editor> In Boleslaw K. Szymanski, editor, </editor> <booktitle> Parallel Functional Languages and Compilers, chapter 6, </booktitle> <pages> pages 197-253. </pages> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: Some examples are EPL, an equational language with recursive array definitions [25, 33], Sisal which has a rich set of array operations and is implemented efficiently on a number of vector- and parallel computers [10, 29], and Id <ref> [9] </ref>. Also Haskell [19] can be brought into this category, due to its array comprehensions. An extension of Haskell, DPHaskell, has "PODs", lazy, possibly sparse arrays supporting parallel operations [16]. Both Backus' FP [2] and NESL [5] support nested sequences for parallel data.
Reference: [10] <author> John T. Feo, David C. Cann, and Rodney R. Oldehoeft. </author> <title> A report on the Sisal language project. </title> <journal> J. Parallel Distrib. Comput., </journal> <volume> 10 </volume> <pages> 349-366, </pages> <year> 1990. </year>
Reference-contexts: Examples of languages with this kind of syntax are Fortran 90 [6] and Sisal <ref> [10] </ref>. Both these languages use arrays, but this kind of syntax could well be used for operations on other kinds of data fields. Later versions of *Lisp [34], for instance, use it for the "pvar" data type. <p> Some examples are EPL, an equational language with recursive array definitions [25, 33], Sisal which has a rich set of array operations and is implemented efficiently on a number of vector- and parallel computers <ref> [10, 29] </ref>, and Id [9]. Also Haskell [19] can be brought into this category, due to its array comprehensions. An extension of Haskell, DPHaskell, has "PODs", lazy, possibly sparse arrays supporting parallel operations [16]. Both Backus' FP [2] and NESL [5] support nested sequences for parallel data.
Reference: [11] <author> David Goldberg. </author> <title> What every computer scientist should know about floating-point arithmetic. </title> <journal> ACM Computing Surveys, </journal> <volume> 23(1) </volume> <pages> 5-48, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: This is extremely bad from a performance point of view, because it means that every little operation gets conditioned. However, there are alternatives. For IEEE floating point operations, the "non-signaling not a number" elements have the correct algebraic properties to represent ? <ref> [11] </ref>. Also, ? can be implemented in an interrupt-driven fashion. For flat data types, the return of ? as value of a subexpression forces the value of the entire expression to be ?.
Reference: [12] <author> George Gratzer. </author> <title> Universal Algebra. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1979. </year>
Reference-contexts: integer, will be seen as the function type () ! integer where () is the "empty type". 2 This can be interpreted as the set of functions from the empty set to the integers, which is in accordance with the habit in universal algebra to treat constants as nullary operators <ref> [12] </ref>. Now, any "scalar" type s in the signature of an operator will be changed to the polymorphic function type a ! s, where a is a type variable.
Reference: [13] <author> Nicholas Halbwachs, Yann-Eric Proy, and Pascal Raymond. </author> <title> Verification of linear hybrid systems by means of convex approximations. </title> <editor> In Baudouin Le Charlier, editor, </editor> <booktitle> Proc. International Symposium on Static Analysis, Vol. 864 of Lecture Notes in Comput. Sci., </booktitle> <pages> pages 223-237, </pages> <address> Namur, </address> <month> September </month> <year> 1994. </year> <note> Springer-Verlag. </note>
Reference-contexts: These approximations can be extremely crude. One interesting extension is to consider general convex polyhedra: there are representations, allowing fast implementations of intersection and convex hull of convex polyhedra, that could be used by a more sophisticated request function <ref> [13] </ref>. Another interesting extension would be the introduction of sparse data field representations in Hampa. Acknowledgments This work has been funded by the Department of Numerical Analysis and Computing Science, Royal Inst. of Tech. (Joacim Halen), and the Swedish Research Council for Engineering Sciences grant TFR 94-109.
Reference: [14] <author> Per Hammarlund and Bjorn Lisper. </author> <title> On the relation between functional and data parallel programming languages. </title> <booktitle> In Proc. Sixth Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 210-222. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: Many of these semantical problems can be alleviated if data parallelism is expressed in a suitable declarative programming paradigm. In <ref> [23, 14] </ref> a programming model has been developed with the aim to provide a clean semantical basis for data 1 In *Lisp, the answer is yes: scalar assignments within data parallel "masked environments" are always carried out regardless of the mask. 2 parallel constructs. <p> Related is also the work on bounded quantification in Prolog [3]. 2 An Abstract Model of Data Parallelism The Hampa language builds on a previously developed semantical model for data parallelism <ref> [23, 14] </ref>, where aggregate data are functions and can be operated on as such. Accessing an element, for instance, is simply function application. <p> a weaker form: if b (x) = false and b 2 (x) = true implies b 1 (x) 6= ? for all x, then if (b; f n b 1 ; g n b 2 ) = if (b; f; g) n b 1 _ b 2 : (5) See <ref> [15, 14] </ref>. These rules can be used by optimizing compilers.
Reference: [15] <author> Per Hammarlund and Bjorn Lisper. </author> <title> Purely functional data parallel programming. </title> <note> Submitted., 1995. 13 </note>
Reference-contexts: a weaker form: if b (x) = false and b 2 (x) = true implies b 1 (x) 6= ? for all x, then if (b; f n b 1 ; g n b 2 ) = if (b; f; g) n b 1 _ b 2 : (5) See <ref> [15, 14] </ref>. These rules can be used by optimizing compilers. <p> Another interesting possibility is to develop memo-functions which are not hyperstrict but rather access their arguments in the same way as the original function, in order to obtain the same strictness properties. For a discussion, see <ref> [15] </ref>. 5.2 Treatment of Soft Bottom (?) All the basic operators in Hampa must handle the "soft bottom" element ?. In the current version of Hampa this is implemented this in a straightforward way, by performing an explicit test before the actual computation, e.g. <p> This handling of ? is akin to "failure" in prolog. For non-flat data types, the situation is slightly more complicated, as if speculative execution is employed. For a discussion, see <ref> [15] </ref>. 6 Conclusions and Future Work We have described the syntax, semantics and implementation of Hampa, a lazy functional language where aggregate data, data fields, are seen as functions.
Reference: [16] <author> Jonathan M.D. Hill. </author> <title> The AIM is laziness in a data-parallel language. </title> <editor> In K. Hammond and J. T. O'Donnell, editors, </editor> <booktitle> Glasgow functional programming workshop. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Also Haskell [19] can be brought into this category, due to its array comprehensions. An extension of Haskell, DPHaskell, has "PODs", lazy, possibly sparse arrays supporting parallel operations <ref> [16] </ref>. Both Backus' FP [2] and NESL [5] support nested sequences for parallel data. In this context it is also appropriate to 3 mention the Bird-Meertens formalism [4], an algebra for operations on lists which has been proposed as a basis for data parallel programming [30].
Reference: [17] <author> W. Daniel Hillis and Guy L. Steele, Jr. </author> <title> Data parallel algorithms. </title> <journal> Comm. ACM, </journal> <volume> 29(12) </volume> <pages> 1170-1183, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: 1 Introduction Data parallelism <ref> [17] </ref> is a programming paradigm where operations are, at least conceptually, made in parallel over aggregate data. These aggregate data can be 1 arrays, possibly parallel, but also more unstructured collections of data, like ho-mogenous lists, trees, or other sparse data structures.
Reference: [18] <author> R. W. Hockney and C. R. Jesshope. </author> <title> Parallel Computers 2. </title> <editor> Adam Hilger, </editor> <year> 1988. </year>
Reference-contexts: Later versions of *Lisp [34], for instance, use it for the "pvar" data type. A possible problem is that the meaning of operations as above can be unclear: see, e.g, the discussion in <ref> [18, p. 394] </ref>. <p> Then Z has the range 1 . . . 18, Z [1] = X [1], and Z <ref> [18] </ref> = Y [1]. But this solution relies on zero being the identity element of addition, and it does not generalize to operators without identity elements.
Reference: [19] <author> Paul Hudak, Simon Peyton Jones, Philip Wadler, Brian Boutel, Jon Fairbairn, Joseph Fasel, Maria M. Guzman, Kevin Hammond, John Hughes, Thomas Johnsson, Dick Kieburtz, Rishiyur Nikhil, Will Partain, and John Peterson. </author> <title> Report on the programming language Haskell: A non-strict, purely functional language. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 27(5), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: Some examples are EPL, an equational language with recursive array definitions [25, 33], Sisal which has a rich set of array operations and is implemented efficiently on a number of vector- and parallel computers [10, 29], and Id [9]. Also Haskell <ref> [19] </ref> can be brought into this category, due to its array comprehensions. An extension of Haskell, DPHaskell, has "PODs", lazy, possibly sparse arrays supporting parallel operations [16]. Both Backus' FP [2] and NESL [5] support nested sequences for parallel data. <p> Explicit restriction could actually be expressed directly in Haskell: " x -&gt; case b x of True -&gt; f x - This is equivalent since the value of a case expression in Haskell where all alternatives fail to match is defined to be ? <ref> [19] </ref> (or, to be exact, ?). The above is sufficient for "ordinary" function evaluation, where a function f is applied to an argument x to yield the single value of f (x). But we also want to express the evaluation of aggregate data. <p> An important case is the conditional. But the first argument 3 The type variables with limited domain are semantically similar to Haskell's type classes <ref> [35, 19] </ref> and Geoffrey Smith's constrained type schemes [31]. 10 of the conditional is non-polymorphic: thus, the overloading can be resolved in the following way. In the type system of Hampa, if has the type (a ! boolean) fi b fi b ! b where a, b are type variables.
Reference: [20] <author> John Hughes. </author> <title> Lazy memo-functions. </title> <booktitle> In Proc. Second Int. Conf. on Functional Programming, Languages and Computer Architecture, </booktitle> <volume> volume 201, </volume> <pages> pages 129-146. </pages> <publisher> Springer Verlag, </publisher> <year> 1985. </year>
Reference-contexts: This speeds up future accesses to the same data field considerably. On the other hand, as was observed by Hughes <ref> [20] </ref>, a memoised function becomes hyperstrict. Thus, memoisation can change the semantics of functions in a lazy language.
Reference: [21] <author> John Hughes. </author> <title> Compile-time analysis of functional programs. </title> <editor> In David A. Turner, editor, </editor> <booktitle> Research Topics in Functional Programming, The UT Year of Programming Series, chapter 5, </booktitle> <pages> pages 117-153. </pages> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: Static analyses will be needed to guide this, however. Classical analyses for functional programs, such as strictness analysis <ref> [21] </ref> will definitely be useful, but one can also anticipate various analyses that are specific for the data field programming model. One such analysis, Extent Analysis, attempts to estimate the "extent" of a data field at compile-time [24].
Reference: [22] <author> Herve Le Verge, Christophe Mauras, and Patrice Quinton. </author> <title> A language-oriented approach to the design of systolic chips. </title> <journal> Journal of VLSI Signal Processing, </journal> <volume> 3 </volume> <pages> 173-182, </pages> <year> 1991. 1991. </year>
Reference-contexts: In this context it is also appropriate to 3 mention the Bird-Meertens formalism [4], an algebra for operations on lists which has been proposed as a basis for data parallel programming [30]. Closest to our own model are Crystal [7], Alpha <ref> [22, 28] </ref> and CM Lisp [32], which all model parallel data as functions over finite domains.
Reference: [23] <author> Bjorn Lisper. </author> <title> Data parallelism and functional programming. </title> <editor> In Guy-Renee Per-rin and Alain Darte, editors, </editor> <title> The Data Parallel Programming Model: Foundations, HPF Realization, </title> <journal> and Scientific Applications, </journal> <volume> Vol. </volume> <booktitle> 1132 of Lecture Notes in Comput. Sci., </booktitle> <pages> pages 220-251, </pages> <address> Les Menuires, France, March 1996. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Many of these semantical problems can be alleviated if data parallelism is expressed in a suitable declarative programming paradigm. In <ref> [23, 14] </ref> a programming model has been developed with the aim to provide a clean semantical basis for data 1 In *Lisp, the answer is yes: scalar assignments within data parallel "masked environments" are always carried out regardless of the mask. 2 parallel constructs. <p> Related is also the work on bounded quantification in Prolog [3]. 2 An Abstract Model of Data Parallelism The Hampa language builds on a previously developed semantical model for data parallelism <ref> [23, 14] </ref>, where aggregate data are functions and can be operated on as such. Accessing an element, for instance, is simply function application. <p> These situations are operationally quite different, since the latter can be detected in finite time. It is possible to define a more refined semantic domain where a total element "?", or "soft bottom", represents this case <ref> [23] </ref>. ? should then have, to the largest extent possible, the same algebraic properties as ?: for instance, if f is strict in some argument (f (. . . ; ?; . . .) = ?) then f (. . . ; ?; . . .) = ? should hold.
Reference: [24] <author> Bjorn Lisper and Jean-Francois Collard. </author> <title> Extent analysis of data fields. </title> <editor> In Bau-douin Le Charlier, editor, </editor> <booktitle> Proc. International Symposium on Static Analysis, Vol. 864 of Lecture Notes in Comput. Sci., </booktitle> <pages> pages 208-222, </pages> <address> Namur, Belgium, </address> <month> September </month> <year> 1994. </year> <note> Springer-Verlag. </note>
Reference-contexts: Classical analyses for functional programs, such as strictness analysis [21] will definitely be useful, but one can also anticipate various analyses that are specific for the data field programming model. One such analysis, Extent Analysis, attempts to estimate the "extent" of a data field at compile-time <ref> [24] </ref>. One application is to remove the sometimes costly runtime estimation of restricting predicate that is done when evaluating the request operation.
Reference: [25] <author> Bruce McKenney and Boleslaw Szymanski. </author> <title> Generating parallel code for SIMD machines. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1(1) </volume> <pages> 59-73, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Quite a few functional languages exist where this is done to some extent. Typically, these languages have a certain designated type for data aggregates with a number of predefined operations. Some examples are EPL, an equational language with recursive array definitions <ref> [25, 33] </ref>, Sisal which has a rich set of array operations and is implemented efficiently on a number of vector- and parallel computers [10, 29], and Id [9]. Also Haskell [19] can be brought into this category, due to its array comprehensions.
Reference: [26] <author> Patrice Quinton, Sanjay Rajopadhye, and Doran Wilde. </author> <title> Derivation of data parallel code from a functional program. </title> <booktitle> In 9th International Parallel Processing Symposium, </booktitle> <pages> pages 1-15, </pages> <year> 1995. </year>
Reference-contexts: This analysis can also sometimes be used to pre-allocate memory and distribute elements for recursively defined data fields, or to perform static scheduling of data field computations to generate efficient code as is done for the language Alpha <ref> [26, 27] </ref>. An important technique in the Hampa implementation is the view of basic types as functional types from the empty type. This facilitates the handling of overloaded scalar operations which are to be interpreted as pointwise extended.
Reference: [27] <author> Patrice Quinton, Sanjay Rajopadhye, and Doran Wilde. </author> <title> Deriving imperative code from functional programs. </title> <booktitle> In 7th Conference on Functional Programming Languages and Computer Architecture, </booktitle> <address> La Jolla, CA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: This analysis can also sometimes be used to pre-allocate memory and distribute elements for recursively defined data fields, or to perform static scheduling of data field computations to generate efficient code as is done for the language Alpha <ref> [26, 27] </ref>. An important technique in the Hampa implementation is the view of basic types as functional types from the empty type. This facilitates the handling of overloaded scalar operations which are to be interpreted as pointwise extended.
Reference: [28] <author> S. Rajopadhye and D. Wilde. </author> <title> The naive execution of affine recurrence equations. </title> <booktitle> International Conference on Application-Specific Array Processors, </booktitle> <month> Jul </month> <year> 1995. </year>
Reference-contexts: In this context it is also appropriate to 3 mention the Bird-Meertens formalism [4], an algebra for operations on lists which has been proposed as a basis for data parallel programming [30]. Closest to our own model are Crystal [7], Alpha <ref> [22, 28] </ref> and CM Lisp [32], which all model parallel data as functions over finite domains.
Reference: [29] <author> Stephen K. Skedzielewski. </author> <title> Sisal. </title> <editor> In Boleslaw K. Szymanski, editor, </editor> <booktitle> Parallel Functional Languages and Compilers, chapter 4, </booktitle> <pages> pages 105-157. </pages> <publisher> Addison-Wesley, </publisher> <year> 1991. </year> <month> 14 </month>
Reference-contexts: Some examples are EPL, an equational language with recursive array definitions [25, 33], Sisal which has a rich set of array operations and is implemented efficiently on a number of vector- and parallel computers <ref> [10, 29] </ref>, and Id [9]. Also Haskell [19] can be brought into this category, due to its array comprehensions. An extension of Haskell, DPHaskell, has "PODs", lazy, possibly sparse arrays supporting parallel operations [16]. Both Backus' FP [2] and NESL [5] support nested sequences for parallel data.
Reference: [30] <author> David B. Skillicorn. </author> <title> Architecture-independent parallel computation. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 38-50, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Both Backus' FP [2] and NESL [5] support nested sequences for parallel data. In this context it is also appropriate to 3 mention the Bird-Meertens formalism [4], an algebra for operations on lists which has been proposed as a basis for data parallel programming <ref> [30] </ref>. Closest to our own model are Crystal [7], Alpha [22, 28] and CM Lisp [32], which all model parallel data as functions over finite domains.
Reference: [31] <author> Geoffrey S. Smith. </author> <title> Principal type schemes for functional programs with overloading and subtyping. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 23 </volume> <pages> 197-226, </pages> <year> 1994. </year>
Reference-contexts: An important case is the conditional. But the first argument 3 The type variables with limited domain are semantically similar to Haskell's type classes [35, 19] and Geoffrey Smith's constrained type schemes <ref> [31] </ref>. 10 of the conditional is non-polymorphic: thus, the overloading can be resolved in the following way. In the type system of Hampa, if has the type (a ! boolean) fi b fi b ! b where a, b are type variables.
Reference: [32] <author> Guy L. Steele Jr. and W. Daniel Hillis. </author> <title> Connection Machine Lisp: Fine-Grained Parallel Symbolic Processing. </title> <type> Technical Report PL86-2, </type> <institution> Thinking Machine Corporation, Thinking Machines Corporation, </institution> <address> 245 First Street, Cambridge, Massachusetts 02142, </address> <month> May </month> <year> 1986. </year>
Reference-contexts: In this context it is also appropriate to 3 mention the Bird-Meertens formalism [4], an algebra for operations on lists which has been proposed as a basis for data parallel programming [30]. Closest to our own model are Crystal [7], Alpha [22, 28] and CM Lisp <ref> [32] </ref>, which all model parallel data as functions over finite domains.
Reference: [33] <author> Boleslaw K. Szymanski. </author> <title> EPL-parallel programming with recurrent equations. </title> <editor> In Boleslaw K. Szymanski, editor, </editor> <booktitle> Parallel Functional Languages and Compilers, chapter 3, </booktitle> <pages> pages 51-104. </pages> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: Quite a few functional languages exist where this is done to some extent. Typically, these languages have a certain designated type for data aggregates with a number of predefined operations. Some examples are EPL, an equational language with recursive array definitions <ref> [25, 33] </ref>, Sisal which has a rich set of array operations and is implemented efficiently on a number of vector- and parallel computers [10, 29], and Id [9]. Also Haskell [19] can be brought into this category, due to its array comprehensions.
Reference: [34] <institution> TMC, Thinking Machines Corporation, </institution> <address> 245 First Street, Cambridge, Mas-sachusetts 02142. </address> <booktitle> Connection Machine: Programming in *Lisp, </booktitle> <address> 6.1 edition, </address> <year> 1991. </year>
Reference-contexts: Examples of languages with this kind of syntax are Fortran 90 [6] and Sisal [10]. Both these languages use arrays, but this kind of syntax could well be used for operations on other kinds of data fields. Later versions of *Lisp <ref> [34] </ref>, for instance, use it for the "pvar" data type. A possible problem is that the meaning of operations as above can be unclear: see, e.g, the discussion in [18, p. 394].
Reference: [35] <author> Philip Wadler and Stephen Blott. </author> <title> How to make ad-hoc polymorphism less ad-hoc. </title> <booktitle> In Proc 16th ACM Symposium on Principles of Programming Languages, </booktitle> <address> Austin, Texas, </address> <pages> pages 60-76, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: An important case is the conditional. But the first argument 3 The type variables with limited domain are semantically similar to Haskell's type classes <ref> [35, 19] </ref> and Geoffrey Smith's constrained type schemes [31]. 10 of the conditional is non-polymorphic: thus, the overloading can be resolved in the following way. In the type system of Hampa, if has the type (a ! boolean) fi b fi b ! b where a, b are type variables. <p> However, the present type system of Hampa is quite rudimentary and we would like to combine pointwise extensibility with parametric polymorphism and sub-typing in its most general form, with full type inference. Here the concept of type classes seems as a very fruitful way to go <ref> [35] </ref>. In the present implementation the request operation approximates restrictions with hyper-rectangles. These approximations can be extremely crude.
Reference: [36] <author> J. Allan Yang and Young-il Choo. </author> <title> Data fields as parallel programs. </title> <booktitle> In Proceedings of the Second International Workshop on Array Structures, </booktitle> <address> Montreal, Canada, </address> <month> June/July </month> <year> 1992. </year> <month> 15 </month>
Reference-contexts: 1 Introduction Data parallelism [17] is a programming paradigm where operations are, at least conceptually, made in parallel over aggregate data. These aggregate data can be 1 arrays, possibly parallel, but also more unstructured collections of data, like ho-mogenous lists, trees, or other sparse data structures. Following Yang and Choo <ref> [36] </ref>, we use the term "data field" to refer to data aggregates in general.
References-found: 36

