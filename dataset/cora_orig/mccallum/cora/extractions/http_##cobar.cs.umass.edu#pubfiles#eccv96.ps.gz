URL: http://cobar.cs.umass.edu/pubfiles/eccv96.ps.gz
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: fravela, manmathag@cs.umass.edu  
Title: Image Retrieval Using Scale-Space Matching  
Author: S. Ravela R. Manmatha E. M. Riseman 
Date: August 6, 1996  
Address: Amherst  
Affiliation: Computer Vision Research Laboratory Center for Intelligent Information Retrieval University of Massachusetts at  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Myron Flickner, Harpreet Sawhney, Wayne Niblack, Jonathan Ashley, Qian Huang, Byron Dom, Monika Gorkani, Jim Hafner, Denis Lee, Dragutin Petkovix, David Steele, and Peter Yanker: </author> <title> Query By Image and Video Content: The QBIC System. </title> <journal> IEEE Computer Magazine, Septem-ber 1995, pp.23-30. </journal> <volume> 13 </volume>
Reference-contexts: The variability and richness of interpretation is quite enormous as is the human effort required for annotation. To be effective an image retrieval system should exploit image attributes such as color distribution, motion, shape <ref> [1] </ref>, structure, texture or perhaps user drawn sketches or even abstract token sets (such as points, lines etc.). Image retrieval can be viewed as an ordering of match scores that are obtained by searching through the database. <p> The user ultimately views and evaluates the results, allowing for tolerance to the few incorrect retrieval instances. 1 The retrieved images for this case are shown in Figure 3. 3 2 Related Work A number of researchers have investigated the use of shape for retrieval <ref> [1, 9, 10] </ref>. However, unlike the technique presented in this paper, these methods all require prior segmentation of the object using knowledge of the contour or binary shape of the object.
Reference: [2] <author> Gosta H. Granlund, and Hans Knutsson: </author> <title> Signal Processing in Computer Vision. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> 1995, ISBN 0-7923-9530-1, Dor-drecht, The Netherlands. </address>
Reference: [3] <author> Venkat N. Gudivada, and Vijay V. Raghavan: </author> <title> Content-Based Image Retrieval Systems. </title> <journal> IEEE Computer Magazine, </journal> <month> September </month> <year> 1995, </year> <month> pp.18-21. </month>
Reference-contexts: The application potential is enormous; ranging from database management in museums and medicine, architectural and interior design, image archiving, to constructing multi-media documents or presentations <ref> [3] </ref>. Simple image retrieval solutions have been proposed, one of which is to annotate images with text and then use a traditional text-based retrieval engine. While this solution is fast, it cannot however be effective over large collections of complex images.
Reference: [4] <author> P. J. B. Hancock, R. J. Bradley and L. S. Smith: </author> <title> The Principal Components of Natural Images. Network, </title> <booktitle> 1992, </booktitle> <volume> 3 </volume> <pages> 61-70. </pages>
Reference-contexts: It has been argued by Koenderink and van Doorn [5] and others that the structure of an image may be represented using Gaussian derivatives. Hancock et al <ref> [4] </ref> have shown that the principal components of a set of images containing natural structures may be modeled as the outputs of a Gaussian and its derivatives at several scales. That is, there is a natural decomposition of an image into Gaussian derivatives at several scales.
Reference: [5] <author> J. J. Koenderink, and A. J. van Doorn: </author> <title> Representation of Local Geometry in the Visual System. </title> <journal> Biological Cybernetics, 1987, </journal> <volume> vol. 55, </volume> <pages> pp. 367-375. </pages>
Reference-contexts: However, unlike the technique presented in this paper, these methods all require prior segmentation of the object using knowledge of the contour or binary shape of the object. It has been argued by Koenderink and van Doorn <ref> [5] </ref> and others that the structure of an image may be represented using Gaussian derivatives. Hancock et al [4] have shown that the principal components of a set of images containing natural structures may be modeled as the outputs of a Gaussian and its derivatives at several scales.
Reference: [6] <author> Tony Lindeberg: </author> <title> Scale-Space Theory in Computer Vision. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> 1994, ISBN 0-7923-9418-6 , Dordrecht, The Nether-lands. </address>
Reference-contexts: In particular a vector representation (VR) of an image is obtained by associating each pixel with a vector of responses to Gaussian derivative filters of several different orders. To retrieve similar looking images under varying scale a representation over the scale parameter is required and scale-space representations <ref> [6] </ref> are a natural choice. Lists of VRs generated using banks of Gaussian derivative filters at several different scales form a scale-space representation [6] of the object. A match score for any pair of images is obtained by correlating their scale-space vector representations. <p> To retrieve similar looking images under varying scale a representation over the scale parameter is required and scale-space representations <ref> [6] </ref> are a natural choice. Lists of VRs generated using banks of Gaussian derivative filters at several different scales form a scale-space representation [6] of the object. A match score for any pair of images is obtained by correlating their scale-space vector representations. Thus, the entire process of retrieval can be viewed as the following three-step process. <p> After the query is matched with each of the image VRs, the location in the image which has the best correlation score is returned. It is instructive to note that VR lists over scale are scale-space representations in the sense described by Lindeberg <ref> [6] </ref>. By smoothing an image with Gaussians at several different scales Lindeberg generates a scale-space representation. While VR lists are scale-space representations, however, they differ from Lindeberg's approach in two fundamental ways. <p> This is the reason warping is required during VR matching across scales. VR lists are proper scale-space representations unlike pyramidal representations <ref> [6, 12] </ref> 8 5 Constructing Query Images The query construction process begins with the user marking salient regions on an object. VRs generated at several scales within these regions are matched with the database in accordance with the description in Section 4. Unselected regions are not used in matching.
Reference: [7] <author> R. Manmatha: </author> <title> Measuring Affine Transformations Using Gaussian Filters. </title> <booktitle> Proc. European Conference on Computer Vision, 1994, </booktitle> <volume> vol II, </volume> <pages> pp. 159-164. </pages>
Reference-contexts: In particular consider two corresponding points p 0 and p 1 and assume the image is Gaussian filtered at p 0 . Then it can be shown that <ref> [7] </ref>, Z Z In other words, the output of I 0 filtered with a Gaussian of scale at p 0 is equal to the output of I 1 filtered with a Gaussian of scale s i.e. the Gaussian has to be stretched in the same manner as the image if the <p> This is not a surprising result if the output of a Gaussian filter is viewed as a Gaussian weighted average of the intensity. A more detailed derivation of this result is provided in <ref> [7] </ref>. The derivation above does not use an explicit value of the scale change s. Thus, equation 4 is valid for any scale change s.
Reference: [8] <author> R. Manmatha and J. Oliensis: </author> <title> Measuring Affine Transform I, Scale and Rotation. </title> <booktitle> Proc. DARPA IUW, </booktitle> <year> 1993, </year> <pages> pp. 449-458, </pages> <address> Washington D.C. </address>
Reference-contexts: The form of equation 4 resembles a convolution and in fact it may be rewritten as a convolution I 0 (r) ? G (:; ) = I 1 (sr) ? G (:; s) (5) Similarly, filtering with the first and second derivatives of a Gaussian gives <ref> [8] </ref> I 0 ? G (:; ) = I 1 ? G (:; s) (6) I 0 ? G " (:; ) = I 1 ? G " (:; s) (7) where the normalized first derivative of a Gaussian is given by G 0 (r; s) = s dG (r; s)=dr
Reference: [9] <author> Rajiv Mehrotra and James E. Gary: </author> <booktitle> Similar-Shape Retrieval In Shape Data Management.IEEE Computer Magazine, </booktitle> <month> September </month> <year> 1995, </year> <pages> pp. 57-62. </pages>
Reference-contexts: The user ultimately views and evaluates the results, allowing for tolerance to the few incorrect retrieval instances. 1 The retrieved images for this case are shown in Figure 3. 3 2 Related Work A number of researchers have investigated the use of shape for retrieval <ref> [1, 9, 10] </ref>. However, unlike the technique presented in this paper, these methods all require prior segmentation of the object using knowledge of the contour or binary shape of the object.
Reference: [10] <author> A. Pentland, R. W. Picard, and S. Sclaroff: Photobook: </author> <title> Tools for Content-Based Manipulation of Databases. Proc. Storage and Retrieval for Image and Video Databases II, </title> <booktitle> 1994, Vol.2, 185, SPIE, </booktitle> <pages> pp. 34-47, </pages> <address> Bellingham, Wash. </address>
Reference-contexts: The user ultimately views and evaluates the results, allowing for tolerance to the few incorrect retrieval instances. 1 The retrieved images for this case are shown in Figure 3. 3 2 Related Work A number of researchers have investigated the use of shape for retrieval <ref> [1, 9, 10] </ref>. However, unlike the technique presented in this paper, these methods all require prior segmentation of the object using knowledge of the contour or binary shape of the object.
Reference: [11] <author> R. Rao, and D. Ballard: </author> <title> Object Indexing Using an Iconic Sparse Distributed Memory. </title> <booktitle> Proc. International Conference on Computer Vision, </booktitle> <year> 1995, </year> <pages> pp. 24-31. </pages>
Reference-contexts: Similar results in terms of out-of-plane rotations were reported by <ref> [11] </ref>. 4 Matching Across Scales The database contains many objects imaged at several different scales. For example, the database used in our experiments has several diesel locomotives. The actual image size of these locomotives depends on the distance from which they are imaged and shows considerable variability in the database.
Reference: [12] <author> S. Ravela, R. Manmatha and E. M. Riseman: </author> <title> Retrieval from Image Databases Using Scale-Space Matching. </title> <type> Technical Report UM-CS-95-104, </type> <institution> 1995, Dept. of Computer Science, </institution> <address> Amherst, MA 01003. </address> <month> 14 </month>
Reference-contexts: That is, there is a natural decomposition of an image into Gaussian derivatives at several scales. Gaussians and their derivatives have, therefore, been successfully used for matching images of the same object under different viewpoints (see <ref> [12] </ref> for references). This paper is an extension to matching "similar" objects using Gaussian derivatives. 3 Matching Vector Representations The key processing involves obtaining and matching vector-representations of a sample gray level image patch S and a candidate image C. <p> I xx ,I xy and I yy are the appropriate second derivative responses. The choice of first and second Gaussian derivatives is discussed in <ref> [12] </ref>. <p> The mean C M is in this case computed at (m,n) over a neighborhood in C (the neighborhood is the same size as S). Vector correlation performs well under small view variations. It is observed in <ref> [12] </ref> that typically for the experiments carried out with this method, in-plane rotations of up to 20 o , out-of plane rotation of up to 30 0 and scale changes of less than 1:2 can be tolerated. <p> This is the reason warping is required during VR matching across scales. VR lists are proper scale-space representations unlike pyramidal representations <ref> [6, 12] </ref> 8 5 Constructing Query Images The query construction process begins with the user marking salient regions on an object. VRs generated at several scales within these regions are matched with the database in accordance with the description in Section 4. Unselected regions are not used in matching. <p> Further, there are no constraints imposed on the selection of regions and the regions need not overlap. Careful design of a query is important. It is interesting to note that marking the entire object does not work very well (see <ref> [12] </ref> for examples). Marking extremely small regions has also not worked with this database. There are too many coincidental structures that can lead to poor retrieval. Many of these problems are, however, simplified by having the user interact extensively with the system. <p> This performance compares very well with typical text retrieval systems 2 . To the best of our knowledge other image retrieval systems either need prior segmentation or work on restricted domains. Therefore, accurate comparisons cannot be made. Several experiments were carried out with the database <ref> [12] </ref>. The results of the experiments carried out with a car query, a diesel query and a steam query are presented in table 6. The number of retrieved images in intervals of ten is charted in Table 6. <p> Due to space limitations only the results of the Car retrieval are displayed (Figure 3) and analyzed in detail (for the others see <ref> [12] </ref>). The car image used for retrieval is shown in the top left picture of Figure 3. The objective is to 'obtain all similar cars to this picture'. Towards this end a query was marked by the user, highlighting the wheels, side view-mirror and mid section.
References-found: 12

