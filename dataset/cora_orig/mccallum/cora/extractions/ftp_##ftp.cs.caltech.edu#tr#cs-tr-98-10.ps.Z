URL: ftp://ftp.cs.caltech.edu/tr/cs-tr-98-10.ps.Z
Refering-URL: ftp://ftp.cs.caltech.edu/tr/INDEX.html
Root-URL: http://www.cs.caltech.edu
Title: Analysis of Scalable Algorithms for Dynamic Load Balancing and Mapping with Application to Photo-realistic Rendering  
Author: Alan Heirich 
Degree: Thesis by  In Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy  
Date: 1998 (Submitted May 1997)  
Address: Pasadena, California  
Affiliation: California Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Akeley, K. </author> <title> (Reality engine) graphics. </title> <booktitle> Proceedings of SIGGRAPH (1993) pp. </booktitle> <pages> 109-116. </pages>
Reference-contexts: The simplicity of these approaches makes it possible to implement them in VLSI. This is the basis of real-time implementations of the graphics pipeline that are becoming pervasive in personal computers and workstations <ref> [1] </ref>. This approach only allows light to reflect once between the emitter and the camera, and it ignores the fact that objects can cast shadows on each other. The images produced by this approach lack realism but they are fast.
Reference: [2] <author> Amdahl, G. </author> <title> Validity of the single processor approach to achieving large scale computing capabilities. </title> <booktitle> Proceedings AFIPS Conference, </booktitle> <volume> vol. </volume> <pages> 30 (1967) pp. 483-485. </pages>
Reference-contexts: In order to circumvent this error a master-slave termination mechanism was implemented as described in algorithm 3. 4 The Amdahl fraction is the portion of a computation that cannot be sped up through parallelism. It is the ultimate limiter of scaling for any concurrent algorithm <ref> [2] </ref>. 50 This study was repeated on a cluster of inexpensive Intel workstations connected by a fast ethernet switch, as reported in table 4.4. All of the rendering times were slightly better than on the SP2.
Reference: [3] <author> Arvo, J. & Kirk, D. </author> <title> Particle transport and image synthesis. </title> <journal> Computer Graphics, </journal> <volume> vol. </volume> <pages> 24 (1990) pp. 63-66. </pages>
Reference-contexts: For the purposes of photo-realism it is important to ensure that these strategies do not introduce bias into the result, as is the case with many common methods of antialiasing and path termination strategies <ref> [3, 37] </ref>. One reliable strategy is to explicitly sample the surfaces of the light sources, and we have done so in this implementation. Another reliable strategy is to model different surface properties independently, in ways that are unbiased, and then to combine samples from the different properties [61].
Reference: [4] <author> Badouel, D. & Priol, T. </author> <title> An efficient parallel ray-tracing scheme for highly parallel architectures. </title> <booktitle> Proceedings of the Fifth Eurographics Workshop on Graphics Hardware (1989). </booktitle>
Reference-contexts: The best of these strategies, "scattering", will be used to initialize the experiment. In ray tracing it is useful to begin a computation with an initially balanced workload. A number of strategies have been explored for achieving this initial balance <ref> [4, 6, 11, 16, 38, 48, 51, 53, 68] </ref>. Among the more successful strategies has been the use of a random initial mapping [53]. The expected behavior of this approach can be predicted from the 43 central limit theorem.
Reference: [5] <author> Barnard, S.T. & Simon, H. </author> <title> A parallel implementation of multi-level recursive spectral bisection for application to adaptive unstructured meshes. </title> <booktitle> In Proceedings of the 7 th SIAM Conference on Parallel Processing for Scientific Computing (1995) pp. </booktitle> <pages> 627-632. </pages>
Reference-contexts: The general problem can be treated by any number of graph partitioning algorithms. Advocates of heuristic partitioners claim that they produce good solutions at low cost [35, 36, 54]. A competing approach, recursive spectral bisection, uses spectral properties of the graph to compute minimal bisectors <ref> [5, 50, 57] </ref>. Having a minimal bisector at each step does not guarantee that the recursive process will yield a minimal partition of the graph, and it is a matter of debate whether spectral bisection yields better results than the heuristic approaches [35]. <p> One thing that is not in dispute is that spectral bisection is more expensive than other methods <ref> [5, 35] </ref>. Spectral bisection finds a minimal bisector by computing the Fiedler vector of the graph, and then uses the elements of the Fiedler vector to assign graph vertices to one subgraph or the other. <p> Recursive spectral bisection, in particular, is too expensive to use routinely to remap an application <ref> [5] </ref>. All of these methods might be described as "all or nothing": they require that all of the computers participating in a computation stop and synchronously compute a new mapping. This requirement is clearly impractical for envi 15 complete eigenvalue spectrum. Right, two representative eigenvectors.
Reference: [6] <author> Barrett, </author> <title> M.L. A load balancing experiment for parallel ray-tracing. </title> <booktitle> Proceedings of Aus-graph (1990) pp. </booktitle> <pages> 145-155. </pages>
Reference-contexts: The best of these strategies, "scattering", will be used to initialize the experiment. In ray tracing it is useful to begin a computation with an initially balanced workload. A number of strategies have been explored for achieving this initial balance <ref> [4, 6, 11, 16, 38, 48, 51, 53, 68] </ref>. Among the more successful strategies has been the use of a random initial mapping [53]. The expected behavior of this approach can be predicted from the 43 central limit theorem.
Reference: [7] <author> Boillat, </author> <title> J.E. Load balancing and Poisson equation in a graph. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> vol. </volume> <month> 2 </month> <year> (1990) </year> <month> 289-313. </month>
Reference-contexts: A few of them rely on the theory of the iterative solution of linear systems of equations in order to prove convergence properties of their algorithms [65, 66, 67]. Still others derive 16 their algorithms from models of differential equations <ref> [7, 12, 23, 27] </ref>. This author proposed a load balancing algorithm based on the heat equation u t = Kr 2 u [27]. The algorithm used an implicit numerical integration scheme to ensure numerical stability for very large time steps.
Reference: [8] <author> Boillat, J.E., Bruge, F. & Kropf, P.G. </author> <title> A dynamic load balancing algorithm for molecular dynamics simulations on multiprocessor systems. </title> <journal> Journal of Computational Physics, </journal> <volume> vol. </volume> <pages> 96 (1991) pp. 1-14. </pages>
Reference: [9] <author> Bokhari, S. </author> <title> Assignment Problems in Parallel and Distributed Computing (Kluwer, </title> <address> Boston, </address> <year> 1987). </year>
Reference-contexts: This is one of the first algorithms ever proposed for the dynamic mapping problem on general interconnection topologies. The local nature of the algorithm ensures that it will produce better solutions than random placement algorithms <ref> [9] </ref>. The similarity of algorithms 1 and 4 serves to both unify and highlight the differences between the problems of load balancing and mapping. 6 Chapter 2 Dynamic Load Balancing The load balancing problem is intrinsic to any distributed computation. <p> The problem of placing the processes is combinatorial, and is an instance of the NP-complete quadratic assignment problem <ref> [9] </ref>. This is the essence of the mapping problem, which will be discussed in a later chapter of this thesis. Many existing proposals for solving the load balancing problem can be distinguished by how explicitly they treat this consideration. <p> This is convenient because, while there are many known algorithms for static mapping, very little has been written about the dynamic problem. One of the only such proposals uses random placement <ref> [9] </ref>. Such an approach clearly violates the locality constraint of problem 2 and therefore can't provide an optimal solution. 5.1 The mapping problem The setting for the mapping problem is the same as for load balancing. A set of n computers runs a set of concurrent processes between two barriers. <p> There are number of problems which are known to be similar to these: circuit partitioning and layout, network capacity planning, and sparse matrix reordering, to name just a few <ref> [9, 52] </ref>. This thesis began by mentioning recursive spectral bisection (RSB) and discussing properties of the Laplacian matrix of a graph. This construction method has been used for the same two problems that are solved by RSB, namely mapping and load balancing.
Reference: [10] <author> Bruge, F. & Fornili, </author> <title> S.L. A distributed dynamic load balancer and it's implementation on multi-transputer systems for molecular dynamics simulation. </title> <journal> Computer Physics Communications, </journal> <volume> vol. </volume> <pages> 60 (1990) pp. 39-45. 71 </pages>
Reference: [11] <author> Caspary, E. & Scherson, </author> <title> I.D. A self-balanced parallel ray-tracing algorithm. </title> <booktitle> Proceedings of the International Conference on Parallel Processing for Computer Vision and Display (1988). </booktitle>
Reference-contexts: The best of these strategies, "scattering", will be used to initialize the experiment. In ray tracing it is useful to begin a computation with an initially balanced workload. A number of strategies have been explored for achieving this initial balance <ref> [4, 6, 11, 16, 38, 48, 51, 53, 68] </ref>. Among the more successful strategies has been the use of a random initial mapping [53]. The expected behavior of this approach can be predicted from the 43 central limit theorem.
Reference: [12] <author> Conley, A.J. </author> <title> Using a transfer function to describe the load balancing problem. </title> <type> Technical report ANL-93/40, </type> <institution> Argonne National Laboratory (1993). </institution>
Reference-contexts: A few of them rely on the theory of the iterative solution of linear systems of equations in order to prove convergence properties of their algorithms [65, 66, 67]. Still others derive 16 their algorithms from models of differential equations <ref> [7, 12, 23, 27] </ref>. This author proposed a load balancing algorithm based on the heat equation u t = Kr 2 u [27]. The algorithm used an implicit numerical integration scheme to ensure numerical stability for very large time steps.
Reference: [13] <author> Cybenko, G. </author> <title> Dynamic load balancing for distributed memory multiprocessors. </title> <journal> The Journal of Parallel and Distributed Computing, </journal> <volume> vol. </volume> <pages> 7 (1989) pp. 279-301. </pages>
Reference-contexts: Unfortunately these methods have a weakness that recursive bisection methods don't have: because these are local methods, it is more difficult to address the mapping problem. The first formal proposal in this class was due to Cybenko <ref> [13] </ref>. Cybenko's proposal considers the load balancing operation as a matrix-vector iteration in which computers are represented by a vector of workloads. Necessary conditions are formulated for convergence to equilibrium of the matrix-vector iteration.
Reference: [14] <author> Delany, H.C. </author> <title> Ray tracing on the Connection Machine. </title> <booktitle> Proceedings of SIGGRAPH (1988) pp. </booktitle> <pages> 659-664. </pages>
Reference-contexts: One reason for this is that solution algorithms can become unstable if the grid changes dramatically, and therefore it is important to refine a grid gradually. 2.2 Computer graphics Computer graphics is a rapidly developing subject that is readily amenable to parallel implementation <ref> [14] </ref>. This thesis will be concerned with image synthesis, the problem of computing a two dimensional image from a three dimensional geometric model. <p> For all of the above reasons we conclude that these predictions apply to a wide range of images and ray tracing algorithms. Many static load balancing strategies partition the image plane among a set of computers and then render the different portions of the image concurrently <ref> [14, 16, 21, 51, 53, 68] </ref>. Naive strategies that partition contiguous segments of the image fare poorly [21]. These strategies suffer from the effects of locality in the image which can lead to wide variations in workload for different computers.
Reference: [15] <author> Fletcher, C.A.J. </author> <title> Computational Techniques for Fluid Dynamics (Springer, </title> <address> New York, </address> <year> 1991). </year>
Reference-contexts: For example, Computational Fluid Dynamics (CFD) applications solve Navier-Stokes or Eu-ler equations of fluid mechanics, discretized according to finite-difference or finite-element methods <ref> [15] </ref>. Solutions to these equations are most often described by fields of velocity vectors, pressure, and sometimes temperature, organized into grids of two or three spatial dimensions. Automobile designers use CFD to simulate the cabin acoustics and ventilation inside a passenger compartment under various operating conditions.
Reference: [16] <author> Green, S.A. & Paddon, </author> <title> D.J. Exploiting coherence for multiprocessor ray-tracing. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> vol. </volume> <pages> 9 (1989) pp. 12-26. </pages>
Reference-contexts: The best of these strategies, "scattering", will be used to initialize the experiment. In ray tracing it is useful to begin a computation with an initially balanced workload. A number of strategies have been explored for achieving this initial balance <ref> [4, 6, 11, 16, 38, 48, 51, 53, 68] </ref>. Among the more successful strategies has been the use of a random initial mapping [53]. The expected behavior of this approach can be predicted from the 43 central limit theorem. <p> For all of the above reasons we conclude that these predictions apply to a wide range of images and ray tracing algorithms. Many static load balancing strategies partition the image plane among a set of computers and then render the different portions of the image concurrently <ref> [14, 16, 21, 51, 53, 68] </ref>. Naive strategies that partition contiguous segments of the image fare poorly [21]. These strategies suffer from the effects of locality in the image which can lead to wide variations in workload for different computers.
Reference: [17] <author> Golub, G. H. & Van Loan, C. F. </author> <title> Matrix Computations (Johns Hopkins University Press, </title> <address> Baltimore, </address> <year> 1989). </year>
Reference-contexts: The role of the Fiedler vector in computing minimal graph bisectors is well established [18, 44]. Spectral bisection typically computes the Fielder vector by using Lanczos iteration, but any other algorithm for computing eigensystems of symmetric matrices could be used, such as a Householder-QR sequence <ref> [17] </ref>. <p> The first objective can accomplished in a scalable way. Solutions of the Laplace equation r 2 u = 0 are equilibria when boundary conditions are constant. The standard iterations (Jacobi, Gauss-Seidel, SOR) <ref> [17] </ref> are well-studied algorithms for solving certain classes of systems of linear equations. Linear systems of the form A~u = ~ b can be solved by the standard iterations if the matrix A is diagonally dominant. <p> Some comments about RSB are in order to place these algorithms in perspective. RSB is very expensive since it requires solving an eigenvalue problem many times, once for each bisector. This is normally done by Lanczos iteration <ref> [17] </ref> which can be implemented in a distributed way.
Reference: [18] <author> Hall, K. </author> <title> An r-dimensional quadratic placement algorithm. </title> <journal> Management Science, </journal> <volume> vol. 17, no. </volume> <pages> 3 (1970) pp. 219-229. </pages>
Reference-contexts: The matrix of coefficients that results from this discretization is called the Laplacian matrix of the graph. The Fiedler vector is the eigenvector of this Laplacian matrix corresponding to the smallest non-zero eigenvalue. The role of the Fiedler vector in computing minimal graph bisectors is well established <ref> [18, 44] </ref>. Spectral bisection typically computes the Fielder vector by using Lanczos iteration, but any other algorithm for computing eigensystems of symmetric matrices could be used, such as a Householder-QR sequence [17].
Reference: [19] <author> Hanrahan, P., Salzman, D. & Aupperle, L. </author> <title> A rapid hierarchical radiosity algorithm. </title> <booktitle> Proceedings of SIGGRAPH (1991) pp. </booktitle> <pages> 197-206. </pages>
Reference-contexts: Hierar chical radiosity methods have been developed to reduce this O complexity to O (n) by representing the surface interactions at multiple levels of detail <ref> [19, 58] </ref>. These algorithms are effective in reducing the complexity of the computation but it is very difficult to assess the error that is introduced into the solution as a result of the geometric simplifications.
Reference: [20] <author> Heckbert, P. </author> <title> Radiosity in flatland. </title> <booktitle> Proceedings of Eurographics'92, </booktitle> <volume> vol. </volume> <pages> 11 (1992) pp. 181-192. </pages>
Reference-contexts: Finite element and Monte Carlo methods, long staples of numerical analysis, have become powerful tools for solving global illumination <ref> [20, 24, 56] </ref>. Other image synthesis algorithms that have been developed specifically for global illumination include ray tracing, and radiosity methods. Ray tracing algorithms simulate individual photon paths through space and thereby compute reflections very accurately [63]. <p> Radios-ity algorithms ignore the effects of individual paths in favor of computing the total transfer of energy between objects with purely diffuse, omni-directional surface reflection [55]. Radios-ity computations are equivalent to finite element discretizations of the integral equations of light transport <ref> [20] </ref>. These equations are usually known as the rendering or radiance equations [33] but they can be formulated in a number of ways including formulations in terms of radiance, spectral radiance and transport intensity.
Reference: [21] <author> Heirich, A. & Arvo, J. </author> <title> A competitive analysis of load balancing strategies for parallel ray tracing. </title> <journal> The Journal of Supercomputing, </journal> <volume> vol. 12, no. </volume> <pages> 1 & 2 (1998) pp. 57-68. </pages>
Reference-contexts: In general the problem becomes more difficult with increasing numbers of computers. These results have been reported in publications <ref> [21, 22, 25] </ref>. . . . . . . . . . . . . 49 4.3 Results of an initial study on the SP2. In all of these runs the naive strategy was used for the initial mapping followed by algorithm 1. <p> For all of the above reasons we conclude that these predictions apply to a wide range of images and ray tracing algorithms. Many static load balancing strategies partition the image plane among a set of computers and then render the different portions of the image concurrently <ref> [14, 16, 21, 51, 53, 68] </ref>. Naive strategies that partition contiguous segments of the image fare poorly [21]. These strategies suffer from the effects of locality in the image which can lead to wide variations in workload for different computers. <p> Many static load balancing strategies partition the image plane among a set of computers and then render the different portions of the image concurrently [14, 16, 21, 51, 53, 68]. Naive strategies that partition contiguous segments of the image fare poorly <ref> [21] </ref>. These strategies suffer from the effects of locality in the image which can lead to wide variations in workload for different computers. A more effective strategy assigns pixels pseudo-randomly to computers in an attempt to obtain a balanced workload. <p> In general the problem becomes more difficult with increasing numbers of computers. These results have been reported in publications <ref> [21, 22, 25] </ref>. of the soda shop interior. In all cases the naive decomposition produced unacceptably high values of *, as high as 2.22 for the bath image on 32 computers.
Reference: [22] <author> Heirich, A. & Arvo, J. </author> <title> Parallel Radiometric Image Synthesis. </title> <booktitle> The International Journal of Advances in Engineering Software (to appear, 1998). Previously appeared in Proceedings of the Fourth National Symposium on Large Scale Analysis and Design on High-Performance Computers and Workstations, </booktitle> <address> Williamsburg, VA (October 1997). </address> <month> 72 </month>
Reference-contexts: In general the problem becomes more difficult with increasing numbers of computers. These results have been reported in publications <ref> [21, 22, 25] </ref>. . . . . . . . . . . . . 49 4.3 Results of an initial study on the SP2. In all of these runs the naive strategy was used for the initial mapping followed by algorithm 1. <p> In general the problem becomes more difficult with increasing numbers of computers. These results have been reported in publications <ref> [21, 22, 25] </ref>. of the soda shop interior. In all cases the naive decomposition produced unacceptably high values of *, as high as 2.22 for the bath image on 32 computers.
Reference: [23] <author> Heirich, A. </author> <title> A scalable diffusion algorithm for dynamic mapping and load balancing on networks of arbitrary topology. </title> <journal> The International Journal of Foundations of Computer Science, </journal> <volume> vol. 8, no. </volume> <pages> 3 (1997) pp. 329-346. </pages>
Reference-contexts: A few of them rely on the theory of the iterative solution of linear systems of equations in order to prove convergence properties of their algorithms [65, 66, 67]. Still others derive 16 their algorithms from models of differential equations <ref> [7, 12, 23, 27] </ref>. This author proposed a load balancing algorithm based on the heat equation u t = Kr 2 u [27]. The algorithm used an implicit numerical integration scheme to ensure numerical stability for very large time steps. <p> Related algorithms were derived from the Laplace equation and applied to both the load balancing and mapping problems <ref> [23] </ref>. This is one of the first proposed solutions to the dynamic mapping problem. It is these algorithms that are presented in this thesis. 2.5 A load balancing algorithm This section presents an algorithm to solve problems 1 and 2.
Reference: [24] <author> Heirich, A. & Arvo, J. </author> <title> Scalable Monte Carlo image synthesis. </title> <journal> Parallel Computing, </journal> <volume> vol. 23, no. </volume> <pages> 7 (1997) pp. 845-859. </pages>
Reference-contexts: This study revealed the existence of errors in the original distributed algorithm for termination detection. These errors showed up the runs on 128 and 256 computers, where they caused a slowdown rather than a speedup. These results have been re ported in publications <ref> [24, 26] </ref>. . . . . . . . . . . . . . . . . . . . . . . . . . 51 4.4 Rendering times on Intel cluster. These runs were computed with parameters identical to table 4.3 and are directly comparable. <p> These runs were computed with parameters identical to table 4.3 and are directly comparable. In every respect the performance was slightly better than on the SP2. These results have been reported in publications <ref> [24, 26] </ref>. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 xii 4.5 Time measured within algorithm 1, in milliseconds, and total elapsed time, in seconds, for six cases. <p> Finite element and Monte Carlo methods, long staples of numerical analysis, have become powerful tools for solving global illumination <ref> [20, 24, 56] </ref>. Other image synthesis algorithms that have been developed specifically for global illumination include ray tracing, and radiosity methods. Ray tracing algorithms simulate individual photon paths through space and thereby compute reflections very accurately [63]. <p> This study revealed the existence of errors in the original distributed algorithm for termination detection. These errors showed up the runs on 128 and 256 computers, where they caused a slowdown rather than a speedup. These results have been reported in publications <ref> [24, 26] </ref>. Office Glass Conference n T * T * T * 8 3:26 0.044 4:21 0.014 20:34 0.013 Table 4.4: Rendering times on Intel cluster. These runs were computed with parameters identical to table 4.3 and are directly comparable. <p> These runs were computed with parameters identical to table 4.3 and are directly comparable. In every respect the performance was slightly better than on the SP2. These results have been reported in publications <ref> [24, 26] </ref>.
Reference: [25] <author> Heirich, A. & Arvo, J. </author> <title> Parallel rendering with an Actor model. </title> <booktitle> Proceedings of Euro-graphics '97, Workshop on Programming Paradigms for Graphics, </booktitle> <address> Budapest, Hungary (September 1997). </address>
Reference-contexts: In general the problem becomes more difficult with increasing numbers of computers. These results have been reported in publications <ref> [21, 22, 25] </ref>. . . . . . . . . . . . . 49 4.3 Results of an initial study on the SP2. In all of these runs the naive strategy was used for the initial mapping followed by algorithm 1. <p> If the combined program does not scale then we can infer that algorithm 1, or some artifact of the implementation, is not scalable. A program that combines algorithms 1 and 2 was implemented using a prioritized message-driven scheme <ref> [25] </ref>. The program consisted of a set of logical processes connected through a set of communication channels. A large number of rendering processes were connected in a mesh arrangement that matched the grid of equation 3.2. <p> In general the problem becomes more difficult with increasing numbers of computers. These results have been reported in publications <ref> [21, 22, 25] </ref>. of the soda shop interior. In all cases the naive decomposition produced unacceptably high values of *, as high as 2.22 for the bath image on 32 computers.
Reference: [26] <author> Heirich, A. & Arvo, J. </author> <title> Scalable photo-realistic rendering of complex scenes. </title> <booktitle> Proceedings of the First Eurographics Workshop on Parallel Graphics and Visualization, </booktitle> <address> Bristol, England (September 1996). </address>
Reference-contexts: This study revealed the existence of errors in the original distributed algorithm for termination detection. These errors showed up the runs on 128 and 256 computers, where they caused a slowdown rather than a speedup. These results have been re ported in publications <ref> [24, 26] </ref>. . . . . . . . . . . . . . . . . . . . . . . . . . 51 4.4 Rendering times on Intel cluster. These runs were computed with parameters identical to table 4.3 and are directly comparable. <p> These runs were computed with parameters identical to table 4.3 and are directly comparable. In every respect the performance was slightly better than on the SP2. These results have been reported in publications <ref> [24, 26] </ref>. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 xii 4.5 Time measured within algorithm 1, in milliseconds, and total elapsed time, in seconds, for six cases. <p> This study revealed the existence of errors in the original distributed algorithm for termination detection. These errors showed up the runs on 128 and 256 computers, where they caused a slowdown rather than a speedup. These results have been reported in publications <ref> [24, 26] </ref>. Office Glass Conference n T * T * T * 8 3:26 0.044 4:21 0.014 20:34 0.013 Table 4.4: Rendering times on Intel cluster. These runs were computed with parameters identical to table 4.3 and are directly comparable. <p> These runs were computed with parameters identical to table 4.3 and are directly comparable. In every respect the performance was slightly better than on the SP2. These results have been reported in publications <ref> [24, 26] </ref>.
Reference: [27] <author> Heirich, A. & Taylor, S. </author> <title> A parabolic load balancing method. </title> <booktitle> Proceedings of the 24th International Conference on Parallel Processing, vol. III (1995) pp. </booktitle> <pages> 192-202. </pages>
Reference-contexts: A few of them rely on the theory of the iterative solution of linear systems of equations in order to prove convergence properties of their algorithms [65, 66, 67]. Still others derive 16 their algorithms from models of differential equations <ref> [7, 12, 23, 27] </ref>. This author proposed a load balancing algorithm based on the heat equation u t = Kr 2 u [27]. The algorithm used an implicit numerical integration scheme to ensure numerical stability for very large time steps. <p> Still others derive 16 their algorithms from models of differential equations [7, 12, 23, 27]. This author proposed a load balancing algorithm based on the heat equation u t = Kr 2 u <ref> [27] </ref>. The algorithm used an implicit numerical integration scheme to ensure numerical stability for very large time steps. Analysis of this algorithm showed that it required only a small fixed number of steps to accomplish a matrix inversion that guaranteed numerical stability. <p> In this case there is no imbalance since all computers have equal workloads. A more interesting case occurs when disturbances are random but not in sufficient number to have equal expected imbalance. A simulation was performed to explore this 26 case in the context of the heat equation algorithm <ref> [27] </ref>. The simulation was of system of 1,000,000 computers that was initially balanced. The simulation was run for 1,000 steps, and a random disturbance was created on each of the first 700 steps.
Reference: [28] <author> Hong, J., Tan, X. & Chen, M. </author> <title> From local to global: an analysis of nearest-neighbor balancing on hypercube. </title> <booktitle> Proceedings of the ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems (1988) pp. </booktitle> <pages> 73-82. </pages>
Reference-contexts: Although these proposals were conceived independently the authors with few exceptions use the term "diffusion" in the descriptions of their algorithms. Few of these proposals are explicitly concerned with nearest neighbor communication <ref> [28] </ref>. A few of them rely on the theory of the iterative solution of linear systems of equations in order to prove convergence properties of their algorithms [65, 66, 67]. Still others derive 16 their algorithms from models of differential equations [7, 12, 23, 27].
Reference: [29] <author> Horn, R. A. & Johnson, C. R. </author> <title> Matrix Analysis (Cambridge University Press, </title> <address> New York, </address> <year> 1991). </year>
Reference: [30] <author> Horton, G. </author> <title> A multi-level diffusion method for dynamic load balancing. </title> <journal> Parallel Computing, </journal> <volume> vol. </volume> <pages> 19 (1993) pp. 209-218. </pages>
Reference: [31] <author> Hosseini, S. et al. </author> <title> Analysis of graph coloring based distributed load balancing algorithm. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. </volume> <pages> 10 (1990) pp. 160-166. </pages>
Reference: [32] <author> Hughes, T.J.R. </author> <title> The Finite Element Method (Prentice-Hall, </title> <address> Englewood Cliffs, </address> <year> 1987). </year>
Reference-contexts: In a similar way, problems in structural mechanics can be solved by using finite element methods to discretize equations of elasticity and heat transfer, and a variety of other equations for problems in electromagnetic scattering, radiative transfer, and other subjects <ref> [32] </ref>.
Reference: [33] <author> Kajiya, J.T. </author> <title> The rendering equation. </title> <journal> Computer Graphics, </journal> <volume> vol. </volume> <pages> 20 (1986) pp. 143-150. </pages>
Reference-contexts: Radios-ity computations are equivalent to finite element discretizations of the integral equations of light transport [20]. These equations are usually known as the rendering or radiance equations <ref> [33] </ref> but they can be formulated in a number of ways including formulations in terms of radiance, spectral radiance and transport intensity. <p> Monte Carlo methods are an alternative to finite elements for explicitly estimating solutions to the integral equations of light transport <ref> [33, 56, 61, 62] </ref>. Like ray tracing methods Monte Carlo methods calculate the contributions of light transported along individual paths through space, and they are usually (but not necessarily) implemented using ray tracing inner kernels. Like radiosity methods Monte Carlo methods can model diffuse surface reflection.
Reference: [34] <author> Karp, R. </author> <title> Reducibility in combinatorial problems. In Complexity of Computer Computations, </title> <editor> Miller & Thatcher (eds.) </editor> <publisher> (Plenum, </publisher> <address> New York, </address> <note> 1972) pp. 85-103. 73 </note>
Reference-contexts: For example, in 2 The usual vector norms are defined k~uk 1 P 3 In the partition problem a set of integers is to be divided into two subsets of equal sum. This problem is NP-complete <ref> [34] </ref>. 12 solving field equations it is necessary to maintain spatial locality among grid points. A load balancing algorithm that remapped grid points to randomly chosen computers would cause the field equation solvers to slow down severely because of the resulting increase in communication, for example.
Reference: [35] <author> Karypis, G. & Kumar, V. </author> <title> Multilevel graph partitioning schemes. </title> <booktitle> Proceedings of the 24th International Conference on Parallel Processing, vol. III (1995) pp. </booktitle> <pages> 113-122. </pages>
Reference-contexts: The general problem can be treated by any number of graph partitioning algorithms. Advocates of heuristic partitioners claim that they produce good solutions at low cost <ref> [35, 36, 54] </ref>. A competing approach, recursive spectral bisection, uses spectral properties of the graph to compute minimal bisectors [5, 50, 57]. <p> Having a minimal bisector at each step does not guarantee that the recursive process will yield a minimal partition of the graph, and it is a matter of debate whether spectral bisection yields better results than the heuristic approaches <ref> [35] </ref>. One thing that is not in dispute is that spectral bisection is more expensive than other methods [5, 35]. <p> One thing that is not in dispute is that spectral bisection is more expensive than other methods <ref> [5, 35] </ref>. Spectral bisection finds a minimal bisector by computing the Fiedler vector of the graph, and then uses the elements of the Fiedler vector to assign graph vertices to one subgraph or the other.
Reference: [36] <author> Karypis, G. & Kumar, V. </author> <title> A parallel algorithm for multilevel graph partitioning and sparse matrix reordering. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. </volume> <pages> 48 (1998) pp. 71-95. </pages>
Reference-contexts: The general problem can be treated by any number of graph partitioning algorithms. Advocates of heuristic partitioners claim that they produce good solutions at low cost <ref> [35, 36, 54] </ref>. A competing approach, recursive spectral bisection, uses spectral properties of the graph to compute minimal bisectors [5, 50, 57].
Reference: [37] <author> Kirk, D. & Arvo, J. </author> <title> Unbiased sampling techniques for image synthesis. </title> <booktitle> Proceedings of SIGGRAPH (1991) pp. </booktitle> <pages> 153-156. </pages>
Reference-contexts: For the purposes of photo-realism it is important to ensure that these strategies do not introduce bias into the result, as is the case with many common methods of antialiasing and path termination strategies <ref> [3, 37] </ref>. One reliable strategy is to explicitly sample the surfaces of the light sources, and we have done so in this implementation. Another reliable strategy is to model different surface properties independently, in ways that are unbiased, and then to combine samples from the different properties [61].
Reference: [38] <author> Kobayashi, H., Nakamura, T. & Shigei, Y. </author> <title> Parallel processing of an object space for image synthesis using ray-tracing. </title> <journal> The Visual Computer, </journal> <volume> vol. </volume> <pages> 3 (1987) pp. 13-22. </pages>
Reference-contexts: The best of these strategies, "scattering", will be used to initialize the experiment. In ray tracing it is useful to begin a computation with an initially balanced workload. A number of strategies have been explored for achieving this initial balance <ref> [4, 6, 11, 16, 38, 48, 51, 53, 68] </ref>. Among the more successful strategies has been the use of a random initial mapping [53]. The expected behavior of this approach can be predicted from the 43 central limit theorem.
Reference: [39] <author> Kung, H.T. & Stevenson, D. </author> <title> A software technique for reducing the routing time on a parallel computer with a fixed interconnection network. In High Speed Computer and Algorithm Organization, Kuck, </title> <editor> Lawrie & Sameh (eds.) </editor> <publisher> (Academic Press, </publisher> <address> New York, </address> <note> 1977) pp. 423-433. </note>
Reference-contexts: Find a new mapping ^ M to minimize Obj kCA ( ^ M )DA ( ^ M ) 1 C 1 k 2 . This definition is similar to the original formulation of this problem by Kung & Stevenson <ref> [39] </ref>.
Reference: [40] <author> Lafortune, E.P.F., Foo, S.-C., Torrance, K.E. & Greenberg, D. </author> <title> Non-linear approximation of reflectance functions. </title> <booktitle> Proceedings of SIGGRAPH (1997) pp. </booktitle> <pages> 117-126. </pages>
Reference-contexts: The algorithm computes independent trees of paths for specular, diffuse, and glossy surface properties, and combines the results of these independent computations. These surface properties could be extended with additional properties, or could be combined into general models of reflectance functions <ref> [40] </ref>. 36 Algorithm 2 (Path Tracing Iteration) for (some number of steps) do begin choose a descriptor (x; ! 0 ; I; x 0 ) from the queue find point x 0 visible from x in direction ! 0 if (x 0 is on a light source with radiance emission e)
Reference: [41] <author> Lin, F.C.H. & Keller, </author> <title> R.M. The gradient model load balancing method. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. </volume> <pages> SE-13 (1987) pp. 32-38. </pages>
Reference: [42] <author> Lindgren, B. W. </author> <title> Statistical Theory (MacMillan, </title> <address> New York, </address> <year> 1962). </year>
Reference-contexts: Similar arguments can be made for disturbances with any number of points, if these disturbances occur at random times and locations and with random intensity. When these disturbances occur in sufficiently large numbers the expected imbalance at every computer is the same, as implied by the central limit theorem <ref> [42] </ref>. In this case there is no imbalance since all computers have equal workloads. A more interesting case occurs when disturbances are random but not in sufficient number to have equal expected imbalance. <p> If the sample population is uniform then it is possible to quantify the probability that the sum of any individual set of p samples is below a given bound y <ref> [42] </ref>. In the general case we have P i=1 # 1 2 p 1 e u 2 =2 du = 2 1 Erf y p p In this expression and 2 are the mean and variance of the sample population.
Reference: [43] <author> McCormick, S. </author> <title> Multigrid Methods (SIAM, </title> <address> Philadelphia, </address> <year> 1987). </year>
Reference-contexts: These two characteristics are in sharp contrast to problems that commonly arise in solving differential equations by iterative algorithms and that give rise to research in multigrid methods <ref> [43] </ref>. <p> Disturbances of this sort are very challenging to any algorithm derived from the standard iterations. These disturbances have been discussed extensively in the literature on numerical analysis, particularly with respect to solving discretized partial differential equations, where they have given rise to multigrid methods <ref> [43] </ref>. Multigrid methods address the slow convergence of these components by computing approximate solutions at several levels of resolution and then combining these approximate solutions to obtain an accurate solution. These methods can be used successfully but they require grids with regular structure, something that is not always available.
Reference: [44] <author> Mohar, B. </author> <title> The Laplacian Spectrum of Graphs. In Graph Theory: Combinatorics and Applications, </title> <editor> Alavi et al (eds.) </editor> <publisher> (Wiley, </publisher> <address> New York, </address> <note> 1988) pp. 871-898. </note>
Reference-contexts: The matrix of coefficients that results from this discretization is called the Laplacian matrix of the graph. The Fiedler vector is the eigenvector of this Laplacian matrix corresponding to the smallest non-zero eigenvalue. The role of the Fiedler vector in computing minimal graph bisectors is well established <ref> [18, 44] </ref>. Spectral bisection typically computes the Fielder vector by using Lanczos iteration, but any other algorithm for computing eigensystems of symmetric matrices could be used, such as a Householder-QR sequence [17]. <p> When a graph is not a two-dimensional regular grid the corresponding eigenvalues are still similar to equation (3.3) in that they cover the same interval, but with different spacing. This result follows from theorem 3.2 of Mohar <ref> [44] </ref>: Call ~ the eigenvalues of the Laplacian matrix Q (G) of a graph G. Construct a new graph G 0 by adding an edge between any two vertices of G.
Reference: [45] <author> Muniz, F.J. & Zaluska, E.J. </author> <title> Parallel load balancing: an extension to the gradient model. </title> <journal> Parallel Computing, </journal> <volume> vol. </volume> <pages> 21 (1995) pp. 287-301. </pages>
Reference: [46] <author> Naylor, B. & Thibault, W. </author> <title> Application of (BSP) trees to ray-tracing and (CGS) evaluation. </title> <type> Technical report GIT-ICS 86/03, </type> <institution> Georgia Institute of Technology, School of Information and Computer Science (1986). </institution> <month> 74 </month>
Reference-contexts: Most of these other handlers performed mundane tasks, such as updating the value of a pixel sample, defining portions of the geometric model, or constructing a binary space partition (BSP) tree for use in visibility calculations <ref> [46] </ref>.
Reference: [47] <author> Ni, L.M., Xu, C. & Gendreau, </author> <title> T.B. A distributed drafting algorithm for load balancing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. </volume> <month> SE-11 </month> <year> (1985). </year>
Reference: [48] <author> Notkin, I. & Gotsman, C. </author> <title> Parallel progressive ray-tracing. </title> <journal> Computer Graphics Forum, </journal> <volume> vol. </volume> <pages> 17 (1997) pp. 43-55. </pages>
Reference-contexts: The best of these strategies, "scattering", will be used to initialize the experiment. In ray tracing it is useful to begin a computation with an initially balanced workload. A number of strategies have been explored for achieving this initial balance <ref> [4, 6, 11, 16, 38, 48, 51, 53, 68] </ref>. Among the more successful strategies has been the use of a random initial mapping [53]. The expected behavior of this approach can be predicted from the 43 central limit theorem.
Reference: [49] <author> Ortega, J.M. </author> <title> Introduction to Parallel and Vector Solution of Linear Systems (Plenum, </title> <address> New York, </address> <year> 1988). </year>
Reference-contexts: For a detailed discussion of these issues see <ref> [49] </ref>. 20 Gauss-Seidel iteration converges faster than Jacobi, but at a cost: the unknowns must be updated in a fixed order. This order requirement isn't practical for algorithm 1 since it executes independently on each computer.
Reference: [50] <author> Pothen, A., Simon, H. & Liou, K. </author> <title> Partitioning Sparse Matrices with Eigenvectors of Graphs. </title> <journal> SIAM Journal of Matrix Analysis, </journal> <volume> vol. </volume> <pages> 11 (1990) pp. 430-452. </pages>
Reference-contexts: The general problem can be treated by any number of graph partitioning algorithms. Advocates of heuristic partitioners claim that they produce good solutions at low cost [35, 36, 54]. A competing approach, recursive spectral bisection, uses spectral properties of the graph to compute minimal bisectors <ref> [5, 50, 57] </ref>. Having a minimal bisector at each step does not guarantee that the recursive process will yield a minimal partition of the graph, and it is a matter of debate whether spectral bisection yields better results than the heuristic approaches [35].
Reference: [51] <author> Priol, T. & Bouatouch, K. </author> <title> Static load balancing for (a) parallel ray-tracing on a (MIMD) hypercube. </title> <journal> The Visual Computer, </journal> <volume> vol. </volume> <pages> 5 (1989) pp. 109-119. </pages>
Reference-contexts: The best of these strategies, "scattering", will be used to initialize the experiment. In ray tracing it is useful to begin a computation with an initially balanced workload. A number of strategies have been explored for achieving this initial balance <ref> [4, 6, 11, 16, 38, 48, 51, 53, 68] </ref>. Among the more successful strategies has been the use of a random initial mapping [53]. The expected behavior of this approach can be predicted from the 43 central limit theorem. <p> For all of the above reasons we conclude that these predictions apply to a wide range of images and ray tracing algorithms. Many static load balancing strategies partition the image plane among a set of computers and then render the different portions of the image concurrently <ref> [14, 16, 21, 51, 53, 68] </ref>. Naive strategies that partition contiguous segments of the image fare poorly [21]. These strategies suffer from the effects of locality in the image which can lead to wide variations in workload for different computers.
Reference: [52] <author> Rosenberg, A. </author> <title> Issues in the study of graph embedding. In Graph Theoretic Concepts in Computer Science, </title> <editor> Noltemeier (ed.) </editor> <publisher> (Springer, </publisher> <address> New York, </address> <note> 1981) pp. 150-176. </note>
Reference-contexts: There are number of problems which are known to be similar to these: circuit partitioning and layout, network capacity planning, and sparse matrix reordering, to name just a few <ref> [9, 52] </ref>. This thesis began by mentioning recursive spectral bisection (RSB) and discussing properties of the Laplacian matrix of a graph. This construction method has been used for the same two problems that are solved by RSB, namely mapping and load balancing.
Reference: [53] <author> Salmon, J. & Goldsmith, J. </author> <title> A hypercube ray-tracer. </title> <booktitle> Proceedings of the Third Conference on Hypercube Concurrent Computers and Applications (1988) pp. </booktitle> <pages> 1194-1206. </pages>
Reference-contexts: The best of these strategies, "scattering", will be used to initialize the experiment. In ray tracing it is useful to begin a computation with an initially balanced workload. A number of strategies have been explored for achieving this initial balance <ref> [4, 6, 11, 16, 38, 48, 51, 53, 68] </ref>. Among the more successful strategies has been the use of a random initial mapping [53]. The expected behavior of this approach can be predicted from the 43 central limit theorem. <p> A number of strategies have been explored for achieving this initial balance [4, 6, 11, 16, 38, 48, 51, 53, 68]. Among the more successful strategies has been the use of a random initial mapping <ref> [53] </ref>. The expected behavior of this approach can be predicted from the 43 central limit theorem. This theorem states that when a sufficiently large number of samples w i are drawn from a sample population the sums of any sets of p samples will take on a normal distribution. <p> For all of the above reasons we conclude that these predictions apply to a wide range of images and ray tracing algorithms. Many static load balancing strategies partition the image plane among a set of computers and then render the different portions of the image concurrently <ref> [14, 16, 21, 51, 53, 68] </ref>. Naive strategies that partition contiguous segments of the image fare poorly [21]. These strategies suffer from the effects of locality in the image which can lead to wide variations in workload for different computers. <p> A more effective strategy assigns pixels pseudo-randomly to computers in an attempt to obtain a balanced workload. The most straightforward version of this strategy assigns pixels in an alternating sequence so that M (i) = (i mod n). This strategy is sometimes called the "scatter" method <ref> [53] </ref>. The effectiveness of various static load balancing strategies can be predicted using data to the right of the mean, leads to poor performance because it is hard to balance large statistical outliers. In contrast "left skew" does not present these problems.
Reference: [54] <author> Schloegel, K., Karypis, G., Kumar, V., Biswas, R. & Oliker, L. </author> <title> A performance study of diffusive versus remapped load balancing schemes. </title> <type> Technical report 98-018, </type> <institution> Army High Performance Computing Center, University of Minnesota (1998). </institution>
Reference-contexts: The general problem can be treated by any number of graph partitioning algorithms. Advocates of heuristic partitioners claim that they produce good solutions at low cost <ref> [35, 36, 54] </ref>. A competing approach, recursive spectral bisection, uses spectral properties of the graph to compute minimal bisectors [5, 50, 57].
Reference: [55] <editor> Sillion, F.X. & Puech, C. </editor> <publisher> Radiosity and Global Illumination (Morgan Kaufmann, </publisher> <address> San Francisco, </address> <year> 1994). </year>
Reference-contexts: They are often used to render models with mirror-like surface properties in which realistic reflection is important. Radios-ity algorithms ignore the effects of individual paths in favor of computing the total transfer of energy between objects with purely diffuse, omni-directional surface reflection <ref> [55] </ref>. Radios-ity computations are equivalent to finite element discretizations of the integral equations of light transport [20]. These equations are usually known as the rendering or radiance equations [33] but they can be formulated in a number of ways including formulations in terms of radiance, spectral radiance and transport intensity.
Reference: [56] <author> Shirley, P., Wang, C.Y. & Zimmerman, K. </author> <title> Monte Carlo techniques for direct lighting calculations. </title> <journal> ACM Transactions on Graphics, </journal> <volume> vol. </volume> <pages> 15 (1996) pp. 1-36. </pages>
Reference-contexts: Finite element and Monte Carlo methods, long staples of numerical analysis, have become powerful tools for solving global illumination <ref> [20, 24, 56] </ref>. Other image synthesis algorithms that have been developed specifically for global illumination include ray tracing, and radiosity methods. Ray tracing algorithms simulate individual photon paths through space and thereby compute reflections very accurately [63]. <p> Monte Carlo methods are an alternative to finite elements for explicitly estimating solutions to the integral equations of light transport <ref> [33, 56, 61, 62] </ref>. Like ray tracing methods Monte Carlo methods calculate the contributions of light transported along individual paths through space, and they are usually (but not necessarily) implemented using ray tracing inner kernels. Like radiosity methods Monte Carlo methods can model diffuse surface reflection.
Reference: [57] <author> Simon, H. </author> <title> Partitioning unstructured problems for parallel processing. </title> <booktitle> Computer Systems in Engineering, </booktitle> <volume> vol. 2, no. </volume> <pages> 2/3 (1991) pp. 135-148. </pages>
Reference-contexts: The general problem can be treated by any number of graph partitioning algorithms. Advocates of heuristic partitioners claim that they produce good solutions at low cost [35, 36, 54]. A competing approach, recursive spectral bisection, uses spectral properties of the graph to compute minimal bisectors <ref> [5, 50, 57] </ref>. Having a minimal bisector at each step does not guarantee that the recursive process will yield a minimal partition of the graph, and it is a matter of debate whether spectral bisection yields better results than the heuristic approaches [35].
Reference: [58] <author> Smits, B., Arvo, J. & Greenberg, D. </author> <title> A clustering algorithm for radiosity in complex environments. </title> <booktitle> Proceedings of SIGGRAPH (1994) pp. </booktitle> <pages> 435-442. </pages>
Reference-contexts: Hierar chical radiosity methods have been developed to reduce this O complexity to O (n) by representing the surface interactions at multiple levels of detail <ref> [19, 58] </ref>. These algorithms are effective in reducing the complexity of the computation but it is very difficult to assess the error that is introduced into the solution as a result of the geometric simplifications.
Reference: [59] <author> Sterling, T., Becker, D., et al. Beowulf: </author> <title> a parallel workstations for scientific computation. </title> <booktitle> Proceedings of the 24th International Conference on Parallel Processing, vol. I (1995) pp. </booktitle> <pages> 11-14. 75 </pages>
Reference: [60] <author> Tutte, W. T. </author> <title> How to draw a graph. </title> <journal> Proceedings of the London Mathematical Society, </journal> <volume> vol. </volume> <pages> 13 (1963) pp. 743-768. </pages>
Reference-contexts: The cases in figures 5.2 and 5.3 would be resolved by algorithm 1 implemented in a way that observes the locality constraint of problem 2. 5.4 Discussion Algorithm 4 is similar to a well-known algorithm for embedding a graph in the plane <ref> [60] </ref>. This variant extends the plane to arbitrary dimensions so that a computer network of any topology could be an embedding target.
Reference: [61] <author> Veach, E. & Guibas, L. </author> <title> Optimally combining sampling techniques for Monte Carlo rendering. </title> <booktitle> Proceedings of SIGGRAPH (1995) pp. </booktitle> <pages> 419-428. </pages>
Reference-contexts: Monte Carlo methods are an alternative to finite elements for explicitly estimating solutions to the integral equations of light transport <ref> [33, 56, 61, 62] </ref>. Like ray tracing methods Monte Carlo methods calculate the contributions of light transported along individual paths through space, and they are usually (but not necessarily) implemented using ray tracing inner kernels. Like radiosity methods Monte Carlo methods can model diffuse surface reflection. <p> One reliable strategy is to explicitly sample the surfaces of the light sources, and we have done so in this implementation. Another reliable strategy is to model different surface properties independently, in ways that are unbiased, and then to combine samples from the different properties <ref> [61] </ref>. In this implementation we have separate models of the purely specular and purely diffuse surface properties, and of a "glossy" property that is similar to a directional Phong shading model. Each of these separate properties leads to a separate calculation for 37 the reflection coefficient r.
Reference: [62] <author> Ward, G.J., Rubenstein, </author> <title> F.M. & Clear, R. A ray tracing solution for diffuse inter-reflection. </title> <booktitle> Proceedings of SIGGRAPH (1988) pp. </booktitle> <pages> 85-92. </pages>
Reference-contexts: Monte Carlo methods are an alternative to finite elements for explicitly estimating solutions to the integral equations of light transport <ref> [33, 56, 61, 62] </ref>. Like ray tracing methods Monte Carlo methods calculate the contributions of light transported along individual paths through space, and they are usually (but not necessarily) implemented using ray tracing inner kernels. Like radiosity methods Monte Carlo methods can model diffuse surface reflection.
Reference: [63] <author> Whitted, T. </author> <title> An improved illumination model for shaded display. </title> <journal> Communications of the ACM, </journal> <volume> vol. </volume> <pages> 23 (1980) pp. 343-349. </pages>
Reference-contexts: Other image synthesis algorithms that have been developed specifically for global illumination include ray tracing, and radiosity methods. Ray tracing algorithms simulate individual photon paths through space and thereby compute reflections very accurately <ref> [63] </ref>. They are often used to render models with mirror-like surface properties in which realistic reflection is important. Radios-ity algorithms ignore the effects of individual paths in favor of computing the total transfer of energy between objects with purely diffuse, omni-directional surface reflection [55].
Reference: [64] <author> Williams, R. </author> <title> Performance of dynamic load balancing algorithms for unstructured mesh calculations. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> vol. </volume> <pages> 3 (1991) pp. 457-481. </pages>
Reference-contexts: to have weight p j = 1. 4 A minimal bisector is one for which the sum of the cut edge weights is minimal. 14 The most efficient of these approaches is recursive coordinate bisection in which the spatial coordinates associated with grid points are used to find the bisector <ref> [64] </ref>. In this algorithm the bisector computation is inexpensive, but unfortunately the algorithm is not applicable to the general problem in which spatial coordinates are not present. The general problem can be treated by any number of graph partitioning algorithms.
Reference: [65] <author> Xu, C. & Lau, F.C.M. </author> <title> Analysis of the generalized dimension exchange method for dynamic load balancing. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. </volume> <pages> 16 (1992) pp. 385-393. </pages>
Reference-contexts: Few of these proposals are explicitly concerned with nearest neighbor communication [28]. A few of them rely on the theory of the iterative solution of linear systems of equations in order to prove convergence properties of their algorithms <ref> [65, 66, 67] </ref>. Still others derive 16 their algorithms from models of differential equations [7, 12, 23, 27]. This author proposed a load balancing algorithm based on the heat equation u t = Kr 2 u [27]. <p> If the weighting is chosen correctly SOR converges faster than either Jacobi or Gauss-Seidel. The choice of an optimal SOR weighting for load balancing on various interconnection topologies is the subject of <ref> [65, 66, 67] </ref>. Equation (3.2) is one of the most studied algorithms in numerical analysis. When it is discretized in this way on a regular grid in two dimensions, the iteration has a well-known basis with eigenvalues i;j and eigenvectors ~ X i;j [69].
Reference: [66] <author> Xu, C. & Lau, F.C.M. </author> <title> The generalized dimension exchange method for load balancing in k-ary n-cubes and variants. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. </volume> <pages> 24 (1995) pp. 72-85. </pages>
Reference-contexts: Few of these proposals are explicitly concerned with nearest neighbor communication [28]. A few of them rely on the theory of the iterative solution of linear systems of equations in order to prove convergence properties of their algorithms <ref> [65, 66, 67] </ref>. Still others derive 16 their algorithms from models of differential equations [7, 12, 23, 27]. This author proposed a load balancing algorithm based on the heat equation u t = Kr 2 u [27]. <p> If the weighting is chosen correctly SOR converges faster than either Jacobi or Gauss-Seidel. The choice of an optimal SOR weighting for load balancing on various interconnection topologies is the subject of <ref> [65, 66, 67] </ref>. Equation (3.2) is one of the most studied algorithms in numerical analysis. When it is discretized in this way on a regular grid in two dimensions, the iteration has a well-known basis with eigenvalues i;j and eigenvectors ~ X i;j [69].
Reference: [67] <author> Xu, C. & Lau, F.C.M. </author> <title> Load Balancing in Parallel Computers: Theory and Practice (Kluwer, </title> <address> Boston, </address> <year> 1997). </year>
Reference-contexts: Few of these proposals are explicitly concerned with nearest neighbor communication [28]. A few of them rely on the theory of the iterative solution of linear systems of equations in order to prove convergence properties of their algorithms <ref> [65, 66, 67] </ref>. Still others derive 16 their algorithms from models of differential equations [7, 12, 23, 27]. This author proposed a load balancing algorithm based on the heat equation u t = Kr 2 u [27]. <p> If the weighting is chosen correctly SOR converges faster than either Jacobi or Gauss-Seidel. The choice of an optimal SOR weighting for load balancing on various interconnection topologies is the subject of <ref> [65, 66, 67] </ref>. Equation (3.2) is one of the most studied algorithms in numerical analysis. When it is discretized in this way on a regular grid in two dimensions, the iteration has a well-known basis with eigenvalues i;j and eigenvectors ~ X i;j [69].
Reference: [68] <author> Yoon, H.J., Fun, S. & Cho, J.W. </author> <title> An image parallel ray-tracing using static load balancing and data prefetching. </title> <booktitle> Proceedings of the First Eurographics Workshop on Parallel Graphics and Visualization, </booktitle> <address> Bristol, </address> <note> England (September 1996) pp. 53-66. </note>
Reference-contexts: The best of these strategies, "scattering", will be used to initialize the experiment. In ray tracing it is useful to begin a computation with an initially balanced workload. A number of strategies have been explored for achieving this initial balance <ref> [4, 6, 11, 16, 38, 48, 51, 53, 68] </ref>. Among the more successful strategies has been the use of a random initial mapping [53]. The expected behavior of this approach can be predicted from the 43 central limit theorem. <p> For all of the above reasons we conclude that these predictions apply to a wide range of images and ray tracing algorithms. Many static load balancing strategies partition the image plane among a set of computers and then render the different portions of the image concurrently <ref> [14, 16, 21, 51, 53, 68] </ref>. Naive strategies that partition contiguous segments of the image fare poorly [21]. These strategies suffer from the effects of locality in the image which can lead to wide variations in workload for different computers.
Reference: [69] <author> Young, D. M. </author> <title> Iterative Solution of Large Linear Systems (Academic Press, </title> <address> New York, </address> <year> 1971). </year>
Reference-contexts: Equation (3.2) is one of the most studied algorithms in numerical analysis. When it is discretized in this way on a regular grid in two dimensions, the iteration has a well-known basis with eigenvalues i;j and eigenvectors ~ X i;j <ref> [69] </ref>. For example, in the Jacobi iteration these take the form i;j = 2 cos p + cos p (X i;j ) x;y = k i;j cos p cos p : (3.4) In the case of Gauss-Seidel the eigenvalues are i;j = 1 4 cos i p n [69]. <p> X i;j <ref> [69] </ref>. For example, in the Jacobi iteration these take the form i;j = 2 cos p + cos p (X i;j ) x;y = k i;j cos p cos p : (3.4) In the case of Gauss-Seidel the eigenvalues are i;j = 1 4 cos i p n [69].
References-found: 69

