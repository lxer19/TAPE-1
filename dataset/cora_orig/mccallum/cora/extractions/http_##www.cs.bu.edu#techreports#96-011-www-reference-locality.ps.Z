URL: http://www.cs.bu.edu/techreports/96-011-www-reference-locality.ps.Z
Refering-URL: http://cs-www.bu.edu/techreports/Home.html
Root-URL: 
Email: (virgilio@bu.edu)  (best@bu.edu)  (crovella@bu.edu)  (dri@dcc.ufmg.br)  
Title: Characterizing Reference Locality in the WWW  
Author: Virglio Almeida yx Azer Bestavros Mark Crovella Adriana de Oliveira Depto. de Ciencia da Computac~ao, 
Keyword: Self-similarity; Long-range dependence; Distance strings; Reference locality; Caching; Performance modeling.  
Note: This work has been partially supported by NSF (grants CCR-9308344 and CCR-9501822) and by CNPq-Brazil.  On sabbatical at Boston University from  
Address: Boston, MA 02215  Boston, MA 02215, USA.  Minas Gerais, Belo Horizonte, MG 30161, Brazil.  
Affiliation: Department of Computer Science Boston University  Computer Science Department, Boston University,  Universidade Federal de  Universidade Federal de Minas Gerais.  
Pubnum: TR-96-11  
Abstract: As the World Wide Web (Web) is increasingly adopted as the infrastructure for large-scale distributed information systems, issues of performance modeling become ever more critical. In particular, locality of reference is an important property in the performance modeling of distributed information systems. In the case of the Web, understanding the nature of reference locality will help improve the design of middleware, such as caching, prefetching, and document dissemination systems. For example, good measurements of reference locality would allow us to generate synthetic reference streams with accurate performance characteristics, would allow us to compare empirically measured streams to explain differences, and would allow us to predict expected performance for system design and capacity planning. In this paper we propose models for both temporal and spatial locality of reference in streams of requests arriving at Web servers. We show that simple models based only on document popularity (likelihood of reference) are insufficient for capturing either temporal or spatial locality. Instead, we rely on an equivalent, but numerical, representation of a reference stream: a stack distance trace. We show that temporal locality can be characterized by the marginal distribution of the stack distance trace, and we propose models for typical distributions and compare their cache performance to our traces. We also show that spatial locality in a reference stream can be characterized using the notion of self-similarity. Self-similarity describes long-range correlations in the dataset, which is a property that previous researchers have found hard to incorporate into synthetic reference strings. We show that stack distance strings appear to be stongly self-similar, and we provide measurements of the degree of self-similarity in our traces. Finally, we discuss methods for generating synthetic Web traces that exhibit the properties of temporal and spatial locality that we measured in our data. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Marc Abrams, Charles R. Standridge, Ghaleb Abdulla, Stephen Williams, and Edward A. Fox. </author> <title> Caching proxies: Limitations and potentials. </title> <booktitle> In Proceedings of the Fourth Interntional COnference on the WWW, Boston, </booktitle> <address> MA, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: This finding agrees with Glassman's predictions [17] and was further confirmed for general proxy caching by Abrams et al <ref> [1] </ref>. Williams et al [35] present a taxonomy (and compare the performance) of a number of proxy cache replacement policies. Their work suggests that proxy cache management should consider document sizes when making replacement decisions. <p> Similar results about the inadequacy of classic LRU cache replacement are presented in <ref> [1] </ref>.
Reference: [2] <author> S. Acharya, R. Alonso, M. Franklin, and S. Zdonik. </author> <title> Broadcast disks: Data management for asymmetric communications environments. </title> <booktitle> In Proceedings of ACM SIGMOD conference, </booktitle> <address> San Jose, CA, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Again, the tightness of the fit for the family of curves in Figure-2 to straight lines slope close to -1 suggest that Zipf's law does apply to sequences of requests. Given the above observations, one possible access model <ref> [17, 2] </ref> is to generate document requests according to the popularity profile of documents. We call this model the Zipf-based model.
Reference: [3] <author> Swarup Acharya and Stanley B. Zdonik. </author> <title> An efficient scheme for dynamic data replication. </title> <type> Technical Report CS-93-43, </type> <institution> Brown University, </institution> <address> Providence, Rhode Island 02912, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: In this study, a hierarchical caching system that caches files at Core Nodal Switching Subsystems is shown to reduce the NSFNET backbone traffic by 21%. The effect of data placement and replication on network traffic was also studied in <ref> [3] </ref>, where file access patterns are used to suggest a distributed dynamic replication scheme. A more static solution based on fixed network and storage costs for the delivery of multimedia home entertainment was suggested in [27].
Reference: [4] <author> Jan Beran. </author> <title> Statistics for Long-Memory Processes. Monographs on Statistics and Applied Probability. </title> <publisher> Chapman and Hall, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: These methods are useful for assessing whether assumptions about the data are correct (such as stationarity) and for providing a single estimate of H. The fourth method is the maximum likelihood estimator for H, called the Whittle estimator, which provide confidence intervals as well. Interested readers are referred to <ref> [4, 22] </ref> for a discussion of these methods in more detail. Plots of the graphical estimators for the BU trace are shown in Figure 10.
Reference: [5] <author> Azer Bestavros. </author> <title> Demand-based document dissemination to reduce traffic and balance load in distributed information systems. </title> <booktitle> In Proceedings of SPDP'95: The 7 th IEEE Symposium on Parallel and Distributed Processing, </booktitle> <address> San Anotonio, Texas, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: In these studies, it was shown that "Popular files are very popular" <ref> [5, 18] </ref>. In [12], Cunha, Bestavros, and Crovella characterized the popularity of Web documents requested by clients and confirmed the applicability of Zipf's law [36, discussed in [23]] to Web documents. <p> Similar results about the inadequacy of classic LRU cache replacement are presented in [1]. In <ref> [5] </ref>, Bestavros proposed an alternative to client-based caching, which attempts to capitalize on the global knowledge amassed at servers about geographical locality of reference|the property that an object accessed by a client at a site is likely to be accessed again in the future by a client in a "nearby" site.
Reference: [6] <author> Azer Bestavros. </author> <title> Using speculation to reduce server load and service time on the www. In Proceedings of CIKM'95: </title> <booktitle> The 4 th ACM International Conference on Information and Knowledge Management, </booktitle> <address> Baltimore, Maryland, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: Preliminary results indicate that client-initiated prefetching is extremely effective for access patterns that involve frequently-traversed documents, but not effective at all for access patterns that involve newly-traversed documents. For such access patterns, Bestavros proposed an alternative protocol <ref> [6] </ref> that allows prefetching to be initiated by servers (or by clients as a result of hints generated by servers) based on a Markov model built by analyzing the server's access logs. 7 Conclusion In this paper we have measured the locality present in reference traces arriving at four servers in
Reference: [7] <author> Azer Bestavros, Robert Carter, Mark Crovella, Carlos Cunha, Abdelsalam Heddaya, and Su-laiman Mirdad. </author> <title> Application level document caching in the internet. </title> <booktitle> In IEEE SDNE'96: The Second International Workshop on Services in Distributed and Networked Environments, </booktitle> <address> Whistler, British Columbia, </address> <month> June </month> <year> 1995. </year> <month> 19 </month>
Reference-contexts: The first comprehensive study of client-based caching for the Web was conducted by our Oceans group. 6 In that study <ref> [7] </ref>, the effectiveness of session caching, host caching, and LAN proxy caching 6 http://cs-www.bu.edu/groups/oceans/ 17 were established using a unique set of 5,700 client traces (almost 600,000 URL requests), which were obtained by intrumenting Mosaic as detailed in [12].
Reference: [8] <author> Azer Bestavros and Carlos Cunha. </author> <title> A prefetching protocol using client speculation for the www. Technical Report TR-95-011, </title> <institution> Boston University, CS Dept, </institution> <address> Boston, MA 02215, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: Exploiting the spatial locality of reference properties exhibited in Web access patterns was investigated in two recent prefetching studies of our Oceans group. In <ref> [8] </ref>, Bestavros and Cunha propose a protocol that allows a client to prefetch Web documents based on Markov models built from the client's previous access patterns.
Reference: [9] <author> Matthew Addison Blaze. </author> <title> Caching in Large Scale Distributed File Systems. </title> <type> PhD thesis, </type> <institution> Prince-ton University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: A more static solution based on fixed network and storage costs for the delivery of multimedia home entertainment was suggested in [27]. Multi-level caching was studied in [26], where simulations of a two-level caching system is shown to reduce both network and server loads. In <ref> [9] </ref>, a dynamic hierarchical file system, that supports demand-driven replication is proposed, whereby clients are allowed to service requests issued by other clients from the local disk cache. A similar cooperative caching idea was suggested in [13].
Reference: [10] <author> Jean-Chrysostome Bolot and Philipp Hoschka. </author> <title> Performance engineering of the world wide web: Application to dimensioning and cache design. </title> <booktitle> In Proceedings of the Fifth Interntional COnference on the WWW, Paris, </booktitle> <address> France, </address> <year> 1996. </year>
Reference-contexts: Williams et al [35] present a taxonomy (and compare the performance) of a number of proxy cache replacement policies. Their work suggests that proxy cache management should consider document sizes when making replacement decisions. This was also confirmed by Bolot and Hoschka <ref> [10] </ref>, who showed the usefulness of using information about document size and network load in the replacement algorithms of Web caches, based on time series analysis techniques of Web traffic. Similar results about the inadequacy of classic LRU cache replacement are presented in [1].
Reference: [11] <author> Mark E. Crovella and Azer Bestavros. </author> <title> Self-similarity in World Wide Web traffic: Evidence and possible causes. </title> <booktitle> In Proceedings of the 1996 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1996. </year>
Reference: [12] <author> Carlos A. Cunha, Azer Bestavros, and Mark E. Crovella. </author> <title> Characteristics of www client-based traces. </title> <type> Technical Report TR-95-010, </type> <institution> Boston University Department of Computer Science, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: In these studies, it was shown that "Popular files are very popular" [5, 18]. In <ref> [12] </ref>, Cunha, Bestavros, and Crovella characterized the popularity of Web documents requested by clients and confirmed the applicability of Zipf's law [36, discussed in [23]] to Web documents. Zipf's law was originally applied to the 2 Since we have shown in previous work [12] that document size is correlated with expected <p> In <ref> [12] </ref>, Cunha, Bestavros, and Crovella characterized the popularity of Web documents requested by clients and confirmed the applicability of Zipf's law [36, discussed in [23]] to Web documents. Zipf's law was originally applied to the 2 Since we have shown in previous work [12] that document size is correlated with expected reference frequency, this assumption is somewhat limiting for direct use in cache performance analysis. For that reason we are currently extending this work to include document sizes in our analysis. <p> the Web was conducted by our Oceans group. 6 In that study [7], the effectiveness of session caching, host caching, and LAN proxy caching 6 http://cs-www.bu.edu/groups/oceans/ 17 were established using a unique set of 5,700 client traces (almost 600,000 URL requests), which were obtained by intrumenting Mosaic as detailed in <ref> [12] </ref>. This study concluded that LAN proxy caching|while effective in reducing response time by as much as a half|is ultimately limited by the low level of sharing of remote documents amongst clients of the same site. <p> In [24], Markatos examines the potential performance gains from using Main Memory Web Caches. He shows that a small amount of main memory could yield substantial improvement in performance if cache management methods that are sensitive to document popularity and to user preferences for small documents <ref> [12] </ref> are employed. Exploiting the spatial locality of reference properties exhibited in Web access patterns was investigated in two recent prefetching studies of our Oceans group.
Reference: [13] <author> Michael D. Dahlin, Randolph Y. Wang, Thomas E. Anderson, and Dacid A. Patterson. </author> <title> Cooperative caching: Using remote client memory to improve file system performance. </title> <booktitle> In First Symposium on Operating systems Design and Implementation (OSDI), </booktitle> <pages> pages 267-280, </pages> <year> 1994. </year>
Reference-contexts: In [9], a dynamic hierarchical file system, that supports demand-driven replication is proposed, whereby clients are allowed to service requests issued by other clients from the local disk cache. A similar cooperative caching idea was suggested in <ref> [13] </ref>. Glassman [17] presents one of the earliest attempts for caching on the Web, whereby "satellite relays" (proxy caches) are organized into a tree-structured hierarchy with cache misses in lower relays percolating up through higher relays until the requested object is found.
Reference: [14] <author> Peter Danzig, Richard Hall, and Michael Schwartz. </author> <title> A case for caching file objects inside internetworks. </title> <type> Technical Report CU-CS-642-93, </type> <institution> University of Colorado at Boulder, Boulder, Colorado 80309-430, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: Caching to reduce the bandwidth requirements for the FTP protocol on the NSFNET has been studied in <ref> [14] </ref>. In this study, a hierarchical caching system that caches files at Core Nodal Switching Subsystems is shown to reduce the NSFNET backbone traffic by 21%.
Reference: [15] <author> P. Denning and S. Schwartz. </author> <title> Properties of the working set model. </title> <journal> Communications of the ACM, </journal> <volume> 15(3) </volume> <pages> 191-198, </pages> <year> 1972. </year>
Reference-contexts: 1 Introduction The principle of locality of reference has very important consequences for computer systems design. Reference streams exhibiting temporal locality can benefit from caching; and reference streams exhibiting spatial locality can benefit from prefetching. The application of these principles in, e.g., memory systems is well understood <ref> [15, 31] </ref>. In order to apply these principles to the design of World Wide Web (Web) caching and prefetch-ing systems, it's important to characterize the degree of temporal and spatial locality present in typical Web reference streams. <p> of only temporal locality properties are encouraging. 6 Related Work In this section we review previous research directly 5 related to our work, namely work in reference locality modeling, use of fractals for modeling program behavior, and work in exploiting Web reference locality. 6.1 Reference Locality Modeling Denning and Schwartz <ref> [15] </ref> established the fundamental properties that characterize the phenomenon of locality in hierarchical structures of memory. In [25], the authors studied stack algorithms and introduced stack distance as a means for analyzing behavior of demand-paged memory systems.
Reference: [16] <author> Kenneth Falconer. </author> <title> Fractal Geometry. </title> <publisher> John Wiley & Sons, Ltd., </publisher> <year> 1990. </year>
Reference-contexts: In fact, a statistically self-similar series X t like the one shown on the left of Figure 9 has an almost sure fractal dimension (in the sense of either the Hausdorff dim H or box-counting dimension dim B ) of <ref> [16] </ref> Thus the fractal dimension of such a series is 3/2 for Gaussian noise (H = 1=2), and decreases to 1 as the correlation present in the series increases (H ! 1). The corresponds with intuition: a series with more dependence is more "predictable" and fills space less completely.
Reference: [17] <author> Steven Glassman. </author> <title> A caching relay for the world wide web. </title> <booktitle> In Proceedings of the First Intern-tional COnference on the WWW, 1994. </booktitle>
Reference-contexts: Again, the tightness of the fit for the family of curves in Figure-2 to straight lines slope close to -1 suggest that Zipf's law does apply to sequences of requests. Given the above observations, one possible access model <ref> [17, 2] </ref> is to generate document requests according to the popularity profile of documents. We call this model the Zipf-based model. <p> In [9], a dynamic hierarchical file system, that supports demand-driven replication is proposed, whereby clients are allowed to service requests issued by other clients from the local disk cache. A similar cooperative caching idea was suggested in [13]. Glassman <ref> [17] </ref> presents one of the earliest attempts for caching on the Web, whereby "satellite relays" (proxy caches) are organized into a tree-structured hierarchy with cache misses in lower relays percolating up through higher relays until the requested object is found. <p> This study concluded that LAN proxy caching|while effective in reducing response time by as much as a half|is ultimately limited by the low level of sharing of remote documents amongst clients of the same site. This finding agrees with Glassman's predictions <ref> [17] </ref> and was further confirmed for general proxy caching by Abrams et al [1]. Williams et al [35] present a taxonomy (and compare the performance) of a number of proxy cache replacement policies. Their work suggests that proxy cache management should consider document sizes when making replacement decisions.
Reference: [18] <author> James Gwertzman and Margo Seltzer. </author> <title> The case for geographical push caching. </title> <booktitle> In In Proceedings of HotOS'95: The Fifth IEEE Workshop on Hot Topics in Operating Systems, </booktitle> <address> Washing-ton, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: In these studies, it was shown that "Popular files are very popular" <ref> [5, 18] </ref>. In [12], Cunha, Bestavros, and Crovella characterized the popularity of Web documents requested by clients and confirmed the applicability of Zipf's law [36, discussed in [23]] to Web documents. <p> A similar philosophy was sketched in <ref> [18] </ref>, whereby the placement of popular documents was based on geographical information (such as the distance in actual miles between servers and clients). In [24], Markatos examines the potential performance gains from using Main Memory Web Caches.
Reference: [19] <author> The Internet Town Hall. </author> <title> The internet traffic archive. </title> <note> available as http://www.town.hall.org/Archives/pub/ITA/, 1995. </note>
Reference-contexts: In the case of the NCSA, the data refers only to one server (Costello). The SDSC and EPA logs are available at the Internet Traffic Archives <ref> [19] </ref>, the NCSA log was obtained after contacting the staff at the site and the BU logs were collected at the departmental Web server. The logs have one line of information per request processed by the server.
Reference: [20] <author> John H. Howard, Michael L. Kazar, Sherri G. Menees, David A. Nichols, M. Satyanarayanan, Robert N. Sidebotham, and Michael J. West. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 51-81, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Most of the caching studies for large distributed information systems concentrate on client-based caching, whereby recently/frequently accessed information is cached at the client (or at a proxy thereof) in anticipation of future accesses to the same information. Traditionally, this was done in the realms of distributed file systems <ref> [20] </ref>, but more recently, there have been some attempts at extending these techniques to distributed information systems such as FTP and HTTP. Caching to reduce the bandwidth requirements for the FTP protocol on the NSFNET has been studied in [14].
Reference: [21] <author> Changcheng Huang, Michael Devetsikiotis, Ioannis Lambadaris, and A. Roger Kaye. </author> <title> Modeling and simulation of self-similar variable bit rate compressed video: A unified approach. </title> <booktitle> In Proceedings of ACM SIGCOMM '95, </booktitle> <pages> pages 114-125, </pages> <year> 1995. </year>
Reference-contexts: Invert the stack distance trace to form a sequence of file names. On first glance, step 2 seems difficult. Fortunately recent results have shown that marginal distribution and long-range dependence can be considered as separate problems for trace generation <ref> [21] </ref>. That work shows that, given a long-range dependent series X t with H = H X and marginal cumulative probability function F X (x), we can generate another long-range dependent series Y t with H = H X and arbitrary marginal cumulative probability function F Y (x). <p> This is achieved by individual transformation of the elements of X t as follows: Y t = F 1 15 The authors in <ref> [21] </ref> show that this transformation preserves long-range dependence with the same value of H. Thus, our approach to step 2 is as follows. First, generate a self-similar series with given H. This can be done in a number of ways; a fast approach is described in [28].
Reference: [22] <author> W.E. Leland, M.S. Taqqu, W. Willinger, and D.V. Wilson. </author> <title> On the self-similar nature of Ethernet traffic (extended version). </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 2 </volume> <pages> 1-15, </pages> <year> 1994. </year> <month> 20 </month>
Reference-contexts: These methods are useful for assessing whether assumptions about the data are correct (such as stationarity) and for providing a single estimate of H. The fourth method is the maximum likelihood estimator for H, called the Whittle estimator, which provide confidence intervals as well. Interested readers are referred to <ref> [4, 22] </ref> for a discussion of these methods in more detail. Plots of the graphical estimators for the BU trace are shown in Figure 10.
Reference: [23] <author> Benoit B. Mandelbrot. </author> <title> The Fractal Geometry of Nature. </title> <editor> W. H. </editor> <publisher> Freedman and Co., </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: In these studies, it was shown that "Popular files are very popular" [5, 18]. In [12], Cunha, Bestavros, and Crovella characterized the popularity of Web documents requested by clients and confirmed the applicability of Zipf's law [36, discussed in <ref> [23] </ref>] to Web documents. Zipf's law was originally applied to the 2 Since we have shown in previous work [12] that document size is correlated with expected reference frequency, this assumption is somewhat limiting for direct use in cache performance analysis. <p> The intersection of fractal X having 1 &lt; dim H (X) &lt; 2 and a line L (dim H (L) = 1) is almost surely a new fractal X 0 with dim H (X 0 ) = dim H (X) 1 <ref> [23] </ref>. This means that a cache miss fractal derived from a stack distance fractal such as our traces should have a dimension between 0 and 1.
Reference: [24] <author> Evangelos Markatos. </author> <title> Main memory caching of web documents. </title> <booktitle> In Proceedings of the Fifth Interntional COnference on the WWW, Paris, </booktitle> <address> France, </address> <year> 1996. </year>
Reference-contexts: A similar philosophy was sketched in [18], whereby the placement of popular documents was based on geographical information (such as the distance in actual miles between servers and clients). In <ref> [24] </ref>, Markatos examines the potential performance gains from using Main Memory Web Caches. He shows that a small amount of main memory could yield substantial improvement in performance if cache management methods that are sensitive to document popularity and to user preferences for small documents [12] are employed.
Reference: [25] <author> R. Mattson, J. Gecsei, D. Slutz, and I. Traiger. </author> <title> Evaluation techniques and storage hierarchies. </title> <journal> IBM Systems Journal, </journal> <volume> 9 </volume> <pages> 78-117, </pages> <year> 1970. </year>
Reference-contexts: Previous research in the locality properties of symbolic reference streams have shown the benefits of transforming the reference stream into an equivalent, but numerical, representation: a stack distance stream <ref> [25] </ref>. This transformation preserves all of the information of the original trace except for the specific reference names, and so it is invertible, allowing reconstruction of the original trace (albeit with synthetic names). <p> Two properties of the stack distance stream can be used to measure the notions of temporal and spatial locality: marginal distribution, and correlation structure <ref> [25, 30] </ref>. The marginal distribution measures the likelihood that two references to the same object are separated by some number of intervening references in the stream. The correlation structure of the stream measures the likelihood that we can predict future references based on the stream of past references. <p> Based on the concepts proposed in <ref> [25, 32] </ref>, we define a stack distance model that captures the temporal locality relationships present in a request stream. <p> In <ref> [25] </ref>, the authors studied stack algorithms and introduced stack distance as a means for analyzing behavior of demand-paged memory systems. They also discussed the significance of stack distance strings for evaluating performance of memory management schemes. Then, Spirn [32] proposes the use of distance string models to represent program behavior.
Reference: [26] <author> D. Muntz and P. Honeyman. </author> <title> Multi-level caching in distributed file systems or your cache ain't nuthing but trash. </title> <booktitle> In Proceedings of the Winter 1992 USENIX, </booktitle> <pages> pages 305-313, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: A more static solution based on fixed network and storage costs for the delivery of multimedia home entertainment was suggested in [27]. Multi-level caching was studied in <ref> [26] </ref>, where simulations of a two-level caching system is shown to reduce both network and server loads. In [9], a dynamic hierarchical file system, that supports demand-driven replication is proposed, whereby clients are allowed to service requests issued by other clients from the local disk cache.
Reference: [27] <author> Christos H. Papadimitriou, Srinivas Ramanathan, and P. Venkat Rangan. </author> <title> Information caching for delivery of personalized video programs on home entertainment channels. </title> <booktitle> In Proceedings of the International Confrence on Multimedia Computing and Systems, </booktitle> <pages> pages 214-223, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The effect of data placement and replication on network traffic was also studied in [3], where file access patterns are used to suggest a distributed dynamic replication scheme. A more static solution based on fixed network and storage costs for the delivery of multimedia home entertainment was suggested in <ref> [27] </ref>. Multi-level caching was studied in [26], where simulations of a two-level caching system is shown to reduce both network and server loads.
Reference: [28] <author> Vern Paxson. </author> <title> Fast approximation of self-similar network traffic. </title> <type> Technical Report LBL-36750, </type> <institution> Lawrence Berkeley Laboratory, </institution> <address> 1 Cyclotron Road, Berkeley, CA 94720, </address> <year> 1995. </year>
Reference-contexts: Thus, our approach to step 2 is as follows. First, generate a self-similar series with given H. This can be done in a number of ways; a fast approach is described in <ref> [28] </ref>. Then apply the transformation of Equation 5 to obtain a series with the proper lognormal marginal distribution. We have begun to use the method for generating web reference traces and are currently evaluating the properties of the resulting traces.
Reference: [29] <author> Mimi M. Recker and James E. Pitkow. </author> <title> Predicting document access in large, multimedia repositories. </title> <type> Technical Report Technical Report VU-GIT-94-35, </type> <institution> Georgia Tech|Graphics, Visualization, and Usability Center, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: In particular, it was estimated that with an infinite-size cache, the maximum achievable hit rate is 40%. Another early attempt at characterizing Web access patterns for the purpose of engineering Web caching systems is the work of Recker and Pitkow <ref> [29] </ref>, in which a model for Web information access is proposed based on two metrics borrowed from psychological research on human memory|namely the frequency and recency rates of past accesses.
Reference: [30] <author> G. Shedlar and C. Tung. </author> <title> Locality in page reference strings. </title> <journal> SIAM Jounral of Computing, </journal> <volume> 1(3), </volume> <month> September </month> <year> 1972. </year>
Reference-contexts: Two properties of the stack distance stream can be used to measure the notions of temporal and spatial locality: marginal distribution, and correlation structure <ref> [25, 30] </ref>. The marginal distribution measures the likelihood that two references to the same object are separated by some number of intervening references in the stream. The correlation structure of the stream measures the likelihood that we can predict future references based on the stream of past references. <p> SDSC, EPA) 5 Characterizing Spatial Locality Having characterized the temporal locality present in our traces, we now present models for spatial locality. Previous work has shown that the correlation structure of the stack distance stream is useful for modeling spatial locality <ref> [30] </ref>; however previous attempts to model the correlation structure of reference strings have used models with only short-range dependence, such as finite first-order Markov chains.
Reference: [31] <author> Alan Jay Smith. </author> <title> Cache memories. </title> <journal> Computing Surveys, </journal> <volume> 14(3) </volume> <pages> 473-530, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: 1 Introduction The principle of locality of reference has very important consequences for computer systems design. Reference streams exhibiting temporal locality can benefit from caching; and reference streams exhibiting spatial locality can benefit from prefetching. The application of these principles in, e.g., memory systems is well understood <ref> [15, 31] </ref>. In order to apply these principles to the design of World Wide Web (Web) caching and prefetch-ing systems, it's important to characterize the degree of temporal and spatial locality present in typical Web reference streams.
Reference: [32] <author> Jeffrey Spirn. </author> <title> Distance string models for program behavior. </title> <journal> IEEE Computer, </journal> <volume> 13(11), </volume> <month> November </month> <year> 1976. </year>
Reference-contexts: Based on the concepts proposed in <ref> [25, 32] </ref>, we define a stack distance model that captures the temporal locality relationships present in a request stream. <p> Previous work has shown that the correlation structure of the stack distance stream is useful for modeling spatial locality [30]; however previous attempts to model the correlation structure of reference strings have used models with only short-range dependence, such as finite first-order Markov chains. As pointed out in <ref> [32] </ref>, such short-range dependent models are not capable of capturing the long-term structure of reference strings, which includes phase change behavior. 10 5.1 Measuring Stack Distance Self-Similarity To capture the long-range dependence in stack distance strings we employ the statistics of self-similarity. <p> In [25], the authors studied stack algorithms and introduced stack distance as a means for analyzing behavior of demand-paged memory systems. They also discussed the significance of stack distance strings for evaluating performance of memory management schemes. Then, Spirn <ref> [32] </ref> proposes the use of distance string models to represent program behavior. Distance strings are equivalent in information content to the reference string, but are more easily handled by mathematical models. <p> Usually, the abrupt changes in locality generate large distances in distance string model. Markov distance string models are capable of predicting bursts based on the most recent generated distances. Thus, the work in <ref> [32] </ref> argues that Markov models are not able to capture the behavior of real programs, which exhibit some form of long-range dependencies. <p> However, the model is not easily used because of the empirical process of obtaining and adjusting its parameters from plots of the traces. Also, the proposed model does not represent multiprogramming environments, where context switches occur frequently. Our paper extends the work referenced in <ref> [34, 33, 32] </ref> to the context of large distributed systems and also introduces new parameters that fully describe locality aspects of a reference stream that arrives at a Web server. 6.3 Exploiting Web Reference Locality Previous studies in caching, replication, dissemination, and prefetching protocols for large distributed information systems have recognized
Reference: [33] <author> Dominique Thiebaut. </author> <title> On the fractal dimension of computer programs and its application to the prediction of the cache miss ratio. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(7), </volume> <month> July </month> <year> 1989. </year>
Reference-contexts: Covering this literature is beyond the scope of this paper. 16 Based on the work in [34], paper <ref> [33] </ref> models the patterns generated by a processor accessing memory as random walk with fractal dimension. The author proposes that in an asymptotic behavior the number of misses that a program encounters in an infinite cache is given by a hyperbolic function of the fractal dimension. <p> However, the model is not easily used because of the empirical process of obtaining and adjusting its parameters from plots of the traces. Also, the proposed model does not represent multiprogramming environments, where context switches occur frequently. Our paper extends the work referenced in <ref> [34, 33, 32] </ref> to the context of large distributed systems and also introduces new parameters that fully describe locality aspects of a reference stream that arrives at a Web server. 6.3 Exploiting Web Reference Locality Previous studies in caching, replication, dissemination, and prefetching protocols for large distributed information systems have recognized
Reference: [34] <author> Jean Voldman, Benoit Mandelbrot, Lee W. Hoevel, Joshua Knight, and Philip L. Rosenfeld. </author> <title> Fractal nature of software-cache interaction. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 27(2) </volume> <pages> 164-170, </pages> <year> 1983. </year>
Reference-contexts: A timeseries with long-range dependence appears much more "bursty" than series with only short-range or no dependence | which agrees with generally observed characterizations of reference locality. Long-range dependence in the stack distance series is also related to previously noted fractal properties of cache miss patterns <ref> [34] </ref>, and we interpret prior work in fractal reference patterns in terms of our observations. This method of measuring spatial locality also provides an interpretation for the notion of spatial locality when reference streams are composed of symbols rather than numbers. <p> The corresponds with intuition: a series with more dependence is more "predictable" and fills space less completely. The fractal properties of stack-distance series serve to place earlier work by Voldman et. al. <ref> [34] </ref> in a slightly broader context. Those authors found that patterns of cache misses often form random fractals. <p> the distance probabilities, are not suitable for simulation studies of program behavior, because they lack the ability to mimic long-range effects. 6.2 Application of Fractals to Reference Modeling The use of fractal geometry and self-similarity to analyze behavior of computer systems was pioneered by the work of Voldman et al <ref> [34] </ref>. The authors looked at memory reference traces of three software environments and found that the distributions of intermiss distances are hyperbolic. The cache misses are grouped over time in clusters, which are statistically self-similar. <p> Covering this literature is beyond the scope of this paper. 16 Based on the work in <ref> [34] </ref>, paper [33] models the patterns generated by a processor accessing memory as random walk with fractal dimension. The author proposes that in an asymptotic behavior the number of misses that a program encounters in an infinite cache is given by a hyperbolic function of the fractal dimension. <p> However, the model is not easily used because of the empirical process of obtaining and adjusting its parameters from plots of the traces. Also, the proposed model does not represent multiprogramming environments, where context switches occur frequently. Our paper extends the work referenced in <ref> [34, 33, 32] </ref> to the context of large distributed systems and also introduces new parameters that fully describe locality aspects of a reference stream that arrives at a Web server. 6.3 Exploiting Web Reference Locality Previous studies in caching, replication, dissemination, and prefetching protocols for large distributed information systems have recognized
Reference: [35] <author> Stephen Williams, Marc Abramsand Charles R. Standridge, Ghaleb Abdulla, and Ed-ward A. Fox. </author> <title> Removal policies in network caches for world-wide web documents. </title> <address> http://ei.cs.vt.edu/ succeed/96WAASF1/, </address> <year> 1996. </year>
Reference-contexts: This finding agrees with Glassman's predictions [17] and was further confirmed for general proxy caching by Abrams et al [1]. Williams et al <ref> [35] </ref> present a taxonomy (and compare the performance) of a number of proxy cache replacement policies. Their work suggests that proxy cache management should consider document sizes when making replacement decisions.
Reference: [36] <author> G. K. Zipf. </author> <title> Human Behavior and the Principle of Least-Effort. </title> <publisher> Addison-Wesley, </publisher> <address> Cambridge, MA, </address> <year> 1949. </year>
Reference-contexts: In these studies, it was shown that "Popular files are very popular" [5, 18]. In [12], Cunha, Bestavros, and Crovella characterized the popularity of Web documents requested by clients and confirmed the applicability of Zipf's law <ref> [36, discussed in [23] </ref>] to Web documents. Zipf's law was originally applied to the 2 Since we have shown in previous work [12] that document size is correlated with expected reference frequency, this assumption is somewhat limiting for direct use in cache performance analysis.
References-found: 36

