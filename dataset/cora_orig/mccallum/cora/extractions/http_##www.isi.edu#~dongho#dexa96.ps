URL: http://www.isi.edu/~dongho/dexa96.ps
Refering-URL: http://www.isi.edu/~dongho/publications.html
Root-URL: http://www.isi.edu
Title: On-line Reorganization of Data in Scalable Continuous Media Servers  
Author: Shahram Ghandeharizadeh and Dongho Kim 
Address: Los Angeles, California 90089  
Affiliation: Department of Computer Science University of Southern California  
Abstract: The number of simultaneous displays supported by a continuous media server (e.g, Mitra) depends on the number of disk drives as well as the amount of memory in the system. To support a higher number of displays, one may increase the number of disks in the system and reorganize the placement of data to incorporate their bandwidth. This study presents alternative on-line reorganization techniques that modify the placement of data without disrupting service. We quantify the memory and disk storage requirements of these techniques using analytical models.
Abstract-found: 1
Intro-found: 1
Reference: [BGMJ94] <author> S. Berson, S. Ghandeharizadeh, R. Muntz, and X. Ju. </author> <title> Staggered Striping in Multimedia Information Systems. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <year> 1994. </year>
Reference-contexts: For example, a two hour MPEG-2 encoded video clip requiring 4 Megabit per second bandwidth (Mbps) for its display is 3.6 Gigabyte in size. Given a hardware platform with D disks, a scalable server would stripe (e.g., staggered striping <ref> [BGMJ94] </ref>) a clip across the disks. This would enable the system to distribute the work imposed by a display evenly across the D disks. <p> the placement of data (as an on-line operation) to incorporate the bandwidth of new disks. 2 Target Environment Our target architecture for supporting continuous media applications (e.g., Mitra [GZS + ]) is hierarchical, consisting of: a tertiary storage device (e.g., tape robots), a group of disk drives, and some memory <ref> [GZS + , GS93, MWS93, BGMJ94] </ref>. Hierarchical storage managers reduce the cost of storing large files, such as those corresponding to audio and video clips. <p> Simple striping with four clusters Fig. 2. Simple striping with six clusters bandwidth of at least d = d R C R D e disk drives to support a continuous display of an object. This can be achieved by a method termed Simple Striping <ref> [BGMJ94] </ref>. First, the D disk drives in the system are partitioned into C = b D d c disk clusters. Next, each object in the database (say X) is organized as a sequence of n equi-sized blocks (X 0 , X 1 , ..., X n1 ). <p> The duration of a time slot is dependent on the physical characteristic of the secondary storage device (its seek and latency time, and transfer rate), and the size of the fragments. The fragment size is a parameter that might be decided at the system configuration time <ref> [BGMJ94] </ref>. Fig. 4. On-line reorganization The number of simultaneous displays supported by a continuous media server (e.g, Mitra [GZS + ]) depends on the number of disk clusters as well as the amount of memory in the system [CP93, RV93, TPBG93, RW94, BGMJ94, GK95]. <p> Fig. 4. On-line reorganization The number of simultaneous displays supported by a continuous media server (e.g, Mitra [GZS + ]) depends on the number of disk clusters as well as the amount of memory in the system <ref> [CP93, RV93, TPBG93, RW94, BGMJ94, GK95] </ref>. To increase this number, one may increase the number of disk clusters in the system. <p> minutes to reorganize the entire file system with this optimization 5 with no extra memory requirement. 3.4 Storage and Memory Requirement In a scalable continuous media server that employs round robin data placement on its disk clusters, the system has to follow only one scheduling paradigm at a given time <ref> [CP93, RV93, TPBG93, BGMJ94, GK95, GKSZ96] </ref>. During the reorganization process, two different data placements (P orig and P new ) for the different files will coexist in the system.
Reference: [CDRS89] <author> M. Carey, D. DeWitt, J. Richardson, and E. Shekita. </author> <title> Storage management for objects in EXODUS. </title> <editor> In W. Kim and F. Lochovsky, editors, </editor> <booktitle> Object-Oriented Concepts, Databases, and Applications, </booktitle> <pages> pages 341-371. </pages> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: This is achieved by assigning a fraction of system resources to the reorganization process. The primary advantage of on-line reorganization is that it provides uninterrupted service to clients when performed during off-peak hours. Uninterrupted service is important in several emerging application domains <ref> [CDRS89, SSU91] </ref>. For example, a continuous media server might be an integral component of a health-care information system that enables physicians at different hospitals to view surgery procedures on demand. This server might be deployed for use in emergency rooms as a reference source.
Reference: [CP93] <author> P. M. Chen and D. Paterson. </author> <title> A new approach to I/O performance evaluation - self-scaling I/O benchmarks, predicted I/O performance. </title> <booktitle> In Proceedings of the 1993 ACM SIGMETRICS Int'l Conf. on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Fig. 4. On-line reorganization The number of simultaneous displays supported by a continuous media server (e.g, Mitra [GZS + ]) depends on the number of disk clusters as well as the amount of memory in the system <ref> [CP93, RV93, TPBG93, RW94, BGMJ94, GK95] </ref>. To increase this number, one may increase the number of disk clusters in the system. <p> minutes to reorganize the entire file system with this optimization 5 with no extra memory requirement. 3.4 Storage and Memory Requirement In a scalable continuous media server that employs round robin data placement on its disk clusters, the system has to follow only one scheduling paradigm at a given time <ref> [CP93, RV93, TPBG93, BGMJ94, GK95, GKSZ96] </ref>. During the reorganization process, two different data placements (P orig and P new ) for the different files will coexist in the system.
Reference: [GD90] <author> S. Ghandeharizadeh and D. DeWitt. </author> <title> A multiuser performance analysis of alternative declustering strategies. </title> <booktitle> In Proceedings of International Conference on Database Engineering, </booktitle> <year> 1990. </year>
Reference-contexts: Each block X i represents a contiguous portion of X. When X is materialized from the tertiary storage device, its blocks are assigned to the clusters in a round-robin manner, starting with an available cluster. In a cluster, a block is declustered <ref> [RE78, LKB87, GD90] </ref> into d pieces (fragments), with each fragment assigned to a different disk drive in the cluster. To illustrate, in Figure 1, a system consisting of eight disks is organized into four clusters (C=4, D=8), each cluster consisting of two disks.
Reference: [GK95] <author> S. Ghandeharizadeh and S. H. Kim. </author> <title> Striping in Multi-disk Video Servers. </title> <booktitle> In SPIE International Symposium on Photonics Technologies and Systems for Voice, Video, and Data Communications, </booktitle> <month> October </month> <year> 1995. </year>
Reference-contexts: Fig. 4. On-line reorganization The number of simultaneous displays supported by a continuous media server (e.g, Mitra [GZS + ]) depends on the number of disk clusters as well as the amount of memory in the system <ref> [CP93, RV93, TPBG93, RW94, BGMJ94, GK95] </ref>. To increase this number, one may increase the number of disk clusters in the system. <p> The length of the pattern (i.e., the number of time periods), termed Cycle Length, is: Cycle Length = LCM + 1. The extra time period per cycle is attributed to our assumption that the system cannot read and write during one time period <ref> [YCK93, GK95, GZS + ] </ref>. During reorganization, the available bandwidth of newly introduced clusters are used only to write blocks. The bandwidth of original clusters is used to both read and write blocks. <p> minutes to reorganize the entire file system with this optimization 5 with no extra memory requirement. 3.4 Storage and Memory Requirement In a scalable continuous media server that employs round robin data placement on its disk clusters, the system has to follow only one scheduling paradigm at a given time <ref> [CP93, RV93, TPBG93, BGMJ94, GK95, GKSZ96] </ref>. During the reorganization process, two different data placements (P orig and P new ) for the different files will coexist in the system.
Reference: [GK96] <author> S. Ghandeharizadeh and Dongho Kim. </author> <title> On-line Reorganization of Data in Scalable Continuous Media Servers. </title> <type> Technical Report USC-CS-TR96-634, </type> <institution> USC, </institution> <year> 1996. </year>
Reference-contexts: ? (2) How does the system display an object that is not yet reorganized (P orig (X)) using S new ? (3) How does the system switch from S orig to S new without disrupting the cur rent displays? Due to lack of space, we refer the interested reader to <ref> [GK96] </ref> for a discussion of these topics. We can reduce temporary memory and/or disk space requirement by using two alternative hybrid methods of maintaining and deleting original blocks. <p> We quantified both the memory and disk storage requirements of these techniques using analytical models. These techniques are presented based on a special case of staggered striping, i.e., simple striping. For other cases of staggered striping, these techniques can be extended without fundamental changes <ref> [GK96] </ref>.
Reference: [GKSZ96] <author> S. Ghandeharizadeh, S. H. Kim, C. Shahabi, and R. Zimmermann. </author> <title> Placement of Continuous Media in Multi-Zone Disks. </title> <editor> In S. Chung, editor, </editor> <title> Multimedia Information Storage and Management. </title> <publisher> Kluwer, </publisher> <year> 1996. </year>
Reference-contexts: minutes to reorganize the entire file system with this optimization 5 with no extra memory requirement. 3.4 Storage and Memory Requirement In a scalable continuous media server that employs round robin data placement on its disk clusters, the system has to follow only one scheduling paradigm at a given time <ref> [CP93, RV93, TPBG93, BGMJ94, GK95, GKSZ96] </ref>. During the reorganization process, two different data placements (P orig and P new ) for the different files will coexist in the system.
Reference: [GS93] <author> S. Ghandeharizadeh and C. Shahabi. </author> <title> Management of Physical Replicas in Parallel Multimedia Information Systems. </title> <booktitle> In Proceedings of the Foundations of Data Organization and Algorithms (FODO) Conference, </booktitle> <month> October </month> <year> 1993. </year>
Reference-contexts: the placement of data (as an on-line operation) to incorporate the bandwidth of new disks. 2 Target Environment Our target architecture for supporting continuous media applications (e.g., Mitra [GZS + ]) is hierarchical, consisting of: a tertiary storage device (e.g., tape robots), a group of disk drives, and some memory <ref> [GZS + , GS93, MWS93, BGMJ94] </ref>. Hierarchical storage managers reduce the cost of storing large files, such as those corresponding to audio and video clips. <p> economical to stage the data at the different levels of hierarchy in the following manner: a small fraction of referenced objects in memory for immediate display, a number of frequently accessed objects (e.g., the popular movie titles) on the disk drives, and the remaining objects on the tertiary storage device <ref> [GS93] </ref>. Audio and video objects must be retrieved and displayed at a pre-specified bandwidth. Otherwise, their display might suffer from frequent disruptions and delays. In this paper, we focus on the display of these objects from magnetic disks.
Reference: [GZS + ] <author> S. Ghandeharizadeh, R. Zimmermann, W. Shi, R. Rejaie, D. Ierardi, and T. Li. Mitra: </author> <title> A Scalable Continuous Media Server. </title> <note> Submitted to PDIS '96. </note>
Reference-contexts: 1 Introduction A scalable continuous media server (e.g., Mitra <ref> [GZS + ] </ref>) supports the continuous display of audio and video clips. The number of simultaneous displays supported by a system is a function of the available disk bandwidth. This is because continuous media objects, in particular video, are large in size and almost always disk resident. <p> This study introduces on-line reorganization techniques that enable a continuous media server to modify the placement of data (as an on-line operation) to incorporate the bandwidth of new disks. 2 Target Environment Our target architecture for supporting continuous media applications (e.g., Mitra <ref> [GZS + ] </ref>) is hierarchical, consisting of: a tertiary storage device (e.g., tape robots), a group of disk drives, and some memory [GZS + , GS93, MWS93, BGMJ94]. Hierarchical storage managers reduce the cost of storing large files, such as those corresponding to audio and video clips. <p> The fragment size is a parameter that might be decided at the system configuration time [BGMJ94]. Fig. 4. On-line reorganization The number of simultaneous displays supported by a continuous media server (e.g, Mitra <ref> [GZS + ] </ref>) depends on the number of disk clusters as well as the amount of memory in the system [CP93, RV93, TPBG93, RW94, BGMJ94, GK95]. To increase this number, one may increase the number of disk clusters in the system. <p> The length of the pattern (i.e., the number of time periods), termed Cycle Length, is: Cycle Length = LCM + 1. The extra time period per cycle is attributed to our assumption that the system cannot read and write during one time period <ref> [YCK93, GK95, GZS + ] </ref>. During reorganization, the available bandwidth of newly introduced clusters are used only to write blocks. The bandwidth of original clusters is used to both read and write blocks.
Reference: [Hwa93] <author> Kai Hwang. </author> <title> Advanced Computer Architecture: Parallelism, Scalability, </title> <booktitle> Programmability, </booktitle> <pages> pages 221-223. </pages> <publisher> McGraw-Hill, Inc., </publisher> <year> 1993. </year>
Reference-contexts: This server might be deployed for use in emergency rooms as a reference source. Such a server might not tolerate the down-time introduced by an off-line reorganization process. Hardware vendors have recognized the importance of uninterrupted service by introducing mass storage components that feature hot-swap or live-insertion capability <ref> [Qui96, IEE, Hwa93] </ref> (e.g., HP NetServer Storage System/6 [Pac95] and IBM Hot Swap Hard Disk Drives with IBM Hot Swap Expansion Enclosure [IBM95]). With these systems, one might introduce new "hot-swappable" disk drives without shutting down the system.
Reference: [IBM95] <author> IBM. </author> <title> DASD Hot Swap Expansion Enclosure and Hot Swap Hard Disk Drives, </title> <month> August 31 </month> <year> 1995. </year> <title> Product Catalog of Options IBM. </title>
Reference-contexts: Hardware vendors have recognized the importance of uninterrupted service by introducing mass storage components that feature hot-swap or live-insertion capability [Qui96, IEE, Hwa93] (e.g., HP NetServer Storage System/6 [Pac95] and IBM Hot Swap Hard Disk Drives with IBM Hot Swap Expansion Enclosure <ref> [IBM95] </ref>). With these systems, one might introduce new "hot-swappable" disk drives without shutting down the system.
Reference: [IEE] <author> IEEE. </author> <title> IEEE Standard for Futurebus+ Physical Layer and Profile Specification. </title> <publisher> IEEE Std 896.2-1991. </publisher>
Reference-contexts: This server might be deployed for use in emergency rooms as a reference source. Such a server might not tolerate the down-time introduced by an off-line reorganization process. Hardware vendors have recognized the importance of uninterrupted service by introducing mass storage components that feature hot-swap or live-insertion capability <ref> [Qui96, IEE, Hwa93] </ref> (e.g., HP NetServer Storage System/6 [Pac95] and IBM Hot Swap Hard Disk Drives with IBM Hot Swap Expansion Enclosure [IBM95]). With these systems, one might introduce new "hot-swappable" disk drives without shutting down the system.
Reference: [LKB87] <author> M. Livny, S. Khoshafian, and H. Boral. </author> <title> Multi-Disk Management Algorithms. </title> <booktitle> In Proceedings of the 1987 ACM SIGMETRICS Int'l Conf. on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1987. </year>
Reference-contexts: Each block X i represents a contiguous portion of X. When X is materialized from the tertiary storage device, its blocks are assigned to the clusters in a round-robin manner, starting with an available cluster. In a cluster, a block is declustered <ref> [RE78, LKB87, GD90] </ref> into d pieces (fragments), with each fragment assigned to a different disk drive in the cluster. To illustrate, in Figure 1, a system consisting of eight disks is organized into four clusters (C=4, D=8), each cluster consisting of two disks.
Reference: [MWS93] <author> D. Maier, J. Walpole, and R. Staehli. </author> <title> Storage System Architectures for Continuous Media Data. </title> <booktitle> In Proceedings of the Foundations of Data Organization and Algorithms (FODO) Conference, </booktitle> <month> October </month> <year> 1993. </year>
Reference-contexts: the placement of data (as an on-line operation) to incorporate the bandwidth of new disks. 2 Target Environment Our target architecture for supporting continuous media applications (e.g., Mitra [GZS + ]) is hierarchical, consisting of: a tertiary storage device (e.g., tape robots), a group of disk drives, and some memory <ref> [GZS + , GS93, MWS93, BGMJ94] </ref>. Hierarchical storage managers reduce the cost of storing large files, such as those corresponding to audio and video clips.
Reference: [Pac95] <institution> Hewlett Packard. HP Introduces The HP NetServer Storage System/6, </institution> <month> September 25 </month> <year> 1995. </year> <note> HP Press Release. </note>
Reference-contexts: Such a server might not tolerate the down-time introduced by an off-line reorganization process. Hardware vendors have recognized the importance of uninterrupted service by introducing mass storage components that feature hot-swap or live-insertion capability [Qui96, IEE, Hwa93] (e.g., HP NetServer Storage System/6 <ref> [Pac95] </ref> and IBM Hot Swap Hard Disk Drives with IBM Hot Swap Expansion Enclosure [IBM95]). With these systems, one might introduce new "hot-swappable" disk drives without shutting down the system.
Reference: [Qui96] <author> Richard A. Quinnell. </author> <title> Live Insertion: Do it without Killing Your System. </title> <journal> EDN magazine, </journal> <month> February 1 </month> <year> 1996. </year>
Reference-contexts: This server might be deployed for use in emergency rooms as a reference source. Such a server might not tolerate the down-time introduced by an off-line reorganization process. Hardware vendors have recognized the importance of uninterrupted service by introducing mass storage components that feature hot-swap or live-insertion capability <ref> [Qui96, IEE, Hwa93] </ref> (e.g., HP NetServer Storage System/6 [Pac95] and IBM Hot Swap Hard Disk Drives with IBM Hot Swap Expansion Enclosure [IBM95]). With these systems, one might introduce new "hot-swappable" disk drives without shutting down the system.
Reference: [RE78] <author> D. Ries and R. Epstein. </author> <title> Evaluation of distribution criteria for distributed database systems. </title> <type> UCB/ERL Technical Report M78/22, </type> <institution> UC Berkeley, </institution> <month> May </month> <year> 1978. </year>
Reference-contexts: Each block X i represents a contiguous portion of X. When X is materialized from the tertiary storage device, its blocks are assigned to the clusters in a round-robin manner, starting with an available cluster. In a cluster, a block is declustered <ref> [RE78, LKB87, GD90] </ref> into d pieces (fragments), with each fragment assigned to a different disk drive in the cluster. To illustrate, in Figure 1, a system consisting of eight disks is organized into four clusters (C=4, D=8), each cluster consisting of two disks.
Reference: [RV93] <author> P. Rangan and H. Vin. </author> <title> Efficient Storage Techniques for Digital Continuous Media. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 5(4), </volume> <month> August </month> <year> 1993. </year>
Reference-contexts: Fig. 4. On-line reorganization The number of simultaneous displays supported by a continuous media server (e.g, Mitra [GZS + ]) depends on the number of disk clusters as well as the amount of memory in the system <ref> [CP93, RV93, TPBG93, RW94, BGMJ94, GK95] </ref>. To increase this number, one may increase the number of disk clusters in the system. <p> minutes to reorganize the entire file system with this optimization 5 with no extra memory requirement. 3.4 Storage and Memory Requirement In a scalable continuous media server that employs round robin data placement on its disk clusters, the system has to follow only one scheduling paradigm at a given time <ref> [CP93, RV93, TPBG93, BGMJ94, GK95, GKSZ96] </ref>. During the reorganization process, two different data placements (P orig and P new ) for the different files will coexist in the system.
Reference: [RW94] <author> A. L. N. Reddy and J. C. Wyllie. </author> <title> I/O Issues in a Multimedia System. </title> <journal> IEEE Computer Magazine, </journal> <volume> 27(3) </volume> <pages> 69-74, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Fig. 4. On-line reorganization The number of simultaneous displays supported by a continuous media server (e.g, Mitra [GZS + ]) depends on the number of disk clusters as well as the amount of memory in the system <ref> [CP93, RV93, TPBG93, RW94, BGMJ94, GK95] </ref>. To increase this number, one may increase the number of disk clusters in the system.
Reference: [SSU91] <author> A. Silberschatz, M. Stonebraker, and J. Ullman. </author> <title> Database systems: Achievements and opportunities. </title> <journal> Communications of the ACM, </journal> <month> October </month> <year> 1991. </year>
Reference-contexts: This is achieved by assigning a fraction of system resources to the reorganization process. The primary advantage of on-line reorganization is that it provides uninterrupted service to clients when performed during off-peak hours. Uninterrupted service is important in several emerging application domains <ref> [CDRS89, SSU91] </ref>. For example, a continuous media server might be an integral component of a health-care information system that enables physicians at different hospitals to view surgery procedures on demand. This server might be deployed for use in emergency rooms as a reference source.
Reference: [TPBG93] <author> F.A. Tobagi, J. Pang, R. Baird, and M. Gang. </author> <title> Streaming RAID-A Disk Array Management System for Video Files. </title> <booktitle> In First ACM Conference on Multimedia, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: Fig. 4. On-line reorganization The number of simultaneous displays supported by a continuous media server (e.g, Mitra [GZS + ]) depends on the number of disk clusters as well as the amount of memory in the system <ref> [CP93, RV93, TPBG93, RW94, BGMJ94, GK95] </ref>. To increase this number, one may increase the number of disk clusters in the system. <p> minutes to reorganize the entire file system with this optimization 5 with no extra memory requirement. 3.4 Storage and Memory Requirement In a scalable continuous media server that employs round robin data placement on its disk clusters, the system has to follow only one scheduling paradigm at a given time <ref> [CP93, RV93, TPBG93, BGMJ94, GK95, GKSZ96] </ref>. During the reorganization process, two different data placements (P orig and P new ) for the different files will coexist in the system.
Reference: [YCK93] <author> P.S. Yu, M-S. Chen, and D.D. Kandlur. </author> <title> Grouped sweeping scheduling for DASD-based multimedia storage management. </title> <journal> Multimedia Systems, </journal> <volume> 1(1) </volume> <pages> 99-109, </pages> <month> January </month> <year> 1993. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: The length of the pattern (i.e., the number of time periods), termed Cycle Length, is: Cycle Length = LCM + 1. The extra time period per cycle is attributed to our assumption that the system cannot read and write during one time period <ref> [YCK93, GK95, GZS + ] </ref>. During reorganization, the available bandwidth of newly introduced clusters are used only to write blocks. The bandwidth of original clusters is used to both read and write blocks.
References-found: 22

