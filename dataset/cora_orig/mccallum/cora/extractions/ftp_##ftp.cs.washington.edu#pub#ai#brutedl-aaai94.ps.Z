URL: ftp://ftp.cs.washington.edu/pub/ai/brutedl-aaai94.ps.Z
Refering-URL: http://www.cs.washington.edu/homes/segal/resume.html
Root-URL: 
Email: fsegal, etzionig@cs.washington.edu  
Title: Learning Decision Lists Using Homogeneous Rules  
Author: Richard Segal and Oren Etzioni 
Note: Appears in AAAI-94  
Address: Seattle, WA 98195  
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract: rules (Rivest 1987). Inductive algorithms such as AQ and CN2 learn decision lists incrementally, one rule at a time. Such algorithms face the rule overlap problem | the classification accuracy of the decision list depends on the overlap between the learned rules. Thus, even though the rules are learned in isolation, they can only be evaluated in concert. Existing algorithms solve this problem by adopting a greedy, iterative structure. Once a rule is learned, the training examples that match the rule are removed from the training set. We propose a novel solution to the problem: composing decision lists from homogeneous rules, rules whose classification accuracy does not change with their position in the decision list. We prove that the problem of finding a maximally accurate decision list can be reduced to the problem of finding maximally accurate homogeneous rules. We report on the performance of our algorithm on data sets from the UCI repository and on the MONK's problems. 
Abstract-found: 1
Intro-found: 1
Reference: <author> W. Buntine and R. Caruana. </author> <title> Introduction to IND and recursive partitioning. </title> <institution> NASA Ames Research Center, Mail Stop 269-2 Moffet Field, </institution> <address> CA 94035, </address> <year> 1991. </year>
Reference-contexts: Experimental Results We ran BruteDL on several data sets from the UCI repository (Murphy 1994) 2 and on all the data sets from the MONK's competition (Thrun et al. 1991). The results are shown in Table 3. For comparison, the results for the IND <ref> (Buntine and Caruana 1991) </ref> implementation of C4 (Quinlan 1986) are also included. The results for the UCI data sets are averaged over 10 iterations. Each iteration randomly splits the available data into 70% for training and 30% for testing.
Reference: <author> P. Clark and T. Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 261-283, </pages> <month> March </month> <year> 1989. </year>
Reference: <author> R. S. Michalski. </author> <title> On the quasi-minimal solution of the general covering problem. </title> <booktitle> In Proceedings of the Fifth International Symposium on Information Processing, </booktitle> <pages> pages 125-128, </pages> <address> Bled, Yugoslavia, </address> <year> 1969. </year>
Reference: <author> Patrick M. Murphy and Michael J. Pazzani. </author> <title> Exploring the decision forest: An empirical investigation of Occam's razor in decision tree induction. </title> <note> Submitted to Artificial Intelligence Research, </note> <year> 1994. </year>
Reference: <author> Patrick M. Murphy. </author> <title> UCI repository of machine learning databases. [Machine-readable data repository]. </title> <address> Irvine, CA. </address> <institution> University of California, Department of Information and Computer Science., </institution> <year> 1994. </year>
Reference: <author> T. Niblett. </author> <title> Constructing decision trees in noisy domains. </title> <booktitle> In Progress in Machine Learning (Proceedings of the 2nd European Working Session on Learning), </booktitle> <pages> pages 67-78, </pages> <address> Wilmslow, UK, </address> <year> 1987. </year>
Reference-contexts: In practice, BruteDL is only given a set of training data from which it must approximate P and determine which rules are homogeneous. BruteDL uses LaplaceAccuracy as an approximation of the actual accuracy of a rule <ref> (Niblett 1987) </ref>. Let r be a rule that classifies r p training examples correctly out of the r n training examples it matches. Let jGj denote the number of goal classes.
Reference: <author> G. Pagallo and D. Haussler. </author> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 5(1) </volume> <pages> 71-100, </pages> <month> March </month> <year> 1990. </year>
Reference: <author> J. R. Quinlan. </author> <title> Simplifying decision trees. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 27 </volume> <pages> 221-234, </pages> <year> 1986. </year>
Reference-contexts: The results are shown in Table 3. For comparison, the results for the IND (Buntine and Caruana 1991) implementation of C4 <ref> (Quinlan 1986) </ref> are also included. The results for the UCI data sets are averaged over 10 iterations. Each iteration randomly splits the available data into 70% for training and 30% for testing. The MONK's problems specify both the training set and test set to use for each problem.
Reference: <author> Patricia Riddle, Richard Segal, and Oren Etzioni. </author> <title> Representation design and brute-force induction in a Boeing manufacturing domain. </title> <journal> Applied Artificial Intelligence, </journal> <volume> 8 </volume> <pages> 125-147, </pages> <year> 1994. </year> <note> Available via anonymous FTP from /pub/ai at cs.washington.edu. </note>
Reference: <author> R. Rivest. </author> <title> Learning decision trees. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 229-246, </pages> <year> 1987. </year>
Reference-contexts: Introduction A decision list is an ordered list of conjunctive rules <ref> (Rivest 1987) </ref>. A decision list classifies examples by assigning to each example the class associated with the first conjunctive rule that matches the example. The decision list induction problem is to identify, from a set of training examples, the decision list that will most accurately classify future examples. <p> Finally, poor rule choices at the beginning of the list can significantly reduce the accuracy of the decision list learned. Nevertheless, Rivest showed that a greedy, iterative algorithm can provably PAC learn the concept class k-DL, decision lists composed of rules of length at most k <ref> (Rivest 1987) </ref>. However, Rivest's PAC guarantee pre supposes there exist 100% accurate rules of length at most k that cover the training examples.
Reference: <author> Wesley C. Salmon. </author> <title> Scientific Explanation and the Causal Structure of the World. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1984. </year>
Reference: <author> J. C. Schlimmer. </author> <title> Efficiently inducing determinations: A complete and systematic search algorithm that uses optimal pruning. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <address> Amherst, MA, </address> <month> June </month> <year> 1993. </year>
Reference: <author> P. Smyth and R. M. Goodman. </author> <title> Rule induction using information theory. </title> <booktitle> In Knowledge Discovery in Databases, </booktitle> <pages> pages 159-176. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: The results demonstrate the effectiveness of depth-bounded search on a complex real-world domain. Brute's running time on the two data sets was less than 3 CPU minutes on a SPARC-10 workstation. 3 nSeveral other systems have used depth-bounded search. ITRULE <ref> (Smyth and Goodman 1991) </ref>, like 3 We previously reported Brute's running time as 33 CPU minutes. We have since added additional pruning axioms that significantly improve Brute's efficiency. Brute, uses depth-bounded search to find accurate predictive rules. Schlimmer (1993) uses depth-bounded search to find determinations.
Reference: <author> S.B. Thrun, J. Bala, E. Bloedorn, I. Bratko, B. Ces-tnik J. Cheng, K. De Jong, S. Dzeroski, S. </author> <note> E. </note>
Reference: <author> Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J. Kreuziger, R.S. Michal-ski, T. Mitchell, P. Pachowicz, Y. Reich, H. Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang. </author> <title> The MONK's problems A performance comparison of different learning algorithms. </title> <type> Technical Report CS-CMU-91-197, </type> <institution> Carnegie Mellon University, </institution> <year> 1991. </year>
Reference: <author> Geoffrey I. Webb. </author> <title> Systematic search for categorical attribute-value data-driven machine learning. </title> <editor> In N. Foo and C. Rowles, editors, </editor> <booktitle> AI `93. World Scientific, </booktitle> <address> Singapore, </address> <year> 1993. </year>
Reference: <author> S. M. Weiss, R. S. Galen, and P. V. Tadepalli. </author> <title> Maximizing the predictive value of production rules. </title> <journal> Artificial Intelligence, </journal> <volume> 45 </volume> <pages> 47-71, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Furthermore, the greedy structure introduces dependencies among the decision list's rules that can make the decision list difficult to interpret. BruteDL's solution to the overlap problem avoids both these pitfalls by learning each rule in the decision list independently. The PVM system <ref> (Weiss et al. 1990) </ref> does a massive search of the space of classifiers.
References-found: 17

