URL: http://www.eecs.umich.edu/PPP/SIGMETRICS93.ps
Refering-URL: http://www.eecs.umich.edu/PPP/publist.html
Root-URL: http://www.cs.umich.edu
Email: email: rabin@eecs.umich.edu, sga@eecs.umich.edu  
Title: Efficient Simulation of Caches under Optimal Replacement with Applications to Miss Characterization  
Author: Rabin A. Sugumar and Santosh G. Abraham 
Address: Ann Arbor, MI 48109-2122  
Affiliation: Advanced Computer Architecture Laboratory Department of Electrical Engineering and Computer Science University of Michigan,  
Abstract: Cache miss characterization models such as the three Cs model are useful in developing schemes to reduce cache misses and their penalty. In this paper we propose the OPT model that uses cache simulation under optimal (OPT) replacement to obtain a finer and more accurate characterization of misses than the three Cs model. However, current methods for optimal cache simulation are slow and difficult to use. We present three new techniques for optimal cache simulation. First, we propose a limited lookahead strategy with error fixing, which allows one pass simulation of multiple optimal caches. Second, we propose a scheme to group entries in the OPT stack, which allows efficient tree-based fully-associative cache simulation under OPT. Third, we propose a scheme for exploiting partial inclusion in set-associative cache simulation under OPT. Simulators based on these algorithms were used to obtain cache miss characterizations using the OPT model for nine SPEC benchmarks. The results indicate that miss ratios under OPT are substantially lower than those under LRU replacement, by up to 70% in fully-associative caches, and up to 32% in two-way set-associative caches. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal. </author> <title> Analysis of Cache Performance for Operating Systems and Multiprogramming. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1988. </year> <note> Available as Technical Report CSL-TR-87-332. </note>
Reference-contexts: Thiebaut and Stone [21], Agarwal <ref> [1] </ref>, Hill [6, 5] and others have proposed models which can explain or classify misses. These models are useful both for gaining insight in developing caching strategies and also for evaluating these strategies.
Reference: [2] <author> L. A. Belady. </author> <title> A study of replacement algorithms for a virtual-storage computer. </title> <journal> IBM Systems Journal, </journal> <volume> 5(2) </volume> <pages> 78-101, </pages> <year> 1966. </year>
Reference-contexts: The OPT model for characterizing misses is described, and a miss characterization for nine of the SPEC benchmarks is presented in Section 6. Section 7 concludes the paper. 2 Related Work On a miss, optimal replacement <ref> [12, 2] </ref> replaces the block 2 that is re-referenced furthest in the future. Optimal replacement minimizes bus traffic over the class of all replacement algorithms when write-backs are ignored, and minimizes the cache miss ratio as well over the class of demand fetching algorithms. <p> Since it requires future information, it cannot be used in a real cache, and is mainly used in performance analysis. Belady, in his paper introducing optimal replacement <ref> [2] </ref>, describes an algorithm for simulating a single 2 We will use block and cache line interchangeably in this paper. cache under optimal replacement, where the decision on which address is replaced is delayed till there is no uncertainty.
Reference: [3] <author> B. T. Bennett and V. J. Kruskal. </author> <title> LRU stack processing. </title> <journal> IBM J. of Research and Development, </journal> <pages> pages 353-357, </pages> <month> July </month> <year> 1975. </year>
Reference-contexts: In this paper we propose a limited lookahead scheme to do single-pass optimal cache simulation without the reverse pass. The sequential list-based search of the stack is a bottleneck in stack simulation. This problem has been addressed for LRU replacement <ref> [3, 16, 22, 11] </ref>. These algorithms make use of the fact that the stack update is simple in LRU; the referenced entry is just moved from its current position to the top of the stack.
Reference: [4] <author> D. Gannon, W. Jalby, and K. Gallivan. </author> <title> Strategies for cache and local memory management by global program transformation. </title> <journal> J. of Par. and Dist. Comp., </journal> <volume> 5 </volume> <pages> 587-616, </pages> <year> 1988. </year>
Reference-contexts: Several strategies This research is supported in part by ONR contract N00014-93-1-0163. 0 This paper appeared in the Proceedings of the 1993 ACM SIGMETRICS Conference. have been proposed to improve cache performance, such as remapping basic blocks in memory [8, 14], blocking algorithms <ref> [4] </ref>, using two or more levels of caching, miss caches [10] and shadow directories [18]. Thiebaut and Stone [21], Agarwal [1], Hill [6, 5] and others have proposed models which can explain or classify misses.
Reference: [5] <author> J. L. Hennessy and D. A. Patterson. </author> <title> Computer Architecture | A Quantitive Approach. </title> <publisher> Morgan Kaufmann Publishers Inc., </publisher> <year> 1990. </year>
Reference-contexts: Thiebaut and Stone [21], Agarwal [1], Hill <ref> [6, 5] </ref> and others have proposed models which can explain or classify misses. These models are useful both for gaining insight in developing caching strategies and also for evaluating these strategies. <p> Some other comments and caveats about the miss components follow. Firstly, the compulsory miss component is negligible in most cases and much smaller than that reported for instance in <ref> [5] </ref>. Since we simulate much longer (or complete) traces, the cold start effects that contribute toward the compulsory miss component are amortized and are negligible. Furthermore, we simulate a single program at a time and do not account for multiprogramming effects [9].
Reference: [6] <author> M. D. Hill. </author> <title> Aspects of Cache Memory and Instruction Buffer Performance. </title> <type> PhD thesis, </type> <institution> University of Cali-fornia, Berkeley, </institution> <year> 1987. </year> <note> Available as Technical Report UCB/CSD 87/381. </note>
Reference-contexts: Thiebaut and Stone [21], Agarwal [1], Hill <ref> [6, 5] </ref> and others have proposed models which can explain or classify misses. These models are useful both for gaining insight in developing caching strategies and also for evaluating these strategies. <p> Second, the OPT model separately identifies mapping misses that occur as a result of the set mapping strategy and replacement 1 More precisely, Hill <ref> [6] </ref> defines capacity misses as the non-compulsory misses from a fully-associative cache using the same replacement strategy as that in the cache being characterized. Empirical characterizations have used LRU [6], and practical caches usually use LRU. misses that occur as a result of sub-optimal replacement inside a set. <p> model separately identifies mapping misses that occur as a result of the set mapping strategy and replacement 1 More precisely, Hill <ref> [6] </ref> defines capacity misses as the non-compulsory misses from a fully-associative cache using the same replacement strategy as that in the cache being characterized. Empirical characterizations have used LRU [6], and practical caches usually use LRU. misses that occur as a result of sub-optimal replacement inside a set. In the three Cs model this distinction is not made. The replacement strategy is thus included in the OPT model.
Reference: [7] <author> M. D. Hill and A. J. Smith. </author> <title> Evaluating associativity in CPU caches. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 38(12) </volume> <pages> 1612-1630, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: This grouping enables efficient tree or multilevel list implementations for optimal replacement too. Single-pass set-associative cache simulation where the number of sets and the associativity are varied has been considered before for LRU replacement. Three algorithms have been proposed: all-associativity simulation <ref> [12, 7] </ref>, generalized binomial forest simulation [19] and generalized forest simulation [7]. In this paper we describe an adaptation to the generalized forest simulation algorithm, which greatly increases the efficiency of set-associative cache simulation under OPT. <p> Single-pass set-associative cache simulation where the number of sets and the associativity are varied has been considered before for LRU replacement. Three algorithms have been proposed: all-associativity simulation [12, 7], generalized binomial forest simulation [19] and generalized forest simulation <ref> [7] </ref>. In this paper we describe an adaptation to the generalized forest simulation algorithm, which greatly increases the efficiency of set-associative cache simulation under OPT. When cache bypass is permitted the referenced line need not be put in the cache, and is itself one of the candidates for replacement. <p> The lookahead routine works exactly as described earlier. For stack processing an adaptation of generalized forest simulation is used. Generalized forest simulation (FS+) is a single-pass cache simulation algorithm for set associative caches under LRU replacement <ref> [7] </ref>. FS+ exploits the property that with LRU replacement, when a line is found at the stack-top for one degree of mapping (number of sets) it is found at the stack-top for other degrees as well.
Reference: [8] <author> W. W. Hwu and P. P. Chang. </author> <title> Achieving high instruction cache performance with an optimizing compiler. </title> <booktitle> In Proc. of 16th Intl. Symp. on Computer Architecture, </booktitle> <pages> pages 242-251, </pages> <year> 1989. </year>
Reference-contexts: Several strategies This research is supported in part by ONR contract N00014-93-1-0163. 0 This paper appeared in the Proceedings of the 1993 ACM SIGMETRICS Conference. have been proposed to improve cache performance, such as remapping basic blocks in memory <ref> [8, 14] </ref>, blocking algorithms [4], using two or more levels of caching, miss caches [10] and shadow directories [18]. Thiebaut and Stone [21], Agarwal [1], Hill [6, 5] and others have proposed models which can explain or classify misses.
Reference: [9] <author> W. W. Hwu and T. M. Conte. </author> <title> The susceptibility of programs to context switching. </title> <type> Technical Report CRHC-91-14, </type> <institution> Center for Reliable and High-Performance Computing, University of Illinois, Urbana, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: Since we simulate much longer (or complete) traces, the cold start effects that contribute toward the compulsory miss component are amortized and are negligible. Furthermore, we simulate a single program at a time and do not account for multiprogramming effects <ref> [9] </ref>. Multiprogramming tends to increase the number of compulsory misses. Secondly, mapping and replacement misses are quite large for the instruction traces. Software remapping of basic blocks of the programs was not performed, and is likely decrease the magnitude of these components.
Reference: [10] <author> N. P. Jouppi. </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers. </title> <booktitle> In Proc. of 17th Intl. Symp. on Computer Architecture, </booktitle> <pages> pages 364-373, </pages> <year> 1990. </year>
Reference-contexts: research is supported in part by ONR contract N00014-93-1-0163. 0 This paper appeared in the Proceedings of the 1993 ACM SIGMETRICS Conference. have been proposed to improve cache performance, such as remapping basic blocks in memory [8, 14], blocking algorithms [4], using two or more levels of caching, miss caches <ref> [10] </ref> and shadow directories [18]. Thiebaut and Stone [21], Agarwal [1], Hill [6, 5] and others have proposed models which can explain or classify misses. These models are useful both for gaining insight in developing caching strategies and also for evaluating these strategies.
Reference: [11] <author> Y. H. Kim, M. D. Hill, and D. A. Wood. </author> <title> Implementing stack simulation for highly-associative memories. </title> <booktitle> In Proc. ACM SIGMETRICS Conf., </booktitle> <pages> pages 212-213, </pages> <year> 1991. </year>
Reference-contexts: In this paper we propose a limited lookahead scheme to do single-pass optimal cache simulation without the reverse pass. The sequential list-based search of the stack is a bottleneck in stack simulation. This problem has been addressed for LRU replacement <ref> [3, 16, 22, 11] </ref>. These algorithms make use of the fact that the stack update is simple in LRU; the referenced entry is just moved from its current position to the top of the stack.
Reference: [12] <author> R. L. Mattson, J. Gecsei, D. R. Slutz, and I. L. Trai-ger. </author> <title> Evaluation techniques for storage hierarchies. </title> <journal> IBM Systems Journal, </journal> <volume> 9(2) </volume> <pages> 78-117, </pages> <year> 1970. </year>
Reference-contexts: The OPT model for characterizing misses is described, and a miss characterization for nine of the SPEC benchmarks is presented in Section 6. Section 7 concludes the paper. 2 Related Work On a miss, optimal replacement <ref> [12, 2] </ref> replaces the block 2 that is re-referenced furthest in the future. Optimal replacement minimizes bus traffic over the class of all replacement algorithms when write-backs are ignored, and minimizes the cache miss ratio as well over the class of demand fetching algorithms. <p> In 1970, Mattson et al <ref> [12] </ref> developed the notion of stack simulation which allows single-pass trace-driven simulation of many alternative caches, subject to several restrictions. The major restriction is that all caches use the same stack replacement algorithm. <p> This grouping enables efficient tree or multilevel list implementations for optimal replacement too. Single-pass set-associative cache simulation where the number of sets and the associativity are varied has been considered before for LRU replacement. Three algorithms have been proposed: all-associativity simulation <ref> [12, 7] </ref>, generalized binomial forest simulation [19] and generalized forest simulation [7]. In this paper we describe an adaptation to the generalized forest simulation algorithm, which greatly increases the efficiency of set-associative cache simulation under OPT. <p> The TNR attribute is used to assign priorities to each address reference; addresses whose TNR is unknown are treated as having lower priority than all knowns. The stack processing routine also maintains information required for stack repair. Below we briefly review the stack lookup and update procedure described in <ref> [12] </ref>. The objective of stack processing is to obtain the hit ratios of a range of fully-associative caches efficiently. A single stack maintains the contents of fully-associative caches of sizes ranging from one line to the maximum number of lines in the stack.
Reference: [13] <author> S. McFarling. </author> <title> Program Analysis and Optimization for Machines with Instruction Cache. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1988. </year> <note> Technical Report No. CSL-TR-91-493. </note>
Reference-contexts: In this paper we describe an adaptation to the generalized forest simulation algorithm, which greatly increases the efficiency of set-associative cache simulation under OPT. When cache bypass is permitted the referenced line need not be put in the cache, and is itself one of the candidates for replacement. Mcfarling <ref> [13] </ref> discusses OPT replacement with cache bypass. Cache bypass has a significant effect in set-associative caches with low associativities. After some minor modifications, the algorithms described in the paper can work with bypass.
Reference: [14] <author> S. McFarling. </author> <title> Program optimization for instruction caches. </title> <booktitle> In Proceedings of ASPLOS III, </booktitle> <year> 1989. </year>
Reference-contexts: Several strategies This research is supported in part by ONR contract N00014-93-1-0163. 0 This paper appeared in the Proceedings of the 1993 ACM SIGMETRICS Conference. have been proposed to improve cache performance, such as remapping basic blocks in memory <ref> [8, 14] </ref>, blocking algorithms [4], using two or more levels of caching, miss caches [10] and shadow directories [18]. Thiebaut and Stone [21], Agarwal [1], Hill [6, 5] and others have proposed models which can explain or classify misses.
Reference: [15] <editor> T. N. Mudge et al. </editor> <booktitle> The design of a microsupercom-puter. IEEE Computer, </booktitle> <pages> pages 57-64, </pages> <month> Jan </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Caches have an increasing impact on overall performance because of the growing gap between CPU cycle times and memory access times. Cache misses contribute significantly to the cycles per instruction (CPI) performance metric <ref> [15] </ref>. The effect that cache misses have on performance has led to research on methods to reduce cache misses or their penalty.
Reference: [16] <author> F. Olken. </author> <title> Efficient methods for calculating the success function of fixed space replacement policies. </title> <type> Technical Report LBL-12370, </type> <institution> Lawrence Berkeley Laboratory, </institution> <year> 1981. </year>
Reference-contexts: In this paper we propose a limited lookahead scheme to do single-pass optimal cache simulation without the reverse pass. The sequential list-based search of the stack is a bottleneck in stack simulation. This problem has been addressed for LRU replacement <ref> [3, 16, 22, 11] </ref>. These algorithms make use of the fact that the stack update is simple in LRU; the referenced entry is just moved from its current position to the top of the stack. <p> In the LRU tree algorithm, the time of previous reference of an address is obtained by a hash lookup. The hit depth is then determined by a tree lookup that uses this time as the key <ref> [16, 22] </ref>. In the OPT tree implementation, a list of groups is maintained numbered in order. A descriptor is associated with each group that contains the first and last addresses of the group, and the number of entries in the group.
Reference: [17] <author> D. D. Sleator and R. E. Tarjan. </author> <title> Self adjusting binary search trees. </title> <journal> J. of the ACM, </journal> <volume> 32(3) </volume> <pages> 652-686, </pages> <year> 1985. </year>
Reference-contexts: All execution times are in seconds and all other metrics are unitless. The tree-based algorithms use splay trees <ref> [17] </ref> which are self-balancing and well-suited for cache simulation. In the LRU tree algorithm, the time of previous reference of an address is obtained by a hash lookup. The hit depth is then determined by a tree lookup that uses this time as the key [16, 22].
Reference: [18] <author> H. S. Stone. </author> <title> High-Performance Computer Architecture. </title> <publisher> Addison-Wesley, </publisher> <address> 2 nd edition, </address> <year> 1987. </year>
Reference-contexts: part by ONR contract N00014-93-1-0163. 0 This paper appeared in the Proceedings of the 1993 ACM SIGMETRICS Conference. have been proposed to improve cache performance, such as remapping basic blocks in memory [8, 14], blocking algorithms [4], using two or more levels of caching, miss caches [10] and shadow directories <ref> [18] </ref>. Thiebaut and Stone [21], Agarwal [1], Hill [6, 5] and others have proposed models which can explain or classify misses. These models are useful both for gaining insight in developing caching strategies and also for evaluating these strategies.
Reference: [19] <author> R. A. Sugumar and S. G. Abraham. </author> <title> Efficient simulation of multiple cache configurations using binomial trees. </title> <type> Technical Report CSE-TR-111-91, </type> <institution> CSE Division, University of Michigan, </institution> <year> 1991. </year>
Reference-contexts: This grouping enables efficient tree or multilevel list implementations for optimal replacement too. Single-pass set-associative cache simulation where the number of sets and the associativity are varied has been considered before for LRU replacement. Three algorithms have been proposed: all-associativity simulation [12, 7], generalized binomial forest simulation <ref> [19] </ref> and generalized forest simulation [7]. In this paper we describe an adaptation to the generalized forest simulation algorithm, which greatly increases the efficiency of set-associative cache simulation under OPT.
Reference: [20] <author> R. A. Sugumar and S. G. Abraham. </author> <title> Efficient simulation of caches under optimal replacement with applications to miss characterization. </title> <type> Technical Report CSE-TR-143-92, </type> <institution> CSE Division, University of Michigan, </institution> <year> 1992. </year>
Reference-contexts: The dummy priority assignment forces an automatic encoding of information which may be used to do the stack repair. We just describe the scheme in this section; for a proof see <ref> [20] </ref>. The dummy priorities are assigned following the two rules below: 1. Each unknown is given a dummy priority lower than the priority of all knowns. 2.
Reference: [21] <author> D. Thiebaut. </author> <title> On the fractal dimension of computer programs and its application to the prediction of the cache miss ratio. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 38(7) </volume> <pages> 1012-1026, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Thiebaut and Stone <ref> [21] </ref>, Agarwal [1], Hill [6, 5] and others have proposed models which can explain or classify misses. These models are useful both for gaining insight in developing caching strategies and also for evaluating these strategies.
Reference: [22] <author> J. G. Thompson. </author> <title> Efficient analysis of Caching Systems. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1987. </year>
Reference-contexts: In this paper we propose a limited lookahead scheme to do single-pass optimal cache simulation without the reverse pass. The sequential list-based search of the stack is a bottleneck in stack simulation. This problem has been addressed for LRU replacement <ref> [3, 16, 22, 11] </ref>. These algorithms make use of the fact that the stack update is simple in LRU; the referenced entry is just moved from its current position to the top of the stack. <p> In the LRU tree algorithm, the time of previous reference of an address is obtained by a hash lookup. The hit depth is then determined by a tree lookup that uses this time as the key <ref> [16, 22] </ref>. In the OPT tree implementation, a list of groups is maintained numbered in order. A descriptor is associated with each group that contains the first and last addresses of the group, and the number of entries in the group.
References-found: 22

