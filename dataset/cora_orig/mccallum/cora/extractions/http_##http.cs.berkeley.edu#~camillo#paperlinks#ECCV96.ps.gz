URL: http://http.cs.berkeley.edu/~camillo/paperlinks/ECCV96.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~camillo/
Root-URL: 
Email: email: fcamillo,debevec,malikg@cs.berkeley.edu  
Phone: Fax: (510) 642 5775  
Title: Reconstructing Polyhedral Models of Architectural Scenes from Photographs  
Author: Camillo J. Taylor and Paul E. Debevec and Jitendra Malik 
Address: Berkeley, CA 94720-1776  
Affiliation: EECS Department, U.C. Berkeley  
Abstract: This paper presents a new image-based modeling method that facilitates the recovery of accurate polyhedral models of architectural scenes. The method is particularly effective because it exploits many of the constraints that are characteristic of architectural scenes. This work is placed in the context of the Fa~cade project, whose goal is to use images to produce photo-realistic novel views of architectural scenes.
Abstract-found: 1
Intro-found: 1
Reference: [DTM96] <author> Paul E. Debevec, Camillo J. Taylor, and Jitendra Malik. </author> <title> Modeling and rendering architecture from photographs: A hybrid geometry- and image-based approach. </title> <type> Technical Report UCB//CSD-96-893, </type> <institution> U.C. Berkeley, CS Division, </institution> <month> January </month> <year> 1996. </year>
Reference-contexts: This paper describes the techniques we have developed to solve the first stage of our modeling process: to interactively obtain polyhedral models of architectural scenes from images. A complete description of the entire system can be found in <ref> [DTM96] </ref>. Section 2 of this paper describes the interactive polyhedral modeling program, Fa~cade, along with the algorithms that have been developed to recover the parameters of a polyhedral model from image measurements. Some of the results obtained with the Fa~cade system are presented in this section. <p> Fig. 5 shows that the recovered model conforms to the photographs to within a pixel, indicating an accurate reconstruction. 3 Conclusion We have developed a two stage procedure, embodied in a system called Fa~cade, for recovering geometric models of architectural scenes from photographs <ref> [DTM96] </ref>. (a) (b) Fig. 5. Two of the twelve photographs used to reconstruct a high school building are shown in (a) and (b). The overlaid lines indicate the edges the user has marked.
Reference: [Fau93] <author> Olivier Faugeras. </author> <title> Three-Dimensional Computer Vision. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: While the genesis of these techniques goes back to the photogrammetric literature, there has been a considerable development in the computer vision community under the topics of stereopsis and structure from motion. A good survey of the knowledge in this field up to 1992 is provided in Faugeras's book <ref> [Fau93] </ref>. Later work has focused on the use of uncalibrated cameras [FLR + 95]. Most of the work that has been done on recovering the geometry of a scene from multiple images tackles the problem in its most general form.
Reference: [FLR + 95] <author> Olivier Faugeras, Stephane Laveau, Luc Robert, Gabriella Csurka, and Cyril Zeller. </author> <title> 3-d reconstruction of urban scenes from sequences of images. </title> <type> Technical Report Rapport de recherche 2572, </type> <institution> INRIA Sophia-Antipolis, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: A good survey of the knowledge in this field up to 1992 is provided in Faugeras's book [Fau93]. Later work has focused on the use of uncalibrated cameras <ref> [FLR + 95] </ref>. Most of the work that has been done on recovering the geometry of a scene from multiple images tackles the problem in its most general form. Their goal is typically to recover the 3D positions of a set of features, points or lines, from multiple image measurements.
Reference: [TK92] <author> Carlo Tomasi and Takeo Kanade. </author> <title> Shape and motion from image streams under orthography: a factorization method. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9(2) </volume> <pages> 137-154, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: This generality comes at a price-it is well known that the recovery of scene structure from multiple views is sensitive to noise. Long image sequences help <ref> [WHA89, WHA93, TK92] </ref>, but we believe that at least part of the difficulty comes from the fact that the traditional formulation does not exploit all of the available constraints.
Reference: [TK94] <author> Camillo J. Taylor and David J. Kriegman. </author> <title> Minimization on the lie group so(3) and related manifolds. </title> <type> Technical Report 9405, </type> <institution> Center for Systems Science, Dept. of Electrical Engineering, Yale University, </institution> <address> New Haven, CT, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: The error function used to measure the disparity Err i is presented in [TK95]. This non-linear objective function is minimized using a variant of the Newton-Raphson method described in <ref> [TK94] </ref>. The minimization procedure involves calculating the gradient and hessian of the objective function with respect to the model parameters and camera positions.
Reference: [TK95] <author> Camillo J. Taylor and David J. Kriegman. </author> <title> Structure and motion from line segments in multiple images. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> 17(11), </volume> <month> November </month> <year> 1995. </year>
Reference-contexts: Estimates for the unknown model parameters and camera positions are obtained by minimizing the objective function with respect to these variables. The error function used to measure the disparity Err i is presented in <ref> [TK95] </ref>. This non-linear objective function is minimized using a variant of the Newton-Raphson method described in [TK94]. The minimization procedure involves calculating the gradient and hessian of the objective function with respect to the model parameters and camera positions. <p> The first procedure recovers initial estimates for the camera rotations while the second provides initial estimates for the camera translations and the parameters of the model. Both of these procedures are based on techniques described in <ref> [TK95] </ref>. Once initial estimates have been obtained, the non-linear minimization over the entire parameter space is applied to produce a more accurate estimate for all of the unknown parameters. This stage typically reduces the error in the reconstruction by a factor of 2 to 4. 2.4 Results single image.
Reference: [WHA93] <author> Juyang Weng, Thomas S. Huang, and Narendra Ahuja. </author> <title> Motion and Structure from Image Sequences. </title> <booktitle> Springer Series on Information Sciences. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1993. </year>
Reference-contexts: This generality comes at a price-it is well known that the recovery of scene structure from multiple views is sensitive to noise. Long image sequences help <ref> [WHA89, WHA93, TK92] </ref>, but we believe that at least part of the difficulty comes from the fact that the traditional formulation does not exploit all of the available constraints.
Reference: [WHA89] <author> J. Weng, T.S. Huang, and N. Ahuja. </author> <title> Motion and structure from two perspective views: Algorithms, error analysis, and error estimation. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> 11(5) </volume> <pages> 451-476, </pages> <month> May 89. </month> <title> This article was processed using the L a T E X macro package with ECCV'96 style </title>
Reference-contexts: This generality comes at a price-it is well known that the recovery of scene structure from multiple views is sensitive to noise. Long image sequences help <ref> [WHA89, WHA93, TK92] </ref>, but we believe that at least part of the difficulty comes from the fact that the traditional formulation does not exploit all of the available constraints.
References-found: 8

