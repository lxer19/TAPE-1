URL: ftp://ftp.cs.unc.edu/pub/users/goddard/dimacs.ps.Z
Refering-URL: http://www.cs.unc.edu/~goddard/DissertationSummary.html
Root-URL: http://www.cs.unc.edu
Title: CONNECTED COMPONENTS ALGORITHMS FOR MESH-CONNECTED PARALLEL COMPUTERS  
Author: STEVE GODDARD, SUBODH KUMAR, AND JAN F. PRINS 
Abstract: We present a new CREW PRAM algorithm for finding connected components. For a graph G with n vertices and m edges, algorithm A 0 requires at most O(log n) parallel steps and performs O((n+m) log n) work in the worst case. The advantage our algorithm has over others in the literature is that it can be adapted to a 2-D mesh-connected communication model in which all CREW operations are replaced by O(log n) parallel row and column operations without increasing the time complexity. We present the mapping of A 0 to a mesh-connected computer and describe two implementations, A 1 and A 2 . Algorithm A 1 , which uses an adjacency matrix to represent the graph, performs O(n 2 log n) work. Hence, it only achieves work efficiency on dense graphs. The second implementation, A 2 , uses a sparse representation of the adjacency matrix and again performs O(log n) row and column operations but reduces the work to O((m + n) log n) on all graphs. We report MasPar MP-1 performance figures for implementations of the algorithms described. The implementations are exercised on a variety of parametrically generated graphs, differing in structure and connectivity. These graphs are generated externally and read in as input for the algorithms, permitting comparison of different implementations on identical graphs. 
Abstract-found: 1
Intro-found: 1
Reference: [AS87] <author> B. Awerbuch and Y. Shiloach. </author> <title> New connectivity and MSF algorithms for Ultracom-puter and PRAM. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 36(10) </volume> <pages> 1258-1263, </pages> <year> 1987. </year>
Reference-contexts: The initial presentation of the algorithm, A 0 , is for the CREW-PRAM model of computation and is based on ideas found in the CRCW-PRAM algorithms for sparse graphs developed by Shiloach et al. in <ref> [SV82, AS87] </ref>. For a graph G with n vertices and m edges, A 0 requires at most O (log n) parallel steps and performs O ((n + m) log n) work (hence, like [SV82, AS87], is not quite work efficient). A 0 differs from [SV82, AS87] in that it can be <p> based on ideas found in the CRCW-PRAM algorithms for sparse graphs developed by Shiloach et al. in <ref> [SV82, AS87] </ref>. For a graph G with n vertices and m edges, A 0 requires at most O (log n) parallel steps and performs O ((n + m) log n) work (hence, like [SV82, AS87], is not quite work efficient). A 0 differs from [SV82, AS87] in that it can be adapted to a 2-D mesh-connected communication model in which all CREW operations are replaced by parallel row and column operations. <p> developed by Shiloach et al. in <ref> [SV82, AS87] </ref>. For a graph G with n vertices and m edges, A 0 requires at most O (log n) parallel steps and performs O ((n + m) log n) work (hence, like [SV82, AS87], is not quite work efficient). A 0 differs from [SV82, AS87] in that it can be adapted to a 2-D mesh-connected communication model in which all CREW operations are replaced by parallel row and column operations. <p> Since vertices are always trying to decrease their parent function, eventually all trees of a connected component are combined and contracted to a single rooted star. While the Shiloach-Vishkin algorithms of <ref> [SV82, AS87] </ref> must be very particular about how trees are grafted, A 0 hangs a tree on any lower numbered vertex without concern for its height in the tree. 2.1. Correctness. Algorithm A 0 terminates when all vertices of a connected component have the same parent. Theorem 2.1.
Reference: [Ble90] <author> G. Blelloch. </author> <title> Unpublished CVL Code, </title> <year> 1990. </year>
Reference-contexts: The corresponding probability of the existence of a grid edge in the graph is 20% and 40% respectively. 5. Slower Algorithms While working with early versions of A 1 and A 2 we evaluated the possibility of performance gains using random mating techniques from the RM algorithm of <ref> [Ble90] </ref>, a variation of which was presented as cc RM 2 () in [Gre93]. Table 7 shows timing results of the NESL program cc RM 2 () compared with the MPL implementations 1 of Algorithm 5.2 of [J 92] and algorithm A 2 .
Reference: [CLC82] <author> F. Chin, J. Lam, and I. Chen. </author> <title> Efficient parallel algorithms for some graph problems. </title> <journal> Communications of the ACM, </journal> <volume> 25(9) </volume> <pages> 659-665, </pages> <year> 1982. </year>
Reference: [CV91] <author> R. Cole and U. Vishkin. </author> <title> Approximate parallel scheduling. Part II: Application to optimal parallel graph algorithms in logarithmic time. </title> <journal> Information and Computation, </journal> <volume> 92(1) </volume> <pages> 1-47, </pages> <year> 1991. </year>
Reference: [Gre93] <author> J. Greiner. </author> <title> A comparison of data-parallel algorithms for connected components. </title> <type> Technical Report CMU-CS-93-191, CMU, </type> <year> 1993. </year>
Reference-contexts: This algorithm performs O (log n) parallel row and column reduction and broadcast operations, but performs O (n 2 log n) work, hence achieves very poor work efficiency on sparse graphs. Since sparse graphs are typical in applications requiring high-speed determination of connected components (see <ref> [Gre93] </ref>), this is unsatisfactory. Algorithm A 2 uses a sparse representation of the adjacency matrix and again performs O (log n) row and column operations but reduces the work to O ((m + n) log n) on all graphs. <p> A 2D graph is a subset of a two-dimensional toroidal grid. The neighbors of a vertex in a 2D graph form a subset of the four neighbors on such a grid <ref> [Gre93] </ref>. Similarly, a 3D graph is a subset of a three-dimensional toroidal grid [Gre93]. The vertices of a random graph are joined at random, and unless otherwise noted, the number of components is not constrained; it is a function of the random edge generation. <p> A 2D graph is a subset of a two-dimensional toroidal grid. The neighbors of a vertex in a 2D graph form a subset of the four neighbors on such a grid <ref> [Gre93] </ref>. Similarly, a 3D graph is a subset of a three-dimensional toroidal grid [Gre93]. The vertices of a random graph are joined at random, and unless otherwise noted, the number of components is not constrained; it is a function of the random edge generation. Each vertex of a tertiary graph has degree 3. <p> Slower Algorithms While working with early versions of A 1 and A 2 we evaluated the possibility of performance gains using random mating techniques from the RM algorithm of [Ble90], a variation of which was presented as cc RM 2 () in <ref> [Gre93] </ref>. Table 7 shows timing results of the NESL program cc RM 2 () compared with the MPL implementations 1 of Algorithm 5.2 of [J 92] and algorithm A 2 . We acknowledge that the comparison is not entirely fair since MPL programs are in general faster than NESL versions.
Reference: [HCS79] <author> D. Hirschberg, A. Chandra, and D. Saraswate. </author> <title> Computing connected components on parallel computers. </title> <journal> Communications of the ACM, </journal> <volume> 22(8) </volume> <pages> 461-464, </pages> <year> 1979. </year>
Reference: [Hir76] <author> D. Hirschberg. </author> <title> Parallel algorithms for the transitive closure and the connected component problems. </title> <booktitle> In Eighth Annual ACM Symposium on theory of Computing, </booktitle> <pages> pages 55-57, </pages> <address> Hershey, Pennsylvania, </address> <year> 1976. </year>
Reference: [HRD92] <author> T. Hsu, V. Ramachandran, and N. Dean. </author> <title> Implementation of parallel graph algorithms on the MasPar. </title> <type> Technical Report TR-92-38, </type> <institution> University of Texas at Austin, </institution> <year> 1992. </year>
Reference-contexts: However, the RM algorithm relies on CRCW capabilities, and the MasPar doesn't provide such support in hardware. CRCW can be simulated using library routines as was done in <ref> [HRD92] </ref>, but then the constant communication costs assumed in the PRAM analysis isn't constant in the implementation. Moreover, the NESL implementation of the RM algorithm uses calls to the router for the mating, which can take up to 100 times longer than a mesh oriented communication mechanism.
Reference: [HRD94] <author> T. Hsu, V. Ramachandran, and N. Dean. </author> <title> Parallel implementation of algorithms for finding connected components. In DIMACS implementation challenge, </title> <year> 1994. </year>
Reference-contexts: Each vertex of a tertiary graph has degree 3. When no duplicate edges are allowed, a tertiary graph has 1:5n edges. 4.2. Generating Benchmark Graphs. Initially, we created graphs `on the fly' as other research projects had done <ref> [KLCY94, HRD94] </ref>. However, we found that this method presented two problems. First, duplicate edges were created which inflated the `actual' number of edges, resulting in better performance for our algorithms.
Reference: [HW90] <author> Y. Han and A. Wagner. </author> <title> An efficient and fast parallel-connected component algorithm. </title> <journal> JACM, </journal> <volume> 37(3) </volume> <pages> 626-642, </pages> <year> 1990. </year>
Reference: [J 92] <author> J. Jaja. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison Wesley, </publisher> <address> NewYork, </address> <year> 1992. </year>
Reference-contexts: Table 7 shows timing results of the NESL program cc RM 2 () compared with the MPL implementations 1 of Algorithm 5.2 of <ref> [J 92] </ref> and algorithm A 2 . We acknowledge that the comparison is not entirely fair since MPL programs are in general faster than NESL versions. Greiner claims the RM algorithm has O (log n) time complexity and O (m log n) work complexity in the worst case.
Reference: [KLCY94] <author> A. Krishnamurthy, S. Lumetta, D. Culler, and K. Yelick. </author> <title> Connected components on distributed memory machines. In DIMACS implementation challenge, </title> <year> 1994. </year>
Reference-contexts: Each vertex of a tertiary graph has degree 3. When no duplicate edges are allowed, a tertiary graph has 1:5n edges. 4.2. Generating Benchmark Graphs. Initially, we created graphs `on the fly' as other research projects had done <ref> [KLCY94, HRD94] </ref>. However, we found that this method presented two problems. First, duplicate edges were created which inflated the `actual' number of edges, resulting in better performance for our algorithms. <p> Thus, each tertiary graph has 1.5n edges. As with all graphs generated by mkgraph, no self-loops or duplicate edges are allowed. We employed a number of other definitions for tertiary graphs, but the performance of our algorithms was not significantly affected. In particular, we created AD3 <ref> [KLCY94] </ref> graphs. Each vertex in an AD3 graph selects between 0 and 3 neighbors so that one vertex may end up being directly connected to many different nodes. Such graphs tend to have more components [KLCY94]. <p> In particular, we created AD3 <ref> [KLCY94] </ref> graphs. Each vertex in an AD3 graph selects between 0 and 3 neighbors so that one vertex may end up being directly connected to many different nodes. Such graphs tend to have more components [KLCY94]. We also generated graphs in which the degree of each vertex lies between 0 and 6 (uniformly distributed). The performance of A 1 and A 2 on these graphs mirrored the results shown for tertiary graphs.
Reference: [KRS86] <author> C. Kruskal, L. Rudolph, and M. Snir. </author> <title> Efficient parallel algoritms for graph problems. </title> <booktitle> In 1986 International Conference on Parallel Processing, </booktitle> <pages> pages 278-284, </pages> <address> St. Charles, Illinois, </address> <year> 1986. </year>
Reference: [SV82] <author> Y. Shiloach and U. Vishkin. </author> <title> An O(log n) parallel connectivity algorithm. </title> <journal> Journal of Algorithms, </journal> <volume> 3(1) </volume> <pages> 57-67, </pages> <year> 1982. </year>
Reference-contexts: The initial presentation of the algorithm, A 0 , is for the CREW-PRAM model of computation and is based on ideas found in the CRCW-PRAM algorithms for sparse graphs developed by Shiloach et al. in <ref> [SV82, AS87] </ref>. For a graph G with n vertices and m edges, A 0 requires at most O (log n) parallel steps and performs O ((n + m) log n) work (hence, like [SV82, AS87], is not quite work efficient). A 0 differs from [SV82, AS87] in that it can be <p> based on ideas found in the CRCW-PRAM algorithms for sparse graphs developed by Shiloach et al. in <ref> [SV82, AS87] </ref>. For a graph G with n vertices and m edges, A 0 requires at most O (log n) parallel steps and performs O ((n + m) log n) work (hence, like [SV82, AS87], is not quite work efficient). A 0 differs from [SV82, AS87] in that it can be adapted to a 2-D mesh-connected communication model in which all CREW operations are replaced by parallel row and column operations. <p> developed by Shiloach et al. in <ref> [SV82, AS87] </ref>. For a graph G with n vertices and m edges, A 0 requires at most O (log n) parallel steps and performs O ((n + m) log n) work (hence, like [SV82, AS87], is not quite work efficient). A 0 differs from [SV82, AS87] in that it can be adapted to a 2-D mesh-connected communication model in which all CREW operations are replaced by parallel row and column operations. <p> The tree hanging operation is critical for rapid convergence and plays the same role as the grafting operation of <ref> [SV82] </ref>. The pseudo code of A 0 follows. <p> Since vertices are always trying to decrease their parent function, eventually all trees of a connected component are combined and contracted to a single rooted star. While the Shiloach-Vishkin algorithms of <ref> [SV82, AS87] </ref> must be very particular about how trees are grafted, A 0 hangs a tree on any lower numbered vertex without concern for its height in the tree. 2.1. Correctness. Algorithm A 0 terminates when all vertices of a connected component have the same parent. Theorem 2.1.
Reference: [Vis84] <author> U. Vishkin. </author> <title> An optimal parallel connectivity algorithm. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 9(2) </volume> <pages> 197-207, </pages> <year> 1984. </year>
Reference: [Wyl79] <author> J. Wyllie. </author> <title> The Complexity of Parallel Computation. </title> <type> PhD thesis, </type> <institution> Cornell University, Department of Computer Science, Ithaca, NewYork, 1979. Department of Computer Science, University of North Carolina, </institution> <address> Chapel Hill NC 27599-3175, USA, </address> <publisher> E-mail address: goddard@cs.unc.edu </publisher>
References-found: 16

