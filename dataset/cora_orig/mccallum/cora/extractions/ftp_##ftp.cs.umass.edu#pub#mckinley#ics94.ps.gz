URL: ftp://ftp.cs.umass.edu/pub/mckinley/ics94.ps.gz
Refering-URL: http://spa-www.cs.umass.edu/bibliography.html
Root-URL: 
Email: mckinley@cs.umass.edu  
Title: Evaluating Automatic Parallelization for Efficient Execution on Shared-Memory Multiprocessors  
Author: Kathryn S. M c Kinley 
Address: Amherst, MA 01003-4610  
Affiliation: Department of Computer Science, University of Massachusetts,  
Abstract: We present a parallel code generation algorithm for complete applications and a new experimental methodology that tests the efficacy of our approach. The algorithm optimizes for data locality and parallelism, reducing or eliminating false sharing. It also uses interpro-cedural analysis and transformations to improve the granularity of parallelism. Although the individual components of the algorithm have been published previously, their coordination is unique to this paper. For experimental validation, we do not attempt to parallelize `dusty deck' programs where many have tried and failed. Instead, we collect programs where the users tried to achieve excellent parallel performance. We apply our optimizations to sequential versions of these programs, i.e., the compiler was required to use its analysis and algorithms to parallelize the program and could not rely on user assertions that for example, a loop is parallel. With this metric, our algorithm improves or matches hand-coded parallel programs on shared-memory, bus-based parallel machines for eight of the nine programs in our test suite. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. R. Allen, D. Callahan, and K. Kennedy. </author> <title> Automatic decomposition of scientific programs for parallel execution. </title> <booktitle> In Proceedings of the Fourteenth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <address> Munich, Germany, </address> <month> January </month> <year> 1987. </year>
Reference-contexts: Each scr is then placed in a loop by itself which divides the statements up into the finest granularity possible. In the style of Allen et al. <ref> [1] </ref>, the process is repeated for l n1 until some loop cannot be distributed over the statements (this loop may of course be l n ). If new nests are created as in Figure 3, these become candidates for parallelization by Optimize. <p> If new nests are created as in Figure 3, these become candidates for parallelization by Optimize. This algorithm is not optimal because combining distribution with loop permutation may result in a deeper distribution that in turn may be more effectively parallelized <ref> [1, 18] </ref>. This flexibility was not required in our experiments, so for simplicity it is not explored further here. After distribution and parallelization, there may be a sequence of parallel and sequential nests, some of which may be fused back together.
Reference: [2] <author> J. R. Allen and K. Kennedy. </author> <title> Automatic translation of Fortran programs to vector form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: Although the individual transformations were automated, the code generation algorithm was not. 5.3 Automatic Parallel Code Generation Analysis. To overcome gaps in the current implementation of program analysis in PED, we imported dependence information from PFC. PFC is the Rice system for automatic vectorization <ref> [2] </ref>. PFC's analysis is more mature and includes important features which were not yet implemented in PED. It performs advanced symbolic dependence tests. It also computes interprocedural constants, inter-procedural symbolics and interprocedural MOD and REF information for simple array sections [10].
Reference: [3] <author> V. Balasundaram and K. Kennedy. </author> <title> A technique for summarizing data access and its use in parallelism enhancing transformations. </title> <booktitle> In Proceedings of the SIGPLAN '89 Conference on Program Language Design and Implementation, </booktitle> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: f (n,n) integer i,j integer i,j integer i,j do j = 1,100 enddo (a) before optimization (b) loop extraction (c) fusion, interchange, & parallelization terprocedural optimizations, loop embedding, loop extraction, and procedure cloning, to effect it. 3.4.1 Interprocedural Analysis We use section analysis to analyze interprocedural side effects to arrays <ref> [3, 9, 10] </ref>. Our sections [18] are slightly more precise than data access descriptors [3]. Sections represent a restricted set of the most commonly occurring array access patterns; single elements, rows, columns, grids, and their higher dimensional analogs. <p> Our sections [18] are slightly more precise than data access descriptors <ref> [3] </ref>. Sections represent a restricted set of the most commonly occurring array access patterns; single elements, rows, columns, grids, and their higher dimensional analogs. The various approaches to interprocedural array side-effect analysis must make tradeoffs between precision and efficiency [3, 4, 10, 16, 23]. <p> Sections represent a restricted set of the most commonly occurring array access patterns; single elements, rows, columns, grids, and their higher dimensional analogs. The various approaches to interprocedural array side-effect analysis must make tradeoffs between precision and efficiency <ref> [3, 4, 10, 16, 23] </ref>. Section analysis loses precision because it only represents a selection of array structures and it merges sections for all references to a variable in a procedure into a single section.
Reference: [4] <author> M. Burke and R. Cytron. </author> <title> Interprocedural dependence analysis and parallelization. </title> <booktitle> In Proceedings of the SIGPLAN '86 Symposium on Compiler Construction, </booktitle> <address> Palo Alto, CA, </address> <month> June </month> <year> 1986. </year>
Reference-contexts: Sections represent a restricted set of the most commonly occurring array access patterns; single elements, rows, columns, grids, and their higher dimensional analogs. The various approaches to interprocedural array side-effect analysis must make tradeoffs between precision and efficiency <ref> [3, 4, 10, 16, 23] </ref>. Section analysis loses precision because it only represents a selection of array structures and it merges sections for all references to a variable in a procedure into a single section.
Reference: [5] <author> S. Carr, K. S. M c Kinley, and C. Tseng. </author> <title> Compiler optimizations for improving data locality. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> San Jose, CA, </address> <month> October </month> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: For convenience, we name the components as follows. Optimize uses loop permutation and tiling to exploit data locality and parallelism, minimizing or eliminating false sharing <ref> [11, 5] </ref>. Fuser performs loop fusion and distribution to enable Optimize and increase the granularity of parallelism [12, 13]. The combination is an effective kernel (intraprocedural) parallelization algorithm. Enabler uses interprocedural analysis and transformations to enable the kernel algorithm to be applied across procedure calls. <p> To illuminate the algorithm and experimental results, we summarize its components below. 3.1 Optimize: Data Locality and Parallelism The most effective and essential component of our parallel code generation algorithm uses a simple memory model to drive optimizations for data locality and parallelism <ref> [5, 11] </ref>. We employ loop permutation and tiling to introduce and exploit data locality and parallelism. Using a memory model and loop transformations, our algorithm places the loops with the most reuse innermost and parallel loops outermost, where each is most effective. <p> Adjustments are made for nonunit strides less than the cache line size <ref> [5] </ref>. Non-consecutive if the subscripts vary with l in any other manner, then the array reference is assumed to require a different cache line every iteration, yielding a total of trip cache line accesses. <p> To determine if the order is a legal one, we permute the corresponding entries in the distance/direction vector. If the result is lexicographically positive (the majority of the time it is <ref> [5] </ref>), the permutation is legal and we transform the nest. If not, we use an algorithm called NearbyPermutation [11]. <p> In our experiments, memory order is usually a legal permutation of the nest <ref> [5] </ref>. The complexity of the entire algorithm in this case is dominated by the time to sort the loops in the nest and the corresponding dependence vectors. <p> In the worst case, when the desired outermost loop must be innermost, NearbyPermutation's complexity dominates, O (n 2 time. The parallelization step of the algorithm is linear. These algorithms have proven effective in practice for uniprocessors and shared-memory multiprocessors <ref> [5, 11] </ref>. We define the subroutine Optimize to perform the above algorithms on an arbitrary loop nest. 3.2 Fuser: Improving the Granularity of Parallelism Loop fusion and distribution have several purposes in our parallel code generation algorithm [5, 12]. <p> These algorithms have proven effective in practice for uniprocessors and shared-memory multiprocessors [5, 11]. We define the subroutine Optimize to perform the above algorithms on an arbitrary loop nest. 3.2 Fuser: Improving the Granularity of Parallelism Loop fusion and distribution have several purposes in our parallel code generation algorithm <ref> [5, 12] </ref>.
Reference: [6] <author> K. Cooper, M. W. Hall, R. T. Hood, K. Kennedy, K. S. McKin-ley, J. M. Mellor-Crummey, L. Torczon, and S. K. Warren. </author> <title> The ParaScope parallel programming environment. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 81(2) </volume> <pages> 244-263, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: We created the sequential version of each program simply by ig noring all the parallel directives. Directives included parallel loops, variable privatization, and critical sections. On the sequential version, we then used the advanced analysis and transformations available in our interactive parallel programming tool, the ParaScope Editor (PED) <ref> [6, 14] </ref>, to perform our parallel code generation algorithm. Although the individual transformations were automated, the code generation algorithm was not. 5.3 Automatic Parallel Code Generation Analysis. To overcome gaps in the current implementation of program analysis in PED, we imported dependence information from PFC.
Reference: [7] <author> K. Cooper, K. Kennedy, and L. Torczon. </author> <title> The impact of inter-procedural analysis and optimization in the IR n programming environment. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 8(4) </volume> <pages> 491-523, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: However, if loop nests originating from more than one call site are needed to perform an optimization, extraction is required, as illustrated in Figure 5 (b). 3.4.3 Procedure Cloning Procedure cloning generates multiple copies of a procedure each tailored to its calling environment <ref> [7] </ref>. Even without embedding or extraction, cloning is necessary for interprocedural parallel code generation because multiple versions of a procedure are required if a procedure is called in two or more settings that require different parallelizing optimizations.
Reference: [8] <author> R. Eigenmann, J. Hoeflinger, G. Jaxon, Z. Li, and D. Padua. </author> <title> Restructuring Fortran programs for Cedar. </title> <journal> Concurrency: Practice & Experience, </journal> <volume> 5(7) </volume> <pages> 553-574, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Indeed, finding medium to large grain parallelism is more difficult than single statement parallelism and compilers have had few successes on dusty deck programs <ref> [8, 15, 20, 21] </ref>. Since it is unknown how much parallelism a dusty deck program contains, measuring the success of a compiler on one is at best tenuous. The programs may actually be completely sequential, parallel, or somewhere in between. <p> The studies of which we are aware are from Illinois and Stanford [8, 15, 2 Fusion of sequential loops in Control also improves its performance, but scalar improvements are beyond the scope of this work. 20, 21]. The Illinois studies are traditional <ref> [8, 15] </ref>; they extend Kap, an automatic parallelizer, and then use it to parallelize the Perfect Benchmarks, dusty deck programs. Their target architecture is Cedar, a shared-memory parallel machine with cluster memory and vector processors. The algorithms Kap uses are unpublished, which limits what can be learned from these papers.
Reference: [9] <author> M. W. Hall, K. Kennedy, and K. S. M c Kinley. </author> <title> Interprocedural transformations for parallel code generation. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <address> Albuquerque, NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: Enabler uses interprocedural analysis and transformations to enable the kernel algorithm to be applied across procedure calls. In particular, loops containing calls can be parallelized and nests spanning calls optimized. The interprocedural transformations, loop embedding, loop extraction, and procedure cloning are used only when they enable loop transformations <ref> [9, 18] </ref>. These components appeared previously in the literature and for the algorithmic details the reader should refer to the appropriate articles [9, 11, 12, 18]. Section 3.4 however extends and integrates them for the first time into a single code generation algorithm. <p> The interprocedural transformations, loop embedding, loop extraction, and procedure cloning are used only when they enable loop transformations [9, 18]. These components appeared previously in the literature and for the algorithmic details the reader should refer to the appropriate articles <ref> [9, 11, 12, 18] </ref>. Section 3.4 however extends and integrates them for the first time into a single code generation algorithm. <p> f (n,n) integer i,j integer i,j integer i,j do j = 1,100 enddo (a) before optimization (b) loop extraction (c) fusion, interchange, & parallelization terprocedural optimizations, loop embedding, loop extraction, and procedure cloning, to effect it. 3.4.1 Interprocedural Analysis We use section analysis to analyze interprocedural side effects to arrays <ref> [3, 9, 10] </ref>. Our sections [18] are slightly more precise than data access descriptors [3]. Sections represent a restricted set of the most commonly occurring array access patterns; single elements, rows, columns, grids, and their higher dimensional analogs. <p> Sections reduce the dependence problem on loops containing procedure calls to the problem on ordinary statements [10]. To increase the precision of our representation, we include access order and the precision of sections [18]. We also create an augmented call graph <ref> [9] </ref>. It represents procedure calls and the loop nesting structure. These extensions enable the profitability and safety of intraprocedural transformations (e.g., fusion, permutation, and parallelization) to be determined when the nests span procedure boundaries [18].
Reference: [10] <author> P. Havlak and K. Kennedy. </author> <title> An implementation of interproce-dural bounded regular section analysis. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 350-360, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: f (n,n) integer i,j integer i,j integer i,j do j = 1,100 enddo (a) before optimization (b) loop extraction (c) fusion, interchange, & parallelization terprocedural optimizations, loop embedding, loop extraction, and procedure cloning, to effect it. 3.4.1 Interprocedural Analysis We use section analysis to analyze interprocedural side effects to arrays <ref> [3, 9, 10] </ref>. Our sections [18] are slightly more precise than data access descriptors [3]. Sections represent a restricted set of the most commonly occurring array access patterns; single elements, rows, columns, grids, and their higher dimensional analogs. <p> Sections represent a restricted set of the most commonly occurring array access patterns; single elements, rows, columns, grids, and their higher dimensional analogs. The various approaches to interprocedural array side-effect analysis must make tradeoffs between precision and efficiency <ref> [3, 4, 10, 16, 23] </ref>. Section analysis loses precision because it only represents a selection of array structures and it merges sections for all references to a variable in a procedure into a single section. <p> Section analysis loses precision because it only represents a selection of array structures and it merges sections for all references to a variable in a procedure into a single section. However, these properties make it efficient; in practice, it often works as well as more precise techniques <ref> [10, 16] </ref>. Sections reduce the dependence problem on loops containing procedure calls to the problem on ordinary statements [10]. To increase the precision of our representation, we include access order and the precision of sections [18]. We also create an augmented call graph [9]. <p> However, these properties make it efficient; in practice, it often works as well as more precise techniques [10, 16]. Sections reduce the dependence problem on loops containing procedure calls to the problem on ordinary statements <ref> [10] </ref>. To increase the precision of our representation, we include access order and the precision of sections [18]. We also create an augmented call graph [9]. It represents procedure calls and the loop nesting structure. <p> PFC is the Rice system for automatic vectorization [2]. PFC's analysis is more mature and includes important features which were not yet implemented in PED. It performs advanced symbolic dependence tests. It also computes interprocedural constants, inter-procedural symbolics and interprocedural MOD and REF information for simple array sections <ref> [10] </ref>. PFC produces a file of dependence information that is converted into PED's internal representations. Transformation. Our implementation was not complete when these experiments were performed. We used the augmented call graph, program analysis, and the transformations available in PED, to apply our parallel code generation algorithm.
Reference: [11] <author> K. Kennedy and K. S. M c Kinley. </author> <title> Optimizing for parallelism and data locality. </title> <booktitle> In Proceedings of the 1992 ACM International Conference on Supercomputing, </booktitle> <address> Washington, DC, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: For convenience, we name the components as follows. Optimize uses loop permutation and tiling to exploit data locality and parallelism, minimizing or eliminating false sharing <ref> [11, 5] </ref>. Fuser performs loop fusion and distribution to enable Optimize and increase the granularity of parallelism [12, 13]. The combination is an effective kernel (intraprocedural) parallelization algorithm. Enabler uses interprocedural analysis and transformations to enable the kernel algorithm to be applied across procedure calls. <p> The interprocedural transformations, loop embedding, loop extraction, and procedure cloning are used only when they enable loop transformations [9, 18]. These components appeared previously in the literature and for the algorithmic details the reader should refer to the appropriate articles <ref> [9, 11, 12, 18] </ref>. Section 3.4 however extends and integrates them for the first time into a single code generation algorithm. <p> To illuminate the algorithm and experimental results, we summarize its components below. 3.1 Optimize: Data Locality and Parallelism The most effective and essential component of our parallel code generation algorithm uses a simple memory model to drive optimizations for data locality and parallelism <ref> [5, 11] </ref>. We employ loop permutation and tiling to introduce and exploit data locality and parallelism. Using a memory model and loop transformations, our algorithm places the loops with the most reuse innermost and parallel loops outermost, where each is most effective. <p> To determine if the order is a legal one, we permute the corresponding entries in the distance/direction vector. If the result is lexicographically positive (the majority of the time it is [5]), the permutation is legal and we transform the nest. If not, we use an algorithm called NearbyPermutation <ref> [11] </ref>. <p> Because this loop structure maximizes data locality, it minimizes communication of data between iterations and therefore between processors. In experiments on the Sequent, this structure results in speed-ups of up to 16.4 on 19 processors. The algorithm obtains linear speed-ups for kernels such as matrix multiply <ref> [11] </ref>. do j = 1, n2 y (i) = y (i) + x (j) * m (i,j) parallel do ii = 1, n1, tile do j = 1, n2 do i = ii, min (ii + tile - 1,n1) y (i) = y (i) + x (j) * m (i,j) Discussion. <p> In the worst case, when the desired outermost loop must be innermost, NearbyPermutation's complexity dominates, O (n 2 time. The parallelization step of the algorithm is linear. These algorithms have proven effective in practice for uniprocessors and shared-memory multiprocessors <ref> [5, 11] </ref>. We define the subroutine Optimize to perform the above algorithms on an arbitrary loop nest. 3.2 Fuser: Improving the Granularity of Parallelism Loop fusion and distribution have several purposes in our parallel code generation algorithm [5, 12].
Reference: [12] <author> K. Kennedy and K. S. M c Kinley. </author> <title> Maximizing loop parallelism and improving data locality via loop fusion and distribution. </title> <booktitle> In Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: For convenience, we name the components as follows. Optimize uses loop permutation and tiling to exploit data locality and parallelism, minimizing or eliminating false sharing [11, 5]. Fuser performs loop fusion and distribution to enable Optimize and increase the granularity of parallelism <ref> [12, 13] </ref>. The combination is an effective kernel (intraprocedural) parallelization algorithm. Enabler uses interprocedural analysis and transformations to enable the kernel algorithm to be applied across procedure calls. In particular, loops containing calls can be parallelized and nests spanning calls optimized. <p> The interprocedural transformations, loop embedding, loop extraction, and procedure cloning are used only when they enable loop transformations [9, 18]. These components appeared previously in the literature and for the algorithmic details the reader should refer to the appropriate articles <ref> [9, 11, 12, 18] </ref>. Section 3.4 however extends and integrates them for the first time into a single code generation algorithm. <p> These algorithms have proven effective in practice for uniprocessors and shared-memory multiprocessors [5, 11]. We define the subroutine Optimize to perform the above algorithms on an arbitrary loop nest. 3.2 Fuser: Improving the Granularity of Parallelism Loop fusion and distribution have several purposes in our parallel code generation algorithm <ref> [5, 12] </ref>. <p> We showed that the problem of fusing a set loops is the same, regardless if they resulted from distribution or were written that way <ref> [12] </ref>. 3.2.2 Loop Fusion Loop fusion merges multiple loops with conformable headers into a single loop. It eliminates unnecessary barrier synchronization and reduces communication of shared data between loops. <p> We proved this general form of fusion is NP-hard [13]. When there are only two types which are differentiated by their parallel and sequential status and n candidate nests, we have an O (n 2 ) time and space algorithm that minimizes the number of parallel loops <ref> [12] </ref>. This restricted case arises frequently in practice. In particular, it occurs when the fusion candidates result from distribution. Programmers also write these types of adjacent and fusible nests and several occur in programs in our test suite. 3.3 Kernel Parallelization Our kernel parallelization algorithm appears in Figure 4.
Reference: [13] <author> K. Kennedy and K. S. M c Kinley. </author> <title> Typed fusion with applications to parallel and sequential code generation. </title> <type> Technical Report TR93-208, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: For convenience, we name the components as follows. Optimize uses loop permutation and tiling to exploit data locality and parallelism, minimizing or eliminating false sharing [11, 5]. Fuser performs loop fusion and distribution to enable Optimize and increase the granularity of parallelism <ref> [12, 13] </ref>. The combination is an effective kernel (intraprocedural) parallelization algorithm. Enabler uses interprocedural analysis and transformations to enable the kernel algorithm to be applied across procedure calls. In particular, loops containing calls can be parallelized and nests spanning calls optimized. <p> It eliminates unnecessary barrier synchronization and reduces communication of shared data between loops. Two loop headers are conformable if they have the same number of iterations and are both either sequential or parallel loops <ref> [13] </ref>. Loop fusion is safe if it does not reverse any dependences between candidate loops. We only perform safe fusions [13]. Our goal is to maximize parallelism. Subject to this constraint, we then minimize the number of parallel loops. <p> Two loop headers are conformable if they have the same number of iterations and are both either sequential or parallel loops <ref> [13] </ref>. Loop fusion is safe if it does not reverse any dependences between candidate loops. We only perform safe fusions [13]. Our goal is to maximize parallelism. Subject to this constraint, we then minimize the number of parallel loops. Fusion does not combine two parallel loops when the result must be executed sequentially, as illustrated in Figure 3. Fusion algorithm. <p> Two or more loop nests with conformable headers have the same type. Typed fusion seeks to find the minimal number of loops resulting from a fusion in which nodes of a different type cannot be fused. We proved this general form of fusion is NP-hard <ref> [13] </ref>. When there are only two types which are differentiated by their parallel and sequential status and n candidate nests, we have an O (n 2 ) time and space algorithm that minimizes the number of parallel loops [12]. This restricted case arises frequently in practice.
Reference: [14] <author> K. Kennedy, K. S. M c Kinley, and C. Tseng. </author> <title> Analysis and transformation in an interactive parallel programming tool. </title> <journal> Concurrency: Practice & Experience, </journal> <volume> 5(7) </volume> <pages> 575-602, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: We created the sequential version of each program simply by ig noring all the parallel directives. Directives included parallel loops, variable privatization, and critical sections. On the sequential version, we then used the advanced analysis and transformations available in our interactive parallel programming tool, the ParaScope Editor (PED) <ref> [6, 14] </ref>, to perform our parallel code generation algorithm. Although the individual transformations were automated, the code generation algorithm was not. 5.3 Automatic Parallel Code Generation Analysis. To overcome gaps in the current implementation of program analysis in PED, we imported dependence information from PFC.
Reference: [15] <author> D. Kuck, E. Davidson, D. Lawrie, A. Sameh, C.-Q. Zhu, A. Veidenbaum, J. Konicek, P. Yew, K. Gallivan, W. Jalby, H. Wijshoff, R. Bramley, U.M. Yang, P. Emrath, D. Padua, R. Eigenmann, J. Hoeflinger, G. Jaxon, Z. Li, T. Murphy, J. Andrews, and S. Turner. </author> <title> The Cedar system and an initial performance study. </title> <booktitle> In Proceedings of the 20th International Symposium on Computer Architecture, </booktitle> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Indeed, finding medium to large grain parallelism is more difficult than single statement parallelism and compilers have had few successes on dusty deck programs <ref> [8, 15, 20, 21] </ref>. Since it is unknown how much parallelism a dusty deck program contains, measuring the success of a compiler on one is at best tenuous. The programs may actually be completely sequential, parallel, or somewhere in between. <p> The studies of which we are aware are from Illinois and Stanford [8, 15, 2 Fusion of sequential loops in Control also improves its performance, but scalar improvements are beyond the scope of this work. 20, 21]. The Illinois studies are traditional <ref> [8, 15] </ref>; they extend Kap, an automatic parallelizer, and then use it to parallelize the Perfect Benchmarks, dusty deck programs. Their target architecture is Cedar, a shared-memory parallel machine with cluster memory and vector processors. The algorithms Kap uses are unpublished, which limits what can be learned from these papers.
Reference: [16] <author> Z. Li and P. Yew. </author> <title> Efficient interprocedural analysis for program restructuring for parallel programs. </title> <booktitle> In Proceedings of the ACM SIGPLAN Symposium on Parallel Programming: Experience with Applications, Languages, and Systems (PPEALS), </booktitle> <address> New Haven, CT, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: Sections represent a restricted set of the most commonly occurring array access patterns; single elements, rows, columns, grids, and their higher dimensional analogs. The various approaches to interprocedural array side-effect analysis must make tradeoffs between precision and efficiency <ref> [3, 4, 10, 16, 23] </ref>. Section analysis loses precision because it only represents a selection of array structures and it merges sections for all references to a variable in a procedure into a single section. <p> Section analysis loses precision because it only represents a selection of array structures and it merges sections for all references to a variable in a procedure into a single section. However, these properties make it efficient; in practice, it often works as well as more precise techniques <ref> [10, 16] </ref>. Sections reduce the dependence problem on loops containing procedure calls to the problem on ordinary statements [10]. To increase the precision of our representation, we include access order and the precision of sections [18]. We also create an augmented call graph [9].
Reference: [17] <author> K. S. McKinley. </author> <title> Dependence analysis of arrays subscripted by index arrays. </title> <type> Technical Report TR91-162, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: Several of these were monotonic non-decreasing with a regular, well defined pattern. In three programs, automatic parallelization would not have been possible without using user assertions and the testing techniques developed in our earlier research <ref> [17] </ref>. The other two programs used them in a way that did not affect parallelization. Linearized Arrays. The programs ODE and Banded contained linearized arrays and used symbolics to index them in order to simulate multiply dimensioned arrays.
Reference: [18] <author> K. S. McKinley. </author> <title> Automatic and Interactive Parallelization. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: It could not rely on user assertions, e.g., a loop is parallel or a variable privatizable. Most of the programs in our test suite are published versions of state of the art parallel algorithms <ref> [18] </ref>. It is therefore unlikely that large amounts of additional parallelism are available without more algorithm restructuring. Nor are these programs obviously parallel. Many require interprocedural and symbolic analysis to find parallel loops. <p> Enabler uses interprocedural analysis and transformations to enable the kernel algorithm to be applied across procedure calls. In particular, loops containing calls can be parallelized and nests spanning calls optimized. The interprocedural transformations, loop embedding, loop extraction, and procedure cloning are used only when they enable loop transformations <ref> [9, 18] </ref>. These components appeared previously in the literature and for the algorithmic details the reader should refer to the appropriate articles [9, 11, 12, 18]. Section 3.4 however extends and integrates them for the first time into a single code generation algorithm. <p> The interprocedural transformations, loop embedding, loop extraction, and procedure cloning are used only when they enable loop transformations [9, 18]. These components appeared previously in the literature and for the algorithmic details the reader should refer to the appropriate articles <ref> [9, 11, 12, 18] </ref>. Section 3.4 however extends and integrates them for the first time into a single code generation algorithm. <p> If new nests are created as in Figure 3, these become candidates for parallelization by Optimize. This algorithm is not optimal because combining distribution with loop permutation may result in a deeper distribution that in turn may be more effectively parallelized <ref> [1, 18] </ref>. This flexibility was not required in our experiments, so for simplicity it is not explored further here. After distribution and parallelization, there may be a sequence of parallel and sequential nests, some of which may be fused back together. <p> Our sections <ref> [18] </ref> are slightly more precise than data access descriptors [3]. Sections represent a restricted set of the most commonly occurring array access patterns; single elements, rows, columns, grids, and their higher dimensional analogs. <p> Sections reduce the dependence problem on loops containing procedure calls to the problem on ordinary statements [10]. To increase the precision of our representation, we include access order and the precision of sections <ref> [18] </ref>. We also create an augmented call graph [9]. It represents procedure calls and the loop nesting structure. These extensions enable the profitability and safety of intraprocedural transformations (e.g., fusion, permutation, and parallelization) to be determined when the nests span procedure boundaries [18]. <p> include access order and the precision of sections <ref> [18] </ref>. We also create an augmented call graph [9]. It represents procedure calls and the loop nesting structure. These extensions enable the profitability and safety of intraprocedural transformations (e.g., fusion, permutation, and parallelization) to be determined when the nests span procedure boundaries [18]. In addition, these determinations need only in spect the results in the calling procedure. 3.4.2 Loop Embedding and Loop Extraction Loop embedding pushes a loop header into a procedure called within the loop, and loop extraction extracts an outermost loop from a procedure body into the calling procedure. <p> They require an outer loop which encompasses all the other statements in the called procedure. Using extended section analysis, the kernel optimizer and thus Optimize can test for permutation, fusion, distribution, tiling, and parallelization for loop nests that span procedures <ref> [18] </ref>. If an optimization is applicable across procedure boundaries, then we use embedding or extraction to enable it. The same analysis could decide when to perform inlining. Example. Consider Figure 5 (a) where the calls to Q are annotated by S a , the sections of array a. <p> However, testing the safety and profitability of each of the transformations is complicated somewhat. Our strategy separates legality and profitability tests from the mechanics of the transformations <ref> [18] </ref>. The safety tests depend on the precision of the dependence information and the sections analysis. <p> Interior is a sparse matrix code. The authors are all numerical scientists and 6 of the 9 programs are state of the art parallel versions. Papers have been published about them and a lot of attention was paid to their performance. They are described in more detail elsewhere <ref> [18] </ref>. By collecting programs rather than writing them ourselves we avoided the pitfall of writing a test suite to match the abilities of our techniques and architecture. However, many of the problems inherent to any program test suite also arise here.
Reference: [19] <author> A. Osterhaug, </author> <title> editor. Guide to Parallel Programming on Sequent Computer Systems. </title> <publisher> Sequent Technical Publications, </publisher> <address> San Diego, CA, </address> <year> 1989. </year>
Reference-contexts: Each processor has its own 64Kbyte two-way set-associative cache and is connected to the bus. The cache line size is 4 words. The Sequent has a flexible compiler that allows the program to completely specify parallelism, <ref> [19] </ref>. To introduce parallelism into the programs, we used the parallel loop compiler directives. We compiled with version 2.1 of Sequent's Fortran ATS compiler using the compiler options that specify multiprocessing, the Weitek 1167 floating-point accelerator, and optimization at its highest level (O3).
Reference: [20] <author> J. Singh and J. Hennessy. </author> <title> An empirical investigation of the effectiveness of and limitations of automatic parallelization. </title> <booktitle> In Proceedings of the International Symposium on Shared Memory Multiprocessors, </booktitle> <address> Tokyo, Japan, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Indeed, finding medium to large grain parallelism is more difficult than single statement parallelism and compilers have had few successes on dusty deck programs <ref> [8, 15, 20, 21] </ref>. Since it is unknown how much parallelism a dusty deck program contains, measuring the success of a compiler on one is at best tenuous. The programs may actually be completely sequential, parallel, or somewhere in between. <p> The Illinois papers also lack statistics about the effectiveness and applicability of optimizations and analysis. Their interprocedural analysis results de facto from inlining or is performed by hand. Singh & Hennessy used the Alliant FX/8, the Encore Multimax and their Fortran compilers <ref> [20, 21] </ref>. The compiler algorithms are again unpublished. The FX/8 has cluster memory instead of local caches, so their parallelization problem was easier than the one considered here. On the Encore, the slow processors minimized the impact of its small local caches.
Reference: [21] <author> J. Singh and J. Hennessy. </author> <title> Finding and exploiting parallelism in an ocean simulation program: Experiences, results, and implications. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 15(1) </volume> <pages> 27-48, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Indeed, finding medium to large grain parallelism is more difficult than single statement parallelism and compilers have had few successes on dusty deck programs <ref> [8, 15, 20, 21] </ref>. Since it is unknown how much parallelism a dusty deck program contains, measuring the success of a compiler on one is at best tenuous. The programs may actually be completely sequential, parallel, or somewhere in between. <p> The Illinois papers also lack statistics about the effectiveness and applicability of optimizations and analysis. Their interprocedural analysis results de facto from inlining or is performed by hand. Singh & Hennessy used the Alliant FX/8, the Encore Multimax and their Fortran compilers <ref> [20, 21] </ref>. The compiler algorithms are again unpublished. The FX/8 has cluster memory instead of local caches, so their parallelization problem was easier than the one considered here. On the Encore, the slow processors minimized the impact of its small local caches.
Reference: [22] <author> J. Subhlok. </author> <title> Analysis of Synchronization in a Parallel Programming Environment. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: Each of BTN and Multi contain parallel loops with critical sections that update shared variables. Analysis techniques exist that can properly identify the parallelism <ref> [22] </ref>, but since it was not part of our algorithm, we did not use them. In BTN, the benefit of parallelism was actually overwhelmed by the overhead of the critical section, resulting in better performance when the loop executed sequentially.
Reference: [23] <author> R. Triolet, F. Irigoin, and P. Feautrier. </author> <title> Direct parallelization of CALL statements. </title> <booktitle> In Proceedings of the SIGPLAN '86 Symposium on Compiler Construction, </booktitle> <address> Palo Alto, CA, </address> <month> June </month> <year> 1986. </year>
Reference-contexts: Sections represent a restricted set of the most commonly occurring array access patterns; single elements, rows, columns, grids, and their higher dimensional analogs. The various approaches to interprocedural array side-effect analysis must make tradeoffs between precision and efficiency <ref> [3, 4, 10, 16, 23] </ref>. Section analysis loses precision because it only represents a selection of array structures and it merges sections for all references to a variable in a procedure into a single section.
Reference: [24] <author> M. E. Wolf. </author> <title> Improving Locality and Parallelism in Nested Loops. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Stanford University, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: Every time our algorithms chose an optimization strategy that differed from the users, it was an improvement. 7 Related Work Our core technique, Optimize, bears the most similarity to Wolf & Lam's research <ref> [24, 25] </ref>. Their algorithm is potentially more precise and uses skewing and reversal, but in their experiments on data locality, skewing was never useful [24]. Our algorithm is simpler, can take advantage of known loop bounds, and is more efficient. <p> Their algorithm is potentially more precise and uses skewing and reversal, but in their experiments on data locality, skewing was never useful <ref> [24] </ref>. Our algorithm is simpler, can take advantage of known loop bounds, and is more efficient. When a nest of depth n is fully permutable our algorithm experiences it's best case O (n log (n)) time complexity while Wolf & Lam's algorithm experiences exponential behavior.
Reference: [25] <author> M. E. Wolf and M. Lam. </author> <title> A loop transformation theory and an algorithm to maximize parallelism. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 452-471, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Every time our algorithms chose an optimization strategy that differed from the users, it was an improvement. 7 Related Work Our core technique, Optimize, bears the most similarity to Wolf & Lam's research <ref> [24, 25] </ref>. Their algorithm is potentially more precise and uses skewing and reversal, but in their experiments on data locality, skewing was never useful [24]. Our algorithm is simpler, can take advantage of known loop bounds, and is more efficient.
References-found: 25

