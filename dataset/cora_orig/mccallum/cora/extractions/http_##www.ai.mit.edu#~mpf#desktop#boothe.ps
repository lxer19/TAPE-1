URL: http://www.ai.mit.edu/~mpf/desktop/boothe.ps
Refering-URL: 
Root-URL: 
Email: email: boothe@cs.usm.maine.edu  
Title: Algorithms for Bidirectional Debugging  
Author: Bob Boothe 
Address: 96 Falmouth St.  Portland, ME 04104-9300  
Affiliation: Computer Science Dept.  University of Southern Maine  
Date: February 1998  
Pubnum: Technical Report No. USM/CS-98-2-23  
Abstract: This report discusses our research into algorithms and techniques for creating an efficient bidirectional debugger in which all traditional forward movement commands can be performed with equal ease in the reverse direction. With a bidirectional debugger, the user will be able to step backwards along the execution path of their program as easily as they currently step forwards. We expect that adding these backwards movement capabilities to a debugger will greatly increase the efficacy of the debugger as a programming tool. Rather than start at the beginning of the program's execution, far removed from the location of the bug, the programmer can now start at the point where the bug manifests itself. From this point the programmer can directly chase down in reverse how the program got there and where incorrect values originated. fl This research was partly supported by NSF grant CCR-9619456.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Hiralal Agrawal, Richard A. DeMillo, and Eugene H. Spafford. </author> <title> An Execution-Bracktracking Approach to Debugging. </title> <journal> IEEE Software, </journal> <volume> 8(3) </volume> <pages> 21-26, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: From this point the programmer can directly chase down in reverse how the program got there and where incorrect values originated. This is the motivating goal behind research on flowback analysis [2, 7] and dynamic program slicing <ref> [1, 13] </ref>. In contrast, current debugging practice often involves a frustrating process of trying to "sneak up on a bug". <p> With a bidirectional debugger it will become trivial to undo an over stepped the bug mistake. Moreover, with an efficient bidirectional debugger it will be far easier and faster to simply start at the manifestation of the bug and work one's way backwards. Numerous previous researchers <ref> [1, 2, 4, 7, 8, 12, 15] </ref> have investigated a variety of mechanisms for looking backward along the execution path of a program. All of these research projects attempted only to provide limited backward movement capabilities. <p> The debugger then allows the user to examine and search this history log in the forward or reverse direction. The main problem with this technique is the rapid and unbounded growth of the history log. More recent history loggers <ref> [1, 9, 7] </ref> have sought to reduce the amount of information logged. Miller and Choi's system PPD [7] broke the code into blocks that are used as a more limited set of logging points. They logged values on entry and exit to blocks (larger blocks required less logging). <p> They logged values on entry and exit to blocks (larger blocks required less logging). They then performed flowback analysis [2] on this log using emulation to fill in the gaps. The Spyder system <ref> [1] </ref> instead recorded the old values of variables at each point where they changed; however for program structures such as loops and procedure calls, they retained only the earliest values of the variables. <p> Two of these systems [10, 14] also created periodic checkpoints so that the user did not have to re-execute all the way back from the start. Re-execution was also used by Spyder <ref> [1] </ref> and Nezter and Weaver [9] to allow the user to move forward from points in their history log. There have been two reverse debugging projects with goals closer to our own.
Reference: [2] <author> R. M. Balzer. </author> <title> Exdams: Extensible Debugging and Monitorin System. </title> <booktitle> In Proc. Spring Joint Computer Conf., </booktitle> <pages> pages 567-589. </pages> <publisher> AFIPS Press, </publisher> <address> Reston, VA, </address> <year> 1969. </year>
Reference-contexts: From this point the programmer can directly chase down in reverse how the program got there and where incorrect values originated. This is the motivating goal behind research on flowback analysis <ref> [2, 7] </ref> and dynamic program slicing [1, 13]. In contrast, current debugging practice often involves a frustrating process of trying to "sneak up on a bug". <p> With a bidirectional debugger it will become trivial to undo an over stepped the bug mistake. Moreover, with an efficient bidirectional debugger it will be far easier and faster to simply start at the manifestation of the bug and work one's way backwards. Numerous previous researchers <ref> [1, 2, 4, 7, 8, 12, 15] </ref> have investigated a variety of mechanisms for looking backward along the execution path of a program. All of these research projects attempted only to provide limited backward movement capabilities. <p> The history logging approach builds a log spanning the complete execution history of the program being debugged. The re-execution approach instead re-executes the program to recreate execution points as needed. 2.1 History Logging The simplest type of history logger <ref> [2, 8, 15] </ref> creates a log of every operation that occurs during the execution of a program. This log can be created either by instrumenting the program to output a record of each event [2, 15], or by simulating the program and having the simulator record the history [8]. <p> This log can be created either by instrumenting the program to output a record of each event <ref> [2, 15] </ref>, or by simulating the program and having the simulator record the history [8]. The debugger then allows the user to examine and search this history log in the forward or reverse direction. The main problem with this technique is the rapid and unbounded growth of the history log. <p> Miller and Choi's system PPD [7] broke the code into blocks that are used as a more limited set of logging points. They logged values on entry and exit to blocks (larger blocks required less logging). They then performed flowback analysis <ref> [2] </ref> on this log using emulation to fill in the gaps. The Spyder system [1] instead recorded the old values of variables at each point where they changed; however for program structures such as loops and procedure calls, they retained only the earliest values of the variables.
Reference: [3] <author> T.A. Cargill and B.N. Locanthi. </author> <title> Cheap hardware support for software debugging and profiling. </title> <booktitle> In ASPLOS-II Proceedings, </booktitle> <pages> pages 82-83, </pages> <month> October </month> <year> 1987. </year> <note> Appeared as SIGPLAN Notices 22(10). </note>
Reference-contexts: the source code [12], during the compilation process when compiling for debugging [6], to an executable image as might be done with ATOM [11], to a running program in a fashion similar to inserting breakpoint traps by a debugger, or perhaps even by using hardware counters as suggested by Cargill <ref> [3] </ref>. In our system we perform augmentation during both compilation and execution. When a user compiles their program for bidirectional debugging, we insert the calls to our software counter at the tail end of the compilation process by modifying the assembly language code produced by the compiler.
Reference: [4] <author> Stuart I. Feldman and Channing B. Brown. Igor: </author> <title> a system for program debugging via reversible execution. </title> <booktitle> In Proc. of the ACM SIGPLAN/SIGOPS Workshop on 13 Parallel and Distributed Debugging, published in SIGPLAN Notices, </booktitle> <pages> pages 112--123, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: With a bidirectional debugger it will become trivial to undo an over stepped the bug mistake. Moreover, with an efficient bidirectional debugger it will be far easier and faster to simply start at the manifestation of the bug and work one's way backwards. Numerous previous researchers <ref> [1, 2, 4, 7, 8, 12, 15] </ref> have investigated a variety of mechanisms for looking backward along the execution path of a program. All of these research projects attempted only to provide limited backward movement capabilities. <p> There have been two reverse debugging projects with goals closer to our own. Both were interactive uniprocessor debuggers that could move backwards to earlier states along the execution path of a program. The first of these was a project called IGOR <ref> [4] </ref>. Their technique was to create frequent checkpoints of the process, and then allow the users to backup to these checkpoints. They also provided an emulator to search forward from a checkpoint to try to locate a specific point of interest, such as when a variable reached a specific value. <p> For repeated bnext commands, since the 12 bnext counters have already been gathered, only the second pass is needed. These slowdowns compare favorably to the tracing slowdowns of 1.75-7 reported by Netzer and Weaver [9] and to the interpreter slowdown of 140 incurred by IGOR <ref> [4] </ref> just to provide forward replay from a checkpoint. For short running programs all movement operations appear instantaneous under bdb.
Reference: [5] <author> T.J. LeBlanc and J.M. Mellor-Crummey. </author> <title> Debugging parallel programs with instant replay. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 36(4) </volume> <pages> 471-482, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: Our bidirectional debugger aims to automate this process and make it both natural and efficient. Re-execution works only if a program is deterministic. Many parallel programs exhibit non-deterministic behavior and are thus inherently more difficult to debug. A number of research projects into parallel debuggers <ref> [5, 10, 14] </ref> have developed re-execution techniques for the purpose of providing the same basic forward replay ability available on uniprocessors. These debuggers recorded interactions among the processes and logged I/O operations so that they could be replayed during re-execution.
Reference: [6] <author> J. M. Mellor-Crummey and T. J. LeBlanc. </author> <title> A software instruction counter. </title> <booktitle> In ASPLOS-III Proceedings, </booktitle> <pages> pages 78-86, </pages> <month> April </month> <year> 1989. </year> <note> Appeared as SIGPLAN Notices 24(Special Issue). </note>
Reference-contexts: There are a variety of ways to augment the child program with these counter calls. It can be done before compilation by augmenting the source code [12], during the compilation process when compiling for debugging <ref> [6] </ref>, to an executable image as might be done with ATOM [11], to a running program in a fashion similar to inserting breakpoint traps by a debugger, or perhaps even by using hardware counters as suggested by Cargill [3]. In our system we perform augmentation during both compilation and execution.
Reference: [7] <author> Barton P. Miller and Jong-Deok Choi. </author> <title> A mechanism for efficient debugging of parallel programs. </title> <booktitle> In Proc. of the ACM SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, published in SIGPLAN Notices, </booktitle> <pages> pages 141-150, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: From this point the programmer can directly chase down in reverse how the program got there and where incorrect values originated. This is the motivating goal behind research on flowback analysis <ref> [2, 7] </ref> and dynamic program slicing [1, 13]. In contrast, current debugging practice often involves a frustrating process of trying to "sneak up on a bug". <p> With a bidirectional debugger it will become trivial to undo an over stepped the bug mistake. Moreover, with an efficient bidirectional debugger it will be far easier and faster to simply start at the manifestation of the bug and work one's way backwards. Numerous previous researchers <ref> [1, 2, 4, 7, 8, 12, 15] </ref> have investigated a variety of mechanisms for looking backward along the execution path of a program. All of these research projects attempted only to provide limited backward movement capabilities. <p> The debugger then allows the user to examine and search this history log in the forward or reverse direction. The main problem with this technique is the rapid and unbounded growth of the history log. More recent history loggers <ref> [1, 9, 7] </ref> have sought to reduce the amount of information logged. Miller and Choi's system PPD [7] broke the code into blocks that are used as a more limited set of logging points. They logged values on entry and exit to blocks (larger blocks required less logging). <p> The main problem with this technique is the rapid and unbounded growth of the history log. More recent history loggers [1, 9, 7] have sought to reduce the amount of information logged. Miller and Choi's system PPD <ref> [7] </ref> broke the code into blocks that are used as a more limited set of logging points. They logged values on entry and exit to blocks (larger blocks required less logging). They then performed flowback analysis [2] on this log using emulation to fill in the gaps.
Reference: [8] <author> T. G. Moher. </author> <title> PROVIDE: A Process Visualization and Debugging Environment. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 14(6) </volume> <pages> 849-857, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: With a bidirectional debugger it will become trivial to undo an over stepped the bug mistake. Moreover, with an efficient bidirectional debugger it will be far easier and faster to simply start at the manifestation of the bug and work one's way backwards. Numerous previous researchers <ref> [1, 2, 4, 7, 8, 12, 15] </ref> have investigated a variety of mechanisms for looking backward along the execution path of a program. All of these research projects attempted only to provide limited backward movement capabilities. <p> The history logging approach builds a log spanning the complete execution history of the program being debugged. The re-execution approach instead re-executes the program to recreate execution points as needed. 2.1 History Logging The simplest type of history logger <ref> [2, 8, 15] </ref> creates a log of every operation that occurs during the execution of a program. This log can be created either by instrumenting the program to output a record of each event [2, 15], or by simulating the program and having the simulator record the history [8]. <p> This log can be created either by instrumenting the program to output a record of each event [2, 15], or by simulating the program and having the simulator record the history <ref> [8] </ref>. The debugger then allows the user to examine and search this history log in the forward or reverse direction. The main problem with this technique is the rapid and unbounded growth of the history log.
Reference: [9] <author> Robert H. B. Netzer and Mark H. Weaver. </author> <title> Optimal tracing and incremental reexecution for debugging long-running programs. </title> <journal> SIGPLAN Notices, </journal> <volume> 29(6) </volume> <pages> 313-325, </pages> <month> June </month> <year> 1994. </year> <month> PLDI'94. </month>
Reference-contexts: The debugger then allows the user to examine and search this history log in the forward or reverse direction. The main problem with this technique is the rapid and unbounded growth of the history log. More recent history loggers <ref> [1, 9, 7] </ref> have sought to reduce the amount of information logged. Miller and Choi's system PPD [7] broke the code into blocks that are used as a more limited set of logging points. They logged values on entry and exit to blocks (larger blocks required less logging). <p> A large drawback of both systems was that they could only bound the growth of the history log for programs that did not use arrays or pointers. Netzer and Weaver <ref> [9] </ref> addressed this by dynamically breaking the execution history into time windows for which the user could trade off between history granularity and trace size. They found a 5 second window gave them acceptably compact traces. <p> Two of these systems [10, 14] also created periodic checkpoints so that the user did not have to re-execute all the way back from the start. Re-execution was also used by Spyder [1] and Nezter and Weaver <ref> [9] </ref> to allow the user to move forward from points in their history log. There have been two reverse debugging projects with goals closer to our own. Both were interactive uniprocessor debuggers that could move backwards to earlier states along the execution path of a program. <p> For repeated bnext commands, since the 12 bnext counters have already been gathered, only the second pass is needed. These slowdowns compare favorably to the tracing slowdowns of 1.75-7 reported by Netzer and Weaver <ref> [9] </ref> and to the interpreter slowdown of 140 incurred by IGOR [4] just to provide forward replay from a checkpoint. For short running programs all movement operations appear instantaneous under bdb.
Reference: [10] <author> Douglas Z. Pan and Mark A. Linton. </author> <title> Supporting reverse execution of parallel programs. </title> <booktitle> In Proc. of the ACM SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, published in SIGPLAN Notices, </booktitle> <pages> pages 124-129, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: Our bidirectional debugger aims to automate this process and make it both natural and efficient. Re-execution works only if a program is deterministic. Many parallel programs exhibit non-deterministic behavior and are thus inherently more difficult to debug. A number of research projects into parallel debuggers <ref> [5, 10, 14] </ref> have developed re-execution techniques for the purpose of providing the same basic forward replay ability available on uniprocessors. These debuggers recorded interactions among the processes and logged I/O operations so that they could be replayed during re-execution. <p> These debuggers recorded interactions among the processes and logged I/O operations so that they could be replayed during re-execution. Two of these systems <ref> [10, 14] </ref> also created periodic checkpoints so that the user did not have to re-execute all the way back from the start. Re-execution was also used by Spyder [1] and Nezter and Weaver [9] to allow the user to move forward from points in their history log.
Reference: [11] <author> Amitabh Srivastava and Alan Eustace. </author> <title> ATOM A System for Building Customized Program Analysis Tools. </title> <booktitle> In Proc. of the SIGPLAN '94 PLDI Conf., </booktitle> <pages> pages 196-205, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: There are a variety of ways to augment the child program with these counter calls. It can be done before compilation by augmenting the source code [12], during the compilation process when compiling for debugging [6], to an executable image as might be done with ATOM <ref> [11] </ref>, to a running program in a fashion similar to inserting breakpoint traps by a debugger, or perhaps even by using hardware counters as suggested by Cargill [3]. In our system we perform augmentation during both compilation and execution.
Reference: [12] <author> Andrew P. Tolmach and Andrew W. Appel. </author> <title> A debugger for standard ML. </title> <editor> J. </editor> <booktitle> Functional Programming, </booktitle> <year> 1994. </year>
Reference-contexts: With a bidirectional debugger it will become trivial to undo an over stepped the bug mistake. Moreover, with an efficient bidirectional debugger it will be far easier and faster to simply start at the manifestation of the bug and work one's way backwards. Numerous previous researchers <ref> [1, 2, 4, 7, 8, 12, 15] </ref> have investigated a variety of mechanisms for looking backward along the execution path of a program. All of these research projects attempted only to provide limited backward movement capabilities. <p> They also provided an emulator to search forward from a checkpoint to try to locate a specific point of interest, such as when a variable reached a specific value. The other project was a debugger developed by Tolmach and Appel <ref> [12] </ref> for the ML language. They instrumented the source code of the application with a call to a debugger routine at each program event. This debugger routine incremented a "time counter", and it compared the time counter to a stopping value. <p> This counter routine increments the global step counter and tests to see if it has reached the stopping point. As done in the ML debugger by Tolmach and Appel <ref> [12] </ref>, the debugger single steps forward by setting the stop value equal to the current value of the step counter + 1, and then resumes the child process. <p> There are a variety of ways to augment the child program with these counter calls. It can be done before compilation by augmenting the source code <ref> [12] </ref>, during the compilation process when compiling for debugging [6], to an executable image as might be done with ATOM [11], to a running program in a fashion similar to inserting breakpoint traps by a debugger, or perhaps even by using hardware counters as suggested by Cargill [3].
Reference: [13] <author> M. Weiser. </author> <title> Programmers Use Slices When Debugging. </title> <journal> Communications of the ACM, </journal> <volume> 25(7) </volume> <pages> 446-452, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: From this point the programmer can directly chase down in reverse how the program got there and where incorrect values originated. This is the motivating goal behind research on flowback analysis [2, 7] and dynamic program slicing <ref> [1, 13] </ref>. In contrast, current debugging practice often involves a frustrating process of trying to "sneak up on a bug".
Reference: [14] <author> Larry D. Wittie. </author> <title> Debugging distributed c programs by real-time replay. </title> <booktitle> In Proc. of the ACM SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging. Appeared as SIGPLAN Notices, </booktitle> <month> January </month> <year> 1989. </year>
Reference-contexts: Our bidirectional debugger aims to automate this process and make it both natural and efficient. Re-execution works only if a program is deterministic. Many parallel programs exhibit non-deterministic behavior and are thus inherently more difficult to debug. A number of research projects into parallel debuggers <ref> [5, 10, 14] </ref> have developed re-execution techniques for the purpose of providing the same basic forward replay ability available on uniprocessors. These debuggers recorded interactions among the processes and logged I/O operations so that they could be replayed during re-execution. <p> These debuggers recorded interactions among the processes and logged I/O operations so that they could be replayed during re-execution. Two of these systems <ref> [10, 14] </ref> also created periodic checkpoints so that the user did not have to re-execute all the way back from the start. Re-execution was also used by Spyder [1] and Nezter and Weaver [9] to allow the user to move forward from points in their history log.
Reference: [15] <author> M.V. Zelkowitz. </author> <title> Reversible execution. </title> <journal> Communications of the ACM, </journal> <volume> 16(9):566, </volume> <month> September </month> <year> 1973. </year> <month> 14 </month>
Reference-contexts: With a bidirectional debugger it will become trivial to undo an over stepped the bug mistake. Moreover, with an efficient bidirectional debugger it will be far easier and faster to simply start at the manifestation of the bug and work one's way backwards. Numerous previous researchers <ref> [1, 2, 4, 7, 8, 12, 15] </ref> have investigated a variety of mechanisms for looking backward along the execution path of a program. All of these research projects attempted only to provide limited backward movement capabilities. <p> The history logging approach builds a log spanning the complete execution history of the program being debugged. The re-execution approach instead re-executes the program to recreate execution points as needed. 2.1 History Logging The simplest type of history logger <ref> [2, 8, 15] </ref> creates a log of every operation that occurs during the execution of a program. This log can be created either by instrumenting the program to output a record of each event [2, 15], or by simulating the program and having the simulator record the history [8]. <p> This log can be created either by instrumenting the program to output a record of each event <ref> [2, 15] </ref>, or by simulating the program and having the simulator record the history [8]. The debugger then allows the user to examine and search this history log in the forward or reverse direction. The main problem with this technique is the rapid and unbounded growth of the history log.
References-found: 15

