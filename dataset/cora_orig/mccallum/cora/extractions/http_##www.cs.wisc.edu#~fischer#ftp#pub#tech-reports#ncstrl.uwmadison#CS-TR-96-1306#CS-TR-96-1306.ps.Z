URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-96-1306/CS-TR-96-1306.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-96-1306/
Root-URL: http://www.cs.wisc.edu
Email: mirong@cs.wisc.edu  
Title: Goal-Oriented Buffer Management Revisited  
Author: Kurt P. Brown Michael J. Carey Miron Livny fbrown, carey, 
Address: Wisconsin, Madison, WI  
Affiliation: Computer Sciences Department, University of  
Abstract: In this paper we revisit the problem of achieving multi-class workload response time goals by automatically adjusting the buffer memory allocations of each workload class. We discuss the virtues and limitations of previous work with respect to a set of criteria we lay out for judging the success of any goal-oriented resource allocation algorithm. We then introduce the concept of hit rate concavity and develop a new goal-oriented buffer allocation algorithm, called Class Fencing, that is based on this concept. Exploiting the notion of hit rate concavity results in an algorithm that not only is as accurate and stable as our previous work, but also more responsive, more robust, and simpler to implement. 
Abstract-found: 1
Intro-found: 1
Reference: [Belady 66] <author> L. Belady, </author> <title> "A Study of Replacement Algorithms for a Virtual-Storage Computer," </title> <journal> IBM Systems Journal, </journal> <volume> 5(2), </volume> <month> July </month> <year> 1966. </year>
Reference-contexts: To estimate hit rate as a function of memory, the Dynamic Tuning algorithm adopts observations from Belady's virtual memory study <ref> [Belady 66] </ref>, modeling the hit rate function as 1 a=M b , where M is the memory allocation and the constants a and b are specific to a particular combination of workload and buffer page replacement policy. <p> The concavity theorem says that the slope of the hit rate curve never increases as more memory is added to an optimal buffer replacement policy. An optimal buffer replacement policy is defined as one that always chooses the least valuable page to replace (e.g. Belady's MIN algorithm <ref> [Belady 66] </ref>). While optimal replacement policies are not realizable in practice because they require knowledge of future reference patterns, we will argue shortly that the behavior of industrial-strength DBMS replacement policies are "optimal enough" that hit rate concavity applies to them as well.
Reference: [Bitton 83] <author> D. Bitton, D. DeWitt, C. Turbyfill, </author> <title> "Benchmarking Database Systems A Systematic Approach," </title> <booktitle> Proc. 9th Int'l VLDB Conf, </booktitle> <address> Florence, Italy, </address> <month> October </month> <year> 1983. </year>
Reference-contexts: The DBMIN portion of the database is a subset of the original Wisconsin Benchmark Database <ref> [Bitton 83] </ref>, except that here we scale up the number of tuples in each relation by a factor of ten. The TPC-C benchmark represents an order-entry application for a wholesale distribution company. Its files and associated B+ tree indexes are summarized in Table 1.
Reference: [Brown 93] <author> K. Brown, M. Carey, M. Livny, </author> <title> "Managing Memory to Meet Multiclass Workload Response Time Goals," </title> <booktitle> Proc. 19th Int'l VLDB Conf, </booktitle> <address> Dublin, Ireland, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Therefore, the general approach common to all goal-oriented resource allocation work <ref> [Pierce 83, Ferg 93, Brown 93, Brown 94, Chung 94] </ref> is the notion of feedback coupled with "best guess" estimation. <p> This process of observing, estimating, and adjusting knobs is repeated continuously at regular intervals. The length of these intervals can be expressed as a predefined number of transaction completions, and should be chosen to strike a good balance between responsiveness and statistical stability <ref> [Brown 93] </ref>. 1.2 Criteria for Success How successfully a class meets its response time goal is not the only criteria with which to judge a goal-oriented resource allocation algorithm. <p> It should be noted that these criteria will normally be in conflict (stability versus responsiveness, responsiveness versus overhead, etc.), and therefore a goal-oriented resource allocation algorithm necessarily represents a careful balance between them. 1.3 Our Work In earlier work, we described a goal-oriented buffer management algorithm called Fragment Fencing <ref> [Brown 93] </ref>. Encouraged by our initial simulation studies, we built a prototype version of Fragment Fencing in DB2/6000, IBM's commercial relational database for Unix [IBM 93b]. We then experimented with our simulated workloads and some additional workloads, including the TPC-B, TPC-C, and multi-user TPC-D benchmarks [TPC 94]. <p> Using this relationship, the target hit rate estimated to achieve the response time 1 2.5% of the total buffer pool was used in [Chung 94]. Similarly, Fragment Fencing caps its per-step changes in memory allocation at 10% of the buffer pool <ref> [Brown 93] </ref>. 6 goals is computed as: HIT target = 1:0 (M obsv fl (R goal =R obsv )) where R obsv and R goal are the observed response time and response time goals, respectively, and M obsv is the observed miss rate that occurs with the observed response time. <p> These minimum amounts are called target residencies and are analogous to a working set size for each fragment. When a class's hit rate needs to be increased by some amount, all of the fragments referenced by the class are sorted in order of decreasing class temperature <ref> [Copeland 88, Brown 93] </ref>, which is their size-normalized access frequency (in references per page per second). <p> It is passive in the sense that it does not explicitly direct the appropriate pages into the buffer pool; it only prevents their ejection from the pool by the DBMS's native replacement policy. 7 2.4 Fragment Fencing Issues A potential problem with a fragment-oriented approach, as noted in <ref> [Brown 93] </ref>, is what happens when references within a fragment are not uniform. Since Fragment Fencing measures the actual hit rates of each fragment, it can easily test for violations of the uniform reference assumption by comparing the estimated hit rate to the actual hit rate. <p> Another problem with Fragment Fencing has to do with its "passive" memory allocation mechanism. Keeping the DBMS's replacement policy "in the dark" with regard to which buffer frames are fenced or not provides a high degree of independence from the underlying replacement policy <ref> [Brown 93] </ref>, but it also has the potential for significant overhead. Because the replacement policy is unaware of which frames are fenced, it is forced to waste time inspecting frames that seem like good candidates only to be overruled by Fragment Fencing. <p> For index pages themselves, it is possible to use reference frequency statistics or information about the last few references to insure that more valuable index pages are not replaced by less valuable index pages <ref> [Copeland 88, O'Neil 93, Brown 93] </ref>.
Reference: [Brown 94] <author> K. Brown, M. Mehta, M. Carey, M. Livny, </author> <title> "Towards Automated Performance Tuning for Complex Workloads," </title> <booktitle> Proc. 20th Int'l VLDB Conf, </booktitle> <address> Santiago, Chile, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Therefore, the general approach common to all goal-oriented resource allocation work <ref> [Pierce 83, Ferg 93, Brown 93, Brown 94, Chung 94] </ref> is the notion of feedback coupled with "best guess" estimation. <p> Finally, we plan on replacing the Fragment Fencing component of our more general M&M algorithm <ref> [Brown 94] </ref> and then re-evaluating M&M's performance on even complex multiclass workloads. (In addition to the buffer memory knob, M&M also controls working storage memory and multiprogramming levels). Acknowledgements The authors would like to thank Praveen Seshadri and Mark McAuliffe for valuable comments on previous versions of this paper.
Reference: [Chen 93] <author> C. Chen, N. Roussopoulos, </author> <title> "Adaptive Database Buffer Allocation Using Query Feedback," </title> <booktitle> Proc. 19th Int'l VLDB Conf, </booktitle> <address> Dublin, Ireland, </address> <month> August </month> <year> 1993. </year> <month> 25 </month>
Reference-contexts: class as quickly as possible to the "X", which represents the memory allocation MT that results in the 4 This is certainly true for relational systems, but less so for object-oriented systems that support navigational access. 5 A straight line approximation of buffer hit rate functions was also used in <ref> [Chen 93] </ref> to predict a memory allocation that maximizes marginal gain [Ng 91]. 10 target hit rate HT.
Reference: [Cheng 84] <author> J. Cheng et al, </author> <title> "IBM Database 2 Performance: Design, Implementation, and Tuning," </title> <journal> IBM Systems Journal, </journal> <volume> 23(2), </volume> <year> 1984. </year>
Reference-contexts: While it would be impossible to offer any definitive statement about the likelihood of a hit rate knee in real-world buffer managers, we conducted an empirical study of two simulated buffer managers, one modeled after DB2/MVS <ref> [Cheng 84, Teng 84, IBM 93a] </ref> and the other modeled after DB2/6000 [IBM 93b].
Reference: [Chou 85] <author> H. Chou and D. DeWitt, </author> <title> "An Evaluation of Buffer Management Strategies for Relational Database Systems," </title> <booktitle> Proc. 11th Int'l VLDB Conf., </booktitle> <address> Stockholm, Sweden, </address> <month> August. </month> <year> 1985. </year>
Reference-contexts: For both of these buffer managers, we mapped the hit rate functions for the TPC A/B and C benchmarks, as well as all of the canonical database reference patterns documented in the DBMIN Query Locality Set Model <ref> [Chou 85] </ref>. None of them showed a knee. Additional empirical evidence for concavity is provided by Dan et al [Dan 95], where hit rate functions derived from actual traces of DB2/MVS customers were also seen to be free of knees. <p> On a buffer miss by a violating class, a free frame is 6 A similar sharing technique was used by the DBMIN algorithm <ref> [Chou 85] </ref>. Class Fencing differs from that approach in that DBMIN partitioned memory on the basis of file instances and used a different replacement policy for each instance. <p> - U Table 1: Database characteristics 15 The database model consists of a two-part database, with one part taken directly from the TPC-C benchmark [TPC 94] using a scale factor of one (one warehouse), and the other drawn from a previously published performance study of the DBMIN buffer management algorithm <ref> [Chou 85] </ref>. The DBMIN portion of the database is a subset of the original Wisconsin Benchmark Database [Bitton 83], except that here we scale up the number of tuples in each relation by a factor of ten. The TPC-C benchmark represents an order-entry application for a wholesale distribution company. <p> Note that because of its skewed references within database fragments, TPC-C violates Fragment Fencing's uniform reference assumption and therefore its performance cannot be controlled by Fragment Fencing. DBMIN Query 2 (Q2): The Q2 class is a non-clustered index scan of DBMIN file A with a 1% selectivity <ref> [Chou 85] </ref>. Because file A and its index can fit entirely in memory, this class is very sensitive to its buffer hit rate and is therefore more easily controlled than TPC-C. <p> <ref> [Chou 85] </ref>. Because file A and its index can fit entirely in memory, this class is very sensitive to its buffer hit rate and is therefore more easily controlled than TPC-C. DBMIN Query 3 (Q3): The Q3 class is an index nested loops join of DBMIN files A and B [Chou 85]. File A is scanned using a clustered index with a 2% selectivity, and file B is scanned directly. When Q2 and Q3 are running together in the same workload, they share the common file A, causing their performance is somewhat linked.
Reference: [Chung 94] <author> J. Chung, D. Ferguson, G. Wang, C. Nikolaou, J. Teng, </author> <title> "Goal Oriented Dynamic Buffer Pool Management for Database Systems," </title> <institution> IBM Research Report RC19807, </institution> <month> October, </month> <year> 1994. </year>
Reference-contexts: Therefore, the general approach common to all goal-oriented resource allocation work <ref> [Pierce 83, Ferg 93, Brown 93, Brown 94, Chung 94] </ref> is the notion of feedback coupled with "best guess" estimation. <p> In the next section, we review the Fragment Fencing algorithm in more detail and discuss some of the insight that we gained from implementing it in an industrial-strength DBMS. We also discuss the only other goal-oriented memory management algorithm of which we are aware, Dynamic Tuning <ref> [Chung 94] </ref>. We then explain the notion of hit rate concavity and describe the Class Fencing algorithm in Section 3. In Section 4, we describe a detailed simulation model that is used in Section 5 to analyze the performance of Class Fencing. <p> This abstract framework will be used in the remainder of this section to describe the Dynamic Tuning and Fragment Fencing algorithms, and will be used again in Section 3 to explain the Class Fencing algorithm. 2.1 Dynamic Tuning Description The Dynamic Tuning algorithm <ref> [Chung 94] </ref> differs from other goal-oriented algorithms ([Ferg 93, Brown 93, Brown 94]) in one important respect: response time goals are specified with respect to low-level buffer management requests (i.e., in terms of target service times for individual get/read page requests) as opposed to overall transaction response times. <p> This approach is simple and effective for classes that do not share data, but some provision needs to be made for classes that do share buffer pages. Sharing is not discussed in <ref> [Chung 94] </ref>. 2.3 Fragment Fencing Description Fragment Fencing's response time estimator makes the simplifying assumption that response time and buffer miss rate are directly proportional. Using this relationship, the target hit rate estimated to achieve the response time 1 2.5% of the total buffer pool was used in [Chung 94]. <p> discussed in <ref> [Chung 94] </ref>. 2.3 Fragment Fencing Description Fragment Fencing's response time estimator makes the simplifying assumption that response time and buffer miss rate are directly proportional. Using this relationship, the target hit rate estimated to achieve the response time 1 2.5% of the total buffer pool was used in [Chung 94].
Reference: [Copeland 88] <author> G. Copeland, W. Alexander, E. Boughter, T. Keller, </author> <title> "Data Placement in Bubba," </title> <booktitle> Proc. ACM SIGMOD '88 Conf., </booktitle> <address> Chicago, IL, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: These minimum amounts are called target residencies and are analogous to a working set size for each fragment. When a class's hit rate needs to be increased by some amount, all of the fragments referenced by the class are sorted in order of decreasing class temperature <ref> [Copeland 88, Brown 93] </ref>, which is their size-normalized access frequency (in references per page per second). <p> For index pages themselves, it is possible to use reference frequency statistics or information about the last few references to insure that more valuable index pages are not replaced by less valuable index pages <ref> [Copeland 88, O'Neil 93, Brown 93] </ref>.
Reference: [Corbato 68] <author> F. Corbato, </author> <title> "A Paging Experiment with the Multics System," Project MAC memo MAC-M-384, </title> <institution> Massachusetts Institute of Technology, </institution> <address> Boston, MA, </address> <month> July </month> <year> 1968. </year>
Reference: [Dan 95] <author> A. Dan, P.S. Yu, J.-Y. Chung, </author> <title> "Characterization of Database Access Pattern for Analytic Prediction of Buffer Hit Probability," </title> <journal> VLDB Journal, </journal> <volume> 4(1), </volume> <month> January </month> <year> 1995. </year>
Reference-contexts: To our knowledge, no one has explicitly stated it in the form we do here, although some previous work has exploited the notion of concavity in any case <ref> [Dan 95] </ref>. 3 This notion of page value is synonymous with the concept of marginal gain defined in [Ng 91]. 9 will be scanned [Stonebraker 81]. <p> None of them showed a knee. Additional empirical evidence for concavity is provided by Dan et al <ref> [Dan 95] </ref>, where hit rate functions derived from actual traces of DB2/MVS customers were also seen to be free of knees. While we acknowledge that hit rate function knees are possible in the real world, we believe that they represent pathological cases.
Reference: [DeWitt 90] <author> D. DeWitt et al, </author> <title> "The Gamma Database Machine Project," </title> <journal> IEEE Trans. on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: The number of disks, number of terminals, and think times were chosen to ensure that disk utilizations lie in the 50 to 60% range. The software-related parameters in Table 3 are based on instruction counts taken from the Gamma parallel database system prototype <ref> [DeWitt 90] </ref>, and the disk characteristics approximate those of the Fujitsu Model M2266 disk drive (as stated earlier). 17 5 Experiments and Results In this section, we use our simulation model to examine how well Class Fencing can achieve a variety of goals for several different multiclass workloads.
Reference: [Easton 79] <author> M. Easton, P. Franaszek, </author> <title> "Use Bit Scanning in Replacement Decisions," </title> <journal> IEEE Transactions on Computing, </journal> <volume> 28(2), </volume> <month> February </month> <year> 1979. </year>
Reference: [Ferg 93] <author> D. Ferguson, C. Nikolaou, L. Geargiadis, K. Davies, </author> <title> "Goal Oriented, Adaptive Transaction Routing for High Performance Transaction Processing Systems," </title> <booktitle> Proc. 2nd Int'l Conf. on Parallel and Distributed Systems, </booktitle> <address> San Diego CA, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: Therefore, the general approach common to all goal-oriented resource allocation work <ref> [Pierce 83, Ferg 93, Brown 93, Brown 94, Chung 94] </ref> is the notion of feedback coupled with "best guess" estimation.
Reference: [Haas 90] <author> L. Haas et al, </author> <title> "Starburst Mid-Flight: As the Dust Clears," </title> <journal> IEEE Trans. on Knowledge and Data Eng., </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: Random accesses to pages are generally made via indexes, 4 and there are a number of techniques available to insure that more valuable index pages are not replaced by less valuable data pages <ref> [Haas 90, O'Neil 93, Johnson 94] </ref>. For index pages themselves, it is possible to use reference frequency statistics or information about the last few references to insure that more valuable index pages are not replaced by less valuable index pages [Copeland 88, O'Neil 93, Brown 93].
Reference: [IBM 93a] <author> IBM Corporation, </author> <title> IBM Database 2 Version 3 Performance Monitoring and Tuning SC26-4888, </title> <institution> IBM Corporation, </institution> <address> San Jose CA, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: While it would be impossible to offer any definitive statement about the likelihood of a hit rate knee in real-world buffer managers, we conducted an empirical study of two simulated buffer managers, one modeled after DB2/MVS <ref> [Cheng 84, Teng 84, IBM 93a] </ref> and the other modeled after DB2/6000 [IBM 93b]. <p> The buffer manager is modeled after that of DB2/MVS <ref> [Teng 84, IBM 93a] </ref>.
Reference: [IBM 93b] <institution> IBM Corporation, Database 2 AIX/6000 Administration Guide SC09-1571, IBM Corporation, </institution> <address> North York, Ontario, Canada, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: Encouraged by our initial simulation studies, we built a prototype version of Fragment Fencing in DB2/6000, IBM's commercial relational database for Unix <ref> [IBM 93b] </ref>. We then experimented with our simulated workloads and some additional workloads, including the TPC-B, TPC-C, and multi-user TPC-D benchmarks [TPC 94]. <p> While it would be impossible to offer any definitive statement about the likelihood of a hit rate knee in real-world buffer managers, we conducted an empirical study of two simulated buffer managers, one modeled after DB2/MVS [Cheng 84, Teng 84, IBM 93a] and the other modeled after DB2/6000 <ref> [IBM 93b] </ref>. For both of these buffer managers, we mapped the hit rate functions for the TPC A/B and C benchmarks, as well as all of the canonical database reference patterns documented in the DBMIN Query Locality Set Model [Chou 85]. None of them showed a knee.
Reference: [Johnson 94] <author> T. Johnson, D. Shasha, </author> <title> "2Q: A Low Overhead High Performance Buffer Management Replacement Algorithm," </title> <booktitle> Proc. 20th Int'l VLDB Conf, </booktitle> <address> Santiago, Chile, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Random accesses to pages are generally made via indexes, 4 and there are a number of techniques available to insure that more valuable index pages are not replaced by less valuable data pages <ref> [Haas 90, O'Neil 93, Johnson 94] </ref>. For index pages themselves, it is possible to use reference frequency statistics or information about the last few references to insure that more valuable index pages are not replaced by less valuable index pages [Copeland 88, O'Neil 93, Brown 93].
Reference: [Ng 91] <author> R. Ng, C. Faloutsos, T. Sellis, </author> <title> "Flexible Buffer Allocation Based on Marginal Gains," </title> <booktitle> Proc. ACM SIGMOD '91 Conf., </booktitle> <address> Denver, CO, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: To our knowledge, no one has explicitly stated it in the form we do here, although some previous work has exploited the notion of concavity in any case [Dan 95]. 3 This notion of page value is synonymous with the concept of marginal gain defined in <ref> [Ng 91] </ref>. 9 will be scanned [Stonebraker 81]. Random accesses to pages are generally made via indexes, 4 and there are a number of techniques available to insure that more valuable index pages are not replaced by less valuable data pages [Haas 90, O'Neil 93, Johnson 94]. <p> memory allocation MT that results in the 4 This is certainly true for relational systems, but less so for object-oriented systems that support navigational access. 5 A straight line approximation of buffer hit rate functions was also used in [Chen 93] to predict a memory allocation that maximizes marginal gain <ref> [Ng 91] </ref>. 10 target hit rate HT.
Reference: [Nikolaou 92] <author> C. Nikolaou, D. Ferguson, P. Constantopoulos, </author> <title> "Towards Goal Oriented Resource Management," </title> <institution> IBM Research Report RC17919, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: Accuracy: The observed average response times for goal classes should be close to their goals. A convenient way to quantify accuracy is the performance index <ref> [Nikolaou 92] </ref>, which is simply the average observed response time divided by the average response time goal. A performance index of one is ideal, greater than one indicates a goal violation, and less than one indicates an exceeded goal. <p> Class Fencing is not designed to make any attempt to reallocate memory in order to minimize the maximum performance index in cases like these where the goals are likely too aggressive for the system as configured. This situation is called degraded 21 mode <ref> [Nikolaou 92] </ref>.
Reference: [O'Neil 93] <author> E. O'Neil, P. O'Neil, G. Weikum, </author> <title> "The LRU-K Page Replacement Algorithm For Database Disk Buffering," </title> <booktitle> Proc. ACM SIGMOD '93 Conf., </booktitle> <address> Washington D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Random accesses to pages are generally made via indexes, 4 and there are a number of techniques available to insure that more valuable index pages are not replaced by less valuable data pages <ref> [Haas 90, O'Neil 93, Johnson 94] </ref>. For index pages themselves, it is possible to use reference frequency statistics or information about the last few references to insure that more valuable index pages are not replaced by less valuable index pages [Copeland 88, O'Neil 93, Brown 93]. <p> For index pages themselves, it is possible to use reference frequency statistics or information about the last few references to insure that more valuable index pages are not replaced by less valuable index pages <ref> [Copeland 88, O'Neil 93, Brown 93] </ref>.
Reference: [Pierce 83] <author> B. Pierce, </author> <title> "The Most Misunderstood Parts of the SRM," </title> <booktitle> Proc. SHARE 61 (IBM users group), </booktitle> <address> New York NY, </address> <month> August </month> <year> 1983. </year>
Reference-contexts: Therefore, the general approach common to all goal-oriented resource allocation work <ref> [Pierce 83, Ferg 93, Brown 93, Brown 94, Chung 94] </ref> is the notion of feedback coupled with "best guess" estimation.
Reference: [Stonebraker 81] <author> M. Stonebraker, </author> <title> "Operating System Support for Database Management," </title> <journal> CACM, </journal> <volume> 24(7), </volume> <month> July, </month> <year> 1981. </year>
Reference-contexts: knowledge, no one has explicitly stated it in the form we do here, although some previous work has exploited the notion of concavity in any case [Dan 95]. 3 This notion of page value is synonymous with the concept of marginal gain defined in [Ng 91]. 9 will be scanned <ref> [Stonebraker 81] </ref>. Random accesses to pages are generally made via indexes, 4 and there are a number of techniques available to insure that more valuable index pages are not replaced by less valuable data pages [Haas 90, O'Neil 93, Johnson 94].
Reference: [Teng 84] <author> J. Teng and R. Gumaer, </author> <title> "Managing IBM Database 2 Buffers to Maximize Performance," </title> <journal> IBM Systems Journal, </journal> <volume> 23(2), </volume> <year> 1984. </year>
Reference-contexts: While it would be impossible to offer any definitive statement about the likelihood of a hit rate knee in real-world buffer managers, we conducted an empirical study of two simulated buffer managers, one modeled after DB2/MVS <ref> [Cheng 84, Teng 84, IBM 93a] </ref> and the other modeled after DB2/6000 [IBM 93b]. <p> The buffer manager is modeled after that of DB2/MVS <ref> [Teng 84, IBM 93a] </ref>.
Reference: [TPC 94] <institution> Transaction Processing Performance Council, TPC Benchmark C, Revision 2.0, </institution> <month> 20 October </month> <year> 1993, </year> <title> and TPC Benchmark D, </title> <note> Working Draft 7.0, </note> <month> 6 May </month> <year> 1994, </year> <title> C/O Shanley Public Relations, 777 N. </title> <booktitle> First St, </booktitle> <address> San Jose, CA. </address>
Reference-contexts: Encouraged by our initial simulation studies, we built a prototype version of Fragment Fencing in DB2/6000, IBM's commercial relational database for Unix [IBM 93b]. We then experimented with our simulated workloads and some additional workloads, including the TPC-B, TPC-C, and multi-user TPC-D benchmarks <ref> [TPC 94] </ref>. Our prototype performed as expected for the types of workloads that we had used in our simulation studies, and accurately held classes to their goals in a stable manner. While our initial experiments were encouraging, our experiments with the TPC workloads uncovered two problems with Fragment Fencing. <p> file B 182 100K 2223 72.3 - U DBMIN unclustered idx B 12 100K 147 4.8 - U DBMIN clustered idx B 12 100K 147 4.8 - U Table 1: Database characteristics 15 The database model consists of a two-part database, with one part taken directly from the TPC-C benchmark <ref> [TPC 94] </ref> using a scale factor of one (one warehouse), and the other drawn from a previously published performance study of the DBMIN buffer management algorithm [Chou 85]. <p> U/H and U/C are special distributions defined in the TPC-C benchmark and can be roughly described as uniform with hot spots and uniform with cold spots, respectively (see <ref> [TPC 94] </ref> for a detailed description). <p> TPC-C: This simulated workload class faithfully duplicates the reference patterns of the TPC-C benchmark as specified in <ref> [TPC 94] </ref>. TPC-C models an order-entry business and is composed of a mix of five different transaction types. These queries are mostly index scans of varying selectivities that produce the reference frequencies and patterns shown in Table 1 (a detailed description is provided in [TPC 94]). <p> the TPC-C benchmark as specified in <ref> [TPC 94] </ref>. TPC-C models an order-entry business and is composed of a mix of five different transaction types. These queries are mostly index scans of varying selectivities that produce the reference frequencies and patterns shown in Table 1 (a detailed description is provided in [TPC 94]). As stated earlier, TPC-C exhibits a high degree of locality.
Reference: [van den Berg 93] <author> J. van den Berg, D. Towsley, </author> <title> "Properties of the Miss Ratio for a 2-Level Storage Model with LRU or FIFO Replacement Strategy and Independent Reference," </title> <journal> IEEE Trans. on Computers, </journal> <volume> 42(4), </volume> <month> April </month> <year> 1993. </year> <month> 26 </month>
Reference-contexts: referenced, and once they are referenced, it can toss or retain these pages based on knowledge of the total number of pages that 2 A similar theorem has been proven for the case of an IRM reference pattern coupled with an LRU replacement policy by van den Berg and Towsley <ref> [van den Berg 93] </ref>.
References-found: 26

