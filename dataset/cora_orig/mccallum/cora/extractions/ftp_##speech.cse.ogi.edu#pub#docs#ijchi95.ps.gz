URL: ftp://speech.cse.ogi.edu/pub/docs/ijchi95.ps.gz
Refering-URL: http://www.cse.ogi.edu/CSLU/personnel/bios/cole.html
Root-URL: http://www.cse.ogi.edu
Title: EXPERIMENTS WITH A SPOKEN DIALOGUE SYSTEM FOR TAKING THE U.S. CENSUS  for Spoken Language Understanding  
Author: R.A. Cole, D.G. Novick, P.J.E. Vermeulen, S. Sutton, M. Fanty L.F.A. Wessels, J.H. de Villiers, J. Schalkwyk, B. Hansen, D. Burnett 
Address: P.O.Box 91000, Portland, OR 97291-1000  
Affiliation: Center  Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  
Abstract: This paper reports the results of the development, deployment and testing of a large spoken-language dialogue application for use by the general public. We built an automated spoken questionnaire for the U.S. Bureau of the Census. In the project's first phase, the basic recognizers and dialogue system were developed using 4,000 calls. In the second phase, the system was adapted to meet Census Bureau requirements and deployed in the Bureau's 1995 national test of new technologies. In the third phase, we refined the system and showed empirically that an automated spoken questionnaire could successfully collect and recognize census data, and that subjects preferred the spoken system to written questionnaires. Our large data collection effort and two subsequent field tests showed that, when questions are asked correctly, the answers contain information within the desired response categories about 99 percent of the time.
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> National Center for Education Statistics. Adult literacy in America. </institution> <type> Technical Report GPO 065-000-00588-3, U.S. </type> <institution> Department of Education, </institution> <address> Washington, DC, </address> <month> Sept </month> <year> 1993. </year>
Reference-contexts: According to a recent study, about 40 percent of the people living in the United States are functionally illiterate; they are unable to read well enough to understand instructions and vcomplete a form <ref> [1] </ref>. By comparison, almost everyone can understand and speak a language, and spoken language systems can be developed for different languages. Spoken language systems might therefore increase responsiveness.
Reference: [2] <author> R.A. Cole, L. Hirschman, L. Atlas, M. Beckman, A. Bierman, M. Bush, J. Cohen, O. Gar-cia, B. Hanson, H. Hermansky, S. Levinson, K. McKeown, N. Morgan, D. Novick, M. Os-tendorf, S. Oviatt, P. Price, H. Silverman, J. Spitz, A. Waibel, C. Weinstein, S. Zahorian, 24 and V. Zue. </author> <title> The challengee of spoken language systems: Research directions for the nineties. </title> <journal> IEEE Transactions on Speech and Audio Processing, </journal> <volume> 3(1) </volume> <pages> 1-21, </pages> <year> 1995. </year>
Reference-contexts: Through careful design of the wording of questions, or prompts, the system can constrain the caller to produce an acceptable range of responses. In highly constrained tasks with relatively small vocabularies, spoken language systems can produce acceptable performance today <ref> [2] </ref>. Moreover, recognition technology is improving at a steady rate, and very low 2 error rates can be expected by the year 2000, especially if large amounts of training data are used to capture the many sources of variability in the signal.
Reference: [3] <author> H. Hermansky. </author> <title> Perceptual linear predictive (PLP) analysis of speech. </title> <journal> Journal of Acoustical Society of America, </journal> <volume> 87(4) </volume> <pages> 1738-1752, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: We use perceptual linear predictive (PLP) analysis <ref> [3] </ref>, which is based on linear predictive coding and takes into account some of the properties of human hearing. The computed seventh-order PLP coefficients and the energy in a 10 msec window is computed every 10 msec and forms a frame of speech. 2.1 Isolated Word Recognition.
Reference: [4] <author> R. A. Cole, M. Noel, D. C. Burnett, M. Fanty, T. Lander, B. Oshika, and S. Sutton. </author> <title> Corpus development activities at the Center for Spoken Language Understanding. </title> <booktitle> In Proceedings of the ARPA Workshop on Human Language Technology, </booktitle> <month> Apr </month> <year> 1994. </year>
Reference-contexts: All the networks had between 25 and 45 hidden units; the performance was not sensitive to the exact number. The networks were trained on a combination of the hand-transcribed portion of the phase 1 corpus, using automatically located phoneme boundaries and a phonetically hand-labeled corpus of telephone speech <ref> [4] </ref>. In the case of hand-labeled data, each labeled phoneme is cut into equal thirds and relabeled according to context as described above. The frames so labeled provide the training data for the network.
Reference: [5] <author> E. Barnard and R. A. Cole. </author> <title> A neural-net training program based on conjugate-gradient optimization. </title> <type> Technical Report CSE 89-014, </type> <institution> Oregon Graduate Institute, 20000 N.W. Walker Rd., Beaverton, </institution> <address> OR, </address> <month> July </month> <year> 1989. </year>
Reference-contexts: We did not have the computational resources to train on every available frame of training data. Instead, we sub-sampled the data so that 1000 frames of each category were selected. The network is a three-layered perceptron, trained with a combination of gradient descent and conjugate-gradient optimization <ref> [5] </ref>, using a mean-squared criterion function. The advantages and disadvantages of using neural networks rather than the typically employed multivariate Gaussians are discussed in detail in [6]. 5 2.1.2 Viterbi Search.
Reference: [6] <author> E. Barnard, R. Cole, M. Fanty, and P. Vermeulen. </author> <title> Real-world speech recognition with neural networks. </title> <booktitle> In Proceedings of the International Workshop on Applications of Neural Networks to Telecommunications 2, </booktitle> <pages> pages 186-193. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hills-dale, NJ, </address> <year> 1995. </year>
Reference-contexts: The network is a three-layered perceptron, trained with a combination of gradient descent and conjugate-gradient optimization [5], using a mean-squared criterion function. The advantages and disadvantages of using neural networks rather than the typically employed multivariate Gaussians are discussed in detail in <ref> [6] </ref>. 5 2.1.2 Viterbi Search. The phonetic classification produces an estimate of the probability that each phoneme part is present at each 10 msec time frame. A Viterbi search then combines this matrix of phoneme classification scores over time so as to decide which word was spoken.
Reference: [7] <author> J.M. Boite, H. Boulard, B. D'Hoore, and M. Haesen. </author> <title> A new approach toward keyword spotting. </title> <booktitle> In Proceedings of the 3rd European Conference on Speech Communication and Technology, </booktitle> <pages> pages 1273-1276, </pages> <address> Berlin, </address> <month> Sept </month> <year> 1993. </year>
Reference-contexts: In addition, there is a great deal of background noise in many of the calls. To overcome these problems, we implemented a simple word-spotting approach in which all words and sounds not in the target set match a single garbage model. We use the approach described in <ref> [7] </ref>, in which the output score for the garbage word is computed as the median value of the top N phoneme scores for each frame, where N varies with the task and is set empirically.
Reference: [8] <author> R. A. Cole, K. Roginski, and M. Fanty. </author> <title> English alphabet recognition with telephone speech. </title> <booktitle> In Advances in Neural Information Processing Systems 4. </booktitle> <address> San Mateo, CA: </address> <note> Morgan Kaufmann, to appear, </note> <year> 1992. </year>
Reference-contexts: If the number of keywords is large (as in the case of the year and day recognizers), a single threshold is used. 2.2 Name Retrieval. The name retrieval algorithm is more complex than the other recognition tasks. It uses the OGI alphabet recognizer <ref> [8] </ref> together with a database of first and last names. The alphabet recognizer has two stages. The first is essentially similar to the isolated word recognizer described above, where the words are the letters of the alphabet and any number of letters is allowed, separated by pauses.
Reference: [9] <author> R. Cole, D. Novick, M. Fanty, S. Sutton, B. Hansen, and D. Burnett. </author> <title> Rapid prototyping of spoken-language systems: The Year 2000 Census project. </title> <booktitle> In Proceedings of the Conference on Spoken Language Systems, </booktitle> <pages> pages 19-23, </pages> <address> Tokyo, Japan, </address> <month> Nov </month> <year> 1993. </year>
Reference: [10] <author> R.A. Cole, D.G. Novick, M. Fanty, P.J.E. Vermeulen, S. Sutton, and D. Burnett. </author> <title> A prototype voice-response questionnaire for the U.S. Census. </title> <booktitle> In Proceedings of ICSLP-94, </booktitle> <pages> pages 683-686, </pages> <month> Sept </month> <year> 1994. </year> <month> 25 </month>
Reference: [11] <author> R.A. Cole, D.G. Novick, D. Burnett, B. Hansen, S. Sutton, and M. Fanty. </author> <title> Towards automatic collection of the U.S. census. </title> <booktitle> In Proceedings of ICASSP'94, </booktitle> <volume> volume I, </volume> <pages> pages 93-96, </pages> <address> Adelaide, Australia, </address> <month> April </month> <year> 1994. </year>
Reference: [12] <author> S. Sutton, B. Hansen, T. Lander, D.G. Novick, and R.A. Cole. </author> <title> Evaluating the effectiveness of dialogue for an automated spoken questionnaire. </title> <type> Technical Report CSE95-12, </type> <institution> Department of Computer Science and Engineering, Oregon Graduate Institute, </institution> <year> 1995. </year>
Reference-contexts: We evaluated the recognition performance of the system, while our colleagues at the Census Bureau evaluated user satisfaction. 3.1 Dialogue Design and Evaluation The goal of this research, described in detail in <ref> [12] </ref>, was to refine the selection and wording of the system prompts and to design a natural dialogue allowing conversational repair and review of the recognized information. <p> All responses to the prompts were transcribed at the word level (time-aligned to the waveform). A behavioral code was assigned to each prompt, indicating if the response fit classifications such as "informative" or "concise." The behavioral coding scheme is described in <ref> [12] </ref>. Data collection and coding was 9 labor intensive, requiring the full time efforts of four people for over six months. 3.1.2 Evaluation of the Prompts Analysis of the behavioral codes was undertaken for at least 1,200 callers for each prompt.
Reference: [13] <author> M. Fanty, R. A. Cole, and K. Roginski. </author> <title> English alphabet recognition with telephone speech. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippman, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: Only responses containing a target word were run. The data collected for this task is noisier than other corpora we have collected. It is also regionally very diverse. Name Recognition The OGI name retrieval algorithm is designed for spelling with pauses between the letters <ref> [13] </ref>. However, callers were not asked to pause during the collection of this corpus in order to create a data set on which to develop fluent letter recognition. Other than retraining the classifier, the system architecture has not yet changed; in particular, alternate segmentations are not considered.
Reference: [14] <author> C.R. Jenkins and J. Kemper. </author> <title> Report on respondents' attitudes towards a computer administered voice-recognition census short form. </title> <type> Internal report, </type> <institution> Statistical Research Division, U.S. Bureau of the Census, </institution> <month> October 28, </month> <year> 1994. </year>
Reference-contexts: About 90 percent of the respondents in both the pre- and the posttest said that they were willing to answer the census by computer... In general, respondents 12 were impressed with the system, ranking it just below a comparable interviewer-administered questionnaire <ref> [14] </ref>." 3.5 Summary of Feasibility Study Phase 1 of the OGI Census project demonstrated that a voice questionnaire could be designed to capture information on the census form with high reliability.
Reference: [15] <author> R. A. Cole, M. Noel, T. Lander, and T. Durham. </author> <title> New telephone speech corpora at CSLU. </title> <booktitle> In Proceedings of Eurospeech95, </booktitle> <address> Madrid, Spain, </address> <month> Oct </month> <year> 1995. </year> <month> 26 </month>
Reference-contexts: The recognizers were trained on OGI's phonetically labeled speech corpora <ref> [15] </ref>. 17 4.2 The Two-Day Census Load Test Because so few calls were received during the actual test, a two-day load test was performed to assess the ability of the system to handle multiple simultaneous calls.
References-found: 15

