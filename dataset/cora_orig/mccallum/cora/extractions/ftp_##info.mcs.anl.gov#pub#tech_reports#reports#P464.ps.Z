URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P464.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts94.htm
Root-URL: http://www.mcs.anl.gov
Title: SOFTWARE FOR THE GENERALIZED EIGENPROBLEM ON DISTRIBUTED MEMORY ARCHITECTURES  
Author: MARK T. JONES AND PAUL E. PLASSMANN 
Abstract: The generalized eigenproblem is of significant importance in several fields. Generalized eigenproblems can be very large with matrices of order greater than one million for problems arising from three-dimensional finite element models. To solve such problems we are proposing a flexible software system for parallel distributed memory architectures. This software is based on the Lanczos algorithm with a shift-and-invert transformation. In this paper we briefly describe the prototype version of the software, present computational results, and indicate the status of the project. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. P. Blankenship and R. J. Hayduk, </author> <title> Potential supercomputer needs for structural analysis. </title> <booktitle> Presentation at the Second International Conference on Supercomputing (Santa Clara, </booktitle> <address> CA), </address> <month> May 3-8 </month> <year> 1987. </year>
Reference-contexts: 1. Introduction. The solution of the symmetric generalized eigenvalue problem, Kx = M x;(1) where K and M are real, symmetric matrices, and either K or M is positive semi-definite, is of significant practical importance, especially in structural engineering as the vibration problem and the buckling problem <ref> [1] </ref>. The matrices K and M are either banded or sparse. Usually m &lt;< n of the smallest eigenvalues of Equation 1 are sought, where n is the order of the system.
Reference: [2] <author> T. Canfield, M. T. Jones, P. E. Plassmann, and M. Tang, </author> <title> Thermal effects on the frequency response of piezoelectric crystals, in New Methods in Transient Analysis, </title> <booktitle> PVP-Vol. 246 and AMD-Vol. 143, </booktitle> <address> New York, </address> <year> 1992, </year> <booktitle> ASME, </booktitle> <pages> pp. 103-108. </pages>
Reference-contexts: Some Experimental Results. Using a prototype version of the core, reverse communication software combined with BlockSolve, the following results were obtained on the Intel DELTA for a practical vibration problem arising from a finite element model <ref> [2] </ref>: p n nnz Mflops/ Total Proc. Mflops 64 7:7 fi 10 4 1:6 fi 10 7 4.88 312 256 3:2 fi 10 5 6:8 fi 10 7 4.87 1247 2 Note that the problem size per processor is fixed as the number of processors varies.
Reference: [3] <author> R. G. Grimes, J. G. Lewis, and H. D. Simon, </author> <title> The implementation of a block shifted and inverted Lanczos algorithm for eigenvalue problems in structural engineering, </title> <institution> ETA-TR-39, Boeing Computer Services, </institution> <address> Seattle, Washington, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: In this paper we will discuss our plans for scalable software, provide brief prototype results, and give the current status of the software. 2. Distributed-Memory Software. The basic algorithm in the software is the block Lanczos algorithm with a spectral transformation as described in <ref> [3] </ref>. The reader is referred to [3] for a complete description of the algorithm. <p> Distributed-Memory Software. The basic algorithm in the software is the block Lanczos algorithm with a spectral transformation as described in <ref> [3] </ref>. The reader is referred to [3] for a complete description of the algorithm.
Reference: [4] <author> M. T. Jones and M. L. Patrick, LANZ: </author> <title> Software for solving the large sparse symmetric generalized eigenproblem, </title> <type> Preprint MCS-P158-0690, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Il., </institution> <year> 1990. </year> <note> Also available as ICASE Interim Report no. </note> <month> 12. </month> <title> [5] , The Lanczos algorithm for the generalized symmetric eigenproblem on shared-memory architectures, </title> <journal> Applied Numerical Mathematics, </journal> <volume> 12 (1993), </volume> <pages> pp. </pages> <month> 377-389. </month> <title> [6] , Factoring symmetric indefinite matrices on high-performance architectures, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 15 (1994), </volume> <pages> pp. 273-283. </pages>
Reference-contexts: The Lanczos algorithm for the generalized eigenproblem [10] has been shown to be effective on vector supercomputers and shared-memory parallel computers [5]. An effective software package, LANZ <ref> [4] </ref>, for shared-memory parallel computers has been developed and is available from netlib. However, the LANZ software is not suitable for distributed-memory architectures such as the Intel DELTA, the Thinking Machines CM-5, and the IBM SP-1.
Reference: [7] <author> M. T. Jones and P. E. Plassmann, </author> <title> BlockSolve v1.0: Scalable library software for the parallel solution of sparse linear systems, </title> <type> ANL Report ANL-92/46, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1992. </year> <title> [8] , A parallel graph coloring heuristic, </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 14 (1993), </volume> <pages> pp. 654-669. </pages>
Reference-contexts: The most difficult part of the eigensolution to parallelize, as well as the most com-putationally expensive, is the solution of Equation 2. For this computation at least two options are planned. First, a preliminary interface to the iterative methods in the Block-Solve package <ref> [7] </ref> has been constructed. This package provides portable, parallel software for the conjugate gradient method preconditioned by incomplete factorization; the parallelism is obtained by employing a parallel graph coloring heuristic [8].
Reference: [9] <author> C. </author> <title> Lanczos, An iteration method for the solution of the eigenvalue problem of linear differential and integral operators, </title> <journal> Journal of Research of the National Bureau of Standards, </journal> <volume> 45 (1950), </volume> <pages> pp. 255-282. </pages>
Reference-contexts: The matrices K and M are either banded or sparse. Usually m &lt;< n of the smallest eigenvalues of Equation 1 are sought, where n is the order of the system. The method of Lanczos <ref> [9] </ref>, suitably altered for the generalized eigenvalue problem, has been shown to be useful for the efficient solution of Equation 1 [10]. The Lanczos algorithm for the generalized eigenproblem [10] has been shown to be effective on vector supercomputers and shared-memory parallel computers [5].
Reference: [10] <author> B. Nour-Omid, B. N. Parlett, T. Ericsson, and P. S. Jensen, </author> <title> How to implement the spectral transformation, </title> <journal> Mathematics of Computation, </journal> <volume> 48 (1987), </volume> <pages> pp. 663-673. </pages>
Reference-contexts: Usually m &lt;< n of the smallest eigenvalues of Equation 1 are sought, where n is the order of the system. The method of Lanczos [9], suitably altered for the generalized eigenvalue problem, has been shown to be useful for the efficient solution of Equation 1 <ref> [10] </ref>. The Lanczos algorithm for the generalized eigenproblem [10] has been shown to be effective on vector supercomputers and shared-memory parallel computers [5]. An effective software package, LANZ [4], for shared-memory parallel computers has been developed and is available from netlib. <p> The method of Lanczos [9], suitably altered for the generalized eigenvalue problem, has been shown to be useful for the efficient solution of Equation 1 <ref> [10] </ref>. The Lanczos algorithm for the generalized eigenproblem [10] has been shown to be effective on vector supercomputers and shared-memory parallel computers [5]. An effective software package, LANZ [4], for shared-memory parallel computers has been developed and is available from netlib.
Reference: [11] <author> A. Pothen, H. D. Simon, and K.-P. Liou, </author> <title> Partitioning sparse matrices with eigenvectors of graphs, </title> <journal> SIAM Journal of Matrix Analysis and Applications, </journal> <volume> 11 (1990), </volume> <pages> pp. 430-452. </pages>
Reference-contexts: If such a partitioning has not been done, many algorithms and some software currently exist for this problem (see, for example, <ref> [11] </ref> [13]). The most difficult part of the eigensolution to parallelize, as well as the most com-putationally expensive, is the solution of Equation 2. For this computation at least two options are planned. First, a preliminary interface to the iterative methods in the Block-Solve package [7] has been constructed.
Reference: [12] <author> P. Raghavan, </author> <title> User's manual: CAPSS: A Cartesian parallel sparse solver. </title> <institution> National Center for Supercomputer Applications, University of Illinois at Urbana-Champaign, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: The interface to this package is relatively straightforward, but poor convergence can result when oe in Equation 2 is large relative to the smallest eigenvalue in Equation 1. This difficulty must be addressed. Also planned is an interface to the parallel direct sparse factorization methods in the CAPSS package <ref> [12] </ref>. This package provides a parallel implementation of sparse Cholesky factorization. When oe is larger than the smallest eigenvalue in Equation 1, one could, at the risk of a loss of stability, use the LDL T decomposition.
Reference: [13] <author> R. D. Williams, </author> <title> Performance of dynamic load balancing algorithms for unstructured mesh calculations, </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 3 (1991), </volume> <pages> pp. 457-481. 3 </pages>
Reference-contexts: If such a partitioning has not been done, many algorithms and some software currently exist for this problem (see, for example, [11] <ref> [13] </ref>). The most difficult part of the eigensolution to parallelize, as well as the most com-putationally expensive, is the solution of Equation 2. For this computation at least two options are planned. First, a preliminary interface to the iterative methods in the Block-Solve package [7] has been constructed.
References-found: 10

