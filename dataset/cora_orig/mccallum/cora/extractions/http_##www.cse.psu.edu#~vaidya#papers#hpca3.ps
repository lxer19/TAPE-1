URL: http://www.cse.psu.edu/~vaidya/papers/hpca3.ps
Refering-URL: http://www.cse.psu.edu/~vaidya/publications.html
Root-URL: http://www.cse.psu.edu
Email: dasg@cse.psu.edu  
Title: Towards a Communication Characterization Methodology for Parallel Applications  
Author: Sucheta Chodnekar, Viji Srinivasan, Aniruddha S. Vaidya Anand Sivasubramaniam, Chita R. Das fchodneka, srinivas, vaidya, anand, 
Address: Park, PA 16802  
Affiliation: Department of Computer Science and Engineering The Pennsylvania State University University  
Abstract: Interconnection network (ICN) is a vital component of a parallel machine and is often the limiting factor in the performance of several parallel applications. While ICN performance evaluation has been a widely researched topic, there have been very few studies that have used real applications to drive this research. In this paper, we develop a framework for characterizing the communication properties of parallel applications. Message generation frequency, spatial distribution of messages and message length are the three attributes that quantify any communication. We develop a methodology to quantify these attributes, in particular the first two attributes. We employ two strategies, namely dynamic and static, in our methodology. In the former, the applications are executed on an execution-driven simulator called SPASM, while in the latter they are executed on a parallel machine, IBM SP2. We gather communication events from these executions and feed them to a 2-D mesh network simulator. The log of the network activity is then analyzed using a statistical analysis package (SAS) to find the message inter-arrival time distribution and spatial distribution via regression analysis. Five shared memory applications and two message passing applications are analyzed to quantify their communication workloads. It is shown that it is possible to express the message generation and spatial distribution of an application in terms of commonly used distributions. These distributions can be used in the analysis of ICNs for developing realistic performance models. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. P. Singh, E. Rothberg, and A. Gupta, </author> <title> Modeling communication in parallel algorithms: A fruitful interaction between theory and systems?, </title> <booktitle> in Proceedings of the Sixth Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1994. </year>
Reference-contexts: The communication traffic of a parallel application can be captured by three attributes namely the temporal, spatial and volume components <ref> [1] </ref>. Temporal behavior is captured by the message generation rate, spatial behavior is expressed in terms of the message distribution or traffic pattern, and volume of communication is specified by the number of messages and the message length distribution. <p> The need to characterize the communication properties of parallel applications is stated emphatically in <ref> [1] </ref>. It is, therefore, crucial to develop some formal techniques to capture the communication properties of parallel applications.
Reference: [2] <author> D. A. Reed and D. C. Grunwald, </author> <title> The Performance of Multicomputer Interconnection Networks, </title> <booktitle> IEEE Computer, </booktitle> <pages> pp. 63-73, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: However, most performance models for interconnection networks have been accused of making unrealistic assumptions about the communication workload. The most critical one being the uniform traffic assumption in the network. Locality of communication has been addressed by a few researchers <ref> [2, 3, 4, 5] </ref> But these studies do not show the correspondence between the parallel applications and traffic patterns. It is not clear what are the traffic patterns generated by parallel applications and how these traffic patterns can be captured by a distribution function for subsequent study.
Reference: [3] <author> V. S. Adve and M. K. Vernon, </author> <title> Performance Analysis of Mesh Interconnection Networks with Deterministic Routing, </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> vol. 5, </volume> <pages> pp. 225-246, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: However, most performance models for interconnection networks have been accused of making unrealistic assumptions about the communication workload. The most critical one being the uniform traffic assumption in the network. Locality of communication has been addressed by a few researchers <ref> [2, 3, 4, 5] </ref> But these studies do not show the correspondence between the parallel applications and traffic patterns. It is not clear what are the traffic patterns generated by parallel applications and how these traffic patterns can be captured by a distribution function for subsequent study.
Reference: [4] <author> J. Kim and C. R. Das, </author> <title> Hypercube Communication Delay with Wormhole Routing, </title> <journal> IEEE Trans. on Computers, </journal> <volume> vol. 43, </volume> <pages> pp. 806-814, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: However, most performance models for interconnection networks have been accused of making unrealistic assumptions about the communication workload. The most critical one being the uniform traffic assumption in the network. Locality of communication has been addressed by a few researchers <ref> [2, 3, 4, 5] </ref> But these studies do not show the correspondence between the parallel applications and traffic patterns. It is not clear what are the traffic patterns generated by parallel applications and how these traffic patterns can be captured by a distribution function for subsequent study.
Reference: [5] <author> M. L. Fulgham and L. Snyder, </author> <title> Performance of Chaos and Oblivous Routers under Non-Uniform Traffic, </title> <type> Tech. Rep. </type> <institution> UW-CSE-93-06-01, Depart--ment of Computer Science and Engineering, University of Washington, </institution> <address> Seattle, WA 98195, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: However, most performance models for interconnection networks have been accused of making unrealistic assumptions about the communication workload. The most critical one being the uniform traffic assumption in the network. Locality of communication has been addressed by a few researchers <ref> [2, 3, 4, 5] </ref> But these studies do not show the correspondence between the parallel applications and traffic patterns. It is not clear what are the traffic patterns generated by parallel applications and how these traffic patterns can be captured by a distribution function for subsequent study.
Reference: [6] <author> R. Ponnusamy, R. Thakur, A. Choudhary, K. Vela-makanni, Z. Bozkus, and G. Fox, </author> <title> Experimental performance evaluation of the CM-5, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 19, </volume> <pages> pp. 192-202, </pages> <year> 1993. </year>
Reference-contexts: Therefore, the credibility of many model-based performance results has been questioned frequently. In an effort to predict performance more accurately, researchers have relied on actual execution <ref> [6, 7] </ref> or execution-driven simulation [8, 9, 10, 11, 12] of parallel applications. The main problem with these approaches is that they are both expensive. The actual execution approach requires the physical realization of the machine before the evaluation can be conducted. <p> The NAS [15], PARKBENCH [16], and SPLASH [17] suites are examples of applications that have been widely used for benchmarking the performance of parallel machines <ref> [15, 7, 18, 6] </ref>. However, there have been very few studies [8, 19, 20] that have used real applications to evaluate the interconnection network.
Reference: [7] <author> U. Ramachandran, G. Shah, S. Ravikumar, and J. Muthukumarasamy, </author> <title> Scalability study of the KSR-1, </title> <booktitle> in Proceedings of the 1993 International Conference on Parallel Processing, </booktitle> <pages> pp. </pages> <address> I-237-240, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Therefore, the credibility of many model-based performance results has been questioned frequently. In an effort to predict performance more accurately, researchers have relied on actual execution <ref> [6, 7] </ref> or execution-driven simulation [8, 9, 10, 11, 12] of parallel applications. The main problem with these approaches is that they are both expensive. The actual execution approach requires the physical realization of the machine before the evaluation can be conducted. <p> The NAS [15], PARKBENCH [16], and SPLASH [17] suites are examples of applications that have been widely used for benchmarking the performance of parallel machines <ref> [15, 7, 18, 6] </ref>. However, there have been very few studies [8, 19, 20] that have used real applications to evaluate the interconnection network.
Reference: [8] <author> A. Sivasubramaniam, A. Singla, U. Ramachandran, and H. Venkateswaran, </author> <title> An Approach to Scalability Study of Shared Memory Parallel Systems, </title> <booktitle> in Proceedings of the ACM SIGMETRICS 1994 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pp. 171-180, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Therefore, the credibility of many model-based performance results has been questioned frequently. In an effort to predict performance more accurately, researchers have relied on actual execution [6, 7] or execution-driven simulation <ref> [8, 9, 10, 11, 12] </ref> of parallel applications. The main problem with these approaches is that they are both expensive. The actual execution approach requires the physical realization of the machine before the evaluation can be conducted. <p> The NAS [15], PARKBENCH [16], and SPLASH [17] suites are examples of applications that have been widely used for benchmarking the performance of parallel machines [15, 7, 18, 6]. However, there have been very few studies <ref> [8, 19, 20] </ref> that have used real applications to evaluate the interconnection network. Siva-subramaniam et al. [8, 19] use an execution-driven simulator called SPASM to study the performance of a set of applications on different network topologies in both shared memory [8] and message-passing settings [19]. <p> However, there have been very few studies [8, 19, 20] that have used real applications to evaluate the interconnection network. Siva-subramaniam et al. <ref> [8, 19] </ref> use an execution-driven simulator called SPASM to study the performance of a set of applications on different network topologies in both shared memory [8] and message-passing settings [19]. <p> However, there have been very few studies [8, 19, 20] that have used real applications to evaluate the interconnection network. Siva-subramaniam et al. [8, 19] use an execution-driven simulator called SPASM to study the performance of a set of applications on different network topologies in both shared memory <ref> [8] </ref> and message-passing settings [19]. Bhuyan et al. [20] use another execution-driven simulator to study the impact of virtual channels on the performance of a 2-D torus in a shared memory environment. <p> But, none of these studies help us quantify the three communication attributes which can be used in subsequent network performance evaluation research. 2.3 Execution-driven Simulation Several execution-driven simulators such as Tango [9], Proteus [10], Rice Parallel Processing Testbed [11], MINT [12] and SPASM <ref> [8, 19] </ref> have been developed to evaluate parallel architectures. These simulators do not capture the details of instruction execution of a processor. They work on the presumption that simulating each instruction is not likely to significantly impact the understanding of parallel system behavior. <p> Most of the application code is executed at the speed of the native processor and only interesting instructions are trapped to the simulator and simulated. However, apart from SPASM <ref> [8, 19] </ref> and an augmentation to the Proteus simulator by Kumar and Bhuyan [20], other simulators [9, 11, 12] do not simulate the details of the interconnection network. 3 Traffic Characterization Methodology The goal of this research is to characterize the communication behavior of a wide spectrum of parallel applications. <p> Hence, we resort to an execution-driven simulation of the applications using SPASM <ref> [8] </ref>. In an execution-driven simulator, as each communication event is generated there is also a feedback from the network simulator to the event generator indicating the simulated time of the event (as indicated by the two arrows between the network simulator and the execution-driven simulator in order. <p> The simulated CC-NUMA machine for this study employs an invalidation- based cache coherence scheme with sequential consistency using a full-map directory <ref> [8] </ref>. <p> In the following discussion, we give a brief description of each application along with the results from the statistical analysis. 4.1 Shared Memory Applications 1D-FFT: 1D-FFT <ref> [8] </ref> implements a 1-dimensional complex Fast Fourier Transform. Each processor works on an assigned portion of the data space that is equally partitioned. There are three main phases in the execution. In the first and last phase, the processors perform the radix-2 Butterfly computation, which is an entirely local operation. <p> Note that we are plotting the fraction of messages sent by a processor to others in the system. IS: IS is an Integer Sort kernel <ref> [8] </ref> that uses bucket sort to rank a list of integers. This application also has a regular communication pattern. The input data is equally partitioned among the processors. Each processor maintains local buckets for the chunk of the input list that is allocated to it.
Reference: [9] <author> H. Davis, S. R. Goldschmidt, and J. L. Hen-nessy, </author> <title> Multiprocessor Simulation and Tracing Using Tango, </title> <booktitle> in Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <pages> pp. II 99-107, </pages> <year> 1991. </year>
Reference-contexts: Therefore, the credibility of many model-based performance results has been questioned frequently. In an effort to predict performance more accurately, researchers have relied on actual execution [6, 7] or execution-driven simulation <ref> [8, 9, 10, 11, 12] </ref> of parallel applications. The main problem with these approaches is that they are both expensive. The actual execution approach requires the physical realization of the machine before the evaluation can be conducted. <p> Also, it may not be feasible to change or include additional features to an existing machine. An execution-driven simulator, on the other hand, can simulate any architecture. But, the resource requirement (in terms of space and time) for such simulators is high. Thus, simulators like Proteus [10], Tango <ref> [9] </ref> and Rice Parallel Processing Test bed [11] have refrained from simulating the network in detail. <p> Hsu and Banerjee [23] analyze the communication characteristics of parallel CAD applications on a hypercube. But, none of these studies help us quantify the three communication attributes which can be used in subsequent network performance evaluation research. 2.3 Execution-driven Simulation Several execution-driven simulators such as Tango <ref> [9] </ref>, Proteus [10], Rice Parallel Processing Testbed [11], MINT [12] and SPASM [8, 19] have been developed to evaluate parallel architectures. These simulators do not capture the details of instruction execution of a processor. <p> Most of the application code is executed at the speed of the native processor and only interesting instructions are trapped to the simulator and simulated. However, apart from SPASM [8, 19] and an augmentation to the Proteus simulator by Kumar and Bhuyan [20], other simulators <ref> [9, 11, 12] </ref> do not simulate the details of the interconnection network. 3 Traffic Characterization Methodology The goal of this research is to characterize the communication behavior of a wide spectrum of parallel applications. <p> We use SPASM for simulating the CC-NUMA architecture. As with several recent simulators <ref> [10, 9, 11] </ref>, SPASM does not simulate the details of the instruction execution. Instead, it only simulates instructions that may potentially involve network access such as LOADs and STOREs on shared memory machines. The input to the simulator are applications written in C.
Reference: [10] <author> E. A. Brewer, C. N. Dellarocas, A. Colbrook, and W. E. Weihl, </author> <title> PROTEUS : A high-performance parallel-architecture simulator, </title> <type> Tech. Rep. </type> <institution> MIT-LCS-TR-516, Massachusetts Institute of Technology, </institution> <address> Cambridge, MA 02139, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: Therefore, the credibility of many model-based performance results has been questioned frequently. In an effort to predict performance more accurately, researchers have relied on actual execution [6, 7] or execution-driven simulation <ref> [8, 9, 10, 11, 12] </ref> of parallel applications. The main problem with these approaches is that they are both expensive. The actual execution approach requires the physical realization of the machine before the evaluation can be conducted. <p> Also, it may not be feasible to change or include additional features to an existing machine. An execution-driven simulator, on the other hand, can simulate any architecture. But, the resource requirement (in terms of space and time) for such simulators is high. Thus, simulators like Proteus <ref> [10] </ref>, Tango [9] and Rice Parallel Processing Test bed [11] have refrained from simulating the network in detail. <p> Hsu and Banerjee [23] analyze the communication characteristics of parallel CAD applications on a hypercube. But, none of these studies help us quantify the three communication attributes which can be used in subsequent network performance evaluation research. 2.3 Execution-driven Simulation Several execution-driven simulators such as Tango [9], Proteus <ref> [10] </ref>, Rice Parallel Processing Testbed [11], MINT [12] and SPASM [8, 19] have been developed to evaluate parallel architectures. These simulators do not capture the details of instruction execution of a processor. <p> We use SPASM for simulating the CC-NUMA architecture. As with several recent simulators <ref> [10, 9, 11] </ref>, SPASM does not simulate the details of the instruction execution. Instead, it only simulates instructions that may potentially involve network access such as LOADs and STOREs on shared memory machines. The input to the simulator are applications written in C.
Reference: [11] <author> R. G. Covington, S. Madala, V. Mehta, J. R. Jump, and J. B. Sinclair, </author> <title> The Rice parallel processing testbed, </title> <booktitle> in Proceedings of the ACM SIGMETRICS 1988 Conference on Measurement and Modeling of Computer Systems, </booktitle> <address> (Santa Fe, NM), </address> <pages> pp. 4-11, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Therefore, the credibility of many model-based performance results has been questioned frequently. In an effort to predict performance more accurately, researchers have relied on actual execution [6, 7] or execution-driven simulation <ref> [8, 9, 10, 11, 12] </ref> of parallel applications. The main problem with these approaches is that they are both expensive. The actual execution approach requires the physical realization of the machine before the evaluation can be conducted. <p> An execution-driven simulator, on the other hand, can simulate any architecture. But, the resource requirement (in terms of space and time) for such simulators is high. Thus, simulators like Proteus [10], Tango [9] and Rice Parallel Processing Test bed <ref> [11] </ref> have refrained from simulating the network in detail. <p> But, none of these studies help us quantify the three communication attributes which can be used in subsequent network performance evaluation research. 2.3 Execution-driven Simulation Several execution-driven simulators such as Tango [9], Proteus [10], Rice Parallel Processing Testbed <ref> [11] </ref>, MINT [12] and SPASM [8, 19] have been developed to evaluate parallel architectures. These simulators do not capture the details of instruction execution of a processor. They work on the presumption that simulating each instruction is not likely to significantly impact the understanding of parallel system behavior. <p> Most of the application code is executed at the speed of the native processor and only interesting instructions are trapped to the simulator and simulated. However, apart from SPASM [8, 19] and an augmentation to the Proteus simulator by Kumar and Bhuyan [20], other simulators <ref> [9, 11, 12] </ref> do not simulate the details of the interconnection network. 3 Traffic Characterization Methodology The goal of this research is to characterize the communication behavior of a wide spectrum of parallel applications. <p> We use SPASM for simulating the CC-NUMA architecture. As with several recent simulators <ref> [10, 9, 11] </ref>, SPASM does not simulate the details of the instruction execution. Instead, it only simulates instructions that may potentially involve network access such as LOADs and STOREs on shared memory machines. The input to the simulator are applications written in C.
Reference: [12] <author> J. E. Veenstra and R. J. Fowler, MINT: </author> <title> A Front End for Efficient Simulation of Shared Memory Multiprocessors, </title> <booktitle> in Proceedings of MASCOTS '94, </booktitle> <pages> pp. 201-207, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: Therefore, the credibility of many model-based performance results has been questioned frequently. In an effort to predict performance more accurately, researchers have relied on actual execution [6, 7] or execution-driven simulation <ref> [8, 9, 10, 11, 12] </ref> of parallel applications. The main problem with these approaches is that they are both expensive. The actual execution approach requires the physical realization of the machine before the evaluation can be conducted. <p> But, none of these studies help us quantify the three communication attributes which can be used in subsequent network performance evaluation research. 2.3 Execution-driven Simulation Several execution-driven simulators such as Tango [9], Proteus [10], Rice Parallel Processing Testbed [11], MINT <ref> [12] </ref> and SPASM [8, 19] have been developed to evaluate parallel architectures. These simulators do not capture the details of instruction execution of a processor. They work on the presumption that simulating each instruction is not likely to significantly impact the understanding of parallel system behavior. <p> Most of the application code is executed at the speed of the native processor and only interesting instructions are trapped to the simulator and simulated. However, apart from SPASM [8, 19] and an augmentation to the Proteus simulator by Kumar and Bhuyan [20], other simulators <ref> [9, 11, 12] </ref> do not simulate the details of the interconnection network. 3 Traffic Characterization Methodology The goal of this research is to characterize the communication behavior of a wide spectrum of parallel applications.
Reference: [13] <author> S. R. Goldschmidt and J. L. Hennessy, </author> <title> The accuracy of trace-driven simulations of multiprocessors, </title> <booktitle> in Proceedings of the ACM SIGMETRICS 1993 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pp. 146-157, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: These traces are then intelligently used by a trace profiler and analyzer and are input to the 2-D network simulator avoiding the usual pitfalls of trace-driven simulation <ref> [13] </ref>. For both application categories, we intentionally use the same 2-D network topology and log the network events in our simulation. We then use a statistical package (SAS [14]) to analyze the log to quantify the communication attributes (primarily message inter-arrival time distribution, and spatial distribution of messages). <p> Application execution on a parallel machine would be much faster than simulating the application details. We execute such applications on an available parallel machine and trace the communication events. These traces are then fed intelligently to our network simulator to avoid the traditional pitfalls of trace-driven simulation <ref> [13] </ref>. Since the order of execution of events on our network simulator would be the same as the order of execution on any machine, the event generator does not have to be informed or stalled unlike the execution-driven approach.
Reference: [14] <institution> SAS Institute Inc., Cary, </institution> <address> NC 27512, </address> <note> SAS/STAT User's Guide, </note> <year> 1988. </year>
Reference-contexts: For both application categories, we intentionally use the same 2-D network topology and log the network events in our simulation. We then use a statistical package (SAS <ref> [14] </ref>) to analyze the log to quantify the communication attributes (primarily message inter-arrival time distribution, and spatial distribution of messages). <p> We have used the statistical analysis package, SAS <ref> [14] </ref> for the regression analysis. The non-linear model with iterative methods for curve-fitting is provided by the package. We have used the multivariate secant method for our study. <p> From this log, we obtain the source-destination information of the messages along with the message length and time of injection. This information has been analyzed to obtain regression models using the SAS <ref> [14] </ref> statistical package.
Reference: [15] <author> D. Bailey et al., </author> <title> The NAS Parallel Benchmarks, </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> vol. 5, no. 3, </volume> <pages> pp. 63-73, </pages> <year> 1991. </year>
Reference-contexts: The NAS <ref> [15] </ref>, PARKBENCH [16], and SPLASH [17] suites are examples of applications that have been widely used for benchmarking the performance of parallel machines [15, 7, 18, 6]. However, there have been very few studies [8, 19, 20] that have used real applications to evaluate the interconnection network. <p> The NAS [15], PARKBENCH [16], and SPLASH [17] suites are examples of applications that have been widely used for benchmarking the performance of parallel machines <ref> [15, 7, 18, 6] </ref>. However, there have been very few studies [8, 19, 20] that have used real applications to evaluate the interconnection network. <p> The applications (3D-FFT and MG from the NAS suite <ref> [15] </ref>) that we use in this study employ the Message Passing Interface (MPI) library to communicate between processors. The tracing of the communication in the application has been performed using a utility obtained from IBM. This utility traces the communication calls at the application level, not at the hardware level. <p> Number (8 procs) 0 0.04 0.08 0.12 0 1 2 3 4 5 6 7 Message Volume Distribution for p0 Processor Number (8 procs) 0 0.04 0.08 0.12 0 1 2 3 4 5 6 7 Message Volume Distribution for p1 Processor Number (8 procs) 3D-FFT: The kernel benchmark 3D-FFT <ref> [15] </ref> is an implementation of the 3D-FFT. A 3-D array of data is dis tributed according to z-planes of the array one or more planes are stored in each processor. <p> This is because the application uses processor p0 as the root of all the broadcast calls resulting in processor p0 being the favorite. However, the volume distribution is uniform for all the processors as shown in the Figure 9. MG: The multigrid <ref> [15] </ref> benchmark is a simple multigrid solver in computing a three dimensional potential field. It solves only a constant coefficient equation, on a uniform cubical field. It requires a power-of-two number of processors.
Reference: [16] <author> PARKBENCH Committee, </author> <title> Public International Benchmarks for Parallel Computers, </title> <month> February </month> <year> 1994. </year> <editor> Report-1, assembled by R. Hockney and M. </editor> <publisher> Berry. </publisher>
Reference-contexts: The NAS [15], PARKBENCH <ref> [16] </ref>, and SPLASH [17] suites are examples of applications that have been widely used for benchmarking the performance of parallel machines [15, 7, 18, 6]. However, there have been very few studies [8, 19, 20] that have used real applications to evaluate the interconnection network.
Reference: [17] <author> J. P. Singh, W.-D. Weber, and A. Gupta, </author> <title> SPLASH: Stanford Parallel Applications for Shared-Memory, </title> <type> Tech. Rep. </type> <institution> CSL-TR-91-469, Computer Systems Laboratory, Stanford University, </institution> <year> 1991. </year>
Reference-contexts: The NAS [15], PARKBENCH [16], and SPLASH <ref> [17] </ref> suites are examples of applications that have been widely used for benchmarking the performance of parallel machines [15, 7, 18, 6]. However, there have been very few studies [8, 19, 20] that have used real applications to evaluate the interconnection network. <p> This pattern can be expressed as a bimodal uniform distribution one processor gets the maximum number of messages and the rest of them get equal number of messages. Cholesky: Cholesky is an application drawn from the SPLASH benchmark suite <ref> [17] </ref>. This application performs a Cholesky factorization of a sparse positive definite matrix. The sparse nature of the matrix results in an algorithm with a data-dependent dynamic access pattern. <p> As stated for the IS application, the favorite processor pattern can be modeled by a bimodal uniform distribution. Nbody: The Nbody <ref> [17] </ref> application simulates over time the movement of bodies due to the gravitational forces exerted on one another, given some set of initial conditions. The parallel implementation statically allocates a set of bodies to each processor and goes through three phases for each simulated time step.
Reference: [18] <author> J. P. Singh, T. Joe, A. Gupta, and J. L. Hennessy, </author> <title> An Empirical Comparison of the Kendall Square Research KSR-1 and Stanford DASH Multiprocessors, </title> <booktitle> in Proceedings of Supercomputing '93, </booktitle> <pages> pp. 214-225, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: The NAS [15], PARKBENCH [16], and SPLASH [17] suites are examples of applications that have been widely used for benchmarking the performance of parallel machines <ref> [15, 7, 18, 6] </ref>. However, there have been very few studies [8, 19, 20] that have used real applications to evaluate the interconnection network.
Reference: [19] <author> A. Sivasubramaniam, A. Singla, U. Ramachandran, and H. Venkateswaran, </author> <title> A Simulation-based Scalability Study of Parallel Systems, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 22, </volume> <pages> pp. 411-426, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: The NAS [15], PARKBENCH [16], and SPLASH [17] suites are examples of applications that have been widely used for benchmarking the performance of parallel machines [15, 7, 18, 6]. However, there have been very few studies <ref> [8, 19, 20] </ref> that have used real applications to evaluate the interconnection network. Siva-subramaniam et al. [8, 19] use an execution-driven simulator called SPASM to study the performance of a set of applications on different network topologies in both shared memory [8] and message-passing settings [19]. <p> However, there have been very few studies [8, 19, 20] that have used real applications to evaluate the interconnection network. Siva-subramaniam et al. <ref> [8, 19] </ref> use an execution-driven simulator called SPASM to study the performance of a set of applications on different network topologies in both shared memory [8] and message-passing settings [19]. <p> Siva-subramaniam et al. [8, 19] use an execution-driven simulator called SPASM to study the performance of a set of applications on different network topologies in both shared memory [8] and message-passing settings <ref> [19] </ref>. Bhuyan et al. [20] use another execution-driven simulator to study the impact of virtual channels on the performance of a 2-D torus in a shared memory environment. <p> But, none of these studies help us quantify the three communication attributes which can be used in subsequent network performance evaluation research. 2.3 Execution-driven Simulation Several execution-driven simulators such as Tango [9], Proteus [10], Rice Parallel Processing Testbed [11], MINT [12] and SPASM <ref> [8, 19] </ref> have been developed to evaluate parallel architectures. These simulators do not capture the details of instruction execution of a processor. They work on the presumption that simulating each instruction is not likely to significantly impact the understanding of parallel system behavior. <p> Most of the application code is executed at the speed of the native processor and only interesting instructions are trapped to the simulator and simulated. However, apart from SPASM <ref> [8, 19] </ref> and an augmentation to the Proteus simulator by Kumar and Bhuyan [20], other simulators [9, 11, 12] do not simulate the details of the interconnection network. 3 Traffic Characterization Methodology The goal of this research is to characterize the communication behavior of a wide spectrum of parallel applications.
Reference: [20] <author> A. Kumar and L. N. Bhuyan, </author> <title> Evalutaing Virtual Channels for Cache-Coherent Shared-Memory Multiprocessors, </title> <booktitle> in Proceedings of the ACM 1996 International Conference on Supercomputing, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: The NAS [15], PARKBENCH [16], and SPLASH [17] suites are examples of applications that have been widely used for benchmarking the performance of parallel machines [15, 7, 18, 6]. However, there have been very few studies <ref> [8, 19, 20] </ref> that have used real applications to evaluate the interconnection network. Siva-subramaniam et al. [8, 19] use an execution-driven simulator called SPASM to study the performance of a set of applications on different network topologies in both shared memory [8] and message-passing settings [19]. <p> Siva-subramaniam et al. [8, 19] use an execution-driven simulator called SPASM to study the performance of a set of applications on different network topologies in both shared memory [8] and message-passing settings [19]. Bhuyan et al. <ref> [20] </ref> use another execution-driven simulator to study the impact of virtual channels on the performance of a 2-D torus in a shared memory environment. <p> Most of the application code is executed at the speed of the native processor and only interesting instructions are trapped to the simulator and simulated. However, apart from SPASM [8, 19] and an augmentation to the Proteus simulator by Kumar and Bhuyan <ref> [20] </ref>, other simulators [9, 11, 12] do not simulate the details of the interconnection network. 3 Traffic Characterization Methodology The goal of this research is to characterize the communication behavior of a wide spectrum of parallel applications.
Reference: [21] <author> A. Sivasubramaniam, A. Singla, U. Ramachandran, and H. Venkateswaran, </author> <title> On characterizing bandwidth requirements of parallel applications, </title> <booktitle> in Proceedings of the ACM SIGMETRICS 1995 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pp. 198-207, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: While each of these studies provide some useful insight for the specific archi-tectures being studied, none of them have characterized the communication behavior of these applications. 2.2 Characterizing Communication Behavior of Applications A few researchers <ref> [21, 22] </ref> have investigated the communication behavior of applications. Cypher et al. [22] use a range of applications running on the Intel Touchstone Delta to quantify the processing, memory, communication and I/O requirements. <p> They present the communication demands in terms of the number of messages exchanged between processors and the volume (size) of these messages. To faithfully capture all the attributes of communication, Sivasubramaniam et al. <ref> [21] </ref> use an execution-driven simulator to model an application's communication behavior and derive the bandwidth that is needed for the efficient performance of several applications. Hsu and Banerjee [23] analyze the communication characteristics of parallel CAD applications on a hypercube.
Reference: [22] <author> R. Cypher, A. Ho, S. Konstantinidou, and P. Messina, </author> <title> Architectural requirements of parallel scientific applications with explicit communication, </title> <booktitle> in Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 2-13, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: While each of these studies provide some useful insight for the specific archi-tectures being studied, none of them have characterized the communication behavior of these applications. 2.2 Characterizing Communication Behavior of Applications A few researchers <ref> [21, 22] </ref> have investigated the communication behavior of applications. Cypher et al. [22] use a range of applications running on the Intel Touchstone Delta to quantify the processing, memory, communication and I/O requirements. <p> While each of these studies provide some useful insight for the specific archi-tectures being studied, none of them have characterized the communication behavior of these applications. 2.2 Characterizing Communication Behavior of Applications A few researchers [21, 22] have investigated the communication behavior of applications. Cypher et al. <ref> [22] </ref> use a range of applications running on the Intel Touchstone Delta to quantify the processing, memory, communication and I/O requirements. They present the communication demands in terms of the number of messages exchanged between processors and the volume (size) of these messages.
Reference: [23] <author> J.-M. Hsu and P. Banerjee, </author> <title> Performance Measurement and Trace Driven Simulation of Parallel CAD and Numeric Applications on a Hypercube Multicom-puter, </title> <booktitle> in Proc. 17th Annual Intl. Symp. on Computer Architecture, </booktitle> <pages> pp. 260-269, </pages> <year> 1990. </year>
Reference-contexts: To faithfully capture all the attributes of communication, Sivasubramaniam et al. [21] use an execution-driven simulator to model an application's communication behavior and derive the bandwidth that is needed for the efficient performance of several applications. Hsu and Banerjee <ref> [23] </ref> analyze the communication characteristics of parallel CAD applications on a hypercube.
Reference: [24] <author> T. Agerwala, J. L. Martin, J. H. Mirza, D. C. Sadler, D. M. Dias, and M. Snir, </author> <title> SP2 System Architecture, </title> <journal> IBM Systems Journal, </journal> <volume> vol. 34, no. 2, </volume> <pages> pp. 152-184, </pages> <year> 1995. </year>
Reference-contexts: We have run extensive experiments to exercise the network hardware and the communication software. From these experiments and from the data provided in <ref> [24] </ref>, we have been able to obtain validated costs associated with the communication software of the IBM SP2. For instance, the software overheads amount to 4:63 fl 10 2 x + 73:42 microseconds to transfer x bytes of data.
Reference: [25] <institution> Microelectronics and Computer Technology Corporation, Austin, TX 78759, </institution> <note> CSIM User's Guide, </note> <year> 1990. </year>
Reference-contexts: This network simulator is process oriented and has been written using the CSIM <ref> [25] </ref> simulation package. Inputs to the simulator are messages defined by their source, destination, length and time since the last network activity at the source. The output is the network latency and contention incurred by the message and overall utilization of the different network resources.
Reference: [26] <author> R. J. Anderson and J. C. Setubal, </author> <title> On the Parallel Implementation of Goldberg's Maximum Flow Algorithm, </title> <booktitle> in Proceedings of the Fourth Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 168-177, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The distribution functions for each processor can be used to generate the messages accurately. On the other hand, a simple averaging of the means of all the processors can be done to define a single expression. Maxflow: The Maxflow <ref> [26] </ref> application finds the maximum flow from a source to a sink, in a directed graph.
References-found: 26

