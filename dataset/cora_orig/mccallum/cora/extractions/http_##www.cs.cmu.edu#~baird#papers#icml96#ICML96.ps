URL: http://www.cs.cmu.edu/~baird/papers/icml96/ICML96.ps
Refering-URL: http://www.cs.cmu.edu/~baird/papers/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: cba@amherst.com  fjv@eva.psi.uma.es,  harmonme@aa.wpafb.af.mil  baird@cs.usafa.af.mil  
Phone: 2185  
Title: Residual Q-Learning Applied to Visual Attention  
Author: Cesar Bandera Francisco J. Vico, Jose M. Bravo Mance E. Harmon Leemon C. Baird III 
Address: 30 Wilson Road Buffalo, New York 14221-7082  29017 Malaga (Spain)  WL/AAAT Bldg. 635  45433-7301  2354 Fairchild Dr. Suite 6K41 USAFA, Colorado 80840-6234  
Affiliation: Amherst Systems, Inc. Machine Vision Dept.  Facultad de Psicologia Universidad de Malaga  Wright Laboratory  Avionics Circle Wright-Patterson AFB, Ohio  U.S.A.F. Academy  
Date: 3-6 July 1996.  
Note: To appear in the Proceedings of the Thirteenth International Conference on Machine Learning, Bari, Italy,  
Abstract: Foveal vision features imagers with graded acuity coupled with context sensitive sensor gaze control, analogous to that prevalent throughout vertebrate vision. Foveal vision operates more efficiently than uniform acuity vision because resolution is treated as a dynamically allocatable resource, but requires a more refined visual attention mechanism. We demonstrate that reinforcement learning (RL) significantly improves the performance of foveal visual attention, and of the overall vision system, for the task of model based target recognition. A simulated foveal vision system is shown to classify targets with fewer fixations by learning strategies for the acquisition of visual information relevant to the task, and learning how to generalize these strategies in ambiguous and unexpected scenario conditions.
Abstract-found: 1
Intro-found: 1
Reference: <author> Baird, L. C. </author> <year> (1995). </year> <title> Residual Algorithms: Reinforcement Learning with Function Approximation. </title> <editor> In Armand Prieditis & Stuart Russell, eds. </editor> <booktitle> Machine Learning: Proceedings of the Twelfth International Conference, </booktitle> <address> 9-12 July, </address> <publisher> Morgan Kaufman Publishers, </publisher> <address> San Francisco, CA. </address>
Reference-contexts: Model #1 Model #2 Model #3 Composite The visual attention mechanism selects a feature from the model database for interrogation given the state of the recognition process. This selection process is learned through the use of the residual form <ref> (Baird 1995, and Harmon, Baird, and Klopf 1995) </ref> of Q-learning (Watkins 1989), which we will refer to as residual-Q.
Reference: <author> Bandera, C., Scott P. </author> <year> (1989). </year> <title> Foveal Machine Vision Systems. </title> <booktitle> IEEE International Conference on Systems, Man, and Cybernetics, </booktitle> <address> Cambridge, MA, </address> <month> November. </month>
Reference-contexts: The rectilinear arrangement of receptive fields, the linear roll-off in acuity, and the power of two steps in acuity support computationally efficient multiresolution image processing. This approach to multiacuity sampling and processing is called hierarchical foveal machine vision (HFMV) <ref> (Bandera and Scott 1989, 1992) </ref>. The problem of visual attention is amenable to machine learning solutions. Classical or analytical solutions are very difficult due to unpredictable variability in scenario conditions (e.g., object range and orientation) and the model database (e.g., the addition of new classes).
Reference: <author> Bandera, C., Scott P. </author> <year> (1992). </year> <title> Multiacuity target recognition and tracking. </title> <booktitle> Proceedings of the Second Automatic Target Recognizer Systems and Technology Conference, </booktitle> <institution> Fort Belvoir Center for Night Vision and Electro-Optics, </institution> <month> March 17. </month>
Reference: <author> Harmon, M.E., Baird, L.C, & Klopf, A.H. </author> <year> (1995). </year> <title> Advantage updating applied to a differential game. </title> <editor> In Tesauro, G., Touretzky, D.S., and Leen, T.K. (eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 7 . MIT Press, </booktitle> <address> Cambridge MA. </address>
Reference-contexts: Model #1 Model #2 Model #3 Composite The visual attention mechanism selects a feature from the model database for interrogation given the state of the recognition process. This selection process is learned through the use of the residual form <ref> (Baird 1995, and Harmon, Baird, and Klopf 1995) </ref> of Q-learning (Watkins 1989), which we will refer to as residual-Q.
Reference: <author> Levine, M. D. </author> <year> (1985). </year> <title> Vision in Man and Machine , McGraw Hill. </title>
Reference-contexts: Retinal acuity varies by several orders of magnitude within the field of view (FOV). The region of the retina with notably high acuity, called the fovea, is typically a small percentage of the overall FOV (&lt;3%), centered at the optical axis <ref> (Levine 1985) </ref>. The wide FOV, supported by lower peripheral acuity, and the high acuity fovea impose a much smaller data set (frame size) and permit a much faster frame rate than supporting the entire FOV uniformly at high acuity.
Reference: <author> Lin, L. J. </author> <year> (1992). </year> <title> Self-improving reactive agents based on reinforcement learning, planning and teaching. </title> <journal> Machine Learning, </journal> <volume> no. 8, </volume> <pages> pp. 293-321, </pages> <publisher> Kluer Academic. </publisher>
Reference-contexts: Other parameters follow: discount factor g=0.99, learning constant a=0.9, the residual coefficient f=0.3, entropy threshold (stop rule) e t =0.3, and noise source [- bT, +bT], T=E n -e t , b=0.5 added to the reinforcement signal to invoke exploration <ref> (Lin 1992) </ref>.
Reference: <author> Rumelhart, D., Hinton, G., & Williams, R. </author> <year> (1986). </year> <title> Learning representations by back-propagating errors. </title> <journal> Nature. </journal> <volume> 323, </volume> <month> 9 October, </month> <pages> 533-536. </pages>
Reference-contexts: The initial value of the integrated perception is V (i )=0, i =1, ..., N (i.e., maximum system ambiguity). 3.3 OBJECT RECOGNITION FROM FEATURES To generate the class likelihood vector (from which system entropy can be calculated) from the integrated perception vector, a backpropagation net <ref> (Rumelhart et al., 1986) </ref> is trained on the potential states of the integrated perception. This approach consists of a net with N inputs, M outputs, and a hidden layer with (M+N)/2 nodes.
Reference: <author> Watkins, C. J. C. H. </author> <year> (1989). </year> <title> Learning from delayed rewards. </title> <type> Doctoral thesis, </type> <institution> Cambridge University, </institution> <address> Cambridge, England. </address>
Reference-contexts: Model #1 Model #2 Model #3 Composite The visual attention mechanism selects a feature from the model database for interrogation given the state of the recognition process. This selection process is learned through the use of the residual form (Baird 1995, and Harmon, Baird, and Klopf 1995) of Q-learning <ref> (Watkins 1989) </ref>, which we will refer to as residual-Q.
Reference: <author> Yarbus, A. L. </author> <year> (1967). </year> <title> Eye Movements and Vision, </title> <publisher> Plenum Press. </publisher>
Reference-contexts: Inherent with space-variant sampling is the contextsensitive articulation of the sensors optical axis, whereby the fovea is aligned with relevant features in the scene <ref> (Yarbus 1967) </ref>. These features can be targets (e.g., predators or prey), or classification features on the targets themselves. Space-variant sampling and intelligent gaze control together with multiresolutional image analysis are collectively called foveal vision.
Reference: <author> Yeshurun, E. L. Schwartz. </author> <year> (1989). </year> <title> Shape Description With a Space-Variant Sensor: Algorithms For Scan-path, and Convergence Over Multiple Scans. </title> <journal> IEEE Trans. PAMI, </journal> <volume> vol. 11, no. 11, </volume> <pages> pp. 1217-1222, </pages> <month> November. </month>
Reference-contexts: For example, the retinotopic regions of the human visual system would be 15,000 times larger if the retina supported maximum acuity throughout its FOV <ref> (Yeshurun 1989) </ref>. Inherent with space-variant sampling is the contextsensitive articulation of the sensors optical axis, whereby the fovea is aligned with relevant features in the scene (Yarbus 1967). These features can be targets (e.g., predators or prey), or classification features on the targets themselves.
References-found: 10

