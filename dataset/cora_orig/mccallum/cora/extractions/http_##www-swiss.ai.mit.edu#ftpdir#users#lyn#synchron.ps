URL: http://www-swiss.ai.mit.edu/ftpdir/users/lyn/synchron.ps
Refering-URL: http://www-swiss.ai.mit.edu/~lyn/synchron.html
Root-URL: 
Email: fturbak@wellesley.edu  
Title: First-Class Synchronization Barriers  
Author: Franklyn Turbak 
Affiliation: Wellesley College Computer Science Department  
Abstract: Our purpose is to promote a second-class mechanism | the synchronization barrier | to a first-class value. We introduce the synchron, a novel synchronization mechanism that enables the coordination of a dynamically varying set of concurrent threads that share access to a first-class synchronization token. We demonstrate how synchrons can be used to modularly manage resources in cases where existing techniques are either inapplicable or non-modular. In particular, synchronized lazy aggregates enable the first space-efficient aggregate data decomposition of a wide range of algorithms. We also introduce explicit-demand graph reduction, a new semantic framework that we have developed to describe concurrency and explain the meaning of a synchron rendezvous. 
Abstract-found: 1
Intro-found: 1
Reference: [AA95] <author> Zena Ariola and Arvind. </author> <title> Properties of a first-order functional language with sharing. </title> <journal> Theoretical Computer Science, </journal> <volume> 146 </volume> <pages> 69-108, </pages> <year> 1995. </year>
Reference-contexts: The Edgar semantics for full-featured Opera is clearly not Church-Rosser, but we suspect Church-Rosser may hold for a functional subset of Opera. The key difference between Edgar and other graphical frameworks <ref> [Tur79, Pey87, B + 87, AA95] </ref> is its use of explicit demand tokens to encode evaluation strategies. Edgar specifies evaluation order by annotating some graph edges with a demand token that indicates where evaluation steps can take place.
Reference: [AAS95] <author> Shail Aditya, Arvind, and Joseph E. Stoy. </author> <title> Semantics of barriers in a non-strict, implicitly-parallel language. </title> <type> Technical Report Computation Structures Group Memo 367, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: In most data parallel models, selected processors engage in an implicit rendezvous after the execution of a data parallel operator. The communication protocols in channel-based concurrent process models similarly involve an implicit rendezvous [Hoa85, Mil89, CM90]. Some languages (e.g., Id <ref> [AAS95] </ref>) permit the programmer to insert explicit barriers, but they are not manipulable as first-class values. One approach to making barriers first-class is to manipulate them via the following interface: * barrier : integer ! barrier. Create a new barrier value for synchronizing integer threads. <p> Such barriers are second-class mechanisms that coordinate a set of processes known at barrier-creation time. The Id language supplies a barrier construct for managing program resources and scheduling side-effects in a language based on eager evaluation <ref> [Bar92, AAS95] </ref>. Barriers are indicated by a dotted line that separates groups of eagerly evaluated expressions; no computation is initiated below the line until all computations initiated above the line have terminated.
Reference: [AF94] <author> Zena Ariola and Matthias Felleisen. </author> <title> The call-by-need lambda calculus. </title> <type> Technical Report CIS-TR-94-23, </type> <institution> Department of Computer Science, University of Oregon, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: In the presence 3 We have recently learned [Ari96] that the semantics of Opera can be expressed in a more traditional graph rewriting system using graphical contexts similar to those use in <ref> [AF94] </ref>. Recasting Opera semantics in this new form is a future goal. of explicit demand tokens, a global "reduce any redex" rule suffices because the details of the evaluation strategy are already encoded in the graph itself.
Reference: [App92] <author> Andrew W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: The rules for when objects become inaccessible must be explicit and simple enough so that a programmer can use them as a basis for reasoning. The Opera semantics adopts the liveness and tail-call optimizations described in <ref> [App92] </ref>. These space consumption rules describe the aggressive reclamation of space in a way that the programmer can understand at a relatively high level. They also prevent a correct implementation of Opera from holding references to values longer than strictly necessary.
Reference: [Ari96] <author> Zena Ariola. </author> <type> Personal communication, </type> <month> January </month> <year> 1996. </year>
Reference-contexts: In the presence 3 We have recently learned <ref> [Ari96] </ref> that the semantics of Opera can be expressed in a more traditional graph rewriting system using graphical contexts similar to those use in [AF94].
Reference: [Ash86] <author> E. A. Ashcroft. </author> <title> Dataflow and eduction: Data-driven and demand-driven distributed computing. </title> <editor> In J. W. deBakker, W.-P. de Roever, and G. Rozen-berg, editors, </editor> <booktitle> Current Trends in Concurrency: Overviews and Tutorials, </booktitle> <pages> pages 1-50. </pages> <publisher> Springer-Verlag, </publisher> <year> 1986. </year> <booktitle> Lecture Notes in Computer Science, Number 224. </booktitle>
Reference-contexts: Pingali and Arvind describe a mechanism for simulating demand-driven evaluation in a data flow model; they use data tokens to represent demand [PA85, PA86]. Ashcroft describes a system that combines demand flow (via entities called questons) with data flow (via entities called datons) <ref> [Ash86] </ref>. 5.2 Snapshots A snapshot is a graph consisting of interconnected labelled nodes. Each node can be viewed as a computational device that responds to a demand for a value by computing that value.
Reference: [B + 87] <editor> H.P. Barendregt et al. </editor> <title> Toward an intermediate language based on graph rewriting. </title> <booktitle> In PARLE: Parallel Architectures and Languages Europe, </booktitle> <volume> Volume 2, </volume> <pages> pages 159 - 175. </pages> <publisher> Springer-Verlag, </publisher> <year> 1987. </year> <booktitle> Lecture Notes in Computer Science, Number 259. </booktitle>
Reference-contexts: The Edgar semantics for full-featured Opera is clearly not Church-Rosser, but we suspect Church-Rosser may hold for a functional subset of Opera. The key difference between Edgar and other graphical frameworks <ref> [Tur79, Pey87, B + 87, AA95] </ref> is its use of explicit demand tokens to encode evaluation strategies. Edgar specifies evaluation order by annotating some graph edges with a demand token that indicates where evaluation steps can take place.
Reference: [Bar92] <author> Paul S. Barth. </author> <title> Atomic data structures for parallel computing. </title> <type> Technical Report MIT/LCS/TR-532, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: Such barriers are second-class mechanisms that coordinate a set of processes known at barrier-creation time. The Id language supplies a barrier construct for managing program resources and scheduling side-effects in a language based on eager evaluation <ref> [Bar92, AAS95] </ref>. Barriers are indicated by a dotted line that separates groups of eagerly evaluated expressions; no computation is initiated below the line until all computations initiated above the line have terminated.
Reference: [Baw92] <author> Alan Bawden. </author> <title> Linear Graph Reduction: Confronting the Cost of Naming. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: Synchrons can be viewed as a way of permitting the mul-tiway handshake of CSP [Hoa85] to be integrated into the aggregate data paradigm. A variant of synchrons can be implemented in Bawden's linear language <ref> [Baw92] </ref>, in which objects can only be shared via an explicit copy operation. The copy operation for syn-chrons can maintain a count of non-waiting pointers; a rendezvous occurs when this number drops to zero. A language implementing synchrons removes the need for explicit copy operations by managing this count automatically.
Reference: [Bir88] <author> Richard S. Bird. </author> <title> Lectures on constructive functional programming. </title> <editor> In Manfred Broy, editor, </editor> <booktitle> Constructive Methods in Computing Science (NATO ASI Series, </booktitle> <volume> Vol. F55), </volume> <pages> pages 5-42. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: One drawback of this aggregate data paradigm is that intermediate data structures can cause modular programs to require more time and space than their monolithic counterparts. Numerous strategies have been developed to reduce these overheads in aggregate data programs (e.g., laziness [Hug90], algebraic transformations <ref> [DR76, Bir88] </ref>, listlessness [Wad84], deforestation [Wad88, GLJ93], series [Wat90]). However, these strategies either unduly restrict the style of aggregate data program allowed (e.g., trees are not allowed; aggregates may only have a single consumer), or they provide no guarantees (e.g., a transformation may increase overhead instead of decreasing it).
Reference: [Bir89] <author> Andrew Birrel. </author> <title> An introduction to programming with threads. </title> <type> SRC Report 35, </type> <institution> Digital Equipment Corporation, </institution> <month> January </month> <year> 1989. </year>
Reference-contexts: Even in a functional language, barriers are helpful for limiting the amount of memory used by a program. Barriers serve a purpose different from that of mutual exclusion mechanisms like semaphores [Dij68], locks <ref> [Bir89] </ref>, and monitors [Hoa74]. Whereas mutual exclusion mechanisms prevent threads from simultaneously accessing resources, barriers manage resources (e.g., shared variables and memory) by limiting the extent to which threads can be "out of step".
Reference: [CM90] <author> Eric Cooper and J. Gregory Morrisett. </author> <title> Adding threads to standard ML. </title> <type> Technical Report CMU-CS-90-186, </type> <institution> Carnegie Mellon University Computer Science Department, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: In most data parallel models, selected processors engage in an implicit rendezvous after the execution of a data parallel operator. The communication protocols in channel-based concurrent process models similarly involve an implicit rendezvous <ref> [Hoa85, Mil89, CM90] </ref>. Some languages (e.g., Id [AAS95]) permit the programmer to insert explicit barriers, but they are not manipulable as first-class values. One approach to making barriers first-class is to manipulate them via the following interface: * barrier : integer ! barrier. <p> The first-classness and variable membership of synchrons makes it easy for threads above the barrier to transitively pass along the synchron to all of their descendent threads. The communication handshake in channel-based concurrent languages (e.g., <ref> [Hoa85, Mil89, CM90] </ref>) involves a form of barrier. Neither the sending thread nor receiving thread (s) can proceed until a rendezvous of all the participants. In these languages, synchronization is not separable from communication, and communication events are not first-class.
Reference: [CR + 91] <editor> William Clinger, Jonathan Rees, et al. </editor> <title> Revised 4 report on the algorithmic language Scheme. Lisp Pointers, </title> <type> 4(3), </type> <year> 1991. </year>
Reference-contexts: The semantics presented in Section 5 formalizes this relationship in a high-level way. The rest of the paper is organized as follows: Section 2 presents examples that illustrate the utility of synchrons. Section 3 surveys related work. Section 4 introduces Opera, a concurrent version of Scheme <ref> [CR + 91] </ref> that supports syn-chrons. Section 5 gives a brief overview of Edgar, a graph-rewriting framework that formalizes the semantics of syn-chrons.
Reference: [Dij68] <author> E. W. Dijkstra. </author> <title> Co-operating sequential processes. </title> <editor> In F. Genuys, editor, </editor> <booktitle> Programming Languages (NATO Advanced Study Institute), </booktitle> <pages> pages 43-112. </pages> <address> London: </address> <publisher> Academic Press, </publisher> <year> 1968. </year>
Reference-contexts: Even in a functional language, barriers are helpful for limiting the amount of memory used by a program. Barriers serve a purpose different from that of mutual exclusion mechanisms like semaphores <ref> [Dij68] </ref>, locks [Bir89], and monitors [Hoa74]. Whereas mutual exclusion mechanisms prevent threads from simultaneously accessing resources, barriers manage resources (e.g., shared variables and memory) by limiting the extent to which threads can be "out of step".
Reference: [DR76] <author> John Darlington and R.M.Burstall. </author> <title> A system which automatically improves programs. </title> <journal> Acta Informat-ica, </journal> <pages> pages 41-60, </pages> <year> 1976. </year>
Reference-contexts: One drawback of this aggregate data paradigm is that intermediate data structures can cause modular programs to require more time and space than their monolithic counterparts. Numerous strategies have been developed to reduce these overheads in aggregate data programs (e.g., laziness [Hug90], algebraic transformations <ref> [DR76, Bir88] </ref>, listlessness [Wad84], deforestation [Wad88, GLJ93], series [Wat90]). However, these strategies either unduly restrict the style of aggregate data program allowed (e.g., trees are not allowed; aggregates may only have a single consumer), or they provide no guarantees (e.g., a transformation may increase overhead instead of decreasing it).
Reference: [For91] <author> Alessandro Forin. </author> <title> Futures. </title> <editor> In Peter Lee, editor, </editor> <booktitle> Topics in Advanced Language Implementation, </booktitle> <pages> pages 219-241. </pages> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: the following example deadlocks after displaying A: (let ((b (event (lambda () (display "B")))) (c (event (lambda () (display "C"))))) (let ((a (event (lambda () (begin (-&gt; c b) (display "A")))))) (begin (-&gt; a b) (-&gt; b c)))) returns a placeholder and commences the concurrent evaluation of the placeholder value <ref> [Mil87, Hal85, For91] </ref>. Within event, future forks a thread that forces the thunk application to be sandwiched between the start and stop instants. The -&gt; procedure forks a thread that guarantees that the stopping instant of the first event must precede the starting instant of the second event. <p> O ::= + j * j cons j car j cdr j other Scheme primitives j synchron j wait j simul j synchron? j touch j excludon j excludon? The default strictness of Opera application can be circumvented with two classic forms of non-strictness found in other dialects of Lisp <ref> [Mil87, Hal85, For91] </ref>. (delay E) supports lazy evaluation by suspending evaluation of E until its value is required. (future E) supports eager evaluation by immediately returning a placeholder for the value of E, which is evaluated concurrently with the rest of the program. future and the default parallel argument evaluation strategy
Reference: [GJ90] <author> David Gelernter and Suresh Jagannathan. </author> <title> Program--ming Linguistics. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Edgar's explicit representation of demand was inspired by the demand tokens used in Gelernter and Jagannathan's Ideal Software Machine (ISM) <ref> [GJ90] </ref>, a semantic framework that combines aspects of Petri nets [Pet77] and graph rewriting. A handful of other systems employ explicit representations of demand. Pingali and Arvind describe a mechanism for simulating demand-driven evaluation in a data flow model; they use data tokens to represent demand [PA85, PA86].
Reference: [GLJ93] <author> Andrew Gill, John Launchbury, and Simon L. Pey-ton Jones. </author> <title> A short cut to deforestation. </title> <booktitle> In Functional Programming and Computer Architecture, </booktitle> <year> 1993. </year>
Reference-contexts: One drawback of this aggregate data paradigm is that intermediate data structures can cause modular programs to require more time and space than their monolithic counterparts. Numerous strategies have been developed to reduce these overheads in aggregate data programs (e.g., laziness [Hug90], algebraic transformations [DR76, Bir88], listlessness [Wad84], deforestation <ref> [Wad88, GLJ93] </ref>, series [Wat90]). However, these strategies either unduly restrict the style of aggregate data program allowed (e.g., trees are not allowed; aggregates may only have a single consumer), or they provide no guarantees (e.g., a transformation may increase overhead instead of decreasing it). <p> Moreover, whereas series is limited to iteratively processed sequences, synchronized lazy aggregates can handle recursively processed sequences and tree-structured data. It would be worthwhile to adapt series compilation techniques to handle these more general kinds of processing; we plan to pursue this line of research. Deforestation <ref> [Wad88, GLJ93] </ref> is program transformation technique that removes intermediate data structures from programs. It is more powerful than series in the sense that it can remove tree-structured data. However, unlike series and synchronized lazy aggregates, current deforestation technology cannot deal with fan-out of aggregates. <p> It is more powerful than series in the sense that it can remove tree-structured data. However, unlike series and synchronized lazy aggregates, current deforestation technology cannot deal with fan-out of aggregates. To handle cases like average, transformations that combine accumulators have been proposed <ref> [GLJ93] </ref>, but these are ad hoc and it is not clear how to generalize them to general block diagrams. Barriers are common in parallel processing systems.
Reference: [Hal85] <author> Robert Halstead. </author> <title> Multilisp: A language for concurrent symbolic computation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <pages> pages 501-528, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: the following example deadlocks after displaying A: (let ((b (event (lambda () (display "B")))) (c (event (lambda () (display "C"))))) (let ((a (event (lambda () (begin (-&gt; c b) (display "A")))))) (begin (-&gt; a b) (-&gt; b c)))) returns a placeholder and commences the concurrent evaluation of the placeholder value <ref> [Mil87, Hal85, For91] </ref>. Within event, future forks a thread that forces the thunk application to be sandwiched between the start and stop instants. The -&gt; procedure forks a thread that guarantees that the stopping instant of the first event must precede the starting instant of the second event. <p> O ::= + j * j cons j car j cdr j other Scheme primitives j synchron j wait j simul j synchron? j touch j excludon j excludon? The default strictness of Opera application can be circumvented with two classic forms of non-strictness found in other dialects of Lisp <ref> [Mil87, Hal85, For91] </ref>. (delay E) supports lazy evaluation by suspending evaluation of E until its value is required. (future E) supports eager evaluation by immediately returning a placeholder for the value of E, which is evaluated concurrently with the rest of the program. future and the default parallel argument evaluation strategy
Reference: [Hoa74] <author> C.A.R. Hoare. </author> <title> Monitors: An operating system structuring concept. </title> <journal> Communications of the ACM, </journal> <volume> 17(10) </volume> <pages> 549-557, </pages> <year> 1974. </year>
Reference-contexts: Even in a functional language, barriers are helpful for limiting the amount of memory used by a program. Barriers serve a purpose different from that of mutual exclusion mechanisms like semaphores [Dij68], locks [Bir89], and monitors <ref> [Hoa74] </ref>. Whereas mutual exclusion mechanisms prevent threads from simultaneously accessing resources, barriers manage resources (e.g., shared variables and memory) by limiting the extent to which threads can be "out of step". Although mutual exclusion mechanisms have been encapsulated in first-class values like semaphores and locks, barriers are traditionally second-class mechanisms.
Reference: [Hoa85] <author> C.A.R. Hoare. </author> <title> Communicating Sequential Processes. </title> <publisher> Prentice-Hall, </publisher> <year> 1985. </year>
Reference-contexts: In most data parallel models, selected processors engage in an implicit rendezvous after the execution of a data parallel operator. The communication protocols in channel-based concurrent process models similarly involve an implicit rendezvous <ref> [Hoa85, Mil89, CM90] </ref>. Some languages (e.g., Id [AAS95]) permit the programmer to insert explicit barriers, but they are not manipulable as first-class values. One approach to making barriers first-class is to manipulate them via the following interface: * barrier : integer ! barrier. <p> The first-classness and variable membership of synchrons makes it easy for threads above the barrier to transitively pass along the synchron to all of their descendent threads. The communication handshake in channel-based concurrent languages (e.g., <ref> [Hoa85, Mil89, CM90] </ref>) involves a form of barrier. Neither the sending thread nor receiving thread (s) can proceed until a rendezvous of all the participants. In these languages, synchronization is not separable from communication, and communication events are not first-class. <p> Reppy's first-class events [Rep91] really act as first-class event generators; every call of his sync on a given "event" causes the current thread to wait for a different rendezvous. Synchrons can be viewed as a way of permitting the mul-tiway handshake of CSP <ref> [Hoa85] </ref> to be integrated into the aggregate data paradigm. A variant of synchrons can be implemented in Bawden's linear language [Baw92], in which objects can only be shared via an explicit copy operation.
Reference: [Hug84] <author> R. J. M. Hughes. </author> <title> Parallel functional languages use less space. </title> <type> Technical report, </type> <institution> Oxford University Programming Research Group, </institution> <year> 1984. </year>
Reference-contexts: Although simul declares an explicit temporal constraint, the temporal constraints expressed via wait are implicit in the control flow of individual threads. The design of synchrons was driven by the goal of expressing space-efficient algorithms as the modular composition of aggregate data operators. Following Hughes <ref> [Hug84] </ref>, we argue in Section 2.2 that concurrency and synchronization are essential for preserving the space complexity of non-modular algorithms when decomposing them into reusable components that communicate via aggregate data. In particular, synchrons are the first run-time mechanism to enable the space-efficient decomposition of algorithms that manipulate aggregates non-linearly. <p> But without some form of concurrency, evaluation of one argument to / must finish before the evaluation of the other argument can begin. At this juncture, the entire nums sequence must be in memory, implying a linear space requirement. Hughes argues in <ref> [Hug84] </ref> that any sequential evaluation strategy for average must use linear space. Concurrency alone does not guarantee efficient space requirements for average. <p> g) (let ((sync1 (first seq1)) (sync2 (first seq2)) (hd1 (second seq1)) (hd2 (second seq2)) (tl1 (third seq1)) (tl2 (third seq2))) (list (simul sync1 sync2) (f hd1 hd2) (delay (g (force tl1) (force tl2)))))) 3 Related Work The synchronization mechanism most closely related to the synchron is Hughes's synch E construct <ref> [Hug84] </ref>. This is similar to Scheme's delay in that it creates a promise for evaluating E. The difference is that there are two distinct functions (let's call them force1 and force2) for forcing the computation of E.
Reference: [Hug90] <author> R. J. M. Hughes. </author> <title> Why functional programming matters. </title> <editor> In David Turner, editor, </editor> <booktitle> Research Topics in Functional Programming, </booktitle> <pages> pages 17-42. </pages> <publisher> Addison Wesley, </publisher> <year> 1990. </year>
Reference-contexts: One drawback of this aggregate data paradigm is that intermediate data structures can cause modular programs to require more time and space than their monolithic counterparts. Numerous strategies have been developed to reduce these overheads in aggregate data programs (e.g., laziness <ref> [Hug90] </ref>, algebraic transformations [DR76, Bir88], listlessness [Wad84], deforestation [Wad88, GLJ93], series [Wat90]).
Reference: [Mil87] <author> James S. Miller. MultiScheme: </author> <title> A parallel processing system based on MIT Scheme. </title> <type> Technical Report MIT/LCS/TR-402, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> September </month> <year> 1987. </year>
Reference-contexts: the following example deadlocks after displaying A: (let ((b (event (lambda () (display "B")))) (c (event (lambda () (display "C"))))) (let ((a (event (lambda () (begin (-&gt; c b) (display "A")))))) (begin (-&gt; a b) (-&gt; b c)))) returns a placeholder and commences the concurrent evaluation of the placeholder value <ref> [Mil87, Hal85, For91] </ref>. Within event, future forks a thread that forces the thunk application to be sandwiched between the start and stop instants. The -&gt; procedure forks a thread that guarantees that the stopping instant of the first event must precede the starting instant of the second event. <p> O ::= + j * j cons j car j cdr j other Scheme primitives j synchron j wait j simul j synchron? j touch j excludon j excludon? The default strictness of Opera application can be circumvented with two classic forms of non-strictness found in other dialects of Lisp <ref> [Mil87, Hal85, For91] </ref>. (delay E) supports lazy evaluation by suspending evaluation of E until its value is required. (future E) supports eager evaluation by immediately returning a placeholder for the value of E, which is evaluated concurrently with the rest of the program. future and the default parallel argument evaluation strategy
Reference: [Mil89] <author> Robin Milner. </author> <title> Communication and Concurrency. </title> <publisher> Prentice-Hall, </publisher> <year> 1989. </year>
Reference-contexts: In most data parallel models, selected processors engage in an implicit rendezvous after the execution of a data parallel operator. The communication protocols in channel-based concurrent process models similarly involve an implicit rendezvous <ref> [Hoa85, Mil89, CM90] </ref>. Some languages (e.g., Id [AAS95]) permit the programmer to insert explicit barriers, but they are not manipulable as first-class values. One approach to making barriers first-class is to manipulate them via the following interface: * barrier : integer ! barrier. <p> The first-classness and variable membership of synchrons makes it easy for threads above the barrier to transitively pass along the synchron to all of their descendent threads. The communication handshake in channel-based concurrent languages (e.g., <ref> [Hoa85, Mil89, CM90] </ref>) involves a form of barrier. Neither the sending thread nor receiving thread (s) can proceed until a rendezvous of all the participants. In these languages, synchronization is not separable from communication, and communication events are not first-class.
Reference: [PA85] <author> Keshav Pingali and Arvind. </author> <title> Efficient demand-driven evaluation (I). </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(2) </volume> <pages> 311-333, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: A handful of other systems employ explicit representations of demand. Pingali and Arvind describe a mechanism for simulating demand-driven evaluation in a data flow model; they use data tokens to represent demand <ref> [PA85, PA86] </ref>. Ashcroft describes a system that combines demand flow (via entities called questons) with data flow (via entities called datons) [Ash86]. 5.2 Snapshots A snapshot is a graph consisting of interconnected labelled nodes.
Reference: [PA86] <author> Keshav Pingali and Arvind. </author> <title> Efficient demand-driven evaluation (II). </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 8(1) </volume> <pages> 109-139, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: A handful of other systems employ explicit representations of demand. Pingali and Arvind describe a mechanism for simulating demand-driven evaluation in a data flow model; they use data tokens to represent demand <ref> [PA85, PA86] </ref>. Ashcroft describes a system that combines demand flow (via entities called questons) with data flow (via entities called datons) [Ash86]. 5.2 Snapshots A snapshot is a graph consisting of interconnected labelled nodes.
Reference: [Pet77] <author> James L. Peterson. </author> <title> Petri nets. </title> <journal> ACM Computing Surveys, </journal> <volume> 9(3) </volume> <pages> 223-250, </pages> <year> 1977. </year>
Reference-contexts: Edgar's explicit representation of demand was inspired by the demand tokens used in Gelernter and Jagannathan's Ideal Software Machine (ISM) [GJ90], a semantic framework that combines aspects of Petri nets <ref> [Pet77] </ref> and graph rewriting. A handful of other systems employ explicit representations of demand. Pingali and Arvind describe a mechanism for simulating demand-driven evaluation in a data flow model; they use data tokens to represent demand [PA85, PA86].
Reference: [Pey87] <editor> Simon L. Peyton Jones. </editor> <booktitle> The Implementation of Functional Programming Languages. </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1987. </year>
Reference-contexts: The Edgar semantics for full-featured Opera is clearly not Church-Rosser, but we suspect Church-Rosser may hold for a functional subset of Opera. The key difference between Edgar and other graphical frameworks <ref> [Tur79, Pey87, B + 87, AA95] </ref> is its use of explicit demand tokens to encode evaluation strategies. Edgar specifies evaluation order by annotating some graph edges with a demand token that indicates where evaluation steps can take place.
Reference: [Plo81] <author> Gordon D. Plotkin. </author> <title> A structural approach to operational semantics. </title> <type> Technical Report DAIMI FN-19, </type> <institution> Aarhus University Computer Science Department, </institution> <month> September </month> <year> 1981. </year>
Reference-contexts: of the close tie between synchrons and automatic storage management, an important feature of the Edgar semantics for Opera is that it formalizes garbage collection in a way that programmers can reason about. 5.1 Edgar Overview The overall structure of the Edgar framework follows the recipe for an operational semantics <ref> [Plo81] </ref>: Opera programs are compiled into an initial snapshot (an Edgar graphical configuration), and transitions are made between snapshots in a step-by-step manner according to a collection of rewrite rules. A sequence of snapshots encountered in consecutive transitions is called a trace.
Reference: [Rep91] <author> J. H. Reppy. </author> <title> CML: A higher-order concurrent language. </title> <booktitle> In Proceedings of the SIGPLAN '91 Conference on Programming Language Design and Implementation., </booktitle> <pages> pages 293-305, </pages> <year> 1991. </year>
Reference-contexts: Neither the sending thread nor receiving thread (s) can proceed until a rendezvous of all the participants. In these languages, synchronization is not separable from communication, and communication events are not first-class. Reppy's first-class events <ref> [Rep91] </ref> really act as first-class event generators; every call of his sync on a given "event" causes the current thread to wait for a different rendezvous. Synchrons can be viewed as a way of permitting the mul-tiway handshake of CSP [Hoa85] to be integrated into the aggregate data paradigm.
Reference: [Tur79] <author> D. A. Turner. </author> <title> A new implementation for applicative languages. </title> <journal> Software Practice and Experience, </journal> <volume> 9 </volume> <pages> 31-49, </pages> <year> 1979. </year>
Reference-contexts: The Edgar semantics for full-featured Opera is clearly not Church-Rosser, but we suspect Church-Rosser may hold for a functional subset of Opera. The key difference between Edgar and other graphical frameworks <ref> [Tur79, Pey87, B + 87, AA95] </ref> is its use of explicit demand tokens to encode evaluation strategies. Edgar specifies evaluation order by annotating some graph edges with a demand token that indicates where evaluation steps can take place.
Reference: [Tur94] <author> Franklyn Turbak. Slivers: </author> <title> Computational Modularity via Synchronized Lazy Aggregates. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <month> February </month> <year> 1994. </year> <note> Accessible from http://www-swiss.ai.mit.edu/~lyn/slivers.html. Also to appear as MIT Artificial Intelligence Laboratory AI-TR-1466. </note>
Reference-contexts: The modular handling of tail-recursion in the extended system is especially tricky and requires an extension to the synchron interface. Space does not permit a detailed discussion of these issues; see <ref> [Tur94] </ref> for in-depth coverage. The average example emphasizes that concurrency and first-class barriers are important tools for managing resources (in this case, memory) within a modular program. The feature of average that is hard to handle is the fact that the aggregate nums is used non-linearly (i.e., more than once). <p> Space does not permit a presentation of all of Opera's rewrite rules; for more detailed coverage, see <ref> [Tur94] </ref>. The [synchron-return] rule treats synchron nodes as self-evaluating values. In English: "If the synchron node has been demanded, then it is returned to the demander as a value." The [simultaneous ] rule ensures that all references to two unified synchrons point to the same synchron. <p> But it is possible to package them into abstractions that are accessible to a broader audience. We have used Opera to implement a suite of sequence and tree operators that can be composed to yield computations that exhibit fine-grained operational characteristics of non-modular loops and recursions <ref> [Tur94] </ref>. As suggested by Section 2.2, synchrons are crucial for achieving this behavior. Synchrons and synchronized lazy aggregates are the first steps in a research program whose purpose is to express algorithms in a modular way while preserving important operational properties like asymptotic time and space complexity.
Reference: [Wad84] <author> Philip Wadler. </author> <title> Listlessness is better than laziness: Lazy evaluation and garbage collection at compile-time. </title> <booktitle> In ACM Symposium On Lisp and Functional Programming, </booktitle> <pages> pages 45-52, </pages> <year> 1984. </year>
Reference-contexts: One drawback of this aggregate data paradigm is that intermediate data structures can cause modular programs to require more time and space than their monolithic counterparts. Numerous strategies have been developed to reduce these overheads in aggregate data programs (e.g., laziness [Hug90], algebraic transformations [DR76, Bir88], listlessness <ref> [Wad84] </ref>, deforestation [Wad88, GLJ93], series [Wat90]). However, these strategies either unduly restrict the style of aggregate data program allowed (e.g., trees are not allowed; aggregates may only have a single consumer), or they provide no guarantees (e.g., a transformation may increase overhead instead of decreasing it).
Reference: [Wad88] <author> Philip Wadler. </author> <title> Deforestation: Transforming programs to eliminate trees. </title> <booktitle> In 2nd European Symposium on Programming, </booktitle> <pages> pages 344-358, </pages> <year> 1988. </year> <booktitle> Lecture Notes in Computer Science, Number 300. </booktitle>
Reference-contexts: One drawback of this aggregate data paradigm is that intermediate data structures can cause modular programs to require more time and space than their monolithic counterparts. Numerous strategies have been developed to reduce these overheads in aggregate data programs (e.g., laziness [Hug90], algebraic transformations [DR76, Bir88], listlessness [Wad84], deforestation <ref> [Wad88, GLJ93] </ref>, series [Wat90]). However, these strategies either unduly restrict the style of aggregate data program allowed (e.g., trees are not allowed; aggregates may only have a single consumer), or they provide no guarantees (e.g., a transformation may increase overhead instead of decreasing it). <p> Moreover, whereas series is limited to iteratively processed sequences, synchronized lazy aggregates can handle recursively processed sequences and tree-structured data. It would be worthwhile to adapt series compilation techniques to handle these more general kinds of processing; we plan to pursue this line of research. Deforestation <ref> [Wad88, GLJ93] </ref> is program transformation technique that removes intermediate data structures from programs. It is more powerful than series in the sense that it can remove tree-structured data. However, unlike series and synchronized lazy aggregates, current deforestation technology cannot deal with fan-out of aggregates.
Reference: [Wat90] <author> Richard C. Waters. </author> <title> Series. </title> <editor> In Guy L. Steele Jr., editor, </editor> <title> Common Lisp: </title> <booktitle> The Language, </booktitle> <pages> pages 923-955. </pages> <publisher> Digital Press, </publisher> <year> 1990. </year>
Reference-contexts: Numerous strategies have been developed to reduce these overheads in aggregate data programs (e.g., laziness [Hug90], algebraic transformations [DR76, Bir88], listlessness [Wad84], deforestation [Wad88, GLJ93], series <ref> [Wat90] </ref>). However, these strategies either unduly restrict the style of aggregate data program allowed (e.g., trees are not allowed; aggregates may only have a single consumer), or they provide no guarantees (e.g., a transformation may increase overhead instead of decreasing it). <p> Synchrons are more more modular than Hughes's barrier because the number of threads participating in a barrier is automatically determined by the flow of synchron values through a program, and all threads enter a rendezvous via the same wait primitive. Waters's series system <ref> [Wat90, Wat91] </ref> is the only other system we know of that can execute aggregate data programs like average in constant space. A series is an abstraction of an iteratively processed sequence of values.
Reference: [Wat91] <author> Richard C. Waters. </author> <title> Automatic transformation of series expressions into loops. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(1) </volume> <pages> 52-98, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Synchrons are more more modular than Hughes's barrier because the number of threads participating in a barrier is automatically determined by the flow of synchron values through a program, and all threads enter a rendezvous via the same wait primitive. Waters's series system <ref> [Wat90, Wat91] </ref> is the only other system we know of that can execute aggregate data programs like average in constant space. A series is an abstraction of an iteratively processed sequence of values. <p> Even though concurrency and synchrons seem to be essential for expressing certain algorithms in a modular fashion, this does not imply that these features are required for executing such algorithms. In fact, we suspect that a compiler similar to Waters's series compiler <ref> [Wat91] </ref> should be able to automatically generate efficient sequential monolithic programs for many algorithms modularly expressed via synchronized lazy aggregates. Such a compiler would remove all overhead of concurrency and synchronization, as well as the overhead associated with packaging and unpackaging intermediate aggregates.
Reference: [Wil] <author> Paul R. Wilson. </author> <title> Uniprocessor garbage collection techniques. </title> <note> ACM Computing Surveys (to appear). </note>
Reference-contexts: The synchron is a new member of a class of high-level programming language features whose semantics are inextricably tied to garbage collection. Other examples of such GC-dependent features include object finalization and weak pairs <ref> [Wil] </ref>.
References-found: 38

