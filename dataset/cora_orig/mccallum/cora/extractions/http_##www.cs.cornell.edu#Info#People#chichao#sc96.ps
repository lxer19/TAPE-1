URL: http://www.cs.cornell.edu/Info/People/chichao/sc96.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/chichao/papers.htm
Root-URL: 
Title: Low-Latency Communication on the IBM RISC System/6000 SP  
Author: Chi-Chao Chang, Grzegorz Czajkowski, Chris Hawblitzel and Thorsten von Eicken 
Address: Ithaca NY 14853  
Affiliation: Department of Computer Science Cornell University  
Abstract: The IBM SP is one of the most powerful commercial MPPs, yet, in spite of its fast processors and high network bandwidth, the SP's communication latency is inferior to older machines such as the TMC CM-5 or Meiko CS-2. This paper investigates the use of Active Messages (AM) communication primitives as an alternative to the standard message passing in order to reduce communication overheads and to offer a good building block for higher layers of software. The first part of this paper describes an implementation of Active Messages (SP AM) which is layered directly on top of the SP's network adapter (TB2). With comparable bandwidth, SP AM's low overhead yields a round-trip latency that is 40% lower than IBM MPL's. The second part of the paper demonstrates the power of AM as a communication substrate by layering Split-C as well as MPI over it. Split-C benchmarks are used to compare the SP to other MPPs and show that low message overhead and high throughput compensate for SP's high network latency. The MPI implementation is based on the freely available MPICH version and achieves performance equivalent to IBM's MPI-F on the NAS benchmarks. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Bailey, T. Harris, W. Sahpir, and R. van der Wijngaart, </author> <title> The NAS Parallel Benchmarks 2.0, Report NAS-95-020, Numerical Aerodynamic Simulation Facility, </title> <institution> NASA Ames Research Center, </institution> <month> December </month> <year> 1995. </year>
Reference: [2] <author> Chi-Chao Chang, Grzegorz Czajkowski, and Thorsten von Eicken, </author> <title> Design and Performance of Active Messages on the IBM SP2, </title> <type> Cornell CS Technical Report 96-1572, </type> <month> February </month> <year> 1996. </year>
Reference-contexts: The bandwidth of SP AM's synchronous stores and gets 3 Measurements of the bandwidth on exchange can be found in <ref> [2] </ref>. 3 also converges to 34.3 MBytes/s but at a slower rate due to the round-trip latency as the sender blocks after every transfer waiting for an acknowledgement. <p> The absolute execution times for runs on eight processor are shown in Table 5. Execution times normalized to the SP AM are shown in Figure 4. Detailed explanation of the benchmarks can be found in <ref> [2] </ref>. The two matrix multiply runs use matrices of 4 by 4 blocks with 128 by 128 double floats per block, respectively 16 by 16 blocks with 16 by 16 double floats each.
Reference: [3] <author> D. E. Culler, K. Keeton, L. T. Liu, A. Mainwaring, R. Martin, S. Rodrigues, and K. Wright, </author> <title> Generic Active Messages Interface Specification, </title> <institution> UC Berkeley, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: Copyright c fl1996 IEEE. implementations are also available for the Meiko CS-2 [10], HP workstations on FDDI ring [9], Intel Paragon, and the U-Net ATM cluster of Sun Sparcstations [13]. All the implementations are based on the Generic Active Message Specification Version 1.1 <ref> [3] </ref>. Message passing is the most widely used communication model in parallel computing and is now standardized in the Message Passing Interface (MPI)[5]. It supports blocking and nonblocking sends and receives, collective communication, noncontiguous messages, and contains facilities for dealing with groups of processes and libraries.
Reference: [4] <author> D. E. Culler, A. Dusseau, S. Goldstein, A. Krishnamurthy, S. Lumeta, T. von Eicken, and K. Yelick, </author> <title> Parallel Programming in Split-C, </title> <booktitle> In Proceedings of Supercomputing '93. </booktitle>
Reference-contexts: The asymptotic bandwidth of SP AM is comparable to MPL's asymptotic bandwidth. A half-power point comparison indicates that SP AM delivers better performance than MPL for short messages. 3 Split-C Application Benchmarks Split-C <ref> [4] </ref> is a simple parallel extension to C for programming distributed memory machines using a global address space abstraction. It is implemented on top of Generic Active Messages and is used here to demonstrate the impact of SP AM on applications written in a parallel language.
Reference: [5] <author> Message Passing Interface Forum, </author> <title> The MPI Message Passing Interface Standard, </title> <type> Technical Report, </type> <institution> U. of Tennessee, Knoxville TN, </institution> <month> April </month> <year> 1994. </year>
Reference: [6] <author> H. Franke, C. E. Wu, M. Riviere, P. Pattnaik, and M. Snir, </author> <title> MPI Program ming Environment for IBM SP1/SP2, </title> <booktitle> In Proceedings of the 22nd Int'l Symposium on Computer Architecture, </booktitle> <year> 1995. </year>
Reference-contexts: The optimized version switches over at 8K, but shows no performance hit because of the hybrid buffered/rendez-vous protocol. 4 The MPI-F results on wide nodes presented here differ somewhat from those in <ref> [6] </ref> in that the switch from a buffered to a rendez-vous protocol occurs at a message size of 4K bytes rather than the 8K bytes.
Reference: [7] <author> W. Gropp and E. Lusk, </author> <title> MPICH ADI Implementation Reference Manual (Draft), </title> <month> August </month> <year> 1995. </year>
Reference-contexts: It supports blocking and nonblocking sends and receives, collective communication, noncontiguous messages, and contains facilities for dealing with groups of processes and libraries. Since much of MPI's functionality is machine-independent, a freely available MPICH <ref> [7] </ref> implementation of MPI was developed to take care of the upper layers of MPI while providing an abstract device interface (ADI) to the machine dependent layers.
Reference: [8] <author> IBM, </author> <title> SP2 Command and Technical Reference, </title> <month> December </month> <year> 1994. </year>
Reference-contexts: Each node has its own memory, CPU, operating system (AIX), MicroChannel I/O bus, Ethernet adapter, and high performance switch adapter <ref> [8] </ref>. The SP processing nodes operate at a clock speed of 66MHz and offer a peak performance of 266 Mflops. A model 390 thin node contains a 64 KB data cache with 64-byte lines, a 64-bit memory bus, and 64 to 512 Mbytes of main memory.
Reference: [9] <author> R. P. Martin, HPAM: </author> <title> An Active Message Layer for a Network of Work stations, </title> <booktitle> In Proceedings of Hot Interconnects II, </booktitle> <address> Palo Alto CA, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: Chi-Chao Chang is supported in part by a doctoral fellowship (200812/94-7) from CNPq/Brazil. In the Proceedings of ACM/IEEE Supercomputing, Pittsburgh, PA, November 1996. Copyright c fl1996 IEEE. implementations are also available for the Meiko CS-2 [10], HP workstations on FDDI ring <ref> [9] </ref>, Intel Paragon, and the U-Net ATM cluster of Sun Sparcstations [13]. All the implementations are based on the Generic Active Message Specification Version 1.1 [3]. Message passing is the most widely used communication model in parallel computing and is now standardized in the Message Passing Interface (MPI)[5].
Reference: [10] <author> K. E. Schauser and C. J. Scheiman, </author> <title> Experience with Active Messages on the Meiko CS-2, </title> <booktitle> In Proceedings of the 9th Int'l Parallel Processing Symposium, </booktitle> <address> Santa Barbara, CA, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: Chi-Chao Chang is supported in part by a doctoral fellowship (200812/94-7) from CNPq/Brazil. In the Proceedings of ACM/IEEE Supercomputing, Pittsburgh, PA, November 1996. Copyright c fl1996 IEEE. implementations are also available for the Meiko CS-2 <ref> [10] </ref>, HP workstations on FDDI ring [9], Intel Paragon, and the U-Net ATM cluster of Sun Sparcstations [13]. All the implementations are based on the Generic Active Message Specification Version 1.1 [3].
Reference: [11] <author> C. B. Stunkel et al., </author> <title> The SP2 Communication Subsystem, </title> <month> August </month> <year> 1994. </year>
Reference-contexts: The switch provides four different routes between each pair of nodes, a hardware latency of about 500ns, and a bandwidth close to 40 MBytes/s. SP nodes are connected to the high-speed interconnection switch via communication adapters (referred-to as TB2) <ref> [11] </ref> which contain an Intel i860 microprocessor with 8 MBytes of DRAM. Shown in Figure 1, the adapter plugs into the 32-bit MicroChannel I/O bus with a 80 MB/s peak transfer rate and contains a custom Memory and Switch Management Unit (MSMU) to interface into the network.
Reference: [12] <author> T. von Eicken, D. E. Culler, S. C. Goldstein, and K. E. Schauser, </author> <title> Active Messages: A Mechanism for Integrated Communication and Computation, </title> <booktitle> In Proceedings of the 19th Int'l Symposium on Computer Architecture, </booktitle> <address> Gold Coast, Australia, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Active Messages (AM) provide simple communication primitives that are well suited as building blocks for higher layers of software such as parallel languages and complex message interfaces. Originally developed for the CM-5 <ref> [12] </ref>, This work has been sponsored by IBM under the joint project agreement 11-2691-A and University Agreement MHVU5851, and by NSF under contracts CDA-9024600 and ASC-8902827. Chi-Chao Chang is supported in part by a doctoral fellowship (200812/94-7) from CNPq/Brazil. In the Proceedings of ACM/IEEE Supercomputing, Pittsburgh, PA, November 1996. <p> The NAS benchmarks (Section 6) achieve the same performance using MPICH over SP AM as using MPI-F. 1.1 Active Messages background AM is a low-latency communication mechanism for multiprocessors that emphasizes the overlap of communication and computation <ref> [12] </ref>. Messages are in the form of requests and matching replies and contain the address of a handler that is invoked on receipt of the message along with up to four words of arguments.
Reference: [13] <author> T. von Eicken, A. Basu, V. Buch, and W. Vogels, U-Net: </author> <title> A User-Level Net work Interface for Parallel and Distributed Computing, </title> <booktitle> In Proceedings of the 15th Symposium on Operating System Principles, </booktitle> <address> Cooper Mountain, CO, </address> <month> December </month> <year> 1995. </year> <month> 8 </month>
Reference-contexts: In the Proceedings of ACM/IEEE Supercomputing, Pittsburgh, PA, November 1996. Copyright c fl1996 IEEE. implementations are also available for the Meiko CS-2 [10], HP workstations on FDDI ring [9], Intel Paragon, and the U-Net ATM cluster of Sun Sparcstations <ref> [13] </ref>. All the implementations are based on the Generic Active Message Specification Version 1.1 [3]. Message passing is the most widely used communication model in parallel computing and is now standardized in the Message Passing Interface (MPI)[5].
References-found: 13

