URL: ftp://ftp.engr.orst.edu/pub/dambrosi/ijar-94.ps.Z
Refering-URL: http://www.cs.orst.edu/~dambrosi/
Root-URL: 
Title: Efficient Inference in Bayes Networks As A Combinatorial Optimization Problem  
Author: Zhaoyu Li Bruce D'Ambrosio 
Keyword: belief network, probabilistic inference, combinatorial optimization, optimal factoring, set-factoring, heuristic algorithm.  
Note: Address correspondence to Zhaoyu Li, 1896  International Journal of Approximate Reasoning 1994 11:1-158 c 1994 Elsevier  
Address: Corvallis, OR 97331  Street, Eugene, OR 97403  655 Avenue of the Americas, New York, NY 10010 0888-613X/94/$7.00 1  
Affiliation: Department of Computer Science Oregon State University  Columbia  Science Inc.  
Abstract: A number of exact algorithms have been developed to perform probabilistic inference in Bayesian belief networks in recent years. The techniques used in these algorithms are closely related to network structures and some of them are not easy to understand and implement. In this paper, we consider the problem from the combinatorial optimization point of view and state that efficient probabilistic inference in a belief network is a problem of finding an optimal factoring given a set of probability distributions. From this viewpoint, previously developed algorithms can be seen as alternate factoring strategies. In this paper, we define a combinatorial optimization problem, the optimal factoring problem, and discuss application of this problem in belief networks. We show that optimal factoring provides insight into the key elements of efficient probabilistic inference, and demonstrate simple, easily implemented algorithms with excellent performance. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> B. D'Ambrosio. </author> <title> Symbolic probabilistic inference. </title> <type> Technical report, </type> <institution> CS Dept., Oregon State University, </institution> <year> 1989. </year>
Reference-contexts: The time complexity of computing the full joint probability distribution of a belief network is exponential in the number of nodes of the network. A number of exact algorithms have been developed to perform probabilistic inference in belief networks in recent years <ref> [12, 15, 7, 13, 16, 1, 17, 18, 5, 14, 20] </ref>. These algorithms rely either on the original directed graph, on a related directed graph, or on a related undirected graph. <p> of some exact probabilistic inference algorithms, conditioning, clustering, reduction and an earlier version of SPI, have been analyzed, and their efficiency has been experimentally tested [9] with the implementation of IDEAL system [19] for conditioning, clustering and reduction algorithms and the implementation of the earlier form of SPI described in <ref> [1] </ref>. SPI had equal or better performance in every case in that study. In this study we first experimentally compare set-factoring with the older SPI, then compare it to the current standard exact algorithm, the Jensen algorithm. Three sets of test cases were generated for time complexity experiments. <p> In static factoring, the order of combining factors comes from the original belief network before any querying and observation. An example of a static strategy is the partition strategy in SPI <ref> [1] </ref>, which creates a partition tree before any probability computation. One of the advantages of static factoring is that it is performed only once before any querying and observation, and can be performed off line. <p> This problem is closely related to the caching strategy used in a factoring algorithm. Caching may reduce probabilistic computation depending on the structure of a belief network and the tasks to be carried out, as the test results indicated in <ref> [1, 18] </ref>. Some tasks favor caching: for example, given a set of observations in a belief network and a set of queries on more than one variable. <p> Some belief networks provide good caching structures: for example, a belief network having a long chain would provide many opportunities for caching when the queried nodes are all in the chain. An experimental test has been performed for examining the effects of caching between the SPI algorithm <ref> [1] </ref>, with a static factoring strategy for a partition tree, and the set-factoring algorithm with a dynamic factoring strategy for creating an evaluation tree (see previous section).
Reference: 2. <author> B. D'Ambrosio, T. Fountain, and Z. Li. </author> <title> Parallelizing probabilistic inference-some early explorations. </title> <booktitle> In Proceedings of the Eigth Annual Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Palo Alto, July 1992. </address> <publisher> Morgan Kaufmann, Publishers. </publisher>
Reference: 3. <author> D. Geiger, T. Verma, and J. Pearl. d-separation: </author> <title> From theorems to algorithms. </title> <booktitle> In Proceedings of the Fifth Workshop on Uncertainty in AI, </booktitle> <pages> pages 118-125, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: In this case, we can save some computation time if we just consider the variables relevant to the query instead of computing the conformal products for the full joint probability distribution. Theoretical research in <ref> [3, 13] </ref> provides a way of finding relevant variables to a query in a belief network in polynomial time in the total number of variables. <p> The involved nodes can be chosen from the original belief network by an algorithm which runs in linear time in the number of nodes and arcs in the belief network <ref> [3] </ref>. Once we have obtained the nodes needed for the query, we have all the factors to be combined. In accordance with the definition 2, we have n subsets of n nodes and set Q. We use the following algorithm to combine these factors. 15 1.
Reference: 4. <author> T. C. Hu. </author> <title> Combinatorial Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1982. </year>
Reference-contexts: If we ignore the parentheses in the result of OFP, since the time complexity of putting parentheses in a given permutation of the n nodes to get an optimal result is polynomial in the number of the nodes <ref> [4] </ref>, OFP like SPP is the problem of finding a proper permutation of n nodes. The difference between the two problems is that in SPP edge distances between nodes is static, while in OFP, they are dynamic, that is, they depend on the path taken to the edge. 5 2.3. <p> Therefore the given combination is minimal. Therefore, the factoring is optimal. For the arbitrary factoring problem, we have developed an optimal dynamic factoring algorithm. Dynamic programming is one of the few general techniques for solving optimization problems <ref> [10, 11, 4] </ref>. It is related to branch-and-bound techniques in the sense that it performs an intelligent enumeration of all feasible points of a problem. The idea is to work backwards from the last decisions to the earlier ones.
Reference: 5. <author> F. V. Jensen, K. G. Olesen, and S.K. Andersen. </author> <title> An algebra of bayesian belief universes for knowledge based syste ms. </title> <journal> Networks, </journal> <volume> 20(5) </volume> <pages> 637-659, </pages> <year> 1990. </year>
Reference-contexts: The time complexity of computing the full joint probability distribution of a belief network is exponential in the number of nodes of the network. A number of exact algorithms have been developed to perform probabilistic inference in belief networks in recent years <ref> [12, 15, 7, 13, 16, 1, 17, 18, 5, 14, 20] </ref>. These algorithms rely either on the original directed graph, on a related directed graph, or on a related undirected graph.
Reference: 6. <author> J. H. Kim and J. Pearl. </author> <title> A computational model for causal and diagnostic reasoning in inference engines. </title> <booktitle> In Proceedings of IJCAI-83. </booktitle> <address> Karlsruhe, FRG, </address> <year> 1983. </year>
Reference-contexts: In probability computation, any computation result within a group or among groups can be cached for subsequent use. The top-down and/or bottom-up operations will be avoided if there are cached intermediate results available. &gt;From the combinatorial optimization point of view the poly-tree propagation algorithm <ref> [6, 13] </ref> and Revised poly-tree Algorithm [14] provide an optimal factoring among groups for computing probabilities; but their propagation strategies do not provide any factoring strategy within a group. 4.
Reference: 7. <author> S. Lauritzen and D. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> B 50, </volume> <year> 1988. </year>
Reference-contexts: The time complexity of computing the full joint probability distribution of a belief network is exponential in the number of nodes of the network. A number of exact algorithms have been developed to perform probabilistic inference in belief networks in recent years <ref> [12, 15, 7, 13, 16, 1, 17, 18, 5, 14, 20] </ref>. These algorithms rely either on the original directed graph, on a related directed graph, or on a related undirected graph. <p> These algorithms rely either on the original directed graph, on a related directed graph, or on a related undirected graph. For example, the poly-tree propagation algorithm [13] relies on the original poly-tree and the algorithm developed in <ref> [7] </ref> relies on the related undirected graph. While the graph topology contains all available information for performing inference, much of that information is non-local and difficult to extract.
Reference: 8. <author> Eugene L. Lawler. </author> <title> Combinatorial Optimization: Networks and Matroids. </title> <publisher> Rinehart and Winston, Holt, </publisher> <year> 1976. </year>
Reference-contexts: We guess that OFP is an NP-hard problem although we have not yet proved this. We can see the similarity between OFP and the problem of finding the shortest path among n nodes by passing each node exactly once (SPP) <ref> [8] </ref>, which is NP-hard. In SPP, the problem is to find a permutation of n nodes which results in the shortest path; while in OFP, the problem is to find a proper permutation of n nodes and then put parentheses in so that it results in a minimal computation.
Reference: 9. <author> Z. Li. </author> <title> Experimental characterization of several algorithms for inference in belief nets. </title> <type> Technical report, Master's thesis, </type> <institution> CS Dept., Oregon State University, </institution> <year> 1990. </year>
Reference-contexts: Therefore, the time complexity of the algorithm is O (n 3 ) in the number of nodes. 4.1.2. Experimental tests Time complexity of some exact probabilistic inference algorithms, conditioning, clustering, reduction and an earlier version of SPI, have been analyzed, and their efficiency has been experimentally tested <ref> [9] </ref> with the implementation of IDEAL system [19] for conditioning, clustering and reduction algorithms and the implementation of the earlier form of SPI described in [1]. SPI had equal or better performance in every case in that study. <p> computation If we refer to the computation of conformal products as numeric computation, we find that the numeric computation in probabilistic inference is exponential in the number of variables relevant to the computation while factoring heuristics are typically polynomial with respect to the number of variables related to the query <ref> [9] </ref>. The factoring computation can be very small if we simply randomly combine the distributions for a query and sum over those variables not queried. However, the total computational cost (factoring plus conformal products) could be quite high in that case.
Reference: 10. <author> Georger Numhauser and Laurence A. Wolsey. </author> <title> Integer and Combinatorial Optimization. </title> <publisher> Wiley-interscience, </publisher> <year> 1988. </year>
Reference-contexts: Therefore the given combination is minimal. Therefore, the factoring is optimal. For the arbitrary factoring problem, we have developed an optimal dynamic factoring algorithm. Dynamic programming is one of the few general techniques for solving optimization problems <ref> [10, 11, 4] </ref>. It is related to branch-and-bound techniques in the sense that it performs an intelligent enumeration of all feasible points of a problem. The idea is to work backwards from the last decisions to the earlier ones.
Reference: 11. <author> Christos H. Papadimitriou and Kenneth Steiglitz. </author> <title> Combinatorial Optimization Algorithms and Complexity. </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: Therefore the given combination is minimal. Therefore, the factoring is optimal. For the arbitrary factoring problem, we have developed an optimal dynamic factoring algorithm. Dynamic programming is one of the few general techniques for solving optimization problems <ref> [10, 11, 4] </ref>. It is related to branch-and-bound techniques in the sense that it performs an intelligent enumeration of all feasible points of a problem. The idea is to work backwards from the last decisions to the earlier ones.
Reference: 12. <author> J. Pearl. </author> <title> A constraint-propagation approach to probabilistic reasoning. </title> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 357-370, </pages> <year> 1986. </year>
Reference-contexts: The time complexity of computing the full joint probability distribution of a belief network is exponential in the number of nodes of the network. A number of exact algorithms have been developed to perform probabilistic inference in belief networks in recent years <ref> [12, 15, 7, 13, 16, 1, 17, 18, 5, 14, 20] </ref>. These algorithms rely either on the original directed graph, on a related directed graph, or on a related undirected graph.
Reference: 13. <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> Palo Alto, </address> <year> 1988. </year>
Reference-contexts: A belief network is a compact representation of a full joint probability distribution over the n domain variables in the belief network. In particular, the full joint probability distribution can be calculated as follows <ref> [13, 15] </ref>: p (x 1 ; :::; x n ) = i=1 Where x 1 ,..., x n are n variables in the belief network; i is the set of direct predecessors of x i ; p (x i j i ) is the conditional probability for variable x i if <p> The time complexity of computing the full joint probability distribution of a belief network is exponential in the number of nodes of the network. A number of exact algorithms have been developed to perform probabilistic inference in belief networks in recent years <ref> [12, 15, 7, 13, 16, 1, 17, 18, 5, 14, 20] </ref>. These algorithms rely either on the original directed graph, on a related directed graph, or on a related undirected graph. <p> These algorithms rely either on the original directed graph, on a related directed graph, or on a related undirected graph. For example, the poly-tree propagation algorithm <ref> [13] </ref> relies on the original poly-tree and the algorithm developed in [7] relies on the related undirected graph. While the graph topology contains all available information for performing inference, much of that information is non-local and difficult to extract. <p> In this case, we can save some computation time if we just consider the variables relevant to the query instead of computing the conformal products for the full joint probability distribution. Theoretical research in <ref> [3, 13] </ref> provides a way of finding relevant variables to a query in a belief network in polynomial time in the total number of variables. <p> In probability computation, any computation result within a group or among groups can be cached for subsequent use. The top-down and/or bottom-up operations will be avoided if there are cached intermediate results available. &gt;From the combinatorial optimization point of view the poly-tree propagation algorithm <ref> [6, 13] </ref> and Revised poly-tree Algorithm [14] provide an optimal factoring among groups for computing probabilities; but their propagation strategies do not provide any factoring strategy within a group. 4.
Reference: 14. <author> Mark A. Peot. </author> <title> Fusion and propagation with multiple observations in belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 48 </volume> <pages> 299-318, </pages> <year> 1991. </year>
Reference-contexts: The time complexity of computing the full joint probability distribution of a belief network is exponential in the number of nodes of the network. A number of exact algorithms have been developed to perform probabilistic inference in belief networks in recent years <ref> [12, 15, 7, 13, 16, 1, 17, 18, 5, 14, 20] </ref>. These algorithms rely either on the original directed graph, on a related directed graph, or on a related undirected graph. <p> The top-down and/or bottom-up operations will be avoided if there are cached intermediate results available. &gt;From the combinatorial optimization point of view the poly-tree propagation algorithm [6, 13] and Revised poly-tree Algorithm <ref> [14] </ref> provide an optimal factoring among groups for computing probabilities; but their propagation strategies do not provide any factoring strategy within a group. 4.
Reference: 15. <author> R. Shachter. </author> <title> Evaluating influence diagrams. </title> <journal> Operations Research, </journal> <volume> 34(6):871 - 882, </volume> <month> November-December </month> <year> 1986. </year>
Reference-contexts: A belief network is a compact representation of a full joint probability distribution over the n domain variables in the belief network. In particular, the full joint probability distribution can be calculated as follows <ref> [13, 15] </ref>: p (x 1 ; :::; x n ) = i=1 Where x 1 ,..., x n are n variables in the belief network; i is the set of direct predecessors of x i ; p (x i j i ) is the conditional probability for variable x i if <p> The time complexity of computing the full joint probability distribution of a belief network is exponential in the number of nodes of the network. A number of exact algorithms have been developed to perform probabilistic inference in belief networks in recent years <ref> [12, 15, 7, 13, 16, 1, 17, 18, 5, 14, 20] </ref>. These algorithms rely either on the original directed graph, on a related directed graph, or on a related undirected graph.
Reference: 16. <author> R. Shachter. </author> <title> Probabilistic inference and inference diagrams. </title> <journal> Operations Research, </journal> <volume> 36(6):589 - 604, </volume> <month> July-August </month> <year> 1988. </year>
Reference-contexts: The time complexity of computing the full joint probability distribution of a belief network is exponential in the number of nodes of the network. A number of exact algorithms have been developed to perform probabilistic inference in belief networks in recent years <ref> [12, 15, 7, 13, 16, 1, 17, 18, 5, 14, 20] </ref>. These algorithms rely either on the original directed graph, on a related directed graph, or on a related undirected graph.
Reference: 17. <author> R. Shachter. </author> <title> Evidence absorption and propagation through evidence reversal. </title> <booktitle> In Proceedings of the Fifth Workshop on Uncertainty on AI, </booktitle> <pages> pages 303-310, </pages> <month> Aug. </month> <year> 1989. </year>
Reference-contexts: The time complexity of computing the full joint probability distribution of a belief network is exponential in the number of nodes of the network. A number of exact algorithms have been developed to perform probabilistic inference in belief networks in recent years <ref> [12, 15, 7, 13, 16, 1, 17, 18, 5, 14, 20] </ref>. These algorithms rely either on the original directed graph, on a related directed graph, or on a related undirected graph.
Reference: 18. <author> R. Shachter, B. D'Ambrosio, and B. DelFavero. </author> <title> Symbolic probabilistic inference in belief networks. </title> <booktitle> In Proceedings Eighth National Conference on AI, </booktitle> <pages> pages 126-131. </pages> <publisher> AAAI, </publisher> <month> August </month> <year> 1990. </year> <month> 24 </month>
Reference-contexts: The time complexity of computing the full joint probability distribution of a belief network is exponential in the number of nodes of the network. A number of exact algorithms have been developed to perform probabilistic inference in belief networks in recent years <ref> [12, 15, 7, 13, 16, 1, 17, 18, 5, 14, 20] </ref>. These algorithms rely either on the original directed graph, on a related directed graph, or on a related undirected graph. <p> Given a belief network with m nodes and a set of observations, computing the answer to a query involves identification of a subset of n nodes relevant to the query and computation of the conformal product <ref> [18] </ref> of marginal and conditional probabilities of the n nodes. <p> P (X J jX K ; X E ) can be computed from P (X J ; X K jX E ). For simplicity, we will only consider the case P (X J jX E ) in the algorithm. This ignores several potential simplifications noted in <ref> [18] </ref>, but simplifies the presentation. Given a query P (X J jX E ) in a belief network, often only a subset of the nodes is involved in the probability computation. <p> the index of test cases; * node, the number of nodes in each belief network; * arc/n, the average arcs per node; * obs, the number of observations inserted in the belief network; * qry, the number of queries; * SPI, the test results of the earlier form of SPI <ref> [18] </ref>; 7 Unless noted otherwise, all random selections are from uniform distributions over the indicated range. 8 The optimal algorithm is a dynamic programming algorithm with exponential cost. 18 net node arc/n obs qry SPI set-f opt-alg 1 12 2 3 7 287 52 52 3 9 2.5 4 12 301 <p> This problem is closely related to the caching strategy used in a factoring algorithm. Caching may reduce probabilistic computation depending on the structure of a belief network and the tasks to be carried out, as the test results indicated in <ref> [1, 18] </ref>. Some tasks favor caching: for example, given a set of observations in a belief network and a set of queries on more than one variable.
Reference: 19. <author> S. Srinivas and J. Breese. </author> <title> Ideal: Inference diagram evaluation and analysis in lisp. </title> <type> Technical report, </type> <institution> Rockwell Palo Alto Lab technical report, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: Experimental tests Time complexity of some exact probabilistic inference algorithms, conditioning, clustering, reduction and an earlier version of SPI, have been analyzed, and their efficiency has been experimentally tested [9] with the implementation of IDEAL system <ref> [19] </ref> for conditioning, clustering and reduction algorithms and the implementation of the earlier form of SPI described in [1]. SPI had equal or better performance in every case in that study.
Reference: 20. <author> L. Zhang and D. Poole. </author> <title> Sidestepping the triangulation problem in bayesian net computati ons. </title> <booktitle> In Proceedings of the Eighth Annual Conference on Uncertainty i n Artificial Intelligence, </booktitle> <address> Palo Alto, July 1992. </address> <publisher> Morgan Kaufmann, Publishers. </publisher>
Reference-contexts: The time complexity of computing the full joint probability distribution of a belief network is exponential in the number of nodes of the network. A number of exact algorithms have been developed to perform probabilistic inference in belief networks in recent years <ref> [12, 15, 7, 13, 16, 1, 17, 18, 5, 14, 20] </ref>. These algorithms rely either on the original directed graph, on a related directed graph, or on a related undirected graph.
References-found: 20

