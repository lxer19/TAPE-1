URL: http://www-wavelet.eecs.berkeley.edu/~jyeh/joems.ps.gz
Refering-URL: http://www-wavelet.eecs.berkeley.edu/~jyeh/resume.html
Root-URL: 
Title: Three-Dimensional coding of Motion Vector Fields in Video  
Author: by Joseph Chiaming Yeh 
Degree: Submitted in partial fulfillment of the requirements for the degree of Master of Science, Plan II in Electrical Engineering and Computer Sciences in the GRADUATE DIVISION of the  Committee in charge: Professor  Advisor Professor Avideh Zakhor  
Date: December 1997  
Affiliation: Research Project  UNIVERSITY of CALIFORNIA at BERKELEY  Martin Vetterli, Research  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> C. Auyeung, J. Kosmach, M. Orchard, and T. Kalafatis, </author> <title> "Overlapped Block Motion Compensation", </title> <booktitle> SPIE Conf. Visual Communication Image Processing, </booktitle> <volume> vol. 1605, </volume> <pages> pp. 561-571, </pages> <month> November </month> <year> 1992. </year>
Reference: [2] <author> Y.L. Chan and W.C. Siu, </author> <title> "Variable Temporal-Length 3-D Discrete Cosine Transform Coding", </title> <journal> IEEE Trans. on Image Processing, </journal> <volume> vol. 6, no. 5, </volume> <pages> pp. 758-763, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: However, if N becomes too large, the AR (1) model of the data starts to fail. For this reason, Chan and Siu <ref> [2] </ref> have introduced the idea of doing 3D-DCT's of variable sizes, varying the size along the temporal axis to coincide with scene changes or fast motion in the video. 3.5 Computational Complexity In Section 3.3, we discovered how the DCT transform in one dimension can be seen as a matrix multiplication <p> We then have a "Modified Haar Transform" equivalent to the "Sequential" transform of [14], shown here: H 0 [n] = h [2n] + h [2n + 1] (5.1) 1 (h [2n] h [2n + 1])c (5.2) with inverse transform 39 ~ 2 n ] + H 1 <ref> [ 2 ] </ref> for n even (5.3) h [n] = 1 H 0 [ 2 - n ] for n odd (5.4) When the motion estimator cannot find an appropriate motion vector for a block, it records a DONTCARE value in its place.
Reference: [3] <author> F. Chen, J.D. Villasenor, and D.S. Park, </author> <title> "A Low Complexity Rate- Distortion Model for Motion Estimation in H.263", </title> <booktitle> Proc. of IEEE International Conference on Image Processing, </booktitle> <year> 1996. </year>
Reference-contexts: First, if the coding is lossy, such as in a DCT-based system, the coder must take into account how the encoding error in motion vectors will affect the coding of motion residual data. Chen, Villasenor and 37 Park <ref> [3] </ref> have looked at this problem through posing the estimation and coding of motion vectors as a rate-distortion problem. Second, whereas an image will have a defined value for every pixel, a block-estimated MVF will not necessarily have a motion vector for every block.
Reference: [4] <author> K. Illgner and F. Muller, </author> <title> "Hierarchical Coding of Motion Vector Fields", </title> <booktitle> Proc. of IEEE International Conference on Image Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 566-569, </pages> <month> October </month> <year> 1995. </year>
Reference: [5] <institution> ITU-T/SG15/LBC Special Rapporteur for Very Low Bitrate Visual Telephony, "Draft Recommendation H.26P (Video coding for telecommunication channels at &lt; 64 kbits/s)," PTT Netherlands, </institution> <year> 1995. </year> <month> LBC-95-027. </month>
Reference-contexts: video coding test sequences Hall Monitor, Container Ship and MIT. (We skip through the first 40 frames on Hall Monitor because there is no motion, only image noise.) We compared our method of coding with the DPCM technique currently used in H.263 to code motion vectors illustrated in Figure 5.3 <ref> [5] </ref>. For comparison, we entropy coded the symbols from the zerotree method and we entropy coded the differences from the DPCM method. We then compared the total bitrate in both cases. The results are shown in Table 5.1.
Reference: [6] <author> A. Jain. </author> <title> Fundamentals of Digital Image Processing, </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: Therefore, since both rows and columns of images 18 can be reasonably modeled as AR (1) processes, it makes sense to perform the transform on blocks of images. 3.3 Mathematical Definition The DCT <ref> [6] </ref> A [k]; k = 0; 1; : : : ; N 1 of a sequence a [n]; n = 0; 1; : : :; N 1 is given by A [k] = fi [k] n=0 (2n + 1)k ] (3.1) where fi [0] = q N and fi [k] =
Reference: [7] <author> N.S. Jayant and Peter Noll, </author> <title> Digital Coding of Waveforms, </title> <publisher> Prentice Hall, </publisher> <year> 1984. </year>
Reference-contexts: transform a 3D N fiN fiN array, every N fiN frame in the array would be transformed, and then every segment across time would be transformed (again, the order is not important). 3.4 Coding Gain The DCT performs well in compressing signal data because it has a significant coding gain <ref> [7] </ref> G DCT (over Pulse Code Modulation). This means that if a signal is first DCT-transformed and then quantized, the resulting signal to noise (SNR) ratio will be G DCT times that if the signal is simply quantized. <p> We can therefore use the coding gain analysis of the KLT to estimate an upper bound for the coding gain of the DCT. The KLT coding gain for coding N samples of a 1-D AR (1) signal is given by <ref> [7] </ref> N G KLT = (1 2 ) N1 Since &lt; 1, it seems as if we should let the size N of one side of the block become as large as possible. However, if N becomes too large, the AR (1) model of the data starts to fail.
Reference: [8] <author> G. Karlsson and M. Vetterli, </author> <title> "Three Dimensional Sub-band Coding of Video", </title> <booktitle> Proc. of IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1100-1103, </pages> <month> April </month> <year> 1988. </year>
Reference: [9] <author> Y.Y. Lee and J. W. Woods, </author> <title> "Motion Vector Quantization for Video Coding", </title> <journal> IEEE Trans. on Image Processing, </journal> <month> March </month> <year> 1995. </year> <month> 47 </month>
Reference: [10] <author> A. Leon-Garcia, </author> <title> Probability and Random Processes for Electrical Engineering, </title> <editor> p. </editor> <volume> 265, </volume> <publisher> Addison Wesley, </publisher> <year> 1993. </year>
Reference: [11] <author> M. Nickel and J.H. Husoy, </author> <title> "A hybrid coder for image sequences using detailed motion estimates", </title> <booktitle> Proc. of the SPIE, </booktitle> <volume> vol. 2501, pt. 1, </volume> <pages> pp. 963-71, </pages> <year> 1991. </year>
Reference-contexts: At first glance, motion vector data seems similar to image data because there are often large areas that have exactly or approximately the same value, since they correspond to a large object moving at a constant speed. For this reason, Nickel and Husoy <ref> [11] </ref> and others have tried to use techniques such as the DCT to encode motion vector fields (MVF's). However, there are important differences between motion vector and image data that must be addressed in order for such coding techniques to work well.
Reference: [12] <author> J.-R. Ohm, </author> <title> "Three-Dimensional Subband Coding with Motion Compensation", </title> <journal> IEEE Trans. on Image Processing, </journal> <volume> vol. 3, </volume> <pages> pp. 559-571, </pages> <month> September </month> <year> 1994. </year>
Reference: [13] <author> A. Oppenheim and R. Schafer, </author> <title> Discrete-Time Signal Processing, Chapter 9, </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: In particular, the Discrete Fourier Transform (DFT) and other related transforms, including the DCT have "decimation in time" and "decimation in frequency" algorithms which allow the computation to be done in N log 2 N multiplications and N log 2 N additions if N is a power of 2 <ref> [13] </ref>. For this reason, DCT's are almost always done with a size which is a power of 2. The decimation algorithms work by segmenting a size N transform into 2 size N=2 transforms recursively until the size N transform is broken down into N=2 size 2 transforms.
Reference: [14] <author> A. </author> <title> Said and W.A. Perlman, "An image multiresolution representation for lossless and lossy image compression" , IEEE Trans. </title> <booktitle> on Image Processing, </booktitle> <volume> vol. 6, </volume> <pages> pp. 1303-1310, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Therefore, we can "throw away" the LSB of A + B or A B since it holds redundant information. We choose to throw away the least significant bit of A B (the high frequency component). We then have a "Modified Haar Transform" equivalent to the "Sequential" transform of <ref> [14] </ref>, shown here: H 0 [n] = h [2n] + h [2n + 1] (5.1) 1 (h [2n] h [2n + 1])c (5.2) with inverse transform 39 ~ 2 n ] + H 1 [ 2 ] for n even (5.3) h [n] = 1 H 0 [ 2 - n
Reference: [15] <author> J.M. Shapiro, </author> <title> "Embedded image coding using zerotrees of wavelet coefficients", </title> <journal> IEEE Trans. on Signal Processing, </journal> <volume> vol. 41, no. 12, </volume> <month> December </month> <year> 1993. </year>
Reference-contexts: Figure 5.2 shows how the coefficients are arranged in the final array before encoding. Our coder then takes advantage of structures called zerotrees to code efficiently. This concept was first presented by Shapiro <ref> [15] </ref> in 1993. This concept is illustrated in Figure 5.1 (b) for two dimensions, and in Figure 5.2 for three dimensions. <p> Thus, we can take advantage of zerotrees, illustrated by the boxes in with the magnitude of all its descendants are less than a particular coding threshold. Our coding method is similar to <ref> [15] </ref> in that we use four symbols POS (positive), NEG (negative), IZ (isolated zero) and ZT (zerotree). It is somewhat simpler because we are performing lossless coding; more specifically we do not use a subordinate pass. The general procedure is outlined below: 1.
Reference: [16] <author> D. Taubman and A. Zakhor, </author> <title> "Multirate 3-D Subband Coding of Video", </title> <journal> IEEE Trans. on Image Processing, </journal> <volume> vol. 3, </volume> <pages> pp. 572-588, </pages> <month> September </month> <year> 1994. </year>
Reference: [17] <author> R. Vargas. </author> <title> Fast Algorithms Using MSE for MPEG Motion Estimation, </title> <type> Masters dissertation, </type> <institution> U.C. Berkeley, </institution> <month> May </month> <year> 1996. </year>
Reference: [18] <author> M. Vetterli and J. Kovacevic, </author> <title> Wavelets and Subband Coding, </title> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference: [19] <author> J.Y.A. Wang and E.H. Adelson, </author> <title> "Representing Moving Images with Layers", </title> <journal> IEEE Trans. on Image Processing, </journal> <volume> vol. 3, no. 5, </volume> <pages> pp. 233-242, </pages> <month> September </month> <year> 1994. </year>
Reference: [20] <author> J. Yeh, M. Khansari, and M. Vetterli, </author> <title> "Motion Compensation of Motion Vectors", </title> <booktitle> Proc. of IEEE International Conference on Image Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 574-577, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: When more than one vector is located at (i; j), our algorithm chooses one at random. In <ref> [20] </ref>, MVF's were coded using this algorithm. This thesis goes one step further and estimates its performance in a full video coding system where the bitrate of both motion vectors and motion residual is considered.
References-found: 20

