URL: ftp://ftp.eecs.umich.edu/people/fessler/ps/99,tmi,fma.ps.Z
Refering-URL: http://www.eecs.umich.edu/~fessler/papers/jour.html
Root-URL: http://www.eecs.umich.edu
Email: email: erdogan@umich.edu,  
Title: Fast Monotonic Algorithms for Transmission Tomography  
Author: Hakan Erdogan and Jeffrey A. Fessler 
Address: 4415 EECS Bldg., 1301 Beal Ave. Ann Arbor, MI 48109-2122  
Affiliation: Department of EECS, University of Michigan  
Date: February 10, 1999 1  764 8041  
Note: IEEE TRANSACTIONS ON MEDICAL IMAGING, SUBMITTED  Voice:(734) 647 8390, FAX:(734)  
Abstract: We present a framework for designing fast and monotonic algorithms for transmission tomography penalized-likelihood image reconstruction. The new algorithms are based on paraboloidal surrogate functions for the log-likelihood. Due to the form of the log-likelihood function, it is possible to find low curvature surrogate functions that guarantee monotonicity. Unlike previous methods, the proposed surrogate functions lead to monotonic algorithms even for the nonconvex log- likelihood that arises due to background events such as scatter and random coincidences. The gradient and the curvature of the likelihood terms are evaluated only once per iteration. Since the problem is simplified at each iteration, the CPU time is less than that of current algorithms which directly minimize the objective, yet the convergence rate is comparable. The simplicity, monotonicity and speed of the new algorithms are quite attractive. The convergence rates of the algorithms are demonstrated using real and simulated PET transmission scans. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. C. Huang, E. J. Hoffman, M. E. Phelps, and D. E. Kuhl, </author> <title> "Quantitation in positron emission computed tomography: 2 Effects of inaccurate attenuation correction," </title> <journal> J. Comp. Assisted Tomo., </journal> <volume> vol. 3, no. 6, </volume> <pages> pp. 804-814, </pages> <month> December </month> <year> 1979. </year>
Reference: [2] <author> H. Erdogan and J. A. Fessler, </author> <title> "Statistical image reconstruction methods for simultaneous emission/transmission PET scans," </title> <booktitle> in Proc. IEEE Nuc. Sci. Symp. Med. Im. Conf., </booktitle> <volume> volume 3, </volume> <pages> pp. 1579-83, </pages> <year> 1996. </year>
Reference: [3] <author> E. U. Mumcuoglu, R. M. Leahy, and S. R. Cherry, </author> <title> "Bayesian reconstruction of PET images: methodology and performance analysis," </title> <journal> Phys. Med. Biol., </journal> <volume> vol. 41, no. 9, </volume> <pages> pp. 1777-1807, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: In PET, we estimate the r i 's by smoothing the delayed coincidences from the transmission scan <ref> [3] </ref>. Alternatively, one can use time scaled delayed coincidences from a blank scan (which are less noisy due to longer scan times) as the r i factors [21] or use Bayesian estimation techniques to estimate r i 's from delayed coincidences [3,14].
Reference: [4] <author> J. A. Fessler, </author> <title> "Hybrid Poisson/polynomial objective functions for tomographic image reconstruction from transmission scans," </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> vol. 4, no. 10, </volume> <pages> pp. 1439-50, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: The projection space was 160 radial bins and 192 angles, and the reconstructed images were 128 fi 128 with 4.5 mm pixels. The system matrix fa ij g was computed by using 6 mm wide strip integrals with 3 mm spacing, which roughly approximates the system geometry <ref> [4] </ref>. 7 When l n i is nonzero but small, due to numerical precision, (26) might turn out to be extremely large during computation.
Reference: [5] <author> A. P. Dempster, N. M. Laird, and D. B. Rubin, </author> <title> "Maximum likelihood from incomplete data via the EM algorithm," </title> <journal> J. Royal Stat. Soc. Ser. B, </journal> <volume> vol. 39, no. 1, </volume> <pages> pp. 1-38, </pages> <year> 1977. </year> <journal> IEEE TRANSACTIONS ON MEDICAL IMAGING, </journal> <note> SUBMITTED February 10, 1999 16 </note>
Reference-contexts: The "surrogate" or "substitute" function idea is not new to the tomographic reconstruction area. EM algorithms can be viewed as providing a surrogate function for the log-likelihood function by means of a statistically more informative "complete" data set which is unobservable <ref> [5] </ref>. The conditional expectation of the log-likelihood function for this new space is often easier to maximize, having a closed form for the emission case. This statistical construction of surrogate functions is somewhat indirect and seems to yield a limited selection of choices. <p> inequality at each iteration: h i (l) q i (l; l n 3 We use the notation OE (; n ) to emphasize that the surrogate is a function of once n is fixed and it changes for each n , following the Q function notation of the EM algorithm <ref> [5] </ref>. 4 The second condition follows from the other two conditions.
Reference: [6] <author> K. Lange and R. Carson, </author> <title> "EM reconstruction algorithms for emission and transmission tomography," </title> <journal> J. Comp. Assisted Tomo., </journal> <volume> vol. 8, no. 2, </volume> <pages> pp. 306-316, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: De Pierro has developed surrogate functions for nonnegative least squares problems based solely on convexity arguments, rather than statistics [15]. Our proposed approach is similar in spirit. The EM algorithm did not result in a closed form M-step for the transmission case <ref> [6] </ref>, so direct minimization of the objective function became more attractive. Cyclic Newtonian coordinate descent [11] has been used effectively in transmission tomography. However, coordinate descent based on Newton's iteration for each pixel is not guaranteed to be monotonic. <p> II. The Problem The measurements in a photon-limited application such as PET or SPECT are modeled appropriately as Poisson random variables. In transmission tomography, the means of the prompt coincidences are related exponentially to the projections (or line integrals) of the attenuation map through Beer's Law <ref> [6] </ref>. In addition, the measurements are contaminated by extra "background" counts due mostly to random coincidences and scatter in PET and emission crosstalk in SPECT. <p> The EM algorithm <ref> [6] </ref> provides a statistical method for constructing surrogate functions OE (; n ) satisfying the above conditions. However, in the transmission tomography problem, the EM surrogate is difficult to minimize and leads to slow convergence. In this paper, we construct a simpler surrogate using ordinary calculus rather than statistical techniques.
Reference: [7] <author> J. M. Ollinger, </author> <title> "Maximum likelihood reconstruction of transmission images in emission computed tomography via the EM algorithm," </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 13, no. 1, </volume> <pages> pp. 89-101, </pages> <month> March </month> <year> 1994. </year>
Reference: [8] <author> J. T. Kent and C. Wright, </author> <title> "Some suggestions for transmission tomography based on the EM algorithm," in Stochastic Models, Statistical Methods, and Algorithms in Im. Analysis, </title> <editor> M. P. P Barone, A Frigessi, editor, </editor> <booktitle> volume 74 of Lecture Notes in Statistics, </booktitle> <pages> pp. 219-232, </pages> <publisher> Springer, </publisher> <address> New York, </address> <year> 1992. </year>
Reference: [9] <author> J. A. Browne and T. J. Holmes, </author> <title> "Developments with maximum likelihood X-ray computed tomography," </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 12, no. 2, </volume> <pages> pp. 40-52, </pages> <month> March </month> <year> 1992. </year>
Reference: [10] <author> C. A. Bouman and K. Sauer, </author> <title> "A unified approach to statistical tomography using coordinate descent optimization," </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> vol. 5, no. 3, </volume> <pages> pp. 480-92, </pages> <month> March </month> <year> 1996. </year>
Reference: [11] <author> K. Sauer and C. Bouman, </author> <title> "A local update strategy for iterative reconstruction from projections," </title> <journal> IEEE Tr. Sig. Proc., </journal> <volume> vol. 41, no. 2, </volume> <pages> pp. 534-548, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Our proposed approach is similar in spirit. The EM algorithm did not result in a closed form M-step for the transmission case [6], so direct minimization of the objective function became more attractive. Cyclic Newtonian coordinate descent <ref> [11] </ref> has been used effectively in transmission tomography. However, coordinate descent based on Newton's iteration for each pixel is not guaranteed to be monotonic. <p> The convergence rates per iteration decrease due to the higher curvature of these surrogate functions, but these algorithms require less computation per iteration as compared to single coordinate descent <ref> [11] </ref> and are parallelizable. Furthermore, it is trivial to impose the nonnegativity constraint with an additively separable surrogate function [12]. In this paper, we propose to use a global surrogate function for the original objective function. This global surrogate function is not separable, but has a simple quadratic form. <p> Nevertheless, unlike with (26) monotonicity is not guaranteed with (27). The PS method with the curvature (27) yields faster convergence than the other PS algorithms presented above. This method is related to the PWLS image reconstruction method <ref> [11, 27] </ref>, but instead of making a one-time quadratic approximation to the log-likelihood function, the approximation is renewed at each iteration. Although the curvature of the paraboloid remains same, the gradient is changed to match the gradient of the original objective function at the current iterate. <p> The types are:"M", "O" and "P" for maximum second derivative curvature (13), optimum curvature (26) and precomputed curvature (27) respectively. The other algorithms we used for comparison in this section are as follows. LBFGS: a constrained Quasi-Newton algorithm [31], CD: coordinate descent with precomputed denominators <ref> [11, 12] </ref> applied to objective function, GD: grouped descent with precomputed denominators [12]. Fig. 4 shows images reconstructed by FBP and statistical methods from a 12 minute scan. For comparison, an FBP reconstruction of a 7 hour scan is also shown.
Reference: [12] <author> J. A. Fessler, E. P. Ficaro, N. H. Clinthorne, and K. Lange, </author> <title> "Grouped-coordinate ascent algorithms for penalized-likelihood transmission image reconstruction," </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 16, no. 2, </volume> <pages> pp. 166-75, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: Examples of these types of algorithms are the convex algorithm of [19] which updates all pixels simultaneously and the grouped coordinate ascent (GCA) algorithm of <ref> [12, 16] </ref> which updates a subset of pixels at a time. The surrogate functions used in these algorithms were obtained using De Pierro's convexity trick [18] to form a separable function that is easier to minimize than the non-separable original objective function. <p> The convergence rates per iteration decrease due to the higher curvature of these surrogate functions, but these algorithms require less computation per iteration as compared to single coordinate descent [11] and are parallelizable. Furthermore, it is trivial to impose the nonnegativity constraint with an additively separable surrogate function <ref> [12] </ref>. In this paper, we propose to use a global surrogate function for the original objective function. This global surrogate function is not separable, but has a simple quadratic form. <p> Whereas Huber considered strictly convex cost functions, we extend the method to derive provably monotonic algorithms even for nonconvex log-likelihood functions. Remarkably, these algorithms require less CPU time to converge than the fastest algorithm introduced before (GCA of <ref> [12] </ref>) and as an additional advantage, they are proven to be monotonic. We call the new approach to image reconstruction the "Paraboloidal Surrogates" (PS) method. <p> These curvatures c i in (27) are close approximations to the second derivative of h i functions at the projection values A^ where ^ is the solution to the penalized-likelihood problem <ref> [12] </ref>. This is called the "fast denominator" approach in [12], since it features a one-time precomputed approximation to the curvature that is left unchanged during the iterations so that the denominator terms d n j (20) can be computed prior to iteration (similar to "maximum curvature" in equation (13)). <p> These curvatures c i in (27) are close approximations to the second derivative of h i functions at the projection values A^ where ^ is the solution to the penalized-likelihood problem <ref> [12] </ref>. This is called the "fast denominator" approach in [12], since it features a one-time precomputed approximation to the curvature that is left unchanged during the iterations so that the denominator terms d n j (20) can be computed prior to iteration (similar to "maximum curvature" in equation (13)). <p> The types are:"M", "O" and "P" for maximum second derivative curvature (13), optimum curvature (26) and precomputed curvature (27) respectively. The other algorithms we used for comparison in this section are as follows. LBFGS: a constrained Quasi-Newton algorithm [31], CD: coordinate descent with precomputed denominators <ref> [11, 12] </ref> applied to objective function, GD: grouped descent with precomputed denominators [12]. Fig. 4 shows images reconstructed by FBP and statistical methods from a 12 minute scan. For comparison, an FBP reconstruction of a 7 hour scan is also shown. <p> The other algorithms we used for comparison in this section are as follows. LBFGS: a constrained Quasi-Newton algorithm [31], CD: coordinate descent with precomputed denominators [11, 12] applied to objective function, GD: grouped descent with precomputed denominators <ref> [12] </ref>. Fig. 4 shows images reconstructed by FBP and statistical methods from a 12 minute scan. For comparison, an FBP reconstruction of a 7 hour scan is also shown. Qualitatively, the statistical reconstruction looks better than the FBP image, having less noise and more uniform homogeneous regions. <p> More importantly, in Fig. 6 the PSCD algorithms are seen to be much faster than coordinate descent in terms of the actual CPU time 9 . One of the main overhead costs in coordinate descent is the computation of the log-likelihood gradient term after each pixel change <ref> [12] </ref>. In PSCD algorithm, the gradient of the surrogate function ( _q i 's) can be computed (updated) by a single multiplication (18). <p> This shows that the algorithms such as PSCD which are tailored to our specific problem converge faster than the general purpose Quasi-Newton method. In Fig. 7, we consider the fastest previous algorithm we know of (i.e. GD with 3 fi 3 groups with fast denominator <ref> [12] </ref>) and compare it to the fastest PS algorithms. The PSCD with "precomputed curvatures" (PS,P,CD) (introduced in Section 3-F) requires slightly less CPU time than GD to converge. Although the PS,P,CD algorithm 9 All CPU times are recorded on a DEC 600 5-333 MHz workstation with compiler optimization enabled. <p> Since the curvatures are smaller, this method decreases the objective very rapidly, nevertheless it is not guaranteed to be monotonic. However, as with the CD and GD with precomputed denominators <ref> [12] </ref>, we have never observed any nonmonotonicity in practical applications. The FSCD and CD algorithms consume a lot of CPU cycles per iteration and they are much slower than the proposed algorithms. <p> Such use should increase the emission image quality as compared to conventional methods which use linear processing and FBP for reconstruction. Further "acceleration" is possible by ordered subsets [34], albeit without guaranteed monotonicity. It is possible to parallelize the PS algorithms by applying either grouped descent (GD) <ref> [12, 13] </ref> algorithm to the surrogate function, or by parallelizing the projection and backprojection operators [35] for each pixel. However, in a serial computer we found that PS method with GD update (PSGD) was not faster than the PSCD algorithm.
Reference: [13] <author> K. D. Sauer, S. Borman, and C. A. Bouman, </author> <title> "Parallel computation of sequential pixel updates in statistical tomographic reconstruction," </title> <booktitle> in Proc. IEEE Intl. Conf. on Image Processing, </booktitle> <volume> volume 3, </volume> <pages> pp. 93-6, </pages> <year> 1995. </year>
Reference-contexts: Such use should increase the emission image quality as compared to conventional methods which use linear processing and FBP for reconstruction. Further "acceleration" is possible by ordered subsets [34], albeit without guaranteed monotonicity. It is possible to parallelize the PS algorithms by applying either grouped descent (GD) <ref> [12, 13] </ref> algorithm to the surrogate function, or by parallelizing the projection and backprojection operators [35] for each pixel. However, in a serial computer we found that PS method with GD update (PSGD) was not faster than the PSCD algorithm.
Reference: [14] <author> E. U. Mumcuoglu, R. Leahy, S. R. Cherry, and Z. Zhou, </author> <title> "Fast gradient-based methods for Bayesian reconstruction of transmission and emission PET images," </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 13, no. 3, </volume> <pages> pp. 687-701, </pages> <month> December </month> <year> 1994. </year>
Reference: [15] <author> A. R. De Pierro, </author> <title> "On the relation between the ISRA and the EM algorithm for positron emission tomography," </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 12, no. 2, </volume> <pages> pp. 328-333, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: This statistical construction of surrogate functions is somewhat indirect and seems to yield a limited selection of choices. De Pierro has developed surrogate functions for nonnegative least squares problems based solely on convexity arguments, rather than statistics <ref> [15] </ref>. Our proposed approach is similar in spirit. The EM algorithm did not result in a closed form M-step for the transmission case [6], so direct minimization of the objective function became more attractive. Cyclic Newtonian coordinate descent [11] has been used effectively in transmission tomography. <p> III. Paraboloidal Surrogates Algorithms The penalized-likelihood objective function () has a complex form that precludes analytical minimization. Thus, iterative methods are necessary for minimizing (). Our approach uses the optimization transfer idea proposed by De Pierro <ref> [15, 18] </ref>, summarized as follows. Let n be the attenuation map estimate after the nth iteration. We would like to find a "surrogate" function 3 OE (; n ) which is easier to minimize or to monotonically decrease than ().
Reference: [16] <author> J. Zheng, S. Saquib, K. Sauer, and C. Bouman, </author> <title> "Functional substitution methods in optimization for Bayesian tomography," </title> <journal> IEEE Tr. Im. Proc., </journal> <month> March </month> <year> 1997. </year> <note> Submitted to IEEE Tr. Image Proc. </note>
Reference-contexts: These exponentiations and floating point operations constitute a significant fraction of the CPU time per iteration. Recently, Zheng et al. introduced a "functional substitution" (FS) method <ref> [16, 17] </ref> which is proven to be monotonic for transmission scans with no background counts (r i = 0 in (1) below). Like coordinate descent, FS algorithm cyclically updates the coordinates of the image vector, i.e. the attenuation map values for each pixel. <p> The minimization of the surrogate is guaranteed to monotonically decrease the original objective function if the derivative of the negative log-likelihood is concave (which is true when r i = 0) <ref> [16, 17] </ref>. On the other hand, the FS algorithm requires at least 2M exponentiations and 17M floating point operations per iteration, which means that the guarantee of monotonicity comes at a price of significantly increased computation time per iteration for that method. <p> Examples of these types of algorithms are the convex algorithm of [19] which updates all pixels simultaneously and the grouped coordinate ascent (GCA) algorithm of <ref> [12, 16] </ref> which updates a subset of pixels at a time. The surrogate functions used in these algorithms were obtained using De Pierro's convexity trick [18] to form a separable function that is easier to minimize than the non-separable original objective function. <p> In Fig. 8, we present the results of a transmission scan simulation with zero background counts (r i = 0) and compare the monotonic PSCD algorithm with the functional substitution (FS) method of Zheng et al. <ref> [16, 17] </ref>. The FS algorithm is proven to be monotonic when r i = 0 in which case h i is convex. However, the FSCD method requires considerably more computation per iteration than both CD and PSCD. The plot shows that FSCD requires more CPU time than PSCD.
Reference: [17] <author> S. Saquib, J. Zheng, C. A. Bouman, and K. D. Sauer, </author> <title> "Provably convergent coordinate descent in statistical tomographic reconstruction," </title> <booktitle> in Proc. IEEE Intl. Conf. on Image Processing, </booktitle> <volume> volume 2, </volume> <pages> pp. 741-4, </pages> <year> 1996. </year>
Reference-contexts: These exponentiations and floating point operations constitute a significant fraction of the CPU time per iteration. Recently, Zheng et al. introduced a "functional substitution" (FS) method <ref> [16, 17] </ref> which is proven to be monotonic for transmission scans with no background counts (r i = 0 in (1) below). Like coordinate descent, FS algorithm cyclically updates the coordinates of the image vector, i.e. the attenuation map values for each pixel. <p> The minimization of the surrogate is guaranteed to monotonically decrease the original objective function if the derivative of the negative log-likelihood is concave (which is true when r i = 0) <ref> [16, 17] </ref>. On the other hand, the FS algorithm requires at least 2M exponentiations and 17M floating point operations per iteration, which means that the guarantee of monotonicity comes at a price of significantly increased computation time per iteration for that method. <p> In Fig. 8, we present the results of a transmission scan simulation with zero background counts (r i = 0) and compare the monotonic PSCD algorithm with the functional substitution (FS) method of Zheng et al. <ref> [16, 17] </ref>. The FS algorithm is proven to be monotonic when r i = 0 in which case h i is convex. However, the FSCD method requires considerably more computation per iteration than both CD and PSCD. The plot shows that FSCD requires more CPU time than PSCD.
Reference: [18] <author> A. R. De Pierro, </author> <title> "A modified expectation maximization algorithm for penalized likelihood estimation in emission tomography," </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 14, no. 1, </volume> <pages> pp. 132-137, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Furthermore, the FS algorithm is not monotonic in the nonconvex case of interest in PET and SPECT, where r i 6= 0. De Pierro <ref> [18] </ref> has used a surrogate function for the penalty part of the penalized-likelihood problem for convex penalties. The surrogate function idea was also used in several algorithms which update a group of pixel values at a time instead of sequential update of each pixel. <p> The surrogate functions used in these algorithms were obtained using De Pierro's convexity trick <ref> [18] </ref> to form a separable function that is easier to minimize than the non-separable original objective function. The convergence rates per iteration decrease due to the higher curvature of these surrogate functions, but these algorithms require less computation per iteration as compared to single coordinate descent [11] and are parallelizable. <p> We consider roughness penalties R () that can be expressed in the following very general form <ref> [18, 23] </ref>: R () = k=1 2 The assumption that the background counts r i are known nonnegative constants is an approximation. In PET, we estimate the r i 's by smoothing the delayed coincidences from the transmission scan [3]. <p> III. Paraboloidal Surrogates Algorithms The penalized-likelihood objective function () has a complex form that precludes analytical minimization. Thus, iterative methods are necessary for minimizing (). Our approach uses the optimization transfer idea proposed by De Pierro <ref> [15, 18] </ref>, summarized as follows. Let n be the attenuation map estimate after the nth iteration. We would like to find a "surrogate" function 3 OE (; n ) which is easier to minimize or to monotonically decrease than ().
Reference: [19] <author> K. Lange and J. A. Fessler, </author> <title> "Globally convergent algorithms for maximum a posteriori transmission tomography," </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> vol. 4, no. 10, </volume> <pages> pp. 1430-8, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: The surrogate function idea was also used in several algorithms which update a group of pixel values at a time instead of sequential update of each pixel. Examples of these types of algorithms are the convex algorithm of <ref> [19] </ref> which updates all pixels simultaneously and the grouped coordinate ascent (GCA) algorithm of [12, 16] which updates a subset of pixels at a time.
Reference: [20] <author> P. J. Huber, </author> <title> Robust statistics, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: This global surrogate function is not separable, but has a simple quadratic form. The method is based on finding 1-D parabolic functions that are tangent to and lie above each of the terms in the log-likelihood, similar to Huber's method for robust linear regression <ref> [20] </ref>. Whereas Huber considered strictly convex cost functions, we extend the method to derive provably monotonic algorithms even for nonconvex log-likelihood functions. <p> IEEE TRANSACTIONS ON MEDICAL IMAGING, SUBMITTED February 10, 1999 7 In the context of robust regression, Huber showed (Lemma 8.3 on page 184 in <ref> [20] </ref>, also [23]) that for potential functions k that satisfy the conditions above, we can find a parabola ^ k (t) that lies above k (t); 8t 2 IR.
Reference: [21] <author> M. Yavuz and J. A. Fessler, </author> <title> "New statistical models for randoms-precorrected PET scans," in Information Processing in Medical Im., </title> <editor> J. Duncan and G. Gindi, editors, </editor> <booktitle> volume 1230 of Lecture Notes in Computer Science, </booktitle> <pages> pp. 190-203, </pages> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1997. </year>
Reference-contexts: In PET, we estimate the r i 's by smoothing the delayed coincidences from the transmission scan [3]. Alternatively, one can use time scaled delayed coincidences from a blank scan (which are less noisy due to longer scan times) as the r i factors <ref> [21] </ref> or use Bayesian estimation techniques to estimate r i 's from delayed coincidences [3,14]. In our experience, the small errors in estimating r i 's do not affect the reconstructions much since the main error source is due to the Poisson nature of the prompt coincidences. <p> The phantom used was an anthropomorphic thorax phantom (Data Spectrum, Chapel Hill, NC). Delayed coincidence sinograms were collected separately in each scan. The blank and transmission scan delayed-coincidence sinograms were shown to be numerically close <ref> [21] </ref> 8 , so we used a time-scaled version of blank scan delayed coincidences as the r i factors with no other processing. The projection space was 160 radial bins and 192 angles, and the reconstructed images were 128 fi 128 with 4.5 mm pixels.
Reference: [22] <author> S. R. Meikle, M. Dahlbom, S. R. Cherry, and A. Chatziioannou, </author> <title> "Attenuation correction in whole body PET," </title> <journal> J. Nuc. Med. (Abs. Book), </journal> <volume> vol. 33, no. 5, </volume> <pages> pp. 862, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: However, it is well known that the attenuation map in the body consists of approximately locally homogeneous regions. This property has formed the basis of many segmentation methods for transmission scans <ref> [22] </ref>.
Reference: [23] <author> J. A. Fessler, </author> <title> "Grouped coordinate descent algorithms for robust edge-preserving image restoration," </title> <booktitle> in Proc. SPIE 3071, Im. Recon. and Restor. II, </booktitle> <pages> pp. 184-94, </pages> <year> 1997. </year>
Reference-contexts: We consider roughness penalties R () that can be expressed in the following very general form <ref> [18, 23] </ref>: R () = k=1 2 The assumption that the background counts r i are known nonnegative constants is an approximation. In PET, we estimate the r i 's by smoothing the delayed coincidences from the transmission scan [3]. <p> The functions k we consider are convex, symmetric, nonnegative, differentiable and satisfy some more conditions that are listed in Section 3-C. The fi in equation (4) is a parameter which controls the level of smoothness in the final reconstructed image. For more explanation of the penalty function, see <ref> [23] </ref>. The objective function defined in (4) is not convex when there are nonzero background counts (r i 6= 0) in the data. In this realistic case, there is no guarantee that there is a single global minimum. <p> IEEE TRANSACTIONS ON MEDICAL IMAGING, SUBMITTED February 10, 1999 7 In the context of robust regression, Huber showed (Lemma 8.3 on page 184 in [20], also <ref> [23] </ref>) that for potential functions k that satisfy the conditions above, we can find a parabola ^ k (t) that lies above k (t); 8t 2 IR.
Reference: [24] <author> P. G. Ciarlet, </author> <title> Introduction to numerical linear algebra and optimisation, </title> <address> Cambridge, Cambridge, </address> <year> 1982. </year>
Reference-contexts: A. Maximum Curvature A natural choice for c i (l n i ) is the maximum second derivative in the feasible region for the projections. This "maximum curvature" ensures that (9) holds, which follows from the generalized mean value theorem for twice differentiable functions (page 228, <ref> [24] </ref>). The feasible region for the projections is [0; 1) due to the nonnegativity constraint. Hence, the choice c i (l n l2 [0;1) is guaranteed to satisfy (9).
Reference: [25] <author> J. A. Fessler and A. O. Hero, </author> <title> "Penalized maximum-likelihood image reconstruction using space-alternating generalized EM algorithms," </title> <journal> IEEE Tr. Im. Proc., </journal> <volume> vol. 4, no. 10, </volume> <pages> pp. 1417-29, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: Convergence and Convergence Rate In the absence of background events, i.e. when r i = 0, the penalized-likelihood objective is convex and our proposed PSCD algorithm is globally convergent. This is a fairly straightforward consequence of the proof in <ref> [25] </ref> for convergence of SAGE, so we omit the details. However when r i 6= 0, little can be said about global convergence due to the possibility that there are multiple minima or a continuous region of minima.
Reference: [26] <author> J. A. Fessler, N. H. Clinthorne, and W. L. Rogers, </author> <title> "On complete data spaces for PET reconstruction algorithms," </title> <journal> IEEE Tr. Nuc. Sci., </journal> <volume> vol. 40, no. 4, </volume> <pages> pp. 1055-61, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: We use the results from <ref> [26] </ref> to evaluate the convergence rate. Let N (c 1 ) and N (c 2 ) be two matrices corresponding to curvature vectors c 1 and c 2 respectively with c 1 i &lt; c 2 i ; 8i. <p> Then obviously N (c 2 ) N (c 1 ) is positive definite and it follows from Lemma 1 in <ref> [26] </ref> that the algorithm corresponding to c 1 has a lower root-convergence factor and thus converges faster than the algorithm corresponding to c 2 .
Reference: [27] <author> J. A. Fessler, </author> <title> "Penalized weighted least-squares image reconstruction for positron emission tomography," </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 13, no. 2, </volume> <pages> pp. 290-300, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Nevertheless, unlike with (26) monotonicity is not guaranteed with (27). The PS method with the curvature (27) yields faster convergence than the other PS algorithms presented above. This method is related to the PWLS image reconstruction method <ref> [11, 27] </ref>, but instead of making a one-time quadratic approximation to the log-likelihood function, the approximation is renewed at each iteration. Although the curvature of the paraboloid remains same, the gradient is changed to match the gradient of the original objective function at the current iterate.
Reference: [28] <author> K. Wienhard, L. Eriksson, S. Grootoonk, M. Casey, U. Pietrzyk, and W. D. Heiss, </author> <title> "Performance evaluation of a new generation positron scanner ECAT EXACT," </title> <journal> J. Comp. Assisted Tomo., </journal> <volume> vol. 16, no. 5, </volume> <pages> pp. 804-813, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: We acquired a 15-hour blank scan (b i 's) and a 12-min transmission scan data (y i 's) using a Siemens/CTI ECAT EXACT 921 PET scanner with rotating rod transmission sources <ref> [28] </ref>. The phantom used was an anthropomorphic thorax phantom (Data Spectrum, Chapel Hill, NC). Delayed coincidence sinograms were collected separately in each scan.
Reference: [29] <author> J. A. Fessler and W. L. Rogers, </author> <title> "Spatial resolution properties of penalized-likelihood image reconstruction methods: </title> <journal> Space-invariant tomo-graphs," IEEE Tr. Im. Proc., </journal> <volume> vol. 5, no. 9, </volume> <pages> pp. 1346-58, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: Here w jk is normally equal to 1 for horizontal and vertical neighbors and 1= p for diagonal neighbors. We used the modified w jk 's described in <ref> [29] </ref> to achieve more uniform resolution.
Reference: [30] <author> K. Lange, </author> <title> "Convergence of EM image reconstruction algorithms with Gibbs smoothing," </title> <journal> IEEE Tr. Med. Im., </journal> <volume> vol. 9, no. 4, </volume> <pages> pp. 439-446, </pages> <month> December </month> <year> 1990. </year> <title> Corrections, </title> <month> June </month> <year> 1991. </year>
Reference-contexts: We used the modified w jk 's described in [29] to achieve more uniform resolution. For the potential function, we used one of the edge-preserving nonquadratic cost functions that was introduced in <ref> [30] </ref> (x) = ffi 2 [jx=ffij log (1 + jx=ffij)] : This function acts like a quadratic penalty for small differences in neighboring pixels and is close to absolute value function for differences greater than ffi. This nonquadratic function penalizes sharp edges less than quadratic functions.
Reference: [31] <author> C. Zhu, R. H. Byrd, P. Lu, and J. Nocedal, </author> <title> "Algorithm 778: L-BFGS-B: Fortran subroutines fo r large-scale bound-constrained optimization," </title> <journal> ACM Tr. Math. Software, </journal> <volume> vol. 23, no. 4, </volume> <pages> pp. 550-60, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: The types are:"M", "O" and "P" for maximum second derivative curvature (13), optimum curvature (26) and precomputed curvature (27) respectively. The other algorithms we used for comparison in this section are as follows. LBFGS: a constrained Quasi-Newton algorithm <ref> [31] </ref>, CD: coordinate descent with precomputed denominators [11, 12] applied to objective function, GD: grouped descent with precomputed denominators [12]. Fig. 4 shows images reconstructed by FBP and statistical methods from a 12 minute scan. For comparison, an FBP reconstruction of a 7 hour scan is also shown. <p> However, these c i (l n i )'s are much larger than the optimal curvatures, so more iterations are required for PS,M,CD than PS,O,CD to converge. We also compared the PSCD algorithms to the general purpose constrained Quasi-Newton algorithm (LBFGS) <ref> [31] </ref> in Figures 5 and 6. Although the LBFGS algorithm takes about 25% less CPU time (0.88 seconds) per iteration than PSCD algorithms, it did not converge as fast as the proposed algorithms.
Reference: [32] <author> J. A. Fessler and A. O. Hero, </author> <title> "Space-alternating generalized expectation-maximization algorithm," </title> <journal> IEEE Tr. Sig. Proc., </journal> <volume> vol. 42, no. 10, </volume> <pages> pp. 2664-77, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Practical experience suggests there are rarely multiple minima in this problem, but there is no proof. In the strictly convex case, the proposed algorithms are guaranteed to converge to the global minimum by a proof similar to that in <ref> [32] </ref>. The algorithms we introduced are simple, easy to understand, fast and monotonic. The simplicity in part is due to the additive form of (2), which is a direct consequence of independent measurements.
Reference: [33] <author> J. A. Fessler and H. Erdogan, </author> <title> "Paraboloidal surrogates algorithm for convergent penalized-likelihood emission image reconstruction," </title> <booktitle> in Proc. IEEE Nuc. Sci. Symp. Med. Im. Conf., </booktitle> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: Since the emission tomography log-likelihood has a very similar form due to independence of measurements, it is possible to apply the paraboloidal surrogates idea to the emission case as well to get faster algorithms <ref> [33] </ref>. Convergence is very important for algorithms for any optimization problem, particularly in medical applications. The PSCD algorithm is globally convergent when there are no background counts. Even when there are background counts, the new algorithm is guaranteed to monotonically decrease the objective function making the algorithm stable.
Reference: [34] <author> H. Erdogan, G. Gualtieri, and J. A. Fessler, </author> <title> "An ordered subsets algorithm for transmission tomography," </title> <booktitle> in Proc. IEEE Nuc. Sci. Symp. Med. Im. Conf., </booktitle> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: Such use should increase the emission image quality as compared to conventional methods which use linear processing and FBP for reconstruction. Further "acceleration" is possible by ordered subsets <ref> [34] </ref>, albeit without guaranteed monotonicity. It is possible to parallelize the PS algorithms by applying either grouped descent (GD) [12, 13] algorithm to the surrogate function, or by parallelizing the projection and backprojection operators [35] for each pixel.

References-found: 34

