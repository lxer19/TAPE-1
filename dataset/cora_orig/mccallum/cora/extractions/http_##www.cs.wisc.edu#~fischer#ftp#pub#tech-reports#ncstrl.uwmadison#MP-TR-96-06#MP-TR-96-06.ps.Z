URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/MP-TR-96-06/MP-TR-96-06.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/MP-TR-96-06/
Root-URL: http://www.cs.wisc.edu
Title: EXACT PENALTY FUNCTIONS FOR MATHEMATICAL PROGRAMS WITH LINEAR COMPLEMENTARITY CONSTRAINTS  
Author: O.L. MANGASARIAN AND J.S. PANG 
Keyword: Key words. Mathematical programs with complementarity constraints, exact penalty function, opti mality conditions  
Note: AMS subject classifications. 90C30, 90C33  
Abstract: We establish a new general exact penalty function result for a constrained optimization problem and apply this result to a mathematical program with linear complementarity constraints. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Anandalingam and D.J. White, </author> <title> "A solution method for the linear static Stackelberg problem using penalty function," </title> <note> IEEE Transactions on Automatic Control 35 (1990) 1170-1173. 6 O.L. Mangasarian and J.S. Pang </note>
Reference-contexts: The new exact penalty results generalize previous ones for bilevel linear programs obtained in <ref> [1, 2] </ref> and complement those for mathematical programs with affine equilibrium constraints (MPAECs) in [5, 4]. The cornerstone of our new results is an improved exact penalty result for a constrained optimization problem that attains its minima at a certain finite set of points. <p> In [4], there is no assumption of f but the feasible region is compact. We refer the reader to the cited monograph which discusses how the exact penalty results therein generalize those existing in the literature, in particular, those in <ref> [1, 2] </ref>. The papers [3, 6, 7] discuss the application of the class of linear programs with linear complementarity constraints to several important problems in machine learning. The exact penalty function formulation in Proposition 3.2 is obtained in the latter references.
Reference: [2] <author> Z. Bi, P. Calamai, and A. Conn, </author> <title> "An exact penalty function approach for the linear bilevel programming problem," </title> <type> Technical Report #167-0-310789, </type> <institution> Department of Systems Design and Engineering, University of Waterloo, Waterloo (1989). </institution>
Reference-contexts: The new exact penalty results generalize previous ones for bilevel linear programs obtained in <ref> [1, 2] </ref> and complement those for mathematical programs with affine equilibrium constraints (MPAECs) in [5, 4]. The cornerstone of our new results is an improved exact penalty result for a constrained optimization problem that attains its minima at a certain finite set of points. <p> In [4], there is no assumption of f but the feasible region is compact. We refer the reader to the cited monograph which discusses how the exact penalty results therein generalize those existing in the literature, in particular, those in <ref> [1, 2] </ref>. The papers [3, 6, 7] discuss the application of the class of linear programs with linear complementarity constraints to several important problems in machine learning. The exact penalty function formulation in Proposition 3.2 is obtained in the latter references.
Reference: [3] <author> P.S. Bradley, O.L. Mangasarian, and W.N. </author> <title> Street, "Feature selection via mathematical programming", </title> <type> Mathematical Programming Technical Report 95-21, </type> <institution> Department of Computer Science, University of Wisconsin, </institution> <note> Madison (December 1995). </note>
Reference-contexts: Its extension with free variables z and associated equations defined by (x; y; z) corresponds to the general MPAEC. Recently, several important problems in machine learning have been formulated as the problem (1) with a linear objective function f <ref> [3, 6, 7] </ref>; the acronym LPEC (for Linear Program with Equilibrium Constraints) was coined for this subclass of (1). <p> In [4], there is no assumption of f but the feasible region is compact. We refer the reader to the cited monograph which discusses how the exact penalty results therein generalize those existing in the literature, in particular, those in [1, 2]. The papers <ref> [3, 6, 7] </ref> discuss the application of the class of linear programs with linear complementarity constraints to several important problems in machine learning. The exact penalty function formulation in Proposition 3.2 is obtained in the latter references. <p> The papers [3, 6, 7] discuss the application of the class of linear programs with linear complementarity constraints to several important problems in machine learning. The exact penalty function formulation in Proposition 3.2 is obtained in the latter references. In <ref> [8, 3] </ref>, successive linearization methods have been employed for solving these applied problems and found to be among the most effective methods for minimizing the penalty function ff on V fi T .
Reference: [4] <author> Z.Q. Luo, J.S Pang and D. Ralph, </author> <title> Mathematical Programs with Equilibrium Constraints, </title> <publisher> Cambridge University Press (1996). </publisher>
Reference-contexts: There has been a growing literature on this important mathematical programming problem which is central to many engineering design, economic equilibrium, multi-level game-theoretic and machine learning problems. The monograph <ref> [4] </ref> gives a comprehensive study of the MPEC and presents an extensive theory of exact penalty formulations and first- and second-order optimality conditions for this problem; some iterative algorithms for computing stationary points are also described therein. <p> The new exact penalty results generalize previous ones for bilevel linear programs obtained in [1, 2] and complement those for mathematical programs with affine equilibrium constraints (MPAECs) in <ref> [5, 4] </ref>. The cornerstone of our new results is an improved exact penalty result for a constrained optimization problem that attains its minima at a certain finite set of points. <p> We now compare the above exact penalty results with those in Subsection 2.4.1 in <ref> [4] </ref> for the same problem (1). The essential difference lies in the assumptions made. Here, we assume that the objective function f is concave but we do not assume anything about the feasible region. In [4], there is no assumption of f but the feasible region is compact. <p> We now compare the above exact penalty results with those in Subsection 2.4.1 in <ref> [4] </ref> for the same problem (1). The essential difference lies in the assumptions made. Here, we assume that the objective function f is concave but we do not assume anything about the feasible region. In [4], there is no assumption of f but the feasible region is compact. We refer the reader to the cited monograph which discusses how the exact penalty results therein generalize those existing in the literature, in particular, those in [1, 2].
Reference: [5] <author> Z.Q. Luo, J.S Pang D. Ralph, and S.Q. Wu, </author> <title> "Exact penalization and stationarity conditions for mathematical programs with equilibrium constraints", Mathematical Programming, </title> <publisher> forthcoming. </publisher>
Reference-contexts: The new exact penalty results generalize previous ones for bilevel linear programs obtained in [1, 2] and complement those for mathematical programs with affine equilibrium constraints (MPAECs) in <ref> [5, 4] </ref>. The cornerstone of our new results is an improved exact penalty result for a constrained optimization problem that attains its minima at a certain finite set of points.
Reference: [6] <author> O.L. Mangasarian, </author> <title> "Misclassification minimization", </title> <note> Journal of Global Optimization 5 (1994) 309-323. </note>
Reference-contexts: Its extension with free variables z and associated equations defined by (x; y; z) corresponds to the general MPAEC. Recently, several important problems in machine learning have been formulated as the problem (1) with a linear objective function f <ref> [3, 6, 7] </ref>; the acronym LPEC (for Linear Program with Equilibrium Constraints) was coined for this subclass of (1). <p> In [4], there is no assumption of f but the feasible region is compact. We refer the reader to the cited monograph which discusses how the exact penalty results therein generalize those existing in the literature, in particular, those in [1, 2]. The papers <ref> [3, 6, 7] </ref> discuss the application of the class of linear programs with linear complementarity constraints to several important problems in machine learning. The exact penalty function formulation in Proposition 3.2 is obtained in the latter references.
Reference: [7] <author> O.L. Mangasarian, </author> <title> "Mathematical programming in machine learning", in "Nonlinear Optimization and Applications", </title> <editor> G. Di Pillo and F. Giannessi, editors, </editor> <publisher> Plenum Publishing , New York (1996), </publisher> <pages> pp. 283-295. </pages>
Reference-contexts: Its extension with free variables z and associated equations defined by (x; y; z) corresponds to the general MPAEC. Recently, several important problems in machine learning have been formulated as the problem (1) with a linear objective function f <ref> [3, 6, 7] </ref>; the acronym LPEC (for Linear Program with Equilibrium Constraints) was coined for this subclass of (1). <p> In [4], there is no assumption of f but the feasible region is compact. We refer the reader to the cited monograph which discusses how the exact penalty results therein generalize those existing in the literature, in particular, those in [1, 2]. The papers <ref> [3, 6, 7] </ref> discuss the application of the class of linear programs with linear complementarity constraints to several important problems in machine learning. The exact penalty function formulation in Proposition 3.2 is obtained in the latter references.
Reference: [8] <author> O.L. Mangasarian, </author> <title> "Machine learning via polyhedral concave minimization", in "Applied Mathematics and Parallel Computing - Festschrift for Klaus Ritter", </title> <editor> H. Fischer and B. Riedmueller and S. Schae*er, editors, </editor> <publisher> Physica-Verlag A Springer-Verlag Company, </publisher> <address> Heidelberg (1996), </address> <pages> pp. 175-188. </pages>
Reference-contexts: The papers [3, 6, 7] discuss the application of the class of linear programs with linear complementarity constraints to several important problems in machine learning. The exact penalty function formulation in Proposition 3.2 is obtained in the latter references. In <ref> [8, 3] </ref>, successive linearization methods have been employed for solving these applied problems and found to be among the most effective methods for minimizing the penalty function ff on V fi T .
Reference: [9] <author> R.T. Rockafellar, </author> <title> Convex Analysis, </title> <publisher> Princeton University Press, </publisher> <address> Princeton (1970). </address>
Reference-contexts: Proof. Clearly, V is a polyhedral convex set containing no lines; moreover for all ff &gt; 0, the function ff is clearly concave. Hence by Corollary 32.3.4 in <ref> [9] </ref>, for each ff &gt; 0, the function ff attains its finite minimum at one of the finitely many extreme points of V .
References-found: 9

