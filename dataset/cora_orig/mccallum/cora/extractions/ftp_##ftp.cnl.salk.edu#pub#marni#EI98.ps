URL: ftp://ftp.cnl.salk.edu/pub/marni/EI98.ps
Refering-URL: http://www.cnl.salk.edu/~marni/
Root-URL: 
Title: Independent component representations for face recognition  
Author: Marian Stewart Bartlett a H. Martin Lades b and Terrence J. Sejnowski c 
Keyword: Independent component analysis, ICA, principal component analysis, PCA, face recognition.  
Address: La Jolla, CA 92037.  CA 94550.  La Jolla, CA 92037.  
Affiliation: a University of California San Diego and the Salk Institute,  b Lawrence Livermore National Laboratories, Livermore,  c University of California San Diego and Howard Hughes Medical Institute at the Salk Institute,  
Abstract: In a task such as face recognition, much of the important information may be contained in the high-order relationships among the image pixels. A number of face recognition algorithms employ principal component analysis (PCA), which is based on the second-order statistics of the image set, and does not address high-order statistical dependencies such as the relationships among three or more pixels. Independent component analysis (ICA) is a generalization of PCA which separates the high-order moments of the input in addition to the second-order moments. ICA was performed on a set of face images by an unsupervised learning algorithm derived from the principle of optimal information transfer through sigmoidal neurons. 1 The algorithm maximizes the mutual information between the input and the output, which produces statistically independent outputs under certain conditions. ICA was performed on the face images under two different architectures. The first architecture provided a statistically independent basis set for the face images that can be viewed as a set of independent facial features. The second architecture provided a factorial code, in which the probability of any combination of features can be obtained from the product of their individual probabilities. Both ICA representations were superior to representations based on principal components analysis for recognizing faces across sessions and changes in expression. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> A. Bell and T. Sejnowski, </author> <title> "An information maximization approach to blind separation and blind deconvolution," </title> <booktitle> Neural Computation 7, </booktitle> <pages> pp. 1129-1159, </pages> <year> 1995. </year>
Reference-contexts: Right: f y (y) is plotted for different values of the weight, w. The optimal weight, w opt transmits the most information. Figure from Bell & Sejnowski <ref> (1995) </ref>, reprinted with permission from Neural Computation. The optimal weight is found by gradient ascent on the entropy of the output, y with respect to w. When there are multiple inputs and outputs, maximizing the joint entropy of the output encourages the individual outputs to move towards statistical independence.
Reference: 2. <author> G. Cottrell and J. . Metcalfe, </author> <title> "Face, gender and emotion recognition using holons," </title> <booktitle> in Advances in Neural Information Processing Systems, </booktitle> <editor> D. Touretzky, ed., </editor> <volume> vol. 3, </volume> <pages> pp. 564-571, </pages> <publisher> Morgan Kaufman, </publisher> <address> (San Mateo, CA), </address> <year> 1991. </year>
Reference: 3. <author> M. Turk and A. Pentland, </author> <title> "Eigenfaces for recognition," </title> <journal> J. Cog. Neurosci. </journal> <volume> 3(1), </volume> <pages> pp. 71-86, </pages> <year> 1991. </year>
Reference: 4. <author> P. Penev and J. Atick, </author> <title> "Local feature analysis: a general statistical theory for object representation," Network: </title> <booktitle> Computation in Neural Systems 7(3), </booktitle> <pages> pp. 477-500, </pages> <year> 1996. </year>
Reference: 5. <author> H. O`Toole, Abdi, K. Deffenbacher, and D. Velantin, </author> <title> "Low-dimensional representation of faces in higher dimensions of the face space.," </title> <journal> Journal of the Optical Society of America A 10(3), </journal> <pages> pp. 405-411, </pages> <year> 1993. </year>
Reference: 6. <author> P. Comon, </author> <title> "Independent component analysis anew concept?," </title> <booktitle> Signal Processing 36, </booktitle> <pages> pp. 287-314, </pages> <year> 1994. </year>
Reference: 7. <author> S. Makeig, A. Bell, T.-P. Jung, and T. Sejnowski, </author> <title> "Independent component analysis of electroencephalographic data," </title> <booktitle> in Advances in Neural Information Processing Systems, </booktitle> <editor> D. Touretzky, M. Mozer, and M. Hasselmo, eds., </editor> <volume> vol. 8, </volume> <pages> pp. 145-151, </pages> <publisher> MIT Press, </publisher> <address> (Cambridge, MA), </address> <year> 1996. </year>
Reference: 8. <author> M. McKeown, S. Makeig, G. Brown, T.-P. Jung, S. Kindermann, A. Bell, and T. Sejnowski, </author> <title> "Analysis of fmri data by decomposition into independent components," </title> <booktitle> Proc. </booktitle> <institution> Nat. Acad. Sci. </institution> , <note> in press. </note>
Reference: 9. <author> A. Bell and T. Sejnowski, </author> <title> "The independent components of natural scenes are edge filters," </title> <booktitle> Vision Research 37(23), </booktitle> <pages> pp. 3327-3338, </pages> <year> 1997. </year>
Reference-contexts: Architecture 1 Architecture 2 basis images. Performing source separation on the face images produced independent component images in the rows of U . Right: Architecture for finding a factorial code. Performing source separation on the pixels produced a factorial code in the columns of the output matrix, U . <ref> (1997) </ref>. Each image in the dataset was considered to be a linear combination of underlying basis images, given by the matrix A. The basis images were each associated with a set of independent "causes", given by a vector of coefficients in S.
Reference: 10. <author> H. Barlow, </author> <title> "Unsupervised learning," </title> <booktitle> Neural Computation 1, </booktitle> <pages> pp. 295-311, </pages> <year> 1989. </year>
Reference: 11. <author> J. Atick, </author> <title> "Could information theory provide an ecological theory of sensory processing?," </title> <booktitle> Network 3, </booktitle> <pages> pp. </pages> <address> 213--251, </address> <year> 1992. </year>
Reference: 12. <author> P. Phillips, H. Wechsler, J. Juang, and P. Rauss, </author> <title> "The feret database and evaluation procedure for face-recognition algorithms," Image and Vision Computing Journal , in press. </title>
Reference: 13. <author> A. Pentland, B. Moghaddam, and T. Starner, </author> <title> "View-based and modular eigenspaces for face recognition," </title> <booktitle> in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <year> 1994. </year>
Reference: 14. <author> S. Laughlin, </author> <title> "A simple coding procedure enhances a neuron's information capacity," </title> <journal> Z. </journal> <volume> Naturforsch 36, </volume> <pages> pp. 910-912, </pages> <year> 1981. </year>
Reference: 15. <author> J.-P. Nadal and N. Parga, </author> <title> "Non-linear neurons in the low noise limit: a factorial code maximizes information transfer," </title> <booktitle> Network 5, </booktitle> <pages> pp. 565-581, </pages> <year> 1994. </year>
Reference: 16. <author> B. Olshausen and D. </author> <title> Field, "Natural image statistics and efficient coding," Network: </title> <booktitle> Computation in Neural Systems 7(2), </booktitle> <pages> pp. 333-340, </pages> <year> 1996. </year>
References-found: 16

