URL: ftp://ftp.cs.utah.edu/techreports/1996/CSTD-96-001.ps.Z
Refering-URL: ftp://ftp.cs.utah.edu/techreports/1996/index.html
Root-URL: 
Title: Processor Design  
Author: William F. Richardson 
Date: February 12, 1996  
Note: Self-Timed  
Address: Salt Lake City, UT 84112 USA  
Affiliation: Department of Computer Science University of Utah  
Pubnum: CSTD-96-001  
Abstract: Architectural Considerations in a There are fundamental differences in the structure of asynchronous and synchronous processors, and the problems of each approach require innovative solutions. This work explores some of the ways in which the structure of a specific design is affected by an asynchronous paradigm. The Fred architecture presented here is an example of such a design approach. The self-timed design philosophy directly results in a powerful and flexible architecture which exhibits significant savings in design effort and circuit complexity. Some of the architectural constraints discovered in the course of the research have simple yet unconventional solutions, which in turn provide additional benefits beyond their immediate application. Further, when an asynchronous philosophy is incorporated at every stage of the design, the microarchitecture is more closely linked to the basic structures of the self-timed circuits themselves, and the resulting processor is quite surprising in its simplicity and elegance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. D. Acosta, J. Kjelstrup, and H. C. Torng, </author> <title> An instruction issuing approach to enhancing performance in multiple functional unit processors, </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. C-35, </volume> <pages> pp. 815828, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: Instructions are dynamically scheduled, meaning that they do not have to issue sequentially in program order. Any instruction which can satisfy its dependencies is able to issue, although preference is given to in-order dispatch when more than one instruction is ready. The rules governing out-of-order issues are not complex <ref> [1] </ref>. Briefly, an instruction cannot be issued if any of the following statements is true: 1. The destination register is used as a destination in a prior nonissued instruction. 2. The destination register is used as an operand in a prior nonissued instruction. 3.
Reference: [2] <author> E. Brunvand, </author> <title> A cell set for self-timed design using actel FPGAs, </title> <institution> T echnical Report UUCS91013, University of Utah, </institution> <year> 1991. </year>
Reference-contexts: The delay times for each operation were carefully chosen to mimic typical gate delays found in existing processor designs. Most of the self-timed circuit component library used for the glue logic was developed by Erik Brunvand <ref> [2] </ref> for use with Actel FPGAs. 4 A strong hypobaric forcing function is inherent to Viewlogics VHDL implementation.
Reference: [3] <author> E. Brunvand, </author> <title> Using FPGAs to prototype a self-timed computer , in International Workshop on Field Programmable Logic and Applications, </title> <institution> (Vienna University of Technology), </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: The NSR was tested and found to work well. It is pipelined and decoupled, but does not handle exceptions. It is a very simple processor with only 16 instructions, since it was built partially as an exercise in using FPGAs for rapid prototyping of self-timed circuits <ref> [3] </ref>. 6 2.3. Amulet A group at Manchester has built a self-timed micropipelined VLSI implementation of the ARM processor [17] which is an extremely power efficient commercial microprocessor. The Amulet is more deeply pipelined than the synchronous ARM, but it is not decoupled although it allows for instruction prefetching.
Reference: [4] <author> E. Brunvand, </author> <title> The NSR processor, </title> <booktitle> in Proceedings of the 26th Annual Hawaii International Conference on System Sciences, (Maui, Hawaii), </booktitle> <pages> pp. 428435, </pages> <month> January </month> <year> 1993. </year>
Reference: [5] <author> K.-R. Cho, K. Okura, and K. Asada, </author> <title> Design of a 32-bit fully asynchronous microprocessor (FAM), </title> <booktitle> in Proceedings of the 35th Midwest Symposium on Cir cuits and Systems, </booktitle> <address> (Washington, D.C.), </address> <pages> pp. 15001503, </pages> <year> 1992. </year>
Reference-contexts: It can handle exceptions, and a self-timed implementation which mimics a commercial RISC processor s instruction set is under development. The potential of this architecture is intriguing but still unknown. 2.6. FAM The FAM is a 32-bit, fully asynchronous microprocessor design from the University of Tokyo <ref> [5] </ref>. It contains a four stage pipeline with a central controller and uses four phase handshaking. It uses asynchronous circuits to implement an otherwise fairly conventional RISC processor, which does not take advantage of the micropipeline approach.
Reference: [6] <author> W. A. Clark and C. A. Molnar, </author> <title> Macromodular system design, </title> <type> Tech. Rep. 23, </type> <institution> Computer Systems Laboratory, Washington University, </institution> <month> April </month> <year> 1973. </year>
Reference-contexts: Early work in asynchronous computer architecture includes the Macro-module project during the early 70s at W ashington University <ref> [6] </ref> and the self-timed dataflow machines built at the University of Utah in the late 70s [7]. Although these projects were successful in many ways, asynchronous processor design did not progress much, perhaps because the circuit concepts were a little too far ahead of the available technology.
Reference: [7] <author> A. Davis, </author> <title> The architecture and system method for DDM1: A recursively structured data-driven machine, </title> <booktitle> in 5th Annual Symposium on Computer Ar chitecture, </booktitle> <address> (Palo Alto, CA), </address> <pages> pp. 210215, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: Early work in asynchronous computer architecture includes the Macro-module project during the early 70s at W ashington University [6] and the self-timed dataflow machines built at the University of Utah in the late 70s <ref> [7] </ref>. Although these projects were successful in many ways, asynchronous processor design did not progress much, perhaps because the circuit concepts were a little too far ahead of the available technology.
Reference: [8] <author> A. L. Davis, </author> <title> Asynchronous advantages often cited and NOT often cited. </title> <booktitle> Distributed at the Async94 Conference, </booktitle> <address> Salt Lake City, Utah., </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Although this may provide advantages in achieving average-case performance or simplifying modular composition <ref> [8] </ref>, it makes exception processing dif ficult. Much of the state of the Fred processor is contained in the pipelines, but it is problematic to determine exactly how many items are in a particular pipeline at a given moment in time. <p> Of course, fast design time and reduced complexity (due to the lack of clock circuitry) are two of the often-quoted advantages of asynchronous circuits in general <ref> [8] </ref>. 9.3. Applicability to Synchronous Systems The elastic nature of a micropipeline FIFO allows Freds decoupled units to run at data-dependent speeds; producing or consuming data as fast as possible for the given program and data.
Reference: [9] <author> M. E. Dean, </author> <title> STRiP: A self-timed RISC processor , Technical Report CSL-TR-92-543, </title> <institution> Computer Systems Laboratory, Stanford University, Stanford, </institution> <address> CA 943054055, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: The Amulet has been designed and fabricated. The performance of the f irst-generation design is within a factor of two of the commercial version [29]. Future versions of Amulet are expected to close this gap. 2.4. STRiP The STRiP processor was developed at Stanford University <ref> [9] </ref>. Although the designers refer to it as self-timed, the STRiP processor is not an asynchronous machine in the sense used in this document. Instead it is a synchronous machine which dynamically alters its clock period on a cycle-by-cycle basis.
Reference: [10] <author> H. Dwyer and H. C. Torng, </author> <title> An out-of-order superscalar processor with speculative execution and fast, precise interrupts, </title> <booktitle> in Proceedings of the 25th Annual International Symposium on Microarchitecture, </booktitle> <address> (Portland, OR), </address> <pages> pp. 272281, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: The decoupled memory access should allow for enough prefetching time to obviate the need for speculative execution [15]. Evaluation of a synchronous processor design using an IW indicates that speculative execution does not always provide a performance increase <ref> [10] </ref>. Nonetheless, this could be an interesting topic to investigate further. 65 8.7. Memory Unit Freds Memory Unit is a very simple one. Memory interfaces for commercial microprocessors contain a number of optimizations from which Fred would benef it.
Reference: [11] <author> D. Elsner, J. Fenlason, and friends, </author> <title> Using as The GNU Assembler. Free Software Foundation, </title> <publisher> Inc., </publisher> <address> 675 Massachusetts Avenue, Cambridge, MA 02139, 1.13 ed., </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Several software tools were developed to assist with this process. 46 6.7.1. Assembler Rather than write an assembler from scratch, it was decided to use the GNU assembler <ref> [11] </ref>. The GNU assembler offers several advantages: it is available for free, it works, it is fairly robust, and it is relatively portable. It has only one major disadvantage: there is no documentation on exactly how to port it to a new architecture.
Reference: [12] <author> C. J. Elston, D. B. Christianson, P. A. Findlay, and G. B. Steven, </author> <title> Hadestowards the design of an asynchronous superscalar processor , in Second Working Conference on Asynchronous Design Methodologies, </title> <address> (London, UK), </address> <pages> pp. </pages> <address> 200209, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: The architecture uses a single-ALU von Neumann design and is only slightly pipelined. It is not decoupled and does not handle interrupts. 2.8. Hades A group at the University of Hertfordshire have proposed a superscalar asynchronous processor design named Hades <ref> [12] </ref>. It has a simple RISC instruction set and resembles a conventional synchronous processor in many ways. It issues instructions in sequential order but allows out-of-order completion. Explicit forwarding is done between functional units under the direction of a central scoreboard mechanism. 2.9.
Reference: [13] <author> P. B. Endecott, SCALP: </author> <title> A Superscalar Asynchronous Low-Power Processor. </title> <type> PhD thesis, </type> <institution> University of Manchester, </institution> <year> 1995. </year> <month> ftp://ftp.cs.man.ac.uk/pub/amulet/theses/endecott_phd.ps.gz. </month>
Reference-contexts: It issues instructions in sequential order but allows out-of-order completion. Explicit forwarding is done between functional units under the direction of a central scoreboard mechanism. 2.9. SCALP SCALP is a superscalar pipelined asynchronous processor design, developed at the University of Manchester <ref> [13] </ref>. It was designed to maximize code density and parallelism and to minimize power consumption. Multiple queues are used to forward results between functional units. SCALP does not use a register f ile, but instead each instruction indicates which of several functional units should receive its computed result.
Reference: [14] <author> M. K. Farrens and A. R. Pleszkun, </author> <booktitle> Implementation of the PIPE processor , IEEE Computer, </booktitle> <pages> pp. 6570, </pages> <month> January </month> <year> 1991. </year>
Reference: [15] <author> M. Farrens, P. Ng, and P. Nico, </author> <title> A comparison of superscalar and decoupled access/execute architectures, </title> <booktitle> in Proceedings of the 26th Annual ACM/IEEE International Sympo 88 sium on Microarchitecture, </booktitle> <address> (Austin, Texas), </address> <publisher> IEEE, ACM, </publisher> <month> December </month> <year> 1993. </year>
Reference-contexts: The two operations are scheduled statically but are allowed to move in and out of phase dynamically . In this manner, peaks and valleys in each may be smoothed for an overall performance gain. It has been shown <ref> [15] </ref> that the decoupled approach can provide a limited version of register renaming, out-of-order completion, and dynamic loop unrolling, resulting in performance which equals or surpasses a superscalar implementation. Additionally, the decoupled approach requires significantly less hardware support. <p> Requiring a traditional precise exception model means that order of completion does matter, at least in the order in which instructions are retired from the IW . The decoupled memory access should allow for enough prefetching time to obviate the need for speculative execution <ref> [15] </ref>. Evaluation of a synchronous processor design using an IW indicates that speculative execution does not always provide a performance increase [10]. Nonetheless, this could be an interesting topic to investigate further. 65 8.7. Memory Unit Freds Memory Unit is a very simple one.
Reference: [16] <author> M. K. Farrens and A. R. Pleszkun, </author> <title> Improving performance of small on-chip instruction caches, </title> <booktitle> in 14th Annual International Symposium on Computer Ar chitecture, </booktitle> <address> (Pittsburgh, PA), </address> <pages> pp. 234241, </pages> <publisher> ACM, </publisher> <year> 1987. </year>
Reference: [17] <author> S. B. Furber, P. Day, J. D. Garside, N. C. Paver, and J. V. Woods, </author> <title> A micropipelined ARM, </title> <booktitle> in Proceedings of the VII Banff Workshop: Asynchronous Hardware Design, </booktitle> <address> (Banff, Canada), </address> <month> August </month> <year> 1993. </year>
Reference-contexts: It is a very simple processor with only 16 instructions, since it was built partially as an exercise in using FPGAs for rapid prototyping of self-timed circuits [3]. 6 2.3. Amulet A group at Manchester has built a self-timed micropipelined VLSI implementation of the ARM processor <ref> [17] </ref> which is an extremely power efficient commercial microprocessor. The Amulet is more deeply pipelined than the synchronous ARM, but it is not decoupled although it allows for instruction prefetching. <p> This would greatly increase the size and complexity of the scoreboard unit. Additional dispatch logic would also be required to ensure that the scoreboard counter bits do not overow due to too many last-result-reuse instructions being dispatched at once. The AMULET processor <ref> [17] </ref> uses a scoreboarding mechanism which has a similar ef fect. The destination register of all pending instructions is encoded in unary form in the dispatch FIFO, and the logical OR of each bit column indicates that a register is in use.
Reference: [18] <author> S. Furber, </author> <title> Computing without clocks, </title> <booktitle> in Proceedings of the VII Banff Workshop: Asynchronous Hardware Design, </booktitle> <address> (Banff, Canada), </address> <month> August </month> <year> 1993. </year>
Reference: [19] <author> J. R. Goodman, J. Hsieh, K. Liou, A. R. Pleszkun, P. B. Schechter, and H. C. Young, </author> <title> PIPE: A VLSI decoupled architecture, </title> <booktitle> in 12th Annual International Symposium on Computer Architecture, </booktitle> <address> (Boston, MA), </address> <pages> pp. </pages> <address> 2027, </address> <publisher> IEEE Computer Society, </publisher> <month> June </month> <year> 1985. </year>
Reference: [20] <author> T. R. Gross, J. L. Hennessy, S. A. Przybylski, and C. </author> <title> Rowen, </title> <booktitle> Measurement and evaluation of the MIPS architecture and processor , ACM Transactions on Computer Systems , vol. </booktitle> <volume> 6, </volume> <pages> pp. 229257, </pages> <month> August </month> <year> 1988. </year>
Reference: [21] <author> J. Hennessy, N. Jouppi, F. Baskett, T. Gross, and J. Gill, </author> <title> Hardware/software tradeoffs for increased performance, </title> <booktitle> in Proceedings of the Symposium on Ar chitectural Support for Programming Languages and Operating Systems, </booktitle> <address> (Palo Alto, CA), </address> <pages> pp. 211, </pages> <publisher> ACM, </publisher> <month> April </month> <year> 1982. </year>
Reference: [22] <author> D. Hunt, </author> <title> Advanced performance features of the 64-bit P A-8000, </title> <booktitle> in Proceedings of COMPCON95, </booktitle> <address> (San Francisco, CA), </address> <pages> pp. 123128, </pages> <year> 1995. </year>
Reference-contexts: For example, the Hewlett-Packard PA-8000 uses a precise exception model and has a 56-entry Instruction Reorder Buffer, which serves the purpose of an IW <ref> [22] </ref> with out-of-order completion and in-order retirement. In contrast, Freds functionally precise exception model allows instructions to retire in any order, in many cases as soon as the instructions issue. The IW must track all issued instructions which might fault only until they have completed successfully.
Reference: [23] <author> M. G. H. Katevenis, </author> <title> Reduced Instruction Set Computer Ar chitectures for VLSI . MIT Press, </title> <year> 1985. </year>
Reference: [24] <author> A. Martin, S. Burns, T. Lee, D. Borkovic, and P. Hazewindus, </author> <title> The design of an asynchronous microprocessor, </title> <booktitle> in Proceedings of the CalTech Conference on VLSI, </booktitle> <address> (Pasadena, CA), </address> <year> 1989. </year>
Reference: [25] <author> Motorola, </author> <title> System V Application Binary Interface: Motorola 88000 Processor Supplement. </title> <publisher> Unix Press, </publisher> <year> 1988. </year>
Reference-contexts: Fortunately, the 88100 ABI <ref> [25] </ref> indicates that 88100 register r28 is reserved for future expansion and should never be used by a compiler, so it was possible to replace all 88100 references to r1 with Fred references to r28, leaving Freds r1 register available for the R1 Queue. 47 6.7.5.
Reference: [26] <author> Motorola, </author> <title> MC88100 RISC Microprocessor Users Manual. </title> <address> Englewood Cliffs, New Jersey 07632: </address> <publisher> Prentice Hall, </publisher> <editor> 2nd ed., </editor> <year> 1990. </year>
Reference-contexts: Instruction Set Choosing an instruction set for a RISC processor can be a complex task [21,20,23]. Rather than attempt to design a new instruction set from scratch, much of the Fred instruction set was taken directly from the Motorola 88100 instruction set <ref> [26] </ref>. However, Fred does not implement all of the 88100 instructions, and several of Fred s instructions do not correspond to any instructions of the 88100. Freds instruction format is triadic, where most instructions specify two source registers as operands and one destination register for the result.
Reference: [27] <author> T. Nanya, Y. Ueno, H. Kagotani, M. Kuwako, and A. Takamura, TITAC: </author> <title> Design of quasi-delay-insensitive microprocessor, </title> <journal> IEEE Design & Test of Computers, </journal> <volume> vol. 11, </volume> <pages> pp. 5063, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: The F AM has been designed and simulated for a 0.5mm CMOS technology but has not been built. 7 2.7. TITAC Researchers at the Tokyo Institute of Technology have designed and built TITAC, a simple 8-bit asynchronous microprocessor <ref> [27] </ref>. It uses dual rail encoding for the data paths and has been built using 1mm CMOS gate array technology. The architecture uses a single-ALU von Neumann design and is only slightly pipelined. It is not decoupled and does not handle interrupts. 2.8.
Reference: [28] <author> A. Nicolau and J. A. Fisher, </author> <title> Measuring the parallelism available for very long instruction word architectures, </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. C-33, </volume> <pages> pp. 110118, </pages> <month> Novem-ber </month> <year> 1984. </year>
Reference: [29] <author> N. C. Paver, </author> <title> The Design and Implementation of an Asynchr onous Microprocessor. </title> <type> PhD thesis, </type> <institution> University of Manchester, </institution> <year> 1994. </year> <note> http://www.cs.man.ac.uk/amulet/ publications/thesis/paver94_phd.html. </note>
Reference-contexts: Its precise exception model is a simple one, since its single ALU causes all instructions to issue and complete sequentially . The Amulet has been designed and fabricated. The performance of the f irst-generation design is within a factor of two of the commercial version <ref> [29] </ref>. Future versions of Amulet are expected to close this gap. 2.4. STRiP The STRiP processor was developed at Stanford University [9]. Although the designers refer to it as self-timed, the STRiP processor is not an asynchronous machine in the sense used in this document.
Reference: [30] <author> A. R. Pleszkun, J. R. Goodman, W.-C. Hsu, R. T. Joersz, G. Bier, P. Woest, and P. B. Schechter, WISQ: </author> <title> A restartable architecture using queues, </title> <booktitle> in 1987 Symposium on Com 89 puter Architecture, </booktitle> <address> (Pittsburgh, PA), </address> <pages> pp. 290299, </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1987. </year>
Reference: [31] <author> W. F. Richardson, </author> <title> The Fred VHDL model, </title> <type> Technical Report UUCS95021, </type> <institution> University of Utah, </institution> <month> November </month> <year> 1995. </year> <note> ftp://ftp.cs.utah.edu/techreports/1995/ UUCS-95-021.ps.Z. </note>
Reference-contexts: V iewSims default gate delay time for discrete components is 0.1ns, so the overall delay time was scaled by this value. The delays used in the Fred model are shown in Table 6.9. The schematics and VHDL code are available elsewhere <ref> [31] </ref>. 48 Table 6.9 Simulation delay times Functional Unit Operation Delay time (nsecs) Dispatch add to IW 0.5 search IW 0.3 decode instruction 1.0 retire instruction 0.4 save Shadow IW 1.0 getcr 0.4 putcr 0.5 doit 0.3 rte 1.0 sync.x 0.3 sync.x abort 0.4 Arithmetic add 0.5 cmp 0.6 mul 3.0
Reference: [32] <author> W. F. Richardson and E. Brunvand, </author> <title> The NSR processor prototype, </title> <institution> T echnical Report UUCS92029, University of Utah, </institution> <month> August </month> <year> 1992. </year> <note> ftp://ftp.cs.utah.edu/ techreports/1992/UUCS-92-029.ps.Z. </note>
Reference: [33] <author> W. F. Richardson and E. Brunvand, Fred: </author> <title> An architecture for a self-timed decoupled computer, </title> <type> Technical Report UUCS95008, </type> <institution> University of Utah, </institution> <month> May </month> <year> 1995. </year> <note> ftp:// ftp.cs.utah.edu/techreports/1995/UUCS-95-008.ps.Z. </note>
Reference: [34] <author> W. F. Richardson and E. Brunvand, </author> <title> Precise exception handling for a self-timed processor, </title> <booktitle> in 1995 International Conference on Computer Design: VLSI in Computers & Pr o-cessors, </booktitle> <address> (Los Alamitos, CA), </address> <pages> pp. 3237, </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1995. </year>
Reference: [35] <author> C. L. Seitz, </author> <title> System timing, in Mead and Conway, Introduction to VLSI Systems, ch. 7, </title> <publisher> Addison-Wesley, </publisher> <year> 1980. </year>
Reference-contexts: Asynchronous circuits provide a dif ferent approach. In an asynchronous system, events are restricted to a particular sequence. The time at which these events occur is a separate issue. For correct functioning, it is important only that the correct order of events be maintained within the circuit. Self-timed circuits <ref> [35] </ref> are a subset of the broad class of asynchronous circuits, which applies a different type of structure to circuit design. <p> Two modules connected with a bundled data path are shown in Figure 3.1, and a timing diagram showing the sequence of the signal transitions using two-phase transition signaling is shown in referred to Seitz <ref> [35] </ref>. 3.1. Control Modules Control circuits for transition signalling may be built from the set of simple building blocks shown in Figure 3.3.
Reference: [36] <author> J. E. Smith and A. R. Pleszkun, </author> <title> Implementing precise interrupts in pipelined processors, </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 37, </volume> <pages> pp. 562573, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Adding some mechanism to undo out-of-order instructions is the approach typically taken in synchronous processor designs. The IW is ideally suited to containing instruction information, and some sort of history buf fer or reorder buffer <ref> [36] </ref> can be used to restore any register contents which were changed as a result of an out-of-order instruction. Unfortunately, this does not address all the problems. If the doit has completed, it means that a branch tar get has been removed from the Branch Queue.
Reference: [37] <author> G. S. Sohi, </author> <title> Instruction issue logic for high-performance, interruptible, multiple functional unit, pipelined computers, </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 39, </volume> <pages> pp. 349359, </pages> <month> March </month> <year> 1990. </year>
Reference: [38] <author> R. F. Sproull and I. E. Sutherland, </author> <title> Counterflow pipeline processor architecture, </title> <type> Tech. Rep. </type> <institution> SMLI TR-94-25, Sun Microsystems Laboratories, Inc., </institution> <address> M/S 29-01, 2550 Garcia Avenue, Mountain View, CA 94043, </address> <month> April </month> <year> 1994. </year> <note> http://www.sun.com/smli/ technical-reports/1994/smli_tr-94-25.ps. </note>
Reference-contexts: This processor has been simulated but not built. 2.5. Counterow Pipeline Processor The Counterow Pipeline Processor (CFPP) is an innovative architecture proposed by a group at Sun Microsystems Labs <ref> [38] </ref>. It derives its name from its fundamental feature, that instructions and results flow in opposite directions in a pipeline and interact as they pass.
Reference: [39] <author> I. Sutherland, </author> <title> Micropipelines, </title> <journal> Communications of the ACM , vol. </journal> <volume> 32, no. 6, </volume> <pages> pp. 720 738, </pages> <year> 1989. </year>
Reference-contexts: With some care, standard gated latches can also be used for storage [18,29]. 3.3. Micropipelines The two-phase bundled data protocol offers a number of advantages in its simplicity and com-posability. Using this protocol, Ivan Sutherland described an elegant methodology for constructing self-timed systems, known as micropipelines <ref> [39] </ref>. Micropipelines are self-timed, event driven, elastic pipelines composed of the elements just described, that may or may not contain processing between the pipe stages. If no processing is done between the pipe stages, the micro-pipeline reduces to a simple first-in first-out (FIFO) buffer.
Reference: [40] <author> C. A. Thekkath and H. M. Levy, </author> <title> Hardware and software support for ef ficient exception handling, </title> <booktitle> in Sixth International Conference on Architectural Support for Programming Languages and Operating Systems , (San Jose, </booktitle> <address> CA), </address> <pages> pp. 110119, </pages> <publisher> ACM Press, </publisher> <month> October </month> <year> 1994. </year>
Reference-contexts: Modification of the register scoreboard could also result in better last-result-reuse characteristics, as mentioned in Section 6.2.3.3. This also would require modification of the dispatch logic. Trap instructions are increasingly used to perform user specific functions <ref> [40] </ref>. Fred could well benefit from a faster means of invoking user traps.
Reference: [41] <author> J. A. Tierno, A. J. Martin, D. Borkovic, and T. K. Lee, </author> <title> An asynchronous microprocessor in gallium arsenide, </title> <type> Technical Report CSTR9338, </type> <institution> California Institute of Technology, Department of Computer Science, Pasadena, </institution> <address> CA 91125, </address> <year> 1993. </year>
Reference: [42] <author> H. C. Torng and M. Day, </author> <title> Interrupt handling for out-of-order execution processors, </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 42, </volume> <pages> pp. 122127, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: The scoreboard is set by the Dispatch Unit and is cleared when results arrive at the Register File. Instructions will not be dispatched until all data hazards are resolved. An Instruction Window (IW) is used to buffer incoming instructions and to track the status of issued instructions <ref> [42] </ref>. The IW is a set of internal registers located in the Dispatch Unit which tracks the state of all current instructions. Each slot in the IW contains information about each instruction such as its opcode, address, current status, and various other parameters. <p> Freds decoupled concurrent architecture requires a more general solution. 5.1.1. The Instruction Window To resolve the uncertainty regarding instruction status, Fred uses an IW , similar to that described by Torng and Day <ref> [42] </ref>, to fetch and dispatch instructions. The IW is a set of internal registers located in the Dispatch Unit, which tracks the state of all current instructions. Each slot in the IW contains information about each instruction, such as its opcode, its address, its current status, and various other parameters. <p> This early completion signaling has no effect on data hazards. 5.1.3. Out-of-Order Completion In Torng and Days design, provision was made to reduce interrupt latency by aborting issued instructions which would take a long time to complete <ref> [42] </ref>. In a self-timed processor there is no way to tell how soon an instruction will complete, since there are no clock cycles by which to measure progress. Instead, when an exception occurs, all outstanding instructions are allowed to either complete or fault before handling the exception.
Reference: [43] <author> D. W. Wall, </author> <title> Limits of instruction-level parallelism, WRL T echnical Note TN-15, </title> <institution> Digital Western Research Laboratory, </institution> <address> 100 Hamilton Avenue, Palo Alto, CA 94301, </address> <month> December </month> <year> 1990. </year> <note> ftp://gatekeeper.dec.com/pub/DEC/WRL/research-reports/ WRL-TN-15.ps. </note>
Reference-contexts: The flexibility of the dynamic scheduling mechanism would be decreased, since dependencies on issued as well as nonissued instructions would have to be considered when searching the IW for instructions to issue. The degree of parallelism in most programs is not great <ref> [43] </ref>, yet it is enough that some pipelining is possible. With WAW-safe dispatch, no two concurrent instructions can use the same registers for either source or destination. It is questionable whether typical programs have enough parallelism to maintain performance under these conditions. 6.7.
Reference: [44] <author> C.-J. Wang and F. Emnett, </author> <title> Area and performance comparison of pipelined RISC processors implementing different precise interrupt methods, </title> <booktitle> in 1993 International Conference on Computer Design, </booktitle> <address> (Cambridge, MA), </address> <pages> pp. 102105, </pages> <publisher> IEEE Computer Society Press, </publisher> <month> 90 October </month> <year> 1993. </year>
Reference: [45] <author> W. A. Wulf, </author> <title> The WM computer architecture, </title> <journal> Computer Architecture News, </journal> <volume> vol. 16, </volume> <month> March </month> <year> 1988. </year>
Reference-contexts: Register r0 may be used as the destination of an instruction but will always contain zero. Register r1 is not really a register at all but provides read access to the R1 Queue, a data pipeline similar to that used in the WM machine <ref> [45] </ref>. Specifying r1 as the destination of an instruction inserts the result into the pipeline. Each use of r1 as a source for an instruction retrieves one word from the R1 Queue.
References-found: 45

