URL: http://www.cogs.susx.ac.uk/users/christ/papers/creativity-as-learning.ps
Refering-URL: http://www.cogs.susx.ac.uk/users/christ/index-noframes.html
Root-URL: 
Email: Email: Chris.Thornton@cogs.susx.ac.uk  
Title: Creativity as Runaway Learning  Keywords: AI and Creativity, Induction  
Author: Chris Thornton 
Date: January 22, 1996  
Address: Brighton BN1 9QN, UK  
Affiliation: Cognitive and Computing Sciences University of Sussex  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Shavlik, J. and Dietterich, T. (Eds.) </author> <year> (1990). </year> <booktitle> Readings in Machine Learning. </booktitle> <address> San Mateo, Cal-ifornia: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: On the empiricist account, the world flows into the mind. On the rationalist account, it flows out of it. A reflection of the empiricist/idealist distinction exists in in the modern treatment of learning and creativity. Contemporary models tend to focus either exclusively on learning <ref> [1] </ref>, i.e., on ways in which worldly phenomena can be `absorbed' by the mind; or they focus exclusively on creativity [2], i.e., on ways in which mental phenomena can lead to the creation of artifacts in the world. <p> There are a large number of these <ref> [1, 3, 4] </ref> and their development is the concern of several overlapping research communities. 3 Statistical v. relational learning Analysing inductive justification allows us to divide methods of inductive learning into two basic types.
Reference: [2] <author> Boden, M. </author> <year> (1990). </year> <title> The Creative Mind: Myths and Mechanisms. </title> <publisher> London: Weidenfeld and Ni-icolson. </publisher>
Reference-contexts: A reflection of the empiricist/idealist distinction exists in in the modern treatment of learning and creativity. Contemporary models tend to focus either exclusively on learning [1], i.e., on ways in which worldly phenomena can be `absorbed' by the mind; or they focus exclusively on creativity <ref> [2] </ref>, i.e., on ways in which mental phenomena can lead to the creation of artifacts in the world. However, there are reasons to believe that these two processes are more closely related than modern research suggests. <p> At the other it is more meaningful to speak about the process reifying phenomena which are essentially artifacts of interactions between genuine input data and internal bias. This would seem to be literally a form of creativity, or P-creativity in Boden's sense <ref> [2] </ref>. A practical implementation of an unbounded, recursive learning process might thus have interesting applications in the general area of creativity enhancement.
Reference: [3] <editor> Michalski, R., Carbonell, J. and Mitchell, T. (Eds.) </editor> <booktitle> (1983). Machine Learning: An Artificial Intelligence Approach. </booktitle> <address> Palo Alto: </address> <publisher> Tioga. </publisher>
Reference-contexts: There are a large number of these <ref> [1, 3, 4] </ref> and their development is the concern of several overlapping research communities. 3 Statistical v. relational learning Analysing inductive justification allows us to divide methods of inductive learning into two basic types.
Reference: [4] <editor> Michalski, R., Carbonell, J. and Mitchell, T. (Eds.) </editor> <booktitle> (1986). Machine Learning: An Artificial Intelligence Approach: Vol II. </booktitle> <address> Los Altos: </address> <publisher> Mor-gan Kaufmann. </publisher>
Reference-contexts: There are a large number of these <ref> [1, 3, 4] </ref> and their development is the concern of several overlapping research communities. 3 Statistical v. relational learning Analysing inductive justification allows us to divide methods of inductive learning into two basic types.
Reference: [5] <author> Thornton, C. </author> <year> (1994). </year> <title> Statistical biases in backpropagation learning. </title> <booktitle> Proceedings of the International Conference on Artificial Neural Networks (pp. </booktitle> <pages> 709-712). </pages> <address> Sorrento, Italy. </address>
Reference-contexts: As a result, practical learning methods tend to be predisposed towards the easier task, i.e., they tend to exploit probabilities of the first and second form, rather than of the third form <ref> [5] </ref>. Interestingly, we can deduce that the evaluation function used in the third form must measure a relational property of its inputs. To understand why this is so, we need to think about the way in which the function differentiates different types of input.
Reference: [6] <author> Utgoff, P. </author> <year> (1986). </year> <title> Machine Learning of Inductive Bias. </title> <booktitle> Kluwer International Series in Engineering and Computer Science, </booktitle> <volume> Vol. 15, </volume> <publisher> Kluwer Academic. </publisher>
Reference-contexts: This effectively creates new values and thus new data. These new data can themselves be processed for statistical and relational effects in a recursive manner. However, since the space of relationships is, in general, infinitely large, relational learners always and necessarily incorporate some form of bias <ref> [6] </ref>, i.e., they have a predisposition to focus attention on certain types of relationship. If the learner acts in a recursive manner then this bias becomes stronger at each level of the recursion. In the initial stage, the data are given by the environment.
Reference: [7] <author> Quinlan, J. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <booktitle> Machine Learning, </booktitle> <pages> 1 (pp. 81-106). </pages>
Reference-contexts: Each odd-numbered variable contains the face value for a particular card, represented as a number (where 10=jack, 11=queen, 12=king and 13=ace). The adjacent even-numbered variable holds the corre 1 As a matter of practical interest, the performance of statistical learning methods such as ID3 <ref> [7] </ref> confirms the hypothesis that this induction problem cannot be solved in a statistical way. ID3 for example does not generalise correctly to the missing value. Neither does backpropagation [8]. sponding suit value (1=hearts, 2=spades, 3=clubs and 4=diamonds).
Reference: [8] <author> Rumelhart, D., Hinton, G. and Williams, R. </author> <year> (1986). </year> <title> Learning representations by back-propagating errors. </title> <booktitle> Nature, </booktitle> <pages> 323 (pp. 533-6). 5 </pages>
Reference-contexts: ID3 for example does not generalise correctly to the missing value. Neither does backpropagation <ref> [8] </ref>. sponding suit value (1=hearts, 2=spades, 3=clubs and 4=diamonds).
References-found: 8

