URL: http://www.cs.cornell.edu/Info/People/weichen/research/mypapers/DISC98final.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/weichen/research.htm
Root-URL: http://www.cs.cornell.edu
Email: aguilera,weichen,sam@cs.cornell.edu  
Title: Failure Detection and Consensus in the Crash-Recovery Model  
Author: Marcos Kawazoe Aguilera Wei Chen Sam Toueg 
Address: Ithaca NY 14853-7501, USA  
Affiliation: Cornell University, Computer Science Department,  
Abstract: We study the problems of failure detection and consensus in asynchronous systems in which processes may crash and recover, and links may lose messages. We first propose new failure detectors that are particularly suitable to the crash-recovery model. We next determine under what conditions stable storage is necessary to solve consensus in this model. Using the new failure detectors, we give two consensus algorithms that match these conditions: one requires stable storage and the other does not. Both algorithms tolerate link failures and are particularly efficient in the runs that are most likely in practice those with no failures or failure detector mistakes. In such runs, consensus is achieved within 3ffi time and with 4n messages, where ffi is the maximum message delay and n is the number of processes in the system.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> M. K. Aguilera, W. Chen, and S. Toueg. Heartbeat: </author> <title> a timeout-free failure detector for quiescent reliable communication. </title> <booktitle> In Proceedings of the 11th International Workshop on Distributed Algorithms, Lecture Notes on Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <month> Sept. </month> <year> 1997. </year> <note> A full version is also available as Technical Report 97-1631, </note> <institution> Computer Science Department, Cornell University, </institution> <address> Ithaca, New York, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: reach decision within 2ffi and with O (n 2 ) messages. 11 This is with the round 1 optimization in which the coordinator chooses its own estimate and sends it without waiting for estimates from other processes. 8.2 Quiescence An algorithm is quiescent if eventually all processes stop sending messages <ref> [1] </ref>. It is clear that no consensus algorithm can be quiescent in the presence of unstable processes (each time such a process recovers, it must be sent the decision value, at which point it may crash again and lose this message; this scenario can be repeated infinitely often).
Reference: 2. <author> M. K. Aguilera, W. Chen, and S. Toueg. </author> <title> Failure detection and consensus in the crash-recovery model. </title> <type> Technical Report 98-1676, </type> <institution> Department of Computer Science, Cornell University, </institution> <month> April </month> <year> 1998. </year>
Reference-contexts: Note that the completeness property of 3S e does not require predicting the future (to determine if a process is unstable), and so it does not force implementations to have anomalous behaviors. To illustrate this, in <ref> [2] </ref> we give an implementation of 3S e for some models of partial synchrony: this implementation ensures that if all processes are eventually up forever they will be eventually trusted forever. Failure detector 3S e , however, does not put any restriction on how the bad processes view the system. <p> From the above it is clear that sometimes it is better to have a failure detector with: Strong Accuracy: Some good process is eventually trusted forever by all good and unstable processes, and its epoch number stops changing. Such a failure detector is denoted 3S u . In <ref> [2] </ref>, we show how to transform any 3S e to 3S u in an asynchronous system provided that a majority of processes are good. 1.2 On the Necessity of Stable Storage in the Crash-Recovery Model Can consensus be solved in the crash-recovery model without stable storage, and if so, how? Suppose <p> We then give two matching consensus algorithms: one does not require stable storage (Section 6), and the other uses stable storage (Section 7). In Section 8, we briefly consider the performance of these algorithms. Due to space limitations, all proofs are ommitted here (they are given in <ref> [2] </ref>). 2 Model We consider asynchronous message-passing distributed systems. We assume that every process is connected with every other process through a communication link. Links can fail by intermittently dropping messages. A process can fail by crashing and it may subsequently recover. <p> We first define 3S e to be the class of failure detectors D that satisfy the following properties (the formal definitions of these properties are given in <ref> [2] </ref>): Monotonicity: At every good process, eventually the epoch numbers are nonde creasing 7 . Completeness: For every bad process b and for every good process g, either even tually g permanently suspects b or b's epoch number at g is unbounded. <p> The class of failure detectors that satisfy Monotonicity, Completeness, and Strong Accuracy is denoted 3S u . For convenience, we sometimes use 3S e or 3S u to refer to an arbitrary member of the corresponding class. 3S e and 3S u are closely related: In <ref> [2] </ref> we show that one can transform 3S e into 3S u provided that a majority of processes are good (this transformation does not require stable storage). 7 We require the monotonicity of epoch numbers to hold only eventually and only at good pro cesses so that the failure detector can <p> The consensus algorithm that uses 3S e is given in <ref> [2] </ref>. In this paper, we present a more efficient algorithm that uses a minor variant of 3S e , denoted 3S 0 e . <p> It is worth noting that the implementation of 3S e in <ref> [2] </ref> also implements 3S 0 e . The consensus algorithm that we give here always satisfies the Uniform Agreement and Validity properties of uniform consensus for any choice of n a and n b , and if n a &gt; n b then it also satisfies the Termination property. <p> If no process is unstable, our consensus algorithms are quiescent despite process crashes and message losses (provided all good processes propose a value). Remark The full version of this paper <ref> [2] </ref> contains the following additional material: a consensus algorithm that does not require stable storage and uses 3S e (rather than 3S 0 e ), an implementation of 3S e and 3S 0 e in some models of partial synchrony, an algorithm that transforms 3S e into 3S u , a
Reference: 3. <author> T. D. Chandra, V. Hadzilacos, and S. Toueg. </author> <title> The weakest failure detector for solving consensus. </title> <journal> Journal of the ACM, </journal> <volume> 43(4):685722, </volume> <month> July </month> <year> 1996. </year>
Reference-contexts: 1 Introduction The problem of solving consensus in asynchronous systems with unreliable failure detectors (i.e., failure detectors that make mistakes) was first investigated in <ref> [4, 3] </ref>. But these works only considered systems where process crashes are permanent and links are reliable (i.e., they do not lose messages). In real systems, however, processes may recover after crashing and links may lose messages.
Reference: 4. <author> T. D. Chandra and S. Toueg. </author> <title> Unreliable failure detectors for reliable distributed systems. </title> <journal> Journal of the ACM, </journal> <volume> 43(2):225267, </volume> <month> March </month> <year> 1996. </year>
Reference-contexts: 1 Introduction The problem of solving consensus in asynchronous systems with unreliable failure detectors (i.e., failure detectors that make mistakes) was first investigated in <ref> [4, 3] </ref>. But these works only considered systems where process crashes are permanent and links are reliable (i.e., they do not lose messages). In real systems, however, processes may recover after crashing and links may lose messages. <p> For example, in the rotating coordinator consensus algorithms of <ref> [4, 5, 7] </ref> if a process kept suspecting all processes then consensus would never be reached. <p> This essentially reduces the problem to the case where process crashes are permanent and a majority of processes do not crash (and then an algorithm such as the one in <ref> [4] </ref> can be used). Is it possible to solve consensus without stable storage if 1 n a n=2? To answer this question, assume that in every execution of consensus at most n b processes are bad. <p> Prima facie, this seems to contradict the fact that if a majority of processes may crash then consensus cannot be solved even with 3P <ref> [4] </ref>. There is no contradiction, however, since [4] assumes that all process crashes are 4 An unstable process may fail to receive I am alive messages sent by other processes since all messages that arrive at a process while it is down are lost. permanent, while in our case some of <p> Prima facie, this seems to contradict the fact that if a majority of processes may crash then consensus cannot be solved even with 3P <ref> [4] </ref>. There is no contradiction, however, since [4] assumes that all process crashes are 4 An unstable process may fail to receive I am alive messages sent by other processes since all messages that arrive at a process while it is down are lost. permanent, while in our case some of the processes that crash do recover: even <p> In such runs, consensus is achieved within 3ffi time and with 4n messages, where ffi is the maxi mum message delay and n is the number of processes in the system. 5 If the good processes are not a majority, a simple partitioning argument as the one in <ref> [4] </ref> shows that consensus cannot be solved even with 3P. 1.5 Roadmap The paper is organized as follows. Our model is given in Section 2. <p> Although many algorithms are designed to tolerate such failure detector mistakes, the erroneous suspicions of some good processes may hurt the performance of these algorithms. For example, the erroneous suspicions of good coordinators can delay the termination of the consensus algorithms in <ref> [4, 5, 7, 9] </ref>. Thus, requiring Strong Completeness should be avoided if possible. <p> This algorithm, shown in Fig. 1, is based on the rotating coordinator paradigm <ref> [4] </ref> and uses 3S 0 e . It must deal with unstable processes and link failures. <p> It requires a majority of good processes and works in systems with lossy links. The basic structure of the algorithm (given in Fig. 3) is as in <ref> [4, 5] </ref> and consists of rounds of 4 phases each (task 4phases). In each round r, initially the coordinator c 10 It is not sufficient to use the restarting mechanism only for collecting ACKs: a symmetric ex ample shows that this mechanism must also be used for collecting estimates.
Reference: 5. <author> D. Dolev, R. Friedman, I. Keidar, and D. Malkhi. </author> <title> Failure detectors in omission failure environments. </title> <type> Technical Report 96-1608, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, New York, </address> <month> Sept. </month> <year> 1996. </year>
Reference-contexts: In real systems, however, processes may recover after crashing and links may lose messages. In this paper, we focus on solving consensus with failure detectors in such systems, a problem that was first considered in <ref> [5, 9, 7] </ref> (a brief comparison with these works is in Section 1.3). <p> Accuracy: Some good process is eventually trusted forever by all good processes, and its epoch number stops changing. 1 In fact, this property is assumed in [9, 7]. 2 In <ref> [5] </ref>, crash-recovery is regarded as a special case of omission failures, and the algorithm is not designed to handle unstable processes that can send and receive messages to and from good processes. 3 In such a system, processes execute in synchronized rounds, and all messages are received in the round they <p> For example, in the rotating coordinator consensus algorithms of <ref> [4, 5, 7] </ref> if a process kept suspecting all processes then consensus would never be reached. <p> losses, provided that links are fair lossy, i.e., if p sends messages to a good process q infinitely often, then q receives messages from p infinitely often. 1.3 Related Work The problem of solving consensus with failure detectors in systems where processes may recover from crashes was first addressed in <ref> [5] </ref> (with crash-recovery as a form of omission failures) and more recently studied in [9, 7]. <p> In <ref> [5, 7, 9] </ref>, the question of whether stable storage is always necessary is not addressed, and all the algorithms use stable storage: in [5, 9], the entire state of the algorithm is recorded into stable storage at every state transition; in [7], only a small part of the state is recorded, <p> In [5, 7, 9], the question of whether stable storage is always necessary is not addressed, and all the algorithms use stable storage: in <ref> [5, 9] </ref>, the entire state of the algorithm is recorded into stable storage at every state transition; in [7], only a small part of the state is recorded, and writing to stable storage is done at most once per round. <p> In the one that uses stable storage, only a small part of the state is recorded and this occurs twice per round. The algorithms in [9, 7] use failure detectors that require that unstable processes be eventually suspected forever. The algorithm in <ref> [5] </ref> is not designed to deal with unstable processes which may intermittently communicate with good ones. 1.4 Summary of Results We study the problems of failure detection and consensus in asynchronous systems with process crashes and recoveries, and lossy links. 1. <p> Although many algorithms are designed to tolerate such failure detector mistakes, the erroneous suspicions of some good processes may hurt the performance of these algorithms. For example, the erroneous suspicions of good coordinators can delay the termination of the consensus algorithms in <ref> [4, 5, 7, 9] </ref>. Thus, requiring Strong Completeness should be avoided if possible. <p> It requires a majority of good processes and works in systems with lossy links. The basic structure of the algorithm (given in Fig. 3) is as in <ref> [4, 5] </ref> and consists of rounds of 4 phases each (task 4phases). In each round r, initially the coordinator c 10 It is not sufficient to use the restarting mechanism only for collecting ACKs: a symmetric ex ample shows that this mechanism must also be used for collecting estimates.
Reference: 6. <author> R. Guerraoui, R. Oliveira, and A. Schiper. </author> <title> Stubborn communication channels. </title> <type> Technical report, </type> <institution> Departement d'Informatique, Ecole Polytechnique Federale, Lausanne, Switzerland, </institution> <month> Dec. </month> <year> 1996. </year>
Reference: 7. <author> M. Hurfin, A. Mostefaoui, and M. Raynal. </author> <title> Consensus in asynchronous systems where processes can crash and recover. </title> <type> Technical Report 1144, </type> <institution> Institut de Recherche en Informatique et Systemes Aleatoires, Universite de Rennes, </institution> <month> Nov. </month> <year> 1997. </year>
Reference-contexts: In real systems, however, processes may recover after crashing and links may lose messages. In this paper, we focus on solving consensus with failure detectors in such systems, a problem that was first considered in <ref> [5, 9, 7] </ref> (a brief comparison with these works is in Section 1.3). <p> We also need to determine if and when stable-storage is necessary. 1.1 Failure Detectors for the Crash-Recovery Model We first focus on the problem of failure detection in the crash-recovery model. Previous solutions require unstable processes to be eventually suspected forever <ref> [9, 7] </ref>. 2 We first prove that this requirement has a serious drawback: it forces failure detector implementations to have undesirable behaviors even in perfectly synchronous systems. More precisely, consider a synchronous round-based system with no message losses, 3 where up to n u processes may be unstable. <p> Accuracy: Some good process is eventually trusted forever by all good processes, and its epoch number stops changing. 1 In fact, this property is assumed in <ref> [9, 7] </ref>. 2 In [5], crash-recovery is regarded as a special case of omission failures, and the algorithm is not designed to handle unstable processes that can send and receive messages to and from good processes. 3 In such a system, processes execute in synchronized rounds, and all messages are received <p> For example, in the rotating coordinator consensus algorithms of <ref> [4, 5, 7] </ref> if a process kept suspecting all processes then consensus would never be reached. <p> good process q infinitely often, then q receives messages from p infinitely often. 1.3 Related Work The problem of solving consensus with failure detectors in systems where processes may recover from crashes was first addressed in [5] (with crash-recovery as a form of omission failures) and more recently studied in <ref> [9, 7] </ref>. <p> In <ref> [5, 7, 9] </ref>, the question of whether stable storage is always necessary is not addressed, and all the algorithms use stable storage: in [5, 9], the entire state of the algorithm is recorded into stable storage at every state transition; in [7], only a small part of the state is recorded, <p> In [5, 7, 9], the question of whether stable storage is always necessary is not addressed, and all the algorithms use stable storage: in [5, 9], the entire state of the algorithm is recorded into stable storage at every state transition; in <ref> [7] </ref>, only a small part of the state is recorded, and writing to stable storage is done at most once per round. In this paper, we determine when stable storage is necessary, and give two matching consensus algorithms with and without stable storage. <p> In this paper, we determine when stable storage is necessary, and give two matching consensus algorithms with and without stable storage. In the one that uses stable storage, only a small part of the state is recorded and this occurs twice per round. The algorithms in <ref> [9, 7] </ref> use failure detectors that require that unstable processes be eventually suspected forever. <p> Crash-Recovery Model In this section, we first consider the failure detectors that were previously proposed for solving consensus in the crash-recovery model, and then propose a new type of failure detector for this model. 3.1 Limitations of Existing Failure Detectors To solve consensus in the crash-recovery model, Hurfin et al. <ref> [7] </ref> and Oliveira et al. [9] assume that processes have failure detectors that output lists of processes suspected to be bad, and that these failure detectors satisfy the following property: Strong Completeness: Eventually every bad process is permanently suspected by all good processes. <p> Although many algorithms are designed to tolerate such failure detector mistakes, the erroneous suspicions of some good processes may hurt the performance of these algorithms. For example, the erroneous suspicions of good coordinators can delay the termination of the consensus algorithms in <ref> [4, 5, 7, 9] </ref>. Thus, requiring Strong Completeness should be avoided if possible. <p> Note that 3P is stronger than the other failure detectors in this paper and in <ref> [9, 7] </ref>. Theorem 2. If n a n b consensus cannot be solved without stable storage even in systems where there are no unstable processes, links do not lose messages, and processes can use 3P. <p> How does a rotating coordinator algorithm cope with an unstable coordinator? In <ref> [7, 9] </ref> the burden is entirely on the failure detector: it is postulated that every unstable process is eventually suspected forever. <p> In contrast, in nice executions the consensus algorithms of <ref> [7, 9] </ref> reach decision within 2ffi and with O (n 2 ) messages. 11 This is with the round 1 optimization in which the coordinator chooses its own estimate and sends it without waiting for estimates from other processes. 8.2 Quiescence An algorithm is quiescent if eventually all processes stop sending
Reference: 8. <author> G. Neiger and S. Toueg. </author> <title> Automatically increasing the fault-tolerance of distributed algorithms. </title> <journal> Journal of Algorithms, </journal> <volume> 11(3):374419, </volume> <year> 1990. </year>
Reference-contexts: The following properties must be satisfied: Uniform Validity: If a process decides v then some process previously proposed v. Agreement: Good processes do not decide different values. Termination: If all good processes propose a value, then they all eventually decide. A stronger version of consensus, called uniform consensus <ref> [8] </ref>, requires: Uniform Agreement: Processes do not decide different values. The above specification allows a process to decide more than once. However, with Agreement, a good process cannot decide two different values. Similarly, with Uniform Agreement, no process (whether good or bad) can decide two different values.
Reference: 9. <author> R. Oliveira, R. Guerraoui, and A. Schiper. </author> <title> Consensus in the crash-recover model. </title> <type> Technical Report 97-239, </type> <institution> Departement d'Informatique, Ecole Polytechnique Federale, Lausanne, Switzerland, </institution> <month> Aug. </month> <year> 1997. </year>
Reference-contexts: In real systems, however, processes may recover after crashing and links may lose messages. In this paper, we focus on solving consensus with failure detectors in such systems, a problem that was first considered in <ref> [5, 9, 7] </ref> (a brief comparison with these works is in Section 1.3). <p> We also need to determine if and when stable-storage is necessary. 1.1 Failure Detectors for the Crash-Recovery Model We first focus on the problem of failure detection in the crash-recovery model. Previous solutions require unstable processes to be eventually suspected forever <ref> [9, 7] </ref>. 2 We first prove that this requirement has a serious drawback: it forces failure detector implementations to have undesirable behaviors even in perfectly synchronous systems. More precisely, consider a synchronous round-based system with no message losses, 3 where up to n u processes may be unstable. <p> Accuracy: Some good process is eventually trusted forever by all good processes, and its epoch number stops changing. 1 In fact, this property is assumed in <ref> [9, 7] </ref>. 2 In [5], crash-recovery is regarded as a special case of omission failures, and the algorithm is not designed to handle unstable processes that can send and receive messages to and from good processes. 3 In such a system, processes execute in synchronized rounds, and all messages are received <p> good process q infinitely often, then q receives messages from p infinitely often. 1.3 Related Work The problem of solving consensus with failure detectors in systems where processes may recover from crashes was first addressed in [5] (with crash-recovery as a form of omission failures) and more recently studied in <ref> [9, 7] </ref>. <p> In <ref> [5, 7, 9] </ref>, the question of whether stable storage is always necessary is not addressed, and all the algorithms use stable storage: in [5, 9], the entire state of the algorithm is recorded into stable storage at every state transition; in [7], only a small part of the state is recorded, <p> In [5, 7, 9], the question of whether stable storage is always necessary is not addressed, and all the algorithms use stable storage: in <ref> [5, 9] </ref>, the entire state of the algorithm is recorded into stable storage at every state transition; in [7], only a small part of the state is recorded, and writing to stable storage is done at most once per round. <p> In this paper, we determine when stable storage is necessary, and give two matching consensus algorithms with and without stable storage. In the one that uses stable storage, only a small part of the state is recorded and this occurs twice per round. The algorithms in <ref> [9, 7] </ref> use failure detectors that require that unstable processes be eventually suspected forever. <p> we first consider the failure detectors that were previously proposed for solving consensus in the crash-recovery model, and then propose a new type of failure detector for this model. 3.1 Limitations of Existing Failure Detectors To solve consensus in the crash-recovery model, Hurfin et al. [7] and Oliveira et al. <ref> [9] </ref> assume that processes have failure detectors that output lists of processes suspected to be bad, and that these failure detectors satisfy the following property: Strong Completeness: Eventually every bad process is permanently suspected by all good processes. <p> Although many algorithms are designed to tolerate such failure detector mistakes, the erroneous suspicions of some good processes may hurt the performance of these algorithms. For example, the erroneous suspicions of good coordinators can delay the termination of the consensus algorithms in <ref> [4, 5, 7, 9] </ref>. Thus, requiring Strong Completeness should be avoided if possible. <p> Note that 3P is stronger than the other failure detectors in this paper and in <ref> [9, 7] </ref>. Theorem 2. If n a n b consensus cannot be solved without stable storage even in systems where there are no unstable processes, links do not lose messages, and processes can use 3P. <p> How does a rotating coordinator algorithm cope with an unstable coordinator? In <ref> [7, 9] </ref> the burden is entirely on the failure detector: it is postulated that every unstable process is eventually suspected forever. <p> In contrast, in nice executions the consensus algorithms of <ref> [7, 9] </ref> reach decision within 2ffi and with O (n 2 ) messages. 11 This is with the round 1 optimization in which the coordinator chooses its own estimate and sends it without waiting for estimates from other processes. 8.2 Quiescence An algorithm is quiescent if eventually all processes stop sending
References-found: 9

