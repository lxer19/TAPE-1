URL: http://www.dsv.su.se/~henke/MERLIN/ml96.ps
Refering-URL: http://www.dsv.su.se/~henke/MERLIN/MERLIN.html
Root-URL: 
Email: henke@dsv.su.se  
Title: Theory-Guided Induction of Logic Programs by Inference of Regular Languages recursive clauses. merlin on the
Author: Henrik Bostrom 
Note: producing the  be inferred from a single example.  
Address: Electrum 230, 164 40 Kista, Sweden  
Affiliation: Dept. of Computer and Systems Sciences Stockholm University  
Abstract: resent allowed sequences of resolution steps for the initial theory. There are, however, many characterizations of allowed sequences of resolution steps that cannot be expressed by a set of resolvents. One approach to this problem is presented, the system mer-lin, which is based on an earlier technique for learning finite-state automata that represent allowed sequences of resolution steps. merlin extends the previous technique in three ways: i) negative examples are considered in addition to positive examples, ii) a new strategy for performing generalization is used, and iii) a technique for converting the learned automaton to a logic program is included. Results from experiments are presented in which merlin outperforms both a system using the old strategy for performing generalization, and a traditional covering technique. The latter result can be explained by the limited expressiveness of hypotheses produced by covering and also by the fact that covering needs to produce the correct base clauses for a recursive definition before 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Angluin D., </author> <title> "Learning Regular Sets from Queries and Counterexamples", </title> <journal> Information and Computation, </journal> <volume> 75, </volume> <year> (1987) </year> <month> 87-106 </month>
Reference-contexts: There are a number of possible directions for future research. One is to investigate other techniques for inferring finite-state automata (e.g. <ref> [1] </ref>) and to evaluate them using merlin. Another direction is to extend the expressiveness by using context-free grammars instead of finite-state automata, which also is investigated in [8]. A third direction for future research is to investi gate how the computation rule affects the hypotheses produced by merlin.
Reference: [2] <author> Bar-Hillel Y., Perles M. and Shamir E., </author> <title> "On formal properties of simple phrase structure grammars", </title> <journal> Zeitschrift fur Phonetik, Sprachwissenschaft und Kommunikationsforschung, </journal> <volume> 14, 1, </volume> <publisher> Akademie Verlag, </publisher> <address> Berlin (1961) 143-172 </address>
Reference-contexts: Then the above procedure produces the following proof grammar (nat=1; R), where R is the following rules: nat=1 ! c1 2.2.2 Deriving the Intersection The intersection of a context-free language and a regular language is always a context-free language <ref> [2] </ref>. The following procedure for deriving a context-free grammar that represents the intersection of a proof grammar and a deterministic finite-state automaton is de rived from the algorithm in [2]. <p> ! c1 2.2.2 Deriving the Intersection The intersection of a context-free language and a regular language is always a context-free language <ref> [2] </ref>. The following procedure for deriving a context-free grammar that represents the intersection of a proof grammar and a deterministic finite-state automaton is de rived from the algorithm in [2].
Reference: [3] <author> Bergadano F. and Giordana A., </author> <title> "A Knowledge Intensive Approach to Concept Induction", </title> <booktitle> Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> CA (1988) 305-317 </address>
Reference-contexts: Several approaches to induction of logic programs search top-down from clauses in a theory (i.e. definite program 1 ) by specializing the clauses using literal addition (e.g. [14, 13, 18] 2 ) or resolution (e.g. [9, 10, 4, 7, 5, 6]) or both (e.g. <ref> [3, 16, 15] </ref>). In the previous approaches that use resolution only, the theory can be viewed as a declarative bias that restricts not only what predicate symbols can be used in learned clauses, but also how the predicates can be invoked.
Reference: [4] <author> Bergadano F. and Gunetti D. </author> <title> "Learning Clauses by Tracing Derivations", </title> <booktitle> Proceedings of the 4th International Workshop on Inductive Logic Programming, volume 237 of GMD-Studien, </booktitle> <institution> Gesellschaft fur Mathematik und Datenverarbeitung MBH (1994) 11-29 </institution>
Reference-contexts: Several approaches to induction of logic programs search top-down from clauses in a theory (i.e. definite program 1 ) by specializing the clauses using literal addition (e.g. [14, 13, 18] 2 ) or resolution (e.g. <ref> [9, 10, 4, 7, 5, 6] </ref>) or both (e.g. [3, 16, 15]). In the previous approaches that use resolution only, the theory can be viewed as a declarative bias that restricts not only what predicate symbols can be used in learned clauses, but also how the predicates can be invoked.
Reference: [5] <author> Bostrom H., </author> <title> "Specialization of Recursive Predicates", </title> <booktitle> Proceedings of the Eighth European Confer ence on Machine Learning, </booktitle> <month> Springer-Verlag </month> <year> (1995) </year> <month> 92-106 </month>
Reference-contexts: Several approaches to induction of logic programs search top-down from clauses in a theory (i.e. definite program 1 ) by specializing the clauses using literal addition (e.g. [14, 13, 18] 2 ) or resolution (e.g. <ref> [9, 10, 4, 7, 5, 6] </ref>) or both (e.g. [3, 16, 15]). In the previous approaches that use resolution only, the theory can be viewed as a declarative bias that restricts not only what predicate symbols can be used in learned clauses, but also how the predicates can be invoked.
Reference: [6] <author> Bostrom H., </author> <title> "Covering vs. Divide-and-Conquer for Top-Down Induction of Logic Programs", </title> <booktitle> Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann (1995) 1194-1200 </publisher>
Reference-contexts: Several approaches to induction of logic programs search top-down from clauses in a theory (i.e. definite program 1 ) by specializing the clauses using literal addition (e.g. [14, 13, 18] 2 ) or resolution (e.g. <ref> [9, 10, 4, 7, 5, 6] </ref>) or both (e.g. [3, 16, 15]). In the previous approaches that use resolution only, the theory can be viewed as a declarative bias that restricts not only what predicate symbols can be used in learned clauses, but also how the predicates can be invoked.
Reference: [7] <author> Bostrom H. and Idestam-Almquist P., </author> <title> "Specialization of Logic Programs by Pruning SLD-Trees", </title> <booktitle> Proceedings of the 4th International Workshop on Inductive Logic Programming, volume 237 of GMD-Studien, </booktitle> <institution> Gesellschaft fur Mathematik und Datenver-arbeitung MBH (1994) 31-48 </institution>
Reference-contexts: Several approaches to induction of logic programs search top-down from clauses in a theory (i.e. definite program 1 ) by specializing the clauses using literal addition (e.g. [14, 13, 18] 2 ) or resolution (e.g. <ref> [9, 10, 4, 7, 5, 6] </ref>) or both (e.g. [3, 16, 15]). In the previous approaches that use resolution only, the theory can be viewed as a declarative bias that restricts not only what predicate symbols can be used in learned clauses, but also how the predicates can be invoked. <p> In all experiments, the SLD-refutations of the examples were produced using the standard Prolog computation rule (i.e. to select the leftmost goal to resolve upon). However, as demon strated in <ref> [7] </ref>, the result of the learning procedure can be highly dependent on how the SLD-refutations are derived. Acknowledgements This work has been supported by the European Community ESPRIT Long Term Research Project Inductive Logic Programming II. The author thanks Peter Idestam-Almquist for valuable discussions.
Reference: [8] <author> Cohen W. W., </author> <title> "Generalizing Number and Learning from Multiple Examples in Explanation Based Learning", </title> <booktitle> Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <address> Morgan Kauf-mann (1988) 256-269 </address>
Reference-contexts: The reason for this is that a new predicate symbol is needed in order to express this, and such are never introduced when applying resolution. In this work, we present one approach to this problem, a system called merlin 3 . It is based upon the idea in <ref> [8] </ref> to learn finite-state automata that represent allowed sequences of resolution steps. In the next section, we show how the learning procedure presented in [8], which only handles positive examples 4 , can be slightly modified to deal with negative examples as well. <p> In this work, we present one approach to this problem, a system called merlin 3 . It is based upon the idea in <ref> [8] </ref> to learn finite-state automata that represent allowed sequences of resolution steps. In the next section, we show how the learning procedure presented in [8], which only handles positive examples 4 , can be slightly modified to deal with negative examples as well. Another extension to the technique, which has been included in merlin, is a novel strategy for performing generalization when producing the automaton. <p> We then show how the learned automaton is used in merlin to specialize the theory. 2.1 Regular Language Inference The basic idea in <ref> [8] </ref> is that sequences of input clauses in SLD-refutations can be viewed as strings in a formal language, which can be represented by a finite-state automaton. The learning procedure in [8] can be summarized 5 : i) construct an initial automaton from a given sequence, ii) repeat as long as possible: <p> how the learned automaton is used in merlin to specialize the theory. 2.1 Regular Language Inference The basic idea in <ref> [8] </ref> is that sequences of input clauses in SLD-refutations can be viewed as strings in a formal language, which can be represented by a finite-state automaton. The learning procedure in [8] can be summarized 5 : i) construct an initial automaton from a given sequence, ii) repeat as long as possible: merge two states that have out-going arcs labeled with the same symbol, and make the resulting automaton de 3 Model Extraction by Regular Language INference 4 The procedure was used <p> two states that have out-going arcs labeled with the same symbol, and make the resulting automaton de 3 Model Extraction by Regular Language INference 4 The procedure was used to learn recursive concepts in explanation-based learning. 5 We use ordinary automata [11] rather than the input output automata used in <ref> [8] </ref>. terministic. In [8] it is also shown how to handle multiple sequences: construct initial automata for the sequences, merge the start states, make the automaton deterministic and then apply step ii above. <p> have out-going arcs labeled with the same symbol, and make the resulting automaton de 3 Model Extraction by Regular Language INference 4 The procedure was used to learn recursive concepts in explanation-based learning. 5 We use ordinary automata [11] rather than the input output automata used in <ref> [8] </ref>. terministic. In [8] it is also shown how to handle multiple sequences: construct initial automata for the sequences, merge the start states, make the automaton deterministic and then apply step ii above. <p> Moreover, instead of just merging any of the mergeable states, as done in <ref> [8] </ref>, the merge that leads to the fewest number of positive arcs in the resulting deterministic automaton is chosen. Below, we first give a formal description of the learn ing procedure and then illustrate it with an example. <p> The main motivation for this new approach is that previous resolution-based approaches represent learned definitions as sets of resolvents of a given the ory, and many interesting concepts can not be represented in this way. The new approach is based on the technique in <ref> [8] </ref> to learn a finite-state automaton that represents sequences of allowed resolution steps. mer-lin extends the previous technique in three ways: i) negative examples are considered in addition to positive examples, ii) a new strategy for performing generalization is included, and iii) an inductive hypothesis is produced in the form of <p> There are a number of possible directions for future research. One is to investigate other techniques for inferring finite-state automata (e.g. [1]) and to evaluate them using merlin. Another direction is to extend the expressiveness by using context-free grammars instead of finite-state automata, which also is investigated in <ref> [8] </ref>. A third direction for future research is to investi gate how the computation rule affects the hypotheses produced by merlin. In all experiments, the SLD-refutations of the examples were produced using the standard Prolog computation rule (i.e. to select the leftmost goal to resolve upon).
Reference: [9] <author> Cohen W. W., </author> <title> "The Generality of Overgenerality", </title> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop, </booktitle> <publisher> Morgan Kaufmann (1991) 490-494 </publisher>
Reference-contexts: Several approaches to induction of logic programs search top-down from clauses in a theory (i.e. definite program 1 ) by specializing the clauses using literal addition (e.g. [14, 13, 18] 2 ) or resolution (e.g. <ref> [9, 10, 4, 7, 5, 6] </ref>) or both (e.g. [3, 16, 15]). In the previous approaches that use resolution only, the theory can be viewed as a declarative bias that restricts not only what predicate symbols can be used in learned clauses, but also how the predicates can be invoked.
Reference: [10] <author> Cohen W. W., </author> <title> "Compiling Prior Knowledge Into an Explicit Bias", </title> <booktitle> Machine Learning: Proceedings of the Ninth International Workshop, </booktitle> <address> Morgan Kauf-mann (1992) 102-110 </address>
Reference-contexts: Several approaches to induction of logic programs search top-down from clauses in a theory (i.e. definite program 1 ) by specializing the clauses using literal addition (e.g. [14, 13, 18] 2 ) or resolution (e.g. <ref> [9, 10, 4, 7, 5, 6] </ref>) or both (e.g. [3, 16, 15]). In the previous approaches that use resolution only, the theory can be viewed as a declarative bias that restricts not only what predicate symbols can be used in learned clauses, but also how the predicates can be invoked.
Reference: [11] <author> Lewis H. R. and Papadimitriou C. H., </author> <title> Elements of the Theory of Computation, </title> <publisher> Prentice-Hall (1981) </publisher>
Reference-contexts: given sequence, ii) repeat as long as possible: merge two states that have out-going arcs labeled with the same symbol, and make the resulting automaton de 3 Model Extraction by Regular Language INference 4 The procedure was used to learn recursive concepts in explanation-based learning. 5 We use ordinary automata <ref> [11] </ref> rather than the input output automata used in [8]. terministic. In [8] it is also shown how to handle multiple sequences: construct initial automata for the sequences, merge the start states, make the automaton deterministic and then apply step ii above.
Reference: [12] <author> Lloyd J. W., </author> <booktitle> Foundations of Logic Programming, (2nd edition), </booktitle> <publisher> Springer-Verlag (1987) </publisher>
Reference-contexts: All previous resolution-based approaches represent the identified sequences of resolution steps as a set of resol-vents of a given theory. However, there are many char 1 Familiarity with the standard terminology in logic programming is assumed <ref> [12] </ref>. 2 These systems may perform bottom-up search as well. acterizations of what sequences of resolution steps are allowed that cannot be expressed as sets of resolvents of the theory.
Reference: [13] <author> Mooney R. J. and Ourston D., </author> <title> "Constructive Induction in Theory Refinement", </title> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop, </booktitle> <publisher> Morgan Kaufmann (1991) 178-182 </publisher>
Reference-contexts: Several approaches to induction of logic programs search top-down from clauses in a theory (i.e. definite program 1 ) by specializing the clauses using literal addition (e.g. <ref> [14, 13, 18] </ref> 2 ) or resolution (e.g. [9, 10, 4, 7, 5, 6]) or both (e.g. [3, 16, 15]).
Reference: [14] <author> Ourston D. and Mooney R. J., </author> <title> "Changing the Rules: A Comprehensive Approach to Theory Refinement", </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <publisher> MIT Press (1990) 815-820 </publisher>
Reference-contexts: Several approaches to induction of logic programs search top-down from clauses in a theory (i.e. definite program 1 ) by specializing the clauses using literal addition (e.g. <ref> [14, 13, 18] </ref> 2 ) or resolution (e.g. [9, 10, 4, 7, 5, 6]) or both (e.g. [3, 16, 15]).
Reference: [15] <author> Pazzani M. and Brunk C., </author> <title> "Finding Accurate Frontiers: A Knowledge- Intensive Approach to Relational Learning", </title> <booktitle> Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann (1993) 328-334 </publisher>
Reference-contexts: Several approaches to induction of logic programs search top-down from clauses in a theory (i.e. definite program 1 ) by specializing the clauses using literal addition (e.g. [14, 13, 18] 2 ) or resolution (e.g. [9, 10, 4, 7, 5, 6]) or both (e.g. <ref> [3, 16, 15] </ref>). In the previous approaches that use resolution only, the theory can be viewed as a declarative bias that restricts not only what predicate symbols can be used in learned clauses, but also how the predicates can be invoked.
Reference: [16] <author> Pazzani M., Brunk C. and Silverstein G., </author> <title> "A Knowledge-Intensive Approach to Learning Relational Concepts", </title> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop, </booktitle> <address> Morgan Kauf-mann (1991) 432-436 </address>
Reference-contexts: Several approaches to induction of logic programs search top-down from clauses in a theory (i.e. definite program 1 ) by specializing the clauses using literal addition (e.g. [14, 13, 18] 2 ) or resolution (e.g. [9, 10, 4, 7, 5, 6]) or both (e.g. <ref> [3, 16, 15] </ref>). In the previous approaches that use resolution only, the theory can be viewed as a declarative bias that restricts not only what predicate symbols can be used in learned clauses, but also how the predicates can be invoked.
Reference: [17] <author> Quinlan J. R., </author> <title> "Learning Logical Definitions from Relations", </title> <note> Machine Learning 5 (1990) 239-266 </note>
Reference-contexts: It should be noted that the decision of what resolvent to choose is left unspecified in the procedure, and in our experiments the resolvent that maximizes the information gain (c.f. <ref> [17] </ref>) was chosen.
Reference: [18] <author> Richards B. L. and Mooney R. J., </author> <title> "First-Order Theory Revision", </title> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop, </booktitle> <publisher> Morgan Kaufmann (1991) 447-451 </publisher>
Reference-contexts: Several approaches to induction of logic programs search top-down from clauses in a theory (i.e. definite program 1 ) by specializing the clauses using literal addition (e.g. <ref> [14, 13, 18] </ref> 2 ) or resolution (e.g. [9, 10, 4, 7, 5, 6]) or both (e.g. [3, 16, 15]).
References-found: 18

