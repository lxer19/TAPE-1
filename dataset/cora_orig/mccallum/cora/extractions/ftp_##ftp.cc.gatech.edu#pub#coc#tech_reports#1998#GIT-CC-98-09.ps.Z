URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1998/GIT-CC-98-09.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.98.html
Root-URL: 
Email: jdixon@cc.gatech.edu calvert@cc.gatech.edu  
Title: Tuning TCP and UDP Demultiplexing  
Author: Joseph T. Dixon Kenneth L. Calvert 
Address: Atlanta, GA 30332  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract: Large servers that handle many hundreds of simultaneous clients are becoming more and more important to the Internetwork infrastructure, from Web servers and caches to DNS servers. As the number of clients simultaneously served by a host increases, so may the cost of demul-tiplexing incoming packets to the appropriate application endpoint. This paper explores the effect of caching and hashing on demultiplexing efficiency in TCP/IP implementations using a trace-driven approach. We compare several cache- and hash-based techniques using traffic traces that include mixes of different types of applications. Our results show that different techniques are effective for different types of server (e.g., UDP vs. TCP-based services, Web servers vs. NFS servers). In addition, we show that an extremely simple hash function provides performance comparable to more complex functions at a fraction of the cost and can also compare favorably with content addressable memory (CAM) search performance under certain conditions. Based on our results, we recommend certain simple and transparent strategies for optimizing performance.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Girish P. Chandranmenon and George Varghese, </author> <title> "Trading packet Headers for Packet Processing," </title> <type> SIGCOMM 95, </type> <year> 1995. </year>
Reference-contexts: Two techniques are well-known for improving the performance of this demultiplexing step: caching recently-accessed endpoints [2, 13, 11], and using a hash table to provide direct access to endpoints <ref> [9, 1] </ref>. However, the effectiveness of these techniques is dependent upon the characteristics of the traffic mix. <p> They leave the hashing function, assigned by the source, as an imple mentation option. This technique alters the network protocol. <ref> [1] </ref> * Huitema has proposed passing 32-bit PCB identification parameters as a TCP connect-time option, which yields O (1) lookup. [6] * Mentat, Inc.'s streams-implemented TCP/IP demultiplexes incoming packets in IP rather than TCP or UDP. [10] Our efforts differ in several important ways: (1) we establish clear boundaries on the <p> If the mask is m bits long, then we use the right-most m bits of identifier. Fletcher's Checksum Hash (cksum) Fletcher's checksum is used in the ISO/OSI transport protocol. Given an n-octet hash parameter b [0]:::b [n 1], a two-octet checksum C [0] and C <ref> [1] </ref> is computed as follows: [7] C [0] = C [1] = 0; C [0] = C [0] + b [i]; - The hash result is the 16-bit value C [0]C [1]. We mask the hash value to obtain less than 16-bit results. <p> Fletcher's Checksum Hash (cksum) Fletcher's checksum is used in the ISO/OSI transport protocol. Given an n-octet hash parameter b [0]:::b [n 1], a two-octet checksum C [0] and C <ref> [1] </ref> is computed as follows: [7] C [0] = C [1] = 0; C [0] = C [0] + b [i]; - The hash result is the 16-bit value C [0]C [1]. We mask the hash value to obtain less than 16-bit results. <p> Given an n-octet hash parameter b [0]:::b [n 1], a two-octet checksum C [0] and C <ref> [1] </ref> is computed as follows: [7] C [0] = C [1] = 0; C [0] = C [0] + b [i]; - The hash result is the 16-bit value C [0]C [1]. We mask the hash value to obtain less than 16-bit results. Xor-folding Hash (xfold) Xor-folding consists of an exclusive-or operation on the hash function parameter taken 16 bits at a time.
Reference: [2] <author> David D. Clark, Van Jacobson, John Romkey, and Howard Salwen, </author> <title> "An Analysis of TCP Processing Overhead," </title> <journal> IEEE Communications Magazine, </journal> <month> June, </month> <year> 1989. </year>
Reference-contexts: For such a server, the process of locating the "endpoint" (state information) relevant to each incoming packet can become a significant performance factor. Two techniques are well-known for improving the performance of this demultiplexing step: caching recently-accessed endpoints <ref> [2, 13, 11] </ref>, and using a hash table to provide direct access to endpoints [9, 1]. However, the effectiveness of these techniques is dependent upon the characteristics of the traffic mix. <p> to execute the demux function, given some information about the incoming stream of references from packets. 2.2 Related Work A number of researchers have investigated demultiplexing efficiency; relevant prior work includes: * Clark, et al, suggested that caching a pointer to the last referenced PCB yields a substantial performance benefit. <ref> [2] </ref> 4 * McKenney and Dove showed analytically that solutions combining caching with hashing is better than other well-known alternatives for on-line transaction processing systems. [9] * Partridge and Pink found that a single-entry cache had little effect on UDP lookups. [13] * Mogul investigated persistence and temporal locality at the
Reference: [3] <author> Joseph T. Dixon and Kenneth L. Calvert, </author> <title> "Increasing Demultiplexing Efficiency in TCP/IP Network Servers," </title> <address> ICCCN, </address> <month> October, </month> <year> 1996. </year> <note> (Georgia Tech TR #: GIT-CC-96-08 is a longer version.) </note>
Reference-contexts: These recommendations could be used, for example, in implementing an operating system with installation-configurable options to select a demultiplexing algorithm based on the type of traffic mix the server is expected to handle. Many of these results and recommendations have been presented in conference papers <ref> [3, 4] </ref> We also consider the benefits of hardware-assisted lookup of endpoints via content-addressable memories (CAMs). We develop a model of CAM-based demultiplexing and use it to compare performance with the best caching/hashing algorithms for a generic traffic mix. <p> One problem with cache solutions is that only fully-specified PCBs can be cached|otherwise there might be a better match. 2.3.3 Hashing and Combined Solutions McKenney and Dove first introduced and we later customized a demultiplexing algorithm that hashes incoming references to (smaller) linear lists <ref> [3, 9] </ref>. Each hash bin contains a linked list of PCBs and also has a pointer to the most recently referenced PCB found on that list. In these 7 solutions, demux first applies a hash function to the given reference to obtain a cache and a linked list.
Reference: [4] <author> Joseph T. Dixon and Kenneth L. Calvert, </author> <title> "Efficient Search Strategies for Application-Independent Speedup in UDP Demultiplexing," </title> <address> ICCCN, </address> <month> September, </month> <year> 1997. </year> <note> (Georgia Tech TR #: GIT-CC-97-02 is a longer version.) </note>
Reference-contexts: These recommendations could be used, for example, in implementing an operating system with installation-configurable options to select a demultiplexing algorithm based on the type of traffic mix the server is expected to handle. Many of these results and recommendations have been presented in conference papers <ref> [3, 4] </ref> We also consider the benefits of hardware-assisted lookup of endpoints via content-addressable memories (CAMs). We develop a model of CAM-based demultiplexing and use it to compare performance with the best caching/hashing algorithms for a generic traffic mix.
Reference: [5] <author> A. Gokhale and D. Schmidt, </author> <title> "Evaluating the Performance of Demultiplexing Strategies for Real-time CORBA," </title> <institution> Washington University, </institution> <note> Submitted to GLOBECOM 97, </note> <month> November, </month> <year> 1997. </year>
Reference-contexts: be configured as IP routers, may perform this operation frequently. [16] * ARP (Address Resolution Protocol) caches must be searched during network-to-link layer address resolution. [16] * Request/object demultiplexing in CORBA systems is crucial to CORBA's viability yet is notoriously inefficient (requiring as much as 17% of total processing time). <ref> [5] </ref> 34 * Recent packet filter advances (e.g., the Mach Packet Filter) require effective hash schemes. [17] The algorithms we have presented have straight-forward implementations: they use a simple logical-and operation as a hash and do not require an ordered information store.
Reference: [6] <author> Christian Huitema, </author> <type> "Multi-homed TCP - IETF Draft," </type> <institution> Network Working Group, </institution> <month> May, </month> <year> 1995. </year> <note> This is a work in progress. </note>
Reference-contexts: They leave the hashing function, assigned by the source, as an imple mentation option. This technique alters the network protocol. [1] * Huitema has proposed passing 32-bit PCB identification parameters as a TCP connect-time option, which yields O (1) lookup. <ref> [6] </ref> * Mentat, Inc.'s streams-implemented TCP/IP demultiplexes incoming packets in IP rather than TCP or UDP. [10] Our efforts differ in several important ways: (1) we establish clear boundaries on the best use of caching alone and in combination with hashing; (2) our analysis is based on traces of packets 5
Reference: [7] <author> Raj Jain, </author> <title> "A Comparison of Hashing Schemes for Address Lookup in Computer Networks," </title> <journal> IEEE Transactions on Communications, </journal> <month> October, </month> <year> 1992. </year>
Reference-contexts: He showed that both Fletcher's checksum and xor-folding, which we analyze in this paper, are effective hash functions. <ref> [7] </ref> * Chandranmenon and Varghese proposed source hashing, a technique that can provide O (1) expected lookup costs. They leave the hashing function, assigned by the source, as an imple mentation option. <p> We now formally analyze the performance behavior of modulo hash, Fletcher's checksum, and exclusive-or folding. We chose the latter two hash functions because (1) they are widely accepted and (2) Jain showed that each works well in network address lookups <ref> [7] </ref>. 7.1 Hashing Functions A hashing scheme is a partitioning technique: a single, potentially large store is divided into smaller stores, each of which is less costly to search than the single larger store. <p> Fletcher's Checksum Hash (cksum) Fletcher's checksum is used in the ISO/OSI transport protocol. Given an n-octet hash parameter b [0]:::b [n 1], a two-octet checksum C [0] and C [1] is computed as follows: <ref> [7] </ref> C [0] = C [1] = 0; C [0] = C [0] + b [i]; - The hash result is the 16-bit value C [0]C [1]. We mask the hash value to obtain less than 16-bit results.
Reference: [8] <author> Raj Jain, </author> <title> "Characteristics of Destination Address Locality in Computer Networks: A Comparison of Caching Schemes", </title> <type> Technical Report Number DEC-TR-592, </type> <institution> Digital Equipment Corporation, </institution> <year> 1990. </year> <month> 35 </month>
Reference: [9] <author> Paul E. McKenney and Ken F. Dove, </author> <title> "Efficient Demultiplexing of Incoming TCP Packets," </title> <booktitle> ACM SIGCOMM 92, </booktitle> <month> August, </month> <year> 1992. </year>
Reference-contexts: Two techniques are well-known for improving the performance of this demultiplexing step: caching recently-accessed endpoints [2, 13, 11], and using a hash table to provide direct access to endpoints <ref> [9, 1] </ref>. However, the effectiveness of these techniques is dependent upon the characteristics of the traffic mix. <p> demultiplexing efficiency; relevant prior work includes: * Clark, et al, suggested that caching a pointer to the last referenced PCB yields a substantial performance benefit. [2] 4 * McKenney and Dove showed analytically that solutions combining caching with hashing is better than other well-known alternatives for on-line transaction processing systems. <ref> [9] </ref> * Partridge and Pink found that a single-entry cache had little effect on UDP lookups. [13] * Mogul investigated persistence and temporal locality at the process level, and suggested that a last-sent PCB cache might result in UDP demultiplexing speedup. [11] * Jain compared hashing schemes for an ordered address <p> One problem with cache solutions is that only fully-specified PCBs can be cached|otherwise there might be a better match. 2.3.3 Hashing and Combined Solutions McKenney and Dove first introduced and we later customized a demultiplexing algorithm that hashes incoming references to (smaller) linear lists <ref> [3, 9] </ref>. Each hash bin contains a linked list of PCBs and also has a pointer to the most recently referenced PCB found on that list. In these 7 solutions, demux first applies a hash function to the given reference to obtain a cache and a linked list.
Reference: [10] <author> Mentat, Inc., </author> <title> "Mentat TCP/IP Design Overview" Extracted from Mentat TCP/IP Internals Manual. Mentat, </title> <publisher> Inc., </publisher> <address> Los Angeles, CA., </address> <month> July, </month> <year> 1993. </year>
Reference-contexts: This technique alters the network protocol. [1] * Huitema has proposed passing 32-bit PCB identification parameters as a TCP connect-time option, which yields O (1) lookup. [6] * Mentat, Inc.'s streams-implemented TCP/IP demultiplexes incoming packets in IP rather than TCP or UDP. <ref> [10] </ref> Our efforts differ in several important ways: (1) we establish clear boundaries on the best use of caching alone and in combination with hashing; (2) our analysis is based on traces of packets 5 arriving at actual network servers; (3) we make several concrete recommendations for simple, server-independent modifications.
Reference: [11] <author> Jeffrey C. Mogul, </author> <title> "Network Locality at the Scale of Processes," </title> <journal> ACM Transactions on Computer Systems, </journal> <month> May, </month> <year> 1992. </year>
Reference-contexts: For such a server, the process of locating the "endpoint" (state information) relevant to each incoming packet can become a significant performance factor. Two techniques are well-known for improving the performance of this demultiplexing step: caching recently-accessed endpoints <ref> [2, 13, 11] </ref>, and using a hash table to provide direct access to endpoints [9, 1]. However, the effectiveness of these techniques is dependent upon the characteristics of the traffic mix. <p> than other well-known alternatives for on-line transaction processing systems. [9] * Partridge and Pink found that a single-entry cache had little effect on UDP lookups. [13] * Mogul investigated persistence and temporal locality at the process level, and suggested that a last-sent PCB cache might result in UDP demultiplexing speedup. <ref> [11] </ref> * Jain compared hashing schemes for an ordered address store, and suggested guidelines for determining hash mask sizes required to achieve a specified performance level.
Reference: [12] <author> Music Semiconductors, </author> <title> Application Note AB-N6, What is a CAM?, Music Semiconductors, </title> <note> www.music.com, 1997. </note>
Reference-contexts: A priority encoder sorts out which matching location has the top priority, if there is more than one, and makes the address of the matching location available. <ref> [12] </ref> Thus, CAM can be used to implement a fully-associative cache that returns an endpoint structure pointer when the endpoint's identifier is supplied (assuming each CAM data entry has an associated endpoint structure pointer), thus exploiting endpoint reference locality found in the arriving datagram stream. <p> Though similar to software-based caching strategies, a CAM has several distinctive properties <ref> [12] </ref>: * CAM is highly parallel (i.e., All CAM entries can be examined in a single comparison.) * CAM cache management is functionally independent from and can execute in parallel with a system's main processor. * When the set of possible referenced endpoints is small enough to fit entirely in the
Reference: [13] <author> Craig Partridge and Stephen Pink, </author> <title> "A Faster UDP," </title> <journal> IEEE/ACM Transactions on Networking, </journal> <month> July, </month> <year> 1993. </year>
Reference-contexts: For such a server, the process of locating the "endpoint" (state information) relevant to each incoming packet can become a significant performance factor. Two techniques are well-known for improving the performance of this demultiplexing step: caching recently-accessed endpoints <ref> [2, 13, 11] </ref>, and using a hash table to provide direct access to endpoints [9, 1]. However, the effectiveness of these techniques is dependent upon the characteristics of the traffic mix. <p> the last referenced PCB yields a substantial performance benefit. [2] 4 * McKenney and Dove showed analytically that solutions combining caching with hashing is better than other well-known alternatives for on-line transaction processing systems. [9] * Partridge and Pink found that a single-entry cache had little effect on UDP lookups. <ref> [13] </ref> * Mogul investigated persistence and temporal locality at the process level, and suggested that a last-sent PCB cache might result in UDP demultiplexing speedup. [11] * Jain compared hashing schemes for an ordered address store, and suggested guidelines for determining hash mask sizes required to achieve a specified performance level. <p> performance gain leads to a more general question: what are the limits to cache effectiveness? In the past, some researchers have suggested that there is little or no benefit (mainly due to cache management overhead) in using more than one cache entry to directly reference PCBs for incoming packets (e.g., <ref> [13] </ref>). Table 2 compares the mean number of instructions executed per TCP PCB lookup for the in pcblookup, BSD 4.3-Reno algorithm, and the 2-entry cache algorithms. <p> We did not simulate this method for TCP.) 5 Simulation Results: UDP Demultiplexing 5.1 Cache-enhanced linear search can add cost to UDP demultiplexing. We expected the cached PCB pointer to be ineffective for three reasons: * The one-behind cache saves a linear list search only for cached fully-specified PCBs. <ref> [13] </ref> * Wildcard PCBs are typical for UDP. <p> While informal, this approach puts demultiplexing speedup in the overall packet processing context. For example, Partridge and Pink showed that the checksum calculation (in cksum in Net/3) accounted for 8.4% of total IP and UDP packet processing time for a 512-byte UDP datagram. <ref> [13] </ref> This includes four in cksum invocations (for the IP header and the entire datagram on send and receive.) Our experiments show that, when optimally compiled on a SPARC architecture, the four in cksum invocations require 1680 assembly language instructions to process a 512-byte UDP datagram. 4 Therefore, if we assume
Reference: [14] <editor> Hal Stern Managing NFS and NIS, </editor> <publisher> O'Reilly and Associates, Inc., </publisher> <year> 1992. </year>
Reference-contexts: While more hash bins may yield small increments in performance gain, one must keep in mind that such structures reside in the system kernel: a large number of hash bins may degrade memory and/or instruction cache behavior. <ref> [14] </ref> 4.7 When using a hashing scheme, wildcard TCP PCBs can be effectively man aged on a separate list.
Reference: [15] <author> Marcel Waldvogel, George Varghese, Jon Turner, Bernhard Plattner, </author> <title> "Scalable High Speed IP Routing Lookups", </title> <booktitle> Proceedings of SIGCOMM, </booktitle> <year> 1997. </year>
Reference-contexts: However, an attractive hardware-based alternative exists: content addressable memory (CAM). Many applications that use CAM have shown that it can also substantially speed up search (e.g., high-end IP routers.) <ref> [15] </ref> That both approaches are effective leads to an obvious question: how do the two compare? In this section, we develop a simple model that allows us to analyze CAM effectiveness for the demultiplexing problem that we've already presented.
Reference: [16] <author> Gary R. Wright and W. Richard Stevens, </author> <title> TCP/IP Illustrated, </title> <booktitle> Volume 2: The Implementation, </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1995. </year>
Reference-contexts: Thus, we obtain the overall packet processing speedups shown in Table 10. 3 The precedent is already set: Net/3 and SunOS 4.X demultiplex arriving multicast and broadcast packets using an in-line while-loop rather than a function call. <ref> [16] </ref> 4 A single 20-byte IP header checksum calculation required 87 instructions while the 512-byte UDP datagram checksum required 753 unstructions. <p> The hashing strategy we have presented can be employed in other protocol processing searches. For example, * An endpoint search is performed whenever an application requests a communication instance. A communication endpoint is granted to a network application only if a unique endpoint can be assigned. <ref> [16] </ref> * Route stores must be searched for valid forwarding addresses. Multi-homed hosts, which may be configured as IP routers, may perform this operation frequently. [16] * ARP (Address Resolution Protocol) caches must be searched during network-to-link layer address resolution. [16] * Request/object demultiplexing in CORBA systems is crucial to CORBA's <p> A communication endpoint is granted to a network application only if a unique endpoint can be assigned. <ref> [16] </ref> * Route stores must be searched for valid forwarding addresses. Multi-homed hosts, which may be configured as IP routers, may perform this operation frequently. [16] * ARP (Address Resolution Protocol) caches must be searched during network-to-link layer address resolution. [16] * Request/object demultiplexing in CORBA systems is crucial to CORBA's viability yet is notoriously inefficient (requiring as much as 17% of total processing time). [5] 34 * Recent packet filter advances (e.g., the Mach Packet <p> network application only if a unique endpoint can be assigned. <ref> [16] </ref> * Route stores must be searched for valid forwarding addresses. Multi-homed hosts, which may be configured as IP routers, may perform this operation frequently. [16] * ARP (Address Resolution Protocol) caches must be searched during network-to-link layer address resolution. [16] * Request/object demultiplexing in CORBA systems is crucial to CORBA's viability yet is notoriously inefficient (requiring as much as 17% of total processing time). [5] 34 * Recent packet filter advances (e.g., the Mach Packet Filter) require effective hash schemes. [17] The algorithms we have presented have straight-forward implementations: they
Reference: [17] <author> M. Yuhara, B. Bershad, C. Maeda, and E. Moss, </author> <title> "Efficient Packet Demultiplexing for Multiple Endpoints and Large Messages," </title> <booktitle> Proceedings of the Winter Usenix Conference, </booktitle> <month> January, </month> <year> 1994. </year> <month> 36 </month>
Reference-contexts: caches must be searched during network-to-link layer address resolution. [16] * Request/object demultiplexing in CORBA systems is crucial to CORBA's viability yet is notoriously inefficient (requiring as much as 17% of total processing time). [5] 34 * Recent packet filter advances (e.g., the Mach Packet Filter) require effective hash schemes. <ref> [17] </ref> The algorithms we have presented have straight-forward implementations: they use a simple logical-and operation as a hash and do not require an ordered information store. In addition, their implementations affect only the local host; no protocol modifications are required.
References-found: 17

