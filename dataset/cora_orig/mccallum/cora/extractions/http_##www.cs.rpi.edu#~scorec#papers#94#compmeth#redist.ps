URL: http://www.cs.rpi.edu/~scorec/papers/94/compmeth/redist.ps
Refering-URL: http://www.cs.rpi.edu/~scorec/papers/94/papers.html
Root-URL: http://www.cs.rpi.edu
Title: Parallel Adaptive Mesh Refinement and Redistribution on Distributed Memory Computers  
Author: C. Ozturan, H. L. deCougny, M. S. Shephard, J.E. Flaherty 
Address: Troy, NY 12181  
Affiliation: Scientific Computation Research Center Rensselaer Polytechnic Institute  
Abstract: A procedure to support parallel refinement and redistribution of two dimensional unstructured finite element meshes on distributed memory computers is presented. The procedure uses the mesh topological entity hierarchy as the underlying data structures to easily support the required adjacency information. Mesh refinement is done by employing links back to the geometric representation to place new nodes on the boundary of the domain directly on the curved geometry. The refined mesh is then redistributed by an iterative heuristic based on the Leiss/Reddy [9] load balancing criteria. A fast parallel tree edge-coloring algorithm is used to pair processors having adjacent partitions and forming a tree structure as a result of Leiss/Reddy load request criteria. Excess elements are iteratively migrated from heavily loaded to less loaded processors until load balancing is achieved. The system is implemented on a massively parallel MasPar MP-2 system with a SIMD style of computation and uses message passing primitives to migrate elements during the mesh redistribution phase. Performance results of the redistribution heuristics on various test meshes are given. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. E. Bank and A. H. Sherman. </author> <title> An adaptive multi-level method for elliptic boundary value problems. </title> <journal> Computing, </journal> <volume> 26 </volume> <pages> 91-105, </pages> <year> 1981. </year>
Reference-contexts: Each mesh face can have from zero to three marked mesh edges. For each possible configuration, a template has been defined [18] as shown in Figure 2: 1. 1-edge: the triangle is divided into two (also known as a green subdivision <ref> [1] </ref>). 2. 2-edge: the triangle is divided into three. In this case, there is always a choice between two subdivisions. In order to limit element quality degradation, the cut along longest edge is performed first [12]. 3. 3-edge: the triangle is subdivided into four. <p> In order to limit element quality degradation, the cut along longest edge is performed first [12]. 3. 3-edge: the triangle is subdivided into four. For simplicity, the subdivision that produces 4 triangles similar to the parent is chosen (also known as a regular subdivision <ref> [1] </ref>). Elements are subdivided by traversing the list of mesh faces known by the processor in parallel. Once all mesh faces have been visited, mesh edges resulting from refinement on a partition boundary are linked to their identical duplicates on the neighboring partition.
Reference: [2] <author> M. J. Berger and S. H. Bokhari. </author> <title> A partitioning strategy for nonuniform problems on multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(5):570-580, </volume> <month> May </month> <year> 1987. </year>
Reference-contexts: Recursive Bisection (RB) Techniques which repeatedly split the mesh into two-submeshes. Coordinate RB methods bisect the elements by their spatial coordinates. If the axis of bisection is Cartesian, then it is called Orthogonal RB <ref> [2] </ref>. If the axes are chosen to be along the principal axis of the moment of inertia matrix, then it is called Moment RB. <p> Hence the general router communication was chosen in the implementation. Four test cases involving meshes on a square and an irregular curved boundary were run. Starting with a coarse mesh, ORB method <ref> [2] </ref> was used to get an initial partition sequentially. The partitioned mesh was then mapped onto the processors and refined selectively in parallel to create imbalanced processor loads. The square mesh was refined in one corner to create a 'plateau' of high load distribution.
Reference: [3] <author> S.H. Bokhari, T.W. Crockett, and D. M. Nicol. </author> <title> Parametric binary dissection. </title> <type> Technical Report ICASE 93-39, </type> <institution> ICASE, NASA Langley Res. Ctr.,Hampton, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: RB methods can handle the heterogenous load distributions on each element by assigning weights to each element. Recent efforts incorporate the communication costs into the ORB method by considering the weights on the cut edges of the split domains <ref> [3] </ref>. RB methods applied globally on the whole mesh are too costly to be used repeatedly to redistribute a 2 mesh dynamically with an adaptive technique. They may however, offer their advantages if applied locally to the incrementally altered mesh [17].
Reference: [4] <author> K.D. Devine, J.E. Flaherty, S. R. Wheat, and A. B. Maccabe. </author> <title> A massively parallel adaptive finite element method with dynamic load balancing. </title> <type> Technical Report SAND 93-0936C, </type> <institution> Sandia National Labs, </institution> <address> Albuquerque, </address> <year> 1993. </year>
Reference-contexts: To avoid this problem with the Leiss/Reddy approach while keeping H = 1, two modifications are made to handle the case when the load difference between the neighboring processors is C. Unlike <ref> [4] </ref> which sends at most b (L 0 L i )=2c and considers the L 0 L i = 1 as balanced, the current procedure exchanges the excess load as given in Eq (2) even if the GIM B will remain the same.
Reference: [5] <author> M. Fiedler. </author> <title> Algebraic connectivity of graphs. </title> <journal> Czechoslovak Math. J., </journal> <volume> 23 </volume> <pages> 298-305, </pages> <year> 1973. </year>
Reference-contexts: If the axes are chosen to be along the principal axis of the moment of inertia matrix, then it is called Moment RB. Spectral RB is another method which utilizes the properties of the Laplacian matrix <ref> [5] </ref> of the mesh connectivity graph and bisects it according to the eigenvector corresponding to the second smallest eigenvalue of this matrix [11]. 2. Probabilistic Methods which include simulated annealing and genetic algorithms.
Reference: [6] <author> J.E. Flaherty, P.J. Paslow, </author> <title> M.S. Shephard, </title> <editor> and J.D. Vasilakis, editors. </editor> <title> Adaptive Methods for Partial Differential Equations. </title> <booktitle> SIAM Proceedings Series, </booktitle> <address> Philadelphia, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction Adaptive finite element methods, driven by automatic estimation and control of errors have gained importance recently due to their ability to offer reliable solutions to partial differential equations <ref> [6] </ref>. An adaptive method starts with a solution on a coarse mesh using a low-order method and, based on an estimate of the global and local errors, either refines the mesh (h-refinement) and/or increases the order of numerical solution (p-refinement).
Reference: [7] <author> S. W. Hammond. </author> <title> Mapping Unstructured Grid Computations to Massively Parallel Computers. </title> <type> PhD thesis, </type> <institution> Computer Science Dept., Rensselaer Polytechnic Institue, Troy, </institution> <year> 1991. </year>
Reference-contexts: Iterative Local Migration Techniques exchange load between neighboring processors to improve the load balance and/or decrease the communication volume. The definition of processor neighborhood can either be the hardware link or the connectivity of the split domains. The Cyclic pairwise exchange <ref> [7] </ref> pairs processors connected by a hardware link and exchanges the nodes of the mesh to improve the communication. Leiss/Reddy on the other hand uses the hardware link as the neighborhood to transfer work from heavily loaded to less loaded processors. <p> It is based on the Leiss/Reddy [9] algorithm and employs selection criteria similar to Wheat et al. [20] in transferring elements. Unlike, these approaches, however, the processors are paired during load transfers similar to the pairwise exchange heuristic used by Hammond <ref> [7] </ref>.
Reference: [8] <author> J. JaJa. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, </address> <year> 1992. </year>
Reference-contexts: Criteria for this step are given with convergence criteria in Section 5.3. * Steps 56: To facilitate efficient parallel scan operations on the trees T i , each tree is linearized by constructing an Euler Tour on it. The details of the Euler Tour construction can be found in <ref> [8] </ref>. In the present implementation, each processor stores the links to its adjacent processors; hence, this list is traversed and local addresses sent to the adjacent processors. The received messages are sorted and the links stored.
Reference: [9] <author> E. Leiss and H. Reddy. </author> <title> Distributed load balancing: Design and performance analysis. </title> <editor> W. M. </editor> <booktitle> Keck Research Computation Laboratory, </booktitle> <volume> 5 </volume> <pages> 205-270, </pages> <year> 1989. </year>
Reference-contexts: Hence, they should be advantageous for use with adaptive techniques. The redistribution strategy given here is an iterative local migration scheme. It is based on the Leiss/Reddy <ref> [9] </ref> algorithm and employs selection criteria similar to Wheat et al. [20] in transferring elements. Unlike, these approaches, however, the processors are paired during load transfers similar to the pairwise exchange heuristic used by Hammond [7]. <p> This, in turn, results in a higher surface to volume ratio which increases communication cost. Figure 3 (b) shows the partition graph obtained from the mesh distribution in 3 (a). Following Leiss/Reddy <ref> [9] </ref>, a workload deficient processor will request work from its most heavily loaded neighbor. As a result, a processor can receive multiple requests but can only request load from one processor. <p> This step takes (G P ) time. * Step 3: The Leiss/Reddy <ref> [9] </ref> load request process is invoked and results in the forest of trees T i . The edges of G p is simply marked when a request has been made indicating whether or not it is a tree edge. <p> in a finite number of steps. * Oscillations: There should not be any indefinite cycles (repeating load transfer patterns) while the system is imbalanced. 13 L L 1 L m i r r 5090 90 sender receivers sender receivers send=2 send=13 send=2 (a) (b) r =5 r =5 1 Leiss/Reddy <ref> [9] </ref> prove the following results in [9]. Let an H neighborhood denote the neighbors of a processor within a distance of H, C denote the load treshold value. If elements are taken as load units, then C = 1. <p> * Oscillations: There should not be any indefinite cycles (repeating load transfer patterns) while the system is imbalanced. 13 L L 1 L m i r r 5090 90 sender receivers sender receivers send=2 send=13 send=2 (a) (b) r =5 r =5 1 Leiss/Reddy <ref> [9] </ref> prove the following results in [9]. Let an H neighborhood denote the neighbors of a processor within a distance of H, C denote the load treshold value. If elements are taken as load units, then C = 1.
Reference: [10] <author> R. Lohner and R. Ramamurti. </author> <title> A parallelizable load balancing algorithm. </title> <booktitle> In Proc. of the AIAA 31st Aerospace Sciences Meeting and Exhibit, </booktitle> <address> Reno, </address> <year> 1993. </year>
Reference-contexts: Leiss/Reddy on the other hand uses the hardware link as the neighborhood to transfer work from heavily loaded to less loaded processors. The Tiling algorithm [4][20] extends the Leiss/Reddy algorithm to the case where the neighborhood is defined by the connectivity of the split domains. Lohner et al. <ref> [10] </ref> algorithm exchange elements between subdomains according to a deficit difference function which reflects the imbalance between an element and its neighbors. Adaptive methods refine the mesh incrementally and hence require periodic redistribution of finite elements. <p> Consider one of the element movement criteria proposed by Lohner <ref> [10] </ref> as shown in Figure 7. To prevent noisy partition boundaries in (b), elements surrounding one of the vertices of the boundary edge are transferred as shown in (c). This approach however may pose problems with p-refinement.
Reference: [11] <author> A. Pothen, H. Simon, and K. Liou. </author> <title> Partitioning sparse matrices with eigenvectors of graphs. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 11(3) </volume> <pages> 430-452, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Spectral RB is another method which utilizes the properties of the Laplacian matrix [5] of the mesh connectivity graph and bisects it according to the eigenvector corresponding to the second smallest eigenvalue of this matrix <ref> [11] </ref>. 2. Probabilistic Methods which include simulated annealing and genetic algorithms. These methods however require many iterations and are expensive to use as mesh partitioning meth ods [21]. 3. Iterative Local Migration Techniques exchange load between neighboring processors to improve the load balance and/or decrease the communication volume.
Reference: [12] <author> Maria-Cecilia Rivara. </author> <title> Algorithms for refining triangular grids suitable for adaptive and multigrid techniques. </title> <journal> International Journal for Numerical Methods in Engineering, </journal> <volume> 20 </volume> <pages> 745-756, </pages> <year> 1984. </year>
Reference-contexts: In this case, there is always a choice between two subdivisions. In order to limit element quality degradation, the cut along longest edge is performed first <ref> [12] </ref>. 3. 3-edge: the triangle is subdivided into four. For simplicity, the subdivision that produces 4 triangles similar to the parent is chosen (also known as a regular subdivision [1]). Elements are subdivided by traversing the list of mesh faces known by the processor in parallel.
Reference: [13] <editor> M.S. Shephard and M.K Georges. </editor> <title> Automatic three-dimensional mesh generation by the finite octree technique. </title> <journal> Int. J. Numer. Meth. Engng, </journal> <volume> 32 </volume> <pages> 709-749, </pages> <year> 1991. </year>
Reference-contexts: The current procedure operates on the triangular unstructured meshes generated by the shell capability of the Finite Octree procedure <ref> [13] </ref>. The data structure used in this mesh generator is the complete mesh topological entity hierarchy [19] which provide a two-way link between the mesh entities of consecutive order, i.e., regions, faces, edges, and vertices.
Reference: [14] <author> B.A. Szabo and I. Babuska. </author> <title> Introduction to Finite Element Analysis. </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: It is quite clear that h-refinement benefits from a complete hierarchy to delete and create mesh entities efficiently. The presence of a complete hierarchy is also very useful with the p-version of the finite element method, since it easy to attach the edge and interior modes <ref> [14] </ref> to the mesh entities. Additionally, mesh entities are explicitly classified against the geometric model describing the domain boundary.
Reference: [15] <author> B. K. Szymanski and A. Minczuk. </author> <title> A representation of a distribution power network graph. </title> <journal> Archiwum Elek-trotechniki, </journal> <volume> 27(2) </volume> <pages> 367-380, </pages> <year> 1978. </year>
Reference-contexts: initial lemma is stated about the summation in a subtree of the weights assigned by the coloring algorithm and then this lemma is used to establish the correctness of the coloring algorithm. 1 A recent suggestion by Szymanski to use the depth first traversal links as has been used in <ref> [15] </ref> enables to get an O (max i flog jV i jg) for the parallel scanning step. 8 Tree Edge Coloring Algorithm: Input: A tree T with an Euler Tour T Euler defined on it. Output: Edge coloring of the tree on forward edges. 1.
Reference: [16] <author> V.G. Vizing. </author> <title> On an estimate of a chromatic class of a multigraph. </title> <booktitle> In Proc. Third Siberian Conf. on Mathematics and Mechanics, </booktitle> <address> Tomsk, </address> <year> 1964. </year>
Reference-contexts: Since there is no explicit synchronization by edge coloring in [20], this approach would make implementation of this bidirectional transfer of load extremely difficult. the maximum vertex degree (number of edges incident on a vertex) in a graph G, then Vizing's theorem <ref> [16] </ref> shows that the graph G can be edge-colored using C colors where (G) C (G) + 1. For some special graphs including the trees the number of colors needed is exactly (G). Therefore, (T i ) colors are required to color the tree T i .
Reference: [17] <author> C. Walshaw and M. Berzins. </author> <title> Dynamic load-balancing for pde solvers on adaptive unstructured meshes. </title> <type> Technical Report Preprint, </type> <institution> School of Computer Studies, University of Leeds, Leeds, </institution> <year> 1992. </year>
Reference-contexts: RB methods applied globally on the whole mesh are too costly to be used repeatedly to redistribute a 2 mesh dynamically with an adaptive technique. They may however, offer their advantages if applied locally to the incrementally altered mesh <ref> [17] </ref>. Iterative local migration techniques offer important advantages with an adaptive technique. Since these methods perform local transfers, incremental changes in the mesh can be propagated to the processors to load balance and reduce communication volume without solving an expensive global partitioning problem.
Reference: [18] <author> B. E. Webster, M. S. Shephard, and Z. Rusak. </author> <title> Unsteady compressible airfoil aerodynamics using an automated adaptive finite element method. </title> <journal> AHS Journal, </journal> <note> Submitted, </note> <year> 1993. </year>
Reference-contexts: Duplicate mesh edges on partition boundaries must be marked identically. Each mesh face can have from zero to three marked mesh edges. For each possible configuration, a template has been defined <ref> [18] </ref> as shown in Figure 2: 1. 1-edge: the triangle is divided into two (also known as a green subdivision [1]). 2. 2-edge: the triangle is divided into three. In this case, there is always a choice between two subdivisions.
Reference: [19] <author> K. J. Weiler. </author> <title> Edge based data structures for solid modeling in curved-surface environments. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 5(2), </volume> <year> 1985. </year>
Reference-contexts: The current procedure operates on the triangular unstructured meshes generated by the shell capability of the Finite Octree procedure [13]. The data structure used in this mesh generator is the complete mesh topological entity hierarchy <ref> [19] </ref> which provide a two-way link between the mesh entities of consecutive order, i.e., regions, faces, edges, and vertices. Although this hierarchical data structure requires more memory than classic finite element data structures (e.g., element-node relationship), it has proven to be powerful especially in the context of refinement.
Reference: [20] <author> S. R. Wheat, K. D. Devine, and A. B. Maccabe. </author> <title> Experience with automatic, dynamic load balancing and adaptive finite element computation. </title> <type> Technical Report SAND 93-2172A, </type> <institution> Sandia National Labs, </institution> <address> Albuquerque, </address> <year> 1993. </year>
Reference-contexts: Hence, they should be advantageous for use with adaptive techniques. The redistribution strategy given here is an iterative local migration scheme. It is based on the Leiss/Reddy [9] algorithm and employs selection criteria similar to Wheat et al. <ref> [20] </ref> in transferring elements. Unlike, these approaches, however, the processors are paired during load transfers similar to the pairwise exchange heuristic used by Hammond [7]. <p> The pairing of processors is equivalent to coloring the edges of each tree T i with colors representing separate load transfer (communication) cycles. The edge coloring approach synchronizes the load transfer between neighboring processors and differs from the approach of Wheat et al. <ref> [20] </ref>. According to our implementation, processors P 2 and P 7 in Figure 3 (b) would be engaged with load transfer with only one neighbor at a single transfer step. Wheat et al. [20], however, would let processor P 2 and P 7 receive and send work during the same transfer <p> approach synchronizes the load transfer between neighboring processors and differs from the approach of Wheat et al. <ref> [20] </ref>. According to our implementation, processors P 2 and P 7 in Figure 3 (b) would be engaged with load transfer with only one neighbor at a single transfer step. Wheat et al. [20], however, would let processor P 2 and P 7 receive and send work during the same transfer step. The latter approach would be more efficient if there were load transfer in one direction only, i.e. from heavily loaded to less loaded processor. <p> Firstly, smaller number of messages and the synchronous transfer of load increase communication performance. Second, since the processors are synchronized by pairs, a greater repertoire of selection criteria to decide which elements to transfer can be employed. Unlike <ref> [20] </ref>, where elements can be transferred from only heavily load to less loaded processors, the pairing allows elements to be transferred from the less loaded to the heavily loaded pair. This can be useful in improving the surface to volume ratio of the partitions. <p> This can be useful in improving the surface to volume ratio of the partitions. Since there is no explicit synchronization by edge coloring in <ref> [20] </ref>, this approach would make implementation of this bidirectional transfer of load extremely difficult. the maximum vertex degree (number of edges incident on a vertex) in a graph G, then Vizing's theorem [16] shows that the graph G can be edge-colored using C colors where (G) C (G) + 1. <p> This should be done to reduce communication volume. 11 3. Elements with a larger load should be favored since this will imply fewer element transfers and faster convergence to load balance. The current criteria for selecting elements is similar to the approach in Wheat et al. <ref> [20] </ref> which prioritizes the boundary elements. Each partition boundary element has a cost associated with it based on: 1. The element workload which is the total number of degrees of freedom in the interior, on the edges and the nodes of the element. 2.
Reference: [21] <author> R.D. Williams. </author> <title> Performance of dynamic load balancing algorithms for unstructured grid calculations. </title> <type> Technical Report C3P913, </type> <institution> Pasadena, </institution> <year> 1990. </year> <month> 18 </month>
Reference-contexts: Probabilistic Methods which include simulated annealing and genetic algorithms. These methods however require many iterations and are expensive to use as mesh partitioning meth ods <ref> [21] </ref>. 3. Iterative Local Migration Techniques exchange load between neighboring processors to improve the load balance and/or decrease the communication volume. The definition of processor neighborhood can either be the hardware link or the connectivity of the split domains.
References-found: 21

