URL: http://http.icsi.berkeley.edu/~luby/PAPERS/modules.ps
Refering-URL: http://http.icsi.berkeley.edu/~luby/parallel.html
Root-URL: http://http.icsi.berkeley.edu
Title: Efficient PRAM Simulation on a Distributed Memory Machine  
Author: Richard M. Karp Michael Luby Friedhelm Meyer auf der Heide 
Note: Research partially supported by NSF/DARPA Grant CCR-9005448 Research partially supported by NSF operating grant CCR-9016468 and by grant No. 89-00312 from the United States-Israel Binational Science Foundation (BSF), Jerusalem, Israel. Part of work was done during a visit at the International  supported in part by DFG-Forschergruppe "Effiziente Nutzung massiv paralleler Systeme, Teilprojekt 4", and by the Esprit Basic Research Action Nr. 7141 (ALCOM II).  
Date: August 8, 1994  
Address: Berkeley, CA  Germany  Berkeley;  
Affiliation: University of California at Berkeley and International Computer Science Institute,  International Computer Science Institute, Berkeley, CA and UC Berkeley  Heinz Nixdorf Institute and Computer Science Department, University of Paderborn,  Computer Science Institute at  
Abstract: We present algorithms for the randomized simulation of a shared memory machine (PRAM) on a Distributed Memory Machine (DMM). In a PRAM, memory conflicts occur only through concurrent access to the same cell, whereas the memory of a DMM is divided into modules, one for each processor, and concurrent accesses to the same module create a conflict. The delay of a simulation is the time needed to simulate a parallel memory access of the PRAM. Any general simulation of an m processor PRAM on a n processor DMM will necessarily have delay at least m=n. A randomized simulation is called time-processor optimal if the delay is O(m=n) with high probability. Using a novel simulation scheme based on hashing we obtain a time-processor optimal simulation with delay O(loglog(n)log fl (n)). The best previous simulations use a simpler scheme based on hashing and have much larger delay: fi(log(n)= loglog(n)) for the simulation of an n processor PRAM on an n processor DMM, and fi(log(n)) in the case where the simulation is time-processor optimal. Our simulations use several (2 or 3) hash functions to distribute the shared memory among the memory modules of the PRAM. The stochastic processes modelling the behaviour of our algorithms and their analyses based on powerful classes of universal hash functions may be of independent interest. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon and J. H. Spencer. </author> <title> The Probabilistic Method. </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1991. </year>
Reference-contexts: Thus the random choice of h is reduced to randomly choose the offsets a. As a consists of p n independent random variables, we can apply the following very general tail estimate. It is based on Azuma's inequality. It can be found e.g. in <ref> [1] </ref>. The version described below can be found in [2] and [18].
Reference: [2] <author> H. Bast and T. Hagerup. </author> <title> Fast and reliable parallel hashing. </title> <booktitle> In Proc. of the 3rd Ann. ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 50-61, </pages> <year> 1991. </year>
Reference-contexts: The structure of these hash functions enables us to analyze the delay in our simulation using a powerful martingale tail estimate that was derived independently in <ref> [2] </ref> and [18]. 2 Computation Models A PRAM consists of processors P 1 ; : : : ; P m and a shared memory with cells U = [p]. The processors work synchronously and have random access to the shared memory cells, each of which can store an integer. <p> We show that this set will always be of linear size, with high probability. For implementing SM we use a fast perfect hash table, based on results from [17] and <ref> [2] </ref>, described in section 4. This guarantees that time O (log fl (n)) is sufficient to insert the new write requests into SM, with high probability, and that a parallel read in SM can be done in constant time. <p> The papers <ref> [2] </ref> and [17] give randomized algorithms for realizing a parallel hash table for fln key-value pairs on an n processor PRAM. The inputs and outputs of the operations, as well as the parallel hash table itself, reside in the shared memory of the PRAM. <p> The LOOKUP operation runs in time O (1) and, the BUILD and HASH operations run in time O (log fl (n)) and perform O (n) operations, with high probability. Note that the operation HASH is a little more complex than what is done in <ref> [2] </ref> or [17], because X is hashed in a non-empty hash table. For our version of HASH, we first collect the keys S stored in the hash table, and then hash S [ X to it. This is possible because jS [ Xj = O (n). <p> As a consists of p n independent random variables, we can apply the following very general tail estimate. It is based on Azuma's inequality. It can be found e.g. in [1]. The version described below can be found in <ref> [2] </ref> and [18].
Reference: [3] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: There is an edge from h 1 (x) to h 2 (x) labeled x for each x 2 S. This graph has the structural properties stated in Lemma 6.3 and Claim 6.2 below. Similar properties are well known for random graphs <ref> [3] </ref> and are proved using similar techniques. Note that both h 1 and h 2 are (1; n)-universal on S because of Lemma 5.4. Lemma 6.3 Let H be the graph obtained from G by removing all labels and directions from the edges.
Reference: [4] <author> J. L. Carter and M. N. Wegman. </author> <title> Universal classes of hash functions. </title> <journal> J. Comput. Syst. Sci., </journal> <volume> 18 </volume> <pages> 143-154, </pages> <year> 1979. </year>
Reference-contexts: The notion of universality was first introduced in <ref> [4] </ref>. Some of the simulations assume a complete interconnection network between the processors and the memory modules; others assume a sparse interconnection network such as a butterfly or a hypercube. The delay of a simulation is the time needed to simulate a parallel memory access of the PRAM. <p> In [15] and [20] it is shown that, on a butterfly network, expected routing time O (log (n)) can be achieved, which clearly is asymptotically optimal. The expected contention can be made as small as O (log (n)= loglog (n)), if log (n)-universal hash-functions as introduced in <ref> [4] </ref> are used. These hash functions have evaluation time O (log (n)). Thus these simulations have delay O (log (n)). If a complete interconnection network is assumed then the delay can be reduced. In [19], log (n)= loglog (n)-universal hash functions from [4] are used, yielding delay O (log (n)= loglog <p> (n)), if log (n)-universal hash-functions as introduced in <ref> [4] </ref> are used. These hash functions have evaluation time O (log (n)). Thus these simulations have delay O (log (n)). If a complete interconnection network is assumed then the delay can be reduced. In [19], log (n)= loglog (n)-universal hash functions from [4] are used, yielding delay O (log (n)= loglog (n)). For any scheme that uses a single hash function to distribute the keys among n memory modules, the expected contention is necessarily (log (n)= loglog (n)). <p> Let H p;n be a family of hash functions mapping U into [n]. In <ref> [4] </ref> the notion of universality for families of hash functions was introduced as a measure of the quality of the family for classical hashing purposes. <p> The first one is the class H d p;n fh : [p] ! [n]g of functions h (x) mod n where h is a polynomial of degree d 1 over ZZ p . H d p;n was introduced by Carter and Wegman in <ref> [4] </ref>. It is a (2; d)-universal class. The second class H n k ;n fh : [n k ] ! [n]g introduced by Siegel in [21] consists of more complicated functions. <p> If h is randomly drawn from H d p;n or H n k ;n then Prob [h is d-perfect on S 0 ] 1 n ` . Proof : The results (a), (b) are obvious from the definition of the classes, (c) and (d) can be found in <ref> [4] </ref> for H d p;n and in [21] for H n k ;n and (e) is shown in [16].
Reference: [5] <author> B. S. Chlebus, K. Diks, T. Hagerup, and T. Radzik. </author> <title> Efficient simulations between concurrent-read concurrent-write PRAM models. </title> <booktitle> In MFCS '88, </booktitle> <pages> pages 231-239, </pages> <year> 1988. </year>
Reference-contexts: On the other hand the specific rule how to resolve write conflicts is not of major importance, because several authors have shown efficient simulations among parallel machines with different write conflict resolutions <ref> [5] </ref>, [6], [10], [11], [13], [14]. These simulations are described for PRAMs, but can be transfered to DMMs using Lemma 2.1. 4 For example the TOLERANT rule suffices: If several processors want to write to the same communication window then its contents remains unchanged.
Reference: [6] <author> B. S. Chlebus, K. Diks, T. Hagerup, and T. Radzik. </author> <title> New simulations between CRCW PRAMs. </title> <booktitle> In MFCS '89, </booktitle> <pages> pages 95-104, </pages> <year> 1989. </year>
Reference-contexts: On the other hand the specific rule how to resolve write conflicts is not of major importance, because several authors have shown efficient simulations among parallel machines with different write conflict resolutions [5], <ref> [6] </ref>, [10], [11], [13], [14]. These simulations are described for PRAMs, but can be transfered to DMMs using Lemma 2.1. 4 For example the TOLERANT rule suffices: If several processors want to write to the same communication window then its contents remains unchanged.
Reference: [7] <author> M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer auf der Heide, H. Rohnert, and R. E. Tarjan. </author> <title> Dynamic perfect hashing: upper and lower bounds. </title> <type> Technical Report 77, </type> <institution> Universitat-GH Paderborn, FB Mathematik-Informatik, </institution> <month> Jan. </month> <year> 1991. </year> <title> (Revised version of paper with same title that appeared in Proc. </title> <booktitle> of the 24th IEEE FOCS, </booktitle> <pages> pages 524-531, </pages> <year> 1988), </year> <note> to appear in SIAM J. Comp. </note>
Reference-contexts: Proof : The results (a), (b) are obvious from the definition of the classes, (c) and (d) can be found in [4] for H d p;n and in [21] for H n k ;n and (e) is shown in [16]. The results (f) and (g) are shown in <ref> [7] </ref> for (; d)-universal classes; thus it applies to both of our classes because of (c) and (d). 2 In [8] and [9] a new class of hash functions is introduced. We only present a special case sufficient for our considerations.
Reference: [8] <editor> M. Dietzfelbinger and F. Meyer auf der Heide. </editor> <title> How to distribute a hash table in a complete network. </title> <booktitle> In Proc. of the 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 117-127, </pages> <year> 1990. </year> <month> 25 </month>
Reference-contexts: In [23] a time-processor optimal simulation of EREW-PRAMs on DMMs is presented with expected delay O (log (n)), using hash functions introduced in [21]. In <ref> [8] </ref> the same result is shown for CRCW-PRAMs, using a new class of hash functions. 1.2 New Results In the present paper we have chosen to assume a complete interconnection network in order to avoid confounding the effects of memory contention with the effects of routing delays, and to make possible <p> Thus, we can distribute the table among the modules so that accesses to it can be performed in constant time. The analysis of our simulation depends on the properties of a particular p n-universal class of hash functions which combines the constructions given in <ref> [8] </ref> and [21]. <p> The results (f) and (g) are shown in [7] for (; d)-universal classes; thus it applies to both of our classes because of (c) and (d). 2 In <ref> [8] </ref> and [9] a new class of hash functions is introduced. We only present a special case sufficient for our considerations. <p> Let h be defined by (f; g; a). Claim 6.1 For all t 2 [T ], Exp [jA t j] d 2 n. Proof : In <ref> [8] </ref> (see Definition 5.5 and Theorem 6.1) the following is shown. Lemma 6.2 Let S U , jSj tn for some t 1. Let h be as above; h splits S into buckets B 1 ; : : : ; B n . <p> Thus, at the end of loop (ii), at most a set X 0 , jX 0 j n 9=10 , have not gotten an answer, i.e., their corresponding read requests are not yet satisfied, with high probability. This is shown in Theorem 6.1. In <ref> [8] </ref>, it is shown that a random h l 2 R d p;n is d-perfect (for a sufficiently large constant D) on a set X 0 of size at most n 9=10 , with high probability.
Reference: [9] <editor> M. Dietzfelbinger and F. Meyer auf der Heide. </editor> <title> A new universal class of hash functions and dynamic hashing in real time. </title> <editor> In M. S. Paterson, editor, </editor> <booktitle> Proceedings of 17th ICALP, </booktitle> <pages> pages 6-19. </pages> <publisher> Springer, </publisher> <year> 1990. </year> <note> Lecture Notes in Computer Science 443. </note>
Reference-contexts: The results (f) and (g) are shown in [7] for (; d)-universal classes; thus it applies to both of our classes because of (c) and (d). 2 In [8] and <ref> [9] </ref> a new class of hash functions is introduced. We only present a special case sufficient for our considerations. <p> In this way, each processor can evaluate h on x in constant time, by reading a f (x) from M f (x) . For R d p;n , <ref> [9] </ref> shows that for any given S U , jSj n 11=10 , a randomly chosen and fixed (f; g) pair will have, with high probability, distributional properties with respect to how S is mapped by random a that are very similar to the properties that hold if completely random functions <p> The following lemma is implicitly used in <ref> [9] </ref>. It follows directly from Lemma 5.1 (e) and (f). Lemma 5.2 Let S U , n jSj n 11=10 .
Reference: [10] <author> F. E. Fich, P. L. Ragde, and A. Wigderson. </author> <title> Relations between concurrent-write models of parallel computation. </title> <journal> SIAM J. Comput., </journal> <volume> 17 </volume> <pages> 606-627, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: On the other hand the specific rule how to resolve write conflicts is not of major importance, because several authors have shown efficient simulations among parallel machines with different write conflict resolutions [5], [6], <ref> [10] </ref>, [11], [13], [14]. These simulations are described for PRAMs, but can be transfered to DMMs using Lemma 2.1. 4 For example the TOLERANT rule suffices: If several processors want to write to the same communication window then its contents remains unchanged.
Reference: [11] <author> F. E. Fich, P. L. Ragde, and A. Wigderson. </author> <title> Simulations among concurrent-write PRAMs. </title> <journal> Algorithmica, </journal> <volume> 3:43:51, </volume> <year> 1988. </year>
Reference-contexts: On the other hand the specific rule how to resolve write conflicts is not of major importance, because several authors have shown efficient simulations among parallel machines with different write conflict resolutions [5], [6], [10], <ref> [11] </ref>, [13], [14]. These simulations are described for PRAMs, but can be transfered to DMMs using Lemma 2.1. 4 For example the TOLERANT rule suffices: If several processors want to write to the same communication window then its contents remains unchanged.
Reference: [12] <author> J. Gil and Y. Matias. </author> <title> Fast hashing on a PRAM-designing by expectation. </title> <booktitle> In SODA '91, </booktitle> <pages> pages 271 - 280, </pages> <year> 1991. </year>
Reference-contexts: For our version of HASH, we first collect the keys S stored in the hash table, and then hash S [ X to it. This is possible because jS [ Xj = O (n). For our Simulation 2, a simpler implementation from <ref> [12] </ref> with delay O (log log (n)) would also suffice.
Reference: [13] <author> J. Gil and Y. Matias. </author> <title> Leaders election without a conflict resolution rule fast and efficient randomized simulations among CRCW PRAMs. </title> <booktitle> In LATIN '92, </booktitle> <pages> pages 204 - 218. </pages>
Reference-contexts: On the other hand the specific rule how to resolve write conflicts is not of major importance, because several authors have shown efficient simulations among parallel machines with different write conflict resolutions [5], [6], [10], [11], <ref> [13] </ref>, [14]. These simulations are described for PRAMs, but can be transfered to DMMs using Lemma 2.1. 4 For example the TOLERANT rule suffices: If several processors want to write to the same communication window then its contents remains unchanged.
Reference: [14] <author> J. Gil, Y. Matias, and U. Vishkin. </author> <title> Towards a theory of nearly constant time parallel algorithms. </title> <booktitle> In FOCS '91, </booktitle> <pages> pages 698 - 710, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: On the other hand the specific rule how to resolve write conflicts is not of major importance, because several authors have shown efficient simulations among parallel machines with different write conflict resolutions [5], [6], [10], [11], [13], <ref> [14] </ref>. These simulations are described for PRAMs, but can be transfered to DMMs using Lemma 2.1. 4 For example the TOLERANT rule suffices: If several processors want to write to the same communication window then its contents remains unchanged.
Reference: [15] <author> A. Karlin and E. Upfal. </author> <title> Parallel hashing | an efficient implementation of shared memory. </title> <booktitle> In Proc. of the 18th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 160-168, </pages> <year> 1986. </year>
Reference-contexts: In <ref> [15] </ref> and [20] it is shown that, on a butterfly network, expected routing time O (log (n)) can be achieved, which clearly is asymptotically optimal. The expected contention can be made as small as O (log (n)= loglog (n)), if log (n)-universal hash-functions as introduced in [4] are used.
Reference: [16] <author> C. P. Kruskal, L. Rudolph, and M. Snir. </author> <title> A complexity theory of efficient parallel algorithms. </title> <journal> Theoret. Comput. Sci., </journal> <volume> 71 </volume> <pages> 95-132, </pages> <year> 1990. </year>
Reference-contexts: It is easily seen that, in any time-processor optimal simulation that uses a single hash function to distribute the keys, the expected memory contention, and hence the expected delay, must be (log (n)). The first time-processor optimal simulation was published in <ref> [16] </ref>. It simulates an n 1+" processor PRAM on an n processor DMM with optimal expected delay O (n " ), for arbitrary " &gt; 0. In [23] a time-processor optimal simulation of EREW-PRAMs on DMMs is presented with expected delay O (log (n)), using hash functions introduced in [21]. <p> Proof : The results (a), (b) are obvious from the definition of the classes, (c) and (d) can be found in [4] for H d p;n and in [21] for H n k ;n and (e) is shown in <ref> [16] </ref>. The results (f) and (g) are shown in [7] for (; d)-universal classes; thus it applies to both of our classes because of (c) and (d). 2 In [8] and [9] a new class of hash functions is introduced. We only present a special case sufficient for our considerations.
Reference: [17] <author> Y. Matias and U. Vishkin. </author> <title> Converting high probability into nearly-constant time - with applications to parallel hashing. </title> <booktitle> In Proc. of the 23rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 307-316, </pages> <year> 1991. </year>
Reference-contexts: The process 2 in section 6 models the shrinking and growing of the set of unsatisfied requests stored in SM. We show that this set will always be of linear size, with high probability. For implementing SM we use a fast perfect hash table, based on results from <ref> [17] </ref> and [2], described in section 4. This guarantees that time O (log fl (n)) is sufficient to insert the new write requests into SM, with high probability, and that a parallel read in SM can be done in constant time. <p> The papers [2] and <ref> [17] </ref> give randomized algorithms for realizing a parallel hash table for fln key-value pairs on an n processor PRAM. The inputs and outputs of the operations, as well as the parallel hash table itself, reside in the shared memory of the PRAM. <p> The LOOKUP operation runs in time O (1) and, the BUILD and HASH operations run in time O (log fl (n)) and perform O (n) operations, with high probability. Note that the operation HASH is a little more complex than what is done in [2] or <ref> [17] </ref>, because X is hashed in a non-empty hash table. For our version of HASH, we first collect the keys S stored in the hash table, and then hash S [ X to it. This is possible because jS [ Xj = O (n).
Reference: [18] <author> C. McDiarmid. </author> <title> On the method of bounded differences. </title> <editor> In J. Siemons, editor, </editor> <booktitle> Surveys in Combinatorics, </booktitle> <year> 1989, </year> <pages> pages 148-188. </pages> <publisher> Cambridge University Press, </publisher> <year> 1989. </year> <journal> London Math. Soc. </journal> <note> Lecture Note Series 141. </note>
Reference-contexts: The structure of these hash functions enables us to analyze the delay in our simulation using a powerful martingale tail estimate that was derived independently in [2] and <ref> [18] </ref>. 2 Computation Models A PRAM consists of processors P 1 ; : : : ; P m and a shared memory with cells U = [p]. The processors work synchronously and have random access to the shared memory cells, each of which can store an integer. <p> As a consists of p n independent random variables, we can apply the following very general tail estimate. It is based on Azuma's inequality. It can be found e.g. in [1]. The version described below can be found in [2] and <ref> [18] </ref>. Theorem 5.1 Let X 1 ; : : :; X m be independent random variables with finite ranges, and let F (X 1 ; : : : ; X m ) be any function in X 1 ; : : : ; X m with Exp [F ] 0.
Reference: [19] <author> K. Mehlhorn and U. Vishkin. </author> <title> Randomized and deterministic simulations of PRAMs by parallel machines with restricted granularity of parallel memories. </title> <journal> Acta Informatica, </journal> <volume> 21 </volume> <pages> 339-374, </pages> <year> 1984. </year>
Reference-contexts: These hash functions have evaluation time O (log (n)). Thus these simulations have delay O (log (n)). If a complete interconnection network is assumed then the delay can be reduced. In <ref> [19] </ref>, log (n)= loglog (n)-universal hash functions from [4] are used, yielding delay O (log (n)= loglog (n)). For any scheme that uses a single hash function to distribute the keys among n memory modules, the expected contention is necessarily (log (n)= loglog (n)).
Reference: [20] <author> A. G. Ranade. </author> <title> How to emulate shared memory. </title> <booktitle> In Proc. of the 28th IEEE Ann. Symp. on Foundations of Computer Science, </booktitle> <pages> pages 185-194, </pages> <year> 1987. </year>
Reference-contexts: In [15] and <ref> [20] </ref> it is shown that, on a butterfly network, expected routing time O (log (n)) can be achieved, which clearly is asymptotically optimal. The expected contention can be made as small as O (log (n)= loglog (n)), if log (n)-universal hash-functions as introduced in [4] are used.
Reference: [21] <author> A. Siegel. </author> <title> On universal classes of fast high performance hash functions, their time-space tradeoff, and their applications. </title> <booktitle> In Proc. of the 30th IEEE Ann. Symp. on Foundations of Computer Science, </booktitle> <pages> pages 20-25, </pages> <year> 1989. </year> <note> Revised Version. </note>
Reference-contexts: It simulates an n 1+" processor PRAM on an n processor DMM with optimal expected delay O (n " ), for arbitrary " &gt; 0. In [23] a time-processor optimal simulation of EREW-PRAMs on DMMs is presented with expected delay O (log (n)), using hash functions introduced in <ref> [21] </ref>. <p> Thus, we can distribute the table among the modules so that accesses to it can be performed in constant time. The analysis of our simulation depends on the properties of a particular p n-universal class of hash functions which combines the constructions given in [8] and <ref> [21] </ref>. <p> H d p;n was introduced by Carter and Wegman in [4]. It is a (2; d)-universal class. The second class H n k ;n fh : [n k ] ! [n]g introduced by Siegel in <ref> [21] </ref> consists of more complicated functions. It is the first class with high degree of universality whose functions can be generated fast using little space and have constant evaluation time, if the universe is of size n k for constant k. <p> Proof : The results (a), (b) are obvious from the definition of the classes, (c) and (d) can be found in [4] for H d p;n and in <ref> [21] </ref> for H n k ;n and (e) is shown in [16].
Reference: [22] <author> E. Upfal. </author> <title> Efficient schemes for parallel communication. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 31(3) </volume> <pages> 507-517, </pages> <year> 1984. </year>
Reference: [23] <author> L. G. Valiant. </author> <title> General purpose parallel architectures. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, Vol. A: Algorithms and Complexity, chapter 18, </booktitle> <pages> pages 943-971. </pages> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1990. </year> <month> 27 </month>
Reference-contexts: The first time-processor optimal simulation was published in [16]. It simulates an n 1+" processor PRAM on an n processor DMM with optimal expected delay O (n " ), for arbitrary " &gt; 0. In <ref> [23] </ref> a time-processor optimal simulation of EREW-PRAMs on DMMs is presented with expected delay O (log (n)), using hash functions introduced in [21].
References-found: 23

