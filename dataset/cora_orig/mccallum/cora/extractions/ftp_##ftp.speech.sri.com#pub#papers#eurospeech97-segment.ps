URL: ftp://ftp.speech.sri.com/pub/papers/eurospeech97-segment.ps
Refering-URL: http://www.speech.sri.com/people/stolcke/publications.html
Root-URL: 
Email: stolcke@speech.sri.com  
Title: MODELING LINGUISTIC SEGMENT AND TURN BOUNDARIES FOR N-BEST RESCORING OF SPONTANEOUS SPEECH  
Author: Andreas Stolcke 
Web: http://www.speech.sri.com/  
Address: Menlo Park, CA, U.S.A.  
Affiliation: Speech Technology and Research Laboratory SRI International,  
Abstract: Language modeling, especially for spontaneous speech, often suffers from a mismatch of utterance segmentations between training and test conditions. In particular, training often uses linguistically-based segments, whereas testing occurs on acoustically determined segments, resulting in degraded performance. We present an N-best rescoring algorithm that removes the effect of segmentation mismatch. Furthermore, we show that explicit language modeling of hidden linguistic segment boundaries is improved by including turn-boundary events in the model. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Digalakis and H. Murveit. GENONES: </author> <title> An algorithm for optimizing the degree of tying in a large vocabulary hidden Markov model based speech recognizer. </title> <booktitle> In Proceedings of the IEEE Conference on Acoustics, Speech and Signal Processing, </booktitle> <address> Adelaide, Australia, </address> <year> 1994. </year>
Reference-contexts: The test set consisted of 25 Switchboard conversations (24,000 words) and was acoustically segmented. For each segment, an N-best list of up to 2000 hypotheses was generated, using SRI's Decipher (TM) recognizer with continuous density genonic HMM acoustic models <ref> [1, 6] </ref>. For rescoring purposes, each side in a Switchboard conversation was treated as one stream of speech to be recognized, separate from the opposite side. 4.2. Complexity Issues The time complexity of the dynamic programming algorithm scales with the square of the number of N-best hypotheses.
Reference: [2] <author> J. J. Godfrey, E. C. Holliman, and J. McDaniel. </author> <title> SWITCHBOARD: Telephone speech corpus for research and development. </title> <booktitle> In Proceedings of the IEEE Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> vol. I, </volume> <pages> pp. 517520, </pages> <address> San Francisco, </address> <year> 1992. </year>
Reference-contexts: Similarly, sophisticated LMs modeling syntactic structure typically assume complete sentences as their input [12]. The following excerpt from the Switchboard corpus <ref> [2] </ref> illustrates the discrepancies between acoustic and linguistic segmentations. Linguistic segment boundaries are marked by &lt;s&gt;, whereas acoustic boundaries are indicated by //. A subset of acoustic boundaries corresponds to turn boundaries, indicated by &lt;t&gt;. <p> EXPERIMENTS 4.1. Data and Language Models We tested the concepts and algorithms described here using the Switchboard corpus of spontaneous conversational speech <ref> [2] </ref>. We trained standard trigram language models with backoff smoothing [3] on 1.8 million words from that corpus. Two segmentations of the training data were used. In one case, the full training corpus was acoustically segmented, placing segment boundaries at turn boundaries and at pauses of at least 0.5 seconds.
Reference: [3] <author> S. M. Katz. </author> <title> Estimation of probabilities from sparse data for the language model component of a speech recognizer. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> 35(3):400401, </volume> <year> 1987. </year>
Reference-contexts: EXPERIMENTS 4.1. Data and Language Models We tested the concepts and algorithms described here using the Switchboard corpus of spontaneous conversational speech [2]. We trained standard trigram language models with backoff smoothing <ref> [3] </ref> on 1.8 million words from that corpus. Two segmentations of the training data were used. In one case, the full training corpus was acoustically segmented, placing segment boundaries at turn boundaries and at pauses of at least 0.5 seconds.
Reference: [4] <author> M. Meteer et al. </author> <title> Dysfluency annotation stylebook for the Switchboard corpus. Linguistic Data Consortium. </title> <note> Revised June 1995 by Ann Taylor. </note>
Reference-contexts: In one case, the full training corpus was acoustically segmented, placing segment boundaries at turn boundaries and at pauses of at least 0.5 seconds. A second segmentation was available from the Linguistic Data Consortium, consisting of transcripts with hand-annotated linguistic segment boundaries <ref> [4] </ref>. However, only 1.4 million words were available in hand-segmented form. We therefore trained an automatic linguistic segmenter on this data, and used it to segment the remaining training data.
Reference: [5] <author> M. Meteer and R. Iyer. </author> <title> Modeling conversational speech for speech recognition. </title> <editor> In E. Brill and K. Church, editors, </editor> <booktitle> Proceedings of the Conference on Empirical Methods in Natural Language Processing, </booktitle> <pages> pp. 3347, </pages> <institution> University of Pennsylvania, </institution> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: An approximate version of the hidden segmentation language model that does not require the forward algorithm has been used previously to study the effect of segmentation on language model perplexity <ref> [5] </ref>. 3. N-BEST LIST RESCORING To apply the hidden segmentation model to the output of a speech recognizer, we first generate N-best lists for each of the acoustic segments X 1 ; X 2 ; : : : ; X M .
Reference: [6] <author> H. Murveit, J. Butzberger, V. Digalakis, and M. Weintraub. </author> <title> Large-vocabulary dictation using SRI's DECIPHER speech recognition system: Progressive search techniques. </title> <booktitle> In Proceedings of the IEEE Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> vol. II, </volume> <pages> pp. 319322, </pages> <address> Minneapolis, </address> <year> 1993. </year>
Reference-contexts: The test set consisted of 25 Switchboard conversations (24,000 words) and was acoustically segmented. For each segment, an N-best list of up to 2000 hypotheses was generated, using SRI's Decipher (TM) recognizer with continuous density genonic HMM acoustic models <ref> [1, 6] </ref>. For rescoring purposes, each side in a Switchboard conversation was treated as one stream of speech to be recognized, separate from the opposite side. 4.2. Complexity Issues The time complexity of the dynamic programming algorithm scales with the square of the number of N-best hypotheses.
Reference: [7] <author> M. Ostendorf, B. Byrne, M. Bacchiani, M. Finke, A. Gu-nawardana, K. Ross, S. Roweis, E. Shriberg, D. Talkin, A. Waibel, B. Wheatley, and T. Zeppenfeld. </author> <title> Model systematic variations in pronunciation via a language-dependent hidden speaking mode. Research Note 24, Center for Language and Speech Processing, </title> <institution> Johns Hopkins University, Baltimore, </institution> <year> 1997. </year>
Reference-contexts: This is because current acoustic models exhibit no long-range dependencies, so that P AC (XjH s ) = i=1 i ) In the future, however, acoustic models could incorporate global characteristics of speech, such as speaking mode <ref> [7] </ref>, in which case they, too, should operate across segment boundaries. 4. EXPERIMENTS 4.1. Data and Language Models We tested the concepts and algorithms described here using the Switchboard corpus of spontaneous conversational speech [2].
Reference: [8] <author> M. Ostendorf, A. Kannan, S. Austin, O. Kimball, R. Schwartz, and J. R. Rohlicek. </author> <title> Integration of diverse recognition methodologies through reevaluation of N-best sentence hypotheses. </title> <booktitle> In Proceedings DARPA Speech and Natural Language Processing Workshop, </booktitle> <pages> pp. 8387, </pages> <address> Pacific Grove, CA, </address> <year> 1991. </year> <institution> Defense Advanced Research Projects Agency, Information Science and Technology Office. </institution>
Reference-contexts: These N-best lists are generated using a standard language model operating on one acoustic segment at a time. We based our implementation of the algorithm on N-best lists <ref> [8] </ref>, but with minor changes the same methods could be applied to the rescoring of word lattices. Let H ij , j = 1; : : : ; N , be the N best hypotheses for the ith acoustic segment.
Reference: [9] <author> L. R. Rabiner and B. H. Juang. </author> <title> An introduction to hidden Markov models. </title> <journal> IEEE ASSP Magazine, </journal> <volume> 3(1):416, </volume> <year> 1986. </year>
Reference-contexts: If the language model is Markovian, as in the case of an N-gram model, we obtain a hidden Markov model, and the total sentence probability can be computed by a forward algorithm <ref> [9] </ref>. A corresponding segments. Viterbi algorithm can be used to find the most likely sequence of hidden S and NO-S states, corresponding to the most likely segmentation of a word sequence according to the language model.
Reference: [10] <author> R. Rosenfeld, R. Agarwal, B. Byrne, R. Iyer, M. Liber-man, E. Shriberg, J. Unverfuehrt, D. Vergyri, and E. Vidal. </author> <title> LM95 Project Report: Language modeling of spontaneous speech. Research Note 1, Center for Language and Speech Processing, </title> <institution> Johns Hopkins University, Baltimore, </institution> <year> 1996. </year>
Reference-contexts: Language modeling research on spontaneous speech <ref> [10] </ref> shows that N-gram LMs based on complete utterance units give lower perplexity than those based only on acoustic segmentations.
Reference: [11] <author> E. Shriberg, R. Bates, and A. Stolcke. </author> <title> A prosody-only decision-tree model for disfluency detection. </title> <booktitle> In Proceedings 5th European Conference on Speech Communication and Technology, </booktitle> <address> Rhodes, Greece, </address> <year> 1997. </year>
Reference-contexts: Finally, language modeling of segment and turn boundaries should be accompanied by an explicit modeling of the prosodic features of such events. We have started work on the combined prosodic and language modeling of hidden events <ref> [11] </ref>, which we plan to extended for the purpose of N-best rescoring.
Reference: [12] <author> A. Stolcke, C. Chelba, D. Engle, V. Jimenez, L. Mangu, H. Printz, E. Ristad, R. Rosenfeld, D. Wu, F. Jelinek, and S. Khudanpur. </author> <title> Dependency language modeling. </title> <note> Research Note 24, </note> <institution> Center for Language and Speech Processing,Johns Hopkins University, Baltimore, </institution> <year> 1997. </year>
Reference-contexts: Language modeling research on spontaneous speech [10] shows that N-gram LMs based on complete utterance units give lower perplexity than those based only on acoustic segmentations. Furthermore, work reported in <ref> [12] </ref> showed that the word error rate on spontaneous speech can be reduced simply by resegmenting the speech at linguistic boundaries and using a language model based on the same segmentation. * Explicit modeling of spontaneous speech phenomena such as disfluencies also requires modeling of linguistic (as opposed to acoustic) segment <p> Similarly, sophisticated LMs modeling syntactic structure typically assume complete sentences as their input <ref> [12] </ref>. The following excerpt from the Switchboard corpus [2] illustrates the discrepancies between acoustic and linguistic segmentations. Linguistic segment boundaries are marked by &lt;s&gt;, whereas acoustic boundaries are indicated by //. A subset of acoustic boundaries corresponds to turn boundaries, indicated by &lt;t&gt;.
Reference: [13] <author> A. Stolcke, Y. Konig, and M. Weintraub. </author> <title> Explicit word error minimization in N-best list rescoring. </title> <booktitle> In Proceedings 5th European Conference on Speech Communication and Technology, </booktitle> <address> Rhodes, Greece, </address> <year> 1997. </year>
Reference-contexts: This is because word error is additive over segments, and the error on each segment hypothesis is minimized by maximizing its posterior probability of correctness <ref> [13] </ref>. Viterbi rescoring is somewhat simpler and cheaper computationally; it also computes a best segmentation for the chosen hypotheses. The acoustic models used in both algorithms are the same as in standard N-best rescoring.
Reference: [14] <author> A. Stolcke and E. Shriberg. </author> <title> Automatic linguistic segmentation of conversational speech. </title> <booktitle> In Proceedings of the International Conference on Spoken Language Processing, </booktitle> <volume> vol. 2, </volume> <pages> pp. 10051008, </pages> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: This is the basis of a simple automatic segmentation algorithm, and can been used to segment spontaneous speech transcripts into linguistic utterance units where hand-segmented transcripts are not available <ref> [14] </ref>. An approximate version of the hidden segmentation language model that does not require the forward algorithm has been used previously to study the effect of segmentation on language model perplexity [5]. 3. <p> We therefore trained an automatic linguistic segmenter on this data, and used it to segment the remaining training data. This method had previously been shown to give good segment boundary detection accuracy on this corpus (85% recall, 3% false alarms) <ref> [14] </ref>. The hand-segmented and the automatically segmented training data were pooled, resulting in a linguistic segment language model based on the same amount of training data as the acoustic segment language model. The test set consisted of 25 Switchboard conversations (24,000 words) and was acoustically segmented.
Reference: [15] <author> A. Stolcke and E. Shriberg. </author> <title> Statistical language modeling for speech disfluencies. </title> <booktitle> In Proceedings of the IEEE Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 405408, </pages> <address> Atlanta, </address> <year> 1996. </year>
Reference-contexts: that the word error rate on spontaneous speech can be reduced simply by resegmenting the speech at linguistic boundaries and using a language model based on the same segmentation. * Explicit modeling of spontaneous speech phenomena such as disfluencies also requires modeling of linguistic (as opposed to acoustic) segment boundaries <ref> [15] </ref>. Similarly, sophisticated LMs modeling syntactic structure typically assume complete sentences as their input [12]. The following excerpt from the Switchboard corpus [2] illustrates the discrepancies between acoustic and linguistic segmentations. Linguistic segment boundaries are marked by &lt;s&gt;, whereas acoustic boundaries are indicated by //.
Reference: [16] <author> T. Zeppenfeld, M. Finke, K. Ries, M. Westphal, and A. Waibel. </author> <title> Recognition of conversational telephone speech using the janus speech engine. </title> <booktitle> In Proceedings of the IEEE Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 18151818, </pages> <address> Munich, </address> <year> 1987. </year>
Reference-contexts: The linguistic segment model does not have access to these cues, and is therefore at an inherent disadvantage. This reasoning is consistent with results showing that explicit language modeling of pauses in Switchboard improves recognition accuracy <ref> [16] </ref>. The obvious solution to this problem is to include nonlexical cues such as turn boundaries and pauses in the linguistic segment language model.
References-found: 16

