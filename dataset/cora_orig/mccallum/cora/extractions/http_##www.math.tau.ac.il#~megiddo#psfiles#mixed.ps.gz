URL: http://www.math.tau.ac.il/~megiddo/psfiles/mixed.ps.gz
Refering-URL: http://www.math.tau.ac.il/~megiddo/pub.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Finding Mixed Strategies with Small Supports in Extensive Form Games  
Author: Daphne Koller Nimrod Megiddo 
Address: Center, 650 Harry Road, San Jose, California 95120-6099.  650 Harry Road, San Jose, California 95120-6099,  Israel.  
Affiliation: Computer Science Division, University of California, Berkeley, California 94720, and IBM Almaden Research  IBM Almaden Research Center,  and School of Mathematical Sciences, Tel Aviv University, Tel Aviv,  
Date: June 1994  
Abstract: The complexity of algorithms that compute strategies or operate on them typically depends on the representation length of the strategies involved. One measure for the size of a mixed strategy is the number of strategies in its support|the set of pure strategies to which it gives positive probability. This paper investigates the existence of "small" mixed strategies in extensive form games, and how such strategies can be used to create more efficient algorithms. The basic idea is that, in an extensive form game, a mixed strategy induces a small set of realization weights that completely describe its observable behavior. This fact can be used to show that for any mixed strategy , there exists a realization-equivalent mixed strategy 0 whose size is at most the size of the game tree. For a player with imperfect recall, the problem of finding such a strategy 0 (given the realization weights) is NP-hard. On the other hand, if is a behavior strategy, 0 can be constructed from in time polynomial in the size of the game tree. In either case, we can use the fact that mixed strategies need never be too large for constructing efficient algorithms that search for equilibria. In particular, we construct the first exponential-time algorithm for finding all equilibria of an arbitrary two-person game in extensive form. fl Research supported in part by ONR Contract N00014-91-C-0026, by the Air Force Office of Scientific Research (AFSC) under Contract F49620-91-C-0080, and by a University of California President's Postdoctoral Fellowship. Some of this work was done while Daphne Koller was at Stanford University. The United States Government is authorized to reproduce and distribute reprints for governmental purposes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. A. Beling and N. Megiddo, </author> <title> Using fast matrix multiplication to find basic solutions, </title> <type> Tech. Report RJ 9234, </type> <institution> IBM Research Division, </institution> <year> 1993. </year>
Reference-contexts: Assuming that is given to us in sparse representation, the standard basis-crashing algorithm requires O (jSupp ()j jT j 2 ) arithmetic operations for this conversion. 4 We can speed up this construction somewhat using a faster basis-crashing algorithm due to Beling and Megiddo <ref> [1] </ref>, resulting in the following theorem: Theorem 3.1 Given a mixed strategy in sparse representation, it is possible to construct a small equivalent strategy 0 using O (jSupp ()j jT j 1:62 ) arithmetic operations.
Reference: [2] <author> R. W. Cottle, J.-S. Pang, and R. E. Stone, </author> <title> The linear complementarity problem, </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1992. </year>
Reference-contexts: We now show how this scheme can be used to find equilibria in two-person extensive-form games. In this case, the problem of finding equilibria in a normal-form game can be described as a linear complementarity problem (LCP) (see <ref> [2] </ref>). There are a number of standard algorithms for finding such equilibria. One possibility is to enumerate all the possible supports for a mixed strategy pair (a support for each of the two players), and attempt to find an equilibrium over that support pair. <p> It is straightforward to show that, in the two-player case, an equilibrium over a given support pair is the solution to a system of linear equations <ref> [2, p. 17] </ref>. The approach above modifies this construction by traversing only small supports for the two players. Corollary 5.1 shows that this can be done without loss of generality.
Reference: [3] <author> N. Dalkey, </author> <title> Equivalence of information patterns and essentially indeterminate games, Contributions to the Theory of Games II (Princeton) (H. </title> <editor> W. Kuhn and A. W. Tucker, eds.), </editor> <publisher> Princeton University Press, Princeton, </publisher> <year> 1953, </year> <pages> pp. 217-243. </pages>
Reference-contexts: In this formulation, a pure strategy would represent an entire equivalence class of pure strategies. This reduction of the space of pure strategies forms the basis for the reduced normal form of an extensive game. Further reductions for a particular given payoff function have been considered by Dalkey <ref> [3] </ref> and by Swinkels [11], but these provide no additional savings in the context of a generic game. Unfortunately, the savings provided by the reduced normal form are often limited. Consider a game where the player has parallel information sets|ones where the player's actions cannot affect which is reached.
Reference: [4] <author> D. Koller and N. Megiddo, </author> <title> The complexity of two-person zero-sum games in extensive form, Games and Economic Behavior 4 (1992), 528-552. [5] , Finding small sample spaces satisfying given constraints, </title> <journal> SIAM Journal on Discrete Mathematics (1994), </journal> <pages> 260-274. </pages>
Reference-contexts: A behavior strategy assigns a probability to each possible decision of the player. Thus, it also can be represented in linear space. A mixed strategy assigns a probability to each pure strategy. The number of pure strategies is usually exponential in the size of the game tree <ref> [7, 4] </ref>. Thus, the size of a mixed strategy may be exponential in the size of the tree. In many useful mixed strategies, however, only a small number of pure strategies receive positive probabilities. <p> That is, the weight distribution on the nodes completely specifies the observable behavior of . Realization weights were first introduced by Koller and Megiddo <ref> [4] </ref> in the context of perfect recall games. In their algorithm, and in the more recent ones of von Stengel [12] and of Koller, Megiddo, and von Stengel [6], the realization weights corresponding to equilibrium mixed strategies are computed directly. <p> Unlike general mixed strategies, it is easy to decide whether there exists a behavior strategy that induces a given weight distribution. In fact, such a behavior strategy can be computed in polynomial time from the weight distribution (see also <ref> [4] </ref>). In many interesting problems, behavior strategies play an important role. A player is said to have perfect recall if she remembers throughout the play everything she has known and done. <p> For simplicity, we chose to define "small" based on jT j. See Section 2 for further discussion. 3 has an equivalent behavior strategy. Thus, for such a player, it suffices to investigate only behavior strategies. In <ref> [4] </ref>, we also make the point that for a player with imperfect recall, the use of an arbitrary mixed strategy (one not derived from a behavior strategy), may violate the spirit of the imperfect recall requirement. Thus, in this case one also often wishes to restrict attention to behavior strategies. <p> In particular, for any strategy of a player with perfect recall, a small mixed strategy can be found in polynomial time. For example, using the results of <ref> [4, 12] </ref>, a small optimal mixed strategy can be found for any player in a two-person zero-sum game with perfect recall. Similarly, using the results of [6], an equilibrium pair of small mixed strategies can be found in any two-person game with perfect recall. <p> Kuhn [8] showed that for a player with perfect recall, every mixed strategy has an equivalent behavior strategy. Hence, in those cases where the player has perfect recall, our results from this section apply to any mixed strategy of the player. On the other hand, in <ref> [4] </ref> we argued that for a player with imperfect recall, the use of an arbitrary mixed strategy may violate the spirit of the imperfect recall requirement. Hence, even in the case of imperfect recall, behavior strategies are of particular interest. <p> Otherwise, we define fi j (c) to be r a c r a (this definition is now clearly independent of our choice of a). See <ref> [4, 12] </ref> for further details and proof of correctness.
Reference: [6] <author> D. Koller, N. Megiddo, and B. von Stengel, </author> <title> Fast algorithms for finding randomized strategies in game trees, </title> <booktitle> Proceedings of the 26th ACM Symposium on Theory of Computing, </booktitle> <year> 1994, </year> <pages> pp. 750-759. </pages>
Reference-contexts: Realization weights were first introduced by Koller and Megiddo [4] in the context of perfect recall games. In their algorithm, and in the more recent ones of von Stengel [12] and of Koller, Megiddo, and von Stengel <ref> [6] </ref>, the realization weights corresponding to equilibrium mixed strategies are computed directly. This relies on the fact that, for games with perfect recall, realization weights can be described using a small system of linear equations. <p> For example, using the results of [4, 12], a small optimal mixed strategy can be found for any player in a two-person zero-sum game with perfect recall. Similarly, using the results of <ref> [6] </ref>, an equilibrium pair of small mixed strategies can be found in any two-person game with perfect recall. In general, the representation of a small mixed strategy might not be smaller than the representation of the behavior strategy that induces it. <p> To our knowledge, this was the first exponential-time algorithm for this problem, and is still the only one that works for games with imperfect recall. (For the case of perfect recall games, the recent algorithms of [12] and <ref> [6] </ref> are better.) We also briefly discuss how this result can be used to construct an efficient variant of Wilson's algorithm [14]. <p> We chose not to present this revised algorithm and the associated analysis since, for the case of perfect recall games, a much better algorithm already exists <ref> [6] </ref>.
Reference: [7] <author> H. W. Kuhn, </author> <title> Extensive games, </title> <booktitle> Proc. </booktitle> <institution> National Academy of Sciences of the U.S.A. </institution> <month> 36 </month> <year> (1950), </year> <month> 570-576. </month> <title> [8] , Extensive games and the problem of information, Contributions to the Theory of Games II (Princeton) (H. </title> <editor> W. Kuhn and A. W. Tucker, eds.), </editor> <publisher> Princeton University Press, Princeton, </publisher> <year> 1953, </year> <pages> pp. 193-216. </pages>
Reference-contexts: A behavior strategy assigns a probability to each possible decision of the player. Thus, it also can be represented in linear space. A mixed strategy assigns a probability to each pure strategy. The number of pure strategies is usually exponential in the size of the game tree <ref> [7, 4] </ref>. Thus, the size of a mixed strategy may be exponential in the size of the tree. In many useful mixed strategies, however, only a small number of pure strategies receive positive probabilities. <p> The information set u is never reached in play, so the decision there cannot affect the outcome of the game. Pure strategies that differ only in choices at irrelevant information sets have been called equivalent by Kuhn [8] and even identified <ref> [7] </ref>. This identification can be done by leaving the choices at the irrelevant information sets blank. In this formulation, a pure strategy would represent an entire equivalence class of pure strategies.
Reference: [9] <author> C. E. Lemke and J. T. Howson, Jr., </author> <title> Equilibrium points in bimatrix games, </title> <journal> Journal of the Society for Industrial and Applied Mathematics 12 (1964), </journal> <pages> 413-423. </pages>
Reference-contexts: Mixed strategies whose support is "small" can be specified with a sparse representation. The relatively "manageable" size of these strategies may reduce the space and time complexities of algorithms handling them. This idea was first utilized by Wilson [14] in his modified version of the Lemke-Howson algorithm <ref> [9] </ref>. This algorithm searches the space of mixed strategies pairs for an equilibrium of a general two-person game. Wilson's variant represents the strategies encountered in the search sparsely; i.e., it maintains only the pure strategies in their support, and generates additional pure strategies, as needed, directly from the game tree. <p> Hence, we obtain an algorithm whose running time is: O m t 2 poly (t) (m 1 + m 2 ) t 2 1 m t+1 2 poly (t) An alternative approach to the problem of finding equilibria was proposed by Lemke and How-son <ref> [9] </ref>. Their algorithm searches for a single equilibrium, and cannot be used to enumerate all of them. The algorithm generates a sequence of basic solutions to the underlying system of linear equations.
Reference: [10] <author> J. Rosenmuller, </author> <title> On a generalization of the Lemke-Howson algorithm to noncooperative N - person games, </title> <note> SIAM Journal on Applied Mathematics 21 (1971), 73-79. </note>
Reference-contexts: If that payoff is better than h i () then is not an equilibrium. 6 We could apply this scheme to any of the algorithms for solving N -player normal form games, for example, the algorithms of Rosenmuller <ref> [10] </ref> or Wilson [13]. This would result in an algorithm for finding equilibria in N -player extensive-form games. We now show how this scheme can be used to find equilibria in two-person extensive-form games.
Reference: [11] <author> J. Swinkels, </author> <title> Subgames and the reduced normal form, </title> <type> Tech. Report 344, </type> <institution> Econometric Research Program, Princeton University, </institution> <year> 1989. </year>
Reference-contexts: This reduction of the space of pure strategies forms the basis for the reduced normal form of an extensive game. Further reductions for a particular given payoff function have been considered by Dalkey [3] and by Swinkels <ref> [11] </ref>, but these provide no additional savings in the context of a generic game. Unfortunately, the savings provided by the reduced normal form are often limited. Consider a game where the player has parallel information sets|ones where the player's actions cannot affect which is reached.
Reference: [12] <author> B. von Stengel, </author> <title> LP representation and efficient computation of behavior strategies, </title> <type> Tech. Report S-9301, </type> <institution> University of the Federal Armed Forces at Munich, </institution> <year> 1993. </year>
Reference-contexts: That is, the weight distribution on the nodes completely specifies the observable behavior of . Realization weights were first introduced by Koller and Megiddo [4] in the context of perfect recall games. In their algorithm, and in the more recent ones of von Stengel <ref> [12] </ref> and of Koller, Megiddo, and von Stengel [6], the realization weights corresponding to equilibrium mixed strategies are computed directly. This relies on the fact that, for games with perfect recall, realization weights can be described using a small system of linear equations. <p> In particular, for any strategy of a player with perfect recall, a small mixed strategy can be found in polynomial time. For example, using the results of <ref> [4, 12] </ref>, a small optimal mixed strategy can be found for any player in a two-person zero-sum game with perfect recall. Similarly, using the results of [6], an equilibrium pair of small mixed strategies can be found in any two-person game with perfect recall. <p> To our knowledge, this was the first exponential-time algorithm for this problem, and is still the only one that works for games with imperfect recall. (For the case of perfect recall games, the recent algorithms of <ref> [12] </ref> and [6] are better.) We also briefly discuss how this result can be used to construct an efficient variant of Wilson's algorithm [14]. <p> We could have defined "small" based on this number, instead of on jT j. We chose to use the less precise definition for the sake of simplicity. The definition of sequences and realization plans over sequences also appears in the work of von Stengel <ref> [12] </ref>, who utilizes them to define and solve a generalized sequence form of a multi-player game. <p> Otherwise, we define fi j (c) to be r a c r a (this definition is now clearly independent of our choice of a). See <ref> [4, 12] </ref> for further details and proof of correctness.
Reference: [13] <author> R. Wilson, </author> <title> Computing equilibria of N -person games, </title> <note> SIAM Journal on Applied Mathematics 21 (1971), </note> <month> 80-87. </month> <title> [14] , Computing equilibria of two-person games from the extensive form, </title> <booktitle> Management Science 18 (1972), </booktitle> <pages> 448-460. 16 </pages>
Reference-contexts: If that payoff is better than h i () then is not an equilibrium. 6 We could apply this scheme to any of the algorithms for solving N -player normal form games, for example, the algorithms of Rosenmuller [10] or Wilson <ref> [13] </ref>. This would result in an algorithm for finding equilibria in N -player extensive-form games. We now show how this scheme can be used to find equilibria in two-person extensive-form games.
References-found: 11

