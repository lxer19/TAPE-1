URL: http://www.caip.rutgers.edu/~yuk/papers/icassp96.yuk.ps
Refering-URL: 
Root-URL: 
Email: fyuk,cche,jin,qling@caip.rutgers.edu  
Title: ENVIRONMENT-INDEPENDENT CONTINUOUS SPEECH RECOGNITION USING NEURAL NETWORKS AND HIDDEN MARKOV MODELS networks are trained to
Author: Dong-Suk Yuk ChiWei Che Limin Jin Qiguang Lin 
Address: Piscataway, NJ 08855-1390, USA  
Affiliation: CAIP Center, Rutgers University,  
Date: 3358-3361, May 1996,  
Note: ICASSP, Vol.6, pp.  c flIEEE 1  Furthermore, since neural  
Abstract: Environment-independent continuous speech recognition is important for the successful development of speech rec- ognizers in real world applications. Linear compensation methods do not work well if the mismatches between training and testing environments are not linear. In this paper, neural network compensation technique is explored to mitigate the distortion resulting from additive noise, distant-talking, or telephone channels. The advantage of neural network compensation method is that retraining of a speech recognizer for each particular application is avoided. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Gong, </author> <title> "Speech recognition in noisy environments: A survey", </title> <journal> Speech Communication, </journal> <volume> Vol. 16, No. 3, </volume> <pages> pp. 261-291, </pages> <month> April </month> <year> 1995. </year>
Reference: [2] <author> F. Liu, A. Acero, R. Stern, </author> <title> "Efficient joint compensa-tion of speech for the effects of additive noise and linear filtering", </title> <booktitle> Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> Vol. 1, </volume> <pages> pp. 257-260, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Figure 5 shows the performance of neural network compensation method as a function of adaptation data used to train MLP for single speaker. It can be seen that the neural network compensation method using 10 utterances of adaptation data (79.0%) works better than SNR-dependent cepstral normalization, SDCN <ref> [2] </ref> (65.3%). It can be also seen that the neural network compensation method using 100 utterances of adaptation data (87.3%) works as well as a retrained recognizer (87.6%) which is trained on 600 utterances of distant-talking speech data.
Reference: [3] <author> C. Lee, C. Lin, B. Juang, </author> <title> "A study on speaker adapta-tion of the parameteres of continuous density Hidden Markov Models", </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> Vol. 39, No. 4, </volume> <pages> pp. 806-814, </pages> <month> April </month> <year> 1991. </year>
Reference: [4] <author> M. Gales, S. Young, </author> <title> "Robust continuous speech recog-nition using parallel model combination", </title> <type> Technical Report 172, </type> <institution> Cambridge University Engineering Department, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: It can be seen that neural network compensation method (91.9%) works slightly better than a retrained recognizer (91.4%). While retraining a recognizer requires 600 utterances, neural network compensation method requires only 100 utterances. Compared with <ref> [4] </ref>, it is found that neural network compensation method works better than the parallel model combi <p>- nation (PMC). 50 60 70 80 90 Word Accuracy (%) Noisy Speech Clean Speech Retrained on Noisy Speech Neural Network 91.4 60.8 method for ambient noisy environment.
Reference: [5] <author> R. Lippmann, </author> <title> "An introduction to computing with neural nets", </title> <journal> IEEE ASSP Magazine, </journal> <pages> pp. 4-22, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: We use multi-layer perceptrons (MLP) to establish the mapping function of the mel frequency cepstral coefficients (MFCC) between the testing speech and the training speech. The neural network compensation method has the following advantages. Since MLP can learn arbitrary nonlinear relation between input and target <ref> [5] </ref>, it is able to handle both linear and nonlinear mismatches such as ambient noise, reverberation, and channel mismatches. Further- more, since MFCC of distorted speech is transformed to that of clean speech, neural network compensation method may outperform a retrained recognizer.
Reference: [6] <author> Q. Lin, C. Che, B. de Vries, J. Pearson, J. Flanagan, </author> <title> "Experiments on distant-talking speech recogni-tion", </title> <booktitle> Proceedings of ARPA Spoken Language Technology Workshop, </booktitle> <address> Austin, Texas, </address> <pages> pp. 187-192, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: DISTANT-TALKING SPEECH RECOGNITION A distant-talking version of the ARPA RM database has been created via playback of a high-quality loudspeaker in a noisy, reverberant enclosure, and picked up by a line beam- forming microphone array positioned at a distance of 12 feet from the speaker <ref> [6] </ref>. This speech corpus is used to evaluate neural network compensation capability for distant-talking speech recognition. The same speech recognizer used in the previous section is used for this experiment. Performance is evaluated on 75 utterances of the ARPA evaluation sets.
Reference: [7] <author> E. Jan, P. Svaizer, J. Flanagan, </author> <title> "Matched-filter pro-cessing of microphone array for spatial volume selec-tivity", </title> <booktitle> Proceedings of IEEE International Symposium on Circuits and Systems, Seattle, </booktitle> <pages> pp. 1460-1463, </pages> <year> 1995. </year>
Reference-contexts: ICASSP, Vol.6, pp. 3358-3361, May 1996, c flIEEE 3 3.1. Neural Network for Distant-Talking Distant-talking speech is distorted by room reverberation, ambient noise interference, and channel mismatch. To deal with room reverberation, a microphone array is used for hands-free sound capture, because it provides better sound quality for distant-talking <ref> [7] </ref>. The neural network compensation method is then utilized to deal with channel mismatch and the remaining room reverberation that microphone array can not remove completely.
Reference: [8] <author> K. Lang, A. Waibel, </author> <title> "A time-delay neural network ar-chitecture for isolated word recognition", </title> <booktitle> Neural Networks, </booktitle> <volume> Vol. 3, </volume> <pages> pp. 23-43, </pages> <year> 1990. </year>
Reference: [9] <author> Q. Lin, C. Che, D. Yuk, J. Flanagan, </author> <title> "A microphone array and neural network system", </title> <booktitle> Proceedings of 15th Speech Research Symposium, </booktitle> <address> Baltimore, Maryland, </address> <pages> pp. 111-123, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: To find out an optimal neural network architecture for distant-talking compensation, we have experimented with several different neural network architectures such as time- delay neural network (TDNN)[8], MLP with delta and/or delta-delta coefficients constraints <ref> [9] </ref>. It is observed that TDNN does not work better than MLP for this task. It is also observed that including first and second derivatives as the constraints during the training procedure, does not work better than simple MLP without using derivatives.
Reference: [10] <author> J. Chang, V. Zue, </author> <title> "Speech recognition system robust-ness to microphone variations", </title> <booktitle> Proceedings of 15th Speech Research Symposium, </booktitle> <address> Baltimore, Maryland, </address> <pages> pp. 181-188, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Experimental Results Phone recognition accuracy is given in Figure 6. It can be seen that the result of neural network compensation (34.4%) is competitive with a retrained recognizer (38.7%). The neural network method works better than SDCN (31.6%). Compared with <ref> [10] </ref>, it is found that the present neural 20 30 40 50 Phone Accuarcy (%) NTIMIT SDCN Neural Network Retrained on NTIMIT TIMIT 25.4 34.4 54.0 method for telephone speech.
References-found: 10

