URL: http://www.cs.berkeley.edu/~yelick/arvindk/connect-dimacs95.ps
Refering-URL: http://www.cs.berkeley.edu/~yelick/papers.html
Root-URL: 
Title: Connected Components on Distributed Memory Machines  
Author: Arvind Krishnamurthy, Steven Lumetta, David E. Culler, and Katherine Yelick 
Address: Berkeley  
Affiliation: Computer Science Division University of California,  
Abstract: In this paper, we describe an implementation of the connected components algorithm on a distributed memory machine. A direct implementation of the PRAM algorithm results in an inefficient implementation due to the huge number of remote accesses generated by the algorithm. Instead, we use a hybrid algorithm that invokes the sequential algorithm as a local preprocessing phase before entering a global phase, which is a modified version of the PRAM algorithm. We use the Split-C language, which provides the abstraction of a global address space, for building the distributed graph data structure. We obtain speedups in the order of 20 on a 32 processor CM5 for certain kinds of graphs.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Awerbuch, Y. Shiloach, </author> <title> "New connectivity and MSF algorithms for Ultracomputer and PRAM," </title> <booktitle> International Conference on Parallel Processing, </booktitle> <year> 1983, </year> <pages> pp. 175-179. </pages>
Reference: [2] <author> D. E. Culler, A. Dusseau, S. C. Goldstein, A. Krishnamurthy, S. Lumetta, T. von Eicken, K. Yelick, </author> <title> "Parallel Programming in Split-C," </title> <booktitle> Proceedings of Supercomputing '93, </booktitle> <address> Portland, Oregon, </address> <month> November </month> <year> 1993, </year> <pages> pp. 262-273. </pages> <note> October 3, 1994 - 12 : 43 DRAFT 21 </note>
Reference-contexts: Our selection of algorithms and graphs is based on a study by Greiner [3] of the pragmatic aspects of connected component PRAM algorithms on shared memory and SIMD platforms. We extend the results to MIMD machines, namely the CM-5, using the Split-C language developed at Berkeley <ref> [2] </ref>. We discuss the standard PRAM algorithm in section 2, and a simple implementation of the algorithm is presented in section 3. In section 4, we describe the different optimizations used to improve the running time. <p> In the global phases, the algorithm must address issues that arise when some data resides in the memory of remote processors and must make an effort to handle these remote references as efficiently as possible. Fortunately, we can make use of the Split-C language <ref> [2] </ref> to simplify our task. Split-C provides the abstraction of a global address space and simple but powerful data motion primitives, allowing the programmer to optimize his program in a straightforward manner to any degree desired, and one need not second guess or work around the compiler.
Reference: [3] <author> J. Greiner, </author> <title> "A Comparison of Parallel Algorithms for Connected Components," </title> <booktitle> to appear in the Symposium on Parallel Algorithms and Architectures 1994. </booktitle>
Reference-contexts: In this paper, we explore a set of PRAM algorithms for finding the connected components of a graph using this hybrid approach. Our selection of algorithms and graphs is based on a study by Greiner <ref> [3] </ref> of the pragmatic aspects of connected component PRAM algorithms on shared memory and SIMD platforms. We extend the results to MIMD machines, namely the CM-5, using the Split-C language developed at Berkeley [2]. <p> We drew four of the five types of graphs used directly from Greiner <ref> [3] </ref>, but the fifth type given in that work we found to be fairly pointless (the graphs have one connected component with high probability), and instead used a modified form of the graph. The first two graphs are built on a two dimensional toroidal mesh. <p> October 3, 1994 - 12 : 43 DRAFT 20 6 Comparison with Earlier Work Though a lot of research has been done in proposing theoretically optimal algorithms for finding connected components of a graph, not much work has been done in implementing these algorithms efficiently on parallel machines. Greiner <ref> [3] </ref> implemented the connected components algorithm on the Cray C-90 and on the Connection Machine 2. However, the C-90 is a shared bus multiprocessor system, and the CM2 is a SIMD machine. These machines are easier to program than distributed memory MIMD machines, which are however more scalable.
Reference: [4] <author> S. Lumetta, </author> <title> "A Debugger for the Split-C Language," </title> <note> available from author. </note>
Reference-contexts: In addition to the natural flavor of the Split-C language, it has the added advantage of providing debugging support via the Split-C Debugger <ref> [4] </ref>. This kind of support is a key factor in writing any kind of program, but is poor in some parallel programming environments. Having briefly discussed our tools, we can now introduce the algorithm.
Reference: [5] <author> Y. Shiloach, U. Vishkin, </author> <title> "An O(log n) Parallel Connectivity Algorithm," </title> <journal> Journal of Algorithms, </journal> <volume> No. 3, </volume> <year> 1982, </year> <pages> pp. 57-67. </pages>
Reference-contexts: In section 5, we present the results from running the program on a CM5, and section 6 compares our results with other implementations of the algorithm. 2 Basic Algorithm Our implementation is based on the connected components algorithm presented by Shiloach and Vishkin <ref> [5] </ref>. In this section, we will briefly describe the different stages of the algorithm. <p> The unconditional hooking operation is necessary to obtain log (n) bound on the running time, but is not necessary for correctness <ref> [5] </ref>. We can now provide the pseudo-code for the algorithm. We assume there is one processor for every vertex and for every edge in the graph. The processors can therefore be classified into vertex processors and edge processors.
Reference: [6] <author> T. von Eicken, D. E. Culler, S. C. Goldstein, K. E. Schauser, </author> <title> "Active Messages: a Mechanism for Integrated Communication and Computation," </title> <booktitle> Proceedings of the International Symposium on Computer Architecture, </booktitle> <year> 1992 </year>
Reference: [7] <institution> Thinking Machines Corporation, </institution> <note> "CMMD Reference Manual," Version 3.0, </note> <month> May </month> <year> 1993. </year>
References-found: 7

