URL: http://www.cs.colostate.edu/~pyeatt/4wces.ps
Refering-URL: http://www.cs.colostate.edu/~pyeatt/
Root-URL: 
Email: email: fpyeatt,howeg@cs.colostate.edu  
Phone: tele: 1-970-491-7589 fax: 1-970-491-2466  
Title: REINFORCEMENT LEARNING FOR COORDINATED REACTIVE CONTROL  
Author: Larry D. Pyeatt Adele E. Howe 
Web: URL: http://www.cs.colostate.edu/~fpyeatt,howeg  
Address: Fort Collins, CO 80523  
Affiliation: Computer Science Department Colorado State University  
Abstract: The demands of rapid response and the complexity of many environments make it difficult to decompose, tune and coordinate reactive behaviors while ensuring consistency. Reinforcement learning networks can address the tuning problem, but do not address the problem of decomposition and coordination. We hypothesize that interacting reactions can often be decomposed into separate control tasks resident in separate networks and that the interaction can be coordinated through the tuning mechanism and a higher level controller. To explore these issues, we have implemented a reinforcement learning architecture as the reactive component of a two layer control system for a simulated race car. By varying the architecture, we test whether decomposing reactivity into separate controllers leads to superior overall performance and learning convergence in our domain. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Charles W. Anderson. </author> <title> Strategy learning with multilayer connectionist representations. </title> <booktitle> In Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <pages> pages 103-114, </pages> <year> 1989. </year>
Reference: [2] <author> A.G. Barto, R.S. Sutton, and C.J. Watkins. </author> <title> Learning and sequential decision making. </title> <type> Technical report, COINS Technical Report 89-95, </type> <institution> Dept. of Computer and Information Science, University of Massachusetts, </institution> <year> 1989. </year>
Reference: [3] <author> Daniel Bullock, Stephen Grossberg, and Frank Guenther. </author> <title> A self-organizing neural network model for redundant sensory-motor control, motor equivalence, and tool use. </title> <booktitle> In International Joint Conference on Neural Networks, </booktitle> <pages> pages 91-96, </pages> <address> Baltimore, 1992. </address> <publisher> IEEE. </publisher>
Reference: [4] <author> R. F. Comoglio and A. S. Pandya. </author> <title> Using a cerebellar model arithmetic computer (cmac) neural network to control an autonomous underwater vehicle. </title> <booktitle> In International Joint Conference on Neural Networks, </booktitle> <pages> pages 781-786, </pages> <address> Baltimore, 1992. </address> <publisher> IEEE. </publisher>
Reference: [5] <author> David S. Day. </author> <title> Integrating reaction and reflection in an autonomous agent: An empirical study. </title> <type> Unpublished, </type> <year> 1990. </year>
Reference: [6] <author> M. Dorigo and M. Colombetti. </author> <title> Robot shaping: developing autonomous agents through learning. </title> <journal> Artificial Intelligence, </journal> <volume> 71(2) </volume> <pages> 321-370, </pages> <month> De-cember </month> <year> 1994. </year>
Reference: [7] <author> Gita Drishnaswamy, Marcelo H. Ang Jr., and Gerry B. Andeen. </author> <title> Structured neural-network approach to robot motion control. </title> <booktitle> In International Joint Conference on Neural Networks, </booktitle> <pages> pages 1059-1066. </pages> <publisher> IEEE, </publisher> <year> 1991. </year>
Reference: [8] <author> W. Feiten, U. Wienkop, A. Huster, and G. Law-itsky. </author> <title> Simulation in the design of an autonomous mobile robot. </title> <editor> In R. Trappl, editor, </editor> <booktitle> Cybernetics and Systems '94, </booktitle> <pages> pages 1499-1506. </pages> <publisher> World Scientific Publishing, </publisher> <address> Singapore, </address> <year> 1994. </year> <title> Reinforcement Learning for Coordinated Reactive Control </title>
Reference: [9] <author> D.A. Handelman, S.H. Lane, and J.J. Gelfand. </author> <title> Integrating knowledge-based system and neural network techniques for robotic skill acquisition. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (IJCAI-89), </booktitle> <pages> pages 193-198, </pages> <address> Los Altos, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [10] <author> Adele E. Howe and Paul R. Cohen. </author> <title> Responding to environmental change. </title> <editor> In Katia P. Sycara, editor, </editor> <booktitle> Proceedings of the Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pages 85-92. </pages> <publisher> Morgan Kaufmann Publishers, Inc, </publisher> <month> November </month> <year> 1990. </year>
Reference: [11] <author> M. Knick and F.J. Radermacher. </author> <title> Integration of sub-symbolic and symbolic information processing in robot control. </title> <booktitle> In Proceedings of Third Annual Conference on AI, Simulation and Planning in High Autonomy Systems, </booktitle> <pages> pages 238-243, </pages> <address> Perth, Western Australia, </address> <month> July </month> <year> 1992. </year>
Reference: [12] <author> Kurt Konolige. </author> <title> Erratic robot simulator. </title> <note> Anonymous ftp from ftp://ftp.ai.sri.com/- pub/konolige/erratic-ver2b.tar.Z, </note> <year> 1994. </year>
Reference: [13] <author> Long-H Lin. </author> <title> Self-improving reactive agents based on reinforcement learning, planning and teaching. </title> <journal> Machine Learning, </journal> 8(3/4):69-97, 1992. 
Reference: [14] <author> Huan Liu, Thea Iberall, and George A. Beckey. </author> <title> Neural network architecture for robot hand control. </title> <booktitle> In Proceedings of IEEE International Conference on Neural Networks. IEEE, </booktitle> <month> July </month> <year> 1989. </year>
Reference: [15] <author> Min Meng and A.C. Kak. </author> <title> Mobile robot navigation using neural networks and nonmetrical environment models. </title> <journal> IEEE Control Systems, </journal> <pages> pages 30-39, </pages> <month> October </month> <year> 1993. </year>
Reference: [16] <author> A.N. Poo, M.H. Ang Jr., C.L. Teo, and Qing Li. </author> <title> Performance of a neuro-model-based robot controller: adaptability and noise rejection. </title> <journal> Intelligent Systems Engineering, </journal> <volume> 1(1) </volume> <pages> 50-62, </pages> <year> 1992. </year>
Reference: [17] <author> Jude W. Shavlik. </author> <title> Combining symbolic and neural learning. </title> <journal> Machine Learning, </journal> <volume> 14(3) </volume> <pages> 321-331, </pages> <year> 1994. </year>
Reference: [18] <author> Richard S. Sutton. </author> <title> Temporal Credit Assignment in Reinforcement Learning. </title> <type> PhD thesis, </type> <institution> Dept. of Computer and Information Science, University of Massachusetts, </institution> <year> 1984. </year>
Reference: [19] <author> Richard S. Sutton. </author> <title> Learning to predict by the methods of temporal differences. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 9-44, </pages> <year> 1988. </year>
Reference: [20] <author> Mitchell E. Timin. </author> <title> Robot Auto Racing Simulator. </title> <note> available from http://www.ebc.ee /~mremm/rars/rars.htm, </note> <year> 1995. </year>
Reference: [21] <author> David E. Wilkins, Karen L. Myers, John D. Lowrance, and Leonard P. Wesley. </author> <title> Planning and reacting in uncertain and dynamic environments. </title> <journal> Journal of Experimental and Theoretical AI, </journal> <volume> 7, </volume> <year> 1994. </year>
References-found: 21

