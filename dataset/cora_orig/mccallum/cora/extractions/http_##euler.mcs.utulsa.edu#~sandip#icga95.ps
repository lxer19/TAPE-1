URL: http://euler.mcs.utulsa.edu/~sandip/icga95.ps
Refering-URL: http://euler.mcs.utulsa.edu/~sandip/GAGP.html
Root-URL: 
Email: e-mail: [haynes,rogerw,sandip,dschoen]@euler.mcs.utulsa.edu  
Title: Strongly Typed Genetic Programming in Evolving Cooperation Strategies  
Author: Thomas Haynes, Roger Wainwright, Sandip Sen Dale Schoenefeld 
Address: Tulsa  
Affiliation: Department of Mathematical Computer Sciences The University of  
Abstract: A key concern in genetic programming (GP) is the size of the state-space which must be searched for large and complex problem domains. One method to reduce the state-space size is by using Strongly Typed Genetic Programming (STGP). We applied both GP and STGP to construct cooperation strategies to be used by multiple predator agents to pursue and capture a prey agent on a grid-world. This domain has been extensively studied in Distributed Artificial Intelligence (DAI) as an easy-to-describe but difficult-to-solve cooperation problem. The evolved programs from our systems are competitive with manually derived greedy algorithms. In particular the STGP paradigm evolved strategies in which the predators were able to achieve their goal without explicitly sensing the location of other predators or communicating with other predators. This is an improvement over previous research in this area. The results of our experiments indicate that STGP is able to evolve programs that perform significantly better than GP evolved programs. In addition, the programs generated by STGP were easier to understand.
Abstract-found: 1
Intro-found: 1
Reference: [Angeline 1994] <author> Peter J. Angeline. </author> <title> Genetic programming and emergent intelligence. </title> <editor> In Kenneth E. Kinnear, Jr., editor, </editor> <booktitle> Advances in Genetic Programming, </booktitle> <pages> pages 75-97. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: To address this pressing problem, researchers have been investigating various means to reduce the GP state-space size for complex problems. Notable work in this area include Automatically Defined Functions (ADF) [Kinnear 1994b, Koza 1994], module acquisition (MA) <ref> [Angeline 1994, Kinnear 1994b] </ref>, and Strongly Typed Genetic Programming (STGP) [Montana 1994]. The first two methods utilize function decomposition to reduce the state-space. The STGP method utilizes structuring of the GP S-expression to reduce the state-space.
Reference: [Benda 1985] <author> M. Benda, V. Jagannathan, and R. Dodhi-awalla. </author> <title> On optimal cooperation of knowledge sources. </title> <type> Technical Report BCS-G2010-28, </type> <institution> Boeing AI Center, Boeing Computer Services, Bellevue, WA, </institution> <month> August </month> <year> 1985. </year>
Reference-contexts: depth was increased to six, the size of the search space for the STGP implement ation was 10 11 , while the size of the GP search space was 10 38 . 3 The Pursuit Problem The original version of the predator-prey pursuit problem was introduced by Benda, et al. <ref> [Benda 1985] </ref> and consisted of four blue (predator) agents trying to capture a red (prey) agent by surrounding it from four directions on a grid-world. This problem is a common domain used in Distributed Artificial Intelligence research to evaluate techniques for developing cooperation strategies.
Reference: [Gasser 1989] <author> Les Gasser, Nicolas Rouquette, Randall W. Hill, and John Lieb. </author> <title> Representing and using organizational knowledge in DAI systems. </title> <editor> In Les Gasser and Michael N. Huhns, editors, </editor> <booktitle> Distributed Artificial Intelligence, volume 2 of Research Notes in Artificial Intelligence, </booktitle> <pages> pages 55-78. </pages> <publisher> Pitman, </publisher> <year> 1989. </year>
Reference-contexts: This domain involves multiple predator agents trying to capture a prey agent by surrounding it. The predator-prey problem has been widely used to test new coordination schemes <ref> [Gasser 1989, Stephens 1989, Stephens 1990, Korf 1992] </ref>. The problem is easy to describe, but extremely difficult to solve; the performance of even the best manually generated coordination strategies is less than satisfactory. We will show that STGP evolved coordination strategies perform competitively with the best available manually generated strategies. <p> The goal of this problem was to show the effectiveness of nine organizational structures, with varying degrees of agent cooperation and control, on the efficiency with which the predator agents could capture the prey. Gasser et al. <ref> [Gasser 1989] </ref> approached this problem by allowing the predators to occupy and maintain what is called a Lieb configuration while homing in on the prey. In a Lieb configuration each predator occupies a different quadrant, where a quadrant is defined by diagonals intersecting at the current location of the prey.
Reference: [Haynes 1994] <author> Thomas Haynes, Roger Wainwright, and Sandip Sen. </author> <title> Evolving cooperation strategies. </title> <type> Technical Report No. </type> <institution> UTULSA-MCS-94-10, The University of Tulsa, </institution> <month> December 16, </month> <year> 1994. </year>
Reference-contexts: It is nearly impossible to identify or even prove the existence of the best cooperation strategy. In most cases a cooperation strategy is chosen if it is reasonably good. In <ref> [Haynes 1994] </ref>, we presented a new approach to developing cooperation strategies for multi-agent problem solving situations. <p> The approach proposed in <ref> [Haynes 1994] </ref> for developing cooperation strategies for multi-agent problems is completely domain independent, and uses the GP strategy. <p> The best GP and STGP programs generated were tested against data from Stephens [Stephens 1989] and 1000 random test cases of our own. The averaged results are shown in Table 2. Four human derived algorithms, discussed in detail in <ref> [Haynes 1994] </ref>, are also shown in Table 2: Korf's max norm (MN), Korf's Manhattan distance (MD), Korf's original max norm (MNO), and Korf's original Manhattan distance (MDO). The max norm algorithms determine the best move to make based on the diagonal distance between a predator and the prey.
Reference: [Haynes 1995] <author> Thomas D. Haynes and Roger L. Wainwright. </author> <title> A simulation of adaptive agents in a hostile environment. </title> <booktitle> In Proceedings of the 1995 ACM Symposium on Applied Computing, </booktitle> <pages> pages 318-323. </pages> <publisher> ACM Press, </publisher> <year> 1995. </year>
Reference-contexts: The fitness measure becomes an average of the training cases. Note these training cases can be either the same throughout all generations or randomly generated for each generation. 5 Experimental Results The STGP system, called GPengine, used in this research is an extension of the package developed in <ref> [Haynes 1995] </ref> and is written in C. Furthermore, it can be used as either a STGP or GP system depending on a runtime switch.
Reference: [Kinnear 1994a] <editor> Kenneth E. Kinnear, Jr., editor. </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: The representation language used in GPs are computer programs represented as Lisp S-expressions in a parse tree. Recently GP has attracted a tremendous number of researchers because of the wide range of applicability of this paradigm, and the easily interpretable form of the solutions <ref> [Kinnear 1994a, Koza 1992, Koza 1994] </ref>. We assume the reader is familiar with the fundamentals of GAs and GPs. In GP the user must specify all of the functions, variables and constants that can be used as nodes in a parse tree.
Reference: [Kinnear 1994b] <author> Kenneth E. Kinnear, Jr. </author> <title> Alternatives in automatic function definition: A comparision of performance. </title> <editor> In Kenneth E. Kinnear, Jr., editor, </editor> <booktitle> Advances in Genetic Programming, </booktitle> <pages> pages 119-141. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: To address this pressing problem, researchers have been investigating various means to reduce the GP state-space size for complex problems. Notable work in this area include Automatically Defined Functions (ADF) <ref> [Kinnear 1994b, Koza 1994] </ref>, module acquisition (MA) [Angeline 1994, Kinnear 1994b], and Strongly Typed Genetic Programming (STGP) [Montana 1994]. The first two methods utilize function decomposition to reduce the state-space. The STGP method utilizes structuring of the GP S-expression to reduce the state-space. <p> To address this pressing problem, researchers have been investigating various means to reduce the GP state-space size for complex problems. Notable work in this area include Automatically Defined Functions (ADF) [Kinnear 1994b, Koza 1994], module acquisition (MA) <ref> [Angeline 1994, Kinnear 1994b] </ref>, and Strongly Typed Genetic Programming (STGP) [Montana 1994]. The first two methods utilize function decomposition to reduce the state-space. The STGP method utilizes structuring of the GP S-expression to reduce the state-space.
Reference: [Korf 1992] <author> Richard E. Korf. </author> <title> A simple solution to pursuit games. </title> <booktitle> In Working Papers of the 11th International Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pages 183-194, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: This domain involves multiple predator agents trying to capture a prey agent by surrounding it. The predator-prey problem has been widely used to test new coordination schemes <ref> [Gasser 1989, Stephens 1989, Stephens 1990, Korf 1992] </ref>. The problem is easy to describe, but extremely difficult to solve; the performance of even the best manually generated coordination strategies is less than satisfactory. We will show that STGP evolved coordination strategies perform competitively with the best available manually generated strategies. <p> In a Lieb configuration each predator occupies a different quadrant, where a quadrant is defined by diagonals intersecting at the current location of the prey. This study did not provide any experimental results. Hence their research is difficult to compare with other work on this problem. Korf <ref> [Korf 1992] </ref> claims in his research that a discret-ization of the continuous world that allows only horizontal and vertical movements is a poor approximation. He calls this the orthogonal game. Korf developed several greedy solutions to problems where eight predators are allowed to move orthogonally and diagonally. <p> Figure 2 (b) shows the strategy for a deterministic Korf's max norm, a modification of the algorithm presented in <ref> [Korf 1992] </ref>. It is interesting to note how the agents converge on the prey using the policy. More significantly, the STGP solution is stable, in that once the prey is captured, no predator makes a move that allows the prey to escape.
Reference: [Koza 1992] <author> John R. Koza. </author> <title> Genetic Programming, On the Programming of Computers by Means of Natural Selection. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Our experiments demonstrate the relative advantage of using STGP over GP. 2 Strongly Typed Genetic Programming Genetic programming (GP) is a powerful technique for automatically generating computer programs to perform a wide variety of tasks <ref> [Koza 1992] </ref>. The GP uses the traditional genetic algorithm (GA) operators for selection and recombination of individuals from one population of structures to form another population. The representation language used in GPs are computer programs represented as Lisp S-expressions in a parse tree. <p> The representation language used in GPs are computer programs represented as Lisp S-expressions in a parse tree. Recently GP has attracted a tremendous number of researchers because of the wide range of applicability of this paradigm, and the easily interpretable form of the solutions <ref> [Kinnear 1994a, Koza 1992, Koza 1994] </ref>. We assume the reader is familiar with the fundamentals of GAs and GPs. In GP the user must specify all of the functions, variables and constants that can be used as nodes in a parse tree. <p> Functions which require arguments form the branches of the parse trees, and are called non-terminals. The set of all terminals is called the terminal set, and the set of all non-terminals is called the non-terminal set. Note the term non-terminal is what Koza <ref> [Koza 1992] </ref> calls a function. One serious constraint on the user-defined terminals and non-terminals is called closure. Closure means that all of the non-terminals must accept arguments of a single data type (i.e. a float) and return values of the same data type. <p> Hence, closure means any element can be a child node in a parse tree for any other element without having conflicting data types. Montana [Montana 1994] claims that closure is a serious limitation to genetic programming. Koza <ref> [Koza 1992] </ref> describes a way to relax the closure constraint using the concept of constrained syntax structures. Koza used tree generation routines which only generated legal trees. He also used operations on the parse trees which maintain legal syntactic structures. This is one of the fundamental concepts of STGP.
Reference: [Koza 1994] <author> John R. Koza. </author> <title> Genetic Programming II, Automatic Discovery of Reusable Programs. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: To address this pressing problem, researchers have been investigating various means to reduce the GP state-space size for complex problems. Notable work in this area include Automatically Defined Functions (ADF) <ref> [Kinnear 1994b, Koza 1994] </ref>, module acquisition (MA) [Angeline 1994, Kinnear 1994b], and Strongly Typed Genetic Programming (STGP) [Montana 1994]. The first two methods utilize function decomposition to reduce the state-space. The STGP method utilizes structuring of the GP S-expression to reduce the state-space. <p> The representation language used in GPs are computer programs represented as Lisp S-expressions in a parse tree. Recently GP has attracted a tremendous number of researchers because of the wide range of applicability of this paradigm, and the easily interpretable form of the solutions <ref> [Kinnear 1994a, Koza 1992, Koza 1994] </ref>. We assume the reader is familiar with the fundamentals of GAs and GPs. In GP the user must specify all of the functions, variables and constants that can be used as nodes in a parse tree.
Reference: [Martin 1994] <author> Martin C. Martin. graphs.blt. </author> <note> GP FTP Archives, </note> <year> 1994. </year>
Reference-contexts: Furthermore, it can be used as either a STGP or GP system depending on a runtime switch. A graphical reporting system was created for X-Windows using the Tcl and Tk toolkit with the Blt extension; this system was a modification of the work by Martin <ref> [Martin 1994] </ref>. The basic setup for the simulations is described in Section 3. Programs were evolved for grid sizes ranging from 10 by 10 to 50 by 50, with the prey either moving randomly (Random) or moving away from the nearest predator (MAFNP).
Reference: [Montana 1994] <author> David J. Montana. </author> <title> Strongly typed genetic programming. </title> <type> Technical Report 7866, </type> <institution> Bolt Beranek and Newman, Inc., </institution> <month> March 25, </month> <year> 1994. </year>
Reference-contexts: Even for small terminal and function sets and tree depths, search fl This is a preprint of the paper in the Proceedings of the Sixth International Conference on Genetic Algorithms, 1995. spaces of the order of 10 30 10 40 are not uncommon <ref> [Montana 1994] </ref>. To address this pressing problem, researchers have been investigating various means to reduce the GP state-space size for complex problems. Notable work in this area include Automatically Defined Functions (ADF) [Kinnear 1994b, Koza 1994], module acquisition (MA) [Angeline 1994, Kinnear 1994b], and Strongly Typed Genetic Programming (STGP) [Montana 1994]. <p> uncommon <ref> [Montana 1994] </ref>. To address this pressing problem, researchers have been investigating various means to reduce the GP state-space size for complex problems. Notable work in this area include Automatically Defined Functions (ADF) [Kinnear 1994b, Koza 1994], module acquisition (MA) [Angeline 1994, Kinnear 1994b], and Strongly Typed Genetic Programming (STGP) [Montana 1994]. The first two methods utilize function decomposition to reduce the state-space. The STGP method utilizes structuring of the GP S-expression to reduce the state-space. We strongly agree with Montana's claim of the relative advantage of STGP over GP for complex problems [Montana 1994]. <p> 1994b], and Strongly Typed Genetic Programming (STGP) <ref> [Montana 1994] </ref>. The first two methods utilize function decomposition to reduce the state-space. The STGP method utilizes structuring of the GP S-expression to reduce the state-space. We strongly agree with Montana's claim of the relative advantage of STGP over GP for complex problems [Montana 1994]. Besides the benefit of reducing the state-space, we are interested in whether the structure imposed by strong typing will be useful for analyzing the output of the evolved program. A common problem in AI research is deciphering the complex rules derived by the learning system. <p> This means that all non-terminals return values that can be used as arguments for any other non-terminal. Hence, closure means any element can be a child node in a parse tree for any other element without having conflicting data types. Montana <ref> [Montana 1994] </ref> claims that closure is a serious limitation to genetic programming. Koza [Koza 1992] describes a way to relax the closure constraint using the concept of constrained syntax structures. Koza used tree generation routines which only generated legal trees. <p> Generally the parse tree is limited to some maximum depth. The maximum depth limit on a parse tree is one of the GP parameters. This keeps the search space finite and manageable. It also prevents trees from growing to an extremely large size. Montana <ref> [Montana 1994] </ref> presented several different examples illustrating these concepts. He used STGP in solving a wide variety of moderately complex problems involving multiple data types. He showed in his examples that STGP was very effective in obtaining solutions to his problems compared to GP. <p> STGP eliminates certain combinations of operations. Hence it necessarily reduces the size of the search space. In many cases the reduction is a significant factor. In one of Montana's examples <ref> [Montana 1994] </ref>, he presents a problem with a terminal set of size two, and a non-terminal set of size 10.
Reference: [Stephens 1989] <author> Larry M. Stephens and Matthias B. Merx. </author> <title> Agent organization as an effector of dai system performance. </title> <booktitle> In Working Papers of the 9th International Workshop on Distributed Artificial Intelligence, </booktitle> <month> September </month> <year> 1989. </year>
Reference-contexts: This domain involves multiple predator agents trying to capture a prey agent by surrounding it. The predator-prey problem has been widely used to test new coordination schemes <ref> [Gasser 1989, Stephens 1989, Stephens 1990, Korf 1992] </ref>. The problem is easy to describe, but extremely difficult to solve; the performance of even the best manually generated coordination strategies is less than satisfactory. We will show that STGP evolved coordination strategies perform competitively with the best available manually generated strategies. <p> The best STGP program is due to a good program, as evidenced by consistent scoring in Figure 1 (c). The best GP and STGP programs generated were tested against data from Stephens <ref> [Stephens 1989] </ref> and 1000 random test cases of our own. The averaged results are shown in Table 2. <p> This loophole complicates the process for determining the rules employed for movement. 6 Conclusions We used Genetic Programming to evolve cooperation strategies for predators to capture a prey moving in a grid-world. Results from both the 30 test cases used in a previous study <ref> [Stephens 1989] </ref>, and on an additional 1000 randomly generated test cases show that the solution evolved by the STGP implementation is very competitive with manually derived algorithms, and loses only to the MD algorithm.
Reference: [Stephens 1990] <author> Larry M. Stephens and Matthias B. Merx. </author> <title> The effect of agent control strategy on the performance of a DAI pursuit problem. </title> <booktitle> In Proceedings of the 1990 Distributed AI Workshop, </booktitle> <month> October </month> <year> 1990. </year> <month> 9 </month>
Reference-contexts: This domain involves multiple predator agents trying to capture a prey agent by surrounding it. The predator-prey problem has been widely used to test new coordination schemes <ref> [Gasser 1989, Stephens 1989, Stephens 1990, Korf 1992] </ref>. The problem is easy to describe, but extremely difficult to solve; the performance of even the best manually generated coordination strategies is less than satisfactory. We will show that STGP evolved coordination strategies perform competitively with the best available manually generated strategies.
References-found: 14

