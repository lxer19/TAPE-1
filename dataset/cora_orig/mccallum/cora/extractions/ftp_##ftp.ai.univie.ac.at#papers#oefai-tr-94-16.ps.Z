URL: ftp://ftp.ai.univie.ac.at/papers/oefai-tr-94-16.ps.Z
Refering-URL: http://www.ai.univie.ac.at/cgi-bin/tr-online/?number+94-16
Root-URL: 
Email: E-mail: juffi@ai.univie.ac.at  
Title: A Comparison of Pruning Methods for Relational Concept Learning  
Author: Johannes Furnkranz 
Address: Schottengasse 3 A-1010 Vienna Austria  
Affiliation: Austrian Research Institute for Artificial Intelligence  
Abstract: Pre-Pruning and Post-Pruning are two standard methods of dealing with noise in concept learning. Pre-Pruning methods are very efficient, while Post-Pruning methods typically are more accurate, but much slower, because they have to generate an overly specific concept description first. We have experimented with a variety of pruning methods, including two new methods that try to combine and integrate pre- and post-pruning in order to achieve both accuracy and efficiency. This is verified with test series in a chess position classification task.
Abstract-found: 1
Intro-found: 1
Reference: [Breiman et al., 1984] <author> L. Breiman, J. Friedman, R. Olshen, and C. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth & Brooks, </publisher> <address> Pacific Grove, CA, </address> <year> 1984. </year>
Reference-contexts: From these the most specific theory within one standard error of classification of the most accurate theory is selected as the starting theory for the post-pruning phase. This is quite similar to the approach taken in CART <ref> [Breiman et al., 1984] </ref> where the most general decision tree within this standard error margin is selected as a final theory. However, the implementation of TDP made use of several optimizations, so that finding this theory is often cheaper than fitting the noise.
Reference: [Brunk and Pazzani, 1991] <author> Clifford A. Brunk and Michael J. Pazzani. </author> <title> An investigation of noise-tolerant relational concept learning algorithms. </title> <booktitle> In Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pages 389-393, </pages> <address> Evanston, Illinois, </address> <year> 1991. </year>
Reference-contexts: restriction, because the latter is dependent on the size of the training set, so that the size of the learned concepts (and thus the amount of overfitting) may increase with training set size [Furnkranz, 1994a]. 3 3.2 Post-Pruning Post-pruning was introduced to relational learning algorithms with Reduced Error Pruning (REP) <ref> [Brunk and Pazzani, 1991] </ref> based on previous work by [Quinlan, 1987] and [Pagallo and Haussler, 1990]. <p> See also the Appendix of [Furnkranz, 1993] for a closer description of the domain. The tested algorithms were * the pre-pruning systems FOIL 6.1 [Quinlan and Cameron-Jones, 1993] and FOSSIL (with a cutoff of 0.3) [Furnkranz, 1994a], * the post-pruning systems REP <ref> [Brunk and Pazzani, 1991] </ref> and Grow [Cohen, 1993], * the combined system TDP [Furnkranz, 1994b], * and the integrated system I-REP [Furnkranz and Widmer, 1994]. All algorithms were implemented by the author in PROLOG except for FOIL 6.1 which is written in C and publicly available from ftp.cs.su.oz.au. <p> I-REP | after a bad start with only 84.55% accuracy on 100 examples | achieves the 1 In [Cohen, 1993] REP and Grow also used identical pruning operators. They were, however, slightly different from our choice. We used the operators described in <ref> [Brunk and Pazzani, 1991] </ref>. 6 7 highest accuracy. In predictive accuracy, FOIL did poorly. Its stopping criterion is depen-dent on the training set size and thus too weak to effectively prevent overfitting the noise [Furnkranz, 1994a].
Reference: [Cestnik et al., 1987] <author> Bojan Cestnik, Igor Kononenko, and Ivan Bratko. </author> <title> ASSISTANT 86: A knowledge-elicitation tool for sophisticated users. </title> <editor> In Ivan Bratko and Nada Lavrac, editors, </editor> <booktitle> Progress in Machine Learning, </booktitle> <pages> pages 31-45, </pages> <address> Wilmslow, England, 1987. </address> <publisher> Sigma Press. </publisher>
Reference-contexts: There are two fundamentally different approaches <ref> [Cestnik et al., 1987] </ref>, Pre-Pruning and Post-Pruning. In sections 3.1 and 3.2 we will review some of these methods that have been adopted for relational concept learning systems.
Reference: [Clark and Niblett, 1989] <author> Peter Clark and Tim Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 261-283, </pages> <year> 1989. </year>
Reference-contexts: Most of them learn from an attribute-value representation of the input data and their representational power thus is restricted to decision trees [Quinlan, 1983] or propositional Horn clauses <ref> [Michalski et al., 1986, Clark and Niblett, 1989] </ref>. ILP algorithms on the other hand can not only test attributes for specific values, but also make use of relations between the different attributes. [Dzeroski and Lavrac, 1993] discuss these issues. <p> It prevents overfitting the noise by learning only as long as the costs of encoding a theory together with its exceptions will not exceed the costs of encoding the examples as they are. * Significance Testing was first used in <ref> [Clark and Niblett, 1989] </ref> and later on in the ILP system mFoil [Dzeroski and Bratko, 1992].
Reference: [Cohen, 1993] <author> William W. Cohen. </author> <title> Efficient pruning methods for separate-and-conquer rule learning systems. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 988-994, </pages> <address> Chambery, France, </address> <year> 1993. </year>
Reference-contexts: The concept description that has been learned from the growing set is then simplified by deleting conditions and rules from the theory until any further deletion would result in a decrease of predictive accuracy measured on the pruning set. However, this approach has several disadvantages, most notably efficiency. <ref> [Cohen, 1993] </ref> has shown that REP has a time complexity of (n 4 ) on purely random data. Therefore [Cohen, 1993] proposed Grow, a new pruning algorithm based on a technique used in the Grove learning system [Pagallo and Haussler, 1990]. <p> However, this approach has several disadvantages, most notably efficiency. <ref> [Cohen, 1993] </ref> has shown that REP has a time complexity of (n 4 ) on purely random data. Therefore [Cohen, 1993] proposed Grow, a new pruning algorithm based on a technique used in the Grove learning system [Pagallo and Haussler, 1990]. Like REP, Grow first finds a theory that overfits the data. <p> However, the overall costs of the algorithm are still unnecessarily high, because like REP, Grow has to learn an overly specific intermediate theory. <ref> [Cohen, 1993] </ref> therefore further improves the Grow algorithm by adding two weak MDL-based stopping criteria. <p> See also the Appendix of [Furnkranz, 1993] for a closer description of the domain. The tested algorithms were * the pre-pruning systems FOIL 6.1 [Quinlan and Cameron-Jones, 1993] and FOSSIL (with a cutoff of 0.3) [Furnkranz, 1994a], * the post-pruning systems REP [Brunk and Pazzani, 1991] and Grow <ref> [Cohen, 1993] </ref>, * the combined system TDP [Furnkranz, 1994b], * and the integrated system I-REP [Furnkranz and Widmer, 1994]. All algorithms were implemented by the author in PROLOG except for FOIL 6.1 which is written in C and publicly available from ftp.cs.su.oz.au. <p> All reported results were averaged over 10 runs, except for the training set size 1000, where only 6 runs were performed, because of the complexity of this task for some algorithms. I-REP | after a bad start with only 84.55% accuracy on 100 examples | achieves the 1 In <ref> [Cohen, 1993] </ref> REP and Grow also used identical pruning operators. They were, however, slightly different from our choice. We used the operators described in [Brunk and Pazzani, 1991]. 6 7 highest accuracy. In predictive accuracy, FOIL did poorly.
Reference: [Dzeroski and Bratko, 1992] <author> Saso Dzeroski and Ivan Bratko. </author> <title> Handling noise in Inductive Logic Programming. </title> <booktitle> In Proceedings of the International Workshop on Inductive Logic Programming, </booktitle> <address> Tokyo, Japan, </address> <year> 1992. </year>
Reference-contexts: overfitting the noise by learning only as long as the costs of encoding a theory together with its exceptions will not exceed the costs of encoding the examples as they are. * Significance Testing was first used in [Clark and Niblett, 1989] and later on in the ILP system mFoil <ref> [Dzeroski and Bratko, 1992] </ref>. It tests for significant differences between the distribution of positive and negative examples covered by a rule and the overall distribution of positive and negative examples by comparing the likelihood ratio statistic to a 2 distribution with 1 degree of freedom at the desired significance level. <p> * Cutoff Stopping Criterion: This simple method used in Fossil [Furnkranz, 1994a] only adds a condition to a rule when its heuristic value is above a predefined threshold. mFoil's significance testing along with the m-estimate and a powerful beam search have been very successful in learning concepts in noisy domains <ref> [Dzeroski and Bratko, 1992] </ref>. Similar results have been obtained for the very efficient cutoff criterion.
Reference: [Dzeroski and Lavrac, 1993] <author> Saso Dzeroski and Nada Lavrac. </author> <title> Inductive learning in deductive databases. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 5(6) </volume> <pages> 939-949, </pages> <month> December </month> <year> 1993. </year> <note> Special Issue on Learning and Discovery in Knowledge-Based Databases. </note>
Reference-contexts: The ability to define concepts from data distributed in separate relational tables makes ILP methods particularly appropriate for learning from relational databases (see e.g. <ref> [Dzeroski and Lavrac, 1993] </ref>). However, data from real-world problems often are noisy or incomplete. Learning algorithms that are meant to discover knowledge in real-world domains must be able to deal with this problem [Matheus et al., 1993]. <p> ILP algorithms on the other hand can not only test attributes for specific values, but also make use of relations between the different attributes. <ref> [Dzeroski and Lavrac, 1993] </ref> discuss these issues. <p> Background knowledge consists of the relations X &lt; Y, X = Y and adjacent (X,Y). This task would be very hard for attribute-value learning systems, which typically cannot make use of background knowledge in the form of relations (but see <ref> [Dzeroski and Lavrac, 1993] </ref> for a way to circumvent this problem).
Reference: [Esposito et al., 1993] <author> Floriana Esposito, Donato Malerba, and Giovanni Semeraro. </author> <title> Decision tree pruning as a search in the state space. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, </booktitle> <pages> pages 165-184, </pages> <address> Vienna, Austria, 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In the next section we will discuss several ways of achieving noise-tolerance in ILP programs and will evaluate them with respect to efficiency. 2 3 Pruning in Relational Learning Algorithms Pruning is a standard way of dealing with noise in concept learning (see e.g. [Mingers, 1989] or <ref> [Esposito et al., 1993] </ref>). There are two fundamentally different approaches [Cestnik et al., 1987], Pre-Pruning and Post-Pruning. In sections 3.1 and 3.2 we will review some of these methods that have been adopted for relational concept learning systems.
Reference: [Frawley et al., 1992] <author> William J. Frawley, Gregory Piatetsky-Shapiro, and Christopher J. Matheus. </author> <title> Knowledge discovery in databases: An overview. </title> <journal> AI Magazine, </journal> <pages> pages 57-70, </pages> <month> Fall </month> <year> 1992. </year> <note> Also in [Piatetsky-Shapiro and Frawley, </note> <year> 1991]. </year>
Reference-contexts: However, data from real-world problems often are noisy or incomplete. Learning algorithms that are meant to discover knowledge in real-world domains must be able to deal with this problem [Matheus et al., 1993]. Another major issue for learning from real-world data is efficiency <ref> [Frawley et al., 1992] </ref>. [Muggleton, 1993] argues that in many interesting real-world problems | such as the protein prediction problem [Muggleton et al., 1992] on which the ILP system Golem [Muggleton and Feng, 1990] was tried | millions of examples may be available for training, which is beyond the scope of
Reference: [Furnkranz and Widmer, 1994] <author> Johannes Furnkranz and Gerhard Widmer. </author> <title> Incremental Reduced Error Pruning. </title> <booktitle> In Proceedings of the 11th International Conference on Machine Learning, </booktitle> <address> New Brunswick, NJ, </address> <year> 1994. </year> <month> 10 </month>
Reference-contexts: A more detailed description of this process can be found in [Furnkranz, 1994b]. 4 3.4 Integrating Pre-and Post-Pruning There are several problems with pruning in relational concept learning. Not all of them are attacked by the algorithms in the previous sections <ref> [Furnkranz and Widmer, 1994] </ref>. In particular, the separate-and-conquer strategy used in all Foil-like ILP systems (see section 2) may cause problems. <p> In the worst case, however, those instances may lead the learner down a garden path, because they may change the evaluation of the candidate relations in subsequent learning and thus the "correct" literals might not be selected. A wrong choice of a literal cannot be undone by pruning. <ref> [Furnkranz and Widmer, 1994] </ref> present I-REP, an efficient solution to this problem by means of integrating pre-pruning and post-pruning: Each clause is learned until it covers no more negative examples. <p> The tested algorithms were * the pre-pruning systems FOIL 6.1 [Quinlan and Cameron-Jones, 1993] and FOSSIL (with a cutoff of 0.3) [Furnkranz, 1994a], * the post-pruning systems REP [Brunk and Pazzani, 1991] and Grow [Cohen, 1993], * the combined system TDP [Furnkranz, 1994b], * and the integrated system I-REP <ref> [Furnkranz and Widmer, 1994] </ref>. All algorithms were implemented by the author in PROLOG except for FOIL 6.1 which is written in C and publicly available from ftp.cs.su.oz.au. The PROLOG systems had major parts of their implementations in common. In particular they shared the same interface to the data. <p> I-REP has also been tested on some of the standard Machine Learning databases that can be found in the UCI repository (ics.uci.edu). and again was significantly faster than REP or Grow <ref> [Furnkranz and Widmer, 1994] </ref>. On most natural domains (like Mesh, Promoters and Votes) it achieved a higher accuracy than REP and Grow [Furnkranz and Widmer, 1994]. <p> been tested on some of the standard Machine Learning databases that can be found in the UCI repository (ics.uci.edu). and again was significantly faster than REP or Grow <ref> [Furnkranz and Widmer, 1994] </ref>. On most natural domains (like Mesh, Promoters and Votes) it achieved a higher accuracy than REP and Grow [Furnkranz and Widmer, 1994]. However, it did worse than both of them in domains with low redundancy, where rules have to be found that cover only a few training examples (e.g. 8 Tic-Tac-Toe). In these domains post-pruning methods generally do not do very well, as they all tend to over-generalize.
Reference: [Furnkranz, 1993] <author> Johannes Furnkranz. Fossil: </author> <title> A robust relational learner. </title> <type> Technical Report OEFAI-TR-93-28, </type> <institution> Austrian Research Institute for Artificial Intelligence, </institution> <year> 1993. </year> <note> Extended version. </note>
Reference-contexts: The signs of 10% of the training instances were deliberately reversed to generate noise in the data. The learned concepts were evaluated on test sets with 5000 noise-free examples. The sets used were the same as in [Furnkranz, 1994a]. See also the Appendix of <ref> [Furnkranz, 1993] </ref> for a closer description of the domain.
Reference: [Furnkranz, 1994a] <author> Johannes Furnkranz. Fossil: </author> <title> A robust relational learner. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, </booktitle> <pages> pages 122-137, </pages> <address> Catania, Italy, 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Insignificant rules are rejected. * Cutoff Stopping Criterion: This simple method used in Fossil <ref> [Furnkranz, 1994a] </ref> only adds a condition to a rule when its heuristic value is above a predefined threshold. mFoil's significance testing along with the m-estimate and a powerful beam search have been very successful in learning concepts in noisy domains [Dzeroski and Bratko, 1992]. <p> Both have been shown to be superior to the encoding length restriction, because the latter is dependent on the size of the training set, so that the size of the learned concepts (and thus the amount of overfitting) may increase with training set size <ref> [Furnkranz, 1994a] </ref>. 3 3.2 Post-Pruning Post-pruning was introduced to relational learning algorithms with Reduced Error Pruning (REP) [Brunk and Pazzani, 1991] based on previous work by [Quinlan, 1987] and [Pagallo and Haussler, 1990]. <p> The same is attempted in the top-down pruning (TDP) approach described in [Furnkranz, 1994b]. Here Fossil's simple cutoff stopping criterion (see section 3.1) is exploited for a powerful algorithm that generates all theories learnable by Fossil with different settings of the cutoff parameter <ref> [Furnkranz, 1994a] </ref>. From these the most specific theory within one standard error of classification of the most accurate theory is selected as the starting theory for the post-pruning phase. <p> The signs of 10% of the training instances were deliberately reversed to generate noise in the data. The learned concepts were evaluated on test sets with 5000 noise-free examples. The sets used were the same as in <ref> [Furnkranz, 1994a] </ref>. See also the Appendix of [Furnkranz, 1993] for a closer description of the domain. The tested algorithms were * the pre-pruning systems FOIL 6.1 [Quinlan and Cameron-Jones, 1993] and FOSSIL (with a cutoff of 0.3) [Furnkranz, 1994a], * the post-pruning systems REP [Brunk and Pazzani, 1991] and Grow [Cohen, <p> The sets used were the same as in <ref> [Furnkranz, 1994a] </ref>. See also the Appendix of [Furnkranz, 1993] for a closer description of the domain. The tested algorithms were * the pre-pruning systems FOIL 6.1 [Quinlan and Cameron-Jones, 1993] and FOSSIL (with a cutoff of 0.3) [Furnkranz, 1994a], * the post-pruning systems REP [Brunk and Pazzani, 1991] and Grow [Cohen, 1993], * the combined system TDP [Furnkranz, 1994b], * and the integrated system I-REP [Furnkranz and Widmer, 1994]. <p> The only difference in search space between the PROLOG systems and FOIL 6.1 was that the former did not consider recursive literals for efficiency reasons. FOIL 6.1 would probably have been faster if this had been enforced, but no significant difference in accuracy can be expected (see <ref> [Furnkranz, 1994a] </ref> for results from experiments with the same data sets, where the code of FOIL 4 was modified to prevent recursion). Run-times for most algorithms were measured in CPU seconds for SUN Sparc stations ELC. <p> They were, however, slightly different from our choice. We used the operators described in [Brunk and Pazzani, 1991]. 6 7 highest accuracy. In predictive accuracy, FOIL did poorly. Its stopping criterion is depen-dent on the training set size and thus too weak to effectively prevent overfitting the noise <ref> [Furnkranz, 1994a] </ref>. With 1000 examples FOIL learns concepts that have more than 20 rules and are incomprehensible. I-REP on the other hand consistently produces the 99.57% correct, understandable 4-rule approximation of the correct concept description of figure 1. <p> FOIL, although implemented in C, is slower, because with increasing training set sizes it learns more clauses than FOSSIL <ref> [Furnkranz, 1994a] </ref> and has extensive backtracking mechanisms. REP proves that its pruning method is very inefficient. Grow has an efficient pruning algorithm, but still suffers from the expensive overfitting phase. <p> Conventional pre-pruning methods are very efficient, but not always as accurate as post-pruning methods. The latter, however, tend to be very expensive, because they have to learn an over-specialized theory first. I-REP <ref> [Furnkranz, 1994a] </ref> is an algorithm that integrates pre- and post-pruning into one criterion. Our experiments show that this approach effectively combines the efficiency of pre-pruning with the accuracy of post-pruning in domains with high redundancy.
Reference: [Furnkranz, 1994b] <author> Johannes Furnkranz. </author> <title> Top-down pruning in relational learning. </title> <booktitle> In Proceedings of the 11th European Conference on Artificial Intelligence, </booktitle> <pages> pages 453-457, </pages> <address> Ams-terdam, The Netherlands, </address> <year> 1994. </year>
Reference-contexts: The same is attempted in the top-down pruning (TDP) approach described in <ref> [Furnkranz, 1994b] </ref>. Here Fossil's simple cutoff stopping criterion (see section 3.1) is exploited for a powerful algorithm that generates all theories learnable by Fossil with different settings of the cutoff parameter [Furnkranz, 1994a]. <p> A more detailed description of this process can be found in <ref> [Furnkranz, 1994b] </ref>. 4 3.4 Integrating Pre-and Post-Pruning There are several problems with pruning in relational concept learning. Not all of them are attacked by the algorithms in the previous sections [Furnkranz and Widmer, 1994]. <p> The tested algorithms were * the pre-pruning systems FOIL 6.1 [Quinlan and Cameron-Jones, 1993] and FOSSIL (with a cutoff of 0.3) [Furnkranz, 1994a], * the post-pruning systems REP [Brunk and Pazzani, 1991] and Grow [Cohen, 1993], * the combined system TDP <ref> [Furnkranz, 1994b] </ref>, * and the integrated system I-REP [Furnkranz and Widmer, 1994]. All algorithms were implemented by the author in PROLOG except for FOIL 6.1 which is written in C and publicly available from ftp.cs.su.oz.au. The PROLOG systems had major parts of their implementations in common.
Reference: [King et al., 1992] <author> R. King, S. Muggleton, R. Lewis, and M. Sternberg. </author> <title> Drug design by Machine Learning: The use of Inductive Logic Programming to model the structure-activity relationships of trimethoprim analogues binding to dihydrofolate reductase. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <volume> 89(23), </volume> <year> 1992. </year>
Reference: [Lavrac and Dzeroski, 1993] <author> Nada Lavrac and Saso Dzeroski. </author> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> Ellis Horwood, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction Inductive Logic Programming (ILP) or Relational Learning has established itself as one of the major research areas in the field of Machine Learning <ref> [Muggleton, 1992, Lavrac and Dzeroski, 1993] </ref>. The ability to define concepts from data distributed in separate relational tables makes ILP methods particularly appropriate for learning from relational databases (see e.g. [Dzeroski and Lavrac, 1993]). However, data from real-world problems often are noisy or incomplete.
Reference: [Matheus et al., 1993] <author> Christopher J. Matheus, Philip K. Chan, and Gregory Piatetsky-Shapiro. </author> <title> Systems for knowledge discovery in databases. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 5(6) </volume> <pages> 903-913, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: However, data from real-world problems often are noisy or incomplete. Learning algorithms that are meant to discover knowledge in real-world domains must be able to deal with this problem <ref> [Matheus et al., 1993] </ref>. <p> I-REP [Furnkranz, 1994a] is an algorithm that integrates pre- and post-pruning into one criterion. Our experiments show that this approach effectively combines the efficiency of pre-pruning with the accuracy of post-pruning in domains with high redundancy. As real-world databases typically are large and noisy <ref> [Matheus et al., 1993] </ref>, and thus require learning algorithms that are both efficient and noise-tolerant, I-REP seems to be an appropriate choice for this purpose. 9 Acknowledgements This research is sponsored by the Austrian Fonds zur Forderung der Wissenschaftlichen Forschung (FWF).
Reference: [Michalski et al., 1986] <author> R. S. Michalski, I. Mozetic, J. Hong, and N. Lavrac. </author> <title> The multipurpose incremental learning system AQ15 and its testing application to three medical domains. </title> <booktitle> In Proceedings of the 5th National Conference on Artificial Intelligence, </booktitle> <pages> pages 1041-1045, </pages> <address> Philadelphia, PA, </address> <year> 1986. </year>
Reference-contexts: Most of them learn from an attribute-value representation of the input data and their representational power thus is restricted to decision trees [Quinlan, 1983] or propositional Horn clauses <ref> [Michalski et al., 1986, Clark and Niblett, 1989] </ref>. ILP algorithms on the other hand can not only test attributes for specific values, but also make use of relations between the different attributes. [Dzeroski and Lavrac, 1993] discuss these issues.
Reference: [Mingers, 1989] <author> John Mingers. </author> <title> An empirical comparison of pruning methods for decision tree induction. </title> <journal> Machine Learning, </journal> <volume> 4 </volume> <pages> 227-243, </pages> <year> 1989. </year>
Reference-contexts: In the next section we will discuss several ways of achieving noise-tolerance in ILP programs and will evaluate them with respect to efficiency. 2 3 Pruning in Relational Learning Algorithms Pruning is a standard way of dealing with noise in concept learning (see e.g. <ref> [Mingers, 1989] </ref> or [Esposito et al., 1993]). There are two fundamentally different approaches [Cestnik et al., 1987], Pre-Pruning and Post-Pruning. In sections 3.1 and 3.2 we will review some of these methods that have been adopted for relational concept learning systems.
Reference: [Muggleton and Feng, 1990] <author> Stephen H. Muggleton and Cao Feng. </author> <title> Efficient induction of logic programs. </title> <booktitle> In Proceedings of the 1st Conference on Algorithmic Learning Theory, </booktitle> <pages> pages 1-14, </pages> <address> Tokyo, Japan, </address> <year> 1990. </year>
Reference-contexts: Another major issue for learning from real-world data is efficiency [Frawley et al., 1992]. [Muggleton, 1993] argues that in many interesting real-world problems | such as the protein prediction problem [Muggleton et al., 1992] on which the ILP system Golem <ref> [Muggleton and Feng, 1990] </ref> was tried | millions of examples may be available for training, which is beyond the scope of most ILP systems of today. This paper is mainly concerned with achieving noise-tolerance through efficient Pruning methods for relational learners.
Reference: [Muggleton et al., 1989] <author> Stephen Muggleton, Michael Bain, Jean Hayes-Michie, and Donald Michie. </author> <title> An experimental comparison of human and machine learning formalisms. </title> <booktitle> In Proceedings of the 6th International Workshop on Machine Learning, </booktitle> <pages> pages 113-118, </pages> <year> 1989. </year>
Reference-contexts: Thus the accuracy of a clause on the pruning set also serves as a stopping criterion, i.e. post-pruning methods are used as a pre-pruning heuristic. 4 Experiments We have tested several algorithms in the domain of recognizing illegal chess positions in the KRK chess endgame <ref> [Muggleton et al., 1989] </ref>. This domain has become a standard benchmark problem for relational learning systems. The goal is to learn the concept of an illegal white-to-move position with only white king, white rook and black king on the board.
Reference: [Muggleton et al., 1992] <author> S. Muggleton, R. King, and M. Sternberg. </author> <title> Protein secondary structure prediction using logic-based Machine Learning. </title> <journal> Protein Engineering, </journal> <volume> 5(7) </volume> <pages> 647-657, </pages> <year> 1992. </year>
Reference-contexts: Another major issue for learning from real-world data is efficiency [Frawley et al., 1992]. [Muggleton, 1993] argues that in many interesting real-world problems | such as the protein prediction problem <ref> [Muggleton et al., 1992] </ref> on which the ILP system Golem [Muggleton and Feng, 1990] was tried | millions of examples may be available for training, which is beyond the scope of most ILP systems of today.
Reference: [Muggleton, 1992] <author> Stephen Muggleton, </author> <title> editor. Inductive Logic Programming. </title> <publisher> Academic Press Ltd., </publisher> <address> London, </address> <year> 1992. </year> <month> 11 </month>
Reference-contexts: 1 Introduction Inductive Logic Programming (ILP) or Relational Learning has established itself as one of the major research areas in the field of Machine Learning <ref> [Muggleton, 1992, Lavrac and Dzeroski, 1993] </ref>. The ability to define concepts from data distributed in separate relational tables makes ILP methods particularly appropriate for learning from relational databases (see e.g. [Dzeroski and Lavrac, 1993]). However, data from real-world problems often are noisy or incomplete. <p> In section 4 we give an experimental comparison of all the methods and then draw some conclusions (section 5). 2 Inductive Logic Programming Inductive Logic Programming (ILP) can be viewed at research on the intersection of Logic Programming and Inductive Machine Learning <ref> [Muggleton, 1992] </ref>. In short the research concentrates on the induction of PROLOG programs from relational data. Being able to express the discovered knowledge in a first-order logic representation language can overcome some of the limitations of classical learning algorithms.
Reference: [Muggleton, 1993] <author> Stephen H. Muggleton. </author> <title> Inductive Logic Programming: Derivations, </title> <editor> suc-cesses and shortcomings. In Pavel B. Brazdil, editor, </editor> <booktitle> Machine Learning: ECML-93, number 667 in Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 21-37, </pages> <address> Vienna, Austria, 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: However, data from real-world problems often are noisy or incomplete. Learning algorithms that are meant to discover knowledge in real-world domains must be able to deal with this problem [Matheus et al., 1993]. Another major issue for learning from real-world data is efficiency [Frawley et al., 1992]. <ref> [Muggleton, 1993] </ref> argues that in many interesting real-world problems | such as the protein prediction problem [Muggleton et al., 1992] on which the ILP system Golem [Muggleton and Feng, 1990] was tried | millions of examples may be available for training, which is beyond the scope of most ILP systems of <p> Two of the main problems when dealing with real-world data are noise-tolerance and efficiency. <ref> [Muggleton, 1993] </ref> argues that many real-world problems may involve thousands or even millions of examples, so that efficiency is a major issue for research in ILP.
Reference: [Pagallo and Haussler, 1990] <author> Giulia Pagallo and David Haussler. </author> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 71-99, </pages> <year> 1990. </year>
Reference-contexts: set, so that the size of the learned concepts (and thus the amount of overfitting) may increase with training set size [Furnkranz, 1994a]. 3 3.2 Post-Pruning Post-pruning was introduced to relational learning algorithms with Reduced Error Pruning (REP) [Brunk and Pazzani, 1991] based on previous work by [Quinlan, 1987] and <ref> [Pagallo and Haussler, 1990] </ref>. The basic idea is that in a first pass, no attention is payed to the noise in the data and a concept description that explains all of the positive and none of the negative examples is learned. <p> However, this approach has several disadvantages, most notably efficiency. [Cohen, 1993] has shown that REP has a time complexity of (n 4 ) on purely random data. Therefore [Cohen, 1993] proposed Grow, a new pruning algorithm based on a technique used in the Grove learning system <ref> [Pagallo and Haussler, 1990] </ref>. Like REP, Grow first finds a theory that overfits the data.
Reference: [Piatetsky-Shapiro and Frawley, 1991] <editor> Gregory Piatetsky-Shapiro and William J. Frawley, editors. </editor> <title> Knowledge Discovery in Databases. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference: [Quinlan and Cameron-Jones, 1993] <author> John Ross Quinlan and R. M. Cameron-Jones. </author> <title> FOIL: A midterm report. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, </booktitle> <pages> pages 3-20, </pages> <address> Vienna, Austria, </address> <year> 1993. </year>
Reference-contexts: The learned concepts were evaluated on test sets with 5000 noise-free examples. The sets used were the same as in [Furnkranz, 1994a]. See also the Appendix of [Furnkranz, 1993] for a closer description of the domain. The tested algorithms were * the pre-pruning systems FOIL 6.1 <ref> [Quinlan and Cameron-Jones, 1993] </ref> and FOSSIL (with a cutoff of 0.3) [Furnkranz, 1994a], * the post-pruning systems REP [Brunk and Pazzani, 1991] and Grow [Cohen, 1993], * the combined system TDP [Furnkranz, 1994b], * and the integrated system I-REP [Furnkranz and Widmer, 1994].
Reference: [Quinlan, 1983] <author> J. Ross Quinlan. </author> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In Ryszard S. Michalski, Jaime G. Carbonell, and Tom M. Mitchell, editors, </editor> <booktitle> Machine Learning. An Artificial Intelligence Approach, </booktitle> <pages> pages 463-482. </pages> <publisher> Tioga Publishing Co., </publisher> <year> 1983. </year>
Reference-contexts: Being able to express the discovered knowledge in a first-order logic representation language can overcome some of the limitations of classical learning algorithms. Most of them learn from an attribute-value representation of the input data and their representational power thus is restricted to decision trees <ref> [Quinlan, 1983] </ref> or propositional Horn clauses [Michalski et al., 1986, Clark and Niblett, 1989]. ILP algorithms on the other hand can not only test attributes for specific values, but also make use of relations between the different attributes. [Dzeroski and Lavrac, 1993] discuss these issues.
Reference: [Quinlan, 1987] <author> John Ross Quinlan. </author> <title> Simplifying decision trees. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 27 </volume> <pages> 221-234, </pages> <year> 1987. </year>
Reference-contexts: of the training set, so that the size of the learned concepts (and thus the amount of overfitting) may increase with training set size [Furnkranz, 1994a]. 3 3.2 Post-Pruning Post-pruning was introduced to relational learning algorithms with Reduced Error Pruning (REP) [Brunk and Pazzani, 1991] based on previous work by <ref> [Quinlan, 1987] </ref> and [Pagallo and Haussler, 1990]. The basic idea is that in a first pass, no attention is payed to the noise in the data and a concept description that explains all of the positive and none of the negative examples is learned.
Reference: [Quinlan, 1990] <author> John Ross Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: Many ILP algorithms | including all of the algorithms discussed in this paper | address this problem with the so-called separate-and-conquer strategy used in Foil <ref> [Quinlan, 1990] </ref>. The basic idea behind this approach is to learn one rule after the other until all of the positive examples are covered by at least one rule. <p> The most commonly used criteria are * Encoding Length Restriction: This heuristic used in the classic ILP system Foil <ref> [Quinlan, 1990] </ref> is based on the Minimum Description Length principle [Rissanen, 1978].
Reference: [Rissanen, 1978] <author> J. Rissanen. </author> <title> Modeling by shortest data description. </title> <journal> Automatica, </journal> <volume> 14 </volume> <pages> 465-471, </pages> <year> 1978. </year>
Reference-contexts: The most commonly used criteria are * Encoding Length Restriction: This heuristic used in the classic ILP system Foil [Quinlan, 1990] is based on the Minimum Description Length principle <ref> [Rissanen, 1978] </ref>.
Reference: [Sternberg et al., 1992] <author> M. Sternberg, R. Lewis, R. King, and S. Muggleton. </author> <title> Modelling the structure and function of enzymes by machine learning. </title> <journal> Proceedings of the Royal Society of Chemistry: Faraday Discussions, </journal> <volume> 93 </volume> <pages> 269-280, </pages> <year> 1992. </year> <month> 12 </month>
References-found: 31

