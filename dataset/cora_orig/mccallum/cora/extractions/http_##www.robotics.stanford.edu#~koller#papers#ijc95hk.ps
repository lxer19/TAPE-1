URL: http://www.robotics.stanford.edu/~koller/papers/ijc95hk.ps
Refering-URL: http://www.robotics.stanford.edu/~koller/papers/ijc95hk.html
Root-URL: http://www.robotics.stanford.edu
Email: halpern@almaden.ibm.com  daphne@cs.berkeley.edu  
Title: Representation Dependence in Probabilistic Inference  
Author: Joseph Y. Halpern Daphne Koller 
Address: 650 Harry Road San Jose, CA 95120-6099  Berkeley, CA 94720  
Affiliation: IBM Almaden Research Center  Computer Science Division University of California, Berkeley  
Abstract: Non-deductive reasoning systems are often representation dependent: representing the same situation in two different ways may cause such a system to return two different answers. This is generally viewed as a significant problem. For example, the principle of maximum entropy has been subjected to much criticism due to its representation dependence. There has, however, been almost no work investigating representation dependence. In this paper, we formalize this notion and show that it is not a problem specific to maximum entropy. In fact, we show that any probabilistic inference system that sanctions certain important patterns of reasoning, such as a minimal default assumption of independence, must suffer from representation dependence. We then show that invariance under a restricted class of representation changes can form a reasonable compromise between representation independence and other desiderata.
Abstract-found: 1
Intro-found: 1
Reference: [ Enderton, 1972 ] <author> H. B. Enderton. </author> <title> A Mathematical Introduction to Logic. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: Then f fl () is the set of distributions such that the total probability assigned to the set of states fred; blue; greeng by is 0.7. Note that there are uncountably many such distributions. Embeddings can be viewed as the semantic analogue to the notion of interpretation defined in <ref> [ Enderton, 1972 ] </ref> . Definition 3.3: Let F and Y be two vocabularies. In the propositional case, a interpretation of F into Y is a function i that associates with every propositional symbol p 2 F a formula i (p) 2 L (Y). <p> Given an interpretation i, we get a syntactic translation from formulas in L (F) to formulas in L (Y) using i in the obvious way; for example, i ((p ^ :q) _ r) = (i (p) ^ :i (q)) _ i (r) (see <ref> [ Enderton, 1972 ] </ref> for the details).
Reference: [ Giunchiglia and Walsh, 1992 ] <author> F. Giunchiglia and T. Walsh. </author> <title> A theory of abstraction. </title> <journal> Artificial Intelligence, </journal> <volume> 56(2-3):323-390, </volume> <year> 1992. </year>
Reference-contexts: An embedding is just the semantic version of the standard logical notion of interpretation [ En-derton, 1972, pp. 157-162 ] , which has also been used in the recent literature on abstraction <ref> [ Giunchiglia and Walsh, 1992; Nayak and Levy, 1994 ] </ref> . <p> But unlike the standard Bayesian approach, we do not feel compelled to choose a unique distribution. This enables us to explore a wider spectrum of inference procedures. Another line of research that is relevant to representation independence is the work on abstraction <ref> [ Giunchiglia and Walsh, 1992; Nayak and Levy, 1994 ] </ref> . Although the goal of this work is again to make connections between two different ways of representing the same situation, there are significant differences in focus.
Reference: [ Jaynes, 1968 ] <author> E. T. Jaynes. </author> <title> Prior probabilities. </title> <journal> IEEE Transactions on Systems Science and Cybernetics, </journal> <volume> SSC-4:227-241, </volume> <year> 1968. </year>
Reference-contexts: For example, we would expect that our beliefs about a person's height should be invariant under a transformation from feet to meters. Their hope is that once we specify the transformation under which we want a distribution to be invariant, the distribution will be uniquely determined <ref> [ Jaynes, 1968; Kass and Wasserman, 1993 ] </ref> . In this case, the argument goes, the uniquely determined distribution is perforce the right one. This idea of picking a distribution using its invariance properties is in the same spirit as the approach we take in Section 5.
Reference: [ Jaynes, 1978 ] <author> E. T. Jaynes. </author> <title> Where do we stand on maximum entropy? In R. </title> <editor> D. Levine and M. Tribus, editors, </editor> <booktitle> The Maximum Entropy Formalism, </booktitle> <pages> pages 15-118. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1978. </year>
Reference-contexts: is it to the way knowledge is represented? Consider the following examples, which use perhaps the best-known non-deductive notion of fl Research sponsored in part by the Air Force Office of Scientific Research (AFSC), under Contract F49620-91-C-0080, and by a University of California President's Postdoctoral Fellowship. probabilistic inference, maximum entropy <ref> [ Jaynes, 1978 ] </ref> . 1 Example 1.1: Suppose we have no information whatsoever. What probability should we assign to the proposition colorful? Symmetry arguments might suggest 1=2: Since we have no information, it seems that an object should be just as likely to be colorful as non-colorful.
Reference: [ Kass and Wasserman, 1993 ] <author> R. E. Kass and L. Wasserman. </author> <title> Formal rules for selecting prior distributions: A review and annotated bibliography. </title> <type> Technical Report Technical Report #583, </type> <institution> Dept. of Statistics, Carnegie Mellon University, </institution> <year> 1993. </year>
Reference-contexts: For example, we would expect that our beliefs about a person's height should be invariant under a transformation from feet to meters. Their hope is that once we specify the transformation under which we want a distribution to be invariant, the distribution will be uniquely determined <ref> [ Jaynes, 1968; Kass and Wasserman, 1993 ] </ref> . In this case, the argument goes, the uniquely determined distribution is perforce the right one. This idea of picking a distribution using its invariance properties is in the same spirit as the approach we take in Section 5.
Reference: [ Kraus et al., 1990 ] <author> S. Kraus, D. Lehmann, and M. Magidor. </author> <title> Nonmonotonic reasoning, preferential models and cumulative logics. </title> <journal> Artificial Intelligence, </journal> <volume> 44 </volume> <pages> 167-207, </pages> <year> 1990. </year>
Reference-contexts: Interestingly, these properties are commonly viewed as part of a core of reasonable properties for a nonmonotonic inference relation <ref> [ Kraus et al., 1990 ] </ref> .
Reference: [ Kullback and Leibler, 1951 ] <author> S. Kullback and R. A. Leibler. </author> <title> On information and sufficiency. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 22 </volume> <pages> 76-86, </pages> <year> 1951. </year>
Reference-contexts: We show that if the prior distributions are chosen appropriately, so that they are invariant under the class of embeddings of interest, then we can bootstrap up to obtain a general inference procedure that is invariant under the same class of embeddings, by using cross-entropy <ref> [ Kullback and Leibler, 1951 ] </ref> , a well-known generalization of probabilistic conditioning. This result can be used in a number of ways. <p> If D X and D Y correspond under f , then D X jB and D Y jf (B) also correspond under f . What if we want to update on a constraint which is not objective? The standard extension of conditioning to this case is via cross-entropy <ref> [ Kullback and Leibler, 1951 ] </ref> . <p> Standard Bayesian conditioning is of this form (at least for objective knowledge bases), where we take P (X) to be a single distribution for each space X. More interestingly, it is well-known <ref> [ Kullback and Leibler, 1951 ] </ref> that maximum entropy is I P u where P u (X) is the singleton set containing only the uniform prior on X.
Reference: [ Nayak and Levy, 1994 ] <author> P. P. Nayak and A. Y. Levy. </author> <title> A semantic theory of abstractions. </title> <year> 1994. </year>
Reference-contexts: An embedding is just the semantic version of the standard logical notion of interpretation [ En-derton, 1972, pp. 157-162 ] , which has also been used in the recent literature on abstraction <ref> [ Giunchiglia and Walsh, 1992; Nayak and Levy, 1994 ] </ref> . <p> But unlike the standard Bayesian approach, we do not feel compelled to choose a unique distribution. This enables us to explore a wider spectrum of inference procedures. Another line of research that is relevant to representation independence is the work on abstraction <ref> [ Giunchiglia and Walsh, 1992; Nayak and Levy, 1994 ] </ref> . Although the goal of this work is again to make connections between two different ways of representing the same situation, there are significant differences in focus.
Reference: [ Paris, 1994 ] <author> J. B. Paris. </author> <title> The Uncertain Reasoner's Companion. </title> <publisher> Cambridge University Press, </publisher> <year> 1994. </year>
Reference-contexts: Adding information about symbols that do not appear in either KB or should not affect whether we can infer from KB . Logical entailment, being a monotonic inference procedure, clearly enforces minimal irrelevance. It is not hard to show that maximum entropy does too (see <ref> [ Paris, 1994 ] </ref> for a proof). Unfortunately, minimal irrelevance combined with representation independence forces us to inference procedures that are essentially entailment. Theorem 3.10 : Any representation independent inference procedure that enforces minimal irrelevance is essentially entailment.
Reference: [ Pearl, 1988 ] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, Calif., </address> <year> 1988. </year>
Reference-contexts: To make our discussion more concrete, we discuss this issue in one particular context: probabilistic inference. We focus on probabilistic inference both because of the recent interest in using probability for knowledge representation (e.g., <ref> [ Pearl, 1988 ] </ref> ) and because it has been the source of many of the concerns expressed regarding representation. However, our approach should be applicable far more generally. Suppose we have a procedure for making inferences from a probabilistic knowledge base. <p> For example, if we use propositional logic as our basic knowledge representation language, our choice of primitive propositions characterizes the distinctions that we have chosen to make. In this case, we can take the states to be truth assignments to these propositions. Similarly, if we use belief networks <ref> [ Pearl, 1988 ] </ref> as our knowledge representation language, we must choose some set of relevant variables. The states are then then possible assignments of values to these variables.
Reference: [ Salmon, 1961 ] <author> W. Salmon. </author> <title> Vindication of induction. </title> <editor> In H. Feigl and G. Maxwell, editors, </editor> <booktitle> Current Issues in the Philosophy of Science, </booktitle> <pages> pages 245-264. </pages> <publisher> Holt, Rinehart, and Winston, </publisher> <address> New York, </address> <year> 1961. </year>
Reference-contexts: Examples such as these are the basis for the frequent criticisms of maximum entropy on the grounds of representation dependence. But other than pointing out these examples, there has been little work on this problem. In fact, other than the work of Salmon <ref> [ Salmon, 1961; Salmon, 1963 ] </ref> , there seems to have been no work on formalizing the notion of representation dependence. One might say that the consensus was: whatever representation independence is, it is not a property enjoyed by maximum entropy. <p> Indeed, to the best of our knowledge, the only work on representa-tion independence in the logical sense that we have considered here is that of Salmon. Salmon <ref> [ Salmon, 1961 ] </ref> defined a criterion of linguistic invariance, which seems essentially equivalent to our notion of representation independence. He tried to use this criterion to defend one particular method of inductive inference but, as pointed out by Barker in the commentary at the end of [ Salmon, 1961 ] <p> Salmon <ref> [ Salmon, 1961 ] </ref> defined a criterion of linguistic invariance, which seems essentially equivalent to our notion of representation independence. He tried to use this criterion to defend one particular method of inductive inference but, as pointed out by Barker in the commentary at the end of [ Salmon, 1961 ] , his preferred method does not satisfy his criterion either.
Reference: [ Salmon, 1963 ] <author> W. Salmon. </author> <title> On vindicating induction. </title> <editor> In H. E. Kyburg and E. Nagel, editors, </editor> <title> Induction: </title> <booktitle> Some Current Issues, </booktitle> <pages> pages 27-54. </pages> <publisher> Wesleyan University Press, </publisher> <address> Mid-dletown, Conn., </address> <year> 1963. </year>
Reference-contexts: Examples such as these are the basis for the frequent criticisms of maximum entropy on the grounds of representation dependence. But other than pointing out these examples, there has been little work on this problem. In fact, other than the work of Salmon <ref> [ Salmon, 1961; Salmon, 1963 ] </ref> , there seems to have been no work on formalizing the notion of representation dependence. One might say that the consensus was: whatever representation independence is, it is not a property enjoyed by maximum entropy. <p> Salmon then tried to find a modified inductive inference method that did satisfy his criterion <ref> [ Salmon, 1963 ] </ref> , but it is not clear that it does; in any case, our results show that his modified method certainly cannot be representation independent in our sense.
Reference: [ Seidenfeld, 1987 ] <author> T. Seidenfeld. </author> <title> Entropy and uncertainty. </title> <editor> In I. B. MacNeill and G. J. Umphrey, editors, </editor> <booktitle> Foundations of Statistical Inferences, </booktitle> <pages> pages 259-287. </pages> <year> 1987. </year>
Reference: [ Shore and Johnson, 1980 ] <author> J. E. Shore and R. W. Johnson. </author> <title> Axiomatic derivation of the principle of maximum entropy and the principle of minimimum cross-entropy. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-26(1):26-37, </volume> <year> 1980. </year>
Reference-contexts: Clearly entailment does not satisfy minimal default independence. Maximum entropy, however, does. Indeed, a semantic property that implies minimal default independence is used in <ref> [ Shore and Johnson, 1980 ] </ref> as one of the axioms in an axiomatic characterization of maximum-entropy. Theorem 3.12: Any inference procedure that enforces minimal default independence cannot be representation independent. 4 Discussion These results suggest that any type of representation independence is hard to come by. <p> It follows that maximum entropy is invariant under all such embeddings. In fact, the requirement that maximum entropy be invariant under a subset of these embeddings is one of the axioms in a well-known axiomatic characterization of maximum-entropy <ref> [ Shore and Johnson, 1980 ] </ref> . If we do not like the behavior of maximum entropy under representation shifts, Theorem 5.6 provides a solution. We should simply start out with a different prior function.
References-found: 14

