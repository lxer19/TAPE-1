URL: http://www.cs.rpi.edu/~nibhanum/publications/hpcs98.ps
Refering-URL: http://www.cs.rpi.edu/~nibhanum/arsdir/vbsp_refs.html
Root-URL: http://www.cs.rpi.edu
Email: E-mail: fnibhanum, szymanskg@cs.rpi.edu  
Title: 1 ADAPTIVE BULK-SYNCHRONOUS PARALLELISM IN A NETWORK OF NONDEDICATED WORKSTATIONS  
Author: Mohan V. Nibhanupudi, and Boleslaw K. Szymanski 
Note: This work was partially supported by NSF Grant CCR-9527151. The content does not necessarily reflect the position or policy of the U.S. Government.  
Address: USA  
Affiliation: Rensselaer Polytechnic Institute,  
Abstract: Several computing environments including wide area networks and nondedicated networks of workstations are characterized by frequent unavailability of the participating machines. Parallel computations, with interdependencies among their component processes, can not make progress if some of the participating machines become unavailable during the computation. As a result, to deliver acceptable performance, the set of participating processors must be dynamically adjusted following the changes in computing environment. In this paper, we discuss the design of a run time system to support a Virtual BSP Computer that allows BSP programmers to treat a network of transient processors as a dedicated network. The Virtual BSP Computer enables parallel applications to remove computations from processors that become unavailable and thereby adapt to the changing computing environment. The run time system, which we refer to as adaptive replication system (ARS), uses replication of data and computations to keep current a mapping of a set of virtual processors to a subset of the available machines. ARS has been implemented and integrated with a message passing library for the Bulk-Synchronous Parallel 
Abstract-found: 1
Intro-found: 1
Reference: <author> Barocas, V. H. and Tranquillo, R. </author> <year> (1994). </year> <note> Biphasic theory and in vitro assays of cell-fibril mechanical interactions in tissue-equivalent collagen gels. </note> <editor> In Mow, V. C. and et al., editors, </editor> <booktitle> Cell Mechanics and Cellular Engineering, </booktitle> <pages> pages 185-209, </pages> <address> New York. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: We used the model to build an efficient implementation of plasma simulation on a network of workstations (Nibhanupudi et al., 1995) as well as a partial differential equation solver for modeling of bioartificial artery <ref> (Barocas and Tranquillo, 1994) </ref>. Although the barrier synchronization at the end of each BSP superstep can be expensive, its cost can often be reduced by overlapping communication with local computation and enforcing only logical but not physical synchronism. Barriers have desirable features for parallel system design.
Reference: <author> Bisseling, R. H. and McColl, W. F. </author> <year> (1993). </year> <title> Scientific Computing on Bulk Synchronous Parallel Architectures. </title> <type> Technical Report 836, </type> <institution> Dept. of Mathematics, University of Utrecht. </institution>
Reference-contexts: All the participating processors synchronize at the end of the superstep. By providing an intermediate level of abstraction between hardware and software, BSP provides a model for general-purpose, architecture-independent parallel programming. The BSP model has been used to implement a wide variety of scientific applications including numerical algorithms <ref> (Bisseling and McColl, 1993) </ref>, combinatorial algorithms (Gerbessiotis and Siniolakis, 1996) and several other applications (Calinescu, 1995).
Reference: <author> Bricker, A., Litzkow, M., and Livny, M. </author> <year> (1992). </year> <title> Condor Technical Summary. </title> <type> Technical Report CS-TR-92-1069, </type> <institution> Comp. Sc. Dept, Univ of Wisconsin, Madi-son. </institution>
Reference-contexts: Otherwise, the host is marked as unavailable and the process is suspended before entering a computationally intensive task. The prototype is implemented on Sun Sparcstations using the Solaris (SunOS 5.5) operating system. It makes use of the checkpoint based migration scheme of Condor <ref> (Bricker et al., 1992) </ref> for process migration. 1 The superstep is complete when synchronization has been initiated on behalf of all the participating processes. 10 It should be noted that our protocol for adaptive replication scheme can be applied to other message passing libraries such as MPI (Mpiforum, 1994).
Reference: <author> Cabillic, G. and Puaut, I. </author> <year> (1997). </year> <title> Stardust: an environment for parallel programming on networks of heterogeneous workstations. </title> <journal> J. Parallel and Distributed Computing, </journal> <volume> 40(1). </volume>
Reference-contexts: It provides consistent checkpointing and process migration mechanism for MPI and PVM applications. Stardust <ref> (Cabillic and Puaut, 1997) </ref> is a system for parallel computations on a network of heterogeneous workstations. Stardust uses techniques similar to ours. It captures the state of the computation at the barrier synchronization points in the parallel program.
Reference: <author> Calinescu, R. </author> <year> (1995). </year> <title> Conservative discrete-event simulations on bulk synchronous parallel architectures. </title> <type> Technical Report TR-16-95, </type> <institution> Oxford University Computing Laboratory. </institution>
Reference-contexts: The BSP model has been used to implement a wide variety of scientific applications including numerical algorithms (Bisseling and McColl, 1993), combinatorial algorithms (Gerbessiotis and Siniolakis, 1996) and several other applications <ref> (Calinescu, 1995) </ref>. We used the model to build an efficient implementation of plasma simulation on a network of workstations (Nibhanupudi et al., 1995) as well as a partial differential equation solver for modeling of bioartificial artery (Barocas and Tranquillo, 1994).
Reference: <author> Cap, C. H. and Strumpen, V. </author> <year> (1993). </year> <title> Efficient Parallel Computing in Distributed Workstation Environments. </title> <booktitle> Parallel Computing, </booktitle> <pages> pages 1221-1234. </pages>
Reference-contexts: Synchronous parallel computations with the computation state distributed among the component processes cannot be modeled with master-worker parallelism. A limited form of adaptive parallelism can be achieved by dynamically balancing the load on the participating workstations. Parform <ref> (Cap and Strumpen, 1993) </ref> is a system for providing such capability to parallel applications. Par-form is based on the strategy of initial heterogeneous partitioning of the task according to actual loads on workstations, followed by dynamic load balancing.
Reference: <author> Carriero, N., Freeman, E., Gelernter, and Kaminsky, D. </author> <year> (1995). </year> <title> Adaptive Parallelism and Piranha. </title> <journal> Computer, </journal> <volume> 28(1) </volume> <pages> 40-49. </pages>
Reference-contexts: To enable recovery of the computation of a failed process, the computation state of each process, C s , is saved at every synchronization point on a peer process. Thus our approach uses eager replication of computation state and lazy replication of computations. 4 1.3 RELATED WORK Piranha <ref> (Carriero et al., 1995) </ref> is a system for adaptive parallelism built on top of the tuple-space based coordination language Linda. Piranha implements master-worker parallelism. The master process is assumed to be persistent. The worker processes are created on idle machines and destroyed when the machine becomes busy.
Reference: <author> Deo, N. </author> <year> (1974). </year> <title> Graph Theory with Applications to Engineering and Computer Science. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, N.J. </address>
Reference-contexts: two different applications that illustrate the performance of the scheme for computation dominant applications and data replication dominant applications described in section 1.4.3. 1.6.1 Maximum Independent Set A set of vertices in a graph is said to be an independent set if no two vertices in the set are adjacent <ref> (Deo, 1974) </ref>. A maximal independent set is an independent set which is not a subset of any other independent set. A graph, in general, has many maximal independent sets. In the maximum independent set problem, we want to find a maximal independent set with the largest number of vertices.
Reference: <author> Gerbessiotis, A. V. and Siniolakis, C. J. </author> <year> (1996). </year> <title> Selection on the bulk synchronous parallel model with applications to priority queues. </title> <booktitle> In Proc. 1996 International Conference on Parallel an Distributed Processing Techniques and Applications (PDPTA '96), </booktitle> <address> Sunnyvale, California, USA. </address>
Reference-contexts: By providing an intermediate level of abstraction between hardware and software, BSP provides a model for general-purpose, architecture-independent parallel programming. The BSP model has been used to implement a wide variety of scientific applications including numerical algorithms (Bisseling and McColl, 1993), combinatorial algorithms <ref> (Gerbessiotis and Siniolakis, 1996) </ref> and several other applications (Calinescu, 1995). We used the model to build an efficient implementation of plasma simulation on a network of workstations (Nibhanupudi et al., 1995) as well as a partial differential equation solver for modeling of bioartificial artery (Barocas and Tranquillo, 1994).
Reference: <author> Goldberg, M. K. and Hollinger, D. L. </author> <year> (1997). </year> <title> Database Learning: a Method for Empirical Algorithm Design. </title> <booktitle> In Proc. Workshop on Algorithm Engineering. </booktitle>
Reference-contexts: This procedure will ultimately produce a maximal independent set. In order to find a maximal independent set with the largest number of vertices, we find all the maximal independent sets using a recursive depth first search with backtracking <ref> (Goldberg and Hollinger, 1997) </ref>. To conserve memory, no explicit representation of the graph is maintained. Instead, the connectivity information is used to search through a virtual graph. To reduce the search space, heuristics are used to prune the search space.
Reference: <author> Gropp, W., Lusk, E., and Skjellum, A. </author> <year> (1994). </year> <title> Using MPI:Portable Parallel Programming With the Message-Passing Interface. </title> <publisher> The MIT Press. </publisher>
Reference: <author> Kleinrock, L. and Korfhage, W. </author> <year> (1993). </year> <title> Collecting Unused Processing Capacity: An Analysis of Transient Distributed Systems. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <note> 4(5). ADAPTIVE BULK-SYNCHRONOUS PARALLELISM IN A NOW 15 Leon, </note> <author> J., Fischer, A. L., and Steenkiste, P. </author> <year> (1993). </year> <title> Fail-safe PVM: A portable package for distributed programming with transparent recovery. </title> <type> Technical report, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA 15213. </address>
Reference-contexts: Keywords: Networks of Nondedicated Workstations, Bulk-Synchronous Parallel Model, Adaptive Parallel Computing, Transient Processors, Virtual BSP Computer 1.1 INTRODUCTION Several computing environments are characterized by frequent unavailability of the participating machines. Machines that are available for use only part of the time are referred to as transient processors <ref> (Kleinrock and Korfhage, 1993) </ref>. A transition of the host machine from an available to a non-available state is considered a transient failure. Such model of a network of transient processors applies to several computing paradigms, including wide area networks such as the Internet and local networks of nondedicated workstations (NOWs). <p> Use of workstations in this manner allows additional sequential programs to accumulate work during idle times of the workstations <ref> (Kleinrock and Korfhage, 1993) </ref>. However parallel programs, with interdependencies among their component processes, can not make progress if some of the participating workstations become unavailable during the computation. Parallel computations in such environments must adapt to the changing computing environment to deliver acceptable performance.
Reference: <author> Litzkow, M. J., Livny, M., and Mutka, M. W. </author> <year> (1988). </year> <title> Condor A Hunter of Idle Workstations. </title> <booktitle> In Proc. 8th Intl. Conf. Distributed Computing Systems, </booktitle> <address> San Jose, California. </address>
Reference-contexts: The consistent checkpoint is obtained by forcing a global synchronization before allowing a checkpoint to proceed. CoCheck (Stellner, 1996) tries to blend the resource management capabilities of systems like Condor <ref> (Litzkow et al., 1988) </ref> with parallel programming libraries such as PVM (Sunderam, 1990) and MPI (Snir et al., 1996; Gropp et al., 1994). It provides consistent checkpointing and process migration mechanism for MPI and PVM applications.
Reference: <author> Miller, R. </author> <year> (1993). </year> <title> A Library for Bulk-synchronous Parallel Programming. </title> <booktitle> In British Computer Society Workshop on General Purpose Parallel Computing. </booktitle>
Reference-contexts: Our approach offers a general framework for adaptive parallelism and is algorithm independent. We described a protocol for the replication of computation state and replication of computations. We extended the Oxford BSP library <ref> (Miller, 1993) </ref> with dynamic process management and virtual synchronization and implemented the protocol 14 on top of the extended library. The adaptive parallel extensions to the library include primitives for specification of replication data, memory management for replication data and specification of computation state.
Reference: <author> Miller, R. and Reed, J. </author> <year> (1993). </year> <title> The Oxford BSP Library Users' Guide, version 1.0. </title> <type> Technical report, </type> <institution> Oxford Parallel. </institution> <month> Mpiforum </month> <year> (1994). </year> <title> MPI: A Message Passing Interface Standard. Technical report, Message Passing Interface Forum. </title>
Reference-contexts: Our approach offers a general framework for adaptive parallelism and is algorithm independent. We described a protocol for the replication of computation state and replication of computations. We extended the Oxford BSP library <ref> (Miller, 1993) </ref> with dynamic process management and virtual synchronization and implemented the protocol 14 on top of the extended library. The adaptive parallel extensions to the library include primitives for specification of replication data, memory management for replication data and specification of computation state.
Reference: <author> Mutka, M. W. and Livny, M. </author> <year> (1987). </year> <title> Profiling Workstations' Available Capacity for Remote Execution. </title> <booktitle> In Proc. 12th Symposium on Computer Performance, </booktitle> <address> Brussels, Belgium. </address>
Reference-contexts: These values for t a and t n are within the range of values reported in earlier works <ref> (Mutka and Livny, 1987) </ref>. The measurements were taken on a network of Sun Sparc 5 workstations connected by a 10 Mbps Ethernet. The number of processors available is much larger 12 than the degree of parallelism used in the simulations and therefore, migration to an available processor was always possible.
Reference: <author> Nibhanupudi, M. V. </author> <year> (1998). </year> <title> Adaptive Parallel Computations on Networks of Workstations. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Rensselaer Polytechnic Institute. </institution>
Reference-contexts: A more detailed discussion of the performance of the adaptive replication scheme along with the analysis can be found in <ref> (Nibhanupudi, 1998) </ref>. 1.5 DESIGN AND IMPLEMENTATION OF A-BSP LIBRARY 1.5.1 Design of Adaptive Bulk-Synchronous Parallel Library The adaptive replication scheme is developed using the Oxford BSP library (Miller, 1993; Miller and Reed, 1993). <p> Processes can now perform synchronization for one another, which allows for dynamic work sharing. The run time system to support adaptive parallelism in the Bulk-Synchronous Parallel model has been described in detail in <ref> (Nibhanupudi and Szymanski, 1998) </ref>. The run time support uses two levels of abstraction: replication layer and user layer.
Reference: <author> Nibhanupudi, M. V., Norton, C. D., and Szymanski, B. K. </author> <year> (1995). </year> <title> Plasma Simulation On Networks Of Workstations Using The Bulk-Synchronous Parallel Model. </title> <booktitle> In Proc. Intl. Conf. on Parallel and Distributed Processing Techniques and Applications (PDPTA'95), </booktitle> <address> Athens, Georgia. </address>
Reference-contexts: We used the model to build an efficient implementation of plasma simulation on a network of workstations <ref> (Nibhanupudi et al., 1995) </ref> as well as a partial differential equation solver for modeling of bioartificial artery (Barocas and Tranquillo, 1994). <p> This application can therefore be categorized as a computation dominant application. 1.6.2 Plasma Simulation The plasma Particle In Cell simulation model (Norton et al., 1995) integrates, in time, the trajectories of millions of charged particles in their self-consistent electro-magnetic fields. In the replicated grid version of the plasma simulation <ref> (Nibhanupudi et al., 1995) </ref>, the particles are evenly distributed among the processors for sharing work load; the simulation space (field grid) is replicated on each of the processors to avoid frequent communication between processors.
Reference: <author> Nibhanupudi, M. V. and Szymanski, B. K. </author> <year> (1996). </year> <title> Adaptive Parallelism In The Bulk-Synchronous Parallel model. </title> <booktitle> In Proceedings of the Second International Euro-Par Conference, </booktitle> <address> Lyon, France. </address>
Reference-contexts: However, for the sake of better performance, this new process is migrated to a new host if one is available. For more details on the protocol, refer to <ref> (Nibhanupudi and Szymanski, 1996) </ref>. It should be noted that the assumption of existence of a master process is not necessary for the correctness of the protocol. Using the standard techniques from distributed algorithms, synchronization can be achieved over the virtual ring regardless of transient failures. <p> The library has been extended to pro 8 vide dynamic process management and virtual synchronization as described in <ref> (Nibhanupudi and Szymanski, 1996) </ref>. Using the extended library, processes can now be terminated at any time or migrated to new host machines; new processes can be created to join the parallel computation. Processes can now perform synchronization for one another, which allows for dynamic work sharing.
Reference: <author> Nibhanupudi, M. V. and Szymanski, B. K. </author> <year> (1998). </year> <title> Runtime Support for Virtual BSP Computer. </title> <booktitle> To appear in Proc. of the Workshop on Runtime Systems for Parallel Programming, </booktitle> <address> RTSPP'98. </address>
Reference-contexts: A more detailed discussion of the performance of the adaptive replication scheme along with the analysis can be found in <ref> (Nibhanupudi, 1998) </ref>. 1.5 DESIGN AND IMPLEMENTATION OF A-BSP LIBRARY 1.5.1 Design of Adaptive Bulk-Synchronous Parallel Library The adaptive replication scheme is developed using the Oxford BSP library (Miller, 1993; Miller and Reed, 1993). <p> Processes can now perform synchronization for one another, which allows for dynamic work sharing. The run time system to support adaptive parallelism in the Bulk-Synchronous Parallel model has been described in detail in <ref> (Nibhanupudi and Szymanski, 1998) </ref>. The run time support uses two levels of abstraction: replication layer and user layer.
Reference: <author> Norton, C. D., Szymanski, B. K., and Decyk, V. K. </author> <year> (1995). </year> <title> Object Oriented Parallel Computation for Plasma PIC Simulation. </title> <journal> Communications of the ACM, </journal> <volume> 38(10). </volume> <month> OpenGroup </month> <year> (1997). </year> <title> Network Computer Profile. </title> <type> Technical report, </type> <institution> The Open Group. </institution>
Reference-contexts: That is, the computation state of a failed process can be recreated based on the knowledge of its identity alone. This application can therefore be categorized as a computation dominant application. 1.6.2 Plasma Simulation The plasma Particle In Cell simulation model <ref> (Norton et al., 1995) </ref> integrates, in time, the trajectories of millions of charged particles in their self-consistent electro-magnetic fields.
Reference: <author> Skillicorn, D. B., Hill, J. M. D., and McColl, W. F. </author> <year> (1997). </year> <title> Questions and answers about bsp. </title> <journal> Scientific Programming, </journal> <volume> 6(3) </volume> <pages> 249-274. </pages>
Reference-contexts: Barriers have desirable features for parallel system design. By making circular data dependencies impossible, they avoid potential deadlocks and live locks, which eliminates the need for their costly detection and recovery <ref> (Skillicorn et al., 1997) </ref>. Barriers ensure that all processes reach a globally consistent state, which allows for novel forms of fault tolerance (Skillicorn et al., 1997). <p> By making circular data dependencies impossible, they avoid potential deadlocks and live locks, which eliminates the need for their costly detection and recovery <ref> (Skillicorn et al., 1997) </ref>. Barriers ensure that all processes reach a globally consistent state, which allows for novel forms of fault tolerance (Skillicorn et al., 1997). In our model of parallel computation based on BSP, the participating processors are all in a globally consistent state at the beginning of each computation step, which defines a point of a consistent checkpoint.
Reference: <author> Snir, M., Otto, S., Huss-Lederman, S., and Walker, D. </author> <year> (1996). </year> <title> MPI: The Complete Reference. Scientific and Engg Computation Series. </title> <publisher> MIT Press. </publisher>
Reference: <author> Stellner, G. </author> <year> (1996). </year> <title> CoCheck: Checkpointing and process migration for MPI. </title> <booktitle> In Proceedings of the International Parallel Processing Symposium. </booktitle>
Reference-contexts: Leon et al. (Leon et al., 1993) discuss implementation of a consistent checkpointing and roll back mechanism to transparently recover from individual processor failures. The consistent checkpoint is obtained by forcing a global synchronization before allowing a checkpoint to proceed. CoCheck <ref> (Stellner, 1996) </ref> tries to blend the resource management capabilities of systems like Condor (Litzkow et al., 1988) with parallel programming libraries such as PVM (Sunderam, 1990) and MPI (Snir et al., 1996; Gropp et al., 1994). It provides consistent checkpointing and process migration mechanism for MPI and PVM applications.
Reference: <author> Sunderam, V. S. </author> <year> (1990). </year> <title> PVM: A Framework for Parallel Distributed Computing. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(4) </volume> <pages> 315-339. </pages>
Reference-contexts: The consistent checkpoint is obtained by forcing a global synchronization before allowing a checkpoint to proceed. CoCheck (Stellner, 1996) tries to blend the resource management capabilities of systems like Condor (Litzkow et al., 1988) with parallel programming libraries such as PVM <ref> (Sunderam, 1990) </ref> and MPI (Snir et al., 1996; Gropp et al., 1994). It provides consistent checkpointing and process migration mechanism for MPI and PVM applications. Stardust (Cabillic and Puaut, 1997) is a system for parallel computations on a network of heterogeneous workstations. Stardust uses techniques similar to ours.
Reference: <author> Valiant, L. G. </author> <year> (1990). </year> <title> A Bridging Model for Parallel Computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8) </volume> <pages> 103-111. </pages>
Reference-contexts: However parallel programs, with interdependencies among their component processes, can not make progress if some of the participating workstations become unavailable during the computation. Parallel computations in such environments must adapt to the changing computing environment to deliver acceptable performance. Bulk-Synchronous Parallel (BSP) model <ref> (Valiant, 1990) </ref> is a universal abstraction of a parallel computer. By providing an intermediate level of abstraction between hardware and software, BSP offers a model for general purpose, architecture independent parallel programming. <p> Finally, we summarize our work and conclude in section 1.7. ADAPTIVE BULK-SYNCHRONOUS PARALLELISM IN A NOW 3 1.2 PARALLEL COMPUTING ON NONDEDICATED WORKSTATIONS 1.2.1 Bulk-Synchronous Parallel model Our view of the parallel computation is based on the Bulk-Synchronous Parallel (BSP) model <ref> (Valiant, 1990) </ref>, in which computation proceeds as a series of supersteps comprising of computation and communication operations. All the participating processors synchronize at the end of the superstep. By providing an intermediate level of abstraction between hardware and software, BSP provides a model for general-purpose, architecture-independent parallel programming.
References-found: 26

