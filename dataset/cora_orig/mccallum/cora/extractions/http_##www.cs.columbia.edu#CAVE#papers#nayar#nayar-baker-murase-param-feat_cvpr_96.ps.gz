URL: http://www.cs.columbia.edu/CAVE/papers/nayar/nayar-baker-murase-param-feat_cvpr_96.ps.gz
Refering-URL: http://www.cs.columbia.edu/CAVE/feature-det.html
Root-URL: http://www.cs.columbia.edu
Title: Parametric Feature Detection  
Author: Shree K. Nayar Simon Baker and Hiroshi Murase 
Address: New York, USA  Japan  
Affiliation: Department of Computer Science, Columbia University,  NTT Basic Research Laboratory, Atsugi-shi, Kanagawa,  
Note: Appeared in the Proceedings of Computer Vision and Pattern Recognition, San Francisco, 1996.  
Abstract: We propose an algorithm to automatically construct feature detectors for arbitrary parametric features. To obtain a high level of robustness we advocate the use of realistic multi-parameter feature models and incorporate optical and sensing effects. Each feature is represented as a densely sampled parametric manifold in a low dimensional subspace of a Hilbert space. During detection, the brightness distribution around each image pixel is projected into the subspace. If the projection lies sufficiently close to the feature manifold, the feature is detected and the location of the closest manifold point yields the feature parameters. The concepts of parameter reduction by normalization, dimension reduction, pattern rejection, and heuristic search are all employed to achieve the required efficiency. By applying the algorithm to appropriate parametric feature models, detectors have been constructed for five features, namely, step edge, roof edge, line, corner, and circular disc. Detailed experiments are reported on the robustness of detection and the accuracy of parameter estimation. 
Abstract-found: 1
Intro-found: 1
Reference: [Baker and Nayar 96a] <author> S. Baker and S.K. Nayar, </author> <title> "Pattern Rejection," </title> <booktitle> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> San Francisco, </address> <year> 1996. </year>
Reference-contexts: At first glance this may seem inefficient to the point of impracticality. However, we will demonstrate that our approach is very practical, through a combination of normalization, dimension reduction [Murase and Nayar 95], efficient heuristic search, 471 and rejection techniques <ref> [Baker and Nayar 96a] </ref>. Even in the present unoptimized implementation, feature detection and parameter estimation take only a few seconds on a standard single-processor workstation when applied to a 512fi480 image. <p> So, for a 512 fi 480 image complete processing would take around 4 minutes. However, by applying rejection techniques such as <ref> [Baker and Nayar 96a] </ref> the overall time was reduced to under 30secs. 5 Experimental Results 5.1 Feature Detection Rates We statistically compare our step edge detector with the Canny [Canny 86] and Nalwa-Binford [Nalwa and Binford 86] detectors, following the approach in [Nalwa and Binford 86].
Reference: [Baker and Nayar 96b] <author> S. Baker and S.K. Nayar, </author> <title> "The Design and Implementation of Parametric Feature Detectors," </title> <institution> Columbia University Technical Report, CUCS-008-96. </institution>
Reference-contexts: This happens because F 0 (m; n; q) is (approximately) independent of two of the (brightness) parameters in q. Once a feature has been detected, its mean, , and magnitude, -, can be used to recover the two parameters eliminated during normalization. See <ref> [Baker and Nayar 96b] </ref> for more details. 2.5 Dimension Reduction For several reasons, such as feature symmetries and high correlation between feature instances with similar parameter values, it is possible to represent the feature manifold in a low-dimensional subspace of &lt; N without significant loss of information 2 . <p> The intensity parameters, A and B, are free to take any value because of the normalization described in section 2.4. The structure of a normalized step edge is independent of A and B and is uniquely determined by the parameters, ; , and . Further, as described in <ref> [Baker and Nayar 96b] </ref>, the values of A and B may be recovered from the mean, , and the magnitude, -, calculated during normalization. The window chosen for our edge model is a 49 pixel disc to avoid unnecessary non-linearities induced by a square window.
Reference: [Barbe 80] <editor> D.F. Barbe, editor, Charge-Coupled Devices, </editor> <publisher> Springer-Verlag, </publisher> <year> 1980. </year>
Reference-contexts: First, the light flux falling within each pixel is integrated. If the pixels are rectangular in structure <ref> [Barbe 80] </ref> [Norton 82], the averaging function is: a (x; y) = w x w y 1 x; w y where, w x and w y are the dimensions of the pixel.
Reference: [Born and Wolf 65] <author> M. Born and E. Wolf, </author> <title> Principles of Optics, </title> <publisher> Permagon Press, </publisher> <year> 1965. </year>
Reference-contexts: One such effect is defocus. Another is that the finite size of the lens aperture causes the optical transfer function to be spatially bandlimited. Also, the feature itself, even before imaging, may be somewhat smoothed or rounded. The defocus factor can be approximated as a pillbox function <ref> [Born and Wolf 65] </ref>, the optical transfer function by the square of the first-order Bessel function of the first kind [Born and Wolf 65], and the blurring due to imperfections in the feature by a Gaussian function [Koenderink 84]. <p> Also, the feature itself, even before imaging, may be somewhat smoothed or rounded. The defocus factor can be approximated as a pillbox function <ref> [Born and Wolf 65] </ref>, the optical transfer function by the square of the first-order Bessel function of the first kind [Born and Wolf 65], and the blurring due to imperfections in the feature by a Gaussian function [Koenderink 84].
Reference: [Bracewell 78] <author> R.N. Bracewell, </author> <title> The Fourier Transform and Its Applications, Second Edition, </title> <publisher> McGraw-Hill Book Co., </publisher> <year> 1978. </year>
Reference: [Canny 86] <author> J. Canny, </author> <title> "A computational approach to edge detection," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8 </volume> <pages> 679-698, </pages> <year> 1986. </year>
Reference-contexts: However, by applying rejection techniques such as [Baker and Nayar 96a] the overall time was reduced to under 30secs. 5 Experimental Results 5.1 Feature Detection Rates We statistically compare our step edge detector with the Canny <ref> [Canny 86] </ref> and Nalwa-Binford [Nalwa and Binford 86] detectors, following the approach in [Nalwa and Binford 86]. Since we took great care modeling both the features and the imaging system, we used our step edge model to generate ideal step edges for the comparison. <p> In Figure 5, we compare the performance of our step edge detector with that of the Canny detector <ref> [Canny 86] </ref> and the Nalwa-Binford 3 We did use step 2) 0 of the Nalwa-Binford algorithm, however the inclusion of this step does not radically alter the performance.
Reference: [Davis 75] <author> L.S. Davis, </author> <title> "A Survey of Edge Detection Techniques," </title> <journal> Computer Graphics and Image Processing,' </journal> <volume> 4 </volume> <pages> 349-376, </pages> <year> 1975. </year>
Reference-contexts: A similar approach has been adopted by Nandy et al. [Nandy et al. 96]. 472 3.1 Step Edge Parametric models for edges date back to the work of Hueckel [Hueckel 71]. Since then, the edge has been studied in more detail than any other visual feature (see <ref> [Davis 75] </ref>[Nalwa 93]). Figures 1 (a) and 1 (b) show isometric and plan views of our step edge model. This model is a generalization of those used in [Hueckel 71], [Hummel 79], and [Lenz 87].
Reference: [Fukunaga 90] <author> K. Fukunaga, </author> <title> Introduction to Statistical Pattern Recognition, </title> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: If correlation between feature instances is the preferred measure of similarity, the Karhunen-Loeve (K-L) expansion <ref> [Fukunaga 90] </ref>, yields the optimal subspace.
Reference: [Hueckel 71] <author> M.H. Hueckel, </author> <title> "An Operator Which Locates Edges in Digitized Pictures," </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 18 </volume> <pages> 113-125, </pages> <year> 1971. </year>
Reference-contexts: Then, the exact location (parameters) of the closest manifold point may be used to estimate the scene parameters of the feature. This statement of the feature detection problem was first introduced by Hueckel in <ref> [Hueckel 71] </ref>, and was subsequently used by Hummel [Hummel 79] amongst others. Hueckel and Hummel both argued that to achieve high efficiency, a closed form solution must be found for (the parameters of) the closest manifold point. To make their derivations possible they used simplified feature models. <p> This results in higher precision and greater generality. A similar approach has been adopted by Nandy et al. [Nandy et al. 96]. 472 3.1 Step Edge Parametric models for edges date back to the work of Hueckel <ref> [Hueckel 71] </ref>. Since then, the edge has been studied in more detail than any other visual feature (see [Davis 75][Nalwa 93]). Figures 1 (a) and 1 (b) show isometric and plan views of our step edge model. This model is a generalization of those used in [Hueckel 71], [Hummel 79], and <p> the work of Hueckel <ref> [Hueckel 71] </ref>. Since then, the edge has been studied in more detail than any other visual feature (see [Davis 75][Nalwa 93]). Figures 1 (a) and 1 (b) show isometric and plan views of our step edge model. This model is a generalization of those used in [Hueckel 71], [Hummel 79], and [Lenz 87]. It is closest to the one used by Nalwa and Binford [Nalwa and Binford 86], but differs slightly in its treatment of smoothing effects.
Reference: [Hueckel 73] <author> M.H. Hueckel, </author> <title> "A Local Visual Operator Which Recognizes Edges and Lines," </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 20 </volume> <pages> 634-647, </pages> <year> 1973. </year>
Reference-contexts: If we were able to visualize a higher dimensional projection, these would disappear. 3.2 Line The line consists of a pair of parallel step edges separated by a short distance, namely, the width w of the line <ref> [Hueckel 73] </ref> [Lenz 87]. The line is illustrated in Figure 2 (a). In our definition, we assume that the intensity steps are both of the same magnitude. It is possible to generalize this model to lines with arbitrary brightness on either side with the addition of one extra parameter [Hueckel 73]. <p> line <ref> [Hueckel 73] </ref> [Lenz 87]. The line is illustrated in Figure 2 (a). In our definition, we assume that the intensity steps are both of the same magnitude. It is possible to generalize this model to lines with arbitrary brightness on either side with the addition of one extra parameter [Hueckel 73]. Our symmetric line model has 6 parameters and is given by: F c L (x; y; A; B; ; ; w; ) = The discrete line model is then given by equation (4).
Reference: [Hummel 79] <author> R.A. Hummel, </author> <title> "Feature Detection Using Basis Functions," </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 9 </volume> <pages> 40-55, </pages> <year> 1979. </year>
Reference-contexts: Then, the exact location (parameters) of the closest manifold point may be used to estimate the scene parameters of the feature. This statement of the feature detection problem was first introduced by Hueckel in [Hueckel 71], and was subsequently used by Hummel <ref> [Hummel 79] </ref> amongst others. Hueckel and Hummel both argued that to achieve high efficiency, a closed form solution must be found for (the parameters of) the closest manifold point. To make their derivations possible they used simplified feature models. Our view of feature detection is radically different. <p> The results for the roof edge and the circular disc are similar and may be found in [Nayar et al. 95]. 2 This idea was first explored by Hummel <ref> [Hummel 79] </ref>. Whereas Hummel derived closed-form solutions based on simplistic feature models, our approach is to use elaborate feature models and numerical methods. This results in higher precision and greater generality. <p> Since then, the edge has been studied in more detail than any other visual feature (see [Davis 75][Nalwa 93]). Figures 1 (a) and 1 (b) show isometric and plan views of our step edge model. This model is a generalization of those used in [Hueckel 71], <ref> [Hummel 79] </ref>, and [Lenz 87]. It is closest to the one used by Nalwa and Binford [Nalwa and Binford 86], but differs slightly in its treatment of smoothing effects. <p> The step edge manifold is parameterized by orientation and intrapixel localization for a fixed blurring value and is displayed in a 3-D subspace constructed using the first three eigenvectors. 473 <ref> [Hummel 79] </ref> is immediate. On closer inspection, how-ever, we notice that while Hummel's eigenvectors are radially symmetric, the ones we computed are not. This is to be expected since the introduction of the parameters, and , breaks the radial symmetry that Hummel's edge model assumes.
Reference: [Koenderink 84] <author> J.J. Koenderink, </author> <title> "The Structure of Images," </title> <journal> Biological Cybernetics,' </journal> <volume> 50 </volume> <pages> 363-370, </pages> <year> 1984. </year>
Reference-contexts: The defocus factor can be approximated as a pillbox function [Born and Wolf 65], the optical transfer function by the square of the first-order Bessel function of the first kind [Born and Wolf 65], and the blurring due to imperfections in the feature by a Gaussian function <ref> [Koenderink 84] </ref>.
Reference: [Lenz 87] <author> R. Lenz, </author> <title> "Optimal Filters for the Detection of Linear Patterns in 2-D and Higher Dimensional Images," </title> <journal> Pattern Recognition, </journal> <volume> 20 </volume> <pages> 163-172, </pages> <year> 1987. </year>
Reference-contexts: Since then, the edge has been studied in more detail than any other visual feature (see [Davis 75][Nalwa 93]). Figures 1 (a) and 1 (b) show isometric and plan views of our step edge model. This model is a generalization of those used in [Hueckel 71], [Hummel 79], and <ref> [Lenz 87] </ref>. It is closest to the one used by Nalwa and Binford [Nalwa and Binford 86], but differs slightly in its treatment of smoothing effects. <p> If we were able to visualize a higher dimensional projection, these would disappear. 3.2 Line The line consists of a pair of parallel step edges separated by a short distance, namely, the width w of the line [Hueckel 73] <ref> [Lenz 87] </ref>. The line is illustrated in Figure 2 (a). In our definition, we assume that the intensity steps are both of the same magnitude. It is possible to generalize this model to lines with arbitrary brightness on either side with the addition of one extra parameter [Hueckel 73].
Reference: [Murase and Nayar 95] <author> H. Murase and S.K. Nayar, </author> <title> Visual Learning and Recognition of 3-D Objects from Appearance," </title> <journal> International Journal of Computer Vision, </journal> <volume> 14 </volume> <pages> 5-24, </pages> <year> 1995. </year>
Reference-contexts: Instead, we discretize the search problem by densely sampling the feature manifold. At first glance this may seem inefficient to the point of impracticality. However, we will demonstrate that our approach is very practical, through a combination of normalization, dimension reduction <ref> [Murase and Nayar 95] </ref>, efficient heuristic search, 471 and rejection techniques [Baker and Nayar 96a]. Even in the present unoptimized implementation, feature detection and parameter estimation take only a few seconds on a standard single-processor workstation when applied to a 512fi480 image.
Reference: [Nalwa 93] <author> V.S. Nalwa, </author> <title> A Guided Tour of Computer Vision, </title> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction Most applications in image processing and computational vision rely on robust detection of image features and accurate estimation of their parameters. The standard example of a parametrized feature is the step edge <ref> [Nalwa 93] </ref>. The step edge, however, is by no means the only feature of interest in image understanding. A comprehensive list would also include lines, corners, junctions, and roof edges 1 as well as numerous others.
Reference: [Nalwa and Binford 86] <author> V.S. </author> <title> Nalwa and T.O. Binford, "On detecting edges," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8 </volume> <pages> 699-714, </pages> <year> 1986. </year>
Reference-contexts: Figures 1 (a) and 1 (b) show isometric and plan views of our step edge model. This model is a generalization of those used in [Hueckel 71], [Hummel 79], and [Lenz 87]. It is closest to the one used by Nalwa and Binford <ref> [Nalwa and Binford 86] </ref>, but differs slightly in its treatment of smoothing effects. <p> We restrict the localization parameter, , to lie in [1= p p 2], since any edge must pass closer than 1= p 2 pixels from the center of at least one pixel in the image. The blurring parameter, 2 [0:3; 1:5]. As described in <ref> [Nalwa and Binford 86] </ref>, substantially larger values of could be used, but really represent an edge at a much higher magnification. The intensity parameters, A and B, are free to take any value because of the normalization described in section 2.4. <p> We see that the Canny detector and the parametric manifold technique perform similarly, with the Canny detector doing marginally better for low levels of noise. The results for the Nalwa-Binford detector (which are consistent with the results presented in <ref> [Nalwa and Binford 86] </ref>) are completely different. to perform normalization, projection and search takes around 1ms on a DEC Alpha 3600. So, for a 512 fi 480 image complete processing would take around 4 minutes. <p> However, by applying rejection techniques such as [Baker and Nayar 96a] the overall time was reduced to under 30secs. 5 Experimental Results 5.1 Feature Detection Rates We statistically compare our step edge detector with the Canny [Canny 86] and Nalwa-Binford <ref> [Nalwa and Binford 86] </ref> detectors, following the approach in [Nalwa and Binford 86]. Since we took great care modeling both the features and the imaging system, we used our step edge model to generate ideal step edges for the comparison. For fairness, however, we changed the details slightly. <p> However, by applying rejection techniques such as [Baker and Nayar 96a] the overall time was reduced to under 30secs. 5 Experimental Results 5.1 Feature Detection Rates We statistically compare our step edge detector with the Canny [Canny 86] and Nalwa-Binford <ref> [Nalwa and Binford 86] </ref> detectors, following the approach in [Nalwa and Binford 86]. Since we took great care modeling both the features and the imaging system, we used our step edge model to generate ideal step edges for the comparison. For fairness, however, we changed the details slightly. <p> Hence, we changed the window of our detector to be a square window containing 25 pixels, rather than the 49 pixel disc window used earlier. We generate "not edges" exactly as in <ref> [Nalwa and Binford 86] </ref>, by taking a constant intensity window, and adding white zero-mean Guassian noise. In Figure 4 we compare the detection performance of the three edge detectors. For each pair of S.N.R. and noise to it, and then applied the edge detectors. <p> The closer a curve lies to the origin in Figure 4, the better the performance. Hence, we can see that both the Canny detector and our detector do increasingly well as the S.N.R. increases. The results for the Nalwa-Binford detector are consistent 3 with those described in <ref> [Nalwa and Binford 86] </ref>. Applied to real images, the Nalwa-Binford detector does not perform as poorly as and may well be completely different if we fix the step-size threshold, and vary the tanh-fit threshold. 5.2 Parameter Estimation Accuracy Again following [Nalwa and Binford 86], we analyze parameter estimation accuracy by randomly <p> the Nalwa-Binford detector are consistent 3 with those described in <ref> [Nalwa and Binford 86] </ref>. Applied to real images, the Nalwa-Binford detector does not perform as poorly as and may well be completely different if we fix the step-size threshold, and vary the tanh-fit threshold. 5.2 Parameter Estimation Accuracy Again following [Nalwa and Binford 86], we analyze parameter estimation accuracy by randomly generating a set of feature parameters, synthesizing a feature with these parameters, adding noise, applying the detector, and then measurings the accuracy of the estimated parameters. <p> In Figure 5, we compare the performance of our step edge detector with that of the Canny detector [Canny 86] and the Nalwa-Binford 3 We did use step 2) 0 of the Nalwa-Binford algorithm, however the inclusion of this step does not radically alter the performance. See <ref> [Nalwa and Binford 86] </ref> for more details. 476 and discriminate all 5 example features in the same image using the same technique. [Nalwa and Binford 86] detector. In the figure, we plot the R.M.S. error in the estimate of the orientation, , against the S.N.R. <p> See <ref> [Nalwa and Binford 86] </ref> for more details. 476 and discriminate all 5 example features in the same image using the same technique. [Nalwa and Binford 86] detector. In the figure, we plot the R.M.S. error in the estimate of the orientation, , against the S.N.R. We see that for low S.N.R. the performance of all detectors is limited by the noise.
Reference: [Nandy et al. 96] <author> D. Nandy, Z. Wang, J. Ben-Arie, K.R. Rao, N. Jojic, </author> <title> "A Generalized Feature Extractor using Expansion Matching and the Karhunen-Loeve Transform," </title> <booktitle> In Proceedings of the ARPA Image Understanding Workshop, </booktitle> <pages> pages 969-972, </pages> <address> Palm Springs, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: Whereas Hummel derived closed-form solutions based on simplistic feature models, our approach is to use elaborate feature models and numerical methods. This results in higher precision and greater generality. A similar approach has been adopted by Nandy et al. <ref> [Nandy et al. 96] </ref>. 472 3.1 Step Edge Parametric models for edges date back to the work of Hueckel [Hueckel 71]. Since then, the edge has been studied in more detail than any other visual feature (see [Davis 75][Nalwa 93]).
Reference: [Nayar et al. 95] <author> S.K. Nayar, S. Baker, and H. Murase, </author> <title> "Parametric Feature Detection," </title> <institution> Columbia University Technical Report, CUCS-028-95, </institution> <year> 1995. </year>
Reference-contexts: The results for the roof edge and the circular disc are similar and may be found in <ref> [Nayar et al. 95] </ref>. 2 This idea was first explored by Hummel [Hummel 79]. Whereas Hummel derived closed-form solutions based on simplistic feature models, our approach is to use elaborate feature models and numerical methods. This results in higher precision and greater generality. <p> So long as we sample densely enough, this yields a sufficiently good estimate of the closest manifold point. The search technique used is a heuristic coarse-to-fine search which takes advantage of the relatively smooth manifolds. The details of the sampling and search procedures can be found in <ref> [Nayar et al. 95] </ref>. As an example of the search complexity for the step edge model, if we sample every 1:6 ffi , every 0:088, and every 0:14, we end up with 46,368 sample points. <p> To our knowledge, this is first time these 5 different features have been detected and discriminated in the same image. Further, the proposed technique can easily be generalized to other user-defined parametric features <ref> [Nayar et al. 95] </ref>. Acknowledgements We wish to thank Vic Nalwa for providing an implementation of the Nalwa-Binford edge detector, and Sergio Cuniolo, Michael Heath, Tony Lindenberg, Jose-Maria Montiel, and Geoff West for providing pointers to Canny edge detectors.
Reference: [Nobel 88] <author> J.A. Nobel, </author> <title> "Finding corners," </title> <journal> Image and Vision Computing, </journal> <volume> 6 </volume> <pages> 121-127, </pages> <year> 1988. </year>
Reference-contexts: This results from the following symmetry in the line model: F L (; A; B; + 180 o ; ; w; ) = F L (; A; B; ; ; w; ) 3.3 Corner The corner is a common and hence important image feature <ref> [Nobel 88] </ref>. In our corner model, shown in Figure 3 (a), 1 is the angle of one of the edges which comprise the corner, and 2 is the angle subtended by the corner itself, as illustrated in Figure 3 (b).
Reference: [Norton 82] <author> H.N. Norton, </author> <title> Sensor and Analyzer Handbook, </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year> <month> 477 </month>
Reference-contexts: First, the light flux falling within each pixel is integrated. If the pixels are rectangular in structure [Barbe 80] <ref> [Norton 82] </ref>, the averaging function is: a (x; y) = w x w y 1 x; w y where, w x and w y are the dimensions of the pixel.
References-found: 20

