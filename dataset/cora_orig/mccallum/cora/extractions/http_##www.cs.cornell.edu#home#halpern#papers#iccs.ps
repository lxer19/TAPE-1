URL: http://www.cs.cornell.edu/home/halpern/papers/iccs.ps
Refering-URL: http://www.auai.org/auai-tutes.html
Root-URL: 
Email: halpern@cs.cornell.edu  
Title: A LOGICAL APPROACH TO REASONING ABOUT UNCERTAINTY: A TUTORIAL  
Author: Joseph Y. Halpern 
Date: July 14, 1995  
Web: http://www.cs.cornell.edu/home/halpern  
Address: 4144 Upson Hall Ithaca, NY 14853  
Affiliation: Cornell University Computer Science Department  
Abstract: fl This paper will appear in Discourse, Interaction, and Communication, X. Arrazola, K. Korta, and F. J. Pelletier, eds., Kluwer, 1997. Much of this work was performed while the author was at IBM Almaden Research Center. IBM's support is gratefully acknowledged. 
Abstract-found: 1
Intro-found: 1
Reference: [BF82] <author> M. Bar-Hillel and R. Falk. </author> <title> Some teasers concerning conditional probabilities. </title> <journal> Cognition, </journal> <volume> 11 </volume> <pages> 109-122, </pages> <year> 1982. </year>
Reference-contexts: These puzzles are presented under the assumption that the uncertainty is quantified in terms of probability, but the issues that they bring out arise whatever method we use to represent uncertainty. The second-ace puzzle <ref> [BF82, Fre65, Sha85] </ref>: Suppose we have a deck with four cards: the ace and deuce of hearts, and the ace and deuce of spades. After a fair shu*e of the deck, two cards are dealt to Alice.
Reference: [DP90] <author> D. Dubois and H. Prade. </author> <title> An introduction to possibilistic and fuzzy logics. </title> <editor> In G. Shafer and J. Pearl, editors, </editor> <booktitle> Readings in Uncertain Reasoning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, Calif., </address> <year> 1990. </year>
Reference-contexts: There is nothing to stop us from using different, perhaps more qualititative, representations. For example, we might consider a preferential ordering on worlds [KLM90], 15 where, intuitively, one world is preferred to another if it is significantly more likely. Alternatively, we could use Dempster-Shafer belief functions [Sha76], possibility measures <ref> [DP90] </ref>, comparative probability [Fin73], or ordinal rankings [Spo87]. Recently, Nir Friedman and I have introduced plausibility measures [FH95b], which generalize all of these approaches. A plausibility measure associates with each set its plausibility, which is just some element of a partially ordered set.
Reference: [FH94a] <author> R. Fagin and J. Y. Halpern. </author> <title> Reasoning about knowledge and probability. </title> <journal> Journal of the ACM, </journal> <volume> 41(2) </volume> <pages> 340-367, </pages> <year> 1994. </year>
Reference-contexts: He then asks you if you still want to take what's behind door 1, or to take what's behind door 3 instead. Should you switch? The Two-Coin Problem <ref> [FH94a] </ref>: Alice has two coins. One of them is fair, and so has equal likelihood of landing heads and tails. The other is biased, and is twice 1 as likely to land heads as to land tails. <p> What is the probability, according to Bob, that the outcome of the coin toss will be heads? What is the probability according to Alice? (Both of these probabilities are for the situation before the coin is tossed.) The Single-Coin Problem <ref> [FH94a] </ref>: This time both Bob and Alice know that Alice is using the fair coin. Alice tosses the coin and looks at the outcome. <p> In particular, axiomatizations for modal (multi-agent) logics of knowledge and belief are presented in [HM92], the case of knowledge and time is considered in [HV89], the case of probability is considered in [FHM90], and the combination of knowledge and probability is considered in <ref> [FH94a] </ref>. * As Pearl and others have stressed, one of the most important aspects of probabilistic reasoning involves reasoning about dependencies, independences, and causality. Indeed, Pearl makes a strong case that much human reasoning about uncertainty involves this type of reasoning.
Reference: [FH94b] <author> N. Friedman and J. Y. Halpern. </author> <title> A knowledge-based framework for belief change. Part I: foundations. </title> <editor> In R. Fagin, editor, </editor> <booktitle> Theoretical Aspects of Reasoning about Knowledge: Proc. Fifth Conference, </booktitle> <pages> pages 44-64. </pages> <publisher> Morgan Kauf-mann, </publisher> <address> San Francisco, Calif., </address> <year> 1994. </year>
Reference-contexts: By taking the set to be [0; 1] (with the usual ordering) and imposing some extra requirements on the plausibility, we can get back probability measures. A discussion of how to use preferential orderings rather than probability in the context of systems can be found in <ref> [FH94b] </ref>; in [FH95a], this discussion is redone using plausibility. The changes required are all quite straightforward.
Reference: [FH95a] <author> N. Friedman and J. Y. Halpern. </author> <title> Modeling belief in dynamic systems. Part I: foundations. </title> <type> Technical Report RJ9965, </type> <institution> IBM, </institution> <year> 1995. </year> <note> Available by anonymous ftp from starry.stanford.edu/pub/nir or via WWW at http:// robotics.stanford.edu/users/nir. </note>
Reference-contexts: By taking the set to be [0; 1] (with the usual ordering) and imposing some extra requirements on the plausibility, we can get back probability measures. A discussion of how to use preferential orderings rather than probability in the context of systems can be found in [FH94b]; in <ref> [FH95a] </ref>, this discussion is redone using plausibility. The changes required are all quite straightforward.
Reference: [FH95b] <author> N. Friedman and J. Y. Halpern. </author> <title> Plausibility measures: a user's manual. </title> <editor> In P. Besnard and S. Hanks, editors, </editor> <booktitle> Proc. Eleventh Conference on Uncertainty in Artificial Intelligence (UAI '95). </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, Calif., </address> <year> 1995. </year>
Reference-contexts: Alternatively, we could use Dempster-Shafer belief functions [Sha76], possibility measures [DP90], comparative probability [Fin73], or ordinal rankings [Spo87]. Recently, Nir Friedman and I have introduced plausibility measures <ref> [FH95b] </ref>, which generalize all of these approaches. A plausibility measure associates with each set its plausibility, which is just some element of a partially ordered set.
Reference: [FHM90] <author> R. Fagin, J. Y. Halpern, and N. Megiddo. </author> <title> A logic for reasoning about probabilities. </title> <journal> Information and Computation, </journal> 87(1/2):78-128, 1990. 
Reference-contexts: It is easy to allow even more complicated formulas such as pr i (') + 2pr i ( ) ff (and this, in fact, is done in <ref> [FHM90] </ref>), but all the basic ideas should already be clear with the simple language we are considering. To give semantics to such formulas, we need to augment the Kripke structures used in Section 2 with a probability distribution. <p> There are added complexities in dealing with arbitrary probability distributions, which I would rather avoid here; see <ref> [FHM90] </ref> for details. 8 There are four possible worlds, which we can denote (F; H), (F; T ), (B; H), (B; T ): the fair coin is chosen and will land heads, the fair coin is chosen and will land tails, and so on. 5 Bob cannot distinguish any of these <p> Complete axiomatizations and decision procedures are known for most of the logics presented here. In particular, axiomatizations for modal (multi-agent) logics of knowledge and belief are presented in [HM92], the case of knowledge and time is considered in [HV89], the case of probability is considered in <ref> [FHM90] </ref>, and the combination of knowledge and probability is considered in [FH94a]. * As Pearl and others have stressed, one of the most important aspects of probabilistic reasoning involves reasoning about dependencies, independences, and causality.
Reference: [FHMV95] <author> R. Fagin, J. Y. Halpern, Y. Moses, and M. Y. Vardi. </author> <title> Reasoning about Knowledge. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <note> to appear, 1995. 16 </note>
Reference-contexts: But where are these possible worlds coming from? I shall now consider a more concrete framework, that incorporates both knowledge and time, and takes an agent's knowledge to be determined by the agent's internal state. The ideas presented here are mainly taken from <ref> [HF89, FHMV95] </ref>. Suppose we want to analyze a multi-agent system. The phrase "system" is intended to be interpreted rather loosely here. Players in a poker game, agents conducting a bargaining session, robots interacting to clean a house, and processes in a computing system can all be viewed as multi-agent systems. <p> Where do the runs in the system come from? Typically, they are generated by means of a protocol. I do not want to go into the formal definitions here (these can be found in <ref> [HF89, FHMV95] </ref>), but intuitively, a protocol is a description of the actions that an agent takes as a function of her local state. We shall see some examples of protocols later in the paper. 4 Adding probability Up to now we have considered time and knowledge.
Reference: [Fin73] <author> T. L. </author> <title> Fine. Theories of Probability. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: For example, we might consider a preferential ordering on worlds [KLM90], 15 where, intuitively, one world is preferred to another if it is significantly more likely. Alternatively, we could use Dempster-Shafer belief functions [Sha76], possibility measures [DP90], comparative probability <ref> [Fin73] </ref>, or ordinal rankings [Spo87]. Recently, Nir Friedman and I have introduced plausibility measures [FH95b], which generalize all of these approaches. A plausibility measure associates with each set its plausibility, which is just some element of a partially ordered set.
Reference: [Fre65] <author> J. E. Freund. </author> <title> Puzzle or paradox? American Statistician, </title> <booktitle> 19(4) </booktitle> <pages> 29-44, </pages> <year> 1965. </year>
Reference-contexts: These puzzles are presented under the assumption that the uncertainty is quantified in terms of probability, but the issues that they bring out arise whatever method we use to represent uncertainty. The second-ace puzzle <ref> [BF82, Fre65, Sha85] </ref>: Suppose we have a deck with four cards: the ace and deuce of hearts, and the ace and deuce of spades. After a fair shu*e of the deck, two cards are dealt to Alice.
Reference: [HC68] <author> G. E. Hughes and M. J. Cresswell. </author> <title> An Introduction to Modal Logic. </title> <publisher> Methuen, </publisher> <address> London, </address> <year> 1968. </year>
Reference-contexts: Intuitively, the local state encapsulates all the relevant 3 Readers familiar with modal logic will recognize that if we assume that the K i 's are Euclidean and transitive, we get the modal logic K45; if we further assume that they are equivalence relations, we get S5 <ref> [HM92, HC68] </ref>. information to which the agent has access.
Reference: [HF89] <author> J. Y. Halpern and R. Fagin. </author> <title> Modelling knowledge and action in distributed systems. </title> <journal> Distributed Computing, </journal> <volume> 3(4) </volume> <pages> 159-179, </pages> <year> 1989. </year> <note> A preliminary version appeared in Proc. 4th ACM Symposium on Principles of Distributed Computing, </note> <year> 1985, </year> <title> with the title "A formal model of knowledge, action, and communication in distributed systems: </title> <note> preliminary report". </note>
Reference-contexts: But where are these possible worlds coming from? I shall now consider a more concrete framework, that incorporates both knowledge and time, and takes an agent's knowledge to be determined by the agent's internal state. The ideas presented here are mainly taken from <ref> [HF89, FHMV95] </ref>. Suppose we want to analyze a multi-agent system. The phrase "system" is intended to be interpreted rather loosely here. Players in a poker game, agents conducting a bargaining session, robots interacting to clean a house, and processes in a computing system can all be viewed as multi-agent systems. <p> Where do the runs in the system come from? Typically, they are generated by means of a protocol. I do not want to go into the formal definitions here (these can be found in <ref> [HF89, FHMV95] </ref>), but intuitively, a protocol is a description of the actions that an agent takes as a function of her local state. We shall see some examples of protocols later in the paper. 4 Adding probability Up to now we have considered time and knowledge.
Reference: [Hin62] <author> J. Hintikka. </author> <title> Knowledge and Belief. </title> <publisher> Cornell University Press, </publisher> <address> Ithaca, N.Y., </address> <year> 1962. </year>
Reference-contexts: The various puzzles are analyzed in the resulting framework in Section 5. Other topics are briefly discussed in Section 6. 2 2 Basic modal logic: knowledge, belief, and time Let us start by considering a simple model to capture an agent's knowledge, using ideas that go back to Hintikka <ref> [Hin62] </ref>. Suppose we have an agent with some information, and we want to reason about her beliefs. Given her current information, the agent may not be able to tell which of a number of possible worlds describes the actual state of affairs.
Reference: [HM92] <author> J. Y. Halpern and Y. Moses. </author> <title> A guide to completeness and complexity for modal logics of knowledge and belief. </title> <journal> Artificial Intelligence, </journal> <volume> 54 </volume> <pages> 319-379, </pages> <year> 1992. </year>
Reference-contexts: Intuitively, the local state encapsulates all the relevant 3 Readers familiar with modal logic will recognize that if we assume that the K i 's are Euclidean and transitive, we get the modal logic K45; if we further assume that they are equivalence relations, we get S5 <ref> [HM92, HC68] </ref>. information to which the agent has access. <p> Complete axiomatizations and decision procedures are known for most of the logics presented here. In particular, axiomatizations for modal (multi-agent) logics of knowledge and belief are presented in <ref> [HM92] </ref>, the case of knowledge and time is considered in [HV89], the case of probability is considered in [FHM90], and the combination of knowledge and probability is considered in [FH94a]. * As Pearl and others have stressed, one of the most important aspects of probabilistic reasoning involves reasoning about dependencies, independences,
Reference: [HT93] <author> J. Y. Halpern and M. R. Tuttle. </author> <title> Knowledge, probability, </title> <journal> and adversaries. Journal of the ACM, </journal> <volume> 40(4) </volume> <pages> 917-962, </pages> <year> 1993. </year>
Reference-contexts: It is beyond the scope of these notes to delve into which of the two approaches is "right". (This issue is discussed in some detail in <ref> [HT93] </ref>, where the point is made that a useful way of approaching this issue is to think in terms of the nature of the adversary against which Bob is playing.) 5 Combining knowledge, probability, and time We can now put all the pieces together, and combine knowledge, probability, and time, using <p> Clearly, we would like that probability to be related to the probability on runs. The obvious way to do this is to condition, but what do we condition on? There is not enough space here to go into all the details (see <ref> [HT93] </ref> for those) but the general answer is to condition on the agent's knowledge. To make this clearer, let us consider the two-coin example in a little more detail, by putting in the local states for Alice and Bob.
Reference: [HV89] <author> J. Y. Halpern and M. Y. Vardi. </author> <title> The complexity of reasoning about knowledge and time, I: lower bounds. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 38(1) </volume> <pages> 195-237, </pages> <year> 1989. </year>
Reference-contexts: Complete axiomatizations and decision procedures are known for most of the logics presented here. In particular, axiomatizations for modal (multi-agent) logics of knowledge and belief are presented in [HM92], the case of knowledge and time is considered in <ref> [HV89] </ref>, the case of probability is considered in [FHM90], and the combination of knowledge and probability is considered in [FH94a]. * As Pearl and others have stressed, one of the most important aspects of probabilistic reasoning involves reasoning about dependencies, independences, and causality.
Reference: [KLM90] <author> S. Kraus, D. Lehmann, and M. Magidor. </author> <title> Nonmonotonic reasoning, preferential models and cumulative logics. </title> <journal> Artificial Intelligence, </journal> <volume> 44 </volume> <pages> 167-207, </pages> <year> 1990. </year>
Reference-contexts: There is nothing to stop us from using different, perhaps more qualititative, representations. For example, we might consider a preferential ordering on worlds <ref> [KLM90] </ref>, 15 where, intuitively, one world is preferred to another if it is significantly more likely. Alternatively, we could use Dempster-Shafer belief functions [Sha76], possibility measures [DP90], comparative probability [Fin73], or ordinal rankings [Spo87]. Recently, Nir Friedman and I have introduced plausibility measures [FH95b], which generalize all of these approaches.
Reference: [MCDD91] <author> J. P. Morgan, N. R. Chaganty, R. C. Dahiya, and M. J. Doviak. </author> <title> Let's make a deal: the player's dilemma (with commentary). </title> <journal> The American Statistician, </journal> <volume> 45(4) </volume> <pages> 284-289, </pages> <year> 1991. </year>
Reference-contexts: Why should finding out which particular ace it is raise the conditional probability of Alice having two aces? The Monty Hall Puzzle <ref> [Sav91, MCDD91] </ref>: Suppose you're on a game show and given a choice of three doors. Behind one is a car; behind the others are goats. You pick door 1. <p> Since, with any choice of ff ij , you are at least as likely to win by switching as by not switching, 14 it seems that you ought to switch. However, as pointed out in <ref> [MCDD91] </ref>, this analysis is carried out under the assumption that, at step 3, Monty must open another door.
Reference: [Pea88] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, Calif., </address> <year> 1988. </year>
Reference-contexts: This is an active area of research that holds a great deal of promise; I would encourage the interested reader to consult <ref> [Pea88] </ref> for an overview. * The focus here has been on representing uncertainty with probability. There is nothing to stop us from using different, perhaps more qualititative, representations.
Reference: [Sav91] <author> M. </author> <title> vos Savant. Ask Marilyn. </title> <journal> Parade Magazine, Sept. </journal> <volume> 9, </volume> <year> 1990; </year> <month> Dec. 2, </month> <year> 1990; </year> <month> Feb. 17, </month> <year> 1991. </year>
Reference-contexts: Why should finding out which particular ace it is raise the conditional probability of Alice having two aces? The Monty Hall Puzzle <ref> [Sav91, MCDD91] </ref>: Suppose you're on a game show and given a choice of three doors. Behind one is a car; behind the others are goats. You pick door 1.
Reference: [Sha76] <author> G. Shafer. </author> <title> A Mathematical Theory of Evidence. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, N.J., </address> <year> 1976. </year>
Reference-contexts: There is nothing to stop us from using different, perhaps more qualititative, representations. For example, we might consider a preferential ordering on worlds [KLM90], 15 where, intuitively, one world is preferred to another if it is significantly more likely. Alternatively, we could use Dempster-Shafer belief functions <ref> [Sha76] </ref>, possibility measures [DP90], comparative probability [Fin73], or ordinal rankings [Spo87]. Recently, Nir Friedman and I have introduced plausibility measures [FH95b], which generalize all of these approaches. A plausibility measure associates with each set its plausibility, which is just some element of a partially ordered set.
Reference: [Sha85] <author> G. Shafer. </author> <title> Conditional probability. </title> <journal> International Statistical Review, </journal> <volume> 53(3) </volume> <pages> 261-277, </pages> <year> 1985. </year>
Reference-contexts: These puzzles are presented under the assumption that the uncertainty is quantified in terms of probability, but the issues that they bring out arise whatever method we use to represent uncertainty. The second-ace puzzle <ref> [BF82, Fre65, Sha85] </ref>: Suppose we have a deck with four cards: the ace and deuce of hearts, and the ace and deuce of spades. After a fair shu*e of the deck, two cards are dealt to Alice. <p> This will mean that, after the coin toss, he believes that the probability of heads is either 0 or 1, although he does not know which. We can apply the same methodology to the Second-Ace problem from the introduction. As Shafer points out <ref> [Sha85] </ref>, the ambiguities in the problem become clearer when we specify the protocol that Alice and Bob are following. One possible protocol that is consistent with the story is that, at step 1, Alice is dealt two cards.
Reference: [Spo87] <author> W. Spohn. </author> <title> Ordinal conditional functions: a dynamic theory of epistemic states. </title> <editor> In W. Harper and B. Skyrms, editors, </editor> <title> Causation in Decision, </title> <journal> Belief Change and Statistics, </journal> <volume> volume 2, </volume> <pages> pages 105-134. </pages> <publisher> Reidel, Dordrecht, Holland, </publisher> <year> 1987. </year>
Reference-contexts: For example, we might consider a preferential ordering on worlds [KLM90], 15 where, intuitively, one world is preferred to another if it is significantly more likely. Alternatively, we could use Dempster-Shafer belief functions [Sha76], possibility measures [DP90], comparative probability [Fin73], or ordinal rankings <ref> [Spo87] </ref>. Recently, Nir Friedman and I have introduced plausibility measures [FH95b], which generalize all of these approaches. A plausibility measure associates with each set its plausibility, which is just some element of a partially ordered set.
References-found: 23

