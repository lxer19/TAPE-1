URL: http://robotics.stanford.edu/~ronnyk/roughOODG.ps
Refering-URL: http://robotics.stanford.edu/users/ronnyk/ronnyk-bib.html
Root-URL: 
Email: ronnyk@CS.Stanford.EDU  
Title: Rough Sets and Soft Computing (RSSC 94) A Third Dimension to Rough Sets  
Author: Ron Kohavi 
Address: Stanford, CA 94305  
Affiliation: Computer Science Dept. Stanford University  
Note: To appear in the Third International Workshop on  
Abstract: Rough-sets relative reducts allow one to reduce the number of attributes in a supervised classification problem without sacrificing the consistency of the decision table. In many problems, the cardinality of the relative reducts is large, making the decision table unmanageably big. We propose reducing the size of reducts, and hence the decision table, by increasing the number of label values (values of the decision attribute). The reduction process is accomplished through a two-step process whereby an instance is mapped to an intermediate label using one subset of attributes, and then mapped to the final label using a disjoint subset of attributes. In some cases, the table representation size of the functions generated using this method will be much smaller than the representation of a single unified function. It is possible to repeat the splitting process, creating multiple rough-set approximations, each one containing one attribute less than the previous one, but at a possible increase in the number of labels. The structures formed are isomorphic to oblivious read-once decision graphs (OODGs) and to ordered binary decision diagrams (OBDDs), thus providing an alternative view of how algorithms that construct such graphs operate.
Abstract-found: 1
Intro-found: 1
Reference: [ Brace et al., 1990 ] <author> Karl S. Brace, Richard L. Rudell, and Randal E. Bryant. </author> <title> Efficient implementation of a BDD package. </title> <booktitle> In Proceedings of the 27th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 40-45, </pages> <year> 1990. </year>
Reference: [ Bryant, 1986 ] <author> Randal E. Bryant. </author> <title> Graph-based algorithms for boolean function manipulation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35(8):677-691, </volume> <year> 1986. </year>
Reference-contexts: Even if we include some overhead for specifying which attributes a table needs to examine, the gap between this representation and a unified table is exponential. Figure 5 shows the OODG representation of this function. 4 Discussion and Related Work Bryant <ref> [ Bryant, 1986 ] </ref> introduced Ordered Binary Decision Diagrams (OBDDs), which spawned a plethora of articles and a whole sub-community dealing with ways to build small OBDDs [ Bryant, 1992, Brace et al., 1990, Minato et al., 1990, Fujita et al., 1993 ] .
Reference: [ Bryant, 1992 ] <author> Randal E. Bryant. </author> <title> Symbolic boolean manipulation with ordered binary-decision diagrams. </title> <journal> ACM Computing Surveys, </journal> <volume> 24(3) </volume> <pages> 293-318, </pages> <year> 1992. </year>
Reference-contexts: By generalizing this two-step decomposition to m steps, where m is the number of attributes, one essentially builds an oblivious read-once decision graph (OODG) [ Kohavi, 1994a, Kohavi, 1994b ] , or an ordered binary decision diagram (OBDD) <ref> [ Bryant, 1992 ] </ref> .
Reference: [ Burch et al., 1990 ] <author> J. R. Burch, E. M. Clarke, K. L. McMillan, D. L. Dill, and L. J. Hwang. </author> <title> Symbolic model checking: 10 20 states and beyond. </title> <booktitle> In Fifth Annual IEEE Symposium on Logic in Computer Science., </booktitle> <pages> pages 428-439. </pages> <publisher> IEEE Comput. Soc. Press, </publisher> <year> 1990. </year>
Reference-contexts: OBDDs have been used for automatically verifying finite state machines, including 64-bit ALUs, with up to 10 120 states by representing the state space symbolically instead of explicitly <ref> [ Burch et al., 1990, Burch et al., 1991 ] </ref> . In the machine learning community, Kohavi [ 1994a, 1994b ] investigated the possibility of using oblivious decision graphs as the underlying hypothesis space for supervised classification learning.
Reference: [ Burch et al., 1991 ] <author> J. R. Burch, E. M. Clarke, and D. E. </author> <title> Long. Representing circuits more efficiently in symbolic model checking. </title> <booktitle> In Proceedings of the 28th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 403-407, </pages> <year> 1991. </year>
Reference-contexts: OBDDs have been used for automatically verifying finite state machines, including 64-bit ALUs, with up to 10 120 states by representing the state space symbolically instead of explicitly <ref> [ Burch et al., 1990, Burch et al., 1991 ] </ref> . In the machine learning community, Kohavi [ 1994a, 1994b ] investigated the possibility of using oblivious decision graphs as the underlying hypothesis space for supervised classification learning.
Reference: [ Fujita et al., 1993 ] <author> Masahiro Fujita, Hisanori Fujisawa, and Jusuke Matsunaga. </author> <title> Variable ordering algorithms for ordered binary decision diagrams and their evaluation. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, </journal> <volume> 12(1) </volume> <pages> 6-12, </pages> <year> 1993. </year>
Reference: [ Kohavi, 1994a ] <author> Ron Kohavi. </author> <title> Bottom-up induction of oblivious, read-once decision graphs. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, </booktitle> <month> April </month> <year> 1994. </year> <note> Paper available by anonymous ftp from starry.Stanford.EDU:pub/ronnyk/euroML94.ps. </note>
Reference-contexts: The intermediate label is then mapped into the final label using a disjoint subset of attributes. By generalizing this two-step decomposition to m steps, where m is the number of attributes, one essentially builds an oblivious read-once decision graph (OODG) <ref> [ Kohavi, 1994a, Kohavi, 1994b ] </ref> , or an ordered binary decision diagram (OBDD) [ Bryant, 1992 ] .
Reference: [ Kohavi, 1994b ] <author> Ron Kohavi. </author> <title> Bottom-up induction of oblivious, read-once decision graphs : Strengths and limitations. </title> <booktitle> In Twelfth National Conference on Artificial Intelligence, </booktitle> <year> 1994. </year> <note> Paper available by anonymous ftp from Starry.Stanford.EDU:pub/ronnyk/aaai94.ps. </note>
Reference-contexts: The intermediate label is then mapped into the final label using a disjoint subset of attributes. By generalizing this two-step decomposition to m steps, where m is the number of attributes, one essentially builds an oblivious read-once decision graph (OODG) <ref> [ Kohavi, 1994a, Kohavi, 1994b ] </ref> , or an ordered binary decision diagram (OBDD) [ Bryant, 1992 ] . <p> The rough-sets view provides an interesting alternative view of the process being carried out by the HOODG algorithm <ref> [ Kohavi, 1994b ] </ref> . 2 The Two-Step Decomposition The two-step decomposition divides the attributes into two mutually exclusive and exhaustive sets, such that the first set is used to map to an intermediate label, and the second set is used to map to the goal label. <p> The multi-step decomposition illustrated here provides an interesting view of what algorithms for building OODGs and OBDDs are trying to approximate, namely, multiple precision rough sets using a smaller number of attributes at each level. For example, the HOODG algorithm <ref> [ Kohavi, 1994b ] </ref> chooses the attribute which would lead to the minimal number of intermediate label values at the next decomposition step. 5 Summary Attempts to construct decision tables or similar structures directly using reducts sometimes results in large incomprehensible structures.
Reference: [ Michalski, 1978 ] <author> Ryszard S. Michalski. </author> <title> A planar geometric model for representing multidimensional discrete spaces and multiple-valued logic functions. </title> <type> Technical Report UIUCDCS-R-78-897, </type> <institution> University of Illinois at Urbaba-Champaign, </institution> <year> 1978. </year>
Reference: [ Minato et al., 1990 ] <author> Shin-ichi Minato, Nagisa Ishiura, and Shuzo Yajima. </author> <title> Shared binary decision diagram with attributed edges for efficient boolean function manipulation. </title> <booktitle> In Proceedings of the 27th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 24-28, </pages> <year> 1990. </year>
Reference: [ Modrzejewski, 1993 ] <author> Maciej Modrzejewski. </author> <title> Feature selection using rough sets theory. </title> <editor> In Pavel B. Brazdil, editor, </editor> <booktitle> Proceedings of the European Conference on Machine Learning, </booktitle> <pages> pages 213-226, </pages> <year> 1993. </year>
Reference-contexts: In the machine learning community, Kohavi [ 1994a, 1994b ] investigated the possibility of using oblivious decision graphs as the underlying hypothesis space for supervised classification learning. Modrzejewski's work on feature selection <ref> [ Modrzejewski, 1993 ] </ref> uses oblivious trees (called "preset tree" by Modrzejewski) as the underlying hypothesis space. The induction algorithm chooses attributes for each level using their significance measure.
Reference: [ Pawlak, 1991 ] <author> Zdzislaw Pawlak. </author> <title> Rough Sets. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: 1 Introduction Rough-sets theory <ref> [ Pawlak, 1991, Slowinski, 1992 ] </ref> defines a relative reduct as a subset of attributes such that the indiscernibility relation formed using this subset has the same positive region as the original set of attributes with respect to the label, or decision attribute.
Reference: [ Slowinski, 1992 ] <author> Roman Slowinski. </author> <title> Intelligent decision support : handbook of applications and advances of the rough sets theory. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Rough-sets theory <ref> [ Pawlak, 1991, Slowinski, 1992 ] </ref> defines a relative reduct as a subset of attributes such that the indiscernibility relation formed using this subset has the same positive region as the original set of attributes with respect to the label, or decision attribute.
Reference: [ Thrun et al., 1991 ] <author> S.B. Thrun, J. Bala, E. Bloedorn, I. Bratko, B. Cestnik, J. Cheng, K. De Jong, S. Dzeroski, S.E. Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J. Kreuziger, R.S. Michalski, T. Mitchell, P. Pachowicz, Y. Reich, H. Vafaie, W. Van de Weldel, W. Wenzel, J. Wnek, and J. Zhang. </author> <title> The monk's problems: A performance comparison of different learning algorithms. </title> <type> Technical Report CMU-CS-91-197, </type> <institution> Carnegie Mellon University, </institution> <year> 1991. </year>
Reference: [ Wnek and Michalski, 1994 ] <author> Janusz Wnek and Ryszard S. Michalski. </author> <title> Hypothesis-driven constructive induction in AQ17-HCI : A method and experiments. </title> <journal> Machine Learning, </journal> <volume> 14(2) </volume> <pages> 139-168, </pages> <year> 1994. </year>
References-found: 15

