URL: http://www.neci.nj.nec.com/tr/neci-tr-95-9.ps
Refering-URL: http://www.neci.nj.nec.com/tr/index.html
Root-URL: 
Title: Feature-Based Face Recognition Using  
Author: Mixture-Distance Ingemar J. Cox Joumana Ghosn Peter N. Yianilos 
Keyword: Face Recognition, Mixture Models, Statistical Pattern Recognition, Improved Distance Metrics.  
Abstract: c flNEC Research Institute, Technical Report 95 09. Abstract We consider the problem of feature-based face recognition in the setting where only a single example of each face is available for training. The mixture-distance technique we introduce achieves a recognition rate of 95% on a database of 685 people in which each face is represented by 30 measured distances. This is currently the best recorded recognition rate for a feature-based system applied to a database of this size. By comparison, nearest neighbor search using Euclidean distance yields 84%. In our work a novel distance function is constructed based on local second order statistics as estimated by modeling the training data as a mixture of normal densities. We report on the results from mixtures of several sizes. We demonstrate that a flat mixture of mixtures performs as well as the best model and therefore represents an effective solution to the model selection problem. A mixture perspective is also taken for individual Gaussians to choose between first order (variance) and second order (covariance) models. Here an approximation to flat combination is proposed and seen to perform well in practice. Our results demonstrate that even in the absence of multiple training examples for each class, it is sometimes possible to infer from a statistical model of training data, a significantly improved distance function for use in pattern recognition. fl The first and third authors are with NEC Research Institute, 4 Independence Way, Princeton, NJ 08540. The second is with the University of Montreal, Department of Computer Science. Direct Email to the third author at pny@research.nj.nec.com. This manuscript was completed during October 1995. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. J. Baron. </author> <title> Mechanisms of human face recognition. </title> <journal> Int. J. of Man Machine Studies, </journal> <volume> 15 </volume> <pages> 137-178, </pages> <year> 1981. </year>
Reference-contexts: Of course, direct image methods may also extract features but the distinction is that such features change significantly with variations in illumination. By contrast, the feature based classification is intended to categorize techniques that are robust to illumination conditions. Direct methods included template matching <ref> [1] </ref> and the more recent work of Turk and Pentland [17] on "eigenfaces". Template matching is only effective when the query and model images have the same scale, orientation and illumination properties. This is a very restricted regime that is unlikely to be found in many operating environments. <p> Moreover, when forming Gaussian mixtures, the available data are essentially parceled out to mixture elements further exacerbating the problem. A mixture is just M = (1 f ) M 1 + f M 2 ; f 2 <ref> [0; 1] </ref>. Consider this mixture generatively where one first chooses M 1 with probability 1 f or M 2 with probability f , and then draws a sample at random according to the selected model.
Reference: [2] <author> R. Brunelli and T. Poggio. </author> <title> Face recognition: features versus templates. </title> <journal> IEEE Trans. on PAMI, </journal> <volume> 15(10) </volume> <pages> 1042-1052, </pages> <year> 1993. </year>
Reference-contexts: Template matching is only effective when the query and model images have the same scale, orientation and illumination properties. This is a very restricted regime that is unlikely to be found in many operating environments. Although recently Brunelli and Poggio <ref> [2] </ref> compared a template matching scheme similar to Baron's [1]with a feature-based method on a database of 47 individuals and found their template matching method to be superior, no generalization can be drawn from these results which are "clearly specific to our task and to our implementation".
Reference: [3] <author> I. J. Cox, D. W. Jacobs. S. Krishnamachari and P. N. Yianilos. </author> <title> Experiments on Feature-Based Face Recognition. </title> <institution> NEC Research Institute, </institution> <year> 1994. </year>
Reference-contexts: The authors acknowledge David W. Jacobs of NEC Research Institute, Sunita L. Hingorani of AT&T Bell Laboratories, and Santhana Krishnamachari of the University of Maryland for their participation in this project's predecessor <ref> [3] </ref> where portions of Sections 2 and 3 first appeared.
Reference: [4] <author> A. J. Goldstein, L. D. Harmon, and A. B. Lesk. </author> <title> Identification of human faces. </title> <journal> Proc. of the IEEE, </journal> <volume> 59(5) </volume> <pages> 748-760, </pages> <year> 1971. </year>
Reference-contexts: In principle, feature-based schemes can be made invariant to scale, rotation and/or illumination variations and it is for this reason that we are interested in them. Early work in this area was first reported by Goldstein et al <ref> [4] </ref> in which a "face-feature questionnaire" was manually completed for 3 each face in the database. Human subjects were then asked to identify faces in databases ranging in size from 64 to 255 using 22 features. Interestingly, only 50% accuracy was obtained.
Reference: [5] <author> L. D. Harmon, M. K. Khan, R. LAsch, and P. F. Ramig. </author> <title> Machine identification of human faces. </title> <journal> Pattern Recognition, </journal> <volume> 13 </volume> <pages> 97-110, </pages> <year> 1981. </year>
Reference-contexts: Perhaps because it was perceived as difficult to automatically extract 2-dimensional facial features, significant effort has been directed towards using face profiles <ref> [5, 6, 8] </ref>. In this case, the automatic extraction of features is a somewhat simpler one-dimensional problem. Kaufman and Breeding reported a recognition rate of 90% using facial profiles, but this was on a database of only 10 individuals. <p> Recognition rates of almost 100% are claimed using a classification scheme based on set partitioning and Euclidean distance. However, these experiments did not maintain disjoint training and test sets. Subsequent work by Harmon et al <ref> [5] </ref> did maintain a separate test set and reported recognition accuracies of 96% on a database of 112 individuals. Kaufman and Breeding [8] compared their results with human recognition of facial profiles and found that human performance was not significantly better.
Reference: [6] <author> L. D. Harmon, S. C. Kuo, P. F. Ramig, and U. Raudkivi. </author> <title> Identification of human face profiles by computer. </title> <journal> Pattern Recognition, </journal> <volume> 10 </volume> <pages> 301-312, </pages> <year> 1978. </year>
Reference-contexts: Perhaps because it was perceived as difficult to automatically extract 2-dimensional facial features, significant effort has been directed towards using face profiles <ref> [5, 6, 8] </ref>. In this case, the automatic extraction of features is a somewhat simpler one-dimensional problem. Kaufman and Breeding reported a recognition rate of 90% using facial profiles, but this was on a database of only 10 individuals.
Reference: [7] <author> T. Kanade. </author> <title> Picture processing System By Computer Complex and Recog--nition of Human Faces. </title> <type> PhD thesis, </type> <institution> Kyoto University, </institution> <year> 1973. </year>
Reference-contexts: Human subjects were then asked to identify faces in databases ranging in size from 64 to 255 using 22 features. Interestingly, only 50% accuracy was obtained. Subsequent work addressed the problem of automatically extracting facial features. Kanade <ref> [7, 9] </ref> described a system which automatically extracted a set of facial features, computed a 16-dimensional feature vector based on ratios of distances (and areas) between facial features, and compared two faces based on a sum of distances.
Reference: [8] <author> G. J. Kaufman and K. J. </author> <title> Breeding. Automatic recognition of human faces from profile silhouettes. </title> <journal> IEEE Trans. on Systems, Man and Cybernetics, </journal> <volume> SMC-6(2):113-121, </volume> <year> 1976. </year>
Reference-contexts: Perhaps because it was perceived as difficult to automatically extract 2-dimensional facial features, significant effort has been directed towards using face profiles <ref> [5, 6, 8] </ref>. In this case, the automatic extraction of features is a somewhat simpler one-dimensional problem. Kaufman and Breeding reported a recognition rate of 90% using facial profiles, but this was on a database of only 10 individuals. <p> However, these experiments did not maintain disjoint training and test sets. Subsequent work by Harmon et al [5] did maintain a separate test set and reported recognition accuracies of 96% on a database of 112 individuals. Kaufman and Breeding <ref> [8] </ref> compared their results with human recognition of facial profiles and found that human performance was not significantly better.
Reference: [9] <author> T. Kanade, </author> <title> Computer Recognition of Human Faces. </title> <publisher> Birkhauser Verlag, </publisher> <address> Stuttgart Germany, </address> <year> 1977. </year>
Reference-contexts: Human subjects were then asked to identify faces in databases ranging in size from 64 to 255 using 22 features. Interestingly, only 50% accuracy was obtained. Subsequent work addressed the problem of automatically extracting facial features. Kanade <ref> [7, 9] </ref> described a system which automatically extracted a set of facial features, computed a 16-dimensional feature vector based on ratios of distances (and areas) between facial features, and compared two faces based on a sum of distances.
Reference: [10] <author> Y. Moses, Y. Adini, and S. Ullman. </author> <title> Face recognition: the problem of compensating for changes in illumination direction. </title> <editor> In J.-O. Eklundh, editor, </editor> <booktitle> Third European Conf. on Computer Vision, </booktitle> <pages> pages 286-296, </pages> <year> 1994. </year>
Reference-contexts: However, all images in this test seem to be taken with little variation in viewpoint and lighting, although with significant variation in facial expression. Since the method is similar to, although more computa-tionally efficient than correlation based on pixel intensities, these results are consistent with Moses et al's <ref> [10] </ref> conclusions that correlation methods are relatively insensitive to variations in facial expression. Moses has found that correlation methods are much more sensitive to lighting and viewpoint variations, which raises questions about the potential of the eigenfaces approach to extend to these viewing conditions.
Reference: [11] <author> S. J. Nowlan. </author> <title> Soft Competitive Adaptation: Neural Network Learning Algorithms based on Fitting Statistical Mixtures. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> April </month> <year> 1991. </year>
Reference: [12] <author> A. Pentland, B. Moghaddam, and T. Starner. </author> <title> View-based and modular eigenspaces for face recognition. </title> <booktitle> In Computer Vision and Pattern Recognition, </booktitle> <pages> pages 84-91, </pages> <year> 1994. </year>
Reference-contexts: They then use principal component analysis to find the low-dimensional projection of this space that best represents the data. Using simple nearest neighbor classification in this space Pentland, Moghad-dam and Starner <ref> [12] </ref> report accuracy of 95% on a data base containing about 3000 different faces. However, all images in this test seem to be taken with little variation in viewpoint and lighting, although with significant variation in facial expression.
Reference: [13] <author> R. A. Redner and H. F. Walker. </author> <title> Mixture densities, maximum likelihood and the EM algorithm. </title> <journal> SIAM review, </journal> <volume> vol. 26, </volume> <pages> PP. 195-239, </pages> <year> 1984. </year>
Reference-contexts: Given a finite set of vectors x 1 ; : : : ; x m , the task of estimating the parameters of a normal mixture model which explains the data well, has been heavily studied. The well known expectation maximization method (EM) <ref> [13] </ref> is perhaps that best known approach and we adopt it for our experiments using k-means clustering to provide a starting point.
Reference: [14] <author> G. D. Riccia and A. Iserles. </author> <title> Automatic identification of pictures of human faces. </title> <booktitle> In 1977 Carnahan Conference on Crime Countermeasures, </booktitle> <pages> pages 145-148, </pages> <year> 1977. </year>
Reference: [15] <author> S. Sakamoto and J. Tajima. </author> <title> Face feature analysis for human identification. </title> <type> Technical report, </type> <institution> NEC Central Research Laboratory, </institution> <year> 1994. </year>
Reference: [16] <author> J. Shepherd and H. Ellis. </author> <title> Face recognition and recall using computer-interactive methods with eye witnesses. In Processing Images of Faces, </title> <editor> editor, V. Bruce and H. Burton, </editor> <publisher> Ablex Publishing, </publisher> <year> 1992. </year>
Reference: [17] <author> M. A. Turk and A. P. Pentland. </author> <title> Face recogntion using eigenfaces. </title> <booktitle> In IEEE Int. Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 586-591, </pages> <year> 1991. </year>
Reference-contexts: By contrast, the feature based classification is intended to categorize techniques that are robust to illumination conditions. Direct methods included template matching [1] and the more recent work of Turk and Pentland <ref> [17] </ref> on "eigenfaces". Template matching is only effective when the query and model images have the same scale, orientation and illumination properties. This is a very restricted regime that is unlikely to be found in many operating environments. <p> Turk and Pentland <ref> [17] </ref> have proposed a method of face recognition based on principal component analysis. Each image of a face maps to a single point in a very high-dimensional space in which each dimension represents the intensity of an image pixel.
Reference: [18] <author> S. White. </author> <title> Features in face recognition algorithms. Part of the Area Exam for Area II Course VI, </title> <publisher> MIT, </publisher> <month> February </month> <year> 1992. </year> <month> 19 </month>
Reference: [19] <author> J. Tojima and S. Sakamoto. </author> <title> Private Communication. </title> <year> 1994. </year>
Reference-contexts: We followed the point measurement system of <ref> [19] </ref> since the Japanese portion of our database consisted of measured feature values only, i.e. the original intensity images were unavailable. All distances are normalized by the inter-iris distance to provide similarity invariance.
Reference: [20] <author> L. Xu and M. I. Jordan. </author> <title> On convergence properties of the em algorithm for gaussian mixtures. </title> <type> Technical Report A.I. Memo No. 1520, </type> <institution> Massachusetts Institute of Technology, Artificial Intelligence Laboratory, </institution> <month> January </month> <year> 1995. </year>
Reference: [21] <author> P. N. Yianilos. </author> <title> Metric learning via normal mixtures. </title> <type> Technical report, </type> <institution> The NEC Research Institute, Princeton, </institution> <address> New Jersey, </address> <year> 1995. </year> <month> 20 </month>
Reference-contexts: Our method increases recognition performance to 95%, the highest recognition rate for a feature-based system applied to a database of this size. These functions are discussed later in Section 4 and explored in greater detail in <ref> [21] </ref>. The use of mixture-distances immediately presents two model selection problems: selection of the number of elements in the mixture, and the more basic but sometimes ignored problem of choosing between first and second order statistics for each component Gaussian. <p> Similarly the probability Pr (y i jp) that a particular database element y i was generated by p is O p (y i p). Finally the probability Pr (p) of p itself is just P (p). To judge how similar q and y i , the approach taken in <ref> [21] </ref> is to focus on the 7 probability of the 3-way joint event consisting of the generation of p, followed by its observation as q, followed by a second independent observation as y i . <p> In <ref> [21] </ref> various more complicated expressions are given corresponding to weaker or different assumptions.
References-found: 21

