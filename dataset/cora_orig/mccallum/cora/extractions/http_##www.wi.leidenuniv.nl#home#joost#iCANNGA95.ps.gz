URL: http://www.wi.leidenuniv.nl/home/joost/iCANNGA95.ps.gz
Refering-URL: http://www.wi.leidenuniv.nl/home/joost/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Parzen. On estimation of a probability density function and mode. Annual Mathematical Statistics, 33:1065-1076, 1962.
Author: [] J. Moody and C.J. Darken. [] H. Schioler and Uwe Hartman. [] M.T Musavi, W. Ahmed, K.H. Chan, K.B. Faris, and D.M. Hummels. [] P.D. Wasserman. [] H. Ritter, T. Martinetz, and Klaus Schulten. 
Note: 5 Classification 6 Conclusion References [1] E.  Advanced Methods in Neural Computing. Van Nostrand Reinhold, 1993. [6] B. Kosko. Neural Networks and Fuzzy Systems. Prentice-Hall International Editions, 1992. [7] T.  Addison Wesley, 1992. [9] D. DeSieno. Adding a conscience to competitative learning. In Proceedings of the International Joint Conference on Neural Networks, pages 117-124. IEEE, 1988.  
Abstract: To apply the algorithm for classification we assign each class a separate set of codebook Gaussians. Each set is only trained with patterns from a single class. After having trained the codebook Gaussians, each set provides an estimate of the probability function of one class; just as with Parzen window estimation, we take as the estimate of the pattern distribution the average of all Gaussians in the set. Classification of a pattern may now be done by calculating the probability of each class at the respective sample point, and assigning to the pattern the class with the highest probability. Hence the whole codebook plays a role in the classification of patterns. This is not the case with regular classification schemes using codebooks. We have tested the classification scheme on several classification tasks including the two spiral problem. We compared our algorithm to various other classification algorithms and it came out second; the best algorithm for the applications is the Parzen window estimation. However, the computing time and memory for Parzen window estimation are excessive when compared to our algorithm, and hence, in practical situations, our algorithm is to be preferred. We have developed a fast algorithm which combines attractive properties of both Parzen window estimation and vector quantization. The scale parameter is tuned adaptively and, therefore, is not set in an ad hoc manner. It allows a classification strategy in which all the codebook vectors are taken into account. This yields better results than the standard vector quantization techniques. An interesting topic for further research is to use radially non-symmetric Gaussians. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Parzen. </author> <title> On estimation of a probability density function and mode. </title> <journal> Annual Mathematical Statistics, </journal> <volume> 33 </volume> <pages> 1065-1076, </pages> <year> 1962. </year>
Reference: [2] <author> J. Moody and C.J. Darken. </author> <title> Fast learning in networks of locally-tuned processing units. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 281-294, </pages> <year> 1989. </year>
Reference: [3] <author> H. Schioler and Uwe Hartman. </author> <title> Mapping neural network derived from the Parzen window estimator. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 903-909, </pages> <year> 1992. </year>
Reference: [4] <author> M.T Musavi, W. Ahmed, K.H. Chan, </author> <title> K.B. Faris, and D.M. Hummels. On the trainig of radial basis function classifiers. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 595-603, </pages> <year> 1992. </year>
Reference: [5] <editor> P.D. Wasserman. </editor> <booktitle> Advanced Methods in Neural Computing. </booktitle> <publisher> Van Nostrand Reinhold, </publisher> <year> 1993. </year>
Reference: [6] <author> B. Kosko. </author> <title> Neural Networks and Fuzzy Systems. </title> <publisher> Prentice-Hall International Editions, </publisher> <year> 1992. </year>
Reference: [7] <author> T. Kohonen. </author> <title> Self-Organization and Associative Memory. </title> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference: [8] <author> H. Ritter, T. Martinetz, and Klaus Schulten. </author> <title> Neural Computation and Self-Organizing Maps. </title> <publisher> Addison Wesley, </publisher> <year> 1992. </year>

References-found: 8

