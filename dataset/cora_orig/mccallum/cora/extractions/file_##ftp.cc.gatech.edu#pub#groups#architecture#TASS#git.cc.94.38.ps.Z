URL: file://ftp.cc.gatech.edu/pub/groups/architecture/TASS/git.cc.94.38.ps.Z
Refering-URL: http://www.cs.gatech.edu/computing/Architecture/TASS/tass.html
Root-URL: 
Title: A Comparative Evaluation of Techniques for Studying Parallel System Performance  
Author: Anand Sivasubramaniam Umakishore Ramachandran H. Venkateswaran 
Keyword: Key Words: Parallel systems, performance metrics, performance evaluation, experimentation, theoretical/analytical models, simulation.  
Note: This work has been funded in part by NSF grants MIPS-9058430 and MIPS-9200005, and an equipment grant from DEC.  
Address: Atlanta, GA 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Pubnum: Technical Report GIT-CC-94/38  
Email: e-mail: rama@cc.gatech.edu  
Phone: Phone: (404) 894-5136 Fax: (404) 894-9442  
Date: September 1994  
Abstract: This paper presents a comparative and qualitative survey of techniques for evaluating parallel systems. We also survey metrics that have been proposed for capturing and quantifying the details of complex parallel system interactions. Experimentation, theoretical/analytical modeling and simulation are three frequently used techniques in performance evaluation. Experimentation uses real or synthetic workloads, usually called benchmarks, to measure and analyze their performance on actual hardware. Theoretical and analytical models are used to abstract details of a parallel system, providing the view of a simplified system parameterized by a limited number of degrees of freedom that are kept tractable. Simulation and related performance monitoring/visualization tools have become extremely popular because of their ability to capture the dynamic nature of the interaction between applications and architectures. We first present the figures of merit that are important for any performance evaluation technique. With respect to these figures of merit, we survey the three techniques and make a qualitative comparison of their pros and cons. In particular, for each of the above techniques we discuss: representative case studies; the underlying models that are used for the workload and the architecture; the feasibility and ease of quantifying standard performance metrics from the available statistics; the accuracy/validity of the output statistics; and the cost/effort that is expended in each evaluation strategy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal. </author> <title> Limits on Interconnection Network Performance. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 398-412, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The restriction to regular iterative and synchronous behavior of the application in these studies helps reduce the degrees of freedom in the parallel system for tractability. Analytical models have also helped study the performance and scalability of specific system artifacts such as interconnection network <ref> [18, 1] </ref>, caches [45, 44], scheduling [50] and synchronization [64]. 5.2 Input Model Several theoretical models have been proposed in literature to abstract parallel machine artifacts. The PRAM [26] has been an extremely popular vehicle for algorithm development. <p> Analytical models abstract both the hardware and application details of parallel systems. The behavior of the system artifacts being studied is captured by a few simple parameters. For instance, Agarwal <ref> [1] </ref> models the interconnection network by the network cycle time, the wire delay, the channel width, the dimensionality and radix of the network. Sometimes the hardware details are simplified in order to keep the model tractable. <p> Madala and Sinclair [37] confine their studies to synchronous parallel algorithms. The behavior of these simplified workloads is usually modeled by well-known probability distributions and specifiable parameters. The interconnection network model developed in <ref> [1] </ref> captures application behavior by the probability of message generation by a processor in any particular cycle, and a locality parameter for estimating the number of hops traversed by this message. <p> The two factors, cost and controlled execution, have made simulation popular for parallel system studies. It has been used to study the performance and scalability of specific system artifacts such as the interconnection network <ref> [1, 18] </ref>, caches [7] and scheduling [65]. Such studies simulate the details of the system artifacts being investigated, and evaluate their performance for a chosen workload. <p> From the application point of view, simulation studies may be broadly classified into synthetic workload-driven, abstraction-driven, trace-driven, and execution-driven that differ in the level of detail used to model the workload. Synthetic workload-driven simulations completely abstract application details by simple parameters and probability distributions. Simulation studies conducted in <ref> [1, 7, 65] </ref> to investigate the performance of interconnection networks, caches and scheduling strategies respectively, use such synthetic workloads. For instance, Agarwal [1] models application behavior by the probability of generating a message of a certain size in a particular cycle. <p> Synthetic workload-driven simulations completely abstract application details by simple parameters and probability distributions. Simulation studies conducted in [1, 7, 65] to investigate the performance of interconnection networks, caches and scheduling strategies respectively, use such synthetic workloads. For instance, Agarwal <ref> [1] </ref> models application behavior by the probability of generating a message of a certain size in a particular cycle. Simulation can also use real applications, and the way in which these applications are used results in the other three types of simulation.
Reference: [2] <author> A. Aggarwal, A. K. Chandra, and M. Snir. </author> <title> On Communication Latency in PRAM Computations. </title> <booktitle> In Proceedings of the First Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 11-21, </pages> <year> 1989. </year>
Reference-contexts: These models try to hide hardware details from the programmer, providing a simplified view of the machine. The utility of such models towards developing efficient algorithms for actual machines, depends on the closeness of the model to the actual machine. Several machine models <ref> [2, 3, 27, 14, 59, 17] </ref> have been proposed over the years to bridge the gap between the theoretical abstractions and the hardware. <p> Models that have been proposed as alternatives to the PRAM, try to accommodate limitations in the physical realization of communication and synchronization between the processors. Aggarwal et al. <ref> [2] </ref> propose a model called the BPRAM (Bulk Parallel Random Access Machine) that associates a latency overhead for accesses to shared memory. The 11 model incorporates a latency to access the first word from shared memory and a transfer rate to access subsequent words.
Reference: [3] <author> H. Alt, T. Hagerup, K. Mehlhorn, and F. P. Preparata. </author> <title> Deterministic Simulation of Idealized Parallel Computers on More Realistic Ones. </title> <journal> SIAM Journal of Computing, </journal> <volume> 16(5) </volume> <pages> 808-835, </pages> <year> 1987. </year>
Reference-contexts: These models try to hide hardware details from the programmer, providing a simplified view of the machine. The utility of such models towards developing efficient algorithms for actual machines, depends on the closeness of the model to the actual machine. Several machine models <ref> [2, 3, 27, 14, 59, 17] </ref> have been proposed over the years to bridge the gap between the theoretical abstractions and the hardware. <p> The 11 model incorporates a latency to access the first word from shared memory and a transfer rate to access subsequent words. Mehlhorn et al. <ref> [3] </ref> use a model called the Module Parallel Computer (MPC) which incorporates contention for simultaneous accesses by different processors to the same memory module. The implicit synchronization assumption in PRAMs is removed in [27] and [14].
Reference: [4] <author> G. M. </author> <title> Amdahl. Validity of the Single Processor Approach to achieving Large Scale Computing Capabilities. </title> <booktitle> In Proceedings of the AFIPS Spring Joint Computer Conference, </booktitle> <pages> pages 483-485, </pages> <month> April </month> <year> 1967. </year>
Reference-contexts: Speedup captures only the constant problem size scaling strategy. It is well known that for a problem with a fixed size, the maximum possible speedup with increasing number of processors is limited by the serial fraction in the application <ref> [4] </ref>. But very often, parallel computers are used for solving larger problems and in many of these cases the sequential portion of the application may not increase appreciably regardless of the problem size [30] yielding a lower serial fraction for larger problems.
Reference: [5] <author> T. E. Anderson. </author> <title> The Performance of Spin Lock Alternatives for Shared-Memory Multiprocessors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(1) </volume> <pages> 6-16, </pages> <month> January </month> <year> 1990. </year> <month> 20 </month>
Reference-contexts: The scalability of hardware and software synchronization primitives on the Sequent Symmetry and BBN Butterfly hardware platforms is investigated in [41] and <ref> [5] </ref>. In these studies, each processor is subjected to a large number of synchronization operations to calculate the average overhead for a single operation.
Reference: [6] <author> T. E. Anderson and E. D. Lazowska. Quartz: </author> <title> A Tool for Tuning Parallel Program Performance. </title> <booktitle> In Proceedings of the ACM SIGMETRICS 1990 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 115-125, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: such cases are expected to be rare given that parallel machine abstractions are rapidly converging from the user's viewpoint. 4.4 Tools Tools which use experimentation for performance debugging of parallel programs rely on the above-mentioned instrumentation and hardware monitoring techniques for giving additional information about parallel system execution. 9 Quartz <ref> [6] </ref> uses instrumentation to give a profile of the time spent in different sections of the parallel program similar to the Unix utility called `gprof' which is frequently used in performance debugging of sequential programs.
Reference: [7] <author> J. Archibald and J-L. Baer. </author> <title> Cache Coherence Protocols : Evaluation Using a Multiprocessor Simulation Model. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 4(4) </volume> <pages> 273-298, </pages> <month> November </month> <year> 1986. </year>
Reference-contexts: The two factors, cost and controlled execution, have made simulation popular for parallel system studies. It has been used to study the performance and scalability of specific system artifacts such as the interconnection network [1, 18], caches <ref> [7] </ref> and scheduling [65]. Such studies simulate the details of the system artifacts being investigated, and evaluate their performance for a chosen workload. For instance, Archibald and Baer [7] use a workload which models the data sharing pattern between processors in an application, and simulate its execution over a range of <p> It has been used to study the performance and scalability of specific system artifacts such as the interconnection network [1, 18], caches <ref> [7] </ref> and scheduling [65]. Such studies simulate the details of the system artifacts being investigated, and evaluate their performance for a chosen workload. For instance, Archibald and Baer [7] use a workload which models the data sharing pattern between processors in an application, and simulate its execution over a range of hardware cache coherence schemes. Simulation has also been used to study the behavior of parallel systems as a whole [56, 48, 40, 53]. <p> From the application point of view, simulation studies may be broadly classified into synthetic workload-driven, abstraction-driven, trace-driven, and execution-driven that differ in the level of detail used to model the workload. Synthetic workload-driven simulations completely abstract application details by simple parameters and probability distributions. Simulation studies conducted in <ref> [1, 7, 65] </ref> to investigate the performance of interconnection networks, caches and scheduling strategies respectively, use such synthetic workloads. For instance, Agarwal [1] models application behavior by the probability of generating a message of a certain size in a particular cycle.
Reference: [8] <author> D. Atapattu and D. Gannon. </author> <title> Building analytical models into an interactive performance prediction tool. </title> <booktitle> In Proceedings of Supercomputing '89, </booktitle> <pages> pages 521-530, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: ES uses heuristics to maintain the tree size at an acceptable level, allowing a trade-off between accuracy and efficiency. While PAMELA and ES rely on a static specification of the application model by the user, <ref> [8] </ref> and [25] use the actual application code to derive the models. A static performance evaluation of application code segments is conducted in [8]. Such a static evaluation ignores data dependent and non-deterministic executions and its applicability is thus restricted. <p> While PAMELA and ES rely on a static specification of the application model by the user, <ref> [8] </ref> and [25] use the actual application code to derive the models. A static performance evaluation of application code segments is conducted in [8]. Such a static evaluation ignores data dependent and non-deterministic executions and its applicability is thus restricted. PPPT [25] uses an earlier profiling run of the program to overcome some of these drawbacks. During the profiling run, it collects some information about the program execution.
Reference: [9] <author> D. Bailey et al. </author> <title> The NAS Parallel Benchmarks. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 5(3) </volume> <pages> 63-73, </pages> <year> 1991. </year>
Reference-contexts: For instance, several studies [22, 11, 47, 49] experiment with the KSR-1 hardware for evaluating its computation, communication and scalability properties. The scalability of the KSR-1 is studied in [47] using applications drawn from the NAS benchmark suite <ref> [9] </ref>. Similarly, an experimental evaluation of the computation and communication capabilities of the CM-5 is conducted in [46]. Lenoski et al. [36] evaluate the scalability of the Stanford DASH multiprocessor prototype using a set of applications. <p> Since applications set the standards for computing, it is appropriate to use real-world applications for the performance evaluation of parallel machines, adhering to the RISC ideology in the evolution of sequential architectures. Application suites such as the Perfect Club [10], the NAS Parallel Benchmarks <ref> [9] </ref>, and the SPLASH application suite [54] have been proposed for the evaluation of parallel machines. However, applications normally tend to contain large volumes of code that are not easily portable, and a level of detail that is not very familiar to someone outside that application domain.
Reference: [10] <author> M. Berry et al. </author> <title> The Perfect Club Benchmarks: Effective Performance Evaluation of Supercomputers. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <year> 1989. </year>
Reference-contexts: Since applications set the standards for computing, it is appropriate to use real-world applications for the performance evaluation of parallel machines, adhering to the RISC ideology in the evolution of sequential architectures. Application suites such as the Perfect Club <ref> [10] </ref>, the NAS Parallel Benchmarks [9], and the SPLASH application suite [54] have been proposed for the evaluation of parallel machines.
Reference: [11] <author> E. L. Boyd, J-D. Wellman, S. G. Abraham, and E. S. Davidson. </author> <title> Evaluating the communication performance of MPPs using synthetic sparse matrix multiplication workloads. </title> <booktitle> In Proceedings of the ACM 1993 International Conference on Supercomputing, </booktitle> <pages> pages 240-250, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: For instance, several studies <ref> [22, 11, 47, 49] </ref> experiment with the KSR-1 hardware for evaluating its computation, communication and scalability properties. The scalability of the KSR-1 is studied in [47] using applications drawn from the NAS benchmark suite [9]. <p> Experimentation has also been used to study the performance and scalability of specific system artifacts such as locality, synchronization, and interconnection network. The interconnection network and locality properties of the KSR-1 are studied in <ref> [22, 11, 49] </ref>. Lenoski et al. [36] study the performance and scalability of the cache, synchronization primitives and the interconnection network of DASH. <p> The workload used in [46] evaluates the performance of the CM-5 network by inducing messages to traverse different levels of the fat-tree network under a variety of traffic conditions. Synthetic benchmarks that mimic the behavior of some applications have also been used for evaluating systems. Boyd et al. <ref> [11] </ref> propose a synthetic benchmark using sparse matrices that is expected to model the behavior of typical sparse matrix computations. Synthetic benchmarks called micro-kernels are used in [49] to evaluate the KSR-1. Varying parameters in these synthetic benchmarks is expected to capture typical workloads of real applications.
Reference: [12] <author> E. A. Brewer, C. N. Dellarocas, A. Colbrook, and W. E. Weihl. </author> <title> PROTEUS : A high-performance parallel-architecture simulator. </title> <type> Technical Report MIT-LCS-TR-516, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, MA 02139, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: Simulation has also been used to study the behavior of parallel systems as a whole [56, 48, 40, 53]. General purpose simulators such as SPASM [56, 57], PROTEUS <ref> [12] </ref>, the Rice Parallel Processing Testbed [15], the Wisconsin Wind Tunnel [48], and Tango [19], which can model a range of application and hardware platforms have been developed for studying parallel systems. <p> Execution-driven simulation that simulates the execution of the entire application on the hardware is becoming increasingly popular because of its accuracy in capturing the dynamics of parallel system interactions. Many general purpose simulators <ref> [56, 12, 15, 48, 19, 61] </ref> are based on this paradigm. Execution-driven simulation also provides the flexibility of abstracting out phases of the application that may not significantly impact the system artifacts being studied, in order to speed up the simulation. <p> Hardware simulation can be as detailed as a cycle level or a logic level simulation which simulates every electronic component. Machine details may also be abstracted out depending on the level of detail and accuracy desired by the user. Many simulators <ref> [56, 12, 15, 48, 19, 61] </ref> do not simulate the details of instruction execution by a processor since simulating each instruction is not likely to significantly impact the understanding of parallel system behavior. <p> The Wisconsin Wind Tunnel [48] which simulates shared memory platforms relies on the ECC (error correcting code) bits of the native hardware to trap to the simulator on accesses to shared memory by a processor. SPASM [56], PROTEUS <ref> [12] </ref>, the Rice Parallel Processing Testbed [15], and Tango [19] use application source code augmentation to trap to the simulator for the instructions to be simulated. <p> Similarly, [20] uses application knowledge to abstract out phases of numerical calculations to derive computation and communication profiles in approximating the simulation of parallel algorithms. From the hardware point of view, most general purpose simulators <ref> [56, 12, 15, 19, 48] </ref> do not simulate the parallel machine at the instruction-set level as we discussed earlier. Similarly, different levels of abstractions for other hardware artifacts like the interconnection network and caches may be studied to improve simulation speed. <p> A significant change in the machine or application details would also demand a re-implementation of the simulation model, but the cost of re-simulation is again expected to dominate over the cost of re-implementation. 17 6.4 Tools Several general purpose execution-driven simulators <ref> [56, 12, 15, 19, 48, 61, 63] </ref> have been built for simulation study of parallel systems. Such simulation platforms can serve as testbeds for implementing and studying a wide range of hardware and application platforms.
Reference: [13] <author> H. Burkhart and R. Millen. </author> <title> Performance measurement tools in a multiprocessor environment. </title> <journal> IEEE Transactions on Computer Systems, </journal> <volume> 38(5) </volume> <pages> 725-737, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: It can also help in choosing between alternate application implementations, selecting the best hardware platform, and the different other uses of a performance analysis study outlined earlier in section 1. Recognizing this importance, studies <ref> [57, 56, 16, 13] </ref> have attempted to separate and quantify parallel system overheads. 3 Ignoring effects of superlinearity, one would expect a speedup that increases linearly with the number of processors, as shown by the curve named linear in Figure 1. <p> Instrumentation can help in identifying and quantifying algorithmic overheads, but it is difficult to quantify the hardware interaction overheads using this technique alone. Hardware monitoring can supplement instrumentation to remedy this problem. Burkhart and Millen <ref> [13] </ref> identify a set of hardware and system software monitoring tools that help them quantify several sources of parallel system overheads on the M 3 multiprocessor system. Software agents called the `trap monitor' and the `mailbox monitor' are used to quantify algorithmic and synchronization overheads.
Reference: [14] <author> R. Cole and O. Zajicek. </author> <title> The APRAM: Incorporating Asynchrony into the PRAM Model. </title> <booktitle> In Proceedings of the First Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 169-178, </pages> <year> 1989. </year>
Reference-contexts: These models try to hide hardware details from the programmer, providing a simplified view of the machine. The utility of such models towards developing efficient algorithms for actual machines, depends on the closeness of the model to the actual machine. Several machine models <ref> [2, 3, 27, 14, 59, 17] </ref> have been proposed over the years to bridge the gap between the theoretical abstractions and the hardware. <p> Mehlhorn et al. [3] use a model called the Module Parallel Computer (MPC) which incorporates contention for simultaneous accesses by different processors to the same memory module. The implicit synchronization assumption in PRAMs is removed in [27] and <ref> [14] </ref>. In their models, the processors execute asynchronously, with explicit synchronization steps to enforce synchrony when needed.
Reference: [15] <author> R. G. Covington, S. Madala, V. Mehta, J. R. Jump, and J. B. Sinclair. </author> <title> The Rice parallel processing testbed. </title> <booktitle> In Proceedings of the ACM SIGMETRICS 1988 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 4-11, </pages> <address> Santa Fe, NM, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: Simulation has also been used to study the behavior of parallel systems as a whole [56, 48, 40, 53]. General purpose simulators such as SPASM [56, 57], PROTEUS [12], the Rice Parallel Processing Testbed <ref> [15] </ref>, the Wisconsin Wind Tunnel [48], and Tango [19], which can model a range of application and hardware platforms have been developed for studying parallel systems. <p> Execution-driven simulation that simulates the execution of the entire application on the hardware is becoming increasingly popular because of its accuracy in capturing the dynamics of parallel system interactions. Many general purpose simulators <ref> [56, 12, 15, 48, 19, 61] </ref> are based on this paradigm. Execution-driven simulation also provides the flexibility of abstracting out phases of the application that may not significantly impact the system artifacts being studied, in order to speed up the simulation. <p> Hardware simulation can be as detailed as a cycle level or a logic level simulation which simulates every electronic component. Machine details may also be abstracted out depending on the level of detail and accuracy desired by the user. Many simulators <ref> [56, 12, 15, 48, 19, 61] </ref> do not simulate the details of instruction execution by a processor since simulating each instruction is not likely to significantly impact the understanding of parallel system behavior. <p> The Wisconsin Wind Tunnel [48] which simulates shared memory platforms relies on the ECC (error correcting code) bits of the native hardware to trap to the simulator on accesses to shared memory by a processor. SPASM [56], PROTEUS [12], the Rice Parallel Processing Testbed <ref> [15] </ref>, and Tango [19] use application source code augmentation to trap to the simulator for the instructions to be simulated. <p> Similarly, [20] uses application knowledge to abstract out phases of numerical calculations to derive computation and communication profiles in approximating the simulation of parallel algorithms. From the hardware point of view, most general purpose simulators <ref> [56, 12, 15, 19, 48] </ref> do not simulate the parallel machine at the instruction-set level as we discussed earlier. Similarly, different levels of abstractions for other hardware artifacts like the interconnection network and caches may be studied to improve simulation speed. <p> A significant change in the machine or application details would also demand a re-implementation of the simulation model, but the cost of re-simulation is again expected to dominate over the cost of re-implementation. 17 6.4 Tools Several general purpose execution-driven simulators <ref> [56, 12, 15, 19, 48, 61, 63] </ref> have been built for simulation study of parallel systems. Such simulation platforms can serve as testbeds for implementing and studying a wide range of hardware and application platforms.
Reference: [16] <author> M. E. Crovella and T. J. LeBlanc. </author> <title> Parallel Performance Prediction Using Lost Cycles Analysis. </title> <booktitle> In Proceedings of Supercomputing '94, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: It can also help in choosing between alternate application implementations, selecting the best hardware platform, and the different other uses of a performance analysis study outlined earlier in section 1. Recognizing this importance, studies <ref> [57, 56, 16, 13] </ref> have attempted to separate and quantify parallel system overheads. 3 Ignoring effects of superlinearity, one would expect a speedup that increases linearly with the number of processors, as shown by the curve named linear in Figure 1. <p> To fully understand the scalability of the parallel system, it is important to isolate and quantify the impact of different parallel system overheads on the overall execution as shown in Figure 1. Overhead functions [56, 57] and lost cycles <ref> [16] </ref> are metrics that have been proposed to capture the growth of overheads in a parallel system. Both these metrics quantify the contribution of each overhead towards the overall execution time. The studies differ in the techniques used to quantify these metrics. Experimentation is used in [16] to quantify lost cycles, <p> 57] and lost cycles <ref> [16] </ref> are metrics that have been proposed to capture the growth of overheads in a parallel system. Both these metrics quantify the contribution of each overhead towards the overall execution time. The studies differ in the techniques used to quantify these metrics. Experimentation is used in [16] to quantify lost cycles, while simulation is used in [56, 57] to quantify overhead functions. <p> Instrumentation augments the application code or the system software to accumulate statistics about the program execution. This augmentation may be performed either by the application programmer by hand, or may be relegated to a pre-processor or even the compiler. Crovella and LeBlanc <ref> [16] </ref> identify such a tool called predicate profiler, which uses a run-time library to log events from the application code to find algorithmic overheads such as serial part and work-imbalance. A detailed analysis of the execution time would require a considerable amount of instrumentation of the application code. <p> Hardware monitoring tries to remedy the latter deficiency by using hardware support to accumulate these statistics. The hardware facilities on the KSR-1 for monitoring network traffic and cache actions are used in <ref> [16] </ref> to calculate hardware interaction overheads such as network latency and contention. But the hardware monitoring technique relies on support from the underlying hardware for accumulating statistics and such facilities may not be available uniformly across all hardware platforms. <p> Also, some machines provide flexibility in hardware capabilities, like the ability to vary the cache coherence protocol on the FLASH [35] multiprocessor. For such parameters, one may be able to vary the hardware capabilities and develop analytical or regression models for predicting their impact on performance. Crovella and LeBlanc <ref> [16] </ref> use such an approach to develop analytical models parameterized by the problem size and the number of processors for the lost cycles of FFT on the KSR-1. <p> Software agents called the `trap monitor' and the `mailbox monitor' are used to quantify algorithmic and synchronization overheads. The `bus count monitor', a hardware agent, is used to analyze overheads due to the network. Crovella and LeBlanc <ref> [16] </ref> use a Lost Cycle Analyzer (LCA) to quantify parallel system overheads on the KSR-1. LCA uses instrumentation to track performance loss resulting from algorithmic factors such as work-imbalance and serial parts in the program. Appropriate calls to library functions are inserted in the application code to accumulate these statistics.
Reference: [17] <author> D. Culler et al. </author> <title> LogP : Towards a realistic model of parallel computation. </title> <booktitle> In Proceedings of the 4th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 1-12, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: These models try to hide hardware details from the programmer, providing a simplified view of the machine. The utility of such models towards developing efficient algorithms for actual machines, depends on the closeness of the model to the actual machine. Several machine models <ref> [2, 3, 27, 14, 59, 17] </ref> have been proposed over the years to bridge the gap between the theoretical abstractions and the hardware. <p> By restricting the number of messages exchanged in a superstep, a processor may not exceed the bandwidth of the network allocated to it, thus ensuring that the messages do not encounter any contention in the network. Culler et al. <ref> [17] </ref> propose a more realistic model called LogP that is parameterized by: the latency L which is the maximum time spent in the network by a message from a source to any destination; the overhead o incurred by a processor in the transmission/reception of a message; the communication gap g between
Reference: [18] <author> W. J. Dally. </author> <title> Performance analysis of k-ary n-cube interconnection networks. </title> <journal> IEEE Transactions on Computer Systems, </journal> <volume> 39(6) </volume> <pages> 775-785, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: The restriction to regular iterative and synchronous behavior of the application in these studies helps reduce the degrees of freedom in the parallel system for tractability. Analytical models have also helped study the performance and scalability of specific system artifacts such as interconnection network <ref> [18, 1] </ref>, caches [45, 44], scheduling [50] and synchronization [64]. 5.2 Input Model Several theoretical models have been proposed in literature to abstract parallel machine artifacts. The PRAM [26] has been an extremely popular vehicle for algorithm development. <p> The two factors, cost and controlled execution, have made simulation popular for parallel system studies. It has been used to study the performance and scalability of specific system artifacts such as the interconnection network <ref> [1, 18] </ref>, caches [7] and scheduling [65]. Such studies simulate the details of the system artifacts being investigated, and evaluate their performance for a chosen workload.
Reference: [19] <author> H. Davis, S. R. Goldschmidt, and J. L. Hennessy. </author> <title> Multiprocessor Simulation and Tracing Using Tango. </title> <booktitle> In Proceedings of the 1991 International Conference on Parallel Processing, </booktitle> <pages> pages II 99-107, </pages> <year> 1991. </year>
Reference-contexts: Simulation has also been used to study the behavior of parallel systems as a whole [56, 48, 40, 53]. General purpose simulators such as SPASM [56, 57], PROTEUS [12], the Rice Parallel Processing Testbed [15], the Wisconsin Wind Tunnel [48], and Tango <ref> [19] </ref>, which can model a range of application and hardware platforms have been developed for studying parallel systems. Simulation is also often used to validate and refine analytical models. 6.2 Input Model Simulation provides flexibility for choosing the level of detail in the application and hardware models. <p> Execution-driven simulation that simulates the execution of the entire application on the hardware is becoming increasingly popular because of its accuracy in capturing the dynamics of parallel system interactions. Many general purpose simulators <ref> [56, 12, 15, 48, 19, 61] </ref> are based on this paradigm. Execution-driven simulation also provides the flexibility of abstracting out phases of the application that may not significantly impact the system artifacts being studied, in order to speed up the simulation. <p> Hardware simulation can be as detailed as a cycle level or a logic level simulation which simulates every electronic component. Machine details may also be abstracted out depending on the level of detail and accuracy desired by the user. Many simulators <ref> [56, 12, 15, 48, 19, 61] </ref> do not simulate the details of instruction execution by a processor since simulating each instruction is not likely to significantly impact the understanding of parallel system behavior. <p> The Wisconsin Wind Tunnel [48] which simulates shared memory platforms relies on the ECC (error correcting code) bits of the native hardware to trap to the simulator on accesses to shared memory by a processor. SPASM [56], PROTEUS [12], the Rice Parallel Processing Testbed [15], and Tango <ref> [19] </ref> use application source code augmentation to trap to the simulator for the instructions to be simulated. MINT [61] interprets the binary object code to determine which instructions need to be simulated and thus does not need the standard application code to be recompiled with the special augmenting instructions. <p> Similarly, [20] uses application knowledge to abstract out phases of numerical calculations to derive computation and communication profiles in approximating the simulation of parallel algorithms. From the hardware point of view, most general purpose simulators <ref> [56, 12, 15, 19, 48] </ref> do not simulate the parallel machine at the instruction-set level as we discussed earlier. Similarly, different levels of abstractions for other hardware artifacts like the interconnection network and caches may be studied to improve simulation speed. <p> A significant change in the machine or application details would also demand a re-implementation of the simulation model, but the cost of re-simulation is again expected to dominate over the cost of re-implementation. 17 6.4 Tools Several general purpose execution-driven simulators <ref> [56, 12, 15, 19, 48, 61, 63] </ref> have been built for simulation study of parallel systems. Such simulation platforms can serve as testbeds for implementing and studying a wide range of hardware and application platforms.
Reference: [20] <author> M. D. Dikaiakos, A. Rogers, and K. Steiglitz. </author> <title> FAST: A Functional Algorithm Simulation Testbed. </title> <booktitle> In Proceedings of MASCOTS '94, </booktitle> <pages> pages 142-146, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: For instance, [53] uses a higher level simulation model for Cholesky Factorization that simulates block modifications rather than machine instructions. Mehra et al. [40] attempt to abstract phases of message-passing applications by analytical models gleaned from application knowledge or from earlier simulations. Similarly, <ref> [20] </ref> uses application knowledge to abstract out phases of numerical calculations to derive computation and communication profiles in approximating the simulation of parallel algorithms.
Reference: [21] <author> J. Dongarra, O. Brewer, J. A. Kohl, and S. Fineberg. </author> <title> A tool to aid in the design, implementation, and understanding of matrix algorithms for parallel processors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 9 </volume> <pages> 185-202, </pages> <year> 1990. </year>
Reference-contexts: The above tools are general purpose since they may be used to study any application on the given hardware platform. Tools that are tailored to specific application domains have also been developed. For instance, SHMAP <ref> [21] </ref> has been developed to aid in the design and understanding of matrix problems. Like IPS-2, it generates traces from instrumented FORTRAN programs which are subsequently animated.
Reference: [22] <author> T. H. Dunigan. </author> <title> Kendall Square Multiprocessor : Early Experiences and Performance. </title> <type> Technical Report ORNL/TM-12065, </type> <institution> Oak Ridge National Laboratory, Oak Ridge, TN, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: For instance, several studies <ref> [22, 11, 47, 49] </ref> experiment with the KSR-1 hardware for evaluating its computation, communication and scalability properties. The scalability of the KSR-1 is studied in [47] using applications drawn from the NAS benchmark suite [9]. <p> Experimentation has also been used to study the performance and scalability of specific system artifacts such as locality, synchronization, and interconnection network. The interconnection network and locality properties of the KSR-1 are studied in <ref> [22, 11, 49] </ref>. Lenoski et al. [36] study the performance and scalability of the cache, synchronization primitives and the interconnection network of DASH. <p> On the other hand, the workload model (often called benchmarks) used in evaluations can span a diverse spectrum of realism. The simplest benchmarks exercise and measure the performance of low-level hardware features. Workloads used in <ref> [22] </ref> and [46] which evaluate the low-level communication performance of the KSR-1 and CM-5 respectively, are examples of such benchmarks. The workload used in [46] evaluates the performance of the CM-5 network by inducing messages to traverse different levels of the fat-tree network under a variety of traffic conditions.
Reference: [23] <author> S. J. Eggers and R. H. Katz. </author> <title> The Effect of Sharing on the Cache and Bus Performance of Parallel Programs. </title> <booktitle> In Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 257-270, </pages> <address> Boston, Massachusetts, </address> <month> April </month> <year> 1989. </year>
Reference-contexts: Trace-driven simulations use an input trace of events that is drawn from an earlier execution of the application either on the actual hardware or on another simulated hardware. Traces of applications obtained from a Sequent Balance are used by <ref> [23] </ref> in a simulation platform to study the impact of sharing on the cache and bus performance.
Reference: [24] <author> S. J. Eggers, D. R. Keppel, E. J. Koldinger, and H. M. Levy. </author> <title> Techniques for efficient inline tracing on a shared memory multiprocessor. </title> <booktitle> In Proceedings of the ACM SIGMETRICS 1990 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 37-47, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: The trace may not even be accurate for the system on which it was generated, since the action of collecting traces may perturb the true execution of events <ref> [24] </ref>. Execution-driven simulation that simulates the execution of the entire application on the hardware is becoming increasingly popular because of its accuracy in capturing the dynamics of parallel system interactions. Many general purpose simulators [56, 12, 15, 48, 19, 61] are based on this paradigm.
Reference: [25] <author> T. Fahringer and H. P. Zima. </author> <title> A Static Parameter based Performance Prediction Tool for Parallel Programs. </title> <booktitle> In Proceedings of the ACM 1993 International Conference on Supercomputing, </booktitle> <pages> pages 207-217, </pages> <month> July </month> <year> 1993. </year> <month> 21 </month>
Reference-contexts: ES uses heuristics to maintain the tree size at an acceptable level, allowing a trade-off between accuracy and efficiency. While PAMELA and ES rely on a static specification of the application model by the user, [8] and <ref> [25] </ref> use the actual application code to derive the models. A static performance evaluation of application code segments is conducted in [8]. Such a static evaluation ignores data dependent and non-deterministic executions and its applicability is thus restricted. PPPT [25] uses an earlier profiling run of the program to overcome some <p> static specification of the application model by the user, [8] and <ref> [25] </ref> use the actual application code to derive the models. A static performance evaluation of application code segments is conducted in [8]. Such a static evaluation ignores data dependent and non-deterministic executions and its applicability is thus restricted. PPPT [25] uses an earlier profiling run of the program to overcome some of these drawbacks. During the profiling run, it collects some information about the program execution.
Reference: [26] <author> S. Fortune and J. Wyllie. </author> <title> Parallelism in random access machines. </title> <booktitle> In Proceedings of the 10th Annual Symposium on Theory of Computing, </booktitle> <pages> pages 114-118, </pages> <year> 1978. </year>
Reference-contexts: Nussbaum and Agarwal [43] quantify scalability as a ratio of the application's asymptotic speedup when run on the actual architecture to its corresponding asymptotic speedup when run on an EREW PRAM <ref> [26] </ref>, for a given problem size. Application scalability is a measure of the inherent parallelism in the application and is expressed by its speedup on an architecture with an idealized communication structure such as a PRAM. Architectural scalability is defined as the relative performance between the ideal and real architectures. <p> Each evaluation technique uses an input model for abstracting the application and hardware characteristics in the parallel system being evaluated. For instance, the abstraction for the machine can vary from the actual hardware as is the case with experimentation, to a completely abstract model such as the PRAM <ref> [26] </ref>. Similarly, the application model can range from a completely synthetic workload to a full-fledged application. We present models used in the evaluation techniques and discuss the realism in these models in capturing the behavior of actual parallel systems. <p> Analytical and theoretical models try to abstract details of a system, in order to limit these degrees of freedom to a tractable level. Such abstractions have been used for developing parallel algorithms and for performance analysis of parallel systems. Abstracting machine features by theoretical models like the PRAM <ref> [26] </ref> has facilitated algorithm development and analysis. These models try to hide hardware details from the programmer, providing a simplified view of the machine. The utility of such models towards developing efficient algorithms for actual machines, depends on the closeness of the model to the actual machine. <p> Analytical models have also helped study the performance and scalability of specific system artifacts such as interconnection network [18, 1], caches [45, 44], scheduling [50] and synchronization [64]. 5.2 Input Model Several theoretical models have been proposed in literature to abstract parallel machine artifacts. The PRAM <ref> [26] </ref> has been an extremely popular vehicle for algorithm development. A PRAM consists of a set of identical sequential processors, all of which operate synchronously and can each access a globally shared memory at unit cost.
Reference: [27] <author> P. B. Gibbons. </author> <title> A More Practical PRAM Model. </title> <booktitle> In Proceedings of the First Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 158-168, </pages> <year> 1989. </year>
Reference-contexts: These models try to hide hardware details from the programmer, providing a simplified view of the machine. The utility of such models towards developing efficient algorithms for actual machines, depends on the closeness of the model to the actual machine. Several machine models <ref> [2, 3, 27, 14, 59, 17] </ref> have been proposed over the years to bridge the gap between the theoretical abstractions and the hardware. <p> Mehlhorn et al. [3] use a model called the Module Parallel Computer (MPC) which incorporates contention for simultaneous accesses by different processors to the same memory module. The implicit synchronization assumption in PRAMs is removed in <ref> [27] </ref> and [14]. In their models, the processors execute asynchronously, with explicit synchronization steps to enforce synchrony when needed.
Reference: [28] <author> A. J. Goldberg and J. L. Hennessy. </author> <title> Mtool: An Integrated System for Performance Debugging Shared Memory Multiprocessor Applications. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4 </volume> <pages> 28-40, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Such a tool can help in identifying bottlenecks in sections of code, but it is difficult to understand the reason for such bottlenecks without the separation of the different parallel system overheads. Mtool <ref> [28] </ref> is another utility which uses instrumentation to give additional information about the execution. In the first step, Mtool instruments the basic blocks in the program and creates a performance profile. From this profile, it identifies important regions in the code to instrument further with performance probes.
Reference: [29] <author> S. R. Goldschmidt and J. L. Hennessy. </author> <title> The accuracy of trace-driven simulations of multiprocessors. </title> <booktitle> In Proceedings of the ACM SIGMETRICS 1993 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 146-157, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Since the traces are generated on an alternate hardware platform (either real or simulated), the events in the trace may not represent the actual set of events or their order in which they occur in an execution of the application on the platform being studied yielding inaccurate results <ref> [29] </ref>. The trace may not even be accurate for the system on which it was generated, since the action of collecting traces may perturb the true execution of events [24].
Reference: [30] <author> J. L. Gustafson, G. R. Montry, and R. E. Benner. </author> <title> Development of Parallel Methods for a 1024-node Hypercube. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 9(4) </volume> <pages> 609-638, </pages> <year> 1988. </year>
Reference-contexts: But very often, parallel computers are used for solving larger problems and in many of these cases the sequential portion of the application may not increase appreciably regardless of the problem size <ref> [30] </ref> yielding a lower serial fraction for larger problems. In such cases, memory-constrained and time-constrained scaling strategies are more useful. Gustafson et al. [30] introduce a metric called scaled-speedup that tries to capture the memory-constrained scaling strategy. <p> are used for solving larger problems and in many of these cases the sequential portion of the application may not increase appreciably regardless of the problem size <ref> [30] </ref> yielding a lower serial fraction for larger problems. In such cases, memory-constrained and time-constrained scaling strategies are more useful. Gustafson et al. [30] introduce a metric called scaled-speedup that tries to capture the memory-constrained scaling strategy. Scaled speedup is defined as the speedup curve obtained when the problem size is increased linearly with the number of processors. Sun and Gustafson [58] propose a metric called sizeup to capture the time-constrained scaling strategy.
Reference: [31] <author> D. P. Helmbold and C. E. McDowell. </author> <title> Modeling Speedup (n) Greater than n. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(2) </volume> <pages> 250-256, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Decreasing f is an indication of superlinear speedup that arises due to reasons such as memory size and randomness in application execution, as outlined in <ref> [31] </ref>. Nussbaum and Agarwal [43] quantify scalability as a ratio of the application's asymptotic speedup when run on the actual architecture to its corresponding asymptotic speedup when run on an EREW PRAM [26], for a given problem size.
Reference: [32] <author> A. H. Karp and H. P. Flatt. </author> <title> Measuring Parallel processor Performance. </title> <journal> Communications of the ACM, </journal> <volume> 33(5) </volume> <pages> 539-543, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Similarly, when a parallel system exhibits non-ideal behavior in the memory-constrained or time-constrained scaling 2 strategies, scaled-speedup and sizeup fail to show whether the problem rests with the application and/or the architecture. Three other metrics <ref> [34, 32, 43] </ref> attempt to address this deficiency. Isoefficiency function [34] tries to capture the impact of problem sizes along the application dimension and the number of processors along the architectural dimension. <p> Apart from providing a bound on achievable performance (Amdahl's law), the theoretical serial fraction of an application is not very useful in giving a realistic estimate of performance on actual hardware. Karp and Flatt <ref> [32] </ref> use an experimentally determined serial fraction f for a problem with a fixed size in evaluating parallel systems. f is computed by executing the application on the actual hardware and calculating the effective loss in speedup. <p> Architectural scalability is defined as the relative performance between the ideal and real architectures. A larger ratio is an indication of better performance obtained in running the given application on the hardware platform. Metrics used by <ref> [34, 32, 43] </ref> thus attempt to identify the cause (the application or the architecture) of the problem when the parallel system does not scale as expected.
Reference: [33] <author> V. Kumar and A. Gupta. </author> <title> Analyzing Scalability of Parallel Algorithms and Architectures. </title> <booktitle> In Proceedings of the ACM 1991 International Conference on Supercomputing, </booktitle> <address> Cologne, Germany, </address> <year> 1991. </year>
Reference-contexts: Metrics proposed for scalability attempt to quantify this match. We summarize some of the proposed metrics in this section and also discuss the amount of information provided by each metric towards understanding the parallel system execution. The reader is referred to <ref> [33] </ref> for a detailed survey of different performance metrics for scalability. Speedup is a widely used metric for quantifying improvements in parallel system performance as the number of processors is increased.
Reference: [34] <author> V. Kumar and V. N. Rao. </author> <title> Parallel Depth-First Search. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 16(6) </volume> <pages> 501-519, </pages> <year> 1987. </year>
Reference-contexts: Similarly, when a parallel system exhibits non-ideal behavior in the memory-constrained or time-constrained scaling 2 strategies, scaled-speedup and sizeup fail to show whether the problem rests with the application and/or the architecture. Three other metrics <ref> [34, 32, 43] </ref> attempt to address this deficiency. Isoefficiency function [34] tries to capture the impact of problem sizes along the application dimension and the number of processors along the architectural dimension. <p> Similarly, when a parallel system exhibits non-ideal behavior in the memory-constrained or time-constrained scaling 2 strategies, scaled-speedup and sizeup fail to show whether the problem rests with the application and/or the architecture. Three other metrics [34, 32, 43] attempt to address this deficiency. Isoefficiency function <ref> [34] </ref> tries to capture the impact of problem sizes along the application dimension and the number of processors along the architectural dimension. For a problem with a fixed size, the processor utilization (efficiency) normally decreases with an increase in the number of processors. <p> Architectural scalability is defined as the relative performance between the ideal and real architectures. A larger ratio is an indication of better performance obtained in running the given application on the hardware platform. Metrics used by <ref> [34, 32, 43] </ref> thus attempt to identify the cause (the application or the architecture) of the problem when the parallel system does not scale as expected.
Reference: [35] <author> J. Kuskin et al. </author> <title> The Stanford FLASH multiprocessor. </title> <booktitle> In Proceedings of the 21th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 302-313, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: From the hardware point of view, the number of processors can be varied. Also, some machines provide flexibility in hardware capabilities, like the ability to vary the cache coherence protocol on the FLASH <ref> [35] </ref> multiprocessor. For such parameters, one may be able to vary the hardware capabilities and develop analytical or regression models for predicting their impact on performance.
Reference: [36] <author> D. Lenoski et al. </author> <title> The DASH Prototype: Logic Overhead and Performance. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(1) </volume> <pages> 41-61, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: The scalability of the KSR-1 is studied in [47] using applications drawn from the NAS benchmark suite [9]. Similarly, an experimental evaluation of the computation and communication capabilities of the CM-5 is conducted in [46]. Lenoski et al. <ref> [36] </ref> evaluate the scalability of the Stanford DASH multiprocessor prototype using a set of applications. These applications are implemented on the prototype hardware and their performance is studied using a hardware monitor to obtain statistics on processor usage, cache statistics and network traffic. <p> Experimentation has also been used to study the performance and scalability of specific system artifacts such as locality, synchronization, and interconnection network. The interconnection network and locality properties of the KSR-1 are studied in [22, 11, 49]. Lenoski et al. <ref> [36] </ref> study the performance and scalability of the cache, synchronization primitives and the interconnection network of DASH. They implement artificial workloads which exercise different synchronization alternatives and the prefetch capabilities of the DASH prototype, and measure their performance as a function of the number of processors.
Reference: [37] <author> S. Madala and J. B. Sinclair. </author> <title> Performance of Synchronous Parallel Algorithms with Regular Structures. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(1) </volume> <pages> 105-116, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Vrsalovic et al. [62] develop an analytical model for predicting the performance of iterative algorithms on a simple multiprocessor abstraction, and study the impact of the speed of processors, memory, and network on overall performance. Similarly, <ref> [37] </ref> studies the performance of synchronous parallel algorithms with regular structures. The restriction to regular iterative and synchronous behavior of the application in these studies helps reduce the degrees of freedom in the parallel system for tractability. <p> Analytical models also make simplifying assumptions about the workload. Models developed in [62] are applicable only to regular iterative algorithms with regular communication structures and no data dependent executions. Madala and Sinclair <ref> [37] </ref> confine their studies to synchronous parallel algorithms. The behavior of these simplified workloads is usually modeled by well-known probability distributions and specifiable parameters.
Reference: [38] <author> M. Martonosi, A. Gupta, and T. Anderson. MemSpy: </author> <title> Analyzing Memory System Bottlenecks in Programs. </title> <booktitle> In Proceedings of the ACM SIGMETRICS 1992 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 1-12, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Such simulation platforms can serve as testbeds for implementing and studying a wide range of hardware and application platforms. Some of these simulators provide additional monitoring tools towards understanding the behavior of the simulated systems. For instance, MemSpy <ref> [38] </ref> is a performance debugging tool that is used in conjunction with the Tango simulation platform to locate and fix memory system bottlenecks in applications.
Reference: [39] <author> F. H. McMahon. </author> <title> The Livermore Fortran Kernels : A Computer Test of the Numerical Performance Range. </title> <type> Technical Report UCRL-53745, </type> <institution> Lawrence Livermore National Laboratory, Livermore, </institution> <address> CA, </address> <month> December </month> <year> 1986. </year>
Reference-contexts: Such abstractions of real applications which capture the main phases of the computation are called kernels. One can go even lower than kernels by abstracting the main loops in the computation (like the Lawrence Livermore loops <ref> [39] </ref>) and evaluating their performance. As one goes lower, the outcome of the evaluation becomes less realistic. Even though an application may be abstracted by the kernels inside it, the sum of the times spent in the underlying kernels may not necessarily yield the time taken by the application.
Reference: [40] <author> P. Mehra, C. H. Schulbach, and J. C. Yan. </author> <title> A comparison of two model-based performance-prediction techniques for message-passing parallel programs. </title> <booktitle> In Proceedings of the ACM SIGMETRICS 1994 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 181-190, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: For instance, Archibald and Baer [7] use a workload which models the data sharing pattern between processors in an application, and simulate its execution over a range of hardware cache coherence schemes. Simulation has also been used to study the behavior of parallel systems as a whole <ref> [56, 48, 40, 53] </ref>. General purpose simulators such as SPASM [56, 57], PROTEUS [12], the Rice Parallel Processing Testbed [15], the Wisconsin Wind Tunnel [48], and Tango [19], which can model a range of application and hardware platforms have been developed for studying parallel systems. <p> Many general purpose simulators [56, 12, 15, 48, 19, 61] are based on this paradigm. Execution-driven simulation also provides the flexibility of abstracting out phases of the application that may not significantly impact the system artifacts being studied, in order to speed up the simulation. Mehra et al. <ref> [40] </ref> use such an approach in capturing the local computation between successive communication events of message-passing programs by simple analytical models. Hardware simulation can be as detailed as a cycle level or a logic level simulation which simulates every electronic component. <p> Several techniques have been used to remedy this problem. Abstracting application and hardware details in the simulation model may alleviate this problem. For instance, [53] uses a higher level simulation model for Cholesky Factorization that simulates block modifications rather than machine instructions. Mehra et al. <ref> [40] </ref> attempt to abstract phases of message-passing applications by analytical models gleaned from application knowledge or from earlier simulations. Similarly, [20] uses application knowledge to abstract out phases of numerical calculations to derive computation and communication profiles in approximating the simulation of parallel algorithms. <p> It gives read/write statistics, miss rates and the statistics associated with the reasons for a miss in the local cache of a processor. Identifying the main reasons for cache misses can help in fixing the application to improve its locality properties. The AIMS toolkit that comes with the Axe <ref> [40] </ref> simulation platform supports automatic instrumentation, run-time monitoring and graphical analysis of performance for message-passing parallel programs. Such visualization and animation of system execution can help in understanding the communication pattern of applications, providing information that is important from both the performance and correctness point of view.
Reference: [41] <author> J. M. Mellor-Crummey and M. L. Scott. </author> <title> Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 9(1) </volume> <pages> 21-65, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: They implement artificial workloads which exercise different synchronization alternatives and the prefetch capabilities of the DASH prototype, and measure their performance as a function of the number of processors. The scalability of hardware and software synchronization primitives on the Sequent Symmetry and BBN Butterfly hardware platforms is investigated in <ref> [41] </ref> and [5]. In these studies, each processor is subjected to a large number of synchronization operations to calculate the average overhead for a single operation.
Reference: [42] <author> B. P. Miller et al. IPS-2: </author> <title> The Second Generation of a Parallel Program Measurement System. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(2) </volume> <pages> 206-217, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: IPS-2 <ref> [42] </ref> also uses instrumentation to analyze parallel program performance. It differs from Quartz and Mtool in that it generates a trace of events during application execution, and then analyzes the trace to present useful information to the user.
Reference: [43] <author> D. Nussbaum and A. Agarwal. </author> <title> Scalability of Parallel Machines. </title> <journal> Communications of the ACM, </journal> <volume> 34(3) </volume> <pages> 57-61, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: Similarly, when a parallel system exhibits non-ideal behavior in the memory-constrained or time-constrained scaling 2 strategies, scaled-speedup and sizeup fail to show whether the problem rests with the application and/or the architecture. Three other metrics <ref> [34, 32, 43] </ref> attempt to address this deficiency. Isoefficiency function [34] tries to capture the impact of problem sizes along the application dimension and the number of processors along the architectural dimension. <p> Decreasing f is an indication of superlinear speedup that arises due to reasons such as memory size and randomness in application execution, as outlined in [31]. Nussbaum and Agarwal <ref> [43] </ref> quantify scalability as a ratio of the application's asymptotic speedup when run on the actual architecture to its corresponding asymptotic speedup when run on an EREW PRAM [26], for a given problem size. <p> Architectural scalability is defined as the relative performance between the ideal and real architectures. A larger ratio is an indication of better performance obtained in running the given application on the hardware platform. Metrics used by <ref> [34, 32, 43] </ref> thus attempt to identify the cause (the application or the architecture) of the problem when the parallel system does not scale as expected.
Reference: [44] <author> S. Owicki and A. Agarwal. </author> <title> Evaluating the Performance of Software Cache Coherence. </title> <booktitle> In Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 230-242, </pages> <address> Boston, Massachusetts, </address> <month> April </month> <year> 1989. </year>
Reference-contexts: The restriction to regular iterative and synchronous behavior of the application in these studies helps reduce the degrees of freedom in the parallel system for tractability. Analytical models have also helped study the performance and scalability of specific system artifacts such as interconnection network [18, 1], caches <ref> [45, 44] </ref>, scheduling [50] and synchronization [64]. 5.2 Input Model Several theoretical models have been proposed in literature to abstract parallel machine artifacts. The PRAM [26] has been an extremely popular vehicle for algorithm development.
Reference: [45] <author> J. H. Patel. </author> <title> Analysis of multiprocessors with private cache memories. </title> <journal> IEEE Transactions on Computer Systems, </journal> <volume> 31(4) </volume> <pages> 296-304, </pages> <month> April </month> <year> 1982. </year> <month> 22 </month>
Reference-contexts: The restriction to regular iterative and synchronous behavior of the application in these studies helps reduce the degrees of freedom in the parallel system for tractability. Analytical models have also helped study the performance and scalability of specific system artifacts such as interconnection network [18, 1], caches <ref> [45, 44] </ref>, scheduling [50] and synchronization [64]. 5.2 Input Model Several theoretical models have been proposed in literature to abstract parallel machine artifacts. The PRAM [26] has been an extremely popular vehicle for algorithm development. <p> Sometimes the hardware details are simplified in order to keep the model tractable. For example, under the assumption that there is minimal data inconsistency arising during the execution of an application, some studies <ref> [45] </ref> ignore cache coherence traffic in analyzing multiprocessor caches. Analytical models also make simplifying assumptions about the workload. Models developed in [62] are applicable only to regular iterative algorithms with regular communication structures and no data dependent executions. Madala and Sinclair [37] confine their studies to synchronous parallel algorithms.
Reference: [46] <author> R. Ponnusamy, R. Thakur, A. Choudhary, K. Velamakanni, Z. Bozkus, and G. Fox. </author> <title> Experimental performance evaluation of the CM-5. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 19 </volume> <pages> 192-202, </pages> <year> 1993. </year>
Reference-contexts: The scalability of the KSR-1 is studied in [47] using applications drawn from the NAS benchmark suite [9]. Similarly, an experimental evaluation of the computation and communication capabilities of the CM-5 is conducted in <ref> [46] </ref>. Lenoski et al. [36] evaluate the scalability of the Stanford DASH multiprocessor prototype using a set of applications. These applications are implemented on the prototype hardware and their performance is studied using a hardware monitor to obtain statistics on processor usage, cache statistics and network traffic. <p> On the other hand, the workload model (often called benchmarks) used in evaluations can span a diverse spectrum of realism. The simplest benchmarks exercise and measure the performance of low-level hardware features. Workloads used in [22] and <ref> [46] </ref> which evaluate the low-level communication performance of the KSR-1 and CM-5 respectively, are examples of such benchmarks. The workload used in [46] evaluates the performance of the CM-5 network by inducing messages to traverse different levels of the fat-tree network under a variety of traffic conditions. <p> The simplest benchmarks exercise and measure the performance of low-level hardware features. Workloads used in [22] and <ref> [46] </ref> which evaluate the low-level communication performance of the KSR-1 and CM-5 respectively, are examples of such benchmarks. The workload used in [46] evaluates the performance of the CM-5 network by inducing messages to traverse different levels of the fat-tree network under a variety of traffic conditions. Synthetic benchmarks that mimic the behavior of some applications have also been used for evaluating systems.
Reference: [47] <author> U. Ramachandran, G. Shah, S. Ravikumar, and J. Muthukumarasamy. </author> <title> Scalability study of the KSR-1. </title> <booktitle> In Proceedings of the 1993 International Conference on Parallel Processing, </booktitle> <pages> pages I-237-240, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: For instance, several studies <ref> [22, 11, 47, 49] </ref> experiment with the KSR-1 hardware for evaluating its computation, communication and scalability properties. The scalability of the KSR-1 is studied in [47] using applications drawn from the NAS benchmark suite [9]. <p> For instance, several studies [22, 11, 47, 49] experiment with the KSR-1 hardware for evaluating its computation, communication and scalability properties. The scalability of the KSR-1 is studied in <ref> [47] </ref> using applications drawn from the NAS benchmark suite [9]. Similarly, an experimental evaluation of the computation and communication capabilities of the CM-5 is conducted in [46]. Lenoski et al. [36] evaluate the scalability of the Stanford DASH multiprocessor prototype using a set of applications.
Reference: [48] <author> S. K. Reinhardt et al. </author> <title> The Wisconsin Wind Tunnel : Virtual prototyping of parallel computers. </title> <booktitle> In Proceedings of the ACM SIGMETRICS 1993 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 48-60, </pages> <address> Santa Clara, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: For instance, Archibald and Baer [7] use a workload which models the data sharing pattern between processors in an application, and simulate its execution over a range of hardware cache coherence schemes. Simulation has also been used to study the behavior of parallel systems as a whole <ref> [56, 48, 40, 53] </ref>. General purpose simulators such as SPASM [56, 57], PROTEUS [12], the Rice Parallel Processing Testbed [15], the Wisconsin Wind Tunnel [48], and Tango [19], which can model a range of application and hardware platforms have been developed for studying parallel systems. <p> Simulation has also been used to study the behavior of parallel systems as a whole [56, 48, 40, 53]. General purpose simulators such as SPASM [56, 57], PROTEUS [12], the Rice Parallel Processing Testbed [15], the Wisconsin Wind Tunnel <ref> [48] </ref>, and Tango [19], which can model a range of application and hardware platforms have been developed for studying parallel systems. Simulation is also often used to validate and refine analytical models. 6.2 Input Model Simulation provides flexibility for choosing the level of detail in the application and hardware models. <p> Execution-driven simulation that simulates the execution of the entire application on the hardware is becoming increasingly popular because of its accuracy in capturing the dynamics of parallel system interactions. Many general purpose simulators <ref> [56, 12, 15, 48, 19, 61] </ref> are based on this paradigm. Execution-driven simulation also provides the flexibility of abstracting out phases of the application that may not significantly impact the system artifacts being studied, in order to speed up the simulation. <p> Hardware simulation can be as detailed as a cycle level or a logic level simulation which simulates every electronic component. Machine details may also be abstracted out depending on the level of detail and accuracy desired by the user. Many simulators <ref> [56, 12, 15, 48, 19, 61] </ref> do not simulate the details of instruction execution by a processor since simulating each instruction is not likely to significantly impact the understanding of parallel system behavior. <p> Most of the application code is executed at the speed of the native processor and only interesting instructions are trapped to the simulator and simulated. The Wisconsin Wind Tunnel <ref> [48] </ref> which simulates shared memory platforms relies on the ECC (error correcting code) bits of the native hardware to trap to the simulator on accesses to shared memory by a processor. <p> Similarly, [20] uses application knowledge to abstract out phases of numerical calculations to derive computation and communication profiles in approximating the simulation of parallel algorithms. From the hardware point of view, most general purpose simulators <ref> [56, 12, 15, 19, 48] </ref> do not simulate the parallel machine at the instruction-set level as we discussed earlier. Similarly, different levels of abstractions for other hardware artifacts like the interconnection network and caches may be studied to improve simulation speed. <p> Similarly, different levels of abstractions for other hardware artifacts like the interconnection network and caches may be studied to improve simulation speed. Another way of alleviating the cost is by parallelizing the simulation itself like the Wisconsin Wind Tunnel <ref> [48] </ref> approach which uses the CM-5 hardware for simulating shared memory multiprocessors. With regard to modifiability, a moderate change in hardware parameters may be handled by plugging in these values into the model and re-simulating the system. <p> A significant change in the machine or application details would also demand a re-implementation of the simulation model, but the cost of re-simulation is again expected to dominate over the cost of re-implementation. 17 6.4 Tools Several general purpose execution-driven simulators <ref> [56, 12, 15, 19, 48, 61, 63] </ref> have been built for simulation study of parallel systems. Such simulation platforms can serve as testbeds for implementing and studying a wide range of hardware and application platforms.
Reference: [49] <author> R. H. Saavedra, R. S. Gaines, and M. J. Carlton. </author> <title> Micro Benchmark Analysis of the KSR-1. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <pages> pages 202-213, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: For instance, several studies <ref> [22, 11, 47, 49] </ref> experiment with the KSR-1 hardware for evaluating its computation, communication and scalability properties. The scalability of the KSR-1 is studied in [47] using applications drawn from the NAS benchmark suite [9]. <p> Experimentation has also been used to study the performance and scalability of specific system artifacts such as locality, synchronization, and interconnection network. The interconnection network and locality properties of the KSR-1 are studied in <ref> [22, 11, 49] </ref>. Lenoski et al. [36] study the performance and scalability of the cache, synchronization primitives and the interconnection network of DASH. <p> Synthetic benchmarks that mimic the behavior of some applications have also been used for evaluating systems. Boyd et al. [11] propose a synthetic benchmark using sparse matrices that is expected to model the behavior of typical sparse matrix computations. Synthetic benchmarks called micro-kernels are used in <ref> [49] </ref> to evaluate the KSR-1. Varying parameters in these synthetic benchmarks is expected to capture typical workloads of real applications. Another common way of benchmarking and studying system artifacts is by experimenting with well-known parallel algorithms.
Reference: [50] <author> S. K. Setia, M. S. Squillante, and S. K. Tripathi. </author> <title> Analysis of Processor Allocation in Multiprogrammed, Distributed-Memory Parallel Processing Systems. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(4) </volume> <pages> 401-420, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Analytical models have also helped study the performance and scalability of specific system artifacts such as interconnection network [18, 1], caches [45, 44], scheduling <ref> [50] </ref> and synchronization [64]. 5.2 Input Model Several theoretical models have been proposed in literature to abstract parallel machine artifacts. The PRAM [26] has been an extremely popular vehicle for algorithm development.
Reference: [51] <author> J. B. Sinclair and W. P. Dawkins. </author> <title> ES: A Tool for Predicting the Performance of Parallel Systems. </title> <booktitle> In Proceedings of MASCOTS '94, </booktitle> <pages> pages 164-168, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: But the PAMELA approach relies on static analysis to reduce the complexity of the evaluation. Transformations to convert resource contention to simple delays, and reductions to combine these delays, are used to simplify the evaluation. ES (Event Sequencer) <ref> [51] </ref> is a tool that uses analytical techniques for predicting the performance of parallel algorithms on MIMD machines. ES models the parallel algorithm by a task graph, allowing the user to specify the precedence constraints between these tasks and random variables representing the execution times of each of these tasks.
Reference: [52] <author> J. P. Singh, T. Joe, A. Gupta, and J. L. Hennessy. </author> <title> An Empirical Comparison of the Kendall Square Research KSR-1 and Stanford DASH Multiprocessors. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <pages> pages 214-225, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: The statistics are used to explain the deviation of application performance from ideal behavior. Such evaluations of machine performance using benchmarks may be used to compare different 6 hardware platforms. Singh et al. <ref> [52] </ref> thus use applications from the SPLASH benchmark suite [54] to compare the KSR-1 and DASH multiprocessors. Experimentation has also been used to study the performance and scalability of specific system artifacts such as locality, synchronization, and interconnection network.
Reference: [53] <author> J. P. Singh, E. Rothberg, and A. Gupta. </author> <title> Modeling communication in parallel algorithms: </title> <booktitle> A fruitful interaction between theory and systems? In Proceedings of the Sixth Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1994. </year>
Reference-contexts: But even for theoretical models, a static analysis of application code which is used to estimate the running time can yield inaccurate results. Real applications often display a dynamic computation and communication behavior that may not be pre-determined <ref> [53] </ref>. A static analysis of application code as done by theoretical models may not reveal sufficient information due to dynamic system interactions and data-dependent executions. The results from the worst-case and average-case analysis used with these models can vary significantly from the real execution. <p> For instance, Archibald and Baer [7] use a workload which models the data sharing pattern between processors in an application, and simulate its execution over a range of hardware cache coherence schemes. Simulation has also been used to study the behavior of parallel systems as a whole <ref> [56, 48, 40, 53] </ref>. General purpose simulators such as SPASM [56, 57], PROTEUS [12], the Rice Parallel Processing Testbed [15], the Wisconsin Wind Tunnel [48], and Tango [19], which can model a range of application and hardware platforms have been developed for studying parallel systems. <p> Execution-driven simulations of real parallel systems demand considerable computational resources, both in terms of space and time. Several techniques have been used to remedy this problem. Abstracting application and hardware details in the simulation model may alleviate this problem. For instance, <ref> [53] </ref> uses a higher level simulation model for Cholesky Factorization that simulates block modifications rather than machine instructions. Mehra et al. [40] attempt to abstract phases of message-passing applications by analytical models gleaned from application knowledge or from earlier simulations.
Reference: [54] <author> J. P. Singh, W-D. Weber, and A. Gupta. </author> <title> SPLASH: Stanford Parallel Applications for Shared-Memory. </title> <type> Technical Report CSL-TR-91-469, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <year> 1991. </year>
Reference-contexts: The statistics are used to explain the deviation of application performance from ideal behavior. Such evaluations of machine performance using benchmarks may be used to compare different 6 hardware platforms. Singh et al. [52] thus use applications from the SPLASH benchmark suite <ref> [54] </ref> to compare the KSR-1 and DASH multiprocessors. Experimentation has also been used to study the performance and scalability of specific system artifacts such as locality, synchronization, and interconnection network. The interconnection network and locality properties of the KSR-1 are studied in [22, 11, 49]. <p> Application suites such as the Perfect Club [10], the NAS Parallel Benchmarks [9], and the SPLASH application suite <ref> [54] </ref> have been proposed for the evaluation of parallel machines. However, applications normally tend to contain large volumes of code that are not easily portable, and a level of detail that is not very familiar to someone outside that application domain.
Reference: [55] <author> A. Sivasubramaniam, G. Shah, J. Lee, U. Ramachandran, and H. Venkateswaran. </author> <title> Experimental Evaluation of Algorithmic Performance on Two Shared Memory Multiprocessors. In Norihisa Suzuki, editor, </title> <booktitle> Shared Memory Multiprocessing, </booktitle> <pages> pages 81-107. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Varying parameters in these synthetic benchmarks is expected to capture typical workloads of real applications. Another common way of benchmarking and studying system artifacts is by experimenting with well-known parallel algorithms. Three such frequently used text book algorithms are used in <ref> [55] </ref> to evaluate the performance of two shared memory multiprocessors, and to study the impact of task granularity, data distribution and scheduling strategies on system performance. Benchmarking using low-level measurements, and synthetic workloads has often been criticized due to the lack of realism in capturing the behavior of real applications.
Reference: [56] <author> A. Sivasubramaniam, A. Singla, U. Ramachandran, and H. Venkateswaran. </author> <title> An Approach to Scalability Study of Shared Memory Parallel Systems. </title> <booktitle> In Proceedings of the ACM SIGMETRICS 1994 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 171-180, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: It can also help in choosing between alternate application implementations, selecting the best hardware platform, and the different other uses of a performance analysis study outlined earlier in section 1. Recognizing this importance, studies <ref> [57, 56, 16, 13] </ref> have attempted to separate and quantify parallel system overheads. 3 Ignoring effects of superlinearity, one would expect a speedup that increases linearly with the number of processors, as shown by the curve named linear in Figure 1. <p> To fully understand the scalability of the parallel system, it is important to isolate and quantify the impact of different parallel system overheads on the overall execution as shown in Figure 1. Overhead functions <ref> [56, 57] </ref> and lost cycles [16] are metrics that have been proposed to capture the growth of overheads in a parallel system. Both these metrics quantify the contribution of each overhead towards the overall execution time. The studies differ in the techniques used to quantify these metrics. <p> Both these metrics quantify the contribution of each overhead towards the overall execution time. The studies differ in the techniques used to quantify these metrics. Experimentation is used in [16] to quantify lost cycles, while simulation is used in <ref> [56, 57] </ref> to quantify overhead functions. In addition to quantifying the overheads in a given parallel system, a performance evaluation technique should also be able to quantify the growth of overheads as a function of system parameters such as problem size, number of processors, processor clock speed, and network speed. <p> For instance, Archibald and Baer [7] use a workload which models the data sharing pattern between processors in an application, and simulate its execution over a range of hardware cache coherence schemes. Simulation has also been used to study the behavior of parallel systems as a whole <ref> [56, 48, 40, 53] </ref>. General purpose simulators such as SPASM [56, 57], PROTEUS [12], the Rice Parallel Processing Testbed [15], the Wisconsin Wind Tunnel [48], and Tango [19], which can model a range of application and hardware platforms have been developed for studying parallel systems. <p> Simulation has also been used to study the behavior of parallel systems as a whole [56, 48, 40, 53]. General purpose simulators such as SPASM <ref> [56, 57] </ref>, PROTEUS [12], the Rice Parallel Processing Testbed [15], the Wisconsin Wind Tunnel [48], and Tango [19], which can model a range of application and hardware platforms have been developed for studying parallel systems. <p> Execution-driven simulation that simulates the execution of the entire application on the hardware is becoming increasingly popular because of its accuracy in capturing the dynamics of parallel system interactions. Many general purpose simulators <ref> [56, 12, 15, 48, 19, 61] </ref> are based on this paradigm. Execution-driven simulation also provides the flexibility of abstracting out phases of the application that may not significantly impact the system artifacts being studied, in order to speed up the simulation. <p> Hardware simulation can be as detailed as a cycle level or a logic level simulation which simulates every electronic component. Machine details may also be abstracted out depending on the level of detail and accuracy desired by the user. Many simulators <ref> [56, 12, 15, 48, 19, 61] </ref> do not simulate the details of instruction execution by a processor since simulating each instruction is not likely to significantly impact the understanding of parallel system behavior. <p> The Wisconsin Wind Tunnel [48] which simulates shared memory platforms relies on the ECC (error correcting code) bits of the native hardware to trap to the simulator on accesses to shared memory by a processor. SPASM <ref> [56] </ref>, PROTEUS [12], the Rice Parallel Processing Testbed [15], and Tango [19] use application source code augmentation to trap to the simulator for the instructions to be simulated. <p> It can give the total execution time and the different parallel system overheads for calculating metrics outlined in section 2. In addition, a simulator can supply these metrics for different windows in application execution which can help identify and remedy algorithmic and architectural bottlenecks <ref> [56] </ref>. Since the application and hardware details are modeled in software, the system parameters can be varied and the system re-simulated to give the desired metrics. These results may be used to give regression performance models as 16 a function of system parameters. Such a technique is used in [56] to <p> bottlenecks <ref> [56] </ref>. Since the application and hardware details are modeled in software, the system parameters can be varied and the system re-simulated to give the desired metrics. These results may be used to give regression performance models as 16 a function of system parameters. Such a technique is used in [56] to derive models for system overheads as a function of the number of processors. <p> Similarly, [20] uses application knowledge to abstract out phases of numerical calculations to derive computation and communication profiles in approximating the simulation of parallel algorithms. From the hardware point of view, most general purpose simulators <ref> [56, 12, 15, 19, 48] </ref> do not simulate the parallel machine at the instruction-set level as we discussed earlier. Similarly, different levels of abstractions for other hardware artifacts like the interconnection network and caches may be studied to improve simulation speed. <p> A significant change in the machine or application details would also demand a re-implementation of the simulation model, but the cost of re-simulation is again expected to dominate over the cost of re-implementation. 17 6.4 Tools Several general purpose execution-driven simulators <ref> [56, 12, 15, 19, 48, 61, 63] </ref> have been built for simulation study of parallel systems. Such simulation platforms can serve as testbeds for implementing and studying a wide range of hardware and application platforms. <p> Such visualization and animation of system execution can help in understanding the communication pattern of applications, providing information that is important from both the performance and correctness point of view. The monitoring support provided by SPASM <ref> [56, 57] </ref> exploits the controlled execution feature of simulation to provide a detailed isolation and quantification of different parallel system overheads. SPASM quantifies the algorithmic overhead by executing the parallel program on a PRAM and measuring its deviation from linear behavior.
Reference: [57] <author> A. Sivasubramaniam, A. Singla, U. Ramachandran, and H. Venkateswaran. </author> <title> A Simulation-based Scalability Study of Parallel Systems. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> 1994. To appear. </note>
Reference-contexts: It can also help in choosing between alternate application implementations, selecting the best hardware platform, and the different other uses of a performance analysis study outlined earlier in section 1. Recognizing this importance, studies <ref> [57, 56, 16, 13] </ref> have attempted to separate and quantify parallel system overheads. 3 Ignoring effects of superlinearity, one would expect a speedup that increases linearly with the number of processors, as shown by the curve named linear in Figure 1. <p> To fully understand the scalability of the parallel system, it is important to isolate and quantify the impact of different parallel system overheads on the overall execution as shown in Figure 1. Overhead functions <ref> [56, 57] </ref> and lost cycles [16] are metrics that have been proposed to capture the growth of overheads in a parallel system. Both these metrics quantify the contribution of each overhead towards the overall execution time. The studies differ in the techniques used to quantify these metrics. <p> Both these metrics quantify the contribution of each overhead towards the overall execution time. The studies differ in the techniques used to quantify these metrics. Experimentation is used in [16] to quantify lost cycles, while simulation is used in <ref> [56, 57] </ref> to quantify overhead functions. In addition to quantifying the overheads in a given parallel system, a performance evaluation technique should also be able to quantify the growth of overheads as a function of system parameters such as problem size, number of processors, processor clock speed, and network speed. <p> Simulation has also been used to study the behavior of parallel systems as a whole [56, 48, 40, 53]. General purpose simulators such as SPASM <ref> [56, 57] </ref>, PROTEUS [12], the Rice Parallel Processing Testbed [15], the Wisconsin Wind Tunnel [48], and Tango [19], which can model a range of application and hardware platforms have been developed for studying parallel systems. <p> Such visualization and animation of system execution can help in understanding the communication pattern of applications, providing information that is important from both the performance and correctness point of view. The monitoring support provided by SPASM <ref> [56, 57] </ref> exploits the controlled execution feature of simulation to provide a detailed isolation and quantification of different parallel system overheads. SPASM quantifies the algorithmic overhead by executing the parallel program on a PRAM and measuring its deviation from linear behavior.
Reference: [58] <author> X-H. Sun and J. L. Gustafson. </author> <title> Towards a better Parallel Performance Metric. </title> <journal> Parallel Computing, </journal> <volume> 17 </volume> <pages> 1093-1109, </pages> <year> 1991. </year>
Reference-contexts: Gustafson et al. [30] introduce a metric called scaled-speedup that tries to capture the memory-constrained scaling strategy. Scaled speedup is defined as the speedup curve obtained when the problem size is increased linearly with the number of processors. Sun and Gustafson <ref> [58] </ref> propose a metric called sizeup to capture the time-constrained scaling strategy. Sizeup is defined as the ratio of the size of the problem solved on the parallel machine to the size of the problem solved on the sequential machine for the same execution time.
Reference: [59] <author> L. G. Valiant. </author> <title> A Bridging Model for Parallel Computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8) </volume> <pages> 103-111, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: These models try to hide hardware details from the programmer, providing a simplified view of the machine. The utility of such models towards developing efficient algorithms for actual machines, depends on the closeness of the model to the actual machine. Several machine models <ref> [2, 3, 27, 14, 59, 17] </ref> have been proposed over the years to bridge the gap between the theoretical abstractions and the hardware. <p> The implicit synchronization assumption in PRAMs is removed in [27] and [14]. In their models, the processors execute asynchronously, with explicit synchronization steps to enforce synchrony when needed. Valiant <ref> [59] </ref> introduces the Bulk-Synchronous Parallel (BSP) model which has: a number of components, each performing processing and/or memory functions; a router that delivers point to point messages between components; and a facility for synchronizing all or a subset of the components at regular intervals.
Reference: [60] <author> A. J. van Gemund. </author> <title> Performance Prediction of Parallel Processing Systems: The PAMELA Methodology. </title> <booktitle> In Proceedings of the ACM 1993 International Conference on Supercomputing, </booktitle> <pages> pages 318-327, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: The PAMELA system <ref> [60] </ref> builds abstract models of the application program and the hardware, and uses static model reduction strategies to reduce evaluation complexity. The hardware features of the machine are abstracted by resource models and the user can choose the level of hardware detail that needs to be modeled.
Reference: [61] <author> J. E. Veenstra and R. J. Fowler. MINT: </author> <title> A Front End for Efficient Simulation of Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of MASCOTS '94, </booktitle> <pages> pages 201-207, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: Execution-driven simulation that simulates the execution of the entire application on the hardware is becoming increasingly popular because of its accuracy in capturing the dynamics of parallel system interactions. Many general purpose simulators <ref> [56, 12, 15, 48, 19, 61] </ref> are based on this paradigm. Execution-driven simulation also provides the flexibility of abstracting out phases of the application that may not significantly impact the system artifacts being studied, in order to speed up the simulation. <p> Hardware simulation can be as detailed as a cycle level or a logic level simulation which simulates every electronic component. Machine details may also be abstracted out depending on the level of detail and accuracy desired by the user. Many simulators <ref> [56, 12, 15, 48, 19, 61] </ref> do not simulate the details of instruction execution by a processor since simulating each instruction is not likely to significantly impact the understanding of parallel system behavior. <p> SPASM [56], PROTEUS [12], the Rice Parallel Processing Testbed [15], and Tango [19] use application source code augmentation to trap to the simulator for the instructions to be simulated. MINT <ref> [61] </ref> interprets the binary object code to determine which instructions need to be simulated and thus does not need the standard application code to be recompiled with the special augmenting instructions. <p> A significant change in the machine or application details would also demand a re-implementation of the simulation model, but the cost of re-simulation is again expected to dominate over the cost of re-implementation. 17 6.4 Tools Several general purpose execution-driven simulators <ref> [56, 12, 15, 19, 48, 61, 63] </ref> have been built for simulation study of parallel systems. Such simulation platforms can serve as testbeds for implementing and studying a wide range of hardware and application platforms.
Reference: [62] <author> D. F. Vrsalovic, D. P. Siewiorek, Z. Z. Segall, and E. Gehringer. </author> <title> Performance Prediction and Calibration for a Class of Multiprocessors. </title> <journal> IEEE Transactions on Computer Systems, </journal> <volume> 37(11) </volume> <pages> 1353-1365, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: Such models have found more use in performance analysis than in algorithm development where theoretical models are more widely used. As with experimentation, analytical models have been used to evaluate overall system performance as well as the performance of specific system artifacts. Vrsalovic et al. <ref> [62] </ref> develop an analytical model for predicting the performance of iterative algorithms on a simple multiprocessor abstraction, and study the impact of the speed of processors, memory, and network on overall performance. Similarly, [37] studies the performance of synchronous parallel algorithms with regular structures. <p> For example, under the assumption that there is minimal data inconsistency arising during the execution of an application, some studies [45] ignore cache coherence traffic in analyzing multiprocessor caches. Analytical models also make simplifying assumptions about the workload. Models developed in <ref> [62] </ref> are applicable only to regular iterative algorithms with regular communication structures and no data dependent executions. Madala and Sinclair [37] confine their studies to synchronous parallel algorithms. The behavior of these simplified workloads is usually modeled by well-known probability distributions and specifiable parameters.
Reference: [63] <author> H. Wabnig and G. Haring. </author> <title> PAPS The Parallel Program Performance Prediction Toolset. </title> <booktitle> In Proceedings of the 7th International Conference on Modeling Techniques and Tools for Computer Performance Evaluation, </booktitle> <address> Vienna, Austria, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Simulation can also use real applications, and the way in which these applications are used results in the other three types of simulation. Abstraction-driven simulations capture the behavior of the application by a model, and then simulate the model on 15 the given hardware. The PAPS <ref> [63] </ref> toolset uses this approach to abstract the application behavior by Petri nets which is then simulated. Trace-driven simulations use an input trace of events that is drawn from an earlier execution of the application either on the actual hardware or on another simulated hardware. <p> A significant change in the machine or application details would also demand a re-implementation of the simulation model, but the cost of re-simulation is again expected to dominate over the cost of re-implementation. 17 6.4 Tools Several general purpose execution-driven simulators <ref> [56, 12, 15, 19, 48, 61, 63] </ref> have been built for simulation study of parallel systems. Such simulation platforms can serve as testbeds for implementing and studying a wide range of hardware and application platforms.
Reference: [64] <author> P. J. Woest and J. R. Goodman. </author> <title> An Analysis of Synchronization Mechanisms in Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of the First International Symposium on Shared Memory Multiprocessing, </booktitle> <pages> pages 152-165, </pages> <address> Tokyo, Japan, </address> <month> April </month> <year> 1991. </year> <month> 23 </month>
Reference-contexts: Analytical models have also helped study the performance and scalability of specific system artifacts such as interconnection network [18, 1], caches [45, 44], scheduling [50] and synchronization <ref> [64] </ref>. 5.2 Input Model Several theoretical models have been proposed in literature to abstract parallel machine artifacts. The PRAM [26] has been an extremely popular vehicle for algorithm development.
Reference: [65] <author> J. Zahorjan and C. McCann. </author> <title> Processor Scheduling in Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of the ACM SIGMETRICS 1990 Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 214-225, </pages> <year> 1990. </year>
Reference-contexts: The two factors, cost and controlled execution, have made simulation popular for parallel system studies. It has been used to study the performance and scalability of specific system artifacts such as the interconnection network [1, 18], caches [7] and scheduling <ref> [65] </ref>. Such studies simulate the details of the system artifacts being investigated, and evaluate their performance for a chosen workload. <p> From the application point of view, simulation studies may be broadly classified into synthetic workload-driven, abstraction-driven, trace-driven, and execution-driven that differ in the level of detail used to model the workload. Synthetic workload-driven simulations completely abstract application details by simple parameters and probability distributions. Simulation studies conducted in <ref> [1, 7, 65] </ref> to investigate the performance of interconnection networks, caches and scheduling strategies respectively, use such synthetic workloads. For instance, Agarwal [1] models application behavior by the probability of generating a message of a certain size in a particular cycle.
References-found: 65

