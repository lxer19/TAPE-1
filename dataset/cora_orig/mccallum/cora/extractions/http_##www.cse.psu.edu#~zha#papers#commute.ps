URL: http://www.cse.psu.edu/~zha/papers/commute.ps
Refering-URL: http://www.cse.psu.edu/~zha/papers.html
Root-URL: http://www.cse.psu.edu
Title: COMPUTING THE OPTIMAL COMMUTING MATRIX PAIRS  
Author: HONGYUAN ZHA AND ZHENYUE ZHANG 
Abstract: A matrix can be modified by an additive perturbation so that it commutes with any given matrix. In this paper, we discuss several algorithms for computing the smallest perturbation in the Frobenius norm for a given matrix pair. The algorithms have applications in 2-D direction-of-arrival finding in array signal processing. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Bunse-Gerstner, R. Byers, and V. Mehrmann. </author> <title> Numerical methods for simultaneous diago-nalization. </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 14 </volume> <pages> 927-949, </pages> <year> 1993. </year> <title> 6 We are fully aware that this is not a stable method to use. However, no efficient stable algorithms have been devised so far. </title> <note> 16 HONGYUAN ZHA and ZHENYUE ZHANG Table 2 Means and Standard Deviations Mean i Meanfl i Std i Stdfl i 25.0308 10.0086 0.5958 0.1529 15.0625 19.9670 0.3940 0.3397 </note>
Reference-contexts: by China State Major Key Project for Basic Researches. 1 A more detailed discussion of the array signal processing background is presented in Example 2 of Section 5. 2 It is not a trivial task to stably compute the simultaneous diagonalization of two commuting matrices, the reader is referred to <ref> [1] </ref> for some further discussions. 2 HONGYUAN ZHA and ZHENYUE ZHANG Using Kronecker product and "vec" operation, we can write the equation A (B +X) = (B + X)A as with S = I n A A T I n ; x = vec (X); b = vec (B); where A
Reference: [2] <author> A. Bunse-Gerstner and W.B. Gragg. </author> <title> Singular value decomposition of complex symmetric matrices. </title> <journal> Journal of Computational and Applied Mathematics, </journal> <volume> 21 </volume> <pages> 41-54, </pages> <year> 1988. </year>
Reference-contexts: On the other hand, SP is complex skew-symmetric for a complex A. In the following, we derive the special singular value structure of a complex skew-symmetric matrix. An early development for complex symmetric matrices can be found in <ref> [2] </ref>. First, we need the following lemma. Lemma 3.4. Let W be unitary and W T = W . Then there exists a unitary matrix U such that W = U diag n 1 0 ; ; 0 1 o Proof. <p> Thus the theorem is proved by applying Lemma 3.4 to W j . The fact that SP is a complex skew-symmetric matrix can be exploited to reduce the computational cost of computing the SVD of S. This can be done by using the methods outlined in <ref> [2] </ref> for complex symmetric matrices, and will not be detailed here. 4. Perturbation Analysis. This section is devoted to deriving perturbation bounds for the optimal commuting matrix pair problem.
Reference: [3] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, Maryland, 2nd edition, </address> <year> 1989. </year>
Reference-contexts: If A is a real matrix, then SP is real skew-symmetric, and its eigenvalue structure and singular value structure is well understood <ref> [3] </ref>. On the other hand, SP is complex skew-symmetric for a complex A. In the following, we derive the special singular value structure of a complex skew-symmetric matrix. An early development for complex symmetric matrices can be found in [2]. First, we need the following lemma. Lemma 3.4. <p> Stack x into an upper triangular matrix R X . Then X min = U (R X B L )U H : Remark. The computation of N (S d ) may also be carried out by using a Lanczos-like bidiagonalization process applied to S d <ref> [3] </ref>. There are structures in S d that can be further exploited to reduce the computational cost.
Reference: [4] <author> Y. Hua. </author> <title> Estimating two-dimensional frequencies by matrix enhancement and matrix pencil. </title> <booktitle> in Proceedings of IEEE ICASSP, </booktitle> <year> 1991. </year>
Reference-contexts: n (A); n (B)g; which can be used to compute the azimuth/elevation directions of the signals. 2 Notice that if the eigenvalue decompositions of A and B were computed separately, then one needs to choose the right pairing from many possible combinations by means of some sort of exhaustive search <ref> [4] </ref>. In the presence of noise, the two matrices A and B no longer necessarily commute with each other.
Reference: [5] <author> R. Roy and T. Kailath. </author> <title> ESPRIT|estimation of signal parameters via rotational invariance techniques. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> 37 </volume> <pages> 984-993, </pages> <year> 1989. </year>
Reference-contexts: m 2 : Let E be consist of the d eigenvectors of R ww corresponding to the d largest eigenvalues of R ww , it can be proved that there is a nonsingular T such that E = ^ AT , i.e., E and ^ A span the same subspace <ref> [5] </ref>. <p> The two matrices X j T 1 T and Y j T 1 T can be estimated from (E 1 ; E 2 ) and (E 1 ; E 3 ) using the total least squares techniques <ref> [5] </ref>. Computing the Optimal Commuting Matrix Pairs 15 8 10 12 14 16 18 20 22 24 26 28 10 14 18 22 26 azimuths (degree) elevation (degree) SNR=12dB N=100 200 trials Fig. 2.
Reference: [6] <author> G. W. Stewart and G.-J. Sun. </author> <title> Matrix Perturbation Theory. </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: The minimal norm solution of (1.1) is given by x min = P ? N (S) b = P R (S H ) b. To derive our bounds, we need the following standard perturbation results for orthogonal projections <ref> [6] </ref>: Lemma 4.1. Let A 2 C mfin and B 2 C mfin .
Reference: [7] <author> A. Swindlehurst and T. Kailath. </author> <title> Azimuth/Elevation Direction Finding Using Regular Array Geometries. </title> <journal> IEEE Transactions on Aerospace and Electronic Systems, </journal> <volume> 29 </volume> <pages> 145-155, </pages> <year> 1993. </year>
Reference-contexts: We call the perturbed matrix pair the optimal commuting matrix pair associated with the given matrix pair. This problem arises from 2-D direction-of-arrival finding in array signal processing <ref> [7, 8] </ref>. The particular situation is the following: 1 in the absence of noise, the two matrices under consideration, say A and B which are diagonalizable, commute with each other. <p> Allowing simultaneous perturbations to both A and B turns out to be a much harder problem, and it will be dealt with in a forthcoming paper. Here we will concentrate on the case that only one matrix is subject to perturbation. This simplification was also used in <ref> [7, 8] </ref> for its mathematical tractability. <p> It is easy to verify that the minimal norm solution is given by x min = V I r 0 n )b; where V = [V r ; V z ] with V z an orthonormal basis of N (S), the null space of S <ref> [7, 8] </ref>. The primary purpose of this paper is to present some fast algorithms for computing the optimal commuting matrix pair by taking into account of the structure of the coefficient matrix in (1.1). <p> The results are given in Table 1. It is quite clear that when the clusters of the eigenvalues of A are getting smaller and smaller, the relative residuals are getting larger and larger. Example 2. We consider the problem of estimating azimuths and elevations using a square sensor arrays <ref> [7, 8] </ref>. The sensors are arranged in a square array of m fi m sensors, all equal and omni-directional. We use grid (1 : m; 1 : m) to represent the whole array.
Reference: [8] <author> A.J. Van Der Veen and P.B. Ober and E.F. Deprettere. </author> <title> Azimuth and Elevation Computation in High Resolution DOA Estimation. </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> 40 </volume> <pages> 1828-1832, </pages> <year> 1992. </year>
Reference-contexts: We call the perturbed matrix pair the optimal commuting matrix pair associated with the given matrix pair. This problem arises from 2-D direction-of-arrival finding in array signal processing <ref> [7, 8] </ref>. The particular situation is the following: 1 in the absence of noise, the two matrices under consideration, say A and B which are diagonalizable, commute with each other. <p> Allowing simultaneous perturbations to both A and B turns out to be a much harder problem, and it will be dealt with in a forthcoming paper. Here we will concentrate on the case that only one matrix is subject to perturbation. This simplification was also used in <ref> [7, 8] </ref> for its mathematical tractability. <p> It is easy to verify that the minimal norm solution is given by x min = V I r 0 n )b; where V = [V r ; V z ] with V z an orthonormal basis of N (S), the null space of S <ref> [7, 8] </ref>. The primary purpose of this paper is to present some fast algorithms for computing the optimal commuting matrix pair by taking into account of the structure of the coefficient matrix in (1.1). <p> The results are given in Table 1. It is quite clear that when the clusters of the eigenvalues of A are getting smaller and smaller, the relative residuals are getting larger and larger. Example 2. We consider the problem of estimating azimuths and elevations using a square sensor arrays <ref> [7, 8] </ref>. The sensors are arranged in a square array of m fi m sensors, all equal and omni-directional. We use grid (1 : m; 1 : m) to represent the whole array.
References-found: 8

