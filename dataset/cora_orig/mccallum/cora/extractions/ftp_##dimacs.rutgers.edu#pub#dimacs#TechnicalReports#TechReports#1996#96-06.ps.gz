URL: ftp://dimacs.rutgers.edu/pub/dimacs/TechnicalReports/TechReports/1996/96-06.ps.gz
Refering-URL: http://dimacs.rutgers.edu/TechnicalReports/1996.html
Root-URL: http://www.cs.rutgers.edu
Email: hkl@cs.princeton.edu.  ret@cs.princeton.edu.  
Author: Haim Kaplan ; Robert E. Tarjan ; 
Keyword: Purely Functional Representations of Catenable Sorted Lists.  
Web: N00014-91-J-1463.  
Address: Princeton, NJ 08544 USA.  Princeton, NJ 08544 USA  
Affiliation: 2 Department of Computer Science, Princeton University,  Department of Computer Science, Princeton University,  and NEC Institute, Princeton, NJ. Research at Princeton University  
Note: by  Research supported by by the NSF, Grant No. CCR-8920505, the Office of Naval Research, Contract No. N00014-91-J-1463 and a United States-Israel Educational Foundation (USIEF) Fulbright Grant.  3 Permanent Member 4  partially supported by the NSF, Grant No. CCR-8920505 and the Office of Naval Research, Contract No.  DIMACS is a cooperative project of Rutgers University, Princeton University, AT&T Bell Laboratories and Bellcore. DIMACS is an NSF Science and Technology Center, funded under contract STC-91-19999; and also receives support from the New Jersey Commission on Science and Technology.  
Abstract: DIMACS Technical Report 96-06 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. S. Brodal. </author> <title> Fast Meldable Priority Queues. </title> <booktitle> WADS'95 proceedings, </booktitle> <publisher> LNCS 955, pp.282-290. </publisher>
Reference-contexts: Fix rightmost 2 or -1 by changing x2 to (x+1)0 or x (-1) to (x-1)1. This counter is similar to the spine list and the way it is maintained in Section 3, where 1,2,3,4-nodes correspond to the digits -1,0,1,2 respectively. Recently, in independent and distantly related work Brodal <ref> [1, 2] </ref> and Brodal and Okasaki [3] have designed heaps which can be melded in constant time. Interestingly, an essential ingredient in all the structures they describe is a redundant counter similar to the ones we use here.
Reference: [2] <author> G. S. Brodal. </author> <title> Worst Case Priority Queues. </title> <note> To appear in SODA'96 proceedings. </note>
Reference-contexts: Fix rightmost 2 or -1 by changing x2 to (x+1)0 or x (-1) to (x-1)1. This counter is similar to the spine list and the way it is maintained in Section 3, where 1,2,3,4-nodes correspond to the digits -1,0,1,2 respectively. Recently, in independent and distantly related work Brodal <ref> [1, 2] </ref> and Brodal and Okasaki [3] have designed heaps which can be melded in constant time. Interestingly, an essential ingredient in all the structures they describe is a redundant counter similar to the ones we use here.
Reference: [3] <author> G. S. Brodal and C. Okasaki. </author> <title> Optimal Purely Functional Priority Queues. </title> <note> Unpublished manuscript 1995. </note>
Reference-contexts: This counter is similar to the spine list and the way it is maintained in Section 3, where 1,2,3,4-nodes correspond to the digits -1,0,1,2 respectively. Recently, in independent and distantly related work Brodal [1, 2] and Brodal and Okasaki <ref> [3] </ref> have designed heaps which can be melded in constant time. Interestingly, an essential ingredient in all the structures they describe is a redundant counter similar to the ones we use here.
Reference: [4] <author> M. R. Brown and R. E. Tarjan. </author> <title> Design and analysis of a data structure for representing sorted lists, </title> <journal> Siam J. of Computing, </journal> <year> 1980, </year> <pages> 594-614. </pages>
Reference-contexts: 1 Introduction A finger search tree is a type of balanced search tree in which access in the vicinity of certain preferred positions, indicated by fingers, is especially efficient. Finger search trees were introduced by Guibas, McCreight, Plass and Roberts [17] and further developed by many other researchers <ref> [4, 18, 22, 32, 33, 34] </ref>. <p> This matches the lower bound for any comparison-based algorithm for the problem. The details were described by Brown and Tarjan in <ref> [4] </ref>. Our structure gives a way to turn their implementation into a purely functional one. Another application is a version of purely functional heaps that support delete-min in constant time and delete/insert of the dth item in O (log (d)) time. We actually propose three different implementations in this paper.
Reference: [5] <author> A. L. Buchsbaum, R. Sundar and R. E. Tarjan. </author> <title> Data structural bootstrapping, linear path compression, and catenable heap ordered double ended queues, </title> <booktitle> Proceedings of the 33rd IEEE Symp. on Foundations of Computer Science, </booktitle> <year> 1992, </year> <pages> 40-49. </pages>
Reference: [6] <author> A. L. Buchsbaum and R. E. Tarjan. </author> <title> Confluently persistent deques via data structural bootstrapping, </title> <booktitle> Proceedings of the 4th Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1993, </year> <pages> 155-164. </pages>
Reference-contexts: Driscoll, Sleator, and Tarjan [14] combined a tree representation with several additional ideas to obtain an implementation of persistent catenable stacks in which the k th operation takes O (log log k) time. Buchsbaum and Tarjan <ref> [6] </ref> used a recursive decomposition of trees to obtain two implementations of persistent catenable deques. <p> We describe an implementation for splitting at the dth item that takes O (log (minfd; n dg + 1) + 1) time. Furthermore, using a bootstrapping idea similar to the one used by Buchsbaum and Tarjan in <ref> [6] </ref>, we show how to implement catenate to run in O (log log (n s + 1) + 1) time, where n s is the size of the smaller list being catenated. <p> It is possible to use a version of the structure suggested by Buchsbaum and Tarjan in <ref> [6] </ref> to obtain a representation for sorted lists with constant time for catenate, but the search time degrades to O (log (n) log (d)) for the dth item. Acknowledgements We thank Ian Munro for pointing out to us the related redundant binary counting systems.
Reference: [7] <author> M. J. Clancy and D. E. Knuth. </author> <title> A programming and problem-solving seminar. </title> <institution> STAN-CS-77-606, Computer Science Department, Stanford University. </institution>
Reference-contexts: We have used 2,3 trees to simplify the presentation. The data structures described could be modified to use any kind of a,b-trees. Particularly interesting is a relation between the structures we have presented and redundant binary counting systems as described by Clancy and Knuth in <ref> [7] </ref>. Clancy and Knuth describe two counters. The first uses three digits 0,1,2. Any representation used must satisfy the requirement that any pair of 2 digits is separated by at least one 0 digit and the rightmost digit which is not 1 is 0. <p> Fix the rightmost two by changing x2 to (x+1)0 This binary counter is equivalent to the work allocation mechanism used in the representation of Section 2, where red, yellow, green correspond to the digits 2,1,0 respectively. The second counter suggested in <ref> [7] </ref> uses 4 digits -1,0,1,2. The representations used must not contain consecutive 1's between 2's or consecutive 0's between -1's and must contain either a 0 or -1 to the right of the rightmost 2 and a 1 or 2 to the right of the rightmost -1.
Reference: [8] <author> B. Chazelle. </author> <title> How to search in history, </title> <booktitle> Information and Control 64 (1985), </booktitle> <pages> 77-99. </pages>
Reference: [9] <author> B. Chazelle and L. J. Guibas. Fractional cascading: I. A. </author> <title> data structure technique. </title> <journal> Algorith-mica, </journal> <volume> 1(2) </volume> <pages> 133-62, </pages> <year> 1986. </year>
Reference-contexts: In particular, Driscoll, Sarnak, Sleator, and Tarjan [13] described how to make pointer-based structures fully persistent using a technique called node-splitting, which is related to fractional cascading <ref> [9] </ref> in a way that is not yet fully understood. Dietz [12] described a method for making array-based structures persistent. Additional references on persistence can be found in those papers.
Reference: [10] <author> R. Cole. </author> <title> Searching and storing similar lists, </title> <booktitle> Journal of Algorithms 7 (1986), </booktitle> <pages> 202-220. </pages>
Reference: [11] <author> D. P. Dobkin and J. I. Munro. </author> <title> Efficient uses of the past, </title> <booktitle> Journal of Algorithms 6 (1985), </booktitle> <pages> 455-465. </pages>
Reference: [12] <author> P. F. Dietz. </author> <title> Fully persistent arrays, </title> <booktitle> Proceedings of the 1989 Workshop on Algorithms and Data Structures, Ottawa Canada, Lecture Notes in Computer Science 382, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1989, </year> <pages> 67-74. </pages>
Reference-contexts: In particular, Driscoll, Sarnak, Sleator, and Tarjan [13] described how to make pointer-based structures fully persistent using a technique called node-splitting, which is related to fractional cascading [9] in a way that is not yet fully understood. Dietz <ref> [12] </ref> described a method for making array-based structures persistent. Additional references on persistence can be found in those papers. The general techniques in [12] and [13] fail to work on data structures that can be combined with each other rather than just be changed locally. <p> Dietz <ref> [12] </ref> described a method for making array-based structures persistent. Additional references on persistence can be found in those papers. The general techniques in [12] and [13] fail to work on data structures that can be combined with each other rather than just be changed locally. Perhaps the simplest and probably the most important example of combining data structures is catenation of lists.
Reference: [13] <author> J. R. Driscoll, N. Sarnak, D. Sleator, and R. Tarjan. </author> <title> Making data structures persistent, </title> <journal> Journal of Computer and Systems Science 38 (1989), </journal> <pages> 86-124. - 13 </pages> - 
Reference-contexts: In particular, Driscoll, Sarnak, Sleator, and Tarjan <ref> [13] </ref> described how to make pointer-based structures fully persistent using a technique called node-splitting, which is related to fractional cascading [9] in a way that is not yet fully understood. Dietz [12] described a method for making array-based structures persistent. Additional references on persistence can be found in those papers. <p> Dietz [12] described a method for making array-based structures persistent. Additional references on persistence can be found in those papers. The general techniques in [12] and <ref> [13] </ref> fail to work on data structures that can be combined with each other rather than just be changed locally. Perhaps the simplest and probably the most important example of combining data structures is catenation of lists.
Reference: [14] <author> J. Driscoll, D. Sleator, and R. Tarjan. </author> <title> Fully persistent lists with catenation. </title> <booktitle> In Proc. 2nd ACM-SIAM SYMP. on Discrete Algorithms, </booktitle> <pages> pages 89-99, </pages> <year> 1991. </year> <note> Submitted to J. ACM. </note>
Reference-contexts: A straightforward use of balanced trees gives a representation of persistent catenable deques in which an operation on a deque or deques of total size n takes O (log n) time. Driscoll, Sleator, and Tarjan <ref> [14] </ref> combined a tree representation with several additional ideas to obtain an implementation of persistent catenable stacks in which the k th operation takes O (log log k) time. Buchsbaum and Tarjan [6] used a recursive decomposition of trees to obtain two implementations of persistent catenable deques.
Reference: [15] <author> M. Felleisen. </author> <title> The Theory and Practice of First-Class Prompts. </title> <booktitle> Proc. 15th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> 180-190, </pages> <year> 1988. </year>
Reference: [16] <author> M. Felleisen, M. Wand, D. P. Friedman, and B. F. Duba. </author> <title> Abstract continuations: a mathematical semantics for handling full functional jumps. </title> <booktitle> Proc. Conference on Lisp and Functional Programming, </booktitle> <pages> 52-62, </pages> <year> 1988. </year>
Reference: [17] <author> L. J. Guibas, E. M. McCreight, M. F. Plass and J. R. Roberts. </author> <title> A new representation for linear lists, </title> <booktitle> Proceedings of the 9th Annual ACM Symp. on Theory of comput., </booktitle> <year> 1977, </year> <pages> 49-60. </pages>
Reference-contexts: 1 Introduction A finger search tree is a type of balanced search tree in which access in the vicinity of certain preferred positions, indicated by fingers, is especially efficient. Finger search trees were introduced by Guibas, McCreight, Plass and Roberts <ref> [17] </ref> and further developed by many other researchers [4, 18, 22, 32, 33, 34].
Reference: [18] <author> S. Huddleston. </author> <title> An efficient scheme for fast local updates in linear lists, </title> <institution> Dept. of Information and Computer Science, University of California, </institution> <address> Irvine, CA, </address> <year> 1981. </year>
Reference-contexts: 1 Introduction A finger search tree is a type of balanced search tree in which access in the vicinity of certain preferred positions, indicated by fingers, is especially efficient. Finger search trees were introduced by Guibas, McCreight, Plass and Roberts [17] and further developed by many other researchers <ref> [4, 18, 22, 32, 33, 34] </ref>. <p> For the analysis see [31, 20]. A couple of versions of finger search trees have been designed for which the bounds mentioned above for insert and delete are worst-case instead of amortized <ref> [32, 33, 34, 22, 18] </ref>. A persistent data structure is one in which a change to the structure can be made without destroying the old version, so that all versions of the structure persist and can be accessed or (possibly) modified.
Reference: [19] <author> G. F. Johnson and D. Duggan. </author> <title> Stores and partial continuations as first-class objects in a language and its environment. </title> <booktitle> Proc. 15th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> 158-168, </pages> <year> 1988. </year>
Reference: [20] <author> K. Mehlhorn. </author> <title> Data structures and efficient algorithms, Volume 1: Sorting and Searching, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1984. </year>
Reference-contexts: To catenate a list L 1 with n 1 elements and a list L 2 with n 2 elements takes O (1 + log (minfn 1 ; n 2 g + 1)) amortized time. For the analysis see <ref> [31, 20] </ref>. A couple of versions of finger search trees have been designed for which the bounds mentioned above for insert and delete are worst-case instead of amortized [32, 33, 34, 22, 18].
Reference: [21] <author> H. Kaplan and R. E. Tarjan. </author> <title> Persistent lists with catenation via recursive slow-down, </title> <booktitle> Proceedings of the 27th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1995, </year> <pages> 93-102. </pages>
Reference-contexts: Recently, Kaplan and Tarjan <ref> [21] </ref> have shown how to implement persistent catenable de-ques in O (1) worst-case time per operation. The structure used is recursive. The operations are implemented so that only one operation on the recursive substructure is needed for every two on the top level structure. <p> It is still open whether his approach can be extended to the double-ended problem. This paper is a continuation of the study of the power of functional programming and persistence and in particular efficient functional implementation of data structure combination such as catenation. We use the results of <ref> [21] </ref> and new ideas to implement a powerful set of operations on sorted lists. <p> We actually propose three different implementations in this paper. Our first representation, presented in Section 2, is a structure closely related to the noncatenable deque implementation presented in <ref> [21] </ref>. Its main advantage is its simplicity. This simplicity comes from the fact that a structure like the one in [21] is essential for the other representations we suggest as well. <p> We actually propose three different implementations in this paper. Our first representation, presented in Section 2, is a structure closely related to the noncatenable deque implementation presented in <ref> [21] </ref>. Its main advantage is its simplicity. This simplicity comes from the fact that a structure like the one in [21] is essential for the other representations we suggest as well. The second and the third representations are based on 2-3 finger search trees in which we relax the degree constraint on the spines and represent them as lists with a specific structure. <p> In Section 5 we summarize and point out a very interesting relation between our data structures and redundant binary number systems. 2 Generalized deques In this section we describe an implementation based on the the non-catenable deques of <ref> [21] </ref>. Let a 6-list be a list that can contain no more then 6 elements. For the purposes of this section prefix and suffix will denote 6-lists. Consider the following recursive representation of a list L for elements from a universe U . <p> The result of the fix is a new list L 0 represented by a stack S 0 (L 0 ). A detailed description of a fix step in a persistent setting appears in <ref> [21] </ref>. Inserting or deleting an item located at level i in a list L persistently will require: 1) Inserting or deleting an item from/to a height i 2-3 tree. <p> For example we could use either the catenable or the noncatenable structure of Kaplan and Tarjan <ref> [21] </ref>. Naive persistent implementations for catenate and split can always be added to a structure which supports the operations push,pop,eject and inject. Moreover, if push,pop,eject and inject can be carried out in constant time then the bounds for catenate and split are as required. <p> Moreover, if push,pop,eject and inject can be carried out in constant time then the bounds for catenate and split are as required. Note that one can traverse the lists of <ref> [21] </ref> in constant time per element. In this section we will assume that one of the representations above is used both for the spine lists and the f2,3g-lists. <p> A purely functional implementation for the spine lists and the f2-3g-lists. 2. A purely functional implementation for the operations insert,delete and split on 2,3-trees. The first can be found in <ref> [21] </ref>. All implementations discussed there are purely functional. Addition of naive split and catenate can also be done in a purely functional way. The second is achieved by implementing the operations on 2-3 trees so that the whole access path is copied. <p> The data structure is similar to the one described in Section 3. The main difference is that both the spine lists and the f2,3g-lists are represented either by the structure of Section 2 or the structure of Section 3 instead of the deques of <ref> [21] </ref>. The search keys of the elements are their heights. The lists represented in this way are faster to split but slower to catenate and allow efficient searches for nodes with particular heights. The implementation of all the operations is similar to the one described in Section 3.
Reference: [22] <author> S. R. Kosaraju. </author> <title> Localized search in sorted lists, </title> <booktitle> in Proc. 14th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 62-69, </pages> <year> 1981. </year>
Reference-contexts: 1 Introduction A finger search tree is a type of balanced search tree in which access in the vicinity of certain preferred positions, indicated by fingers, is especially efficient. Finger search trees were introduced by Guibas, McCreight, Plass and Roberts [17] and further developed by many other researchers <ref> [4, 18, 22, 32, 33, 34] </ref>. <p> For the analysis see [31, 20]. A couple of versions of finger search trees have been designed for which the bounds mentioned above for insert and delete are worst-case instead of amortized <ref> [32, 33, 34, 22, 18] </ref>. A persistent data structure is one in which a change to the structure can be made without destroying the old version, so that all versions of the structure persist and can be accessed or (possibly) modified.
Reference: [23] <author> Chris Okasaki. Amortization, </author> <title> lazy evaluation and purely functional catenable lists, </title> <booktitle> IEEE Symposium on Foundations of Computer Science, </booktitle> <month> October </month> <year> 1995, </year> <pages> pages 646-654. </pages>
Reference-contexts: Kaplan and Tarjan called this technique recursive slow-down. In independent work, Okasaki has obtained a persistent implementation of catenable stacks with a constant time bound per operation <ref> [23] </ref>. His structure is simpler than Kaplan and Tarjan's, but it has two technical drawbacks: It is not purely functional but uses memoization, and the time bound is amortized rather than worst case. It is still open whether his approach can be extended to the double-ended problem.
Reference: [24] <author> M. H. Overmars, </author> <title> Searching in the past, I. </title> <type> Technical Report RUU-CS-81-7, </type> <institution> Department of Computer Science, University of Utrecht, </institution> <address> Utricht, The Netherlands, </address> <year> 1981. </year>
Reference: [25] <author> M. H, Overmars, </author> <title> "Searching in the past, II: General Transforms," </title> <type> Technical Report RUU-CS-81-9, </type> <institution> Department of Computer Science, University of Utrecht, </institution> <address> Utricht, The Netherlands, </address> <year> 1981. </year>
Reference: [26] <author> T. Reps, T. Teitelbaum, and A. Demers, </author> <title> Incremental context-dependent analysis for language based editors, </title> <booktitle> ACM Transactions on Programming Languages and Systems 5 (1983), </booktitle> <pages> 449-477. </pages>
Reference: [27] <author> N. Sarnak. </author> <title> Persistent Data Structures. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Sciences, </institution> <address> New York University, </address> <year> 1986. </year>
Reference: [28] <author> N. Sarnak and R. E. Tarjan. </author> <title> Planar point location using persistent search trees. </title> <journal> Communications of the ACM, </journal> <volume> 29(7) </volume> <pages> 669-79, </pages> <year> 1986. </year>
Reference: [29] <author> D. Sitaram, M. Felleisen. </author> <title> Control delimiters and their hierarchies. LISP and Symbolic Computation: </title> <journal> An International Journal, </journal> <volume> 3 (1990), </volume> <pages> 67-99. - 14 </pages> - 
Reference: [30] <author> Hans-Jorg Stoss. </author> <title> K-band simulation von k-Kopf-Turing-maschinen. </title> <journal> Computing, </journal> <volume> 6(3) </volume> <pages> 309-317, </pages> <year> 1970. </year>
Reference: [31] <author> R. E. Tarjan, and C. J. Van Wyk. </author> <title> An O(n log log n)-time algorithm for triangulating a simple polygon, </title> <journal> Siam J. of Computing, </journal> <year> 1988, </year> <pages> 143-173. </pages>
Reference-contexts: Finger search trees were introduced by Guibas, McCreight, Plass and Roberts [17] and further developed by many other researchers [4, 18, 22, 32, 33, 34]. A common type of finger search tree, called a heterogeneous finger search tree in <ref> [31] </ref>, is an ordinary balanced search tree (like an a,b-tree for example) in which each node along the left path points to its parent instead of its left child, and each node along the right path points to its parent instead of its right child. <p> To catenate a list L 1 with n 1 elements and a list L 2 with n 2 elements takes O (1 + log (minfn 1 ; n 2 g + 1)) amortized time. For the analysis see <ref> [31, 20] </ref>. A couple of versions of finger search trees have been designed for which the bounds mentioned above for insert and delete are worst-case instead of amortized [32, 33, 34, 22, 18].
Reference: [32] <author> A. K. Tsakalidis. </author> <title> A simple implementation for localized search, </title> <institution> Computer Technology Institute, </institution> <address> P.O. Box 1122, 26110 Patras, Greece. </address> <year> 1990. </year>
Reference-contexts: 1 Introduction A finger search tree is a type of balanced search tree in which access in the vicinity of certain preferred positions, indicated by fingers, is especially efficient. Finger search trees were introduced by Guibas, McCreight, Plass and Roberts [17] and further developed by many other researchers <ref> [4, 18, 22, 32, 33, 34] </ref>. <p> For the analysis see [31, 20]. A couple of versions of finger search trees have been designed for which the bounds mentioned above for insert and delete are worst-case instead of amortized <ref> [32, 33, 34, 22, 18] </ref>. A persistent data structure is one in which a change to the structure can be made without destroying the old version, so that all versions of the structure persist and can be accessed or (possibly) modified. <p> We also believe that using the techniques developed here, the structures described in <ref> [32, 33, 34] </ref> could be modified to be purely functional and support fast catenation.
Reference: [33] <author> A. K. Tsakalidis. </author> <title> A optimal implementation for localized search, </title> <institution> A84/06 Fachbereich Ange-wante Mathematic und Informatik, Universitat des Saarlandes, Saarbrucken, West Germany, </institution> <year> 1984. </year>
Reference-contexts: 1 Introduction A finger search tree is a type of balanced search tree in which access in the vicinity of certain preferred positions, indicated by fingers, is especially efficient. Finger search trees were introduced by Guibas, McCreight, Plass and Roberts [17] and further developed by many other researchers <ref> [4, 18, 22, 32, 33, 34] </ref>. <p> For the analysis see [31, 20]. A couple of versions of finger search trees have been designed for which the bounds mentioned above for insert and delete are worst-case instead of amortized <ref> [32, 33, 34, 22, 18] </ref>. A persistent data structure is one in which a change to the structure can be made without destroying the old version, so that all versions of the structure persist and can be accessed or (possibly) modified. <p> We also believe that using the techniques developed here, the structures described in <ref> [32, 33, 34] </ref> could be modified to be purely functional and support fast catenation.
Reference: [34] <author> A. K. Tsakalidis. </author> <title> AVL-Trees for Localized Search, </title> <journal> Information and Control, </journal> <volume> 67, </volume> <year> 1985, </year> <pages> 173-194. - 15 </pages> - 
Reference-contexts: 1 Introduction A finger search tree is a type of balanced search tree in which access in the vicinity of certain preferred positions, indicated by fingers, is especially efficient. Finger search trees were introduced by Guibas, McCreight, Plass and Roberts [17] and further developed by many other researchers <ref> [4, 18, 22, 32, 33, 34] </ref>. <p> For the analysis see [31, 20]. A couple of versions of finger search trees have been designed for which the bounds mentioned above for insert and delete are worst-case instead of amortized <ref> [32, 33, 34, 22, 18] </ref>. A persistent data structure is one in which a change to the structure can be made without destroying the old version, so that all versions of the structure persist and can be accessed or (possibly) modified. <p> We also believe that using the techniques developed here, the structures described in <ref> [32, 33, 34] </ref> could be modified to be purely functional and support fast catenation.
References-found: 34

