URL: ftp://ftp.cs.unc.edu/pub/publications/techreports/92-041.ps.Z
Refering-URL: http://www.cs.unc.edu/Info/Publications/PHDAbstracts.html
Root-URL: http://www.cs.unc.edu
Title: c  
Author: Suresh Rajgopal 
Degree: All Rights Reserved  
Abstract-found: 0
Intro-found: 1
Reference: [Agr81] <author> V. Agrawal. </author> <title> An Information Theoretic Approach to Digital Fault Testing. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 582-587, </pages> <month> August </month> <year> 1981. </year>
Reference-contexts: In [TA89], Thearling and Abraham extended this idea to estimate testability at the function level. They use a measure called the information transfer coefficient (ITC) [Koo87] to enable relative testability measures to be computed as against the absolute measures computed by Dussault [Dus78]. Agrawal <ref> [Agr81] </ref> has also applied information theory to test pattern generation.
Reference: [Ake78] <author> S. B. Akers. </author> <title> Binary Decision Diagrams. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-27(6):509-516, </volume> <month> June </month> <year> 1978. </year>
Reference-contexts: The value of the function equals 1 if the terminal node is T , and 0 if the terminal node is F . Binary decision diagrams were first introduced in [Lee59], and further popularized by Akers <ref> [Ake78] </ref>. In [Bry86], Bryant introduced ordered binary decision diagrams (OBDDs), a restriction on the class of binary decision diagrams. In an ordered BDD a strict ordering is imposed on the input variables.
Reference: [AS87] <author> K. J. Antreich and M. H. Schulz. </author> <title> Accelerated Fault Simulation and Fault Grading in Combinational Circuits. </title> <journal> IEEE Transactions on Computer-Aided-Design, </journal> <volume> CAD-6(5):704-711, </volume> <month> Septem-ber </month> <year> 1987. </year>
Reference-contexts: Exact 1-probability computation in circuits with reconvergent fanout has been extensively studied in the areas of fault simulation <ref> [BPH84, MJ90, AS87] </ref>, test generation [HM86], and testability analysis [SDB84, SPA85, JA84]. 45 We begin by reviewing the idea of reconvergence. This is illustrated with a simple example in Figure 3.8. The gate-level implementation and a simple digraph model of a 3 input function is shown. <p> One of the ways to avoid the error in 1-probability computation due to reconvergent fanout is to apply a random patterns to the circuit and compute 1-probability at the internal nodes. A similar approach has been used in fault simulation and random test pattern generation <ref> [AS87, SB87] </ref>, where a circuit is simulated with a sampling of random patterns until it is capable of detecting a high percentage 100 * of faults with a high probability 1 ffi. Typically * &lt; 2,ffi &lt; 0:001. <p> A weighted sum of these values would yield the 1-probability at the internal node. The main drawback is that to compute the probability exactly an exponential number of input patterns is required. As mentioned earlier, exact 1-probability computation in reconvergent 47 fanout circuits has been studied extensively. <ref> [BPH84, MJ90, AS87, HM86, SDB84, SPA85, JA84] </ref>. Parker and McCluskey [PM75] described an algorithm for exact computation of 1-probabilities in circuits with or without reconvergent fanout. But the exact procedure can require exponential space and time.
Reference: [ASSP90] <author> P. Abouzeid, K. Sakouti, G. Saucier, and F. Poirot. </author> <title> Multilevel Synthesis minimizing the routing factor. </title> <booktitle> In 27th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 365-368, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Two approaches were illustrated. The first approach uses a communication matrix while the second approach, which is more efficient, uses cubes and cube overlaps [BHMSV84]. Another partially related approach is discussed in <ref> [ASSP90] </ref>. Here wiring complexity in a synthesized circuit is minimized by controlling input dependency with lexicographic expressions of a boolean function. <p> The variance in cube sizes affects the distance cubes need to travel before getting combined, and this might have an influence on the wiring factor. The recent work on using lexicographic ordering <ref> [PAS90, ASSP90] </ref> to minimize the routing factor in multilevel synthesis further supports this. We elaborate on this briefly. 177 In their research, Saucier et.al adopt a lexicographic factorization strat-egy to generate the multi-level factored form of a function, and show that this strategy reduces wiring complexity in the layout.
Reference: [BA92] <author> H. Bouzouzou and P. Abouzeid. </author> <title> Personal Communication. MCNC Logic Synthesis 91 Benchmarks - BDD Orderings, </title> <month> May </month> <year> 1992. </year>
Reference-contexts: Ordering source - [Min92]. asyl90: Uses the approach in [PAS90] where lexicographic partial ordering is followed by optimization via variable exchanging within a window to improve the size. Ordering source - <ref> [BA92] </ref>. spent: This is the spatial entropy based approach. Here we show the best sizes achieved over all approximations. In Section 4.5.2 and Section 4.5.3 we describe the effect of the various approximations in computing spatial entropy and the different strategies of combining the spatial entropy vector .
Reference: [BBR89] <author> K. S. Brace, R. E. Bryant, and R. L. Rudell. </author> <title> Efficient Implementation of a BDD Package. </title> <booktitle> In Proceedings of the 27th ACM/IEEE Design Automation Conference, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: Any BDD can be reduced to yield this unique representation by a simple efficient algorithm [Bry86]. Furthermore many Boolean functions have efficient, polynomial size BDD representations making it efficient to manipulate such functions and perform operations on them. This in turn yields efficient algorithms <ref> [Bry86, BBR89] </ref> for tasks such as: determining if an input assignment satisfies a function (satisfiability testing), testing the equivalence of two functions (tautology checking), and combining two functions with a boolean operation. These properties led to the early use of BDDs in combinational logic verification [Bry86]. <p> The 5 sources are: cmu91: Orderings from static attribute based heuristics discussed in <ref> [BBR89] </ref>. (Source - [Bra91]). uta91: Orderings using a collection of several static attribute based heuristics [BRM91]. (Source - [Kap91]).
Reference: [Ber91] <author> C. Leonard Berman. </author> <title> Circuit Width, Register Allocation and Ordered Binary Decision Diagrams. </title> <journal> IEEE Transactions on Computer-Aided-Design, </journal> <volume> CAD-10(8):1059-1065, </volume> <month> August </month> <year> 1991. </year>
Reference-contexts: The problem of generating an ordering for the primary input variables of a boolean function in order to build small BDDs is an important one and has been studied extensively <ref> [MWBV88, FFK88, MIY90, Ber91, ISY91, JPHS91, BRM91, MKR92] </ref>. The ordering strategies in most of the literature rely on a static examination of the circuit topology. <p> The best algorithm so far to arrive deterministically at an optimal ordering for a function has a time complexity of O (n 2 3 n ) [FS90]. Several efforts <ref> [Ber91, MWBV88, FFK88, MIY90, ISY91, JPHS91, MKR92] </ref> have been devoted to developing heuristics or approximate strategies for finding a good 59 60 ordering to build small BDDs. There are two broad directions along which these heuristics to solve the BDD ordering problem can be classified. <p> There are two broad directions along which these heuristics to solve the BDD ordering problem can be classified. In the first category are the approaches <ref> [MWBV88, Ber91, MIY90, JPHS91, FFK88, BRM91] </ref> that rely broadly on the idea that an input node further away from the output has a greater influence on the BDD size than an input node closer to the output. <p> An observability based approach is used in [MIY90]. Other approaches use techniques based on algebraic structure theory [JPHS91] and register allocation <ref> [Ber91] </ref>. All these strategies typically require a breadth or a depth first traversal of the network, and can consequently generate orderings in a short time. But on the other hand, they do not seem to be able to generate consistently good orderings.
Reference: [BHMSV84] <author> R. K. Brayton, G. Hatchel, C. McMullen, and A. Sangiovanni--Vincentelli. </author> <title> Logic Minimization Algorithms for VLSI Synthesis. </title> <publisher> Kluwer Academic Press: </publisher> <address> Boston, </address> <year> 1984. </year>
Reference-contexts: It is computationally intractable to find an exact optimal solution for all but the smallest problems. The problem of two-level and multi-level logical minimization is NP-complete <ref> [BHMSV84, Law64] </ref>. Placement and layout tools face an NP-complete problem in trying to embed a non-planar graph on a plane with minimum arc crossing [GJ79]. Complete gate level or transistor level simulation over all the input assignments takes exponential time. <p> Logic minimization and logic synthesis is another area of CAD where solutions are guided by static circuit structure information. One of the objectives here is to map a two-level boolean function representation into a set of gates (from some library) that occupies minimum area <ref> [BHMSV84, BM82, BRSVW87, LKB87, LBK88] </ref>. Ideally one would like to achieve this objective of minimum area with respect to not just the gates in the circuit but also the wiring between them [Sau92]. <p> Two approaches were illustrated. The first approach uses a communication matrix while the second approach, which is more efficient, uses cubes and cube overlaps <ref> [BHMSV84] </ref>. Another partially related approach is discussed in [ASSP90]. Here wiring complexity in a synthesized circuit is minimized by controlling input dependency with lexicographic expressions of a boolean function. <p> In larger complex functions the role of wire lengths becomes significant. Let us see how. Given a two-level or a multi-level representation of a logic function, it can be minimized (for literal count) using logic-minimizers like espresso <ref> [BHMSV84] </ref> along with one of the minimization scripts in the UC, Berkeley MISII/SIS (Sequential Interactive System) system [BRSVW87]. But since exact multi-level logic minimization requires exponential time [Law64], most minimizers use heuristics to find "near-optimal" solutions. <p> From the Lemma 1 on irredundancy, and Lemma 2 on primality. 2 Generating a minimum k-decomposition of monochromatic cubes for a given function is an NP-complete problem [GJ79] just as problems in traditional two-level logic minimization are NP-complete; generating all prime implicants is O ( 3 n n ) <ref> [BHMSV84] </ref>, while extraction of a minimum prime cover is NP-complete [GJ79]. For a given function, the minimum k-decomposition need not be a unique decomposition. For example, Figure 5.4 shows a decomposition of a function into monochromatic one/zero-cubes in two distinct ways. <p> It was proved earlier in this chapter that the k-decomposition of a function is equivalent to its two-level prime irredundant representation. Since computing the information content requires a k-decomposition of one/zero-cubes we use the output of a two-level minimizer espresso <ref> [BHMSV84] </ref> to generate these one/zero-cubes. The program espresso consists of a collection of heuristic algorithms for two-level minimization, and does not always guarantee a minimum two-level form. Thus for some functions our information content estimate does not use a minimum k-decomposition but an approximately minimal k-decomposition. <p> So we compute gate count only only for single output implementations. 157 5.6.2 Data Set The data set for the experiment is made up of two kinds of circuits, both described as boolean functions in the PLA format <ref> [BHMSV84] </ref>. The first set consists of several randomly generated single-output completely specified boolean functions of 4; 5; 6; 7; 8 and 9 input variables. The number of minterms in each of these functions and their positions in cube space was randomly generated.
Reference: [BI86] <author> D. Brand and V. S. Iyengar. </author> <title> Timing Analysis uusing Functional Relationship. </title> <booktitle> In IEEE ICCAD '86 Digest of Technical Papers, </booktitle> <pages> pages 126-130, </pages> <month> November </month> <year> 1986. </year>
Reference-contexts: Since this is expensive the static attributes are used to obtain a quick approximation of the actual delay in terms of gate connectivity and gate depth. A lot of the work in timing analysis now concentrates on eliminating false paths <ref> [BI86, MK89, DYG89, BMCM90, PCD89] </ref>. Logic minimization and logic synthesis is another area of CAD where solutions are guided by static circuit structure information.
Reference: [BM82] <author> R. K. Brayton and C. McMullen. </author> <title> The Decomposition and Factorization of Boolean Expressions. </title> <booktitle> In International Symposium on Circuits and Systems, </booktitle> <pages> pages 49-54, </pages> <month> May </month> <year> 1982. </year>
Reference-contexts: Logic minimization and logic synthesis is another area of CAD where solutions are guided by static circuit structure information. One of the objectives here is to map a two-level boolean function representation into a set of gates (from some library) that occupies minimum area <ref> [BHMSV84, BM82, BRSVW87, LKB87, LBK88] </ref>. Ideally one would like to achieve this objective of minimum area with respect to not just the gates in the circuit but also the wiring between them [Sau92]. <p> A lexicographic expression of a boolean function is a sum of product terms in which the input literals (that every product term depends upon) conform to an ordering called the reference order. This ordering is used to extract a set of lexicographically compatible kernels <ref> [BM82] </ref>. Kernel filtering computes the intersection of the extracted kernels to find shared parts amongst the functions. By tightly controlling this filtering process the logic cones can be prevented from intersecting with each other.
Reference: [BMCM90] <author> J. Benkoski, E. V. Meersch, L. J. M. Claesen, and H. D. Man. </author> <title> Timing Verification using Statically Sensitizable Paths. </title> <journal> IEEE Transactions on Computer-Aided-Design, </journal> <volume> CAD-9(10):1073-1083, </volume> <month> October </month> <year> 1990. </year>
Reference-contexts: Since this is expensive the static attributes are used to obtain a quick approximation of the actual delay in terms of gate connectivity and gate depth. A lot of the work in timing analysis now concentrates on eliminating false paths <ref> [BI86, MK89, DYG89, BMCM90, PCD89] </ref>. Logic minimization and logic synthesis is another area of CAD where solutions are guided by static circuit structure information.
Reference: [BPH84] <author> Franc. Brglez, P. Pownall, and R. Hum. </author> <title> Applications of Testability Analysis. </title> <booktitle> In Proceedings of the IEEE International Test Conference, </booktitle> <pages> pages 705-712, </pages> <year> 1984. </year>
Reference-contexts: In such a case the input vectors that represent various input combinations are dynamic attributes that capture circuit usage as they propagate through the various nodes. Testability analysis <ref> [BPH84, SDB84, JA84, LBdGG87] </ref> which is sometimes viewed as an alternative to fault simulation, is another problem that relies on a dynamic attribute. The objective here is to project the cost of testing by predicting the number of random test patterns needed to achieve high fault coverage. <p> Exact 1-probability computation in circuits with reconvergent fanout has been extensively studied in the areas of fault simulation <ref> [BPH84, MJ90, AS87] </ref>, test generation [HM86], and testability analysis [SDB84, SPA85, JA84]. 45 We begin by reviewing the idea of reconvergence. This is illustrated with a simple example in Figure 3.8. The gate-level implementation and a simple digraph model of a 3 input function is shown. <p> A weighted sum of these values would yield the 1-probability at the internal node. The main drawback is that to compute the probability exactly an exponential number of input patterns is required. As mentioned earlier, exact 1-probability computation in reconvergent 47 fanout circuits has been studied extensively. <ref> [BPH84, MJ90, AS87, HM86, SDB84, SPA85, JA84] </ref>. Parker and McCluskey [PM75] described an algorithm for exact computation of 1-probabilities in circuits with or without reconvergent fanout. But the exact procedure can require exponential space and time.
Reference: [Bra91] <author> K. </author> <title> Brace. </title> <type> Personal Communication. BDD Orderings, </type> <month> June </month> <year> 1991. </year>
Reference-contexts: The criteria for good variable orders is determined by the size of the resultant BDD the smaller the BDD size, the better the ordering. We compare the BDD sizes generated by the spatial entropy approach with those generated by other heuristics <ref> [Bra91, BRM91, ISY91, MKR92, PAS90] </ref>. The accuracy of the spatial entropy attribute, as defined in Chapter 3, is affected by factors such as logic minimization, wire length and reconvergent fanout. The study of the effect of some of these factors on variable orderings is another objective of this experiment. <p> The 5 sources are: cmu91: Orderings from static attribute based heuristics discussed in [BBR89]. (Source - <ref> [Bra91] </ref>). uta91: Orderings using a collection of several static attribute based heuristics [BRM91]. (Source - [Kap91]). The orderings in uta91 are the best known orderings based on static-attribute sources. minwid91: Orderings generated using an optimization intensive approach discussed above. uta92: Orderings also generated using an optimization intensive approach.
Reference: [BRM91] <author> K. M. Butler, D. E. Ross, and M. R. Mercer. </author> <title> Heuristics to Compute Variable Orderings for Efficient Manipulation of Ordered Binary Decision Diagrams. </title> <booktitle> In Proceedings of the IEEE/ACM Design Automation Conference, </booktitle> <pages> pages 417-420, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: In variable ordering for binary decision diagrams (BDDs), the level or depth of a node in a circuit has been used as a static attribute in various heuristics to generate orderings <ref> [BRM91] </ref>. All these CAD tasks are similar in that they are solved using static attributes defined at a given level of abstraction. These attributes do provide useful information about circuit structure and structural connectivity, and they are fairly easy to compute; but they have their drawbacks. <p> The problem of generating an ordering for the primary input variables of a boolean function in order to build small BDDs is an important one and has been studied extensively <ref> [MWBV88, FFK88, MIY90, Ber91, ISY91, JPHS91, BRM91, MKR92] </ref>. The ordering strategies in most of the literature rely on a static examination of the circuit topology. <p> There are two broad directions along which these heuristics to solve the BDD ordering problem can be classified. In the first category are the approaches <ref> [MWBV88, Ber91, MIY90, JPHS91, FFK88, BRM91] </ref> that rely broadly on the idea that an input node further away from the output has a greater influence on the BDD size than an input node closer to the output. <p> All these strategies typically require a breadth or a depth first traversal of the network, and can consequently generate orderings in a short time. But on the other hand, they do not seem to be able to generate consistently good orderings. Butler et al. <ref> [BRM91] </ref> believe that a single algorithm might be inadequate for this purpose; so they use a suite of heuristics to solve the problem. The second category consists of approaches that are more recent [FMK91, ISY91, MKR92]. They formulate the ordering problem as an optimization problem. <p> The criteria for good variable orders is determined by the size of the resultant BDD the smaller the BDD size, the better the ordering. We compare the BDD sizes generated by the spatial entropy approach with those generated by other heuristics <ref> [Bra91, BRM91, ISY91, MKR92, PAS90] </ref>. The accuracy of the spatial entropy attribute, as defined in Chapter 3, is affected by factors such as logic minimization, wire length and reconvergent fanout. The study of the effect of some of these factors on variable orderings is another objective of this experiment. <p> The 5 sources are: cmu91: Orderings from static attribute based heuristics discussed in [BBR89]. (Source - [Bra91]). uta91: Orderings using a collection of several static attribute based heuristics <ref> [BRM91] </ref>. (Source - [Kap91]). The orderings in uta91 are the best known orderings based on static-attribute sources. minwid91: Orderings generated using an optimization intensive approach discussed above. uta92: Orderings also generated using an optimization intensive approach.
Reference: [BRSVW87] <author> R. K. Brayton, R. Rudell, A. Sangiovani-Vincentelli, and A. Wang. </author> <title> MIS: A Multiple-Level Logic Optimization System. </title> <journal> IEEE Transactions on CAD, </journal> <volume> CAD-6:1062-1081, </volume> <month> Novem-ber </month> <year> 1987. </year>
Reference-contexts: A static attribute is a structural attribute that is derived from a static examination of the circuit topology. It does not require the circuit to be exercised with data. For example, consider logic minimization and logic synthesis. The attribute used to guide two-level and multi-level logic minimization <ref> [BRSVW87] </ref> is minimum literal count (or gate count) that can be obtained by static examination of the boolean function description or the circuit topology. The phases of technology mapping [LBK88] and netlist optimization [TSB91] also use a static attribute (gate depth) for critical path removal and delay reduction. <p> Logic minimization and logic synthesis is another area of CAD where solutions are guided by static circuit structure information. One of the objectives here is to map a two-level boolean function representation into a set of gates (from some library) that occupies minimum area <ref> [BHMSV84, BM82, BRSVW87, LKB87, LBK88] </ref>. Ideally one would like to achieve this objective of minimum area with respect to not just the gates in the circuit but also the wiring between them [Sau92]. <p> Let us see how. Given a two-level or a multi-level representation of a logic function, it can be minimized (for literal count) using logic-minimizers like espresso [BHMSV84] along with one of the minimization scripts in the UC, Berkeley MISII/SIS (Sequential Interactive System) system <ref> [BRSVW87] </ref>. But since exact multi-level logic minimization requires exponential time [Law64], most minimizers use heuristics to find "near-optimal" solutions. The optimality of such a solution is usually measured with respect to the minimal literal count in the multi-level implementation. <p> There is also a mix of circuit functions adder, priority encoder, random logic, ALUs etc.. These circuits have also been used as the primary data set for comparing various BDD ordering strategies for combinational circuits. We use the UC Berkeley MISII/SIS system <ref> [BRSVW87] </ref> to further minimize these circuits and then translate them into the VPNR format. Table 4.1 illustrates some characteristics of these circuits. LgSynth91 Circuits: These are benchmark circuits compiled at the MCNC Logic Synthesis Workshop (in May 1991). These circuits are in two-level and multi-level form. <p> This is then used to compute the information content measure. The spatial entropy S is computed along the lines of the experiment in Chapter 4. First the two-level PLA representation is minimized via SIS <ref> [BRSVW87] </ref> and a multi-level technology mapped implementation in VPNR [KB88] is generated. This is then used by the spatial entropy computation program spent to generate spatial entropy measures.
Reference: [Bry86] <author> R. E. Bryant. </author> <title> Graph based algorithms for Boolean function manipulation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35(8):667-691, </volume> <month> August </month> <year> 1986. </year>
Reference-contexts: Then we introduce the variable ordering problem, motivate it and summarize related research in this area. 4.1.1 Binary Decision Diagrams A binary decision diagram (BDD) <ref> [Bry86] </ref> is a directed acyclic graph (DAG) representation (V; E) of a Boolean function f : I ! f1; 0g. The input variables, I, of the function are represented by nodes in the graph . <p> The value of the function equals 1 if the terminal node is T , and 0 if the terminal node is F . Binary decision diagrams were first introduced in [Lee59], and further popularized by Akers [Ake78]. In <ref> [Bry86] </ref>, Bryant introduced ordered binary decision diagrams (OBDDs), a restriction on the class of binary decision diagrams. In an ordered BDD a strict ordering is imposed on the input variables. <p> In particular, for a given variable ordering the smallest BDD for a function is unique. Any BDD can be reduced to yield this unique representation by a simple efficient algorithm <ref> [Bry86] </ref>. Furthermore many Boolean functions have efficient, polynomial size BDD representations making it efficient to manipulate such functions and perform operations on them. <p> Any BDD can be reduced to yield this unique representation by a simple efficient algorithm [Bry86]. Furthermore many Boolean functions have efficient, polynomial size BDD representations making it efficient to manipulate such functions and perform operations on them. This in turn yields efficient algorithms <ref> [Bry86, BBR89] </ref> for tasks such as: determining if an input assignment satisfies a function (satisfiability testing), testing the equivalence of two functions (tautology checking), and combining two functions with a boolean operation. These properties led to the early use of BDDs in combinational logic verification [Bry86]. <p> These properties led to the early use of BDDs in combinational logic verification <ref> [Bry86] </ref>. Since then they have been applied in several other areas of design automation research: sequential verification, test pattern generation, logic synthesis, and optimization.
Reference: [Bry91] <author> R. E. Bryant. </author> <title> On the Complexity of VLSI implementations and Graph Representations of Boolean functions with applications 185 to Integer Multiplication. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-40(2):205-213, </volume> <month> Feb </month> <year> 1991. </year>
Reference-contexts: Figure 4.2 shows a BDD of the function represented in Figure 4.1, but with a different ordering, = fa 1 ; a 2 ; a 3 ; b 1 ; b 2 ; b 3 g. The size of the BDD has increased substantially. Bryant <ref> [Bry91] </ref> has shown that while for certain classes of Boolean functions (integer multipliers) an efficient (polynomial size) BDD representation does not exist regardless of variable ordering, there are still a large class of boolean functions that have efficient BDD representations. <p> Multipliers are also functions with two-way communication and with equal participation from each input variable, causing wiring skew to be absent. In addition the family of (integer) multiplier functions have been proven to have exponential BDD sizes regardless of ordering <ref> [Bry91] </ref>. So the changes caused by wire lengths can only be minor perturbations. Let us now look at decoders. Table 4.11 (page 93) shows that decoders are immune to any kind of wire length approximation. Their BDD sizes are the same regardless of wire length information.
Reference: [CA90] <author> K-T Cheng and V. D. Agrawal. </author> <title> An Entropy Measure for the Complexity of Multi-Output Boolean Functions. </title> <booktitle> In 27th ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 302-305, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: He showed that the complexity of a boolean function can be expressed in terms of an entropy-based definition of (computational) work performed by the combinational network. In 1977 Pippenger further refined this entropy definition to handle don't cares in the function [Pip77]. More recently in <ref> [CA90] </ref>, the entropy formulation was generalized to multi-output functions, both completely specified 20 functions and partially specified ones. They also showed statistically that using the literal count as a measure of circuit area a linear relationship can be observed between entropy and average number of literals in a multi-level implementation. <p> He illustrated his results for single-output networks using diodes and modules as the implementation technology. This was followed by work on entropy based definitions of complexity by several researchers <ref> [Hel72, CF73, Mas78, Pip77, CA90] </ref> with bounds on attributes like diode counts, gate counts and literal counts. These were discussed in detail in Chapter 2.
Reference: [CF73] <author> R. W. Cook and M. J. Flynn. </author> <title> Logical Network Cost and Entropy. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-22:823-826, </volume> <month> September </month> <year> 1973. </year>
Reference-contexts: We begin by reviewing work in these areas. 2.3.2 The Entropy function in CAD One of the first applications of information theory was to use the information-theoretic definition of entropy to predict boolean function complexity. The relationship between function complexity and entropy was first conjectured by Cook and Flynn <ref> [CF73] </ref>. The complexity of a boolean function is expressed by the cost of implementing the function as a combinational network. <p> He illustrated his results for single-output networks using diodes and modules as the implementation technology. This was followed by work on entropy based definitions of complexity by several researchers <ref> [Hel72, CF73, Mas78, Pip77, CA90] </ref> with bounds on attributes like diode counts, gate counts and literal counts. These were discussed in detail in Chapter 2. <p> But the cost of implementing A is more than the cost of implementing F , using the literal count measure. The reason for this is the spatial arrangement of the 1s in the cube space. This was also observed in [Kel68] and <ref> [CF73] </ref>. Their experimental data showed that the maximum-cost data point (for a function of n variables with u 1s in the cube space) appeared when none of the 1s could be covered, while the minimum-cost data point appeared when all the 1s were optimally covered.
Reference: [Dus78] <author> J. Dussault. </author> <title> A Testability Measure. </title> <booktitle> In Proceedings of the 1978 Semiconductor Test Conference, </booktitle> <pages> pages 113-116, </pages> <month> October </month> <year> 1978. </year>
Reference-contexts: They also showed statistically that using the literal count as a measure of circuit area a linear relationship can be observed between entropy and average number of literals in a multi-level implementation. Information theory has also found application as a testability measure. This was first proposed by Dussault <ref> [Dus78] </ref>. He presented observability and controllability measures based on information theory for gate level circuits. In [TA89], Thearling and Abraham extended this idea to estimate testability at the function level. <p> In [TA89], Thearling and Abraham extended this idea to estimate testability at the function level. They use a measure called the information transfer coefficient (ITC) [Koo87] to enable relative testability measures to be computed as against the absolute measures computed by Dussault <ref> [Dus78] </ref>. Agrawal [Agr81] has also applied information theory to test pattern generation.
Reference: [DYG89] <author> D. H. C. Du, S. H. C. Yen, and S. Ghanta. </author> <title> On the General False Path Problem in Timing Analysis. </title> <booktitle> In Proceedings of the 26th IEEE/ACM Design Automation Conference, </booktitle> <year> 1989. </year>
Reference-contexts: Since this is expensive the static attributes are used to obtain a quick approximation of the actual delay in terms of gate connectivity and gate depth. A lot of the work in timing analysis now concentrates on eliminating false paths <ref> [BI86, MK89, DYG89, BMCM90, PCD89] </ref>. Logic minimization and logic synthesis is another area of CAD where solutions are guided by static circuit structure information.
Reference: [FFK88] <author> M. Fujita, H. Fujisawa, and N. Kawato. </author> <title> Evaluation and improvements of Boolean comparison method based on binary decision diagrams. </title> <booktitle> In Proceedings of the IEEE International Conference on Computer-Aided Design, </booktitle> <month> November </month> <year> 1988. </year>
Reference-contexts: The problem of generating an ordering for the primary input variables of a boolean function in order to build small BDDs is an important one and has been studied extensively <ref> [MWBV88, FFK88, MIY90, Ber91, ISY91, JPHS91, BRM91, MKR92] </ref>. The ordering strategies in most of the literature rely on a static examination of the circuit topology. <p> The best algorithm so far to arrive deterministically at an optimal ordering for a function has a time complexity of O (n 2 3 n ) [FS90]. Several efforts <ref> [Ber91, MWBV88, FFK88, MIY90, ISY91, JPHS91, MKR92] </ref> have been devoted to developing heuristics or approximate strategies for finding a good 59 60 ordering to build small BDDs. There are two broad directions along which these heuristics to solve the BDD ordering problem can be classified. <p> There are two broad directions along which these heuristics to solve the BDD ordering problem can be classified. In the first category are the approaches <ref> [MWBV88, Ber91, MIY90, JPHS91, FFK88, BRM91] </ref> that rely broadly on the idea that an input node further away from the output has a greater influence on the BDD size than an input node closer to the output. <p> For instance, [MWBV88] uses node levels and transitive fan-in (TFI) depths as static attributes on a multi-level graph model of the implementation. The decreasing fanout count in the graph is used <ref> [FFK88] </ref> as a heuristic in an approach that generates orderings with the objective of minimizing the number of crossings of a net. An observability based approach is used in [MIY90]. Other approaches use techniques based on algebraic structure theory [JPHS91] and register allocation [Ber91].
Reference: [FMK91] <author> M. Fujita, Y. Matsunaga, and T. Kakuda. </author> <title> On variable ordering of Binary Decision Diagrams for the application of multi-level logic synthesis. </title> <booktitle> In Proceedings of the European Conference on Design Automation, </booktitle> <pages> pages 50-54, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: Butler et al. [BRM91] believe that a single algorithm might be inadequate for this purpose; so they use a suite of heuristics to solve the problem. The second category consists of approaches that are more recent <ref> [FMK91, ISY91, MKR92] </ref>. They formulate the ordering problem as an optimization problem. For a given ordering a cost function is defined to estimate BDD sizes.
Reference: [FS90] <author> S. J. Friedman and K. J. Supowit. </author> <title> Finding the Optimal Variable Ordering for Binary Decision Diagrams. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-39(5):710-713, </volume> <month> May </month> <year> 1990. </year>
Reference-contexts: Complete gate level or transistor level simulation over all the input assignments takes exponential time. The best known deterministic algorithm to arrive at an optimal variable ordering for a BDD is O (3 n ) <ref> [FS90] </ref>. This means that efficient solutions to all these problems are heuristics or approximate strategies that use information derived from the circuit to achieve desired criteria. <p> The best algorithm so far to arrive deterministically at an optimal ordering for a function has a time complexity of O (n 2 3 n ) <ref> [FS90] </ref>. Several efforts [Ber91, MWBV88, FFK88, MIY90, ISY91, JPHS91, MKR92] have been devoted to developing heuristics or approximate strategies for finding a good 59 60 ordering to build small BDDs. There are two broad directions along which these heuristics to solve the BDD ordering problem can be classified.
Reference: [GJ79] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: </title>
Reference-contexts: The problem of two-level and multi-level logical minimization is NP-complete [BHMSV84, Law64]. Placement and layout tools face an NP-complete problem in trying to embed a non-planar graph on a plane with minimum arc crossing <ref> [GJ79] </ref>. Complete gate level or transistor level simulation over all the input assignments takes exponential time. The best known deterministic algorithm to arrive at an optimal variable ordering for a BDD is O (3 n ) [FS90]. <p> Compute the Manhattan wire lengths between grid points. This placement problem itself is NP-complete <ref> [GJ79] </ref>, but approximations can be obtained. Sometimes instead of point-to-point lengths between nodes only a lumped length value may be available at the node. Lumped wire lengths introduce inaccuracies at multiple fanout nodes. <p> Proof. From the Lemma 1 on irredundancy, and Lemma 2 on primality. 2 Generating a minimum k-decomposition of monochromatic cubes for a given function is an NP-complete problem <ref> [GJ79] </ref> just as problems in traditional two-level logic minimization are NP-complete; generating all prime implicants is O ( 3 n n ) [BHMSV84], while extraction of a minimum prime cover is NP-complete [GJ79]. For a given function, the minimum k-decomposition need not be a unique decomposition. <p> on primality. 2 Generating a minimum k-decomposition of monochromatic cubes for a given function is an NP-complete problem <ref> [GJ79] </ref> just as problems in traditional two-level logic minimization are NP-complete; generating all prime implicants is O ( 3 n n ) [BHMSV84], while extraction of a minimum prime cover is NP-complete [GJ79]. For a given function, the minimum k-decomposition need not be a unique decomposition. For example, Figure 5.4 shows a decomposition of a function into monochromatic one/zero-cubes in two distinct ways.
References-found: 25

