URL: ftp://ftp.cis.upenn.edu/pub/treebank/doc/arpa94.ps.gz
Refering-URL: http://www.cis.upenn.edu/~treebank/home.html
Root-URL: 
Title: THE PENN TREEBANK: ANNOTATING PREDICATE ARGUMENT STRUCTURE  
Author: Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz, Robert MacIntyre, Ann Bies, Mark Ferguson, Karen Katz, Britta Schasberger 
Address: Philadelphia, PA, USA  
Affiliation: Department of Computer and Information Science University of Pennsylvania  
Abstract: The Penn Treebank has recently implemented a new syntactic annotation scheme, designed to highlight aspects of predicate-argument structure. This paper discusses the implementation of crucial aspects of this new annotation scheme. It incorporates a more consistent treatment of a wide range of grammatical phenomena, provides a set of coin-dexed null elements in what can be thought of as "underlying" position for phenomena such as wh-movement, passive, and the subjects of infinitival constructions, provides some non-context free annotational mechanism to allow the structure of discontinuous constituents to be easily recovered, and allows for a clear, concise tagging system for some semantic roles. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Black, E., Abney, S., Flickenger, F., Grishman, R., Har-rison, P., Hindle, D., Ingria, R., Jelinek, F., Klavans, J., Liberman, M., Marcus, M., Roukos, S., Santorini, B., and Strzalkowski, T., </author> <year> 1991. </year> <title> A procedure for quantitatively comparing the syntactic coverage of English grammars. </title> <booktitle> In Proceedings of the Fourth DARPA Speech and Natural Language Workshop, </booktitle> <month> February </month> <year> 1991. </year>
Reference-contexts: Such a representation could serve as both a starting point for the kinds of SEMEVAL representations now being discussed as a basis for evaluation of human language technology within the ARPA HLT program, and as a basis for "glass box" evaluation of parsing technology. The ongoing effort <ref> [1] </ref> to develop a standard objective methodology to compare parser outputs across widely divergent grammatical frameworks has now resulted in a widely supported standard for parser comparison.
Reference: 2. <author> Black, E., Jelinek, F., Lafferty, J., Magerman, D.M., Mercer, R., and Roukos, S. </author> <year> 1992. </year> <title> Towards history-based grammars: Using Richer Models for Probabilistic parsing. </title> <booktitle> In Proceedings of the 31th Annual Meeting of the Association for Computational Linguistics. </booktitle>
Reference: 3. <author> Brill, E., Marcus, M., </author> <year> 1992. </year> <title> Automatically acquiring phrase structure using distributional analysis. </title> <booktitle> In Proceedings of the DARPA Speech and Natural Language Workshop, </booktitle> <month> February </month> <year> 1992. </year>
Reference: 4. <author> Brill, E., </author> <year> 1993. </year> <title> Automatic grammar induction and parsing free text: a transformation-based approach. </title> <booktitle> In Proceedings of the 31th Annual Meeting of the Association for Computational Linguistics. </booktitle>
Reference: 5. <author> Francis, W., </author> <year> 1964. </year> <title> A standard sample of present-day English for use with digital computers. Report to the U.S Office of Education on Cooperative Research Project No. </title> <institution> E-007. Brown University, Providence. </institution>
Reference-contexts: Also included is a skeletally parsed version of the Brown corpus, the classic million word balanced corpus of American English <ref> [5, 6] </ref>. hand-retagged using the Penn Treebank tagset. The level of syntactic analysis annotated during this phase of this project was an extended and somewhat modified form of the skeletal analysis which has been produced by the tree-banking effort in Lancaster, England [7].
Reference: 6. <author> Francis, W. and Kucera, H., </author> <year> 1982. </year> <title> Frequency analysis of English usage. Lexicon and grammar. </title> <publisher> Houghton Mi*in, </publisher> <address> Boston. </address>
Reference-contexts: Also included is a skeletally parsed version of the Brown corpus, the classic million word balanced corpus of American English <ref> [5, 6] </ref>. hand-retagged using the Penn Treebank tagset. The level of syntactic analysis annotated during this phase of this project was an extended and somewhat modified form of the skeletal analysis which has been produced by the tree-banking effort in Lancaster, England [7].
Reference: 7. <author> Garside, R., Leech, G., and Sampson, G., </author> <year> 1987. </year> <title> The computational analysis of English. A corpus-based approach. </title> <publisher> Longman, London. </publisher>
Reference-contexts: The level of syntactic analysis annotated during this phase of this project was an extended and somewhat modified form of the skeletal analysis which has been produced by the tree-banking effort in Lancaster, England <ref> [7] </ref>.
Reference: 8. <author> Hindle, D., and Rooth, M., </author> <year> 1993. </year> <title> Structural Ambiguity and Lexical Relations. </title> <journal> Computational Linguistics, </journal> <volume> Vol 19. </volume>
Reference: 9. <author> D. Magerman and M. Marcus, </author> <year> 1991. </year> <title> PEARL | A Probabilistic Chart Parser, </title> <booktitle> In Proceedings, Fifth Conference of the European Chapter of the Association for Computational Linguistics (EACL), </booktitle> <address> Berlin, </address> <month> April </month> <year> 1991. </year>
Reference: 10. <author> Marcus, M., Santorini, B., Marcinkiewicz, M.A., </author> <year> 1993. </year> <title> Building a large annotated corpus of English: the Penn Treebank. </title> <journal> Computational Linguistics, </journal> <volume> Vol 19. </volume>
Reference-contexts: 1. INTRODUCTION During the first phase of the The Penn Treebank project <ref> [10] </ref>, ending in December 1992, 4.5 million words of text were tagged for part-of-speech, with about two-thirds of this material also annotated with a skeletal syntactic bracketing. All of this material has been hand corrected after processing by automatic tools.
Reference: 11. <author> Quirk, R., Greenbaum, S., Leech, G., and Svartvik, J., </author> <year> 1985. </year> <title> A comprehensive grammar of the English language, </title> <publisher> Longman, London. </publisher>
Reference-contexts: These cases are tagged as -CLR (for CLosely Related); they are to be semantically analyzed as adjuncts. This class is an experiment in the current tagging; constituents marked -CLR typically correspond to Quirk et al's <ref> [11] </ref> class of predication adjuncts. At the moment, we distinguish a handful of semantic roles: direction, location, manner, purpose, and time, as well as the syntactic roles of surface subject, logical subject, and (implicit in the syntactic structure) first and second verbal objects. 5.
References-found: 11

