URL: http://theory.lcs.mit.edu/~sivan/implicit.ps.gz
Refering-URL: http://theory.lcs.mit.edu/~sivan/papers.html
Root-URL: 
Email: sivan@mit.edu  
Title: An Efficient Out-of-Core Algorithm for Implicit Time-Stepping Schemes in One Dimension  
Author: Sivan Toledo 
Keyword: out-of-core algorithms, implicit time-stepping schemes.  Abbreviated title: Out-of-core implicit time-stepping algorithm  
Web: 65M06, 65Y10, 65Y20  
Note: AMS subject classifications:  
Date: August 26, 1994  
Address: 545 Technology Square Cambridge, MA 02139  
Affiliation: MIT Lab for Computer Science  
Abstract: This paper describes an efficient out-of-core algorithm for implicit time stepping schemes in one dimension. The algorithm can achieve a reduction in the amount of I/O over a conventional algorithm by a factor of maxf p M ; minfM; M 2 =ngg where M is the size of primary memory and n is the size of the state vector. We have implemented the algorithm and found it to be more than 5 times faster than a conventional algorithm on a workstation when the problem does not fit into the workstation's primary memory. In numerical experiments, the algorithm exhibited good numerical stability.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.-W. Hong and H.T. Kung. </author> <title> I/O complexity: the red-blue pebble game. </title> <booktitle> In Proceedings of the 13th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 326-333, </pages> <year> 1981. </year>
Reference-contexts: We ran the algorithm on two iterative implicit time-stepping schemes arising from the discretization of the one-dimensional heat equation with zero Dirichlet boundary conditions in the interval <ref> [0; 1] </ref>, @ 2 u (x; t) @u (x; t) and with the initial condition x (0) = 2x if x &lt; 1=2 1 2x otherwise : We have used both a backward-time-center-space discretization which leads to a system of equations of the form t (t) t (t) t (t) (t1) <p> This design choice simplified the implementation while still providing excellent performance. Careful scheduling of the computation can result in an efficient out-of-core algorithm for an explicit time-stepping schemes. Such methods are well known, and were analyzed by Hong and Kung <ref> [1] </ref>. Such a method can carry out T iterations of an explicit time-stepping scheme on a d-dimensional mesh with fi (nT ) work and only fi (n) I/O's on a computer with M words of primary memory if T = O (M 1=d =d).
Reference: [2] <author> C.E. Leiserson, S. Rao, and S. Toledo. </author> <title> Efficient out-of-core algorithms for linear relaxation using blocking covers. </title> <booktitle> In Proceedings of the 34rd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 704-713, </pages> <address> Palo Alto, California, </address> <month> November </month> <year> 1993. </year> <note> Submittted for journal publication. </note>
Reference-contexts: A naive way to implement an out-of-core algorithm is to use the in-core algorithm, and perform I/O as needed, using an automatic paging algorithm for example. However, Leiserson, Rao, and Toledo <ref> [2, Theorem 10] </ref> proved a lower bound on the amount of I/O required for a large class of iterative algorithms which includes the iterative invocation of a tridiagonal solver discussed above. <p> In this paper we propose an algorithm which requires much less I/O. Our algorithm can beat the lower bound since it is based on the idea of blockers, first proposed in <ref> [2] </ref>. The algorithm does not invoke a tridiagonal solver on problems of size n, but only on much smaller problems. The main contribution of this paper is a method for decomposing a problem of size n into k decoupled problems of size b (n + 1)=kc 1. <p> Hong and Kung proved that this method is optimal. Using the same proof technique, Leiserson, Rao, and Toledo <ref> [2] </ref> proved that no reduction in I/O relative to the naive algorithm is possible for implicit schemes, if one is using a tridiagonal solver on problems of size n 2M .
Reference: [3] <author> J. </author> <title> Noye. Finite difference techniques for partial differential equations. </title> <editor> In J. Noye, editor, </editor> <booktitle> Computational Techniques for Differential Equations, </booktitle> <pages> pages 95-354. </pages> <publisher> Elsevier, </publisher> <year> 1984. </year>
Reference-contexts: We refer to n as the size of the time-stepping scheme. Equation (1) can express a wide range of implicit time-stepping schemes for time-dependent partial differential equations in one spatial dimension, including backward-time-center-space and Crank-Nicolson (see, for example, <ref> [3] </ref> or [4]) with both Dirichlet and Neumann boundary conditions. A computer with a large primary memory can implement the scheme (1) by invoking a tridi-agonal solver in every step.
Reference: [4] <author> G.D. Smith. </author> <title> Numerical Solutions of Patial Differential Equations,2nd edition. </title> <publisher> Oxford University Press, </publisher> <year> 1978. </year>
Reference-contexts: We refer to n as the size of the time-stepping scheme. Equation (1) can express a wide range of implicit time-stepping schemes for time-dependent partial differential equations in one spatial dimension, including backward-time-center-space and Crank-Nicolson (see, for example, [3] or <ref> [4] </ref>) with both Dirichlet and Neumann boundary conditions. A computer with a large primary memory can implement the scheme (1) by invoking a tridi-agonal solver in every step.
Reference: [5] <author> L.H. Thomas. </author> <title> Elliptic problems in linear difference equations over a network. </title> <type> Technical report, </type> <institution> Watson Scientific Computing Laboratory, Columbia University, </institution> <year> 1949. </year> <month> 13 </month>
Reference-contexts: The amount of work involved in the computation is fi (nT ), assuming the use of an efficient variant of Gaussian Elimination as a tridiagonal solver (this variant is sometimes known as Thomas's algorithm <ref> [5] </ref>). fl This research was supported in part by the Advanced Research Projects Agency under Grant N00014-91-J-1698. 1 If the computation does not fit into the primary memory of the computer, a so-called "out-of--core" method must be used.
References-found: 5

