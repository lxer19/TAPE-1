URL: http://www.almaden.ibm.com/cs/quest/papers/pods97_trans.ps
Refering-URL: http://www.almaden.ibm.com/cs/quest/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: gunopulo@almaden.ibm.com  roni@das.harvard.edu  Heikki.Mannila@cs.helsinki.fi  Hannu.Toivonen@cs.helsinki.fi  
Title: Data mining, Hypergraph Transversals, and Machine Learning Extended abstract  
Author: Dimitrios Gunopulos Roni Khardon Heikki Mannila Hannu Toivonen 
Address: RC K55/B1 650 Harry Rd. San Jose CA 95120 USA  Cambridge, MA 02138 USA  P.O. Box 26, FIN-00014 Helsinki Finland  P.O. Box 26, FIN-00014 Helsinki Finland  
Affiliation: IBM Almaden  Aiken Computation Laboratory Harvard University  University of Helsinki Department of Computer Science  University of Helsinki Department of Computer Science  
Abstract: Several data mining problems can be formulated as problems of finding maximally specific sentences that are interesting in a database. We first show that this problem has a close relationship with the hypergraph transversal problem. We then analyze two algorithms that have been previously used in data mining, proving upper bounds on their complexity. The first algorithm is useful when the maximally specific interesting sentences are "small". We show that this algorithm can also be used to efficiently solve a special case of the hypergraph transversal problem, improving on previous results. The second algorithm utilizes a subroutine for hypergraph transversals, and is applicable in more general situations, with complexity close to a lower bound for the problem. We also relate these problems to the model of exact learning in computational learning theory, and use the correspondence to derive some corollaries. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In Proceedings of ACM SIGMOD Conference on Management of Data (SIGMOD'93), </booktitle> <pages> pages 207 - 216, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: We consider problems that can be formulated as finding maximal elements in a lattice of sentences or patterns. Examples of such problems include finding frequent sets (the essential stage in finding association rules) <ref> [1] </ref>, finding episodes from sequences [21], and finding keys or inclusion dependencies from relation instances [17]. It has been previously observed [19] that the problem of enumerating maximal elements is intimately connected to the hypergraph transversal problem [8]. <p> For some applications, q (r; ') could mean that ' is true or almost true in r, or that ' defines (in some way) an interesting subgroup of r. The approach has been used in various forms for example in <ref> [1, 2, 6, 7, 13, 14, 17, 21] </ref>. Obviously, if L is infinite and q (r; ') is satisfied for infinitely many sentences, (an explicit representation of) T h (L; r; q) cannot be computed. For the above formulation to make sense, the language L has to be defined carefully.
Reference: [2] <author> R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A. I. Verkamo. </author> <title> Fast discovery of association rules. </title> <editor> In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining, </booktitle> <pages> pages 307 - 328. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1996. </year>
Reference-contexts: We utilize this fact in analyzing two algorithms that have been used in practical applications of data mining. Several variations of the levelwise algorithm have been successfully applied to problems of data mining <ref> [2, 19, 20, 21] </ref>. This algorithm computes the maximal elements by walking up in the lattice of interesting sentences, one level at a time. <p> For some applications, q (r; ') could mean that ' is true or almost true in r, or that ' defines (in some way) an interesting subgroup of r. The approach has been used in various forms for example in <ref> [1, 2, 6, 7, 13, 14, 17, 21] </ref>. Obviously, if L is infinite and q (r; ') is satisfied for infinitely many sentences, (an explicit representation of) T h (L; r; q) cannot be computed. For the above formulation to make sense, the language L has to be defined carefully. <p> The generalization is similar for negative and positive borders. Some straightforward lower bounds for the problem of finding all frequent sets are given in <ref> [2, 20] </ref>. Now we consider the problem of lower bounds in a more realistic model of computation. The main effort in finding interesting sets is in the step where the interestingness of subgroups are evaluated against the database. Thus we consider the following model of computation. <p> In the next sections we make use of this result to study the complexity of the data mining problem, computing hypergraph transversals, and also exact learning of monotone functions. 4 The Levelwise Algorithm Several variants of the levelwise algorithm have been used before <ref> [2, 20, 21] </ref>. The algorithm solves the problem MaxTh by simply finding all interesting statements, i.e., the whole theory T h (L; r; q) going bottom up. The method is as follows: Algorithm 9 The levelwise algorithm for finding all interesting statements. <p> Note that the computation to determine the candidate collection does not involve the database (Step 5). For example, in computations of frequent sets Step 5 used only a negligible amount of time <ref> [2] </ref>. Clearly, by definition, the algorithm finds the maximal interesting sentences. Moreover, we show that under certain conditions the algorithm does not take too much time. The following theorem is immediate.
Reference: [3] <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342, </pages> <month> Apr. </month> <year> 1988. </year>
Reference-contexts: We show that there is a direct correspondence between this abstracted data mining problem studied here and the problem of learning monotone functions with membership queries <ref> [3] </ref>. Thus we show that the learning problem is embedded in the problem of mining association rules. We use this relation to derive corollaries (mainly) for learning theory. <p> The task of the learner is to find a representation for a Boolean function that is identical (or approximates) f . In particular we will consider the model of exact learning with membership queries <ref> [3] </ref>. A membership query oracle M Q (f ) allows the learner to ask for the value of f on a certain point. That is, given x 2 f0; 1g n , M Q (f ) returns the value f (x). <p> As a corollary of Theorem 2 we get a lower bound: Corollary 27 Any algorithm that learns monotone functions with membership queries must use at least jDN F (f )j+ jCN F (f )j queries. While the bound is not surprising, it explains the lower bound given by Angluin <ref> [3] </ref>. It is shown there that an algorithm may need to take time exponential in the DNF size when not allowed CNF size as a parameter. Indeed the CNF size of the function used to show the lower bound is exponential. (The lower bound in [3] is, however, more complex since <p> lower bound given by Angluin <ref> [3] </ref>. It is shown there that an algorithm may need to take time exponential in the DNF size when not allowed CNF size as a parameter. Indeed the CNF size of the function used to show the lower bound is exponential. (The lower bound in [3] is, however, more complex since the learner has access to several additional oracles.) On the other hand, by using Theorem 21 we see that with membership queries alone one can come close to this lower bound.
Reference: [4] <author> C. Berge. </author> <title> Hypergraphs. Combinatorics of Finite Sets. </title> <publisher> North-Holland Publishing Company, </publisher> <address> Amsterdam, </address> <note> 3rd edition, </note> <year> 1973. </year>
Reference-contexts: The collection of minimal transversals of H is denoted by Tr (H). It is a hypergraph on R. Problem 5 (HTR) Given a hypergraph H, construct Tr (H). For more information on hypergraphs see <ref> [4] </ref>. The computational problem of computing transversals appears in various branches of computer science; a comprehensive study of this problem is given by [8]. The HTR problem also appears in several forms in databases.
Reference: [5] <author> N. H. Bshouty, R. Cleve, R. Gavalda, S. Kannan, and C. Tamon. </author> <title> Oracles and queries that are sufficient for exact learning. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 52 </volume> <pages> 421-433, </pages> <year> 1996. </year>
Reference-contexts: We use this relation to derive corollaries (mainly) for learning theory. Interestingly, an algorithm similar to the dualize and advance algorithm (though slightly more complicated) has been previously suggested in learning theory in an analysis of worst case complexity of learning <ref> [5] </ref>, and can be used to yield a similar result. To summarize, we analyze and clarify the properties of two data mining algorithms that have already proved useful in several applications. This is also used to show that a new subproblem of hypergraph transversals is solvable. <p> The running time of the algorithm is polynomial in n and T (jCN F (f )j; jDN F (f )j). We note that this corollary can be derived from a more general construction in <ref> [5] </ref> (Theorem 18) that studies the complexity of learning, and uses NP-Oracles. For monotone functions, the NP-Oracle used there, can be replaced with a procedure for HTR, yielding a similar result. This has been previously observed [24]. <p> Acknowledgments We wish to thank Eyal Kushilevitz for pointing out the work in <ref> [5] </ref>, and Christino Tamon for useful discussions.
Reference: [6] <author> L. De Raedt and M. Bruynooghe. </author> <title> A theory of clausal discovery. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pages 1058 - 1053, </pages> <address> Chambery, France, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: For some applications, q (r; ') could mean that ' is true or almost true in r, or that ' defines (in some way) an interesting subgroup of r. The approach has been used in various forms for example in <ref> [1, 2, 6, 7, 13, 14, 17, 21] </ref>. Obviously, if L is infinite and q (r; ') is satisfied for infinitely many sentences, (an explicit representation of) T h (L; r; q) cannot be computed. For the above formulation to make sense, the language L has to be defined carefully.
Reference: [7] <author> L. De Raedt and S. Dzeroski. </author> <title> First-order jk-clausal theories are PAC-learnable. </title> <journal> Artificial Intelligence, </journal> <volume> 70:375 - 392, </volume> <year> 1994. </year>
Reference-contexts: For some applications, q (r; ') could mean that ' is true or almost true in r, or that ' defines (in some way) an interesting subgroup of r. The approach has been used in various forms for example in <ref> [1, 2, 6, 7, 13, 14, 17, 21] </ref>. Obviously, if L is infinite and q (r; ') is satisfied for infinitely many sentences, (an explicit representation of) T h (L; r; q) cannot be computed. For the above formulation to make sense, the language L has to be defined carefully.
Reference: [8] <author> T. Eiter and G. Gottlob. </author> <title> Identifying the minimal transversals of a hypergraph and related problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 24(6):1278 - 1304, </volume> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: It has been previously observed [19] that the problem of enumerating maximal elements is intimately connected to the hypergraph transversal problem <ref> [8] </ref>. We utilize this fact in analyzing two algorithms that have been used in practical applications of data mining. Several variations of the levelwise algorithm have been successfully applied to problems of data mining [2, 19, 20, 21]. <p> It is a hypergraph on R. Problem 5 (HTR) Given a hypergraph H, construct Tr (H). For more information on hypergraphs see [4]. The computational problem of computing transversals appears in various branches of computer science; a comprehensive study of this problem is given by <ref> [8] </ref>. The HTR problem also appears in several forms in databases. In particular, the problem of translating between a set of functional dependencies and their corresponding Armstrong relation [16, 17] is at least as hard as this problem and equivalent to it in special cases [8]. <p> this problem is given by <ref> [8] </ref>. The HTR problem also appears in several forms in databases. In particular, the problem of translating between a set of functional dependencies and their corresponding Armstrong relation [16, 17] is at least as hard as this problem and equivalent to it in special cases [8]. Further discussion of these issues is given by [12, 18]. Notice that in general the output for this problem may be exponentially larger than its input, and thus the question is whether it can be solved in time polynomial in both its input size and output size. <p> That is, an algorithm solves the problem in incremental T (I; i) time if the i'th transversal is computed in time T (I; i). For further discussion and other variations see <ref> [8] </ref>. The exact complexity of the HTR problem is yet unknown. A sub-exponential solution for the problem has been recently discovered [10], and several special cases can be solved in polynomial time [8, 22]. We improve on one of these results here. Now we return to the verification problem. <p> For further discussion and other variations see [8]. The exact complexity of the HTR problem is yet unknown. A sub-exponential solution for the problem has been recently discovered [10], and several special cases can be solved in polynomial time <ref> [8, 22] </ref>. We improve on one of these results here. Now we return to the verification problem. Given S L, we have to determine whether S = M T h (L; r; q) holds using as few evaluations of the interestingness predicate as possible. <p> Set non-transversals to be "interesting" and use the algorithm. We get that the negative border is the required transversal hypergraph. 2 This improves on previous result by <ref> [8] </ref> (Theorem 5.4) that show that this is possible for constant k (and uses a brute force enumeration algorithm using property (i) above). Notice that the levelwise algorithm does not use the structure original hypergraph directly.
Reference: [9] <author> U. M. Fayyad, G. Piatetsky-Shapiro, and P. Smyth. </author> <title> From data mining to knowledge discovery: An overview. </title> <editor> In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining, pages 1 -34. </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1996. </year>
Reference-contexts: 1 Introduction Data mining, or knowledge discovery in databases, aims at finding useful information from large masses of data; see <ref> [9] </ref> for a useful summary. The field of data mining has recently expanded considerably: both applications and methods have been developed at a fast pace.
Reference: [10] <author> M. Fredman and L. Khachiyan. </author> <title> On the complexity of dualization of monotone disjunctive normal forms. </title> <journal> Journal of Algorithms, </journal> <volume> 21 </volume> <pages> 618-628, </pages> <year> 1996. </year>
Reference-contexts: For further discussion and other variations see [8]. The exact complexity of the HTR problem is yet unknown. A sub-exponential solution for the problem has been recently discovered <ref> [10] </ref>, and several special cases can be solved in polynomial time [8, 22]. We improve on one of these results here. Now we return to the verification problem. <p> Then a single run of an HTR subroutine suffices. The current result holds even if the access to the database is restricted to "Is-interesting" queries. Recently, Fredman and Khachiyan <ref> [10] </ref> presented an incremental algorithm for the HTR problem with time complexity T (I; i) = (I+i) O (log (I+i)) . <p> This has been previously observed [24]. The algorithm that results is similar to the dualize and advance algorithm but is slightly more complicated. Here again using the result of Fredman and Khachiyan <ref> [10] </ref> we can derive a sub-exponential learning algorithm for this problem. Corollary 29 There is a learning algorithm for monotone functions with membership queries.
Reference: [11] <author> D. Gunopulos, H. Mannila, and S. Saluja. </author> <title> Discovering all most specific sentences by randomized algorithms. </title> <booktitle> In ICDT'97, </booktitle> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: We also analyze the algorithm Dualize and Advance. This algorithm was motivated by the relation to hypergraph transversals, and was recently used in an empirical study of data mining problems <ref> [11] </ref>. We show that the algorithm has sub-exponential complexity, coming close to a lower bound for the problem, and that improving this bound hinges on the complexity of the hypergraph transversal problem (which is an open problem). <p> A variant of this Dualize and Advance algorithm has recently been used by <ref> [11] </ref>, but no complexity analysis was provided there. This algorithm is far more applicable than the levelwise method, as this does not investigate all interesting statements, but rather jumps more or less directly to maximal ones.
Reference: [12] <author> R. Khardon. </author> <title> Translating between Horn representations and their characteristic models. </title> <journal> Journal of AI Research, </journal> <volume> 3 </volume> <pages> 349-372, </pages> <year> 1995. </year>
Reference-contexts: In particular, the problem of translating between a set of functional dependencies and their corresponding Armstrong relation [16, 17] is at least as hard as this problem and equivalent to it in special cases [8]. Further discussion of these issues is given by <ref> [12, 18] </ref>. Notice that in general the output for this problem may be exponentially larger than its input, and thus the question is whether it can be solved in time polynomial in both its input size and output size. <p> We note that for the case of functional dependencies with fixed right hand side, and for keys, even simpler algorithms can be used <ref> [16, 12] </ref>. In this case one can access the database and directly compute Bd (M T h) (according to the appropriate representation as sets, this corresponds to the so called agree sets of the relation). Then a single run of an HTR subroutine suffices.
Reference: [13] <author> J.-U. Kietz and S. Wrobel. </author> <title> Controlling the complexity of learning in logic through syntactic and task-oriented models. </title> <editor> In S. Muggleton, editor, </editor> <booktitle> Inductive Logic Programming, </booktitle> <pages> pages 335 - 359. </pages> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1992. </year>
Reference-contexts: For some applications, q (r; ') could mean that ' is true or almost true in r, or that ' defines (in some way) an interesting subgroup of r. The approach has been used in various forms for example in <ref> [1, 2, 6, 7, 13, 14, 17, 21] </ref>. Obviously, if L is infinite and q (r; ') is satisfied for infinitely many sentences, (an explicit representation of) T h (L; r; q) cannot be computed. For the above formulation to make sense, the language L has to be defined carefully.
Reference: [14] <author> W. Kloesgen. </author> <title> Efficient discovery of interesting statements in databases. </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> 4(1):53 - 69, </volume> <year> 1995. </year>
Reference-contexts: For some applications, q (r; ') could mean that ' is true or almost true in r, or that ' defines (in some way) an interesting subgroup of r. The approach has been used in various forms for example in <ref> [1, 2, 6, 7, 13, 14, 17, 21] </ref>. Obviously, if L is infinite and q (r; ') is satisfied for infinitely many sentences, (an explicit representation of) T h (L; r; q) cannot be computed. For the above formulation to make sense, the language L has to be defined carefully.
Reference: [15] <author> P. Langley. </author> <title> Elements of Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1995. </year>
Reference-contexts: For the above formulation to make sense, the language L has to be defined carefully. As already considered by Mitchell [23], we use a specialization/generalization relation between sentences. (See, e.g., <ref> [15] </ref> for an overview of approaches to related problems.) A specialization relation is a partial order on the sentences in L. We say that ' is more general than , if ' ; we also say that is more specific than '.
Reference: [16] <author> H. Mannila and K.-J. Raiha. </author> <title> Design by example: An application of Armstrong relations. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 33(2):126 - 141, </volume> <year> 1986. </year>
Reference-contexts: The HTR problem also appears in several forms in databases. In particular, the problem of translating between a set of functional dependencies and their corresponding Armstrong relation <ref> [16, 17] </ref> is at least as hard as this problem and equivalent to it in special cases [8]. Further discussion of these issues is given by [12, 18]. <p> The following example shows that there are cases where the size of M T h (L; r; q) and its negative border are small, but in an intermediate step the size of the negative border of C i may be large. Example 19 <ref> [16] </ref> Consider the case where M T h = M T h (L; r; q) includes all sets of size n 2, and Bd (M T h) thus includes all sets of size n 1. <p> We note that for the case of functional dependencies with fixed right hand side, and for keys, even simpler algorithms can be used <ref> [16, 12] </ref>. In this case one can access the database and directly compute Bd (M T h) (according to the appropriate representation as sets, this corresponds to the so called agree sets of the relation). Then a single run of an HTR subroutine suffices.
Reference: [17] <author> H. Mannila and K.-J. Raiha. </author> <title> Design of Relational Databases. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Wok-ingham, UK, </address> <year> 1992. </year>
Reference-contexts: We consider problems that can be formulated as finding maximal elements in a lattice of sentences or patterns. Examples of such problems include finding frequent sets (the essential stage in finding association rules) [1], finding episodes from sequences [21], and finding keys or inclusion dependencies from relation instances <ref> [17] </ref>. It has been previously observed [19] that the problem of enumerating maximal elements is intimately connected to the hypergraph transversal problem [8]. We utilize this fact in analyzing two algorithms that have been used in practical applications of data mining. <p> For some applications, q (r; ') could mean that ' is true or almost true in r, or that ' defines (in some way) an interesting subgroup of r. The approach has been used in various forms for example in <ref> [1, 2, 6, 7, 13, 14, 17, 21] </ref>. Obviously, if L is infinite and q (r; ') is satisfied for infinitely many sentences, (an explicit representation of) T h (L; r; q) cannot be computed. For the above formulation to make sense, the language L has to be defined carefully. <p> This result, simple as it seems, gives as a corollary a result about finding functional dependencies that in the more specific setting is not easy to find; cf. <ref> [17, 19] </ref>. Similarly, the corresponding verification problem requires at least this number of queries. Problem 3 (Verification) Given L, r, q, and a set S L. Verify that S = M T h (L; r; q). <p> The HTR problem also appears in several forms in databases. In particular, the problem of translating between a set of functional dependencies and their corresponding Armstrong relation <ref> [16, 17] </ref> is at least as hard as this problem and equivalent to it in special cases [8]. Further discussion of these issues is given by [12, 18].
Reference: [18] <author> H. Mannila and K.-J. Raiha. </author> <title> Algorithms for inferring functional dependencies. </title> <journal> Data & Knowledge Engineering, </journal> <volume> 12(1):83 - 99, </volume> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: In particular, the problem of translating between a set of functional dependencies and their corresponding Armstrong relation [16, 17] is at least as hard as this problem and equivalent to it in special cases [8]. Further discussion of these issues is given by <ref> [12, 18] </ref>. Notice that in general the output for this problem may be exponentially larger than its input, and thus the question is whether it can be solved in time polynomial in both its input size and output size.
Reference: [19] <author> H. Mannila and H. Toivonen. </author> <title> On an algorithm for finding all interesting sentences. </title> <booktitle> In Cybernetics and Systems, Volume II, The Thirteenth European Meeting on Cybernetics and Systems Research, </booktitle> <pages> pages 973 - 978, </pages> <address> Vi-enna, Austria, </address> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: Examples of such problems include finding frequent sets (the essential stage in finding association rules) [1], finding episodes from sequences [21], and finding keys or inclusion dependencies from relation instances [17]. It has been previously observed <ref> [19] </ref> that the problem of enumerating maximal elements is intimately connected to the hypergraph transversal problem [8]. We utilize this fact in analyzing two algorithms that have been used in practical applications of data mining. <p> We utilize this fact in analyzing two algorithms that have been used in practical applications of data mining. Several variations of the levelwise algorithm have been successfully applied to problems of data mining <ref> [2, 19, 20, 21] </ref>. This algorithm computes the maximal elements by walking up in the lattice of interesting sentences, one level at a time. <p> This definitely holds in finite lattices, and can be useful in more general cases as well. In this paper we consider the following problem. Problem 1 (MaxTh) Given L, r, and q, what is the complexity of computing M T h (L; r; q). It is easy to show <ref> [19] </ref> that finding frequent sets, episodes, keys, or inclusion dependencies are instances of the problem MaxTh. Especially for the problem of finding keys (or, more generally, functional dependencies) from relation instances the current framework has lots of connections to previous work. <p> We describe here the problem of computing frequent sets, and use this example throughout the paper. Descriptions of the other mappings can be found in <ref> [19] </ref>. Association Rules and Frequent Sets: Given a 0/1 relation r with attributes R, an association rule is an expression X ) A, where X R and A 2 R. <p> For each frequent set Z, and for each A 2 Z one can test the confidence of the rule Z n A ) A. 3 Complexity of Finding all Interesting Sentences To study the complexity of the generation problem we introduce some notation and basic results that appeared previously in <ref> [19] </ref>. Consider a set S of sentences from L such that S is closed downwards under the relation , i.e., if 2 S and ' , then ' 2 S. <p> Thus we consider the following model of computation. Assume the only way of getting information from the database is by asking questions of the form Is-interesting Is the sentence ' interesting, i.e., does q (r; ') hold? Theorem 2 <ref> [19] </ref> Any algorithm for computing T h (L; r; q) that accesses the data using only Is-interesting queries must use at least jBd (T h (L; r; q))j queries. <p> This result, simple as it seems, gives as a corollary a result about finding functional dependencies that in the more specific setting is not easy to find; cf. <ref> [17, 19] </ref>. Similarly, the corresponding verification problem requires at least this number of queries. Problem 3 (Verification) Given L, r, q, and a set S L. Verify that S = M T h (L; r; q). <p> Similarly, the corresponding verification problem requires at least this number of queries. Problem 3 (Verification) Given L, r, q, and a set S L. Verify that S = M T h (L; r; q). Corollary 4 <ref> [19] </ref> Given L, r, q, and a set S L, deter mining whether S = M T h (L; r; q) requires in the worst case at least jBd (S)j evaluations of the predicate q, and it can be solved using exactly this number of evaluations of q. <p> Theorem 7 <ref> [19] </ref> f 1 (Tr (H (S))) = Bd (S). Example 8 Consider the problem of computing frequent sets, where R = fA; B; C; Dg, and let S = fABC; BDg, where we use a shorthand notation for sets, e.g., we represent fA; B; Cg by ABC.
Reference: [20] <author> H. Mannila, H. Toivonen, and A. I. Verkamo. </author> <title> Efficient algorithms for discovering association rules. In Knowledge Discovery in Databases, </title> <booktitle> Papers from the 1994 AAAI Workshop (KDD'94), </booktitle> <pages> pages 181 - 192, </pages> <address> Seattle, Washington, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: We utilize this fact in analyzing two algorithms that have been used in practical applications of data mining. Several variations of the levelwise algorithm have been successfully applied to problems of data mining <ref> [2, 19, 20, 21] </ref>. This algorithm computes the maximal elements by walking up in the lattice of interesting sentences, one level at a time. <p> The generalization is similar for negative and positive borders. Some straightforward lower bounds for the problem of finding all frequent sets are given in <ref> [2, 20] </ref>. Now we consider the problem of lower bounds in a more realistic model of computation. The main effort in finding interesting sets is in the step where the interestingness of subgroups are evaluated against the database. Thus we consider the following model of computation. <p> In the next sections we make use of this result to study the complexity of the data mining problem, computing hypergraph transversals, and also exact learning of monotone functions. 4 The Levelwise Algorithm Several variants of the levelwise algorithm have been used before <ref> [2, 20, 21] </ref>. The algorithm solves the problem MaxTh by simply finding all interesting statements, i.e., the whole theory T h (L; r; q) going bottom up. The method is as follows: Algorithm 9 The levelwise algorithm for finding all interesting statements.
Reference: [21] <author> H. Mannila, H. Toivonen, and A. I. Verkamo. </author> <title> Discovering frequent episodes in sequences. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD'95), </booktitle> <pages> pages 210 - 215, </pages> <address> Montreal, Canada, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: We consider problems that can be formulated as finding maximal elements in a lattice of sentences or patterns. Examples of such problems include finding frequent sets (the essential stage in finding association rules) [1], finding episodes from sequences <ref> [21] </ref>, and finding keys or inclusion dependencies from relation instances [17]. It has been previously observed [19] that the problem of enumerating maximal elements is intimately connected to the hypergraph transversal problem [8]. <p> We utilize this fact in analyzing two algorithms that have been used in practical applications of data mining. Several variations of the levelwise algorithm have been successfully applied to problems of data mining <ref> [2, 19, 20, 21] </ref>. This algorithm computes the maximal elements by walking up in the lattice of interesting sentences, one level at a time. <p> For some applications, q (r; ') could mean that ' is true or almost true in r, or that ' defines (in some way) an interesting subgroup of r. The approach has been used in various forms for example in <ref> [1, 2, 6, 7, 13, 14, 17, 21] </ref>. Obviously, if L is infinite and q (r; ') is satisfied for infinitely many sentences, (an explicit representation of) T h (L; r; q) cannot be computed. For the above formulation to make sense, the language L has to be defined carefully. <p> In particular, the lattice must be finite, and its size must be a power of 2. Note that frequent sets, functional dependencies with a fixed right-hand sides, and inclusion dependencies are easily representable as sets; the same holds for monotone Boolean functions. However, the language of <ref> [21] </ref> used for discovering episodes in sequences does not satisfy this condition. Given S, we can compute Bd + (S) without looking at the data r at all: simply find the most special sentences in S. <p> In particular the mapping f must be surjective, that is, cover all of P (R). Otherwise, after computing the transversal, a set may not have an inverse mapping to be applied in the last transformation in the theorem. This is indeed the case in the episodes of <ref> [21] </ref>. As we have seen, for languages representable as sets the notions of negative border and the minimal transversals give the same results. <p> In the next sections we make use of this result to study the complexity of the data mining problem, computing hypergraph transversals, and also exact learning of monotone functions. 4 The Levelwise Algorithm Several variants of the levelwise algorithm have been used before <ref> [2, 20, 21] </ref>. The algorithm solves the problem MaxTh by simply finding all interesting statements, i.e., the whole theory T h (L; r; q) going bottom up. The method is as follows: Algorithm 9 The levelwise algorithm for finding all interesting statements.
Reference: [22] <author> N. Misra and L. Pitt. </author> <title> On bounded-degree hypergraph transversals. </title> <type> Manuscript., </type> <year> 1995. </year>
Reference-contexts: For further discussion and other variations see [8]. The exact complexity of the HTR problem is yet unknown. A sub-exponential solution for the problem has been recently discovered [10], and several special cases can be solved in polynomial time <ref> [8, 22] </ref>. We improve on one of these results here. Now we return to the verification problem. Given S L, we have to determine whether S = M T h (L; r; q) holds using as few evaluations of the interestingness predicate as possible.
Reference: [23] <author> T. M. Mitchell. </author> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18:203 - 226, </volume> <year> 1982. </year>
Reference-contexts: Obviously, if L is infinite and q (r; ') is satisfied for infinitely many sentences, (an explicit representation of) T h (L; r; q) cannot be computed. For the above formulation to make sense, the language L has to be defined carefully. As already considered by Mitchell <ref> [23] </ref>, we use a specialization/generalization relation between sentences. (See, e.g., [15] for an overview of approaches to related problems.) A specialization relation is a partial order on the sentences in L. <p> Given a simple hypergraph H on R, a transversal T of H is a subset of R intersecting all the edges of H, that is, T " E 6= ; for all E 2 H. 1 I.e., the positive border corresponds to the set "S" of <ref> [23] </ref>. Transversals are also called hitting sets. Here we consider minimal transversals: a transversal T of H is minimal if no T 0 T is a transversal. The collection of minimal transversals of H is denoted by Tr (H). It is a hypergraph on R.
Reference: [24] <author> C. Tamon. </author> <title> Private communication. </title> <year> 1997. </year>
Reference-contexts: For monotone functions, the NP-Oracle used there, can be replaced with a procedure for HTR, yielding a similar result. This has been previously observed <ref> [24] </ref>. The algorithm that results is similar to the dualize and advance algorithm but is slightly more complicated. Here again using the result of Fredman and Khachiyan [10] we can derive a sub-exponential learning algorithm for this problem.
References-found: 24

