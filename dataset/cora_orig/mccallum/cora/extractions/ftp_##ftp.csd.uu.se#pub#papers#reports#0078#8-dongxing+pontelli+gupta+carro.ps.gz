URL: ftp://ftp.csd.uu.se/pub/papers/reports/0078/8-dongxing+pontelli+gupta+carro.ps.gz
Refering-URL: http://www.informatik.uni-trier.de/~ley/db/conf/iclp/iclp94-w6.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fdtang,epontell,guptag@cs.nmsu.edu boris@dia.fi.upm.es  
Title: Last Parallel Call Optimization and Fast Backtracking in And-parallel Logic Programming Systems  
Author: Tang DongXing, Enrico Pontelli Manuel Carro Gopal Gupta 
Address: 28660-Boadilla del Monte Las Cruces NM USA Madrid, Spain  
Affiliation: Laboratory for Logic and Databases Facultad de Informatica Dept of Computer Science Universidad Politecnica de Madrid New Mexico State University  
Abstract: In this paper we present a novel optimization called Last Parallel Call Optimization. The last parallel call optimization can be regarded as an extension of last call optimization, found in sequential systems, to and-parallel systems. The last parallel call optimization leads to improved time and space performance for a majority of and-parallel programs. The last parallel call optimization is presented in detail in this paper and its advantages discussed at length. The last parallel call optimization can be incorporated in a parallel system (such as RAPWAM) through relatively minor modifications to the runtime machinery. We also present some experimental results from a limited implementation of last parallel call operation done on the DDAS System. These experimental results prove that last parallel call optimization is indeed effective and produces better speed-ups with respect to an un-optimized implementation. We also discuss the problem of efficiently performing the kill operation in and-parallel systems. We present two approaches for efficiently propagating the kill signal to other parallel calls subsumed by the subgoal that received the kill signal. The first approach, implemented in the and-parallel component of the ACE system, propagates the kill lazily while the second one propagates the kill signal eagerly. The advantages and disadvantages of both these approaches are presented. The implementation and optimization techniques presented in this paper are very pragmatic and we believe that they will be of considerable utility to implementors of and-parallel systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Barklund, H. Millroth. </author> <title> Providing Iteration and Concurrency in Logic Program through Bounded Quantifications. </title> <booktitle> In Proc. International Conf. on Fifth Generation Computer Systems, </booktitle> <month> June </month> <year> 1992, </year> <pages> pages 817-824. </pages>
Reference-contexts: Barklund et al have suggested new language constructs (the language augmented with these constructs is termed Reform Prolog <ref> [1] </ref>) based on Bounded Quantification that encapsulate a call such as process list (Lin, Lout) in such a way that it is executed in parallel in one (parallel) step.
Reference: [2] <author> D. </author> <title> DeGroot. Restricted AND-parallelism. </title> <booktitle> In International Conference on Fifth Generation Computer Systems, </booktitle> <month> Nov., </month> <year> 1984. </year>
Reference-contexts: Parallel conjunctions may also be conditional, which means that the goals in the conjunction are executed in parallel only if the condition, i.e., the expression upon which the conjunction is conditioned, evaluates to true (e.g., Conditional Graph Expressions <ref> [2, 6] </ref>). Backtracking becomes complicated in and-parallel system because more than one goal may be executing in parallel, one or more of which may encounter failure and backtrack at the same time. Unlike a sequential system, there is no unique backtracking point.
Reference: [3] <author> G. Gupta, </author> <title> "Parallel Execution of Logic Programs on Shared Memory Multiprocessors," </title> <type> Ph.D. Thesis, </type> <institution> University of North Carolina, </institution> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: The implementation of kill as reported in this paper has been incorporated in the and-parallel component of ACE [9], 1 The LPCO was first considered in conjunction with the AO-WAM System <ref> [3] </ref>. an and-or parallel system. Section 7 presents our conclusions. We assume that the user has some familiarity with and-parallelism and and-parallel systems such as &-Prolog.
Reference: [4] <author> G.Gupta, E. Pontelli, M. Hermenegildo, V. San-tos Costa. </author> <title> ACE: And/Or-parallel Copying-based Execution of Logic Programs. </title> <booktitle> In Proc. International Conference on Logic Programming, </booktitle> <year> 1994, </year> <note> MIT Press, to appear. </note>
Reference-contexts: (goal recomputation means that sub-goals to the right of another subgoal g in a parallel conjunction are computed in their entirety for every solution found for subgoal g), although our results are also applicable to dependent and-parallel systems such as DDAS [13] and to and-or parallel systems such as ACE <ref> [4] </ref>. 2 Backtracking in And-parallel Systems An and-parallel system works by executing a program that has been annotated with parallel conjunctions. These parallel conjunction annotations are either inserted by a parallelizing compiler [7, 8] or by the programmer. <p> Note that both the Lazy and Eager schemes for propagating kill can be optimized further, however, we do not describe these possible improvements due to lack of space. More details can be found elsewhere [10]. The Lazy scheme has been incorporated in the and-parallel component of the ACE system <ref> [9, 4] </ref>. 6.4 Experimental Results The two approaches for performing the kill operation during and-parallel computation originated during the design of the and-parallel component of ACE [4], an And/Or-parallel Prolog system. The current implementation supports the lazy approach for killing sub-goals. program that involves massive amount of killing. <p> More details can be found elsewhere [10]. The Lazy scheme has been incorporated in the and-parallel component of the ACE system [9, 4]. 6.4 Experimental Results The two approaches for performing the kill operation during and-parallel computation originated during the design of the and-parallel component of ACE <ref> [4] </ref>, an And/Or-parallel Prolog system. The current implementation supports the lazy approach for killing sub-goals. program that involves massive amount of killing. This program is for computing Fibonacci (16). However, after the computation is finished a failure is forced at the end.
Reference: [5] <author> M. V. Hermenegildo. </author> <title> An Abstract Machine for Restricted AND-parallel Execution of Logic Programs. </title> <booktitle> In Third International Conference on Logic Programming, Lecture Notes in Computer Science 225, </booktitle> <pages> pages 25-40. </pages> <publisher> Springer-Verlag, </publisher> <month> July </month> <year> 1986. </year>
Reference-contexts: Because of and-parallelism not 1 only a new backtracking semantics is needed for such systems, but also its implementation becomes very tricky. We consider the backtracking semantics given by Hermenegildo and Nasr for and-parallel systems [6] and its efficient implementation in RAPWAM <ref> [5] </ref>. The backtracking semantics as given by Hermenegildo and Nasr attempts to emulate the backward execution control of Prolog as much as possible. In this paper, we present some optimizations over this backtracking scheme that permit faster backward execution. <p> The rest of the paper is organized as follows: Section 2 describes the backtracking scheme of Hermenegildo and Nasr for independent and-parallel system and its realization in Hermenegildo's RAP-WAM <ref> [5] </ref>. Section 3 introduces Last Parallel Call Optimization. Section 4 briefly describes an implementation scheme for the LPCO, while Section 5 describes our experiments to test the applicability of LPCO to existing systems. <p> Independent and-parallelism with the backtracking semantics described above has been implemented quite efficiently in RAPWAM <ref> [5] </ref>. RAPWAM is an extension to the sequential WAM for and-parallel execution of Prolog programs with and-parallel annotation (such as CGEs [6]). <p> The two main additional data structures are the goal stack and the parcall frame. Details of the structure of a Parcall frame are shown in Figure 1 (more details can be found in <ref> [5, 6] </ref>). In addition to parcall frames and goal stacks, an input marker node and an end marker node is used to mark the beginning and the end respectively of the segment in the stack corresponding to an and-parallel goal.
Reference: [6] <author> M. V. Hermenegildo, R. I. Nasr, </author> <title> Efficient Implementation of backtracking in AND-parallelism. </title> <booktitle> In 3rd International Conference on Logic Programming, </booktitle> <address> London, </address> <year> 1986. </year> <pages> pages 40-54. </pages>
Reference-contexts: Because of and-parallelism not 1 only a new backtracking semantics is needed for such systems, but also its implementation becomes very tricky. We consider the backtracking semantics given by Hermenegildo and Nasr for and-parallel systems <ref> [6] </ref> and its efficient implementation in RAPWAM [5]. The backtracking semantics as given by Hermenegildo and Nasr attempts to emulate the backward execution control of Prolog as much as possible. In this paper, we present some optimizations over this backtracking scheme that permit faster backward execution. <p> Parallel conjunctions may also be conditional, which means that the goals in the conjunction are executed in parallel only if the condition, i.e., the expression upon which the conjunction is conditioned, evaluates to true (e.g., Conditional Graph Expressions <ref> [2, 6] </ref>). Backtracking becomes complicated in and-parallel system because more than one goal may be executing in parallel, one or more of which may encounter failure and backtrack at the same time. Unlike a sequential system, there is no unique backtracking point. <p> Independent and-parallelism with the backtracking semantics described above has been implemented quite efficiently in RAPWAM [5]. RAPWAM is an extension to the sequential WAM for and-parallel execution of Prolog programs with and-parallel annotation (such as CGEs <ref> [6] </ref>). In order to execute all goals in a parallel conjunction in parallel, RAPWAM has a scheduling mechanism to assign parallel goals to available processors and some extra data structures to keep track of the current state of execution. <p> The two main additional data structures are the goal stack and the parcall frame. Details of the structure of a Parcall frame are shown in Figure 1 (more details can be found in <ref> [5, 6] </ref>). In addition to parcall frames and goal stacks, an input marker node and an end marker node is used to mark the beginning and the end respectively of the segment in the stack corresponding to an and-parallel goal.
Reference: [7] <author> D. Jacobs and A. Langen. </author> <title> Accurate and Efficient Approximation of Variable Aliasing in Logic Programs. </title> <booktitle> In 1989 North American Conference on Logic Programming. </booktitle> <publisher> MIT Press, </publisher> <month> October </month> <year> 1989. </year>
Reference-contexts: These parallel conjunction annotations are either inserted by a parallelizing compiler <ref> [7, 8] </ref> or by the programmer. Execution of all goals in a parallel conjunction is started in parallel when control reaches that parallel conjunction.
Reference: [8] <author> K. Muthukumar and M. Hermenegildo. </author> <title> Compile-time Derivation of Variable Dependency Using Abstract Interpretation. </title> <journal> Journal of Logic Programming, </journal> <volume> 13(2 and </volume> 3):315-347, July 1992. 
Reference-contexts: These parallel conjunction annotations are either inserted by a parallelizing compiler <ref> [7, 8] </ref> or by the programmer. Execution of all goals in a parallel conjunction is started in parallel when control reaches that parallel conjunction.
Reference: [9] <author> E. Pontelli, G. Gupta, M. Hermenegildo. </author> <title> ACE: A progress Report. </title> <type> Technical Report. </type> <institution> Department of Computer Science. New Mexico State University, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: Section 6 describes in detail the kill operation, the problems in implementing it, and the various solutions that we have proposed. The implementation of kill as reported in this paper has been incorporated in the and-parallel component of ACE <ref> [9] </ref>, 1 The LPCO was first considered in conjunction with the AO-WAM System [3]. an and-or parallel system. Section 7 presents our conclusions. We assume that the user has some familiarity with and-parallelism and and-parallel systems such as &-Prolog. <p> Note that both the Lazy and Eager schemes for propagating kill can be optimized further, however, we do not describe these possible improvements due to lack of space. More details can be found elsewhere [10]. The Lazy scheme has been incorporated in the and-parallel component of the ACE system <ref> [9, 4] </ref>. 6.4 Experimental Results The two approaches for performing the kill operation during and-parallel computation originated during the design of the and-parallel component of ACE [4], an And/Or-parallel Prolog system. The current implementation supports the lazy approach for killing sub-goals. program that involves massive amount of killing.
Reference: [10] <author> E. Pontelli, M. Carro, G. Gupta, </author> <title> "Kill and Backtracking in And-parallel Systems," </title> <type> Internal Report, </type> <institution> ACE Project, Department of Computer Science, New Mexico State University, </institution> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: Note that both the Lazy and Eager schemes for propagating kill can be optimized further, however, we do not describe these possible improvements due to lack of space. More details can be found elsewhere <ref> [10] </ref>. The Lazy scheme has been incorporated in the and-parallel component of the ACE system [9, 4]. 6.4 Experimental Results The two approaches for performing the kill operation during and-parallel computation originated during the design of the and-parallel component of ACE [4], an And/Or-parallel Prolog system.
Reference: [11] <author> B. Ramkumar, L.V. Kale, </author> <title> "Compiled Execution of the Reduce-Or Process Model on Multiprocessors," </title> <booktitle> In North American Conference on Logic Programming, </booktitle> <year> 1989. </year>
Reference-contexts: We are not aware of any work that attempts to optimize last parallel call. The only work that one could think of as coming close is that of Ramkumar [12] on what he terms "distributed last call optimization" for his and Kale's ROPM system <ref> [11] </ref>. The distributed last call optimization is specific to process based systems such as ROPM and attempts to reduce the message flow between goals during par allel execution.
Reference: [12] <author> B. Ramkumar, </author> <title> "Distributed Last Call Optimization for Portable Parallel Logic Programming," </title> <journal> In ACM Letters on Programming Languages and Systems, </journal> <volume> 1(3) </volume> <pages> 266-283, </pages> <month> Sep. </month> <year> 1992. </year>
Reference-contexts: We are not aware of any work that attempts to optimize last parallel call. The only work that one could think of as coming close is that of Ramkumar <ref> [12] </ref> on what he terms "distributed last call optimization" for his and Kale's ROPM system [11]. The distributed last call optimization is specific to process based systems such as ROPM and attempts to reduce the message flow between goals during par allel execution.
Reference: [13] <author> K. Shen: </author> <title> Studies in And/Or Parallelism in Pro-log. </title> <type> Ph.D thesis, </type> <institution> University of Cambridge, </institution> <year> 1992. </year>
Reference-contexts: in the context of independent and-parallelism with goal recomputation (goal recomputation means that sub-goals to the right of another subgoal g in a parallel conjunction are computed in their entirety for every solution found for subgoal g), although our results are also applicable to dependent and-parallel systems such as DDAS <ref> [13] </ref> and to and-or parallel systems such as ACE [4]. 2 Backtracking in And-parallel Systems An and-parallel system works by executing a program that has been annotated with parallel conjunctions. These parallel conjunction annotations are either inserted by a parallelizing compiler [7, 8] or by the programmer. <p> Time is also saved because backtracking and kill become faster: there are fewer parallel control structures (parcall frames) on the stack simplifying backward and forward control. 5 Experimental Results We implemented our ideas described above on the emulator of the DDAS <ref> [13] </ref> system. In fact because the implementation was unfamiliar to us, we implemented a diluted form of LPCO (described below). Even with this restricted implementation of LPCO we obtained improved speed-ups for all examples that we tried.
Reference: [14] <author> D. H. D. Warren. </author> <title> Last Call Optimization. "An Improved Prolog Implementation Which Opti-mises Tail Recursion," </title> <booktitle> In 2nd International Logic Programming Conference, </booktitle> <year> 1980, </year> <editor> K. Clark and S. A. Tarnlund (eds). </editor> <title> Academic Press. </title> <note> Also Research Paper 156, DAI, </note> <institution> Univ. of Edinburgh. </institution> <month> 14 </month>
Reference-contexts: It speeds up the process of backtracking, in gen eral; (iv). It saves space on the stacks and allows earlier re covering of space on backtracking. 3 The advantages of LPCO are very similar to those for last call optimization <ref> [14] </ref> in the WAM. The conditions under which the LPCO applies are also very similar to those under which last call optimization is applicable in sequential systems. Consider first an example that covers a special case of LPCO: ?- (p & q). where p :- (r & s).
References-found: 14

