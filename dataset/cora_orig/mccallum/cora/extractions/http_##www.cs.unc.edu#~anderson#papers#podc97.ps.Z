URL: http://www.cs.unc.edu/~anderson/papers/podc97.ps.Z
Refering-URL: http://www.cs.unc.edu/Research/real-time.html
Root-URL: http://www.cs.unc.edu
Title: Implementing Wait-Free Objects on Priority-Based Systems  
Author: James H. Anderson, Srikanth Ramamurthy, and Rohit Jain 
Address: Chapel Hill  
Affiliation: Department of Computer Science, University of North Carolina at  
Abstract: Wait-free objects are often implemented through the use of a "helping scheme", whereby one process "helps" one or more other processes to complete an operation. This paper presents several new helping schemes that can be generally applied to efficiently implement a variety of different objects on priority-based uniprocessor and multiprocessor systems. Examples of such systems include lock-free multiprocessor kernels and real-time systems. Our helping schemes reduce overhead by exploiting the way in which processes are scheduled in priority-based systems. We illustrate the use of these schemes by presenting wait-free implementations of linked lists and a multi-word compare-and-swap primitive. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson, R. Jain, and S. Ramamurthy, </author> <title> "Wait-free Object-Sharing Schemes for Real-Time Uniprocessors and Multiprocessors", </title> <type> manuscript, </type> <month> May </month> <year> 1997. </year>
Reference-contexts: Then, the current value of w, denoted Val (w), is defined as follows. val cnt valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 8 3 true 4 Val (z) = 8 Save <ref> [3; 1] </ref>: 22 Status [3]: 0 (a) val cnt valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: <p> 3 true 4 Val (z) = 8 Save <ref> [3; 1] </ref>: 22 Status [3]: 0 (a) val cnt valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val cnt valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status <p> Status [3]: 0 (a) val cnt valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save <ref> [4; 1] </ref>: 22 Save [4; 2]: 8 (b) val cnt valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; 1]: 22 Status [4]: 2 (c) val <p> [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val cnt valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save <ref> [3; 1] </ref>: 22 Status [4]: 2 (c) val cnt valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status [4]: 1 (d) and z, <p> Val (z) = 17 Status [3]: 1 Save <ref> [3; 1] </ref>: 22 Status [4]: 2 (c) val cnt valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status [4]: 1 (d) and z, with old/new values 12/5, 22/10, and 8/17, respectively. <p> Nonetheless, we believe that it is reasonable to conclude the following from our results: (i) the worst-case performance of our algorithm is very good; (ii) the average-case performance of our algorithm is reasonable (although not as good as the fastest-known algorithm). Recent results from a related paper <ref> [1] </ref> indicate that in real-time systems, our algorithms may exhibit performance that is better than is possible when applying them in a non-real-time system as done here. In particular, it is shown in [1] that if our cyclic helping scheme is used in conjunction with a real-time scheduler, then each operation <p> Recent results from a related paper <ref> [1] </ref> indicate that in real-time systems, our algorithms may exhibit performance that is better than is possible when applying them in a non-real-time system as done here. In particular, it is shown in [1] that if our cyclic helping scheme is used in conjunction with a real-time scheduler, then each operation requires only one traversal of the helping ring, instead of two. In addition, simulations reported in [1] indicate that in real-time multiprocessor systems, priority helping is very effective and results in much better <p> In particular, it is shown in <ref> [1] </ref> that if our cyclic helping scheme is used in conjunction with a real-time scheduler, then each operation requires only one traversal of the helping ring, instead of two. In addition, simulations reported in [1] indicate that in real-time multiprocessor systems, priority helping is very effective and results in much better performance than cyclic helping.
Reference: [2] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Multi-Object Operations", </title> <booktitle> Proc. of the 14th ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1995, </year> <pages> pp. 184-193. </pages>
Reference-contexts: Before a process is allowed to do this, however, it must first help any previously-announced operation (on its processor) to complete execution. This scheme requires only one announce variable per processor. In contrast, previous constructions for asynchronous systems require one announce variable per process <ref> [2, 3, 8] </ref>. In addition, with incremental helping, each process helps at most one other process, while in helping 1 For the application considered by Anderson and Ramamurthy, this is not a problem. <p> This version number is incremented after each wait-free operation and is assumed to not cycle during any single operation. 2 Unfortunately, CAS2 is directly provided on only a few existing processors (e.g., Motorola 68030 and 68040). Algorithms for implementing CAS2 are known <ref> [2, 5, 9] </ref>, but none are efficient enough to be practically applied. An efficient hardware-based implementation of CAS2 was recently proposed by 2 This is reasonable for the kinds of applications targeted by our work. For example, in real-time systems, each task must complete execution by a specified deadline. <p> Indeed, if existing algorithms are any indication <ref> [2, 5, 9] </ref>, disjoint access parallelism, while improving best-case complexity, results in enormous worst-case complexity. In our multiprocessor MWCAS implementation, a W -word MWCAS operation on P processors requires O (P W ) time. When considering multiprocessor workstations, it is reasonable to consider P to be a constant. <p> val cnt valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save <ref> [4; 2] </ref>: 8 (b) val cnt valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; 1]: 22 Status [4]: 2 (c) val cnt valid pid x: <p> Insets (e) and (f) show the operation in-terleavings corresponding to insets (c) and (d), respectively. 2 Our uniprocessor MWCAS implementation is disjoint access parallel [9] and is much simpler and more efficient than previous disjoint access parallel algorithms for asynchronous systems <ref> [2, 5, 9] </ref>. One disadvantage of our implementation is that certain bits within each accessed word must be reserved for control information (the cnt , valid , and pid fields). <p> With this scheme, each read requires time proportional to 2 T . The implementation described in this subsection is ob viously not disjoint access parallel [9], but is much simpler and more efficient than implementations that are <ref> [2, 5, 9] </ref>. Some limited degree of disjoint access parallelism could be achieved with our implementation by using a separate ver sion counter for each set of MWCAS operations that may po tentially transitively conflict. 3.2 Linked Lists Our linked-list implementation for multiprocessors is shown in Figure 7.
Reference: [3] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Large Objects", </title> <booktitle> Proc. of the Ninth Int'l Workshop on Distributed Algorithms, Lecture Notes in Computer Science 972, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995, </year> <pages> pp. 168-182. </pages>
Reference-contexts: Before a process is allowed to do this, however, it must first help any previously-announced operation (on its processor) to complete execution. This scheme requires only one announce variable per processor. In contrast, previous constructions for asynchronous systems require one announce variable per process <ref> [2, 3, 8] </ref>. In addition, with incremental helping, each process helps at most one other process, while in helping 1 For the application considered by Anderson and Ramamurthy, this is not a problem. <p> As mentioned above, we make use of incremental helping in our multiprocessor implementations. In addition, we use two other new techniques, which we call cyclic helping and priority helping, respectively. The notion of cyclic helping is adapted from previous work of Anderson and Moir <ref> [3] </ref>. In this scheme, the processors are thought of as if they were part of a logical ring. Processes are helped through the use of a "help counter", which cycles around the ring. <p> Then, the current value of w, denoted Val (w), is defined as follows. val cnt valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 8 3 true 4 Val (z) = 8 Save <ref> [3; 1] </ref>: 22 Status [3]: 0 (a) val cnt valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: <p> Then, the current value of w, denoted Val (w), is defined as follows. val cnt valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 8 3 true 4 Val (z) = 8 Save [3; 1]: 22 Status <ref> [3] </ref>: 0 (a) val cnt valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: <p> 22 z: 8 3 true 4 Val (z) = 8 Save [3; 1]: 22 Status <ref> [3] </ref>: 0 (a) val cnt valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val cnt valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) <p> 3 true 4 Val (z) = 8 Save <ref> [3; 1] </ref>: 22 Status [3]: 0 (a) val cnt valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val cnt valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status <p> 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val cnt valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status <ref> [3] </ref>: 1 Save [3; 1]: 22 Status [4]: 2 (c) val cnt valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status [4]: 1 <p> [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val cnt valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save <ref> [3; 1] </ref>: 22 Status [4]: 2 (c) val cnt valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status [4]: 1 (d) and z, <p> 0 true 4 Val (z) = 17 Status <ref> [3] </ref>: 1 Save [3; 1]: 22 Status [4]: 2 (c) val cnt valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status [4]: 1 (d) and z, with old/new values 12/5, 22/10, and 8/17, respectively. <p> Val (z) = 17 Status [3]: 1 Save <ref> [3; 1] </ref>: 22 Status [4]: 2 (c) val cnt valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status [4]: 1 (d) and z, with old/new values 12/5, 22/10, and 8/17, respectively. <p> The current value of each word is now the desired new value, and all valid fields are true (so the value of Status [4] is no longer relevant). Before returning, process 4 updates Status <ref> [3] </ref> (line 19 of Figure 3) to indicate that process 3 (which must be of lower priority) has been interfered with. Inset (d) shows relevant variables at the termination of m, assuming an interference on word z by process 9 (which must be of higher-priority) with new value 56. <p> Inset (d) shows relevant variables at the termination of m, assuming an interference on word z by process 9 (which must be of higher-priority) with new value 56. Status [4] is now 1, indicating the failure of process 4's operation. Status <ref> [3] </ref> is left unchanged in this case. Observe that process 4 has successfully restored the original values of words x and y.
Reference: [4] <author> J. Anderson and S. Ramamurthy, </author> <title> "A Framework for Implementing Objects and Scheduling Tasks in Lock-Free Real-Time Systems", </title> <booktitle> Proc. of the 17th IEEE Real-Time Systems Symposium, </booktitle> <year> 1996, </year> <pages> pp. 94-105. </pages>
Reference-contexts: We begin by presenting a wait-free implementation of MWCAS. In this implementation, a W -word MWCAS operation is executed in fi (W ) time, which is asymptotically optimal. The MWCAS implementation presented here is based on one presented previously by Anderson and Ramamurthy <ref> [4] </ref>. Ander-son and Ramamurthy's implementation is not strictly faithful to the semantics of MWCAS. In particular, it allows a MWCAS operation to fail if it is overlapped by another MWCAS operation that accesses a common word. <p> In particular, it allows a MWCAS operation to fail if it is overlapped by another MWCAS operation that accesses a common word. For the case in which the overlapping operation itself fails, it may be impossible to correctly linearize the operations in accordance with the semantics of MWCAS (see <ref> [4] </ref> for details). 1 In the implementation presented here, this problem is corrected. After considering MWCAS, we present an implementation of linked lists for priority-based uniprocessor systems. Our list implementation is based on a novel technique, which we call incremental helping. <p> (z) = 8 Save [3; 1]: 22 Status [3]: 0 (a) val cnt valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status <ref> [4] </ref>: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val cnt valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; <p> Save [3; 1]: 22 Status [3]: 0 (a) val cnt valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save <ref> [4; 0] </ref>: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val cnt valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; 1]: 22 Status <p> Status [3]: 0 (a) val cnt valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save <ref> [4; 1] </ref>: 22 Save [4; 2]: 8 (b) val cnt valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; 1]: 22 Status [4]: 2 (c) val <p> val cnt valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save <ref> [4; 2] </ref>: 8 (b) val cnt valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; 1]: 22 Status [4]: 2 (c) val cnt valid pid x: <p> 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val cnt valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; 1]: 22 Status <ref> [4] </ref>: 2 (c) val cnt valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status [4]: 1 (d) and z, with old/new values 12/5, <p> Status [3]: 1 Save [3; 1]: 22 Status <ref> [4] </ref>: 2 (c) val cnt valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status [4]: 1 (d) and z, with old/new values 12/5, 22/10, and 8/17, respectively. <p> Note that the current value of each word matches the desired old value. Inset (b) shows relevant variables after the first phase of m has completed, assuming no interferences by higher-priority processes. The current value of each word is unchanged. Note that changing the value of Status <ref> [4] </ref> from 0 to 2 in inset (b) would have the effect of atomically changing the current value of each of x, y, and z to the desired new value. Inset (c) shows relevant variables at the termination of m, assuming no interferences by higher-priority processes. <p> Inset (c) shows relevant variables at the termination of m, assuming no interferences by higher-priority processes. The current value of each word is now the desired new value, and all valid fields are true (so the value of Status <ref> [4] </ref> is no longer relevant). Before returning, process 4 updates Status [3] (line 19 of Figure 3) to indicate that process 3 (which must be of lower priority) has been interfered with. <p> Inset (d) shows relevant variables at the termination of m, assuming an interference on word z by process 9 (which must be of higher-priority) with new value 56. Status <ref> [4] </ref> is now 1, indicating the failure of process 4's operation. Status [3] is left unchanged in this case. Observe that process 4 has successfully restored the original values of words x and y.
Reference: [5] <author> H. Attiya and E. Dagan, </author> <title> "Universal Operations: Unary versus Binary", </title> <booktitle> Proc. of the 15th ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1996, </year> <pages> pp. 223-232. </pages>
Reference-contexts: This version number is incremented after each wait-free operation and is assumed to not cycle during any single operation. 2 Unfortunately, CAS2 is directly provided on only a few existing processors (e.g., Motorola 68030 and 68040). Algorithms for implementing CAS2 are known <ref> [2, 5, 9] </ref>, but none are efficient enough to be practically applied. An efficient hardware-based implementation of CAS2 was recently proposed by 2 This is reasonable for the kinds of applications targeted by our work. For example, in real-time systems, each task must complete execution by a specified deadline. <p> Indeed, if existing algorithms are any indication <ref> [2, 5, 9] </ref>, disjoint access parallelism, while improving best-case complexity, results in enormous worst-case complexity. In our multiprocessor MWCAS implementation, a W -word MWCAS operation on P processors requires O (P W ) time. When considering multiprocessor workstations, it is reasonable to consider P to be a constant. <p> Insets (e) and (f) show the operation in-terleavings corresponding to insets (c) and (d), respectively. 2 Our uniprocessor MWCAS implementation is disjoint access parallel [9] and is much simpler and more efficient than previous disjoint access parallel algorithms for asynchronous systems <ref> [2, 5, 9] </ref>. One disadvantage of our implementation is that certain bits within each accessed word must be reserved for control information (the cnt , valid , and pid fields). <p> With this scheme, each read requires time proportional to 2 T . The implementation described in this subsection is ob viously not disjoint access parallel [9], but is much simpler and more efficient than implementations that are <ref> [2, 5, 9] </ref>. Some limited degree of disjoint access parallelism could be achieved with our implementation by using a separate ver sion counter for each set of MWCAS operations that may po tentially transitively conflict. 3.2 Linked Lists Our linked-list implementation for multiprocessors is shown in Figure 7.
Reference: [6] <author> B. Bershad, </author> <title> "Practical Considerations for Non-Blocking Concurrent Objects", </title> <booktitle> Proc. of the 13th Int'l Conference on Distributed Computing Systems, </booktitle> <year> 1993, </year> <pages> pp. 124-149. </pages>
Reference-contexts: Unless deadlines are unrealistically large, it would be impossible for a 32- or 64-bit counter to cycle during the execution of one task. Greenwald and Cheriton [7], but no current machines support this implementation. An operating-system-based approach to implementing CAS2 has been proposed by Bershad <ref> [6] </ref>, but this approach can be problematic to actually implement (see [7] for details). Fortunately, CCAS appears to be much easier to implement than CAS2. If CAS is available, then CCAS can be implemented in just a few instructions.
Reference: [7] <author> M. Greenwald and D. Cheriton, </author> <title> "The Synergy Between Non-blocking Synchronization and Operating System Structure", </title> <booktitle> Proc. of the USENIX Association Second Symposium on Operating Systems Design and Implementation, </booktitle> <year> 1996, </year> <pages> pp. 123-136 </pages>
Reference-contexts: Wait-free and lock-free kernel data structures facilitate the design of re-entrant kernels, because their use eliminates the possibility of deadlock resulting from a preempted object access. Examples of lock-free kernels include the Synthesis Kernel of Massalin and Pu [10] and the Cache Kernel of Greenwald and Cheriton <ref> [7] </ref>. One of the main lessons to be learned from [12] is that fl Work supported, in part, by NSF grants CCR 9216421 and CCR 9510156, and by a Young Investigator Award from the U.S. Army Research Office, grant number DAAH04-95-1-0323. <p> For example, in real-time systems, each task must complete execution by a specified deadline. Unless deadlines are unrealistically large, it would be impossible for a 32- or 64-bit counter to cycle during the execution of one task. Greenwald and Cheriton <ref> [7] </ref>, but no current machines support this implementation. An operating-system-based approach to implementing CAS2 has been proposed by Bershad [6], but this approach can be problematic to actually implement (see [7] for details). Fortunately, CCAS appears to be much easier to implement than CAS2. <p> Greenwald and Cheriton <ref> [7] </ref>, but no current machines support this implementation. An operating-system-based approach to implementing CAS2 has been proposed by Bershad [6], but this approach can be problematic to actually implement (see [7] for details). Fortunately, CCAS appears to be much easier to implement than CAS2. If CAS is available, then CCAS can be implemented in just a few instructions. <p> A very desirable property of this implementation is that it does not require certain bits of flX to be reserved for control information. 3.4 Performance Results We have conducted preliminary performance experiments that compare our multiprocessor wait-free linked-list implementation to a lock-free list implementation presented recently by Greenwald and Cheriton <ref> [7] </ref>. We chose their implementation to test against because it is among the most efficient linked-list algorithms currently known. The experiments we conducted were performed on a four-processor SGI-R10000 machine. The priority-based preemption model was simulated at the user level by inserting predefined preemption points into each process. <p> Another lock-free list implementation, which uses only CAS, was recently proposed by Valois [13]. Although we did not test against Valois' algorithm, Greenwald and Cheriton report that their algorithm is faster than his algorithm by a factor of about ten under high contention <ref> [7] </ref>. Based on this, we believe that our algorithm would perform better than Valois' algorithm on a priority-based system.
Reference: [8] <author> M. Herlihy, </author> <title> "A Methodology for Implementing Highly Concurrent Data Objects", </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 15(5), </volume> <year> 1993, </year> <pages> pp. 745-770. </pages>
Reference-contexts: Before a process is allowed to do this, however, it must first help any previously-announced operation (on its processor) to complete execution. This scheme requires only one announce variable per processor. In contrast, previous constructions for asynchronous systems require one announce variable per process <ref> [2, 3, 8] </ref>. In addition, with incremental helping, each process helps at most one other process, while in helping 1 For the application considered by Anderson and Ramamurthy, this is not a problem. <p> However, while ensuring parallelism in this context is of theoretical importance, practical algorithms that are disjoint access parallel have remained elu 3 For example, in Herlihy's construction <ref> [8] </ref>, two rounds of helping may be required, with N processes being helped per round. 4 For instance, if processes p, q, and r concurrently perform MW-CAS operations on words w and x, x and y, and y and z, respectively, then p has a direct conflict with q and transitive
Reference: [9] <author> A. Israeli and L. Rappoport, </author> <title> "Disjoint-Access-Parallel Implementations of Strong Shared Memory Primitives", </title> <booktitle> Proc. of the 13th ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1994, </year> <pages> pp. 151-160 </pages>
Reference-contexts: This version number is incremented after each wait-free operation and is assumed to not cycle during any single operation. 2 Unfortunately, CAS2 is directly provided on only a few existing processors (e.g., Motorola 68030 and 68040). Algorithms for implementing CAS2 are known <ref> [2, 5, 9] </ref>, but none are efficient enough to be practically applied. An efficient hardware-based implementation of CAS2 was recently proposed by 2 This is reasonable for the kinds of applications targeted by our work. For example, in real-time systems, each task must complete execution by a specified deadline. <p> In the latter part of the paper, we present performance results that show that our multiprocessor linked-list implementation is more efficient than alternative implementations on priority-based multiprocessor workstations. In work on multi-word synchronization primitives like MWCAS, Israeli and Rappoport introduced the important notion of disjoint access parallelism <ref> [9] </ref>. For a wait-free implementation to be disjoint access parallel, a process should only help other processes with which it has a transitive conflict. 4 Our multiprocessor MWCAS implementation does not have this property. <p> Indeed, if existing algorithms are any indication <ref> [2, 5, 9] </ref>, disjoint access parallelism, while improving best-case complexity, results in enormous worst-case complexity. In our multiprocessor MWCAS implementation, a W -word MWCAS operation on P processors requires O (P W ) time. When considering multiprocessor workstations, it is reasonable to consider P to be a constant. <p> Status [3] is left unchanged in this case. Observe that process 4 has successfully restored the original values of words x and y. Insets (e) and (f) show the operation in-terleavings corresponding to insets (c) and (d), respectively. 2 Our uniprocessor MWCAS implementation is disjoint access parallel <ref> [9] </ref> and is much simpler and more efficient than previous disjoint access parallel algorithms for asynchronous systems [2, 5, 9]. One disadvantage of our implementation is that certain bits within each accessed word must be reserved for control information (the cnt , valid , and pid fields). <p> Insets (e) and (f) show the operation in-terleavings corresponding to insets (c) and (d), respectively. 2 Our uniprocessor MWCAS implementation is disjoint access parallel [9] and is much simpler and more efficient than previous disjoint access parallel algorithms for asynchronous systems <ref> [2, 5, 9] </ref>. One disadvantage of our implementation is that certain bits within each accessed word must be reserved for control information (the cnt , valid , and pid fields). <p> This ensures that any partially-completed MWCAS is finished by the time the next read is performed. With this scheme, each read requires time proportional to 2 T . The implementation described in this subsection is ob viously not disjoint access parallel <ref> [9] </ref>, but is much simpler and more efficient than implementations that are [2, 5, 9]. <p> With this scheme, each read requires time proportional to 2 T . The implementation described in this subsection is ob viously not disjoint access parallel [9], but is much simpler and more efficient than implementations that are <ref> [2, 5, 9] </ref>. Some limited degree of disjoint access parallelism could be achieved with our implementation by using a separate ver sion counter for each set of MWCAS operations that may po tentially transitively conflict. 3.2 Linked Lists Our linked-list implementation for multiprocessors is shown in Figure 7.
Reference: [10] <author> H. Massalin and C. Pu, </author> <title> "A Lock-Free Multiprocessor OS Kernel", </title> <type> Technical Report CUCS-005-01, </type> <institution> Computer Science Department, Columbia University, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: Wait-free and lock-free kernel data structures facilitate the design of re-entrant kernels, because their use eliminates the possibility of deadlock resulting from a preempted object access. Examples of lock-free kernels include the Synthesis Kernel of Massalin and Pu <ref> [10] </ref> and the Cache Kernel of Greenwald and Cheriton [7]. One of the main lessons to be learned from [12] is that fl Work supported, in part, by NSF grants CCR 9216421 and CCR 9510156, and by a Young Investigator Award from the U.S. Army Research Office, grant number DAAH04-95-1-0323.
Reference: [11] <author> R. Rajkumar, </author> <title> Synchronization In Real-Time Systems APriority Inheritance Approach, </title> <publisher> Kluwer Academic Pubs., </publisher> <year> 1991. </year>
Reference-contexts: Otherwise, if there are other an nounced operations on other processors with priority greater than q's but less than p's, p may be delayed unnecessarily. This is very similar to priority inheritance in real-time systems <ref> [11] </ref>.) Advancing the help counter in this scheme requires an O (P ) scan of the announce array.
Reference: [12] <author> S. Ramamurthy, M. Moir, and J. Anderson, </author> <title> "Real-Time Object Sharing with Minimal System Support", </title> <booktitle> Proc. of the 15th ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1996, </year> <pages> pp. 233-242. </pages>
Reference-contexts: We assume that processes are scheduled on a per-processor basis and do not migrate between processors during object accesses. Our work extends research reported in a recent paper by Ramamurthy, Moir, and Anderson <ref> [12] </ref> pertaining to the implementation of wait-free objects in priority-based real-time systems. <p> Examples of lock-free kernels include the Synthesis Kernel of Massalin and Pu [10] and the Cache Kernel of Greenwald and Cheriton [7]. One of the main lessons to be learned from <ref> [12] </ref> is that fl Work supported, in part, by NSF grants CCR 9216421 and CCR 9510156, and by a Young Investigator Award from the U.S. Army Research Office, grant number DAAH04-95-1-0323. The first author was also supported by an Alfred P. <p> The reason for this is that, in a priority-based system, operations of high-priority processes automatically appear atomic to low-priority processes running on the same processor. (This is illustrated quite well by Figure 2, which we consider below.) This fact can be exploited to greatly simplify object implementations. In <ref> [12] </ref>, several wait-free algorithms are presented for implementing consensus and compare-and-swap (CAS) objects in priority-based systems. In this paper, we consider objects that are more sophisticated than these, and present several new algorithmic techniques that can be generally applied in priority-based systems to construct wait-free implementations of objects.
Reference: [13] <author> J. Valois, </author> <title> "Lock-Free Linked Lists using Compare-and-Swap", </title> <booktitle> Proc. of the 14th ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1995, </year> <pages> pp. 214-222. </pages>
Reference-contexts: Another lock-free list implementation, which uses only CAS, was recently proposed by Valois <ref> [13] </ref>. Although we did not test against Valois' algorithm, Greenwald and Cheriton report that their algorithm is faster than his algorithm by a factor of about ten under high contention [7]. Based on this, we believe that our algorithm would perform better than Valois' algorithm on a priority-based system.
References-found: 13

