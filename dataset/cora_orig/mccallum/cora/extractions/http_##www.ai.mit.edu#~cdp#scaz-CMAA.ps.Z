URL: http://www.ai.mit.edu/~cdp/scaz-CMAA.ps.Z
Refering-URL: http://www.ai.mit.edu/people/scaz/scaz.html
Root-URL: 
Email: scaz@ai.mit.edu  
Title: Imitation and Mechanisms of Joint Attention: A Developmental Structure for Building Social Skills on a
Author: Brian Scassellati 
Web: http://www.ai.mit.edu/people/scaz/  
Address: 545 Technology Square Cambridge MA 02139, USA  
Affiliation: MIT Artificial Intelligence Lab  
Abstract: Adults are extremely adept at recognizing social cues, such as eye direction or pointing gestures, that establish the basis of joint attention. These skills serve as the developmental basis for more complex forms of metaphor and analogy by allowing an infant to ground shared experiences and by assisting in the development of more complex communication skills. In this chapter, we review some of the evidence for the developmental course of these joint attention skills from developmental psychology, from disorders of social development such as autism, and from the evolutionary development of these social skills. We also describe an on-going research program aimed at testing existing models of joint attention development by building a human-like robot which communicates naturally with humans using joint attention. Our group has constructed an upper-torso humanoid robot, called Cog, in part to investigate how to build intelligent robotic systems by following a developmental progression of skills similar to that observed in human development. Just as a child learns social skills and conventions through interactions with its parents, our robot will learn to interact with people using natural social communication. We further consider the critical role that imitation plays in bootstrapping a system from simple visual behaviors to more complex social skills. We will present data from a face and eye finding system that serves as the basis of this developmental chain, and an example of how this system can imitate the head movements of an individual.
Abstract-found: 1
Intro-found: 1
Reference: <author> Baron-Cohen, S. </author> <year> (1995), </year> <title> Mindblindness, </title> <publisher> MIT Press. </publisher> <address> Fig. </address> <month> 13. </month> <title> Images captured from a videotape of the robot imitating head nods. The upper two images show the robot imitating head nods from a human caretaker. The output of the face detector is used to drive fixed yes/no nodding responses in the robot. The face detector also picks out the face from stuffed animals, </title> <note> and will also mimic their actions. The original video clips are available at http://www.ai.mit.edu/projects/cog/. </note>
Reference: <author> Brooks, R. & Stein, L. A. </author> <year> (1994), </year> <title> `Building Brains for Bodies', </title> <booktitle> Autonomous Robots 1:1, </booktitle> <pages> 725. </pages>
Reference-contexts: The Cog project at the MIT Artificial Intelligence Laboratory has been constructing an upper-torso humanoid robot, called Cog, in part to investigate how to build intelligent robotic systems by following a developmental progression of skills similar to that observed in human development <ref> (Brooks & Stein 1994, Brooks et al. 1998) </ref>. In the past two years, a basic repertoire of perceptual capabilities and sensory-motor skills have been implemented on the robot (see Brooks et al. (1998) for a review).
Reference: <author> Brooks, R. A., Ferrell, C., Irie, R., Kemp, C. C., Marjanovic, M., Scassellati, B. & Williamson, M. </author> <year> (1998), </year> <title> Alternative Essences of Intelligence, </title> <booktitle> in `Proceedings of the Fifteenth National Conference on Artificial Intelligence (AAAI-98)', </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: We believe that by using a developmental program to build social capabilities we will be able to achieve a wide range of natural interactions with untrained observers <ref> (Brooks, Ferrell, Irie, Kemp, Marjanovic, Scassellati & Williamson 1998) </ref>. Robotics also offers a unique tool to developmental psychology and related disciplines in evaluating complex interaction models. By implementing these models in a real-world system, we provide a test bed for manipulating the behavioral progression. <p> To maintain portability between the development platforms and to ensure accuracy in the sensory-motor behaviors, we require that all of our sensory-motor behaviors be learned by on-line adaptive algorithms <ref> (Brooks et al. 1998) </ref>. The mapping between image locations and the motor commands necessary to foveate that target is called a saccade map. This map is implemented as a 17 fi 17 interpolated lookup table, which is trained by the following algorithm: 1.
Reference: <author> Burghardt, G. M. & Greene, H. W. </author> <year> (1990), </year> <title> `Predator Simulation and Duration of Death Feigning in Neonate Hognose Snakes', Animal Behaviour 36(6), </title> <type> 18421843. </type>
Reference-contexts: For example, skills that infants acquire early in life, such as sensitivity to eye direction, have been demonstrated in relatively simple vertebrates, such as snakes <ref> (Burghardt & Greene 1990) </ref>, while skills that are acquired later tend to appear only in the primates (Whiten 1991). 2.2 A Module-Based Decomposition As the basis for our implementation of joint attention, we begin with a developmental model from Baron-Cohen (1995). <p> For further information, see section 2.3. The first step in producing mechanisms of joint attention is the recognition and maintenance of eye contact. Many animals have been shown to be extremely sensitive to eyes that are directed at them, including reptiles like the hognosed snake <ref> (Burghardt & Greene 1990) </ref>, avians like the chicken (Scaife 1976) and the plover (Ristau 1991), and all primates (Cheney & Seyfarth 1990).
Reference: <author> Butterworth, G. </author> <year> (1991), </year> <title> The Ontogeny and Phylogeny of Joint Visual Attention, </title> <editor> in A. Whiten, ed., </editor> <title> `Natural Theories of Mind', </title> <publisher> Blackwell. </publisher>
Reference: <author> Cheney, D. L. & Seyfarth, R. M. </author> <year> (1990), </year> <title> How Monkeys See the World, </title> <publisher> University of Chicago Press. </publisher>
Reference-contexts: Many animals have been shown to be extremely sensitive to eyes that are directed at them, including reptiles like the hognosed snake (Burghardt & Greene 1990), avians like the chicken (Scaife 1976) and the plover (Ristau 1991), and all primates <ref> (Cheney & Seyfarth 1990) </ref>. Identifying whether or not something is looking at you provides an obvious evolutionary advantage in escaping predators, but in many mammals, especially primates, the recognition that another is looking at you carries social significance. <p> <ref> (Cheney & Seyfarth 1990) </ref>. Identifying whether or not something is looking at you provides an obvious evolutionary advantage in escaping predators, but in many mammals, especially primates, the recognition that another is looking at you carries social significance. In monkeys, eye contact is significant for maintaining a social dominance hierarchy (Cheney & Seyfarth 1990). In humans, the reliance on eye contact as a social cue is even more striking. Infants have a strong preference for looking at human faces and eyes, and maintain (and thus recognize) eye contact within the first three months. <p> Imperative pointing is a gesture used to obtain an object that is out of reach by pointing at that object. This behavior is first seen in human children at about nine months of age (Baron-Cohen 1995), and occurs in many monkeys <ref> (Cheney & Seyfarth 1990) </ref>.
Reference: <author> Cohen, D. J. & Volkmar, F. R., </author> <title> eds (1997), Handbook of Autism and Pervasive Developmental Disorders, second edn, </title> <publisher> John Wiley & Sons, Inc. </publisher>
Reference-contexts: Additional work on the etiology and behavioral manifestations of developmental disorders such as autism and Asperger's syndrome have focused on disruptions to joint attention mechanisms and demonstrated how vital these skills are in our social world <ref> (Cohen & Volkmar 1997, Baron-Cohen 1995) </ref>. Philosophers have been interested in joint attention both as an explanation for issues of contextual grounding and as a precursor to a theory of other minds (Whiten 1991, Dennett 1991).
Reference: <author> Dennett, D. C. </author> <year> (1991), </year> <title> Consciousness Explained, Little, </title> <publisher> Brown, & Company. </publisher>
Reference-contexts: Philosophers have been interested in joint attention both as an explanation for issues of contextual grounding and as a precursor to a theory of other minds <ref> (Whiten 1991, Dennett 1991) </ref>. Evolutionary psychologists and primatologists have focused on the evolution of these simple social skills throughout the animal kingdom as a means of evaluating both the presence of theory of mind and as a measure of social functioning (Povinelli & Preuss 1995, Hauser 1996, Premack 1988).
Reference: <author> Diamond, A. </author> <year> (1990), </year> <title> Developmental Time Course in Human Infants and Infant Monkeys, and the Neural Bases, of Inhibitory Control in Reaching, </title> <booktitle> in `Development and Neural Bases of Higher Cognitive Functions', </booktitle> <volume> Vol. 608, </volume> <publisher> New York Academy of Sciences, </publisher> <pages> pp. </pages> <month> 637676. </month> <title> DSM (1994), `Diagnostic and Statistical Manual of Mental Disorders', </title> <publisher> American Psychiatric Association, </publisher> <address> Washington DC. </address>
Reference-contexts: Children pass through a developmental progression of reaching skills <ref> (Diamond 1990) </ref>. The fist stage in this progression appears around the fifth month and is characterized by a very stereotyped reach which always initiates from a position close to the child's eyes and moves ballistically along an angle of gaze directly toward the target object.
Reference: <author> Frith, U. </author> <year> (1990), </year> <title> Autism : Explaining the Enigma, </title> <publisher> Basil Blackwell. </publisher>
Reference-contexts: For example, infants are always sensitive to eye direction before they can interpret and generate pointing gestures. There are also developmental disorders, such as autism, that limit and fracture the components of this system <ref> (Frith 1990) </ref>. Autism is a pervasive developmental disorder of unknown etiology that is diagnosed by a set of behavioral criteria centered around abnormal social and communicative skills (DSM 1994, ICD 1993). Individuals with autism tend to have normal sensory and motor skills, but have difficulty with certain socially relevant tasks.
Reference: <author> Hauser, M. D. </author> <year> (1996), </year> <title> Evolution of Communication, </title> <publisher> MIT Press. </publisher>
Reference-contexts: From the phylogenetic perspective, declarative pointing has not been identified in any nonhuman primate (Premack 1988). This also corresponds to the phylogeny of imitation; no non-human primate has ever been documented to display imitative behavior under general conditions <ref> (Hauser 1996) </ref>. We propose that the child first learns to recognize the declarative pointing gestures of the adult and then imitates those gestures in order to produce declarative pointing.
Reference: <author> Hobson, R. P. </author> <year> (1993), </year> <title> Autism and the Development of Mind, </title> <publisher> Erlbaum. </publisher> <month> ICD </month> <year> (1993), </year> <title> `The ICD-10 Classification of Mental and Behavioral Disorders: Diagnostic Criteria for Research', World Health Organization (WHO), </title> <address> Geneva. </address>
Reference-contexts: Evidence from childhood development shows that not all mechanisms for joint attention are present from birth, and there is a stereotypic progression of skills that occurs in all infants at roughly the same rate <ref> (Hobson 1993) </ref>. For example, infants are always sensitive to eye direction before they can interpret and generate pointing gestures. There are also developmental disorders, such as autism, that limit and fracture the components of this system (Frith 1990).
Reference: <author> Jordan, M. I. & Rumelhart, D. E. </author> <year> (1992), </year> <title> `Forward Models: supervised learning with a distal teacher', </title> <booktitle> Cognitive Science 16, </booktitle> <pages> 307354. </pages>
Reference-contexts: The gaze coordinates can then be used to train a forward and inverse model of the ballistic map using a distal supervised learning technique <ref> (Jordan & Rumelhart 1992) </ref>. A single learning trial proceeds as follows: 1. Locate a visual target. 2. Saccade to that target using the learned saccade map. 3. Convert the eye position to a ballistic reach using the ballistic map. 4.
Reference: <author> Karmiloff-Smith, A., Klima, E., Bellugi, U., Grant, J. & Baron-Cohen, S. </author> <year> (1995), </year> <title> `Is there a social module? Language, face processing, and theory of mind in individuals with Williams Syndrome', </title> <journal> Journal of Cognitive Neuroscience 7:2, 196208. </journal>
Reference: <author> Marjanovic, M., Scassellati, B. & Williamson, M. </author> <year> (1996), </year> <title> Self-Taught Visually-Guided Pointing for a Humanoid Robot, </title> <booktitle> in `From Animals to Animats 4: Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior (SAB-96)', </booktitle> <publisher> Bradford Books, </publisher> <pages> pp. 3544. </pages>
Reference-contexts: To achieve this stage of reaching on our robotic system, we have utilized the foveation behavior obtained from the first step in order to train the arm where to reach <ref> (Marjanovic et al. 1996) </ref>.
Reference: <author> Moore, C. & Dunham, P. J., </author> <title> eds (1995), Joint Attention: Its Origins and Role in Development, </title> <publisher> Erlbaum. </publisher>
Reference: <author> Povinelli, D. J. & Preuss, T. M. </author> <year> (1995), </year> <title> `Theory of Mind: evolutionary history of a cognitive specialization', </title> <booktitle> Trends in Neuroscience. </booktitle>
Reference-contexts: Evolutionary psychologists and primatologists have focused on the evolution of these simple social skills throughout the animal kingdom as a means of evaluating both the presence of theory of mind and as a measure of social functioning <ref> (Povinelli & Preuss 1995, Hauser 1996, Premack 1988) </ref>. We have approached joint attention from a slightly different perspective: the construction of human-like robots that exhibit these social skills (Scassellati 1996). <p> The same ontological progression of joint attention skills that is evident in human infants can also be seen as an evolutionary progression in which the increasingly complex set of skills can be mapped to animals that are increasingly closer to humans on a phylogenetic scale <ref> (Povinelli & Preuss 1995) </ref>. <p> While many animals are sensitive to eyes that are gazing directly at them, only primates show the capability to extrapolate from the direction of gaze to a distal object, and only the great apes will extrapolate to an object that is outside their immediate field of view <ref> (Povinelli & Preuss 1995) </ref>. 1 This evolutionary progression is also mirrored in the ontogeny of social skills. At least by the age 1 The terms monkey and ape are not to be used interchangeably. Apes include orangutans, gorillas, bonobos, chimpanzees, and humans.
Reference: <author> Pratt, G. A. & Williamson, M. M. </author> <year> (1995), </year> <title> Series Elastic Actuators, </title> <booktitle> in `Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS-95)', </booktitle> <volume> Vol. </volume> <pages> 1, </pages> <address> Pittsburg, PA, </address> <pages> pp. 399406. </pages>
Reference-contexts: Cog also has a three degree of freedom neck and a pair of humanlike arms. Each arm has six compliant degrees of freedom, each of which is powered by a series elastic actuator <ref> (Pratt & Williamson 1995) </ref> which provides a sensible natural behavior: if it is disturbed, or hits an obstacle, the arm simply deflects out of the way. 3.1 Implementing Maintenance of Eye Contact Implementing the first stage in our developmental framework, recognizing and responding to eye contact, requires mostly perceptual abilities.
Reference: <author> Premack, D. </author> <year> (1988), </year> <title> Does the chimpanzee have a theory of mind? revisited, </title> <editor> in R. Byrne & A. Whiten, eds, </editor> <booktitle> `Machiavellian Intelligence: Social Expertise and the Evolution of Intellect in Monkeys, Apes, and Humans.', </booktitle> <publisher> Oxford University Press. </publisher>
Reference-contexts: From an ontological perspective, declarative pointing begins to emerge at approximately 12 months in human infants, which is also the same time that other complex imitative behaviors such as pretend play begin to emerge. From the phylogenetic perspective, declarative pointing has not been identified in any nonhuman primate <ref> (Premack 1988) </ref>. This also corresponds to the phylogeny of imitation; no non-human primate has ever been documented to display imitative behavior under general conditions (Hauser 1996).
Reference: <author> Ristau, C. A. </author> <year> (1991), </year> <title> Before Mindreading: Attention, Purposes and Deception in Birds?, </title> <editor> in A. Whiten, ed., </editor> <title> `Natural Theories of Mind', </title> <publisher> Blackwell. </publisher>
Reference-contexts: Many animals have been shown to be extremely sensitive to eyes that are directed at them, including reptiles like the hognosed snake (Burghardt & Greene 1990), avians like the chicken (Scaife 1976) and the plover <ref> (Ristau 1991) </ref>, and all primates (Cheney & Seyfarth 1990). Identifying whether or not something is looking at you provides an obvious evolutionary advantage in escaping predators, but in many mammals, especially primates, the recognition that another is looking at you carries social significance.
Reference: <author> Rowley, H., Baluja, S. & Kanade, T. </author> <year> (1995), </year> <title> Human Face Detection in Visual Scenes, </title> <type> Technical Report CMU-CS-95-158, </type> <institution> Carnegie Mellon University. </institution>
Reference: <author> Scaife, M. </author> <year> (1976), </year> <title> `The response to eye-like shapes by birds. II. The importance of staring, paired-ness, and shape.', Animal Behavior 24, </title> <publisher> 200206. </publisher>
Reference-contexts: The first step in producing mechanisms of joint attention is the recognition and maintenance of eye contact. Many animals have been shown to be extremely sensitive to eyes that are directed at them, including reptiles like the hognosed snake (Burghardt & Greene 1990), avians like the chicken <ref> (Scaife 1976) </ref> and the plover (Ristau 1991), and all primates (Cheney & Seyfarth 1990). Identifying whether or not something is looking at you provides an obvious evolutionary advantage in escaping predators, but in many mammals, especially primates, the recognition that another is looking at you carries social significance.
Reference: <author> Scaife, M. & Bruner, J. </author> <year> (1975), </year> <title> `The capacity for joint visual attention in the infant.', </title> <booktitle> Nature 253, </booktitle> <pages> 265266. </pages>
Reference-contexts: Joint attention has been investigated by researchers in a variety of fields. Experts in child development are interested in these skills as part of the normal developmental course that infants acquire extremely rapidly, and in a stereotyped sequence <ref> (Scaife & Bruner 1975, Moore & Dunham 1995) </ref>. Additional work on the etiology and behavioral manifestations of developmental disorders such as autism and Asperger's syndrome have focused on disruptions to joint attention mechanisms and demonstrated how vital these skills are in our social world (Cohen & Volkmar 1997, Baron-Cohen 1995).
Reference: <author> Scassellati, B. </author> <year> (1996), </year> <title> Mechanisms of Shared Attention for a Humanoid Robot, in `Embodied Cognition and Action: </title> <booktitle> Papers from the 1996 AAAI Fall Symposium', </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: We have approached joint attention from a slightly different perspective: the construction of human-like robots that exhibit these social skills <ref> (Scassellati 1996) </ref>. This approach focuses first on the construction of useful real-world systems that can both recognize and produce normal human social cues, and second on the evaluation of the complex models of joint attention developed by other disciplines.
Reference: <author> Scassellati, B. </author> <year> (1998a), </year> <title> A Binocular, Foveated Active Vision System, </title> <type> Technical Report 1628, </type> <institution> MIT Artificial Intelligence Lab Memo. </institution>
Reference-contexts: Cog's visual system is designed to mimic some of the capabilities of the human visual system, including binocularity and space-variant sensing <ref> (Scassellati 1998a) </ref>.
Reference: <author> Scassellati, B. </author> <year> (1998b), </year> <title> Finding Eyes and Faces with a Foveated Vision System, </title> <booktitle> in `Proceedings of the Fifteenth National Conference on Artificial Intelligence (AAAI-98)', </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: However, these methods are computationally intensive, and current implementations do not operate in real time. However, a simpler strategy for finding faces can operate in real time and produce good results under dynamic conditions <ref> (Scassellati 1998b) </ref>. The strategy that we use is based on the ratio-template method of object detection reported by Sinha (1994). In summary, finding a face is accomplished with the following five steps: Fig. 4. Images obtained from the peripheral (top) and foveal (bottom) cameras on Cog. <p> Of the missed trials, two resulted from an incorrect face identification (a face was falsely detected in the background clutter), and seven resulted from either an inaccurate saccade or motion of the subject <ref> (Scassellati 1998b) </ref>. In order to accurately recognize whether or not the caregiver is looking at the robot, we must take into account both the position of the eye within the head and the position of the head with respect to the body.
Reference: <author> Sinha, P. </author> <year> (1994), </year> <title> `Object Recognition via Image Invariants: A Case Study', </title> <booktitle> Investigative Ophthalmology and Visual Science 35, </booktitle> <pages> 17351740. </pages>
Reference: <author> Sinha, P. </author> <year> (1996), </year> <title> Perceiving and recognizing three-dimensional forms, </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology. </institution>
Reference-contexts: A combination of the pre-filter and some early-rejection optimizations allows us to detect faces at 20 Hz with little accuracy loss. Face detection is done with a method called ratio templates designed to recognize frontal views of faces under varying lighting conditions <ref> (Sinha 1996) </ref>. A ratio template is composed of a number of regions and a number of relations, as shown in Figure 6. Overlaying the template with a grayscale image location, each region is convolved with the grayscale image to give the average grayscale value for that region.
Reference: <author> Sung, K.-K. & Poggio, T. </author> <year> (1994), </year> <title> Example-based Learning for View-based Human Face Detection, </title> <type> Technical Report 1521, </type> <institution> MIT Artificial Intelligence Lab Memo. </institution>
Reference-contexts: The only necessary motor abilities are to maintain a fixation point. Many computational methods of face detection on static images have been investigated by the machine vision community, for example <ref> (Sung & Poggio 1994, Rowley, Baluja & Kanade 1995) </ref>. However, these methods are computationally intensive, and current implementations do not operate in real time. However, a simpler strategy for finding faces can operate in real time and produce good results under dynamic conditions (Scassellati 1998b).
Reference: <author> Thelen, E. & Smith, L. </author> <year> (1994), </year> <title> A Dynamic Systems Approach to the Development of Cognition and Action, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Gaze following is an extremely useful imitative gesture which serves to focus the child's attention on the same object that the caregiver is attending to. This simplest form of joint attention is believed to be critical for social scaffolding <ref> (Thelen & Smith 1994) </ref>, development of theory of mind (Baron-Cohen 1995), and providing shared meaning for learning language (Wood, Bruner & Ross 1976). This functional imitation appears simple, but a complete implementation of gaze following involves many separate proficiencies, as we will discuss in the following section.
Reference: <author> Whiten, A., ed. </author> <year> (1991), </year> <title> Natural Theories of Mind, </title> <publisher> Blackwell. </publisher>
Reference-contexts: Philosophers have been interested in joint attention both as an explanation for issues of contextual grounding and as a precursor to a theory of other minds <ref> (Whiten 1991, Dennett 1991) </ref>. Evolutionary psychologists and primatologists have focused on the evolution of these simple social skills throughout the animal kingdom as a means of evaluating both the presence of theory of mind and as a measure of social functioning (Povinelli & Preuss 1995, Hauser 1996, Premack 1988). <p> For example, skills that infants acquire early in life, such as sensitivity to eye direction, have been demonstrated in relatively simple vertebrates, such as snakes (Burghardt & Greene 1990), while skills that are acquired later tend to appear only in the primates <ref> (Whiten 1991) </ref>. 2.2 A Module-Based Decomposition As the basis for our implementation of joint attention, we begin with a developmental model from Baron-Cohen (1995).
Reference: <author> Wood, D., Bruner, J. S. & Ross, G. </author> <year> (1976), </year> <title> `The role of tutoring in problem-solving', </title> <journal> Journal of Child Psychology and Psychiatry 17, </journal> <volume> 89100. </volume>
Reference-contexts: This simplest form of joint attention is believed to be critical for social scaffolding (Thelen & Smith 1994), development of theory of mind (Baron-Cohen 1995), and providing shared meaning for learning language <ref> (Wood, Bruner & Ross 1976) </ref>. This functional imitation appears simple, but a complete implementation of gaze following involves many separate proficiencies, as we will discuss in the following section. The third step in our account is imperative pointing.
References-found: 32

