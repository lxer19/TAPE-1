URL: ftp://ftp.cs.rochester.edu/pub/papers/systems/90.Comp_Sys.Psyche_Impl.ps.Z
Refering-URL: http://www.cs.rochester.edu/trs/systems-trs.html
Root-URL: 
Title: Implementation Issues for the Psyche Multiprocessor Operating System  
Author: Michael L. Scott, Thomas J. LeBlanc, Brian D. Marsh, Timothy G. Becker, Cezary Dubnicki, Evangelos P. Markatos, and Neil G. Smithline 
Address: Rochester, NY 14627  
Affiliation: University of Rochester Department of Computer Science  
Abstract: Psyche is a parallel operating system under development at the University of Rochester. The Psyche user interface is designed to allow programs with widely differing concepts of process, sharing, protection, and communication to run efficiently on the same machine, and to interact productively. In addition, the Psyche development effort is addressing a host of implementation issues for large-scale shared-memory multiprocessors, including the organization of kernel functions, data structures, and address maps for machines with non-uniform memory; the migration and replication of pages to maximize locality; the introduction of user-level device drivers, memory management, and scheduling; and remote source-level kernel debugging. We focus in this paper on our implementation of Psyche for the BBN Butterfly Plus multiprocessor, though many of the issues we consider apply to any operating system kernel on a large-scale shared-memory machine. We describe our major design decisions, the results of our initial experience with the implementation, and our plans for continued evaluation and experimentation with kernel implementation techniques. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Accetta, R. Baron, W. Bolosky, D. Golub, R. Rashid, A. Tevanian and M. Young, </author> <title> ``Mach: A New Kernel Foundation for UNIX Development,'' </title> <booktitle> Proceedings of the Summer 1986 USENIX Technical Conference and Exhibition, </booktitle> <month> June </month> <year> 1986, </year> <pages> pp. 93-112. </pages>
Reference-contexts: The Agora project [7] at CMU defines new mechanisms 3 for process interaction based on pattern-directed events and a stylized form of shared memory. Its goals are to support parallel AI applications using heterogeneous languages and machines. Mach <ref> [1] </ref> is representative of a class of operating systems designed for parallel computing. Other systems in this class include Amoeba [24], Chorus [29], Topaz [33], and V [11]. To facilitate parallelism within applications, these systems allow more than one kernel-supported process to run in one address space.
Reference: [2] <institution> BBN Advanced Computers Incorporated, </institution> <note> ``Chrysalis Programmers Manual, Version 4.0,'' </note> <institution> Cambridge, </institution> <address> MA, </address> <month> 10 February </month> <year> 1988. </year>
Reference-contexts: Since temporary segments appear at a different virtual address than the local data segment, address arithmetic would be required when accessing data of another kernel instance. This alternative approach is similar to one employed in Chrysalis, the original operating system for the Butterfly <ref> [2] </ref>. We were not happy with the temporary segment mechanism in Chrysalis; it took too long to remap it.
Reference: [3] <author> O. Babaoglu and W. Joy, </author> <title> ``Converting a Swap-Based System to do Paging in an Architecture Lacking Page-Referenced Bits,'' </title> <booktitle> Proceedings of the Eighth ACM Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1981, </year> <pages> pp. 78-86. </pages>
Reference-contexts: Traditional operating systems overload page faults to implement demand paging as well. They 7 may also use them to compensate for missing hardware features, as in the simulation of reference bits on the VAX <ref> [3] </ref>, or the provision of more than one virtual-to-physical mapping on machines with inverted page tables [27].
Reference: [4] <author> B. N. Bershad, D. T. Ching, E. D. Lazowska, J. Sanislo and M. Schwartz, </author> <title> ``A Remote Procedure Call Facility for Interconnecting Heterogeneous Computer Systems,'' </title> <journal> IEEE Transactions on Software Engineering SE-13:8 (August 1987), </journal> <pages> pp. 880-894. </pages>
Reference-contexts: Other researchers have recognized the need for multiple models of parallel computing. Remote procedure call systems, for example, have often been designed to work between programs written in multiple languages <ref> [4, 16, 17, 22] </ref>. Unfortunately, most RPC-based systems support only one style of process interaction, and are usually intended for a distributed environment; there is no obvious way to extend them to fine-grained process interactions.
Reference: [5] <author> B. N. Bershad, E. D. Lazowska, H. M. Levy and D. B. Wagner, </author> <title> ``An Open Environment for Building Parallel Programming Systems,'' </title> <booktitle> Proceedings of the First ACM Conference on Parallel Programming: Experience with Applications, Languages and Systems, </booktitle> <month> 19-21 July </month> <year> 1988, </year> <pages> pp. 1-9. </pages> <booktitle> In ACM SIGPLAN Notices 23:9. </booktitle>
Reference-contexts: In contrast to existing systems, Psyche also emphasizes data sharing between applications as the default, not the exception, distributes access rights without kernel assistance, checks those rights lazily, and presents an explicit tradeoff between protection and performance. Washington's Presto system <ref> [5] </ref> is perhaps the closest relative to Psyche, at least from the point of view of an individual application.
Reference: [6] <author> B. N. Bershad, T. E. Anderson, E. D. Lazowska and H. M. Levy, </author> <title> ``Lightweight Remote Procedure Call,'' </title> <journal> ACM Transactions on Computer Systems 8:1 (February 1990), </journal> <pages> pp. 37-55. </pages> <booktitle> Also in ACM SIGOPS Operating Systems Review 23:5; originally presented at the Twelfth ACM Symposium on Operating Systems Principles, </booktitle> <month> 3-6 December </month> <year> 1989. </year>
Reference-contexts: Unfortunately, most RPC-based systems support only one style of process interaction, and are usually intended for a distributed environment; there is no obvious way to extend them to fine-grained process interactions. Synchronization is supported only via client-server rendezvous, and even the most efficient implementations <ref> [6] </ref> cannot compete with the low latency of direct access to shared memory. At the operating system level, the Choices project at Illinois [10] allows the kernel itself to be customized through the replacement of C++ abstractions. <p> Because these mechanisms lie at the heart of scheduling, device management, and cross-domain communication, it is imperative that they work as fast as possible. It is not yet clear whether techniques similar to those used in LRPC <ref> [6] </ref> or the Synthesis kernel [23] can be made to work well without an explicit, user-specified ``bind to service'' operation. Our hope is that substantial amounts of time can be saved by automatically precomputing linkage mechanisms for protected procedure calls when a realm is first opened for access. 3.
Reference: [7] <author> R. Bisiani and A. Forin, </author> <title> ``Multilanguage Parallel Programming of Heterogeneous Machines,'' </title> <journal> IEEE Transactions on Computers 37:8 (August 1988), </journal> <pages> pp. 930-945. </pages> <booktitle> Originally presented at the Second International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Palo Alto, CA, </address> <month> 5-8 October </month> <year> 1987. </year>
Reference-contexts: Both Choices and the x-Kernel are best described as reconfigurable operating systems; they provide a single programming model defined at system generation time, rather than supporting multiple models at run time. The Agora project <ref> [7] </ref> at CMU defines new mechanisms 3 for process interaction based on pattern-directed events and a stylized form of shared memory. Its goals are to support parallel AI applications using heterogeneous languages and machines. Mach [1] is representative of a class of operating systems designed for parallel computing.
Reference: [8] <author> W. J. Bolosky, R. P. Fitzgerald and M. L. Scott, </author> <title> ``Simple But Effective Techniques for NUMA Memory Management,'' </title> <booktitle> Proceedings of the Twelfth ACM Symposium on Operating Systems Principles, </booktitle> <month> 3-6 December </month> <year> 1989, </year> <pages> pp. 19-31. </pages> <booktitle> In ACM SIGOPS Operating Systems Review 23:5. </booktitle> <pages> 19 </pages>
Reference-contexts: Page faults may be used for lazy initiation of expensive operations, as in copy-on-write message passing [14], time-critical process migration [34, 38], or the management of locality in machines with non-uniform memory access times <ref> [8, 13] </ref>. In Psyche, page faults are given two more functions: the opening of realms for optimized access and the initiation of protected procedure calls. Implementing these functions efficiently, without compromising the performance of other operations triggered by page faults, is a potentially difficult task.
Reference: [9] <author> C. M. Brown, R. J. Fowler, T. J. LeBlanc, M. L. Scott, M. Srinivas and others, </author> <title> ``DARPA Parallel Architecture Benchmark Study,'' </title> <type> BPR 13, </type> <institution> Computer Science Department, University of Rochester, </institution> <month> October </month> <year> 1986. </year>
Reference-contexts: The challenge for systems software is to keep the flexibility of the hardware visible at the level of the kernel interface. A major focus of our experimentation with the Butterfly has been the evaluation and comparison of multiple models of parallel computing <ref> [9, 18, 19] </ref>. Our principal conclusion is that while every programming model has applications for which it seems appropriate, no single model is appropriate for every application. <p> Our principal conclusion is that while every programming model has applications for which it seems appropriate, no single model is appropriate for every application. In an intensive benchmark study conducted in 1986 <ref> [9] </ref>, we implemented seven different computer vision applications on the Butterfly over the course of a three-week period. Based on the characteristics of the problems, programmers chose to use four different programming models, provided by four of our systems packages.
Reference: [10] <author> R. Campbell, G. Johnston and V. Russo, </author> <title> ``Choices (Class Hierarchical Open Interface for Custom Embedded Systems),'' </title> <booktitle> ACM SIGOPS Operating Systems Review 21:3 (July 1987), </booktitle> <pages> pp. 9-17. </pages>
Reference-contexts: Synchronization is supported only via client-server rendezvous, and even the most efficient implementations [6] cannot compete with the low latency of direct access to shared memory. At the operating system level, the Choices project at Illinois <ref> [10] </ref> allows the kernel itself to be customized through the replacement of C++ abstractions. The University of Arizona's x-Kernel [26] adopts a similar approach in the context of communication protocols for message-based machines.
Reference: [11] <author> D. Cheriton, </author> <title> ``The V Kernel A Software Base for Distributed Systems,'' </title> <booktitle> IEEE Software 1:2 (April 1984), </booktitle> <pages> pp. 19-42. </pages>
Reference-contexts: Its goals are to support parallel AI applications using heterogeneous languages and machines. Mach [1] is representative of a class of operating systems designed for parallel computing. Other systems in this class include Amoeba [24], Chorus [29], Topaz [33], and V <ref> [11] </ref>. To facilitate parallelism within applications, these systems allow more than one kernel-supported process to run in one address space. To implement minimal-cost threads of control, however, or to exercise control over the representation and scheduling of threads, coroutine packages must still be used within a single kernel process.
Reference: [12] <author> D. Clark, </author> <title> ``The Structuring of Systems Using Upcalls,'' </title> <booktitle> Proceedings of the Tenth ACM Symposium on Operating Systems Principles, </booktitle> <month> 1-4 December </month> <year> 1985, </year> <pages> pp. 171-180. </pages> <booktitle> In ACM SIGOPS Operating Systems Review 19:5. </booktitle>
Reference-contexts: We are not yet sure how much of that functionality can be recreated in user space, nor are we sure how quickly we will be able to propagate faults through the layers. Experience with systems such as Swift <ref> [12] </ref> and the x-Kernel [26] indicates that layering need not preclude efficiency.
Reference: [13] <author> A. L. Cox and R. J. Fowler, </author> <title> ``The Implementation of a Coherent Memory Abstraction on a NUMA Multiprocessor: Experiences with PLATINUM,'' </title> <booktitle> Proceedings of the Twelfth ACM Symposium on Operating Systems Principles, </booktitle> <month> 3-6 December </month> <year> 1989, </year> <pages> pp. 32-44. </pages> <booktitle> In ACM SIGOPS Operating Systems Review 23:5. </booktitle>
Reference-contexts: Page faults may be used for lazy initiation of expensive operations, as in copy-on-write message passing [14], time-critical process migration [34, 38], or the management of locality in machines with non-uniform memory access times <ref> [8, 13] </ref>. In Psyche, page faults are given two more functions: the opening of realms for optimized access and the initiation of protected procedure calls. Implementing these functions efficiently, without compromising the performance of other operations triggered by page faults, is a potentially difficult task.
Reference: [14] <author> R. Fitzgerald and R. Rashid, </author> <title> ``The Integration of Virtual Memory Management and Inter-process Communication in Accent,'' </title> <journal> ACM Transactions on Computer Systems 4:2 (May 1986), </journal> <pages> pp. 147-177. </pages> <booktitle> Originally presented at the Tenth ACM Symposium on Operating Systems Principles, </booktitle> <month> 1-4 December </month> <year> 1985. </year>
Reference-contexts: Page faults may be used for lazy initiation of expensive operations, as in copy-on-write message passing <ref> [14] </ref>, time-critical process migration [34, 38], or the management of locality in machines with non-uniform memory access times [8, 13]. In Psyche, page faults are given two more functions: the opening of realms for optimized access and the initiation of protected procedure calls.
Reference: [15] <author> R. J. Fowler, T. J. LeBlanc and J. M. Mellor-Crummey, </author> <title> ``An Integrated Approach to Parallel Program Debugging and Performance Analysis on Large-Scale Multiprocessors,'' </title> <booktitle> Proceedings, ACM SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, </booktitle> <month> 5-6 May </month> <year> 1988, </year> <pages> pp. 163-173. </pages> <note> In ACM SIGPLAN Notices 24:1 (January 1989). </note>
Reference-contexts: We intend to use our existing debugging facility as the base for user-level debugging of multi-model programs. As part of a related research project we have developed sophisticated techniques for monitoring and analysis of parallel programs, including deterministic replay of fundamentally non-deterministic programs <ref> [15] </ref>. We are currently developing extensions to our techniques that will allow the developers of programming language run-time packages and communication libraries to define debugging interfaces that allow a debugger to talk to the user in 17 terms of model-specific, high level abstractions.
Reference: [16] <author> R. Hayes and R. D. Schlichting, </author> <title> ``Facilitating Mixed Language Programming in Distributed Systems,'' </title> <journal> IEEE Transactions on Software Engineering SE-13:12 (December 1987), </journal> <pages> pp. 1254-1264. </pages>
Reference-contexts: Other researchers have recognized the need for multiple models of parallel computing. Remote procedure call systems, for example, have often been designed to work between programs written in multiple languages <ref> [4, 16, 17, 22] </ref>. Unfortunately, most RPC-based systems support only one style of process interaction, and are usually intended for a distributed environment; there is no obvious way to extend them to fine-grained process interactions.
Reference: [17] <author> M. B. Jones, R. F. Rashid and M. R. Thompson, ``Matchmaker: </author> <title> An Interface Specification Language for Distributed Processing,'' </title> <booktitle> Conference Record of the Twelfth ACM Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1985, </year> <pages> pp. 225-235. </pages>
Reference-contexts: Other researchers have recognized the need for multiple models of parallel computing. Remote procedure call systems, for example, have often been designed to work between programs written in multiple languages <ref> [4, 16, 17, 22] </ref>. Unfortunately, most RPC-based systems support only one style of process interaction, and are usually intended for a distributed environment; there is no obvious way to extend them to fine-grained process interactions.
Reference: [18] <author> T. J. LeBlanc, </author> <title> ``Shared Memory Versus Message-Passing in a Tightly-Coupled Multiprocessor: A Case Study,'' </title> <booktitle> Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <month> 19-22 August </month> <year> 1986, </year> <pages> pp. 463-466. </pages>
Reference-contexts: The challenge for systems software is to keep the flexibility of the hardware visible at the level of the kernel interface. A major focus of our experimentation with the Butterfly has been the evaluation and comparison of multiple models of parallel computing <ref> [9, 18, 19] </ref>. Our principal conclusion is that while every programming model has applications for which it seems appropriate, no single model is appropriate for every application.
Reference: [19] <author> T. J. LeBlanc, M. L. Scott and C. M. Brown, </author> <title> ``Large-Scale Parallel Programming: Experience with the BBN Butterfly Parallel Processor,'' </title> <booktitle> Proceedings of the First ACM Conference on Parallel Programming: Experience with Applications, Languages and Systems, </booktitle> <month> 19-21 July </month> <year> 1988, </year> <pages> pp. 161-172. </pages>
Reference-contexts: In the course of this experimentation 2 we ported three compilers to the Butterfly, developed five major and several minor library pack-ages, built two different operating systems, and implemented dozens of applications. A summary of this work can be found in <ref> [19] </ref>. As we see it, the most significant strength of a shared-memory architecture is its ability to support efficient implementations of many different parallel programming models, encompassing a wide range of grain sizes of process interaction. <p> The challenge for systems software is to keep the flexibility of the hardware visible at the level of the kernel interface. A major focus of our experimentation with the Butterfly has been the evaluation and comparison of multiple models of parallel computing <ref> [9, 18, 19] </ref>. Our principal conclusion is that while every programming model has applications for which it seems appropriate, no single model is appropriate for every application.
Reference: [20] <author> T. J. LeBlanc, J. M. Mellor-Crummey, N. M. Gafter, L. A. Crowl and P. C. Dibble, </author> <title> ``The Elmwood Multiprocessor Operating System,'' </title> <journal> Software Practice and Experience 19:11 (November 1989), </journal> <pages> pp. 1029-1056. </pages>
Reference-contexts: Ready lists, for example, are manipulated remotely in order to implement protected invocations. The alternative, a message-passing scheme in 8 which instances of the kernel would be asked to perform the manipulations themselves <ref> [20] </ref>, was rejected as overly expensive. Most modifications to remote data structures can be performed asynchronously; the remote kernel will notice them the next time the data is read.
Reference: [21] <author> T. J. LeBlanc, B. D. Marsh and M. L. Scott, </author> <title> ``Memory Management for Large-Scale NUMA Multiprocessors,'' </title> <type> TR 311, </type> <institution> Computer Science Department, University of Roches-ter, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: We were particularly concerned with the interaction of data replication and migration with demand paging and protected procedure calls, and with the structuring of a VM system that could balance all these concerns without becoming unmaintainable. The design we developed <ref> [21] </ref> has 14 four distinct abstraction layers. The lowest layer encapsulates physical page frames and page tables. The next layer provides the illusion of uniform memory access time through page replication and migration. The third layer provides a default pager for backing store and a mechanism for user-level pagers.
Reference: [22] <author> B. Liskov, R. Bloom, D. Gifford, R. Scheifler and W. Weihl, </author> <title> ``Communication in the Mercury System,'' </title> <booktitle> Proceedings of the 21st Annual Hawaii International Conference on System Sciences, </booktitle> <month> January </month> <year> 1988, </year> <pages> pp. 178-187. 20 </pages>
Reference-contexts: Other researchers have recognized the need for multiple models of parallel computing. Remote procedure call systems, for example, have often been designed to work between programs written in multiple languages <ref> [4, 16, 17, 22] </ref>. Unfortunately, most RPC-based systems support only one style of process interaction, and are usually intended for a distributed environment; there is no obvious way to extend them to fine-grained process interactions.
Reference: [23] <author> H. Massalin and C. Pu, </author> <title> ``Threads and Input/Output in the Synthesis Kernel,'' </title> <booktitle> Proceedings of the Twelfth ACM Symposium on Operating Systems Principles, </booktitle> <month> 3-6 December </month> <year> 1989, </year> <pages> pp. 191-201. </pages> <booktitle> In ACM SIGOPS Operating Systems Review 23:5. </booktitle>
Reference-contexts: Because these mechanisms lie at the heart of scheduling, device management, and cross-domain communication, it is imperative that they work as fast as possible. It is not yet clear whether techniques similar to those used in LRPC [6] or the Synthesis kernel <ref> [23] </ref> can be made to work well without an explicit, user-specified ``bind to service'' operation. Our hope is that substantial amounts of time can be saved by automatically precomputing linkage mechanisms for protected procedure calls when a realm is first opened for access. 3. Kernel Organization 3.1. <p> It is currently unclear to what extent this goal can be achieved with reasonable performance. Much will depend on the speed with which we can deliver software interrupts. Experience with the Synthesis kernel at Columbia <ref> [23] </ref> suggests that very high speed may be possible. Psyche is a more complex system than Synthesis, however, and we may be forced to leave part of the network protocol stack (ARP, IP, UDP, etc.) inside the Psyche kernel.
Reference: [24] <author> S. J. Mullender and A. S. Tanenbaum, </author> <title> ``The Design of a Capability-Based Distributed Operating System,'' </title> <journal> The Computer Journal 29:4 (1986), </journal> <pages> pp. 289-299. </pages>
Reference-contexts: Its goals are to support parallel AI applications using heterogeneous languages and machines. Mach [1] is representative of a class of operating systems designed for parallel computing. Other systems in this class include Amoeba <ref> [24] </ref>, Chorus [29], Topaz [33], and V [11]. To facilitate parallelism within applications, these systems allow more than one kernel-supported process to run in one address space.
Reference: [25] <author> J. K. Ousterhout, </author> <title> Medusa, A Distributed Operating System, </title> <publisher> UMI Press, </publisher> <year> 1981. </year>
Reference-contexts: Data and code sharing, synchronization, communication, remote code execution, and process migration can all have serious effects on the performance of the system, which the scheduler can mitigate by using appropriate policies. For example, under round-robin scheduling and without co-scheduling <ref> [25] </ref>, a process may find itself unable to run (due to synchronization constraints) when it is allocated the processor, or it may immediately block or spin due to a synchronization constraint.
Reference: [26] <author> L. Peterson, N. Hutchinson, S. O'Malley and M. Abbott, </author> <title> ``RPC in the x-Kernel: Evaluating New Design Techniques,'' </title> <booktitle> Proceedings of the Twelfth ACM Symposium on Operating Systems Principles, </booktitle> <month> 3-6 December </month> <year> 1989, </year> <pages> pp. 91-101. </pages> <booktitle> In ACM SIGOPS Operating Systems Review 23:5. </booktitle>
Reference-contexts: At the operating system level, the Choices project at Illinois [10] allows the kernel itself to be customized through the replacement of C++ abstractions. The University of Arizona's x-Kernel <ref> [26] </ref> adopts a similar approach in the context of communication protocols for message-based machines. Both Choices and the x-Kernel are best described as reconfigurable operating systems; they provide a single programming model defined at system generation time, rather than supporting multiple models at run time. <p> We are not yet sure how much of that functionality can be recreated in user space, nor are we sure how quickly we will be able to propagate faults through the layers. Experience with systems such as Swift [12] and the x-Kernel <ref> [26] </ref> indicates that layering need not preclude efficiency.
Reference: [27] <author> R. Rashid, A. Tevanian, M. Young, D. Golub, R. Baron, D. Black, W. Bolosky and J. Chew, </author> <title> ``Machine-Independent Virtual Memory Management for Paged Uniprocessor and Multiprocessor Architectures,'' </title> <journal> IEEE Transactions on Computers 37:8 (August 1988), </journal> <pages> pp. 896-908. </pages> <booktitle> Originally presented at the Second International International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> 5-8 October </month> <year> 1987. </year>
Reference-contexts: They 7 may also use them to compensate for missing hardware features, as in the simulation of reference bits on the VAX [3], or the provision of more than one virtual-to-physical mapping on machines with inverted page tables <ref> [27] </ref>. Page faults may be used for lazy initiation of expensive operations, as in copy-on-write message passing [14], time-critical process migration [34, 38], or the management of locality in machines with non-uniform memory access times [8, 13].
Reference: [28] <author> D. Redell, </author> <title> ``Experience with Topaz TeleDebugging,'' </title> <booktitle> Proceedings, ACM SIGPLAN/- SIGOPS Workshop on Parallel and Distributed Debugging, </booktitle> <month> 5-6 May </month> <year> 1988, </year> <pages> pp. 35-44. </pages> <note> In ACM SIGPLAN Notices 24:1 (January 1989). </note>
Reference-contexts: Kernel Debugging The most important tool we have constructed for Psyche is a mechanism for remote, source-level debugging, in the style of the Topaz TeleDebug facility developed at DEC SRC <ref> [28] </ref>. An interactive front end runs on a Sun workstation using the GNU gdb debugger. Gdb comes with a remote debugging facility; relatively minor modifications were required to get it to work with Psyche. The debugger communicates via UDP with a multiplexor running on the Butterfly's host machine.
Reference: [29] <author> M. Rozier and others, </author> <title> ``Chorus Distributed Operating Systems,'' </title> <booktitle> Computing Systems 1:4 (Fall 1988), </booktitle> <pages> pp. 305-370. </pages>
Reference-contexts: Its goals are to support parallel AI applications using heterogeneous languages and machines. Mach [1] is representative of a class of operating systems designed for parallel computing. Other systems in this class include Amoeba [24], Chorus <ref> [29] </ref>, Topaz [33], and V [11]. To facilitate parallelism within applications, these systems allow more than one kernel-supported process to run in one address space.
Reference: [30] <author> M. L. Scott, T. J. LeBlanc and B. D. Marsh, </author> <title> ``Design Rationale for Psyche, a General-Purpose Multiprocessor Operating System,'' </title> <booktitle> Proceedings of the 1988 International Conference on Parallel Processing, V. II Software, </booktitle> <month> 15-19 August </month> <year> 1988, </year> <pages> pp. 255-262. </pages>
Reference: [31] <author> M. L. Scott, T. J. LeBlanc and B. D. Marsh, </author> <title> ``Evolution of an Operating System for Large-Scale Shared-Memory Multiprocessors,'' </title> <type> TR 309, </type> <institution> Computer Science Department, University of Rochester, </institution> <month> March </month> <year> 1989. </year>
Reference: [32] <author> M. L. Scott, T. J. LeBlanc and B. D. Marsh, </author> <booktitle> ``Multi-Model Parallel Programming in Psyche,'' Proceedings of the Second ACM Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> 14-16 March, </month> <year> 1990, </year> <pages> pp. 70-78. </pages> <booktitle> In ACM SIGPLAN Notices 25:3. </booktitle>
Reference-contexts: The fundamental kernel abstraction, an abstract data object called a realm, can be used to implement such diverse mechanisms as monitors, remote procedure calls, buffered message passing, and unconstrained shared memory <ref> [32] </ref>. Sharing is the default in Psyche; protection is provided only when the user specifically indicates a willingness to sacrifice performance in order to obtain it. Sharing also occurs between the user and the kernel, and facilitates explicit, user-level control of process structure and scheduling. <p> In the course of quantifying these costs (and recoding to reduce them), we also plan to investigate the ramifications of allowing virtual processor preemption in the kernel. Multi-model parallel programming forms the focus of our user-level work <ref> [32] </ref>. We are evaluating the extent to which Psyche kernel primitives facilitate use of, and interaction between, disparate process and communication models. We are also investigating appropriate user-level tools for multi-model debugging, parallel program configuration, management of access rights, name service, and file service.
Reference: [33] <author> C. P. Thacker and L. C. Stewart, ``Firefly: </author> <title> A Multiprocessor Workstation,'' </title> <journal> IEEE Transactions on Computers 37:8 (August 1988), </journal> <pages> pp. 909-920. </pages> <booktitle> Originally presented at the Second International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> 5-8 October </month> <year> 1987. </year>
Reference-contexts: Its goals are to support parallel AI applications using heterogeneous languages and machines. Mach [1] is representative of a class of operating systems designed for parallel computing. Other systems in this class include Amoeba [24], Chorus [29], Topaz <ref> [33] </ref>, and V [11]. To facilitate parallelism within applications, these systems allow more than one kernel-supported process to run in one address space.
Reference: [34] <author> M. Theimer, K. Lantz and D. Cheriton, </author> <title> ``Preemptable Remote Execution Facilities for the V-System,'' </title> <booktitle> Proceedings of the Tenth ACM Symposium on Operating Systems Principles, </booktitle> <month> 1-4 December </month> <year> 1985, </year> <pages> pp. 2-12. </pages> <booktitle> In ACM SIGOPS Operating Systems Review 19:5. </booktitle>
Reference-contexts: Page faults may be used for lazy initiation of expensive operations, as in copy-on-write message passing [14], time-critical process migration <ref> [34, 38] </ref>, or the management of locality in machines with non-uniform memory access times [8, 13]. In Psyche, page faults are given two more functions: the opening of realms for optimized access and the initiation of protected procedure calls.
Reference: [35] <author> R. H. Thomas and W. Crowther, </author> <title> ``The Uniform System: An Approach to Runtime Support for Large Scale Shared Memory Parallel Processors,'' </title> <booktitle> Proceedings of the 1988 International Conference on Parallel Processing, V. II Software, </booktitle> <month> 15-19 August </month> <year> 1988, </year> <pages> pp. 245-254. </pages>
Reference-contexts: Shared-memory multiprocessors can support this fine-grained sharing, and match the speed of multicomputers for message passing, too. We have used the BBN Butterfly to experiment with many different programming models. BBN has developed a model based on fine-grain memory sharing <ref> [35] </ref>. In addition, we have implemented remote procedure calls, an object-oriented encapsulation of processes, memory blocks, and messages, a message-based library package, a shared-memory model with numerous lightweight processes, and a message-based programming language.
Reference: [36] <author> A. W. Wilson, Jr., </author> <title> ``Hierarchical Cache/Bus Architecture for Shared Memory Multiprocessors,'' </title> <booktitle> Proceedings of the Fourteenth Annual International Symposium on Computer Architecture, </booktitle> <month> 2-5 June </month> <year> 1987, </year> <pages> pp. 244-252. 21 </pages>
Reference-contexts: A NUMA host is modeled as a collection of clusters, each of which comprises processors and memories with identical locality characteristics. A Sequent or Encore machine consists of a single cluster. On a Butterfly, each node is a cluster unto itself. The proposed Encore Gigamax <ref> [36] </ref> would consist of non-trivial clusters. Our most basic kernel design decisions have been adopted with an eye toward efficient use of very large NUMA machines. (1) The kernel is symmetric; each cluster contains a separate copy of most of the kernel code, and each processor executes this code independently.
Reference: [37] <author> B. Yamauchi, ``Juggler: </author> <title> Real-Time Sensorimotor Control Using Independent Agents,'' </title> <booktitle> Optical Society of America Image Understanding and Machine Vision Conference, 1989 Technical Digest Series, V. </booktitle> <volume> 14, </volume> <month> June </month> <year> 1989, </year> <pages> pp. 6-9. </pages>
Reference-contexts: We began writing code for the kernel in the summer of 1988, building on the bare machine. Our first toy program ran in user space in December of 1988. Our first major application <ref> [37] </ref> was ported to Psyche in November of 1989. It uses video cameras and a robot arm to locate and bat a balloon.
Reference: [38] <author> E. Zayas, </author> <title> ``Attaching the Process Migration Bottleneck,'' </title> <booktitle> Proceedings of the Eleventh ACM Symposium on Operating Systems Principles, </booktitle> <month> 8-11 November </month> <year> 1987, </year> <pages> pp. 13-24. </pages> <booktitle> In ACM SIGOPS Operating Systems Review 21:5. </booktitle> <pages> 22 </pages>
Reference-contexts: Page faults may be used for lazy initiation of expensive operations, as in copy-on-write message passing [14], time-critical process migration <ref> [34, 38] </ref>, or the management of locality in machines with non-uniform memory access times [8, 13]. In Psyche, page faults are given two more functions: the opening of realms for optimized access and the initiation of protected procedure calls.
References-found: 38

