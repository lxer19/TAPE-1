URL: http://www.cs.princeton.edu/~wtcorrea/s98/texture.ps.gz
Refering-URL: http://www.cs.princeton.edu/gfx/proj/texcel/index.html
Root-URL: http://www.cs.princeton.edu
Title: Texture Mapping for Cel Animation  2 Walt Disney Feature Animation (a) Flat colors (b) Complex texture  
Author: Wagner Toledo Correa Robert J. Jensen Craig E. Thayer Adam Finkelstein 
Keyword: CR Categories: I.3.3 and I.3.7 [Computer Graphics]. Keywords: Cel animation, texture mapping, silhouette detection, warp, metamorphosis, morph, non-photorealistic rendering.  
Affiliation: 1 Princeton University  
Abstract: Figure 1: A frame of cel animation with the foreground character painted by (a) the conventional method, and (b) our system. Abstract We present a method for applying complex textures to hand-drawn characters in cel animation. The method correlates features in a simple, textured, 3-D model with features on a hand-drawn figure, and then distorts the model to conform to the hand-drawn artwork. The process uses two new algorithms: a silhouette detection scheme and a depth-preserving warp. The silhouette detection algorithm is simple and efficient, and it produces continuous, smooth, visible contours on a 3-D model. The warp distorts the model in only two dimensions to match the artwork from a given camera perspective, yet preserves 3-D effects such as self-occlusion and foreshortening. The entire process allows animators to combine complex textures with hand-drawn artwork, leveraging the strengths of 3-D computer graphics while retaining the expressiveness of traditional hand-drawn cel animation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Kendall E. Atkinson. </author> <title> An Introduction to Numerical Analysis. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: To calculate the control points, we solve an overdetermined linear system using least squares data fitting techniques that minimize the root-mean-square error between the data and the resulting curve <ref> [1, 17, 19, 22] </ref>. Our fitting procedure attempts to use as few control points as possible, given a maximum error threshold. 4.3 Ghostbusting The marker curves created in this section drive the warp described in Section 5.
Reference: [2] <author> Thaddeus Beier and Shawn Neely. </author> <title> Feature-Based Image Metamorphosis. </title> <editor> In Edwin E. Catmull, editor, </editor> <booktitle> SIGGRAPH 92 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 3542. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> July </month> <year> 1992. </year>
Reference-contexts: The heart of our method is a new warp. Critical for visual effects such as metamorphosis (or morphing), image warps have been extensively studied. Beier and Neely's warp <ref> [2] </ref> distorts images in 2-D based on features marked with line segments; it was the inspiration for the warp that we describe, which works with curved feature markers and provides 3-D effects such as occlusion and foreshortening. <p> Our fitting procedure attempts to use as few control points as possible, given a maximum error threshold. 4.3 Ghostbusting The marker curves created in this section drive the warp described in Section 5. Beier and Neely <ref> [2] </ref> observe that image warps tend to fail if feature lines cross, producing what they call ghosts. Near the intersection between two feature lines, both features exert a strong influence on the warp. <p> Also, this permits us to compute the warp at low resolution for the interactive parts of the process, and later perform the final rendering at high-resolution. Litwinowicz and Williams [13] also use forward mapping, whereas Beier and Neely <ref> [2] </ref> use inverse mapping: for each point in the destination, they find the location at which to sample the input image. <p> By varying f , we control how fast the contribution falls off with distance. If f is large, distant points will have almost no influence. (The factors * and f are similar to the factors a and b of the warp of Beier and Neely <ref> [2] </ref>.) The figures in this paper use * = 10 4 and f between 2 and 3. 6.2 Modeling and Viewing Parameters Our warp is based on the projection of the 3-D model into screen space.
Reference: [3] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1990. </year>
Reference-contexts: Finally, we choose the highest confidence value to represent the type of the edge. After the classification process is finished, finding the edges on the model is equivalent to finding the connected components of G, which can be done efficiently using depth-first search <ref> [3, 26] </ref>. We traverse the graph, finding paths of edges that have the same edge type and the same color (within a tolerance). The running time of depth-first search is fi (jV j+jEj) [3]. In our case, both jV j and jEj are linear in the number of pixels. <p> We traverse the graph, finding paths of edges that have the same edge type and the same color (within a tolerance). The running time of depth-first search is fi (jV j+jEj) <ref> [3] </ref>. In our case, both jV j and jEj are linear in the number of pixels.
Reference: [4] <author> Cassidy J. Curtis, Sean E. Anderson, Joshua E. Seims, Kurt W. Fleischer, and David H. Salesin. </author> <title> Computer-Generated Watercolor. </title> <editor> In Turner Whitted, editor, </editor> <booktitle> SIGGRAPH 97 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 421430. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1997. </year>
Reference-contexts: For the researchers who have investigated animation and video in simulated media (oil paint for Meier [15] and Litwinowicz [12]; pen and ink for Markosian et al. [14] and Winkenbach et al. [32]; and watercolor for Curtis et al. <ref> [4] </ref>) a challenge has been to maintain temporal coherence in the individual strokes of the artwork to avoid boiling.
Reference: [5] <author> Gerald Farin. </author> <title> Curves and Surfaces for Computer Aided Geometric Design: a Practical Guide. </title> <publisher> Academic Press, </publisher> <year> 1997. </year>
Reference-contexts: For the animations shown in this paper, our models were represented by tensor product B-spline patches <ref> [5] </ref>. However, before performing the warp described in Section 5, we convert our models to polygon meshes. <p> that it is simple to implement, it leverages existing support for hidden surface removal and texture mapping, it works for any object with a well-defined parameter space, and produces smooth, visible silhouette curves. 4.2 Curve Fitting To represent each marker curve, we use a chord-length parameterized endpoint-interpolating uniform cubic B-spline <ref> [5, 19] </ref>. These curves have several desirable properties: they are smooth; they can be linked head to tail (without a break between them); the rate of change of the curve with respect to the parameter is uniform; and they are well understood.
Reference: [6] <author> Jean-Daniel Fekete, Erick Bizouarn, Eric Cournarie, Thierry Galas, and Frederic Taillefer. TicTacToon: </author> <title> A Paperless System for Professional 2-D Animation. </title> <editor> In Robert Cook, editor, </editor> <booktitle> SIGGRAPH 95 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 7990. </pages> <publisher> ACM SIGGRAPH, Addison Wes-ley, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Researchers have largely automated the image processing and compositing aspects of cel animation <ref> [6, 18, 25, 28] </ref>, wherein the conventional ink-and-paint stage could be replaced with the textures resulting from our system. Wood et al. [35] demonstrate the use of 3-D computer graphics in the design of static background scenery; in contrast, this paper addresses animated foreground characters. <p> renders the model. (f) The computer composites the rendered model with the hand drawn line art and background scenery. (a) Hand-drawn art (b) 3-D model (c) Edges in model (d) Edges in art (e) Warped model (f) Final frame Our method fits into the existing production pipeline for cel animation <ref> [6, 18] </ref>. Steps (a) and (f) are stages in the current digital production process, with the ink-and-paint stage between them. We are offering, as an alternative to the constant colors of the ink-and-paint stage, a process that applies complex textures to the drawings.
Reference: [7] <author> James D. Foley, Andries van Dam, Steven K. Feiner, and John F. Hughes. </author> <title> Computer Graphics, </title> <booktitle> Principles and Practice. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <note> second edition, </note> <year> 1990. </year>
Reference-contexts: This paper also presents a scheme for silhouette detection based on rendering the 3-D model into a frame buffer. In general, silhouette detection is closely-related to hidden surface removal, for which there are a host of methods <ref> [7] </ref>. Markosian et al. [14] present some improvements and simplifications of traditional algorithms, and are able to trade off accuracy for speed. Most algorithms dealing with polyhedral input traverse the mesh tagging edges of the model as silhouettes.
Reference: [8] <author> Michael Gleicher. </author> <title> Image Snapping. </title> <editor> In Robert Cook, editor, </editor> <booktitle> SIGGRAPH 95 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 183190. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Next the user picks model marker curves, and specifies corresponding drawing marker curves. To specify these curves, the user traces over features in the hand-drawn art a time-consuming and tedious task. To reduce user-intervention, we use contour tracing techniques similar to those presented by Gleicher <ref> [8] </ref> and Mortensen and Barrett [16] in which the cursor automatically snaps onto nearby artwork. For each drawing marker, tracing results in a list of pixels that we subsequently approximate with a smooth curve, as described in Section 4.2. We now have a collection of model and drawing markers.
Reference: [9] <author> Michael Kass, Andrew Witkin, and Demetri Terzopoulos. Snakes: </author> <title> Active Contour Models. </title> <journal> International Journal of Computer Vision, </journal> <pages> pages 321331, </pages> <year> 1988. </year>
Reference-contexts: Lee et al. [10] have described a user-interface based on snakes <ref> [9] </ref> that is useful for feature specification, as well as a new warp based on free-form deformations [24].
Reference: [10] <author> Seung-Yong Lee, Kyung-Yong Chwa, Sung Yong Shin, and George Wolberg. </author> <title> Image Metamorphosis Using Snakes and Free-Form Deformations. </title> <editor> In Robert Cook, editor, </editor> <booktitle> SIG-GRAPH 95 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 439448. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Litwinowicz and Williams [13] describe a warp (based on a thin-plate smoothness functional) that behaves more smoothly than that of Beier and Neely in the neighborhood of feature markers; perhaps a hybrid approach could combine these smoothness properties into the warp that we describe. Lee et al. <ref> [10] </ref> have described a user-interface based on snakes [9] that is useful for feature specification, as well as a new warp based on free-form deformations [24].
Reference: [11] <author> Apostolos Lerios, Chase D. Garfinkle, and Marc Levoy. </author> <title> Feature-Based Volume Metamorphosis. </title> <editor> In Robert Cook, editor, </editor> <booktitle> SIGGRAPH 95 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 449456. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Warps have been applied in other domains as well, such as the work of Sederberg et al. [23] on 2-D curves, Witkin and Popovic [33] on motion curves for 3-D animation, and Lerios et al. <ref> [11] </ref> on volumes. This paper also presents a scheme for silhouette detection based on rendering the 3-D model into a frame buffer. In general, silhouette detection is closely-related to hidden surface removal, for which there are a host of methods [7].
Reference: [12] <author> Peter Litwinowicz. </author> <title> Processing Images and Video for an Impressionist Effect. </title> <editor> In Turner Whitted, editor, </editor> <booktitle> SIGGRAPH 97 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 407414. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1997. </year>
Reference-contexts: For the researchers who have investigated animation and video in simulated media (oil paint for Meier [15] and Litwinowicz <ref> [12] </ref>; pen and ink for Markosian et al. [14] and Winkenbach et al. [32]; and watercolor for Curtis et al. [4]) a challenge has been to maintain temporal coherence in the individual strokes of the artwork to avoid boiling.
Reference: [13] <author> Peter Litwinowicz and Lance Williams. </author> <title> Animating Images with Drawings. </title> <editor> In Andrew Glassner, editor, </editor> <booktitle> SIGGRAPH 94 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 409412. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> July </month> <year> 1994. </year>
Reference-contexts: Beier and Neely's warp [2] distorts images in 2-D based on features marked with line segments; it was the inspiration for the warp that we describe, which works with curved feature markers and provides 3-D effects such as occlusion and foreshortening. Litwinowicz and Williams <ref> [13] </ref> describe a warp (based on a thin-plate smoothness functional) that behaves more smoothly than that of Beier and Neely in the neighborhood of feature markers; perhaps a hybrid approach could combine these smoothness properties into the warp that we describe. <p> The motivation in this case is that we get self-occlusion and hidden-surface removal for free using normal z-buffered rendering. Also, this permits us to compute the warp at low resolution for the interactive parts of the process, and later perform the final rendering at high-resolution. Litwinowicz and Williams <ref> [13] </ref> also use forward mapping, whereas Beier and Neely [2] use inverse mapping: for each point in the destination, they find the location at which to sample the input image.
Reference: [14] <author> Lee Markosian, Michael A. Kowalski, Samuel J. Trychin, Lubomir D. Bourdev, Daniel Goldstein, and John F. Hughes. </author> <title> Real-time Nonphotorealistic Rendering. </title> <editor> In Turner Whitted, editor, </editor> <booktitle> SIGGRAPH 97 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 415420. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1997. </year>
Reference-contexts: However, it turns out that there are several reasons why hand-drawn 2-D animation will not be replaced with computer-generated 3-D figures. For traditional animators, it is much easier to work in 2-D rather than in 3-D. Hand-drawn animation enjoys an economy of line <ref> [14] </ref>, where just a few gestures with a pen can suggest life and emotion that is difficult to achieve by moving 3-D models. Finally, there exists an entire art form (and industry) built around hand-drawn animation, whose techniques have been refined for more than 80 years [27]. <p> This paper also presents a scheme for silhouette detection based on rendering the 3-D model into a frame buffer. In general, silhouette detection is closely-related to hidden surface removal, for which there are a host of methods [7]. Markosian et al. <ref> [14] </ref> present some improvements and simplifications of traditional algorithms, and are able to trade off accuracy for speed. Most algorithms dealing with polyhedral input traverse the mesh tagging edges of the model as silhouettes. <p> For the researchers who have investigated animation and video in simulated media (oil paint for Meier [15] and Litwinowicz [12]; pen and ink for Markosian et al. <ref> [14] </ref> and Winkenbach et al. [32]; and watercolor for Curtis et al. [4]) a challenge has been to maintain temporal coherence in the individual strokes of the artwork to avoid boiling. <p> Thus, we automatically construct model markers for all visible border and silhouette edges, and allow the user to pick the useful marker curves (often, all of them). To get started, we need to define some terminology, consistent with that of Markosian et al. <ref> [14] </ref>. A border edge is an edge adjacent to just one polygon of the mesh. A silhouette edge is an edge shared by a front-facing polygon and a back-facing polygon (relative to the camera).
Reference: [15] <author> Barbara J. Meier. </author> <title> Painterly Rendering for Animation. </title> <editor> In Holly Rushmeier, editor, </editor> <booktitle> SIGGRAPH 96 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 477484. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1996. </year>
Reference-contexts: For the researchers who have investigated animation and video in simulated media (oil paint for Meier <ref> [15] </ref> and Litwinowicz [12]; pen and ink for Markosian et al. [14] and Winkenbach et al. [32]; and watercolor for Curtis et al. [4]) a challenge has been to maintain temporal coherence in the individual strokes of the artwork to avoid boiling.
Reference: [16] <author> Eric N. Mortensen and William A. Barrett. </author> <title> Intelligent Scissors for Image Composition. </title> <editor> In Robert Cook, editor, </editor> <booktitle> SIGGRAPH 95 Conference Proceedings, Annual Conference Series, pages 191198. ACM SIGGRAPH, </booktitle> <publisher> Addison Wesley, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: To specify these curves, the user traces over features in the hand-drawn art a time-consuming and tedious task. To reduce user-intervention, we use contour tracing techniques similar to those presented by Gleicher [8] and Mortensen and Barrett <ref> [16] </ref> in which the cursor automatically snaps onto nearby artwork. For each drawing marker, tracing results in a list of pixels that we subsequently approximate with a smooth curve, as described in Section 4.2. We now have a collection of model and drawing markers.
Reference: [17] <author> Michael Plass and Maureen Stone. </author> <title> Curve Fitting with Piecewise Parametric Cubics. </title> <editor> In Peter Tanner, editor, </editor> <booktitle> SIGGRAPH 83 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 229239. </pages> <publisher> ACM SIGGRAPH, </publisher> <month> July </month> <year> 1983. </year>
Reference-contexts: To calculate the control points, we solve an overdetermined linear system using least squares data fitting techniques that minimize the root-mean-square error between the data and the resulting curve <ref> [1, 17, 19, 22] </ref>. Our fitting procedure attempts to use as few control points as possible, given a maximum error threshold. 4.3 Ghostbusting The marker curves created in this section drive the warp described in Section 5.
Reference: [18] <author> Barbara Robertson. </author> <title> Disney Lets CAPS out of the Bag. </title> <booktitle> Computer Graphics World, </booktitle> <pages> pages 5864, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: Researchers have largely automated the image processing and compositing aspects of cel animation <ref> [6, 18, 25, 28] </ref>, wherein the conventional ink-and-paint stage could be replaced with the textures resulting from our system. Wood et al. [35] demonstrate the use of 3-D computer graphics in the design of static background scenery; in contrast, this paper addresses animated foreground characters. <p> renders the model. (f) The computer composites the rendered model with the hand drawn line art and background scenery. (a) Hand-drawn art (b) 3-D model (c) Edges in model (d) Edges in art (e) Warped model (f) Final frame Our method fits into the existing production pipeline for cel animation <ref> [6, 18] </ref>. Steps (a) and (f) are stages in the current digital production process, with the ink-and-paint stage between them. We are offering, as an alternative to the constant colors of the ink-and-paint stage, a process that applies complex textures to the drawings.
Reference: [19] <author> D. F. Rogers and J. A. Adams. </author> <title> Mathematical Elements for Computer Graphics. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <note> second edition, </note> <year> 1990. </year>
Reference-contexts: that it is simple to implement, it leverages existing support for hidden surface removal and texture mapping, it works for any object with a well-defined parameter space, and produces smooth, visible silhouette curves. 4.2 Curve Fitting To represent each marker curve, we use a chord-length parameterized endpoint-interpolating uniform cubic B-spline <ref> [5, 19] </ref>. These curves have several desirable properties: they are smooth; they can be linked head to tail (without a break between them); the rate of change of the curve with respect to the parameter is uniform; and they are well understood. <p> To calculate the control points, we solve an overdetermined linear system using least squares data fitting techniques that minimize the root-mean-square error between the data and the resulting curve <ref> [1, 17, 19, 22] </ref>. Our fitting procedure attempts to use as few control points as possible, given a maximum error threshold. 4.3 Ghostbusting The marker curves created in this section drive the warp described in Section 5.
Reference: [20] <author> Walter Roberts Sabiston. </author> <title> Extracting 3D Motion from Hand-Drawn Animated Figures. M.Sc. </title> <type> Thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1991. </year>
Reference-contexts: Wood et al. [35] demonstrate the use of 3-D computer graphics in the design of static background scenery; in contrast, this paper addresses animated foreground characters. Sabis-ton <ref> [20] </ref> investigates the use of hand-drawn artwork for driving 3-D animation, which, although not the main focus of our work, is similar to the application we describe in Section 9.2.
Reference: [21] <author> Takafumi Saito and Tokiichiro Takahashi. </author> <title> Comprehensible Rendering of 3-D Shapes. In Forest Baskett, editor, </title> <booktitle> SIG-GRAPH 90 Conference Proceedings, Annual Conference Series, pages 197206. ACM SIGGRAPH, </booktitle> <publisher> Addison Wesley, </publisher> <month> August </month> <year> 1990. </year>
Reference-contexts: As described in Section 4, our method generates this kind of output, and solves the problem of bifurcation along the silhouette edge by rendering the 3-D model colored with texture coordinates into a frame buffer. Saito and Takahashi <ref> [21] </ref> employed a similar technique for highlighting edges in technical illustrations, and Wallach et al. [29] used this idea for finding frame-to-frame coherence in 3-D animations.
Reference: [22] <author> Philip J. Schneider. </author> <title> An Algorithm for Automatically Fitting Digitized Curves. </title> <editor> In Andrew S. Glassner, editor, </editor> <booktitle> Graphics Gems, number I, </booktitle> <pages> pages 612626. </pages> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: To calculate the control points, we solve an overdetermined linear system using least squares data fitting techniques that minimize the root-mean-square error between the data and the resulting curve <ref> [1, 17, 19, 22] </ref>. Our fitting procedure attempts to use as few control points as possible, given a maximum error threshold. 4.3 Ghostbusting The marker curves created in this section drive the warp described in Section 5.
Reference: [23] <author> Thomas W. Sederberg, Peisheng Gao, Guojin Wang, and Hong Mu. </author> <title> 2D Shape Blending: An Intrinsic Solution to the Vertex Path Problem. </title> <editor> In James T. Kajiya, editor, </editor> <booktitle> SIGGRAPH 93 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 1518. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1993. </year>
Reference-contexts: Lee et al. [10] have described a user-interface based on snakes [9] that is useful for feature specification, as well as a new warp based on free-form deformations [24]. Warps have been applied in other domains as well, such as the work of Sederberg et al. <ref> [23] </ref> on 2-D curves, Witkin and Popovic [33] on motion curves for 3-D animation, and Lerios et al. [11] on volumes. This paper also presents a scheme for silhouette detection based on rendering the 3-D model into a frame buffer.
Reference: [24] <author> Thomas W. Sederberg and Scott R. Parry. </author> <title> Free-Form Deformation of Solid Geometric Models. </title> <editor> In David C. Evans and Russell J. Athay, editors, </editor> <booktitle> SIGGRAPH 86 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 151160. </pages> <publisher> ACM SIGGRAPH, </publisher> <month> August </month> <year> 1986. </year>
Reference-contexts: Lee et al. [10] have described a user-interface based on snakes [9] that is useful for feature specification, as well as a new warp based on free-form deformations <ref> [24] </ref>. Warps have been applied in other domains as well, such as the work of Sederberg et al. [23] on 2-D curves, Witkin and Popovic [33] on motion curves for 3-D animation, and Lerios et al. [11] on volumes.
Reference: [25] <author> Michael A. Shantzis. </author> <title> A Model for Efficient and Flexible Image Computing. </title> <editor> In Andrew Glassner, editor, </editor> <booktitle> SIGGRAPH 94 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 147154. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> July </month> <year> 1994. </year>
Reference-contexts: Researchers have largely automated the image processing and compositing aspects of cel animation <ref> [6, 18, 25, 28] </ref>, wherein the conventional ink-and-paint stage could be replaced with the textures resulting from our system. Wood et al. [35] demonstrate the use of 3-D computer graphics in the design of static background scenery; in contrast, this paper addresses animated foreground characters.
Reference: [26] <author> Robert E. Tarjan and Jan van Leeuwen. </author> <title> Worst-Case Analysis of Set Union Algorithms. </title> <journal> Journal of the ACM, </journal> <volume> 31(2):245 281, </volume> <month> April </month> <year> 1984. </year>
Reference-contexts: Finally, we choose the highest confidence value to represent the type of the edge. After the classification process is finished, finding the edges on the model is equivalent to finding the connected components of G, which can be done efficiently using depth-first search <ref> [3, 26] </ref>. We traverse the graph, finding paths of edges that have the same edge type and the same color (within a tolerance). The running time of depth-first search is fi (jV j+jEj) [3]. In our case, both jV j and jEj are linear in the number of pixels.
Reference: [27] <author> Frank Thomas and Ollie Johnston. </author> <title> Disney Animation: The Illusion of Life. Walt Disney Productions, </title> <address> New York, </address> <year> 1981. </year>
Reference-contexts: Finally, there exists an entire art form (and industry) built around hand-drawn animation, whose techniques have been refined for more than 80 years <ref> [27] </ref>. While the industry is increasingly using computer-generated elements in animated films, the vast majority of characters are hand-drawn in 2-D, especially when the figure should convey a sense of life and emotion. In this project, we begin with hand-drawn characters created by a traditional animator. <p> In these frames the ball exhibits squash and stretch, a fundamental principle of traditional cel animation <ref> [27] </ref>. The 3-D model for this case is a simple sphere with a hand-painted beach-ball texture applied to it. The sphere rotates with respect to the camera, so that it appears to be rolling.
Reference: [28] <author> B. A. Wallace. </author> <title> Merging and Transformation of Raster Images for Cartoon Animation. </title> <editor> In Henry Fuchs, editor, </editor> <booktitle> SIGGRAPH 81 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 253262. </pages> <publisher> ACM SIGGRAPH, </publisher> <month> August </month> <year> 1981. </year>
Reference-contexts: Researchers have largely automated the image processing and compositing aspects of cel animation <ref> [6, 18, 25, 28] </ref>, wherein the conventional ink-and-paint stage could be replaced with the textures resulting from our system. Wood et al. [35] demonstrate the use of 3-D computer graphics in the design of static background scenery; in contrast, this paper addresses animated foreground characters.
Reference: [29] <author> Dan S. Wallach, Sharma Kunapalli, and Michael F. Co-hen. </author> <title> Accelerated MPEG Compression of Dynamic Polygonal Scenes. </title> <editor> In Andrew Glassner, editor, </editor> <booktitle> SIGGRAPH 94 Conference Proceedings, Annual Conference Series, pages 193197. ACM SIGGRAPH, </booktitle> <publisher> Addison Wesley, </publisher> <month> July </month> <year> 1994. </year>
Reference-contexts: Saito and Takahashi [21] employed a similar technique for highlighting edges in technical illustrations, and Wallach et al. <ref> [29] </ref> used this idea for finding frame-to-frame coherence in 3-D animations.
Reference: [30] <institution> Walt Disney Home Video. Aladdin and the King of Thieves. Distributed by Buena Vista Home Video, Dept. CS, Burbank, CA, </institution> <note> 91521. Originally released in 1992 as a motion picture. </note>
Reference-contexts: Finally, animators at Disney actually applied a computer graphics texture to color a hand-drawn magic carpet in the film Aladdin <ref> [30] </ref>, but their process involved meticulously rotoscoping a 3-D model to match each frame of artworkan arduous task that would have benefitted from a system such as the one we describe. The heart of our method is a new warp.
Reference: [31] <author> Lance R. Williams. </author> <title> Topological Reconstruction of a Smooth Manifold-Solid from its Occluding Contour. </title> <type> Technical Report 94-04, </type> <institution> University of Massachusetts, </institution> <address> Amherst, MA, </address> <year> 1994. </year>
Reference-contexts: We would like to reduce the amount of effort required to construct and position the 3-D model. One strategy is to investigate the applicability of computer vision algorithms to reconstruct the 3-D geometry from the 2-D drawings. Perhaps the animator could draw hints in the artwork using Williams's scheme <ref> [31] </ref> for conveying depth information through line-drawings. Computer vision techniques would also be useful for discerning camera position, inferring model deformations, and applying kinematics constraints. The computer could orient and deform the 3-D model based on the 2-D drawings.
Reference: [32] <author> Georges Winkenbach and David H. Salesin. </author> <title> Computer Generated PenandInk Illustration. </title> <editor> In Andrew Glassner, editor, </editor> <booktitle> SIGGRAPH 94 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 91100. </pages> <publisher> ACM SIGGRAPH, Addison Wes-ley, </publisher> <month> July </month> <year> 1994. </year>
Reference-contexts: For the researchers who have investigated animation and video in simulated media (oil paint for Meier [15] and Litwinowicz [12]; pen and ink for Markosian et al. [14] and Winkenbach et al. <ref> [32] </ref>; and watercolor for Curtis et al. [4]) a challenge has been to maintain temporal coherence in the individual strokes of the artwork to avoid boiling.
Reference: [33] <author> Andrew Witkin and Zoran Popovic. </author> <title> Motion Warping. </title> <editor> In Robert Cook, editor, </editor> <booktitle> SIGGRAPH 95 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 105108. </pages> <publisher> ACM SIG-GRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Warps have been applied in other domains as well, such as the work of Sederberg et al. [23] on 2-D curves, Witkin and Popovic <ref> [33] </ref> on motion curves for 3-D animation, and Lerios et al. [11] on volumes. This paper also presents a scheme for silhouette detection based on rendering the 3-D model into a frame buffer.
Reference: [34] <author> George Wolberg. </author> <title> Digital Image Warping. </title> <publisher> IEEE Computer Society Press, </publisher> <address> Washington, </address> <year> 1990. </year>
Reference-contexts: This can be computed quickly for all vertices in the model by caching the coordinate systems at sample locations. Our warp uses forward mapping <ref> [34] </ref>: for each point in the source texture, it finds where the point is mapped in the destination. The motivation in this case is that we get self-occlusion and hidden-surface removal for free using normal z-buffered rendering.
Reference: [35] <author> Daniel N. Wood, Adam Finkelstein, John F. Hughes, Craig E. Thayer, and David H. Salesin. </author> <title> Multiperspective Panoramas for Cel Animation. </title> <editor> In Turner Whitted, editor, </editor> <booktitle> SIGGRAPH 97 Conference Proceedings, Annual Conference Series, </booktitle> <pages> pages 243250. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1997. </year>
Reference-contexts: Researchers have largely automated the image processing and compositing aspects of cel animation [6, 18, 25, 28], wherein the conventional ink-and-paint stage could be replaced with the textures resulting from our system. Wood et al. <ref> [35] </ref> demonstrate the use of 3-D computer graphics in the design of static background scenery; in contrast, this paper addresses animated foreground characters.
References-found: 35

