URL: ftp://ftp.cs.indiana.edu/pub/tkeahey/papers/infovis.98/paper.ps.gz
Refering-URL: http://www.cs.indiana.edu/hyplan/tkeahey/research/papers/infovis.98.html
Root-URL: http://www.cs.indiana.edu
Email: keahey@lanl.gov  
Title: The Generalized Detail-In-Context Problem  
Author: T. Alan Keahey 
Address: MS B287 Los Alamos, NM 87545  
Affiliation: Los Alamos National Laboratory,  
Abstract: This paper describes a general formulation of the detail-in-context problem, which is a central issue of fundamental importance to a wide variety of nonlinear magnification systems. A number of tools are described for dealing with this problem effectively. These tools can be applied to any continuous nonlinear magnification system, and are not tied to specific implementation features of the system that produced the original transformation. Of particular interest is the development of seamless multi-level views, which allow multiple global views of an information space (each having different information content) to be integrated into a single view without discontinuity. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Bartram, A. Ho, J. Dill, and F. Henigman. </author> <title> The continuous zoom: A constrained fisheye technique for viewing and navigating large information spaces. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <month> Nov. </month> <year> 1995. </year>
Reference-contexts: Although many of these systems also provide enhanced detail within regions of magnification <ref> [22, 19, 23, 1, 14, 18] </ref>; the techniques that we will describe in this paper are of a more general nature, these methods effectively synchronize detail functions with any continuous nonlinear magnification transformation.
Reference: [2] <author> B. B. Bederson, J. D. Hollan, K. Perlin, J. Meyer, D. Bacon, and G. Furnas. </author> <title> Pad++: A zoomable graphical sketchpad for exploring alternate interface physics. </title> <journal> Journal of Visual Languages and Computing, </journal> <pages> pages 331, </pages> <year> 1996. </year>
Reference-contexts: Figure 6 shows an example of our interactive atlas using both LOD and object size based on implicit magnification. This is but one simple example of how LOD rendering can be incorporated into nonlinearly magnified spaces, many other approaches are possible; for example the Pad++ <ref> [2] </ref> WWW navigation system uses page thumbnails with a LOD function so that the node at the focus of the transformation becomes an actual web page which the user can interact with, other systems for visualization of graph structures expand and collapse subgraphs as their root nodes are magnified or demagnified
Reference: [3] <author> J. F. Blinn and M. E. Newell. </author> <title> Texture and reflection in computer generated images. </title> <journal> Communications of the ACM, </journal> <volume> 19(10):542546, </volume> <month> Oct. </month> <year> 1976. </year>
Reference-contexts: Each atlas example is illustrated both in the paper and in Colour Plate A. These examples make extensive use of texture mapping techniques <ref> [3] </ref> to place the images on the screen. 2.1. Discrete Objects The first general detail-in-context task that we will examine involves rendering discrete objects within a nonlinearly transformed space.
Reference: [4] <author> M. Carpendale, D. Cowperthwaite, and D. Fracchia. </author> <title> 3D pliable surfaces: For the effective presentation of visual information. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 217226, </pages> <year> 1995. </year>
Reference-contexts: Magnification of these downsampled regions may reveal a clearer view of the actual image pixels, however the underlying image content does not change, only the sampling frequency of that image. Nonlinear magnification of individual images was illustrated in <ref> [4] </ref>; details of nonlinear image magnification and the differences between discrete and continuous domains were described extensively in [11], and later mentioned in [5]. <p> Consistent Visual Cues A final issue involved with the detail-in-context problem is the need to provide consistent visual cues to the user as to what regions are being magnified or demagni-fied by a given transformation. This need was addressed in an implementation-specific manner for the 3DPS system <ref> [4] </ref>, through the combination of an additional NURB surface and a computationally expensive lighting model to produce shading of regions of distortion. More generally, suitable shading for any given transformation can also be produced in an implementation-independent fashion through the use of implicit magnification fields.
Reference: [5] <author> M. Carpendale, D. Cowperthwaite, and F. Fracchia. </author> <title> Multi-scale viewing. </title> <booktitle> In SIGGRAPH Visual Proceedings, </booktitle> <pages> page 149, </pages> <month> Aug. </month> <year> 1996. </year> <type> Technical Sketch. </type>
Reference-contexts: Nonlinear magnification of individual images was illustrated in [4]; details of nonlinear image magnification and the differences between discrete and continuous domains were described extensively in [11], and later mentioned in <ref> [5] </ref>. We can extend this idea of image magnification to account for multiple levels of images (i.e. multiple views), where each view can now represent distinct semantic or graphical representations of the overall information space (this idea was first mentioned in [11]).
Reference: [6] <author> M. Carpendale, D. Cowperthwaite, and F. Fracchia. </author> <title> Extending distortion viewing from 2D to 3D. </title> <journal> Computer Graphics and Applications, </journal> <volume> 17(4):4251, </volume> <month> July </month> <year> 1997. </year>
Reference-contexts: However the task becomes more difficult when complex transformations with multiple foci and/or constrained domains are used; simple Euclidean distance is no longer effective as a measure on which to base object size in such cases. A recent article <ref> [6] </ref> describes the separation of transformation (displacement) and magnification (a conceptual distinction describing node size) functions, however the authors do not address the issue of how to ensure that these functions are reasonably synchronized. <p> Figure 3 shows several examples of how object size can be coupled effectively with implicit magnification values. 1 1 Uniform scaling is used in these examples, although non-uniform aspect ratios are also possible. This was illustrated for simple cases in <ref> [6] </ref>, and can be implemented for complex cases via the nonlinear magnification vectors described in [9]. Magnification for our interactive atlas; each point of interest is rendered as an image which is uniformly magnified proportionally to the implicit magnification of the transformation.
Reference: [7] <author> G. W. Furnas. </author> <title> Generalized fisheye views. </title> <booktitle> Human Factors in Computing Systems, CHI '86, </booktitle> <pages> pages 1623, </pages> <month> Apr. </month> <year> 1986. </year>
Reference-contexts: 1. Introduction Many approaches have been described in the literature for stretching and distorting spaces to produce effective visualizations of data. Such techniques have been called polyfocal projection [8], fisheye views <ref> [7] </ref>, distortion-oriented presentation [15], focus + context [14] and many other terms [10]. In [12] we introduced the term nonlinear magnification to describe the effects common to all of these systems. The basic characteristics of nonlinear magnification are non-occluding in-place magnification which preserves a view of the global context.
Reference: [8] <author> N. Kadmon and E. Shlomi. </author> <title> A polyfocal projection for statistical surfaces. </title> <journal> The Cartographic Journal, </journal> <volume> 15(1):3641, </volume> <month> June </month> <year> 1978. </year>
Reference-contexts: 1. Introduction Many approaches have been described in the literature for stretching and distorting spaces to produce effective visualizations of data. Such techniques have been called polyfocal projection <ref> [8] </ref>, fisheye views [7], distortion-oriented presentation [15], focus + context [14] and many other terms [10]. In [12] we introduced the term nonlinear magnification to describe the effects common to all of these systems.
Reference: [9] <author> T. A. Keahey. </author> <title> Nonlinear Magnification. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Indiana University, </institution> <month> Dec. </month> <year> 1997. </year>
Reference-contexts: For the one-dimensional case they define the magnification function as the derivative of the transformation function. This relationship was extended to higher-dimensional nonlinear transformations in [13], resulting in the nonlinear magnification field (described in greater detail in <ref> [9] </ref>). Methods were provided for converting back and forth between 2D nonlinear transformation functions and their associated magnification functions. It was shown that every continuous, order-preserving, nonlinear transformation has an implicit magnification field which is a field of scalar values reflecting the magnificational effect of that transformation. <p> This was illustrated for simple cases in [6], and can be implemented for complex cases via the nonlinear magnification vectors described in <ref> [9] </ref>. Magnification for our interactive atlas; each point of interest is rendered as an image which is uniformly magnified proportionally to the implicit magnification of the transformation. <p> One possibility is to use multi-pass rendering and modulate all of the surfaces with the appropriate colour ramp values during one of the passes. Another simpler method involves mapping the surfaces onto a composite mesh (defined in <ref> [9] </ref>, each node in the composite mesh has the fx; yg coordinates of the transformation grid, and the z value of the implicit magnification mesh of the transformation).
Reference: [10] <author> T. A. Keahey. </author> <title> the Nonlinear Magnification Home Page. A WWW resource devoted to all aspects of nonlinear magnification available at: </title> <address> www.cs.indiana.edu/hyplan/tkeahey/research/nlm/nlm.html, Jan. </address> <year> 1997. </year>
Reference-contexts: 1. Introduction Many approaches have been described in the literature for stretching and distorting spaces to produce effective visualizations of data. Such techniques have been called polyfocal projection [8], fisheye views [7], distortion-oriented presentation [15], focus + context [14] and many other terms <ref> [10] </ref>. In [12] we introduced the term nonlinear magnification to describe the effects common to all of these systems. The basic characteristics of nonlinear magnification are non-occluding in-place magnification which preserves a view of the global context.
Reference: [11] <author> T. A. Keahey and E. L. Robertson. </author> <title> Non-linear image magnification. </title> <type> Technical Report 460, </type> <institution> Department of Computer Science, Indiana University, </institution> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: Nonlinear magnification of individual images was illustrated in [4]; details of nonlinear image magnification and the differences between discrete and continuous domains were described extensively in <ref> [11] </ref>, and later mentioned in [5]. We can extend this idea of image magnification to account for multiple levels of images (i.e. multiple views), where each view can now represent distinct semantic or graphical representations of the overall information space (this idea was first mentioned in [11]). <p> were described extensively in <ref> [11] </ref>, and later mentioned in [5]. We can extend this idea of image magnification to account for multiple levels of images (i.e. multiple views), where each view can now represent distinct semantic or graphical representations of the overall information space (this idea was first mentioned in [11]). An example application where this might be useful involves combining state, county and city maps within a single magnified view.
Reference: [12] <author> T. A. Keahey and E. L. Robertson. </author> <title> Techniques for non-linear magnification transformations. </title> <booktitle> In Proceedings of the IEEE Symposium on Information Visualization, IEEE Visualization, </booktitle> <pages> pages 3845, </pages> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: 1. Introduction Many approaches have been described in the literature for stretching and distorting spaces to produce effective visualizations of data. Such techniques have been called polyfocal projection [8], fisheye views [7], distortion-oriented presentation [15], focus + context [14] and many other terms [10]. In <ref> [12] </ref> we introduced the term nonlinear magnification to describe the effects common to all of these systems. The basic characteristics of nonlinear magnification are non-occluding in-place magnification which preserves a view of the global context. <p> Although most of the transformations in this paper were generated using the nonlinear magnification transformations described in <ref> [12] </ref>, the techniques which we will explore here are independent of the actual mechanism used to produce the original nonlinear transformation. 1.2. Nonlinear Magnification Fields Leung and Apperley [15] first established the mathematical relationship between magnification and transformation functions for nonlinear magnification or distortion-oriented systems.
Reference: [13] <author> T. A. Keahey and E. L. Robertson. </author> <title> Nonlinear magnification fields. </title> <booktitle> In Proceedings of the IEEE Symposium on Information Visualization, IEEE Visualization, </booktitle> <month> Oct. </month> <year> 1997. </year>
Reference-contexts: Nonlinear Magnification Fields Leung and Apperley [15] first established the mathematical relationship between magnification and transformation functions for nonlinear magnification or distortion-oriented systems. For the one-dimensional case they define the magnification function as the derivative of the transformation function. This relationship was extended to higher-dimensional nonlinear transformations in <ref> [13] </ref>, resulting in the nonlinear magnification field (described in greater detail in [9]). Methods were provided for converting back and forth between 2D nonlinear transformation functions and their associated magnification functions. <p> Implicit magnification fields are very inexpensive to compute, provide a consistent measurement of the effect of transformations, and can be computed on any continuous nonlinear magnification transformation, regardless of what type of system was used to produce that transformation (an example shown in <ref> [13] </ref> illustrates the implicit magnification field of the Perspective Wall [17] system). <p> The implicit magnification fields developed in <ref> [13] </ref> are very well suited for the task of synchronizing transformation and magnification functions when complex transformations are involved. <p> for the degree of magnification implicit in a given transformation, making our task simply to render the information in a way that reflects this quantification (the 3DPS system does not provide a mechanism for quantifying the effects of a given transformation, and has an inconsistent relationship between elevation and magnification <ref> [13] </ref>). We have already seen examples in Section 1.2 where the implicit magnification values are mapped into a 1D colour ramp to provide consistent visual cues for a single surface; the situation is somewhat more complicated for textured or multiple surfaces however.
Reference: [14] <author> J. Lamping, R. Rao, and P. Pirolli. </author> <title> A focus+context technique based on hyperbolic geometry for visualizing large hierarchies. </title> <booktitle> In Proceedings of the ACM Conference on Computer Human Interaction, </booktitle> <year> 1995. </year>
Reference-contexts: 1. Introduction Many approaches have been described in the literature for stretching and distorting spaces to produce effective visualizations of data. Such techniques have been called polyfocal projection [8], fisheye views [7], distortion-oriented presentation [15], focus + context <ref> [14] </ref> and many other terms [10]. In [12] we introduced the term nonlinear magnification to describe the effects common to all of these systems. The basic characteristics of nonlinear magnification are non-occluding in-place magnification which preserves a view of the global context. <p> The Perspective Wall [17] was an effort to provide detail and context smoothly integrated. Researchers at Xerox PARC using a 2D hyperbolic transformation for display of graphs referred to their technique as a focus+context technique <ref> [14] </ref>. Similar terminology is scattered through much of the literature since that time. Our definition of the problem has significant differences from these specific approaches however, which we will now outline. Many focus+context techniques are designed to create focus by enlarging spaces, and reduced context by compressing the surrounding spaces. <p> Although many of these systems also provide enhanced detail within regions of magnification <ref> [22, 19, 23, 1, 14, 18] </ref>; the techniques that we will describe in this paper are of a more general nature, these methods effectively synchronize detail functions with any continuous nonlinear magnification transformation.
Reference: [15] <author> Y. Leung and M. Apperley. </author> <title> A review and taxonomy of distortion-oriented presentation techniques. </title> <journal> ACM Transactions on Computer-Human Interaction, </journal> <volume> 1(2):126160, </volume> <year> 1994. </year>
Reference-contexts: 1. Introduction Many approaches have been described in the literature for stretching and distorting spaces to produce effective visualizations of data. Such techniques have been called polyfocal projection [8], fisheye views [7], distortion-oriented presentation <ref> [15] </ref>, focus + context [14] and many other terms [10]. In [12] we introduced the term nonlinear magnification to describe the effects common to all of these systems. The basic characteristics of nonlinear magnification are non-occluding in-place magnification which preserves a view of the global context. <p> Although most of the transformations in this paper were generated using the nonlinear magnification transformations described in [12], the techniques which we will explore here are independent of the actual mechanism used to produce the original nonlinear transformation. 1.2. Nonlinear Magnification Fields Leung and Apperley <ref> [15] </ref> first established the mathematical relationship between magnification and transformation functions for nonlinear magnification or distortion-oriented systems. For the one-dimensional case they define the magnification function as the derivative of the transformation function.
Reference: [16] <author> H. Lieberman. </author> <title> Powers of ten thousand. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 1516, </pages> <month> Nov. </month> <year> 1994. </year> <month> Demo. </month>
Reference-contexts: The fog-based approach to providing visual cues has the benefit of allowing for very simple implementation (most current graphics libraries provide ready support for this), and is also very inexpensive computationally (having hardware support on many platforms). 4. Related Work Lieberman <ref> [16] </ref> takes a different approach to integrating global views of an information space. The primary technique used there relies on overlapping layers of varying translucency, so that the different global views are visible simultaneously.
Reference: [17] <author> J. Mackinlay, G. Robertson, and S. Card. </author> <title> The perspective wall: Detail and context smoothly integrated. </title> <booktitle> In Proceedings of the ACM Conference on Computer Human Interaction, </booktitle> <pages> pages 173179, </pages> <year> 1991. </year>
Reference-contexts: The formulation of this problem is similar to a number of approaches already taken in the literature. The Perspective Wall <ref> [17] </ref> was an effort to provide detail and context smoothly integrated. Researchers at Xerox PARC using a 2D hyperbolic transformation for display of graphs referred to their technique as a focus+context technique [14]. Similar terminology is scattered through much of the literature since that time. <p> are very inexpensive to compute, provide a consistent measurement of the effect of transformations, and can be computed on any continuous nonlinear magnification transformation, regardless of what type of system was used to produce that transformation (an example shown in [13] illustrates the implicit magnification field of the Perspective Wall <ref> [17] </ref> system). These magnification fields play a central role in the methods described in this paper; their implementation-independent nature provides a general-purpose method for quantifying the effects of specific nonlinear magnification transformations, thus providing a rigorous mathematical measure on which to synchronize our detail-rendering methods. <p> Prominent examples of this type of embedded object are found in the Perspective Wall <ref> [17] </ref> and the Document Lens [21]. Figure 7 shows an example of using embedded objects for our interactive atlas. jects There are a number of problems with embedded objects however.
Reference: [18] <author> T. Munzner. H3: </author> <title> Laying out large directed graphs in 3D hyperbolic space. </title> <booktitle> In Proceedings of the IEEE Symposium on Information Visualization, IEEE Visualization, </booktitle> <month> Oct. </month> <year> 1997. </year>
Reference-contexts: Although many of these systems also provide enhanced detail within regions of magnification <ref> [22, 19, 23, 1, 14, 18] </ref>; the techniques that we will describe in this paper are of a more general nature, these methods effectively synchronize detail functions with any continuous nonlinear magnification transformation.
Reference: [19] <author> E. G. Noik. </author> <title> Exploring large hyperdocuments: Fisheye views of nested networks. </title> <booktitle> In Proceedings of the ACM Conference on Hypertext, </booktitle> <pages> pages 192205, </pages> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: Although many of these systems also provide enhanced detail within regions of magnification <ref> [22, 19, 23, 1, 14, 18] </ref>; the techniques that we will describe in this paper are of a more general nature, these methods effectively synchronize detail functions with any continuous nonlinear magnification transformation. <p> the implicit magnification field is C 0 continuous and well defined over the entire domain it does not leave any gaps where the magnification is undefined, as is the case for some of the other approaches for graph visualization that only define magnification locally at the nodes of the graph <ref> [19] </ref>. Figure 3 shows several examples of how object size can be coupled effectively with implicit magnification values. 1 1 Uniform scaling is used in these examples, although non-uniform aspect ratios are also possible. <p> WWW navigation system uses page thumbnails with a LOD function so that the node at the focus of the transformation becomes an actual web page which the user can interact with, other systems for visualization of graph structures expand and collapse subgraphs as their root nodes are magnified or demagnified <ref> [19] </ref>. At this point we are still left with the problem that simple linear scaling of objects proportionally to the implicit magnification of the transformation can result in overlapping objects. In addition, this method leads to the perception of the objects as floating above the transformed space.
Reference: [20] <author> S. Putz. </author> <note> Xerox PARC map viewer, 1993. www.parc.xerox.com/istl/projects/mapdocs/. </note>
Reference-contexts: This technique differs significantly from single image magnification in that we are now dynamically incorporating additional detail within the context provided by our nonlinear magnification transformation. maps from the Xerox PARC Map Server <ref> [20] </ref>. Two views of the California Bay Area are provided, with the larger map showing more detail (roads, railway tracks etc.) than the smaller one. As the smaller, simple view is magnified, additional information is pulled in from the detailed view.
Reference: [21] <author> G. Robertson and J. D. Mackinlay. </author> <title> The document lens. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <pages> pages 101108, </pages> <year> 1993. </year>
Reference-contexts: Prominent examples of this type of embedded object are found in the Perspective Wall [17] and the Document Lens <ref> [21] </ref>. Figure 7 shows an example of using embedded objects for our interactive atlas. jects There are a number of problems with embedded objects however.
Reference: [22] <author> M. Sarkar and M. H. Brown. </author> <title> Graphical fisheye views of graphs. </title> <booktitle> In Proceedings of the ACM Conference on Computer Human Interaction, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: Although many of these systems also provide enhanced detail within regions of magnification <ref> [22, 19, 23, 1, 14, 18] </ref>; the techniques that we will describe in this paper are of a more general nature, these methods effectively synchronize detail functions with any continuous nonlinear magnification transformation. <p> We will now examine these methods individually, and also show different ways in which they can be combined. 2.1.1. Object Size The simplest method for increasing detail of objects involves only increasing their size. This method is commonly used for single-foci systems such as <ref> [22] </ref>, where object size can be based on simple Euclidean proximity to the center of magnification.
Reference: [23] <author> M. Sarkar, S. S. Snibbe, O. Tversky, and S. P. Reiss. </author> <title> Stretching the rubber sheet: A metaphor for visualizing large layouts on small screens. </title> <booktitle> In Proceedings of the ACM Symposium on User Interface Software and Technology, </booktitle> <year> 1993. </year>
Reference-contexts: Although many of these systems also provide enhanced detail within regions of magnification <ref> [22, 19, 23, 1, 14, 18] </ref>; the techniques that we will describe in this paper are of a more general nature, these methods effectively synchronize detail functions with any continuous nonlinear magnification transformation.
Reference: [24] <author> M. C. Stone, K. Fishkin, and E. A. Bier. </author> <title> The movable filter as a user interface tool. </title> <booktitle> In Proceedings of the ACM Conference on Computer Human Interaction, </booktitle> <year> 1994. </year>
Reference-contexts: In contrast, the seamless multi-level views presented here provide smooth transitions that are free of discontinuities. Magic Lens <ref> [24] </ref> filters provide many different methods for changing the visual representation of information as the filters pass over the workspace. Filters are available for increasing or decreasing detail, as well as for altering semantic representation and other effects.
Reference: [25] <author> L. Williams. Pyramidal parametrics. </author> <note> In SIGGRAPH, </note> <year> 1983. </year>
Reference-contexts: Colour Plate B shows our two examples of seamless multi-level views. The implementation of multi-level image magnification can be greatly facilitated by the use of MIP-mapping <ref> [25] </ref>, which is a common technique within the graphics community for dealing with texture mapping, and is supported by hardware acceleration on most workstations and PCs with hardware graphics capabilities.
References-found: 25

