URL: http://www.cs.ucsd.edu/users/vdonalds/tr497.ps
Refering-URL: http://www.cs.ucsd.edu/users/vdonalds/
Root-URL: http://www.cs.ucsd.edu
Email: fvdonalds,ferranteg@cs.ucsd.edu  
Title: Sequencing Asynchronous Pipeline Tasks  
Author: Val Donaldson and Jeanne Ferrante 
Address: La Jolla, California 92093-0114  
Affiliation: Computer Science and Engineering Department University of California, San Diego  
Abstract: Technical Report CS96-497, CSE Dept., UCSD, November 1996 Abstract Asynchronous pipelining is a form of parallelism in which processors execute different loop tasks, as opposed to different loop iterations. An asynchronous pipeline schedule for a loop is a generalization of a noniterative DAG schedule, and consists of a processor assignment|an assignment of loop tasks to processors; plus a task sequence for each processor|an order on instances of tasks assigned to a processor. This variant of pipeline parallelism is particularly relevant in distributed memory systems (since pipeline control may be distributed across processors), but may also be used in shared memory systems. Results for asynchronous pipelining may also provide insights into other forms of pipelining, such as software pipelining. We show that the problem of finding an optimal asynchronous pipeline schedule is NP-hard under three different definitions of optimality, even when the loop body is self-cyclic, i.e., has no multi-task dependence cycles. A number of pipeline scheduling subproblems are themselves NP-hard, but given a processor assignment, the problem of finding an asymptotically optimal task sequence for a self-cyclic loop can be solved in polynomial time. Self-cyclic loops represent a significant subset of loops which may contain cross-iteration dependences, I/O, and simple reductions. Assuming that a processor assignment for a loop is specified, we design a heuristic task sequencing algorithm which can be customized to trade off algorithm execution time against the quality of the resulting task sequence. The algorithm is asymptotically optimal for self-cyclic loops, and can be used as a component of a complete pipeline scheduling algorithm which generates schedules for self-cyclic loops that are guaranteed to be within 18% of optimal. For loops which contain multi-task cycles, the algorithm generates task sequences which average within 3.5-6.8% of optimal for a set of 10,800 random loops. The primary determinant of the execution time of the algorithm is the time required to determine the maximum cycle ratio of a loop, which in practice takes O(ve) time for a loop with v tasks and e dependence edges.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alexander Aiken and Alexandru Nicolau. </author> <title> Optimal loop parallelization. </title> <booktitle> Proc. SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <address> Atlanta, GA, </address> <month> June </month> <year> 1988, </year> <pages> pp. 308-317. </pages>
Reference-contexts: Although asynchronous pipelining is particularly appropriate for distributed memory systems, it may also be used in shared memory architectures. Many of the assumptions made in 1 asynchronous pipelining also apply to software pipelining <ref> [1, 13] </ref>, so results for asynchronous pipelining may provide insights into software pipelining issues as well. <p> Scheduling edges may be added to a DDG to represent scheduling information for each local task sequence specification hX 1 : s 1 ; X 2 : s 2 ; : : : ; X k : s k i as follows. For each i 2 <ref> [1; k 1] </ref>, a scheduling edge (X i ; X i+1 ) is created, with (X i ; X i+1 ):dist = s i s i+1 . <p> Question: Is there a partition V = V 1 [ V 2 [ [ V p of V into disjoint sets such that for all i 2 <ref> [1; p] </ref>, P X2V i X:time D? Theorem 3 The asynchronous pipeline scheduling, kernel scheduling, and processor assignment problems are strongly NP-hard under asymptotic, fixed-count, and variable-count optimality, even when the DDG is self-cyclic. Further, the problems which assume asymptotic optimality are strongly NP-complete. <p> values G 0 1 :moment increment;G 0 2 :moment increment;: : : ;G 0 ` :moment increment (b) Nonnegative integer values G 0 1 :stage increment; G 0 2 :stage increment; : : : ; G 0 ` :stage increment subject to the constraint that for any i; j 2 <ref> [1; `] </ref>, i 6= j, if there is a path in G 0 from G 0 i to G 0 j , then G 0 i :moment increment G 0 j :moment increment and G 0 i :stage increment G 0 j :stage increment 6. <p> determine G 0 :min scc mcr , the smallest maximum cycle ratio of any SCC in G 0 (after self-cycles have been deleted, but before modifying cycle edges), and if G 0 :min scc mcr &lt; G 0 :mcr, use scaling factors for all SCC's evenly distributed over the interval <ref> [1; G 0 :mcr =G 0 :min scc mcr ] </ref>, rounding scaling factors down to G 0 :mcr=G 0 i :mcr when the current scaling bound is greater than this value for a particular SCC G 0 i . <p> For any "moment expansion bound" mexp bound &gt; 1 we can perform multiple task sequencing trials by multiplying all task moments by values uniformly distributed over the interval <ref> [1; mexp bound ] </ref>. For example, to perform four trials with mexp bound = 1:3, the expansion factors for the trials would be 1, 1.1, 1.2, and 1.3. Using an expansion factor of 1 corresponds to choosing unmodified moments, so the schedule generated for this trial will not deadlock.
Reference: [2] <author> Sati Banerjee, Takeo Hamada, Paul M. Chau, and Ronald D. Fellman. </author> <title> Macro pipelining based scheduling on high performance heterogeneous multiprocessor systems. </title> <journal> IEEE Transactions on Signal Processing 43:8 (June 1995), </journal> <pages> pp. 1468-1484. </pages>
Reference-contexts: Loops which contain I/O or reductions, for example, may be pipelined. In asynchronous pipelining [6], pipeline tasks are scheduled for execution as soon as processor and data resources are available. This form of pipelining has been studied in the context of digital signal processing algorithms <ref> [2, 11] </ref>, as well as other contexts [17]. The goal of accommodating execution on distributed memory systems motivates a number of the assumptions made in asynchronous pipelining. <p> Existing asynchronous pipeline scheduling heuristics <ref> [2, 9, 11, 17] </ref> first generate stage assignments for all tasks, and then determine processor assignments and task orders. For a given stage assignment, finding an optimal processor assignment and task order combination is NP-complete even for self-cyclic loops. <p> Existing asynchronous pipeline scheduling heuristics [2, 9, 11, 17] first generate stage assignments for all tasks, and then determine processor assignments and task orders. For a given stage assignment, finding an optimal processor assignment and task order combination is NP-complete even for self-cyclic loops. The comparatively restrictive algorithms in <ref> [2, 11] </ref> (all stage assignments are effectively set to zero) give no theoretical performance guarantees. <p> We are particularly interested in three of these six subproblems. The kernel scheduling problem assumes that a stage assignment is given, and a processor assignment and a task order must be found. The scheduling algorithms in <ref> [2, 9, 11, 17] </ref> determine the stage assignment first, and then generate the other two schedule components.
Reference: [3] <author> Steven M. Burns. </author> <title> Performance Analysis and Optimization of Asynchronous Circuits. </title> <type> Ph.D. Thesis, </type> <institution> California Institute of Technology, Pasadena, California, </institution> <year> 1991. </year>
Reference-contexts: If G is acyclic, G:mcr = 0. The maximum cycle ratio of a DDG can be found in polynomial time; discussions of a number of algorithms can be found in <ref> [3, 6, 17] </ref>. The theoretical complexity of Burns' primal-dual algorithm [3] is unknown, but empirically runs in O (ve) time. The DDG in Figure 1b satisfies the positive cycle constraint, and has an iteration interval b = G:mcr = 1:5, from cycles such as (A; C; D). <p> If G is acyclic, G:mcr = 0. The maximum cycle ratio of a DDG can be found in polynomial time; discussions of a number of algorithms can be found in [3, 6, 17]. The theoretical complexity of Burns' primal-dual algorithm <ref> [3] </ref> is unknown, but empirically runs in O (ve) time. The DDG in Figure 1b satisfies the positive cycle constraint, and has an iteration interval b = G:mcr = 1:5, from cycles such as (A; C; D). <p> For each generated DDG, tasks are assigned to processors using Graham's O (v log v) LPT multiprocessor scheduling algorithm [10]. Data communication times between tasks assigned to the same processor are zeroed. We use Burns primal-dual algorithm <ref> [3] </ref> for computing the maximum cycle ratio of a DDG, modified to use the solution of a longest path problem to provide the initial feasible solution when the DDG has negative dependence distances, or there is an upper bound on the maximum cycle ratio from earlier trials. <p> We use this method in our variant of Burns' primal-dual algorithm <ref> [3] </ref> (if the schedule does not deadlock, the solution to the longest path problem 28 Maximum # Trials mexp bound 2 3 4 5 6 7 8 9 10 20 50 100 1.05 6.25 6.18 6.16 6.15 6.13 6.13 6.13 6.12 6.12 6.11 6.10 6.10 1.15 6.22 5.95* 5.84* 5.78 5.75
Reference: [4] <author> E. G. Coffman, Jr., M. R. Garey, and D. S. Johnson. </author> <title> An application of bin-packing to multiprocessor scheduling. </title> <journal> SIAM Journal on Computing 7:1 (February 1978), </journal> <pages> pp. 1-17. </pages>
Reference-contexts: Graham's "largest processing time first" (LPT) multiprocessor scheduling algorithm [10] has a performance guarantee of 33%; Coffman, Garey, and Johnson's MULTIFIT algorithm <ref> [4] </ref> has a 20% guarantee; and Friesen and Langston's improved MULTIFIT (MFI) algorithm [7] has an 18% guarantee. All three of these algorithms execute in O (v log v) time, although the constants involved increase as the guarantee improves.
Reference: [5] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Graph G b fl can be checked for positive cycles in O (ve) time by solving a single-source longest path problem <ref> [5] </ref>. <p> We use a variant of the Bellman-Ford longest path algorithm <ref> [5] </ref> for longest paths. Statistics for execution of the Base Algorithm on the 10,800 cyclic DDG's are shown in Table 2. Each group of rows in the table summarizes algorithm execution for all 10,800 DDG's from the perspective of one parameter as listed in the first column. <p> For any SCC G 0 i , if we temporarily undirect the directed edges in G 0 i we can then partition the edges in G 0 i into biconnected components <ref> [5] </ref>, which are subcomponents of G 0 i which have at most one task in common with each of the other subcomponents.
Reference: [6] <author> Val Donaldson and Jeanne Ferrante. </author> <title> Determining asynchronous pipeline execution times. </title> <booktitle> Proc. 9th Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> San Jose, CA, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: A computation which can not be parallelized using doall parallelism [15], which assigns different loop iterations to different processors, or noniterative DAG (directed acyclic graph) parallelism [16, 18], may permit pipeline parallelization. Loops which contain I/O or reductions, for example, may be pipelined. In asynchronous pipelining <ref> [6] </ref>, pipeline tasks are scheduled for execution as soon as processor and data resources are available. This form of pipelining has been studied in the context of digital signal processing algorithms [2, 11], as well as other contexts [17]. <p> Although our focus is on minimizing the execution time of a task sequence, other schedule aspects such as memory requirements could also be addressed. The paper is organized as follows. Section 2 summarizes the asynchronous pipelining framework from <ref> [6] </ref>, which provides the foundation for both the theoretical results and algorithm development in the body of the paper. Section 3 discusses the computational complexity of asynchronous pipeline scheduling problems and subproblems, including task sequencing. <p> Section 5 discusses sequencing for self-cyclic loops, and Section 6 considers sequencing for loops which contain arbitrary cycles. We summarize our contributions and conclusions in Section 7. 2 Asynchronous Pipelining This section summarizes the notation, terminology, and primary results used for specifying and analyzing asynchronous pipeline schedules; see <ref> [6] </ref> for more details and discussion. A loop body may be modeled as a data dependence graph (DDG) [15]. <p> If G is acyclic, G:mcr = 0. The maximum cycle ratio of a DDG can be found in polynomial time; discussions of a number of algorithms can be found in <ref> [3, 6, 17] </ref>. The theoretical complexity of Burns' primal-dual algorithm [3] is unknown, but empirically runs in O (ve) time. The DDG in Figure 1b satisfies the positive cycle constraint, and has an iteration interval b = G:mcr = 1:5, from cycles such as (A; C; D). <p> Theorem 1 may be used to determine if a pipeline schedule for a DDG will deadlock, and is also the key to proving that the task sequencing algorithm in Section 4 always produces schedules which do not deadlock. Theorem 1 <ref> [6] </ref> Let G be a scheduled DDG with p scheduling cycles. Then pipeline execution of G on p processors is free of deadlock iff G satisfies the positive cycle constraint. 2 If a schedule will not deadlock, the second fundamental issue is to determine its execution time. <p> Theorem 2 is the key to determining the iteration interval of a pipeline schedule. Theorem 2 <ref> [6] </ref> Let G be a scheduled DDG with p scheduling cycles, satisfying the positive cycle constraint. <p> Asterisks (*) mark the smallest values in each column. conveniently provides an initial feasible solution to the linear programming problem). Some maximum cycle ratio algorithms can detect deadlock with little or no change to the basic algorithm. The monotonic search algorithm in <ref> [6] </ref>, for example, will explicitly find a cycle which violates the positive cycle constraint. As discussed in preceding sections, we generally expect that schedules with larger stage assignments are more likely to have smaller iteration intervals.
Reference: [7] <author> D. K. Friesen and M. A. Langston. </author> <title> Evaluation of a MULTIFIT-based scheduling algorithm. </title> <journal> Journal of Algorithms 7:1 (March, </journal> <year> 1986), </year> <pages> pp. 35-59. </pages>
Reference-contexts: Graham's "largest processing time first" (LPT) multiprocessor scheduling algorithm [10] has a performance guarantee of 33%; Coffman, Garey, and Johnson's MULTIFIT algorithm [4] has a 20% guarantee; and Friesen and Langston's improved MULTIFIT (MFI) algorithm <ref> [7] </ref> has an 18% guarantee. All three of these algorithms execute in O (v log v) time, although the constants involved increase as the guarantee improves.
Reference: [8] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <publisher> Freeman, </publisher> <address> New York, </address> <year> 1979. </year> <month> 32 </month>
Reference-contexts: The 23 problems which are NP-hard (or NP-complete) are considered next, and the lone problem with a polynomial time algorithm is considered in Section 5 (Corollary 8). We will use two reference problems in our proofs. The first is the well-known multiprocessor scheduling problem <ref> [8] </ref>, where a set of independent tasks (tasks with no intertask dependences) are assigned to processors with the goal of balancing the load on each processor. <p> This problem is strongly NP-complete (a problem is strongly NP-complete if it is NP-complete regardless of the magnitude of numerical values in a problem instance <ref> [8] </ref>). * Multiprocessor Scheduling Instance: Set V of tasks, number p 2 Z + of processors, for each task X 2 V an execution time X:time 2 Z + , and a deadline D 2 Z + .
Reference: [9] <author> Franco Gasperoni and Uwe Schwiegelshohn. </author> <title> Scheduling loops on parallel processors: a simple algorithm with close to optimum performance. </title> <booktitle> Second Joint International Conference on Vector and Parallel Processing (Parallel Processing: CONPAR 92-VAPP V), </booktitle> <address> Lyon, France, </address> <month> September </month> <year> 1992, </year> <pages> pp. 625-636. </pages>
Reference-contexts: Existing asynchronous pipeline scheduling heuristics <ref> [2, 9, 11, 17] </ref> first generate stage assignments for all tasks, and then determine processor assignments and task orders. For a given stage assignment, finding an optimal processor assignment and task order combination is NP-complete even for self-cyclic loops. <p> For a given stage assignment, finding an optimal processor assignment and task order combination is NP-complete even for self-cyclic loops. The comparatively restrictive algorithms in [2, 11] (all stage assignments are effectively set to zero) give no theoretical performance guarantees. The algorithms in <ref> [9, 17] </ref> generate schedules which are guaranteed to be within 100% of optimal (i.e., a factor of 2 of optimal) when interprocessor communication times are zero, although this guarantee is with respect to optimal noniterative DAG scheduling for an unrolled loop, rather than optimal pipeline scheduling. <p> Dependence distances may be negative, which is particularly useful for representing pipeline scheduling constraints. In computational complexity discussions we assume that e = O (v). Figure 1a is an example loop from <ref> [9] </ref> with the corresponding DDG in Figure 1b. Since a DDG is a directed multigraph, a number of graph-theoretical definitions are applicable. <p> A schedule is implemented at runtime in terms of local components, but scheduling algorithms such as those in <ref> [9, 17] </ref> and the task sequencing algorithms below generate "global" schedules. A global task order is a total order on all tasks in a DDG, and a global stage assignment is a stage assignment for all tasks. <p> If G is a scheduled DDG with G:mcr = b, G b :cpl b is an upper bound on a. 3 Computational Complexity Gasperoni and Schwiegelshohn <ref> [9] </ref> sketch a proof that one form of the asynchronous pipeline scheduling problem (the "asymptotic" form below) is NP-hard. In this section we show that asynchronous pipeline scheduling is NP-hard under three different definitions of optimality, even when a loop is self-cyclic. <p> We are particularly interested in three of these six subproblems. The kernel scheduling problem assumes that a stage assignment is given, and a processor assignment and a task order must be found. The scheduling algorithms in <ref> [2, 9, 11, 17] </ref> determine the stage assignment first, and then generate the other two schedule components. <p> The kernel scheduling problem assumes that a stage assignment is given, and a processor assignment and a task order must be found. The scheduling algorithms in [2, 9, 11, 17] determine the stage assignment first, and then generate the other two schedule components. The algorithms in <ref> [9, 17] </ref> solve the latter two subproblems simultaneously using a noniterative DAG scheduling algorithm on an acyclic subgraph of the DDG, which in [17] is called a "kernel graph." Our approach is to first find a processor assignment, and then solve the task sequencing problem, which are the other two scheduling <p> The "post-optimization" of DAG edges in the Base Algorithm also applies to DAG edges in cyclic DDG's, so DAG edges may be ignored in the earlier phases of any scheduling algorithm for general DDG's. This observation might be applied to improve the algorithms in <ref> [9, 17] </ref>. When applied to a set of 10,800 random cyclic DDG's, the Base Algorithm generates task sequences which average within 6.82% of optimal.
Reference: [10] <author> R. L. Graham. </author> <title> Bounds on multiprocessing timing anomalies. </title> <journal> SIAM Journal on Applied Mathematics 17:2 (March, </journal> <year> 1969), </year> <pages> pp. 416-429. </pages>
Reference-contexts: Graham's "largest processing time first" (LPT) multiprocessor scheduling algorithm <ref> [10] </ref> has a performance guarantee of 33%; Coffman, Garey, and Johnson's MULTIFIT algorithm [4] has a 20% guarantee; and Friesen and Langston's improved MULTIFIT (MFI) algorithm [7] has an 18% guarantee. <p> The number of processors is taken to be the minimum of the selected value and v 1, to guarantee that at least one processor is shared. For each generated DDG, tasks are assigned to processors using Graham's O (v log v) LPT multiprocessor scheduling algorithm <ref> [10] </ref>. Data communication times between tasks assigned to the same processor are zeroed.
Reference: [11] <author> Phu D. Hoang and Jan M. Rabaey. </author> <title> Scheduling of DSP programs onto multiprocessors for maximum throughput. </title> <journal> IEEE Transactions on Signal Processing 41:6 (June 1993), </journal> <pages> pp. 2225-2235. </pages>
Reference-contexts: Loops which contain I/O or reductions, for example, may be pipelined. In asynchronous pipelining [6], pipeline tasks are scheduled for execution as soon as processor and data resources are available. This form of pipelining has been studied in the context of digital signal processing algorithms <ref> [2, 11] </ref>, as well as other contexts [17]. The goal of accommodating execution on distributed memory systems motivates a number of the assumptions made in asynchronous pipelining. <p> Existing asynchronous pipeline scheduling heuristics <ref> [2, 9, 11, 17] </ref> first generate stage assignments for all tasks, and then determine processor assignments and task orders. For a given stage assignment, finding an optimal processor assignment and task order combination is NP-complete even for self-cyclic loops. <p> Existing asynchronous pipeline scheduling heuristics [2, 9, 11, 17] first generate stage assignments for all tasks, and then determine processor assignments and task orders. For a given stage assignment, finding an optimal processor assignment and task order combination is NP-complete even for self-cyclic loops. The comparatively restrictive algorithms in <ref> [2, 11] </ref> (all stage assignments are effectively set to zero) give no theoretical performance guarantees. <p> We are particularly interested in three of these six subproblems. The kernel scheduling problem assumes that a stage assignment is given, and a processor assignment and a task order must be found. The scheduling algorithms in <ref> [2, 9, 11, 17] </ref> determine the stage assignment first, and then generate the other two schedule components.
Reference: [12] <author> J. A. Hoogeveen, S. L. van de Velde, and B. Veltman. </author> <title> Complexity of scheduling multiprocessor tasks with prespecified processor allocations. </title> <booktitle> Discrete Applied Mathematics 55:3 (December 1994), </booktitle> <pages> pp. 259-272. </pages>
Reference-contexts: not shared, the exact execution time of n iterations of a pipeline schedule can be found by solving an integer linear program [14], so this special case of the problem is in NP.) 2 Our second reference problem, which we will call "noniterative task ordering," is from Hoogeveen et al. <ref> [12] </ref>, and is essentially our asynchronous pipeline task sequencing problem restricted to execution of a single iteration of a task graph. Tasks are executed once in task order (so stage assignments are irrelevant, or may be assumed to be zero).
Reference: [13] <author> Monica Lam. </author> <title> Software pipelining: an effective scheduling technique for VLIW machines. </title> <booktitle> Proc. SIG-PLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <address> Atlanta, GA, </address> <month> June </month> <year> 1988, </year> <pages> pp. 318-328. </pages>
Reference-contexts: Although asynchronous pipelining is particularly appropriate for distributed memory systems, it may also be used in shared memory architectures. Many of the assumptions made in 1 asynchronous pipelining also apply to software pipelining <ref> [1, 13] </ref>, so results for asynchronous pipelining may provide insights into software pipelining issues as well.
Reference: [14] <author> Tsuneo Nakanishi, Kazuki Joe, Constantine D. Polychronopoulos, Akira Fukuda, and Keijiro Araki. </author> <title> Estimating parallel execution time of loops with loop-carried dependences. </title> <booktitle> Proc. 25th International Conference on Parallel Processing, </booktitle> <address> Ithaca, NY, </address> <month> August </month> <year> 1996, </year> <booktitle> Vol III, </booktitle> <pages> pp. 61-69. </pages>
Reference-contexts: or for exactly determining the startup time of a schedule, so it is an open question whether or not the remaining problems are in NP. (When processors are not shared, the exact execution time of n iterations of a pipeline schedule can be found by solving an integer linear program <ref> [14] </ref>, so this special case of the problem is in NP.) 2 Our second reference problem, which we will call "noniterative task ordering," is from Hoogeveen et al. [12], and is essentially our asynchronous pipeline task sequencing problem restricted to execution of a single iteration of a task graph. <p> An affirmative answer to the first and second of the following questions would imply an affirmative answer to the third question. * Is there a polynomial time algorithm for determining the exact execution time of a fixed number of iterations of a pipeline schedule? (The integer linear program in <ref> [14] </ref> for the case where processors are not shared suggests that this problem is probably in NP.) * Is there a polynomial time algorithm for determining the startup time a of a pipeline schedule? * Are the NP-hard entries in Table 1 also NP-complete? * Is the task ordering problem for
Reference: [15] <author> David A. Padua and Michael J. Wolfe. </author> <title> Advanced compiler optimizations for supercomputers. </title> <journal> Communications of the ACM 29:12 (December 1986), </journal> <pages> pp. 1184-1201. </pages>
Reference-contexts: Pipeline parallelism exploits concurrency both within and across loop iterations, complementing other forms of parallelism. A computation which can not be parallelized using doall parallelism <ref> [15] </ref>, which assigns different loop iterations to different processors, or noniterative DAG (directed acyclic graph) parallelism [16, 18], may permit pipeline parallelization. Loops which contain I/O or reductions, for example, may be pipelined. <p> We summarize our contributions and conclusions in Section 7. 2 Asynchronous Pipelining This section summarizes the notation, terminology, and primary results used for specifying and analyzing asynchronous pipeline schedules; see [6] for more details and discussion. A loop body may be modeled as a data dependence graph (DDG) <ref> [15] </ref>. Definition 1 A data dependence graph (DDG) is a weighted directed multigraph G = (V; E; f vtime ; f etime ; f dist ), where: * V is a set of vertices or tasks.
Reference: [16] <author> Vivek Sarkar. </author> <title> Partitioning and Scheduling Parallel Programs for Multiprocessors. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1989. </year>
Reference-contexts: Pipeline parallelism exploits concurrency both within and across loop iterations, complementing other forms of parallelism. A computation which can not be parallelized using doall parallelism [15], which assigns different loop iterations to different processors, or noniterative DAG (directed acyclic graph) parallelism <ref> [16, 18] </ref>, may permit pipeline parallelization. Loops which contain I/O or reductions, for example, may be pipelined. In asynchronous pipelining [6], pipeline tasks are scheduled for execution as soon as processor and data resources are available. <p> In Figure 1b, G:mcr = 1:5 and for b fl = 1:5, and the earliest/latest starting/completion times for all tasks are shown in Figure 1c. Asynchronous pipeline execution is a form of macro-dataflow execution <ref> [16] </ref>. Execution of a task instance is atomic. All instances of a task execute on the same processor.
Reference: [17] <author> Tao Yang, Cong Fu, Apostolos Gerasoulis, and Vivek Sarkar. </author> <title> Mapping iterative task graphs on distributed memory machines. </title> <booktitle> Proc. 24th International Conference on Parallel Processing, </booktitle> <address> Oconomowoc, WI, </address> <month> August </month> <year> 1995, </year> <booktitle> Vol II, </booktitle> <pages> pp. 151-158. </pages>
Reference-contexts: In asynchronous pipelining [6], pipeline tasks are scheduled for execution as soon as processor and data resources are available. This form of pipelining has been studied in the context of digital signal processing algorithms [2, 11], as well as other contexts <ref> [17] </ref>. The goal of accommodating execution on distributed memory systems motivates a number of the assumptions made in asynchronous pipelining. Most notably, communication times between tasks may be nonzero, and pipeline control is local to each processor, to avoid the overhead of global control. <p> Existing asynchronous pipeline scheduling heuristics <ref> [2, 9, 11, 17] </ref> first generate stage assignments for all tasks, and then determine processor assignments and task orders. For a given stage assignment, finding an optimal processor assignment and task order combination is NP-complete even for self-cyclic loops. <p> For a given stage assignment, finding an optimal processor assignment and task order combination is NP-complete even for self-cyclic loops. The comparatively restrictive algorithms in [2, 11] (all stage assignments are effectively set to zero) give no theoretical performance guarantees. The algorithms in <ref> [9, 17] </ref> generate schedules which are guaranteed to be within 100% of optimal (i.e., a factor of 2 of optimal) when interprocessor communication times are zero, although this guarantee is with respect to optimal noniterative DAG scheduling for an unrolled loop, rather than optimal pipeline scheduling. <p> If G is acyclic, G:mcr = 0. The maximum cycle ratio of a DDG can be found in polynomial time; discussions of a number of algorithms can be found in <ref> [3, 6, 17] </ref>. The theoretical complexity of Burns' primal-dual algorithm [3] is unknown, but empirically runs in O (ve) time. The DDG in Figure 1b satisfies the positive cycle constraint, and has an iteration interval b = G:mcr = 1:5, from cycles such as (A; C; D). <p> A schedule is implemented at runtime in terms of local components, but scheduling algorithms such as those in <ref> [9, 17] </ref> and the task sequencing algorithms below generate "global" schedules. A global task order is a total order on all tasks in a DDG, and a global stage assignment is a stage assignment for all tasks. <p> We are particularly interested in three of these six subproblems. The kernel scheduling problem assumes that a stage assignment is given, and a processor assignment and a task order must be found. The scheduling algorithms in <ref> [2, 9, 11, 17] </ref> determine the stage assignment first, and then generate the other two schedule components. <p> The kernel scheduling problem assumes that a stage assignment is given, and a processor assignment and a task order must be found. The scheduling algorithms in [2, 9, 11, 17] determine the stage assignment first, and then generate the other two schedule components. The algorithms in <ref> [9, 17] </ref> solve the latter two subproblems simultaneously using a noniterative DAG scheduling algorithm on an acyclic subgraph of the DDG, which in [17] is called a "kernel graph." Our approach is to first find a processor assignment, and then solve the task sequencing problem, which are the other two scheduling <p> The scheduling algorithms in [2, 9, 11, 17] determine the stage assignment first, and then generate the other two schedule components. The algorithms in [9, 17] solve the latter two subproblems simultaneously using a noniterative DAG scheduling algorithm on an acyclic subgraph of the DDG, which in <ref> [17] </ref> is called a "kernel graph." Our approach is to first find a processor assignment, and then solve the task sequencing problem, which are the other two scheduling subproblems of primary interest. <p> The "post-optimization" of DAG edges in the Base Algorithm also applies to DAG edges in cyclic DDG's, so DAG edges may be ignored in the earlier phases of any scheduling algorithm for general DDG's. This observation might be applied to improve the algorithms in <ref> [9, 17] </ref>. When applied to a set of 10,800 random cyclic DDG's, the Base Algorithm generates task sequences which average within 6.82% of optimal.
Reference: [18] <author> Tao Yang and Apostolos Gerasoulis. </author> <title> DSC: scheduling parallel tasks on an unbounded number of processors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems 5:9 (September 1994), </journal> <pages> pp. 951-967. 33 </pages>
Reference-contexts: Pipeline parallelism exploits concurrency both within and across loop iterations, complementing other forms of parallelism. A computation which can not be parallelized using doall parallelism [15], which assigns different loop iterations to different processors, or noniterative DAG (directed acyclic graph) parallelism <ref> [16, 18] </ref>, may permit pipeline parallelization. Loops which contain I/O or reductions, for example, may be pipelined. In asynchronous pipelining [6], pipeline tasks are scheduled for execution as soon as processor and data resources are available. <p> Many of the assumptions made in 1 asynchronous pipelining also apply to software pipelining [1, 13], so results for asynchronous pipelining may provide insights into software pipelining issues as well. An asynchronous pipeline schedule is a generalization of a noniterative DAG schedule <ref> [18] </ref>, and consists of a processor assignment|an assignment of loop tasks to processors; and a task sequence for each processor| an order on instances of tasks assigned to a processor.
References-found: 18

