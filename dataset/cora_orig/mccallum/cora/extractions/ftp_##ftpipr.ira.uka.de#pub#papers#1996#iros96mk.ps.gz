URL: ftp://ftpipr.ira.uka.de/pub/papers/1996/iros96mk.ps.gz
Refering-URL: ftp://ftpipr.ira.uka.de/.public_html/papersna.html
Root-URL: 
Title: Learning coordination skills in multi-agent systems  
Author: M. Kaiser R. Dillmann H. Friedrich I. Lin F. Wallner P. Weckesser 
Keyword: Robot Programming, Multi-Agent Systems, Robot Control.  
Address: D-76128 Karlsruhe, Germany  
Affiliation: University of Karlsruhe Institute for Real-Time Computer Systems and Robotics  
Date: November 1996  
Note: In: IEEE/RSJ International Conference on Intelligent Robots and Systems, Osaka, Japan,  
Abstract: While distributed control architectures have many advantages over centralized ones, such as their inherent modularity and fault tolerance, a major problem of such architectures is to ensure the goal-oriented be-haviour of the controlled system. This paper presents a framework within which the coordination skills required for goal-orientedness are learned from user demonstrations. The framework is based on a state-space model of the single agents building the system and a corresponding model of the coordination mechanism. Our mobile robot PRIAMOS provides an application example. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Asada and B.-H. Yang. </author> <title> Skill acquisition from human experts through pattern processing of teaching data. </title> <booktitle> In Proceedings of the 1989 IEEE International Conference on Robotics and Automation, </booktitle> <year> 1989. </year>
Reference-contexts: Obviously, the first required component is a sec ond evaluation function that models the agent's ability to contribute to a locally defined goal g: A a (g) 7! <ref> [0; 1] </ref>: Note that the goal g is not necessarily given as a vector of numeric values. It may also be represented symboli cally, e.g., by relations defined over objects and object attributes, as in [10]. <p> Then, this interaction results in adaptation of the agent based on user demonstrations and user feedback and is typically treated within the framework of skill acquisition via human demonstration <ref> [1, 6] </ref>. Here, we concentrate on learning coordination skills in the framework defined above and give a detailed description of the three principal learning tasks that must be solved.
Reference: [2] <author> R. D. Beer. </author> <title> A dynamical systems perspective on agent-environment interaction. </title> <journal> Artificial Intelligence, </journal> <volume> 72 </volume> <pages> 173-215, </pages> <year> 1995. </year>
Reference-contexts: Here, this framework is developed on the basis of system theory and state-space models, based on previous work by Beer <ref> [2] </ref> and ourselves [6]. 2.1 Single agent model Our model of an agent is that of a skilled subsystem. A single agent is able to perform competent actions that are related to its locally defined goal and facilitate goal-oriented state transitions.
Reference: [3] <author> R. Dillmann, M. Kaiser, F. Wallner, and P. Weckesser. PRIAMOS: </author> <title> An advanced mobile system for service, inspection, and surveillance tasks. </title> <editor> In H. Bunke, H. Nolte-meier, and T. Kanade, editors, </editor> <title> Modelling and Planning for Sensor Based Intelligent Robot Systems. </title> <publisher> World Scientific, </publisher> <year> 1995. </year>
Reference-contexts: function is represented by means of an array of values, this learning law is simply A new a i (g) + r with r 2 f0; 1g and a learning rate : 4 Application example The test bed for experiments using the multi-agent approach will be the mobile robot PRIAMOS <ref> [3] </ref>, Fig. 7. PRIAMOS is a mobile system with three degrees of freedom, i.e. motion in longitudinal and transverse directions and rotation around the centre of the vehicle. A set of ultrasonic range sensors is mounted on a circle around the centre of the vehicle.
Reference: [4] <author> A. Dubrawski and P. Reignier. </author> <title> Learning to categorize perceptual space of a mobile robot using fuzzy-art neural network. </title> <booktitle> In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, </booktitle> <year> 1994. </year>
Reference-contexts: Especially in service scenarios, where robots perform diverse non-repetitive tasks in an only partially known environment, learning becomes essential [7]. Different aspects of learning robots, such as learning on the level of reflexes [16, 18], learning in planning [20], and learning in sensing <ref> [4, 9] </ref> have already been investigated. However, while isolated learning components responsible for small-scale, well-defined tasks are now relatively mature, the integration of such components into all levels of robot control and the efficient coordination of self-improving robot subsystems remains a difficult problem.
Reference: [5] <author> R. Heise. </author> <title> Demonstration instead of programming: Focussing attention in robot task acquisition. Research report no. </title> <type> 89/360/22, </type> <institution> Department of Computer Science, University of Calgary, </institution> <year> 1989. </year>
Reference-contexts: Especially the use of advanced sensor systems and the existence of strong requirements with respect to the robot's flexibility and safety ask for very skillful programmers and sophisticated programming environments. These circumstances let the interest in new programming methods such as Robot Programming by Demonstration (RPD) <ref> [5, 11, 6] </ref> grow rapidly. In addition, the ability to learn, i.e., to let the robot increase its performance based on its experiences, has received increasing attention [14, 7]. Especially in service scenarios, where robots perform diverse non-repetitive tasks in an only partially known environment, learning becomes essential [7].
Reference: [6] <author> M. Kaiser and R. Dillmann. </author> <title> Building elementary robot skills from human demonstration. </title> <booktitle> In IEEE International Conference on Robotics and Automation, </booktitle> <address> Minneapolis, Minnesota, USA, </address> <year> 1996. </year>
Reference-contexts: Especially the use of advanced sensor systems and the existence of strong requirements with respect to the robot's flexibility and safety ask for very skillful programmers and sophisticated programming environments. These circumstances let the interest in new programming methods such as Robot Programming by Demonstration (RPD) <ref> [5, 11, 6] </ref> grow rapidly. In addition, the ability to learn, i.e., to let the robot increase its performance based on its experiences, has received increasing attention [14, 7]. Especially in service scenarios, where robots perform diverse non-repetitive tasks in an only partially known environment, learning becomes essential [7]. <p> Here, this framework is developed on the basis of system theory and state-space models, based on previous work by Beer [2] and ourselves <ref> [6] </ref>. 2.1 Single agent model Our model of an agent is that of a skilled subsystem. A single agent is able to perform competent actions that are related to its locally defined goal and facilitate goal-oriented state transitions. <p> Then, this interaction results in adaptation of the agent based on user demonstrations and user feedback and is typically treated within the framework of skill acquisition via human demonstration <ref> [1, 6] </ref>. Here, we concentrate on learning coordination skills in the framework defined above and give a detailed description of the three principal learning tasks that must be solved. <p> Depending on the amount of examples, the actual segmentation is performed based on statistics or on heuristic analysis (for a detailed description of the segmentation process and the methods see <ref> [6, 17] </ref>).
Reference: [7] <author> M. Kaiser, V. Klingspor, J. del R. Millan, M. Accame, F. Wallner, and R. Dillmann. </author> <title> Using machine learning techniques in real-world mobile robots. </title> <journal> IEEE Expert, </journal> <year> 1995. </year>
Reference-contexts: These circumstances let the interest in new programming methods such as Robot Programming by Demonstration (RPD) [5, 11, 6] grow rapidly. In addition, the ability to learn, i.e., to let the robot increase its performance based on its experiences, has received increasing attention <ref> [14, 7] </ref>. Especially in service scenarios, where robots perform diverse non-repetitive tasks in an only partially known environment, learning becomes essential [7]. <p> In addition, the ability to learn, i.e., to let the robot increase its performance based on its experiences, has received increasing attention [14, 7]. Especially in service scenarios, where robots perform diverse non-repetitive tasks in an only partially known environment, learning becomes essential <ref> [7] </ref>. Different aspects of learning robots, such as learning on the level of reflexes [16, 18], learning in planning [20], and learning in sensing [4, 9] have already been investigated.
Reference: [8] <author> M. Kaiser, O. Rogalla, and R. Dillmann. </author> <title> Communication as the basis for learning in multi-agent systems. </title> <editor> In G. Weiss, editor, </editor> <booktitle> ECAI '96 Workshop on Learning in Distributed AI Systems, </booktitle> <address> Budapest, Hungary, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: agents, i.e., if a adds redundancy to the overall system, existing symbols must be associated to a: In both cases, a must "understand" at least parts of the representation used on the global level, in order to determine if it can contribute to the current global goal of the system <ref> [8] </ref>. If a does contribute, feedback must be available that indicates whether a 0 s contribution is complete or, possibly, if the agent failed in its local task.
Reference: [9] <author> V. Klingspor and K. Morik. </author> <title> Towards concept formation grounded on perception and action of a mobile robot. </title> <booktitle> In Proceedings of the 4th Intern. Conference on Intelligent Autonomous Systems (IAS-4), </booktitle> <address> Karlsruhe, </address> <year> 1995. </year>
Reference-contexts: Especially in service scenarios, where robots perform diverse non-repetitive tasks in an only partially known environment, learning becomes essential [7]. Different aspects of learning robots, such as learning on the level of reflexes [16, 18], learning in planning [20], and learning in sensing <ref> [4, 9] </ref> have already been investigated. However, while isolated learning components responsible for small-scale, well-defined tasks are now relatively mature, the integration of such components into all levels of robot control and the efficient coordination of self-improving robot subsystems remains a difficult problem.
Reference: [10] <author> J. Kreuziger and M. Hauser. </author> <title> A new system architecture for applying symbolic learning techniques to robot manipulation. </title> <booktitle> In Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems, </booktitle> <address> Yokohama, </address> <year> 1993. </year>
Reference-contexts: It may also be represented symboli cally, e.g., by relations defined over objects and object attributes, as in <ref> [10] </ref>.
Reference: [11] <author> Y. Kuniyoshi, M. Inaba, and H. Inoue. </author> <title> Learning by watching: Extracting reusable task knowledge from visual observation of human performance. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 10(6) </volume> <pages> 799-822, </pages> <year> 1994. </year>
Reference-contexts: Especially the use of advanced sensor systems and the existence of strong requirements with respect to the robot's flexibility and safety ask for very skillful programmers and sophisticated programming environments. These circumstances let the interest in new programming methods such as Robot Programming by Demonstration (RPD) <ref> [5, 11, 6] </ref> grow rapidly. In addition, the ability to learn, i.e., to let the robot increase its performance based on its experiences, has received increasing attention [14, 7]. Especially in service scenarios, where robots perform diverse non-repetitive tasks in an only partially known environment, learning becomes essential [7].
Reference: [12] <author> Th. Langle, T. C. Luth, and U. Rembold. </author> <title> A distributed control architecture for autonomous robot systems. </title> <editor> In H. Bunke, H. Noltemeier, and T. Kanade, editors, </editor> <title> Mod-elling and Planning for Sensor Based Intelligent Robot Systems. </title> <publisher> World Scientific, </publisher> <year> 1995. </year>
Reference-contexts: In addition, the main advantages of distributed control architectures, such as their modularity, their natural support of cooperation among subsystems, their extendability and modularity, and their inherent fault tolerance (see, for example, <ref> [12] </ref>) are maintained. The paper is organized as follows: First, we develop models of both a single agent, which is seen as a skilled subsystem, and the agent coordination, which is interpreted as a task of its own. <p> Behaviour-fusion by means of a supervisor [15], the definition of a meta-agent (a "mediator," <ref> [12] </ref>), and the definition of task-negotiation protocols are but three out of many approaches to solve the following coordination problem: Given: A task T 2 T : T is the task space of the overall system (see also Fig. 2).
Reference: [13] <author> I. S. Lin, J. Perret, F. Wallner, and R. Dillmann. </author> <title> Interactive environment modeling and vision-based task specification for a teleoperated mobile robot. </title> <booktitle> In 7th International Conference on Advanced Robotics (ICAR '95), </booktitle> <year> 1995. </year>
Reference-contexts: Therefore, the sophisticated user interface that has been developed for easy teleoperation and task specification <ref> [13] </ref> will now be extended to provide examples that are used to let the robot learn exploration strategies.
Reference: [14] <author> L. J. Lin. </author> <title> Reinforcement learning for robots using neural networks. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <year> 1993. </year>
Reference-contexts: These circumstances let the interest in new programming methods such as Robot Programming by Demonstration (RPD) [5, 11, 6] grow rapidly. In addition, the ability to learn, i.e., to let the robot increase its performance based on its experiences, has received increasing attention <ref> [14, 7] </ref>. Especially in service scenarios, where robots perform diverse non-repetitive tasks in an only partially known environment, learning becomes essential [7].
Reference: [15] <author> Y. Maeda, M. Tanabe, M. Yuta, and T. Takagi. </author> <title> Hierarchical control for autonomous mobile robots with behaviour-decision fuzzy algorithm. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <address> Nice, France, </address> <year> 1992. </year>
Reference-contexts: Behaviour-fusion by means of a supervisor <ref> [15] </ref>, the definition of a meta-agent (a "mediator," [12]), and the definition of task-negotiation protocols are but three out of many approaches to solve the following coordination problem: Given: A task T 2 T : T is the task space of the overall system (see also Fig. 2).
Reference: [16] <author> J. del R. Millan and C. Torras. </author> <title> Efficient reinforcement learning of navigation strategies in an autonomous robot. </title> <editor> In V. Graefe, editor, </editor> <booktitle> Intelligent Robots and Systems. Else-vier Science, </booktitle> <year> 1995. </year>
Reference-contexts: Especially in service scenarios, where robots perform diverse non-repetitive tasks in an only partially known environment, learning becomes essential [7]. Different aspects of learning robots, such as learning on the level of reflexes <ref> [16, 18] </ref>, learning in planning [20], and learning in sensing [4, 9] have already been investigated.
Reference: [17] <author> M. Nuttin, A. Giordana, M. Kaiser, and R. </author> <title> Suarez. B-Learn II - D 204. B-Learn II ESPRIT BRA Project No. </title> <type> 7274, </type> <year> 1995. </year>
Reference-contexts: Depending on the amount of examples, the actual segmentation is performed based on statistics or on heuristic analysis (for a detailed description of the segmentation process and the methods see <ref> [6, 17] </ref>).
Reference: [18] <author> M. Nuttin, J. Peirs, A.S. Soembagijo, S. Sonck, and H. Van Brussel. </author> <title> Learning the peg-into-hole assembly with a connectionist reinforcement technique. </title> <booktitle> In Second International CIRP Workshop on Learning in Intelligent Manufacturing Systems, </booktitle> <address> Budapest, Hungary, </address> <year> 1995. </year>
Reference-contexts: Especially in service scenarios, where robots perform diverse non-repetitive tasks in an only partially known environment, learning becomes essential [7]. Different aspects of learning robots, such as learning on the level of reflexes <ref> [16, 18] </ref>, learning in planning [20], and learning in sensing [4, 9] have already been investigated.
Reference: [19] <author> F. Wallner, R. Graf, and R. Dillmann. </author> <title> Real-time map refinement by fusing sonar and active stereo vision. </title> <booktitle> In IEEE International Conference on Robotics and Automation, </booktitle> <year> 1995. </year>
Reference-contexts: A set of ultrasonic range sensors is mounted on a circle around the centre of the vehicle. It is also equipped with the active stereo-vision head KASTOR and a laser scanner [21]. To efficiently integrate PRIAMOS' several sensor systems in order to not only refine geometric maps <ref> [19] </ref> but to generate maps containing topologic and semantic information has proven to be a very difficult task that demands learning capabilities.
Reference: [20] <author> F. Wallner, M. Kaiser, H. Friedrich, and R. Dillmann. </author> <title> A multilevel learning approach to mobile robot path planning. </title> <editor> In V. Graefe, editor, </editor> <booktitle> Intelligent Robots and Systems. </booktitle> <publisher> Elsevier Science, </publisher> <year> 1995. </year>
Reference-contexts: Especially in service scenarios, where robots perform diverse non-repetitive tasks in an only partially known environment, learning becomes essential [7]. Different aspects of learning robots, such as learning on the level of reflexes [16, 18], learning in planning <ref> [20] </ref>, and learning in sensing [4, 9] have already been investigated. However, while isolated learning components responsible for small-scale, well-defined tasks are now relatively mature, the integration of such components into all levels of robot control and the efficient coordination of self-improving robot subsystems remains a difficult problem.
Reference: [21] <author> P. Weckesser, G. Appenzeller, A. von Essen, and R. Dill-mann. </author> <title> Exploration of the environment with an active and intelligent optical sensor system. </title> <booktitle> In IEEE/RSJ International Conference on Intelligent Robots and Systems, </booktitle> <address> Os-aka, Japan, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: A set of ultrasonic range sensors is mounted on a circle around the centre of the vehicle. It is also equipped with the active stereo-vision head KASTOR and a laser scanner <ref> [21] </ref>. To efficiently integrate PRIAMOS' several sensor systems in order to not only refine geometric maps [19] but to generate maps containing topologic and semantic information has proven to be a very difficult task that demands learning capabilities.
References-found: 21

