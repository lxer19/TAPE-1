URL: http://www.cs.wustl.edu/~jxh/research/papers/infocom98-submission.ps.gz
Refering-URL: http://www.cs.wustl.edu/~jxh/research/research.html
Root-URL: 
Email: fjxh,sumedh,schmidtg@cs.wustl.edu  
Phone: TEL: (314) 935-4215 FAX: (314) 935-7302  
Title: Techniques for Developing and Measuring High Performance Web Servers over High Speed Networks  
Author: James C. Hu Sumedh Mungee, Douglas C. Schmidt 
Affiliation: Washington University  
Address: Campus Box 1045/Bryan 509  One Brookings Drive St. Louis, MO 63130, USA  
Abstract: High-performance Web servers are essential to meet the growing demands of the Internet and large-scale intranets. Satisfying these demands requires a thorough understanding of key factors affecting Web server performance. This paper presents empirical analysis illustrating how dynamic and static adaptivity can enhance Web server performance. Two research contributions support this conclusion. First, the paper presents results from a comprehensive empirical study of Web servers (such as Apache, Netscape Enterprise, PHTTPD, Zeus, and JAWS) over high-speed ATM networks. This study illustrates their relative performance and precisely pinpoints the server design choices that cause performance bottlenecks. We found that once network and disk I/O overheads are reduced to negligible constant factors, the main determinants of Web server performance are its protocol processing path and concurrency strategy. Moreover, no single strategy performs optimally for all load conditions and traffic types. Second, we describe the design techniques and optimizations used to develop JAWS, our high-performance, adaptive Web server. JAWS is an object-oriented Web server that was explicitly designed to alleviate the performance bottlenecks we identified in existing Web servers. It consistently outperforms all other Web servers over ATM networks. The performance optimizations used in JAWS include adaptive pre-spawned threading, fixed headers, cached date processing, and file caching. In addition, JAWS uses a novel software architecture that substantially improves its portability and flexibility, relative to other Web servers. Our empirical results illustrate that highly efficient communication software is not antithetical to highly flexible software. fl This work was funded in part by NSF grant NCR-9628218, Object Technologies International, Eastman Kodak, and Siemens MED.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jussara Almeida, Virg ilio Almeida, and David J. Yates. </author> <title> Measuring the Behavior of a World-Wide Web Server. </title> <type> Technical Report TR-CS-96-025, </type> <institution> Department of Computer Science, Boston University, </institution> <month> October 29 </month> <year> 1996. </year>
Reference-contexts: Our results show that no single concurrency strategy provides optimal performance in all circumstances. In general, research on adaptive software has not been pursued deeply in the context of Web systems. Current research on Web server performance has emphasized caching [11, 20], concurrency [7], and I/O <ref> [12, 1] </ref>. While our results corroborate that caching is vital to high performance, non-adaptive caching strategies do not provide optimal performance in Web servers [9].
Reference: [2] <author> Anselm Baird-Smith. </author> <title> Jigsaw performance evaluation. </title> <note> Available from http://www.w3.org/, October 1996. </note>
Reference-contexts: The choice of servers for our study were based on two factors. The first was variation in Web server design, to gauge the performance impact of alternative approaches to concurrency, event dispatching, and filesystem access. The second was published performance, as reported by benchmark results published by Jigsaw <ref> [2] </ref> and NCSA [10], as well as information available from WebCompare [17]. 2.2 Web Server/ATM Testbed 2.2.1 Hardware and Software Platforms We studied Web server performance by observing how the servers in our test suite performed on high-speed networks under heavy workloads.
Reference: [3] <author> Alexander Carlton. </author> <title> An Explanation of the SPECweb96 Benchmark. Standard Performance Evaluation Corporation whitepaper, </title> <note> 1996. Available from http://www.specbench.org/. </note>
Reference-contexts: Document Size (bytes) 500 5 K 50 K 5 M Frequency 35% 50% 14% 1% Table 1: File Access Patterns This table represents actual load conditions on popular servers, based on a study of file access patterns conducted by SPEC <ref> [3] </ref>. We benchmarked each Web server on an UltraSPARC-2 host, while the Web clients ran on three other UltraSPARC-2s. Web clients are controlled by a central Webmaster, which starts the Web clients simultaneously. The Webmaster also collects and combines the measurements made by individual clients.
Reference: [4] <author> Gene Trent and Mark Sake. WebSTONE: </author> <title> The First Generation in HTTP Server Benchmarking. Silicon Graphics, </title> <publisher> Inc. </publisher> <address> whitepaper, </address> <month> February </month> <year> 1995. </year> <note> Available from http://www.sgi.com/. </note>
Reference-contexts: This allows up to eight switched virtual connections per card. This testbed is similar to the one used in [5]. 2.2.2 Benchmarking Methodology We used the WebSTONE <ref> [4] </ref> v2.0 benchmarking software to collect client- and server-side metrics. As described in Section 2.3, these metrics included average server throughput, average client throughput, average number of connections-per-second, and average client latency. The testbed comprised multiple concurrent Web clients, running on UNIX hosts depicted in Figure 1.
Reference: [5] <author> Aniruddha Gokhale and Douglas C. Schmidt. </author> <title> Measuring the Performance of Communication Middleware on High-Speed Networks. </title> <booktitle> In Proceedings of SIGCOMM '96, </booktitle> <pages> pages 306317, </pages> <address> Stanford, CA, </address> <month> August </month> <year> 1996. </year> <note> ACM. </note>
Reference-contexts: A maximum of 32 Kbytes is allotted per ATM virtual circuit connection for receiving and transmitting frames (for a total of 64 K). This allows up to eight switched virtual connections per card. This testbed is similar to the one used in <ref> [5] </ref>. 2.2.2 Benchmarking Methodology We used the WebSTONE [4] v2.0 benchmarking software to collect client- and server-side metrics. As described in Section 2.3, these metrics included average server throughput, average client throughput, average number of connections-per-second, and average client latency.
Reference: [6] <author> James Hu, Sumedh Mungee, and Douglas C. Schmidt. </author> <title> Principles for Developing and Measuring High-performance Web Servers over ATM. </title> <note> In Submitted to INFOCOM '97 (Washington University Technical Report #WUCS-97-10), </note> <month> February </month> <year> 1997. </year>
Reference-contexts: These observations are based on our studies of existing Web server designs and implementation strategies, as well as our experience tuning JAWS. These studies reveal the primary targets for optimizations to develop high performance Web servers. Lightweight concurrency: Process-based concurrency mechanisms can yield poor performance, as seen in <ref> [6] </ref>. In multi-processor systems, a process-based concurrency mechanism might perform well, especially when the number of processes are equal to the number of processors. In this case, each processor can run a Web server process and context switching overhead is minimized. <p> However, the use synchronization penalizes performance. Thus, it is important to minimize the number of locks acquired (or released) during the request lifecycle. In <ref> [6] </ref>, it is shown that servers that average a lower number of lock operations per request perform much better than servers that perform a high number of lock operations. In some cases, acquiring and releasing locks can also result in preemption.
Reference: [7] <author> James Hu, Irfan Pyarali, and Douglas C. Schmidt. </author> <title> Measuring the Impact of Event Dispatching and Concurrency Models on Web Server Performance Over High-speed Networks. </title> <booktitle> In Proceedings of the 2 nd Global Internet Conference. IEEE, </booktitle> <month> November </month> <year> 1997. </year>
Reference-contexts: Traffic increases are due largely to the proliferation of inexpensive and ubiquitous Web browsers (such as NCSA Mosaic, Netscape Navigator, and Internet Explorer). Likewise, Web protocols and browsers are increasingly applied to specialized computation-ally expensive tasks, such as image processing servers used by Siemens <ref> [7] </ref> and Kodak [13] and database search engines (e.g., AltaVista and Lexis Nexis). To keep pace with increasing demand, it is essential to develop high-performance Web servers. <p> Therefore, asynchronous I/O mechanisms in Windows NT and POSIX must be studied, compared, and tested against traditional concurrent server programming paradigms that utilize synchronous event demultiplexing and threading <ref> [7] </ref>. Dynamic adaptivity allows a Web server to alter its run-time behavior on-the-fly. This is useful when external conditions have changed to the point where the initial configuration no longer provides optimal performance. Such situations have been observed in [7] and [9]. <p> concurrent server programming paradigms that utilize synchronous event demultiplexing and threading <ref> [7] </ref>. Dynamic adaptivity allows a Web server to alter its run-time behavior on-the-fly. This is useful when external conditions have changed to the point where the initial configuration no longer provides optimal performance. Such situations have been observed in [7] and [9]. <p> As events are processed, they are dispensed to the Protocol Handler, which is parameterized by a concurrency strategy and an I/O strategy, as discussed below. Concurrency Strategy: This implements concurrency mechanisms (such as single-threaded, Thread-per-Request, or synchronous/asynchronous Thread Pool <ref> [7] </ref>) that can be selected adaptively at run-time or pre-determined at initialization-time. These strategies are discussed in Section 3.2.3. I/O Strategy: This implements the I/O mechanisms (such as asynchronous, synchronous, and reactive). Multiple I/O mechanisms can be used simultaneously. <p> In the case of TransmitFile, our empirical data indicate that the asynchronous form of TransmitFile is the most efficient mechanism for transferring large files over sockets on Windows NT, as shown in <ref> [7] </ref>. Request lifecycle system call overhead: The request life-cycle in a Web server is defined as the sequence of instructions that must be executed by the server after it receives an 8 HTTP request from the client and before it sends out the re-quested file. <p> Our results show that no single concurrency strategy provides optimal performance in all circumstances. In general, research on adaptive software has not been pursued deeply in the context of Web systems. Current research on Web server performance has emphasized caching [11, 20], concurrency <ref> [7] </ref>, and I/O [12, 1]. While our results corroborate that caching is vital to high performance, non-adaptive caching strategies do not provide optimal performance in Web servers [9].
Reference: [8] <author> PureAtria Software Inc. </author> <title> Quantify User's Guide. </title> <institution> PureAtria Software Inc., </institution> <year> 1996. </year>
Reference-contexts: These clients computed several blackbox met-rics, as explained in Section 2.3. To precisely pinpoint the source of performance bottlenecks, we employed whitebox benchmarks. This involved the use of profiling tools, including the UNIX truss (1) tool, TNF [18], and Quantify <ref> [8] </ref>. These tools trace and log the activities of Web servers and measure the time spent on various tasks, as explained in Section 2.4. 2.3 Blackbox Performance Analysis The following WebSTONE blackbox metrics were measured in our Web server performance study.
Reference: [9] <author> Evangelos P. Markatos. </author> <title> Main memory caching of web documents. </title> <booktitle> In Proceedings of the Fifth International World Wide Web Conference, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Dynamic adaptivity allows a Web server to alter its run-time behavior on-the-fly. This is useful when external conditions have changed to the point where the initial configuration no longer provides optimal performance. Such situations have been observed in [7] and <ref> [9] </ref>. <p> Current research on Web server performance has emphasized caching [11, 20], concurrency [7], and I/O [12, 1]. While our results corroborate that caching is vital to high performance, non-adaptive caching strategies do not provide optimal performance in Web servers <ref> [9] </ref>. Moreover, current server implementations and experiments rely on statically configured concurrency and I/O strategies. 9 As a result of our empirical studies, we observed that servers relying on static, fixed strategies cannot behave optimally in many high load circumstances.
Reference: [10] <author> Robert E. McGrath. </author> <title> Performance of Several HTTP Demons on an HP 735 Workstation. </title> <note> Avaiable from http://www.ncsa.uiuc.edu/, April 25 1995. </note>
Reference-contexts: The first was variation in Web server design, to gauge the performance impact of alternative approaches to concurrency, event dispatching, and filesystem access. The second was published performance, as reported by benchmark results published by Jigsaw [2] and NCSA <ref> [10] </ref>, as well as information available from WebCompare [17]. 2.2 Web Server/ATM Testbed 2.2.1 Hardware and Software Platforms We studied Web server performance by observing how the servers in our test suite performed on high-speed networks under heavy workloads.
Reference: [11] <author> Jeffrey C. Mogul. </author> <title> Hinted caching in the Web. </title> <booktitle> In Proceedings of the Seventh SIGOPS European Workshop: Systems Support for Worldwide Applications, </booktitle> <year> 1996. </year>
Reference-contexts: Sizes Request Model mizations JAWS Performance Comparisons 3.2.4 File Caching Strategies Our analysis in Section 2 determined that accessing the filesystem is a significant performance inhibitor. This concurs with other Web server performance research <ref> [11, 20] </ref> that uses caching to achieve better performance. While the baseline version of JAWS does employ caching, it spends too much time synchronizing concurrent thread access to the Cached Virtual Filesystem (CVF). To address this concern, the CVF was re-engineered. <p> Our results show that no single concurrency strategy provides optimal performance in all circumstances. In general, research on adaptive software has not been pursued deeply in the context of Web systems. Current research on Web server performance has emphasized caching <ref> [11, 20] </ref>, concurrency [7], and I/O [12, 1]. While our results corroborate that caching is vital to high performance, non-adaptive caching strategies do not provide optimal performance in Web servers [9].
Reference: [12] <author> Nancy J. Yeager and Robert E. McGrath. </author> <title> Web Server Technology: The Advanced Guide for World Wide Web Information Providers. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year>
Reference-contexts: Our results show that no single concurrency strategy provides optimal performance in all circumstances. In general, research on adaptive software has not been pursued deeply in the context of Web systems. Current research on Web server performance has emphasized caching [11, 20], concurrency [7], and I/O <ref> [12, 1] </ref>. While our results corroborate that caching is vital to high performance, non-adaptive caching strategies do not provide optimal performance in Web servers [9].
Reference: [13] <author> Irfan Pyarali, Timothy H. Harrison, and Douglas C. Schmidt. </author> <title> Design and Performance of an Object-Oriented Framework for High-Performance Electronic Medical Imaging. </title> <booktitle> USENIX Computing Systems, </booktitle> <volume> 9(4), </volume> <month> November/December </month> <year> 1996. </year>
Reference-contexts: Traffic increases are due largely to the proliferation of inexpensive and ubiquitous Web browsers (such as NCSA Mosaic, Netscape Navigator, and Internet Explorer). Likewise, Web protocols and browsers are increasingly applied to specialized computation-ally expensive tasks, such as image processing servers used by Siemens [7] and Kodak <ref> [13] </ref> and database search engines (e.g., AltaVista and Lexis Nexis). To keep pace with increasing demand, it is essential to develop high-performance Web servers.
Reference: [14] <author> Douglas C. Schmidt. GPERF: </author> <title> A Perfect Hash Function Generator. </title> <booktitle> In Proceedings of the 2 nd C++ Conference, </booktitle> <pages> pages 87102, </pages> <address> San Francisco, California, </address> <month> April </month> <year> 1990. </year> <booktitle> USENIX. </booktitle>
Reference-contexts: This allows different caching policies to be profiled for effectiveness and enables optimal strategies to be configured statically or dynamically. These strategies are discussed in Section 3.2.4. Tilde Expander: This mechanism is another cache component that uses a perfect hash table <ref> [14] </ref> to map abbreviated user login names (e.g., ~schmidt) to user home directories (e.g., /home/cs/faculty/schmidt).
Reference: [15] <author> Douglas C. Schmidt. </author> <title> ACE: an Object-Oriented Framework for Developing Distributed Applications. </title> <booktitle> In Proceedings of the 6 th USENIX C++ Technical Conference, </booktitle> <address> Cambridge, Massachusetts, </address> <month> April </month> <year> 1994. </year> <institution> USENIX Association. </institution>
Reference-contexts: JAWS is structured as a framework [16] that contains the following components: an Event Dispatcher, Concurrency Strategy, I/O Strategy, Protocol Pipeline, Protocol Handlers, Cached Virtual Filesystem, and Tilde Expander. Each component is structured as a set of collaborating objects implemented with the ADAPTIVE Communication Environment (ACE) C++ communication framework <ref> [15] </ref>. Each component plays the following role in JAWS: Event Dispatcher: This component is responsible for coordinating the Concurrency Strategy with the I/O Strategy. As events are processed, they are dispensed to the Protocol Handler, which is parameterized by a concurrency strategy and an I/O strategy, as discussed below. <p> Therefore, we conclude that high-performance Web servers must be adaptive, i.e., be customizable to utilize the most beneficial strategy for particular traffic characteristics, workload, and hardware/OS platforms. JAWS supports Web server adaptivity by providing a framework built using an adaptive communication environment (ACE) <ref> [15] </ref>. Future versions of JAWS will support prioritized request handling (to promote requests for smaller objects of requests for larger objects), dynamic protocol pipelines (to support optimal end-to-end data filtering operations, such as compression), as well as automatic configuration for concurrency, I/O dispatching and caching strategies.
Reference: [16] <author> Douglas C. Schmidt. </author> <title> Applying Design Patterns and Frameworks to Develop Object-Oriented Communication Software. </title> <editor> In Peter Salus, editor, </editor> <booktitle> Handbook of Programming Languages. </booktitle> <publisher> MacMillan Computer Publishing, </publisher> <year> 1997. </year>
Reference-contexts: Therefore, JAWS is designed to allow these Web server strategies to be customized according to key environmental factors. These factors include traffic patterns, workload characteristics, support for kernel-level threading and/or asynchronous I/O in the OS, and the number of available CPUs. JAWS is structured as a framework <ref> [16] </ref> that contains the following components: an Event Dispatcher, Concurrency Strategy, I/O Strategy, Protocol Pipeline, Protocol Handlers, Cached Virtual Filesystem, and Tilde Expander. Each component is structured as a set of collaborating objects implemented with the ADAPTIVE Communication Environment (ACE) C++ communication framework [15].
Reference: [17] <author> David Strom. </author> <note> Web Compare. Available from http://webcompare.iworld.com/, 1997. </note>
Reference-contexts: The first was variation in Web server design, to gauge the performance impact of alternative approaches to concurrency, event dispatching, and filesystem access. The second was published performance, as reported by benchmark results published by Jigsaw [2] and NCSA [10], as well as information available from WebCompare <ref> [17] </ref>. 2.2 Web Server/ATM Testbed 2.2.1 Hardware and Software Platforms We studied Web server performance by observing how the servers in our test suite performed on high-speed networks under heavy workloads.
Reference: [18] <author> SunSoft Inc. </author> <title> TNFtools:Programming Utilities Guide. </title> <type> 2550 Garcia Avenue, </type> <address> Mountain View CA 94043, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: These clients computed several blackbox met-rics, as explained in Section 2.3. To precisely pinpoint the source of performance bottlenecks, we employed whitebox benchmarks. This involved the use of profiling tools, including the UNIX truss (1) tool, TNF <ref> [18] </ref>, and Quantify [8]. These tools trace and log the activities of Web servers and measure the time spent on various tasks, as explained in Section 2.4. 2.3 Blackbox Performance Analysis The following WebSTONE blackbox metrics were measured in our Web server performance study.
Reference: [19] <author> J.S. Turner. </author> <title> An optimal nonblocking multicast virtual circuit switch. </title> <booktitle> In Proceedings of the Conference on Computer Communications (INFO-COM), </booktitle> <pages> pages 298305, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: To accomplish this, we constructed a hardware and software testbed consisting of the Web server being tested, and multiple clients connected to it via a high-speed ATM switch <ref> [19] </ref>, as shown in Figure 1. 1 1 We also performed measurements over 10 Mbps Ethernet, but due to a lack of performance variance, we omitted the discussion from this paper. 2 The experiments in this paper were conducted using a Bay Networks LattisCell 10114 ATM switch connected to four dual-processor
Reference: [20] <author> Stephen Williams, Marc Abrams, Charles R. Standridge, Ghalleb Ab-dulla, and Edward A. Fox. </author> <title> Removal Policies in Network Caches for World Wide Web Documents. </title> <booktitle> In Proceedings of SIGCOMM '96, </booktitle> <pages> pages 293305, </pages> <address> Stanford, CA, </address> <month> August </month> <year> 1996. </year> <journal> ACM. </journal> <volume> 10 </volume>
Reference-contexts: Sizes Request Model mizations JAWS Performance Comparisons 3.2.4 File Caching Strategies Our analysis in Section 2 determined that accessing the filesystem is a significant performance inhibitor. This concurs with other Web server performance research <ref> [11, 20] </ref> that uses caching to achieve better performance. While the baseline version of JAWS does employ caching, it spends too much time synchronizing concurrent thread access to the Cached Virtual Filesystem (CVF). To address this concern, the CVF was re-engineered. <p> Our results show that no single concurrency strategy provides optimal performance in all circumstances. In general, research on adaptive software has not been pursued deeply in the context of Web systems. Current research on Web server performance has emphasized caching <ref> [11, 20] </ref>, concurrency [7], and I/O [12, 1]. While our results corroborate that caching is vital to high performance, non-adaptive caching strategies do not provide optimal performance in Web servers [9].
References-found: 20

