URL: ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-93-47.ps.Z
Refering-URL: ftp://ftp.cse.ucsc.edu/pub/tr/README.html
Root-URL: http://www.cse.ucsc.edu
Title: Scalable Parallel Direct Volume Rendering for Nonrectilinear Computational Grids  approved:  
Author: Judith Ann Challinger Dr. Jane Wilhelms Dr. Charles McDowell Dr. Nelson Max Dean 
Degree: A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Computer and Information Science by  
Note: The dissertation of Judith Ann Challinger is  
Date: December 1993  
Affiliation: University of California Santa Cruz  of Graduate Studies and Research  
Abstract-found: 0
Intro-found: 1
Reference: [AG89] <author> George S. Almasi and Allan Gottlieb. </author> <title> Highly Parallel Computing. </title> <publisher> The Ben-jamin/Cummings Publishing Company, Inc., </publisher> <year> 1989. </year>
Reference-contexts: The processors and memory in a system may be connected by a bus, ring, mesh, hypercube, or multistage switching network. An excellent description of many of these parallel architectures, along with a discussion of language and operating system issues, is given by Almasi & Gottlieb <ref> [AG89] </ref>. Several of the newest highly parallel MIMD architectures are described in [Hor93]. 2.2.2 Measurement Techniques In order to assess the efficiency and scalability of various parallel implementations, measurements of performance characteristics are made. Common measures used to analyze 18 n Number of processors. T 1 Serial execution time. <p> This chapter presents an overview of several highly parallel architectures from early attempts to provide a scalable shared-memory system to commercial and research machines still in development. The particular parallel machine used in this research, a BBN TC2000, is described in some detail. 3.1 Overview Almasi and Gottlieb <ref> [AG89] </ref> describe several of the first highly parallel MIMD architectures which utilize shared memory including the Denelcor HEP, NYU Ultracomputer, BBN Butterfly, IBM RP3, and UI Ceder. A survey of more recent highly parallel MIMD architectures is given by Hord [Hor93].
Reference: [Ake93] <author> Kurt Akeley. </author> <title> RealityEngine Graphics. </title> <journal> Computer Graphics, </journal> <pages> pages 109-116, </pages> <year> 1993. </year> <note> Proceedings of SIGGRAPH '93. </note>
Reference-contexts: An interlaced memory scheme is used to achieve load balancing. Several of today's powerful computer graphics workstations utilize a scheme very similar to this to speed the rendering process <ref> [Ake93, DN93] </ref>. Cleary, et al. [CWBV83] give an algorithm for raytracing on a distributed-memory MIMD architecture. A theoretical analysis of expected speedup was done, with software simulation to verify results.
Reference: [BBN88] <author> BBN Advanced Computers, Inc. </author> <title> Programming in C with the Uniform System, revision 1.0 edition, </title> <month> October </month> <year> 1988. </year>
Reference-contexts: This section briefly presents a few of the Uniform System functions. For a full description of the Uniform System the reader is referred to the TC2000 documentation <ref> [BBN88] </ref>. Memory Management The Uniform System implements a large virtual address space that is shared by all processors. This approach allows the programmer to treat all processors as identical workers. Each processor has two kinds of memory at its disposal.
Reference: [BBN89] <institution> BBN Advanced Computers, Inc. Inside the TC2000 Computer, </institution> <note> preliminary edition, </note> <month> August 14 </month> <year> 1989. </year>
Reference-contexts: The cache hit and miss timings are for writethrough mode. 3.2.1 TC2000 Architecture The BBN TC2000 is a multiprocessor architecture with a distributed shared memory <ref> [BBN89] </ref>. The TC2000 processors access the shared memory through an interconnection network called the Butterfly switch. The architecture is modular and scalable and can be configured to contain between 1 and 512 function boards.
Reference: [BGWW91] <author> Eugene D. Brooks III, Brent C. Gorda, Karen H. Warren, and Tammy S. </author> <title> Welcome. Split-Join and Message Passing Programming Models on the BBN TC2000. </title> <booktitle> In The 1991 MPCI Yearly Report: The Attack of the Killer Micros, </booktitle> <pages> pages 6-11. </pages> <institution> Lawrence Livermore National Laboratory, </institution> <month> March </month> <year> 1991. </year> <month> UCRL-ID-107022. </month>
Reference-contexts: It could be combined with the sorting phase at the expense of transforming each grid node three times. Alternatively, a method of task generation in which the overhead of going parallel is reduced (i.e. a "split-join" as opposed to a "fork-join" approach <ref> [PWD93, BGWW91] </ref>) would reduce the inefficiency of having three small task phases. The sorting phase did see a speedup for all datasets, although it certainly tails off by 110 processors and is not close to being linear.
Reference: [BL90] <author> Andrew Burke and Wm Leler. </author> <title> Parallelism and Graphics: an Introduction and Annotated Bibliography. In SIGGRAPH Course Notes: Parallel Algorithms and Architectures for 3D Image Generation, </title> <year> 1990. </year>
Reference-contexts: The machine which produced the results was not identified, but an efficiency of 77% was reported for 16 processors. 2.3 Parallel Computer Graphics Related efforts in the parallelization of computer graphics algorithms are surveyed by Burke and Leler <ref> [BL90] </ref> and Crow [Cro90]. Several representative approaches are summarized here and will be described in more detail below. Fuchs proposed a technique for distributing the z-buffer hidden surface removal algorithm over a distributed-memory MIMD architecture [Fuc77].
Reference: [Bli82a] <author> J. F. </author> <title> Blinn. Light Reflection Functions for Simulation of Clouds and Dusty Surfaces. </title> <booktitle> In Proceedings of SIGGRAPH '82, </booktitle> <pages> pages 21-29, </pages> <year> 1982. </year>
Reference-contexts: In particular, the attempts at rendering such things as clouds, fog, dust, and particle systems can be considered specific applications of volumetric rendering. Blinn utilized a volume of density values to model clouds and presented a technique for rendering them <ref> [Bli82a] </ref>. Nelson Max extended his work in various ways [Max86] and Kajiya addressed methods for raytracing such models [KH84].
Reference: [Bli82b] <author> James Blinn. </author> <title> A Generalization of Algebraic Surface Drawing. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 1(3) </volume> <pages> 235-256, </pages> <year> 1982. </year>
Reference-contexts: All of these algorithms generate a geometric representation of a subset of the volumetric dataset. Closely related to the techniques for isosurface generation are those used in the generation of implicit surfaces [Nor82, WMW86, Blo88], and in specialized methods for raytracing to a contour surface <ref> [Bli82b, NHK + 85] </ref>. 2.1.2 Direct Volume Rendering One drawback to the use of isosurfaces as a means to visualize the contents of volumetric datasets is the fact that this approach inherently presents a subset of the data, throwing the rest of the information away.
Reference: [Blo88] <author> Jules Bloomenthal. </author> <title> Polygonization of Implicit Surfaces. </title> <booktitle> Computer-Aided Geometric Design, </booktitle> <volume> 5 </volume> <pages> 341-355, </pages> <year> 1988. </year>
Reference-contexts: All of these algorithms generate a geometric representation of a subset of the volumetric dataset. Closely related to the techniques for isosurface generation are those used in the generation of implicit surfaces <ref> [Nor82, WMW86, Blo88] </ref>, and in specialized methods for raytracing to a contour surface [Bli82b, NHK + 85]. 2.1.2 Direct Volume Rendering One drawback to the use of isosurfaces as a means to visualize the contents of volumetric datasets is the fact that this approach inherently presents a subset of the data,
Reference: [BP90] <author> Didier Badouel and Thierry Priol. </author> <title> An Efficient Parallel Ray Tracing Scheme for Highly Parallel Architectures. </title> <booktitle> In Proceedings of the Fifth Eurographics Workshop on Graphics Hardware, </booktitle> <month> September </month> <year> 1990. </year>
Reference-contexts: Parallelization of global illumination algorithms in a distributed workstation environment has been addressed by Tampieri and Greenberg [TG88]. Parallelization of the raytracing algorithm on a distributed-memory MIMD architecture using an image-space decomposition is presented by Badouel <ref> [BP90] </ref>. This algorithm depends on an implementation of shared virtual memory with local caching. Whitman explores several image-space decompositions and scheduling strategies on a shared-memory MIMD machine [Whi92]. A detailed analysis of the overhead incurred in the parallelization is presented. <p> The monte carlo method uses a coarse progressive refinement radiosity solution and then an image-space subdivision to trace rays. Demand scheduling is used for load balancing. Badouel and Priol <ref> [BP90] </ref> describe parallel raytracing on a distributed-memory, MIMD architecture. The key feature is the use of shared virtual memory with local caching to make the data structures available to all processors. A task adaptive scheduling strategy is utilized. <p> The Intel iPSC/2 may contain up to 128 80386/80387 processors connected in a hypercube topology. The iPSC/2 system only provides support for message passing, however applications based on software implementations of shared virtual memory have been shown to efficiently utilize the machine <ref> [BP90] </ref>. The nCUBE may be configured with 8 to 8K processors. Each processor is a proprietary 64-bit VLSI chip. The interconnection network utilizes a hypercube topology with data and control messages routed via high-speed DMA communications channels with hardware routing. The nCUBE only supports message passing.
Reference: [Cha90] <author> Judith Ann Challinger. </author> <title> Object-Oriented Rendering of Volumetric and Geometric Primitives. </title> <type> Master's thesis, </type> <institution> University of California, Santa Cruz, </institution> <year> 1990. </year>
Reference-contexts: Their technique does provide the very useful features of arbitrary cutting planes for volumes and texture mapping using volumetric data. We have investigated how object-oriented design and implementation techniques can be used to accomplish an integrated rendering approach <ref> [Cha90] </ref>. The raycasting algorithm presented addresses the rendering of geometrically defined primitives embedded in a volumetric dataset. Algorithms for rendering both rectilinear and nonrectilinear volumetric datasets are given. 14 Giertsen [GT92] has presented an algorithm for rendering embedded geometrical primitives in unstructured volumetric datasets. <p> The rationale behind several key decisions is discussed, along with the statement of several key goals. In order to experiment with various parallel volume rendering algorithms, an object-oriented volume renderer <ref> [Cha90] </ref> was ported to the BBN TC2000. This volume renderer initially used the raycasting algorithm as the method for rendering an image. The code was extended to provide the projection approach as another rendering method [MHC90]. <p> The algorithms also support the inclusion of embedded geometrical primitives (polygons), leading to the ability to render the simulation geometry with the scalar field to obtain a more easily understood image <ref> [Cha90] </ref>. Finally, the two-phase approach gives the user the capability to quickly explore different transfer functions for rendering. This will also lead to increased understanding of the scalar field. 60 4.4 Approach Chosen for Detailed Investigation A very basic tradeoff between decomposition approaches has been identified. <p> Although this chapter focuses primarily on the class design and implementation for curvilinear grids, the design of the system is such that many types of geometric and volumetric objects can be defined and rendered by one or more rendering methods <ref> [Cha90] </ref>. Renderable Objects The renderable objects are the different types of objects that can be specified, oriented, and positioned in the world description, and then rendered to an image. All renderable objects are derived from a base class, object base (see figure 5.2). This mechanism provides several key capabilities.
Reference: [Cha91] <author> Judy Challinger. </author> <title> Parallel Volume Rendering on a Shared-Memory Multiprocessor. </title> <type> Technical Report UCSC-CRL-91-23, </type> <institution> University of California, Santa Cruz, </institution> <year> 1991. </year>
Reference-contexts: Two researchers have reported on parallel splatting algorithms and a few have addressed implementations of parallel projection algorithms on smaller multiprocessor computer graphics workstations. We have conducted a comparison of parallel image-space versus object-space rendering algorithms and the problems inherent in the two approaches <ref> [Cha91] </ref>. The results indicate that image-space decompositions may be easier to parallelize with high efficiency. Most of the research conducted so far has been directed towards direct volume rendering of rectilinear datasets. <p> For a projection or splatting approach, the processing of cells or nodes will need to be ordered to ensure that the resulting compositing operations are also correctly ordered. This will lead to synchronization requirements <ref> [Cha91] </ref>. 4.1.4 Other Issues There are other issues that are important for developing parallel direct volume rendering as a useful, interactive, integrable, visualization tool for volumetric datasets: * As the time to render an image approaches interactive rates the problem of getting the generated image out to the screen where it <p> The serial version of this volume renderer has provided a starting point for several experiments in parallel direct volume rendering. 4.3.1 Comparison of Decompositions for Rectilinear Grids Some initial investigations into parallelization techniques for volume rendering are presented in <ref> [Cha91] </ref>. This work examines parallel implementations for both the raycasting and cell projection approaches to volume rendering for rectilinear grids. Only orthogonal viewing projections are considered in each case. <p> Both algorithms use the raycasting approach to volume rendering, avoiding the issue of inter-processor ordering of the compositing operations for each pixel which arises with parallelization of object-space volume rendering algorithms <ref> [Cha91] </ref>. Only orthogonal viewing projections have been implemented, although the algorithms are equally applicable to perspective projections. The algorithms presented here require that, for each ray, all intersections with cell faces be found. The algorithm proceeds cell by cell through the volume, estimating the line integral of the scalar field. <p> Implementations of object-space decompositions for projection or splatting algorithms have been shown to be limited in terms of their scalability by synchronization requirements <ref> [Cha91, Wil92c, 61 Elv92] </ref>. The parallel direct volume rendering algorithm described in the next chapter utilizes interleaved globally-shared memory to store the volumetric dataset.
Reference: [Cha92] <author> Judy Challinger. </author> <title> Parallel Volume Rendering for Curvilinear Volumes. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference, </booktitle> <pages> pages 14-21. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> April </month> <year> 1992. </year>
Reference-contexts: Another approach is to sort the grid cells or faces in screen-space, and then test for ray intersection only with those cells or faces that are active at a given pixel <ref> [Cha92] </ref>. <p> An early version of the raycasting algorithm presented in this thesis performed bucket sorts in x and y on the cells of a curvilinear grid to reduce intersection testing requirements <ref> [Cha92] </ref>. <p> All of the above research has been directed towards rendering of rectilinear datasets. Very recently researchers have been investigating parallel direct volume rendering algorithms for datasets that are nonrectilinear. We have published results of an investigation of a parallel raycasting algorithm which was implemented on the BBN TC2000 <ref> [Cha92] </ref>. The BBN TC2000 is a distributed-memory architecture which provides virtual shared-memory. An image-space task decomposition was used in which each scanline of the image constitutes one task. The scanlines are dynamically allocated to processors for rendering. <p> These complications will result in even larger memory requirements for the storage of the visibility graph which may be prohibitive for large volumetric datasets. 4.3.2 Extension of Raycasting Approach to Curvilinear Grids A technique for parallel volume rendering of curvilinear grids is described in <ref> [Cha92] </ref>. The cell-by-cell raycasting approach is enhanced with an algorithm for maintaining parallel active lists for each scanline in order to speed computation of ray/cell intersections. This approach also applies to the rendering of unstructured grids where neighboring cells are not known, without requiring the construction of an adjacency graph. <p> A review of the literature and the initial studies discussed above have suggested the direction taken in this research. Key decisions include the approach to memory management, task generation, and the basic algorithm. A review of the literature shows that image-space decompositions for raycasting <ref> [Cha92, NL92, CM92, Luc92] </ref> have achieved better scalability and levels of performance than object-space decompositions [MPS92]. Implementations of object-space decompositions for projection or splatting algorithms have been shown to be limited in terms of their scalability by synchronization requirements [Cha91, Wil92c, 61 Elv92]. <p> Scalable algorithms designed for this type of execution environment will be portable while maintaining a high degree of efficiency. 5.1 System Overview The earlier approach described in section 4.3.2 operated on the cells of the volume, rather than the faces, and utilized a task decomposition based on scanlines <ref> [Cha92] </ref>. The approach to be described here is faster and exhibits better scalability. The algorithm proceeds in three distinct phases. These include processing changes to the grid, processing changes to the view, and rendering the image. Not all phases need to be executed for each new image.
Reference: [CLL + 88] <author> Harvey E. Cline, William E. Lorensen, Sigwalt Ludke, Carl R. Crawford, and Bruce C. Teeter. </author> <title> Two Algorithms for the Reconstruction of Surfaces from Tomograms. </title> <journal> Medical Physics, </journal> <volume> 15(3) </volume> <pages> 320-327, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: More recently, the marching cubes algorithm [LC87] generates an isosurface by examining the eight vertices of each voxel and determining any surface intersections. Intersections along voxel edges are approximated using linear interpolation and a triangle mesh for the isosurface is returned. The dividing cubes <ref> [CLL + 88] </ref> algorithm works along these same lines, but approximates the isosurface with points by doing recursive subdivision. All of these algorithms generate a geometric representation of a subset of the volumetric dataset.
Reference: [CM92] <author> Brian Corrie and Paul Mackerras. </author> <title> Parallel Volume Rendering and Data Coherence on the Fujitsu AP1000. </title> <type> Technical Report TR-CS-92-11, </type> <institution> Department of Computer Science, The Australian National University, </institution> <year> 1992. </year> <month> 127 </month>
Reference-contexts: On the other hand, using a cluster size of 16 processors (data replicated 8 times), rendering took 7.94 seconds for a speedup of 61 and an efficiency of 48%. Corrie and Mackerras <ref> [CM92] </ref> have implemented a parallel ray-casting algorithm for rectilinear volumes on a 128 processor Fujitsu AP1000. This machine is an experimental distributed-memory architecture with three independent communication networks. These include a broadcast network, a 2D torus network, and a synchronization network. <p> the pyramidal volume sampling a 256 3 dataset can be rendered to a 400 2 image in 47 seconds. 25 Machine Data Image Time in Number of Size Size Milliseconds Processors Stanford DASH [NL92] Raycasting 256x256x226 416 2 340 48 nCUBE 2 [MPS92] Raycasting 97x97x116 350x250 4750 128 Fujitsu AP1000 <ref> [CM92] </ref> Raycasting 256x256x109 512 2 54000 127 SGI 4D/380 VGX Scanline 256 3 400 2 47000 8 Pixel-Planes 5 [Neu92] 40 MIMD + Splatting 128x128x124 512 2 263 256K SIMD nCUBE 2 [Elv92] Splatting 256x256x90 200 2 173000 64 Table 2.3: Results reported on MIMD architectures for rectilinear datasets. <p> It also provides only message passing services, however recent work at the Australian National University has demonstrated an efficient application based upon a software implementation of shared virtual memory <ref> [CM92] </ref>. Four recently developed architectures which do support shared virtual memory are the Intel Paragon XP/S, Kendall Square Research KSR1, Cray T3D, and the Stanford Dash Multiprocessor. The Intel Paragon XP/S can be configured with up to 1K processing nodes, each containing two i860 processors. <p> A review of the literature and the initial studies discussed above have suggested the direction taken in this research. Key decisions include the approach to memory management, task generation, and the basic algorithm. A review of the literature shows that image-space decompositions for raycasting <ref> [Cha92, NL92, CM92, Luc92] </ref> have achieved better scalability and levels of performance than object-space decompositions [MPS92]. Implementations of object-space decompositions for projection or splatting algorithms have been shown to be limited in terms of their scalability by synchronization requirements [Cha91, Wil92c, 61 Elv92]. <p> This approach facilitates the use of an image-space task decomposition with dynamic task generation, as well as providing the ability to render from an existing application's data structures. Image-space tasks utilizing square image tiles have been shown to perform better than scanline decompositions due to increased cache coherence <ref> [CM92] </ref>. Rectangular image tiles form the rendering tasks, improving both cache coherence and the possibilities for taking advantage of spatial coherence to speed the rendering process. Task size is easily varied by changing the size of the image tiles.
Reference: [Cra92] <author> Cray Research, Inc. </author> <title> CRAY T3D Software Overview Technical Note, </title> <address> sn-2505 1.0 edition, </address> <year> 1992. </year>
Reference-contexts: The network consists of a two-level hierarchy of uni-directional rings. The ALLCACHE search engine moves data on reference to appropriate local caches and maintains cache coherence. Currently under development at Cray Research, Inc. is the T3D <ref> [Cra92] </ref>, a highly parallel machine which can utilize "hundreds or thousands" of DEC Alpha chips. The memory is physically distributed with the processors and connected via a 3D torus topology. All memory is globally addressable and nonuniform (latency) access.
Reference: [Cro90] <author> Franklin C. Crow. </author> <title> Parallel Computing for Graphics. </title> <type> Technical report, </type> <institution> Xerox Palo Alto Research Center, </institution> <year> 1990. </year>
Reference-contexts: The machine which produced the results was not identified, but an efficiency of 77% was reported for 16 processors. 2.3 Parallel Computer Graphics Related efforts in the parallelization of computer graphics algorithms are surveyed by Burke and Leler [BL90] and Crow <ref> [Cro90] </ref>. Several representative approaches are summarized here and will be described in more detail below. Fuchs proposed a technique for distributing the z-buffer hidden surface removal algorithm over a distributed-memory MIMD architecture [Fuc77].
Reference: [CS78] <author> H.N. Christianson and T. W. Sederburg. </author> <title> Conversion of Complex Contour Line Definitions into Polygonal Element Mosaics. </title> <booktitle> In Proceedings of SIGGRAPH '78, </booktitle> <pages> pages 187-192, </pages> <year> 1978. </year>
Reference-contexts: As early as the mid-1970s researchers were developing algorithms to generate three-dimensional geometric representations by connecting contour lines of adjacent two-dimensional contour maps <ref> [FKU77, CS78, GD82] </ref>. In 1979 an algorithm was presented that would generate a three-dimensional contour map by operating directly on the three-dimensional data [WH79]. More recently, the marching cubes algorithm [LC87] generates an isosurface by examining the eight vertices of each voxel and determining any surface intersections.
Reference: [CWBV83] <author> John G. Cleary, Brian Wyvill, Graham M. Birtwistle, and Reddy Vatti. </author> <title> Multiprocessor Ray Tracing. </title> <type> Technical Report 83/128/17, </type> <institution> University of Calgary, </institution> <year> 1983. </year>
Reference-contexts: Fuchs proposed a technique for distributing the z-buffer hidden surface removal algorithm over a distributed-memory MIMD architecture [Fuc77]. Cleary, et al. give an algorithm for raytracing which utilizes a world-space decomposition on a distributed-memory MIMD system <ref> [CWBV83] </ref>. The rays are represented as messages passed between the processors. Dippe and Swensen extend this approach to achieve better load balancing by using an adaptive world-space decomposition [DS84]. Parallelization of global illumination algorithms in a distributed workstation environment has been addressed by Tampieri and Greenberg [TG88]. <p> An interlaced memory scheme is used to achieve load balancing. Several of today's powerful computer graphics workstations utilize a scheme very similar to this to speed the rendering process [Ake93, DN93]. Cleary, et al. <ref> [CWBV83] </ref> give an algorithm for raytracing on a distributed-memory MIMD architecture. A theoretical analysis of expected speedup was done, with software simulation to verify results.
Reference: [DCH88] <author> Robert A. Drebin, Loren Carpenter, and Pat Hanrahan. </author> <title> Volume Rendering. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 65-74, </pages> <year> 1988. </year> <note> Proceedings of SIGGRAPH '88. </note>
Reference-contexts: Each image sample has an associated implicit location in &lt; 3 . How can such an entity be visualized so as to allow internal structure to be seen while preventing loss of information? This question has led researchers to a technique for rendering volumetric datasets called direct volume rendering <ref> [DCH88, UK88, Sab88, Lev88] </ref>. This approach is called "direct" to differentiate it from other methods, such as isosurface extraction or volume slicing, which utilize only a subset of the data for image creation. <p> Design of the reconstruction kernel may be complicated for more complex grids. 1.1.4 Shear Transformations Direct volume rendering using shear transformations is a hybrid approach, rather than being either an image-space or object-space algorithm <ref> [DCH88, SS91, VFR92, KMS + 92] </ref>. The algorithm implements the viewing transformation as a series of one-dimensional shear transformations and resampling of the dataset. The result gives a volume of data in memory that is view aligned. Compositing may then be accomplished simply by striding through the memory. <p> These methods require that the cells or nodes be sorted into a visibility ordering and projected either front-to-back or back-to-front. Methods using shear transformations first rotate the volume in memory so that it is view aligned. Compositing can then be done by simply striding through the volume <ref> [DCH88] </ref>. Approaches to direct volume rendering have also differed in the techniques used to map the scalar values to color and opacity. This section gives an overview of several of the different approaches that have been taken. <p> These are then used, along with gradients estimated using finite differences, in shading computations. Both image-space and object-space (raycasting and projection) methods are addressed. The algorithm developed at Pixar <ref> [DCH88] </ref> was based on experiences and requirements in the medical imaging field. It requires that each input value in the volume be translated into a set of material percentages. Materials are then given properties such as color, opacity, and density. <p> Upson and Keeler generate isosurfaces by using a step function in their opacity transfer function [UK88]. Drebin, Carpenter, and Hanrahan do surface extraction by computing a "surface normal volume" and a "surface strength volume" based on the percentages and densities of each material present in the volume <ref> [DCH88] </ref>. These derived volumes are then used in the shading calculations. 13 Related efforts in the modeling of natural phenomena and the synthesis of images containing such models are also applicable.
Reference: [DH92] <author> John Danskin and Pat Hanrahan. </author> <title> Fast Algorithms for Volume Ray Tracing. </title> <booktitle> In 1992 Workshop on Volume Visualization, </booktitle> <pages> pages 91-98. </pages> <publisher> ACM, </publisher> <year> 1992. </year>
Reference-contexts: To achieve its ultimate usefulness as an exploratory tool, volume rendering must run at interactive speeds. There have been numerous approaches to speeding up the volume rendering process using sequential algorithms <ref> [Wes89, Wes90, LH91, Lev90, WV91, DH92, VW93, Mal93, TL93] </ref>. Many of these algorithms trade image quality for speed, typically under user control. Hibbard and Santek make the case that interactivity is the most important feature in a system for the analysis of volumetric datasets [HS89]. <p> The number of samples taken per ray is reduced by choosing a volume higher up the pyramid for sampling. Danskin and Hanrahan <ref> [DH92] </ref> present and compare several approaches to speeding the raycasting process. Several raycasting algorithms are presented using volume pyramids and allowing the user to trade image quality for speed.
Reference: [DN93] <author> Michael F. Deering and Scott R. Nelson. Leo: </author> <title> A System for Cost Effective 3D Shaded Graphics. </title> <journal> Computer Graphics, </journal> <pages> pages 101-108, </pages> <year> 1993. </year> <note> Proceedings of SIGGRAPH '93. </note>
Reference-contexts: An interlaced memory scheme is used to achieve load balancing. Several of today's powerful computer graphics workstations utilize a scheme very similar to this to speed the rendering process <ref> [Ake93, DN93] </ref>. Cleary, et al. [CWBV83] give an algorithm for raytracing on a distributed-memory MIMD architecture. A theoretical analysis of expected speedup was done, with software simulation to verify results.
Reference: [DS84] <author> Mark Dippe and John Swensen. </author> <title> An Adaptive Subdivision Algorithm and Parallel Architecture for Realistic Image Synthesis. </title> <journal> Computer Graphics, </journal> <volume> 18(3) </volume> <pages> 149-158, </pages> <year> 1984. </year> <note> Proceedings of SIGGRAPH '84. </note>
Reference-contexts: Cleary, et al. give an algorithm for raytracing which utilizes a world-space decomposition on a distributed-memory MIMD system [CWBV83]. The rays are represented as messages passed between the processors. Dippe and Swensen extend this approach to achieve better load balancing by using an adaptive world-space decomposition <ref> [DS84] </ref>. Parallelization of global illumination algorithms in a distributed workstation environment has been addressed by Tampieri and Greenberg [TG88]. Parallelization of the raytracing algorithm on a distributed-memory MIMD architecture using an image-space decomposition is presented by Badouel [BP90]. <p> A world space decomposition is used, where traced rays are messages which are passed from processor to processor. The results indicate a less than linear speedup, with performance on a 2D lattice better than a 3D lattice. Dippe and Swensen <ref> [DS84] </ref> describe an adaptive algorithm for generating raytraced images in which object space is divided into subregions. Using a theoretical argument, the algorithm is shown to be faster than the standard raytracing algorithm (in which every ray is tested against every object).
Reference: [DT81] <author> Louis J. Doctor and John G. Torborg. </author> <title> Display Techniques for Octree-Encoded Objects. </title> <journal> IEEE Computer Graphics and Applications, </journal> <pages> pages 29-38, </pages> <month> July </month> <year> 1981. </year>
Reference-contexts: Efficient techniques for determining the intersection of an octree node (representing part of the volume) with a quadtree node (representing part of the image) are given. This approach has been extended by Doctor and Torborg <ref> [DT81] </ref> to allow semitransparency of the volumetric object. Jackel [Jac88] proposes the PARCUM II, an architecture that seems to be shared-memory MIMD, however the emulation system that has been built utilizes only one processor. It comes from a solid modeling perspective and uses only opaque voxels.
Reference: [EKM + 91] <author> John Ellis, Gershon Kedem, Richard Marisa, Jai Menon, and Herb Voelcker. </author> <title> Breaking Barriers in Solid Modeling. </title> <journal> Mechanical Engineering, </journal> <volume> 113(2) </volume> <pages> 28-34, </pages> <month> Febuary </month> <year> 1991. </year>
Reference-contexts: These architectures either do not handle semi-transparent voxels, or they do so at a performance penalty. The specialized architectures that have been proposed or developed for solid modeling applications include: the 3DP 4 [OUT85], Insight [Mea85], the PARCUM II [Jac88], and the RayCasting Engine <ref> [EKM + 91] </ref>. Architectures designed for medical imaging applications include: the Voxel Processor [GRB + 85], and the Cube [KB88]. All of the approaches described in this section utilize MIMD architectures having either shared or distributed memory. <p> Architectures designed for medical imaging applications include: the Voxel Processor [GRB + 85], and the Cube [KB88]. All of the approaches described in this section utilize MIMD architectures having either shared or distributed memory. Two use a pipelined approach <ref> [OUT85, EKM + 91] </ref> with different processors assigned to different tasks in the rendering pipeline. In these cases the connections between memory and processors are specific to the task being executed. Memory may also be specialized to speed the rendering process [Jac88, KB88] by allowing simultaneous reads and writes. <p> The system supports 512 3 bits or 256 3 7-bit values. Shading is done using gradients calculated from the z-buffer. The emulation system produces images in 40 to 110 seconds. Ellis, et al. <ref> [EKM + 91] </ref> give an overview of the RayCasting Engine, a special purpose parallel architecture for processing CSG models for rendering and other analysis.
Reference: [Elv92] <author> T. Todd Elvins. </author> <title> Volume Rendering on a Distributed Memory Parallel Computer. </title> <booktitle> In Visualization '92, </booktitle> <pages> pages 93-98. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1992. </year>
Reference-contexts: There are two approaches to the projection method for volume rendering: cell projection [UK88, MHC90, ST90, WV91, Wil92c, SH92, Luc92, VW93] and splatting <ref> [Wes89, Wes90, Neu92, Elv92, LH91] </ref>. Both of these methods begin by creating a visibility sort of the cells or nodes in order to ensure correct ordering of compositing operations. For rectilinear datasets a visibility sort is trivial, however, it is more complex for more general grids. <p> Uniprocessor speed of the algorithm, with scalability and speedup statistics, are not given. Load balancing is difficult and efficiency depends on the correct number of GPs versus Renderers, which in turn depends on the image contents (especially the number of transparent voxels). Elvins <ref> [Elv92] </ref> describes a parallel implementation of the splatting algorithm for rectilinear volumes on a 64 processor nCUBE 2. A master processor is responsible for reading in the dataset, dynamically allocating slices to processors for splatting, and collecting, ordering and compositing the contributions from each slice. <p> DASH [NL92] Raycasting 256x256x226 416 2 340 48 nCUBE 2 [MPS92] Raycasting 97x97x116 350x250 4750 128 Fujitsu AP1000 [CM92] Raycasting 256x256x109 512 2 54000 127 SGI 4D/380 VGX Scanline 256 3 400 2 47000 8 Pixel-Planes 5 [Neu92] 40 MIMD + Splatting 128x128x124 512 2 263 256K SIMD nCUBE 2 <ref> [Elv92] </ref> Splatting 256x256x90 200 2 173000 64 Table 2.3: Results reported on MIMD architectures for rectilinear datasets. All of the above research has been directed towards rendering of rectilinear datasets. Very recently researchers have been investigating parallel direct volume rendering algorithms for datasets that are nonrectilinear.
Reference: [FD82] <author> J.D. Foley and A. Van Dam. </author> <title> Fundamentals of Interactive Computer Graphics. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1982. </year>
Reference-contexts: This point location problem is trivial for regular rectilinear volumes, but much more complex for curvilinear volumes. Our approach is to reduce the number of intersection calculations required for each ray by utilizing the idea of a bucket sort and scanline algorithm from computer graphics <ref> [FD82, HB86] </ref>. For example, a y-bucket sort lists, for each scanline, the objects which begin on that scanline, and how many scanlines they are active. From this information a list of active objects (objects which may possibly be intersected) can be incrementally maintained from scanline to scanline. <p> the tile and image size, the minimum and maximum pixel extents of the tile are computed. 5.5.2 Tile Rendering Algorithm Within each tile, the approach taken to reduce the number of intersection calculations required at each pixel utilizes the idea of a bucket sort and scanline algorithm from computer graphics <ref> [FD82, HB86] </ref>. The algorithm presented here uses a y-bucket sort followed by an x-bucket sort to create a list of active cell faces for each ray.
Reference: [FGH87] <author> K. Fujii, S. Gavali, and T.L. Holst. </author> <title> Vortical Flow over a Delta Wing Computation. </title> <booktitle> In 5th International Conf. on Numerical Methods in Laminar and Turbulent Flow, </booktitle> <address> July 1987. Montreal, Quebec. </address>
Reference-contexts: The third view of the post dataset demonstrates rendering with a nonconvex grid containing a void (figure 6.5). The third dataset is the delta wing dataset, taken from a study of vorti-cal flow over a delta wing <ref> [FGH87] </ref>. It contains 91 fi 51 fi 51 grid nodes, or 236691 nodes defining 225000 cells (figures 6.6 and 6.7). The fourth dataset is the shuttle dataset [MS90], a multi-block grid consisting of 9 grids with a total of 941159 nodes defining 885898 cells.
Reference: [FK90] <author> Wm. Randolph Franklin and Mohan S. Kankanhalli. </author> <title> Parallel Object-Space Hidden Surface Removal. </title> <journal> Computer Graphics, </journal> <volume> 24(4) </volume> <pages> 87-94, </pages> <year> 1990. </year> <note> Proceedings of SIGGRAHP '90. </note>
Reference-contexts: A task adaptive scheduling strategy is utilized. It is an image-space decomposition where each processor begins with a square 28 subimage. Processors which finish early request more work from other processors. The speedup is very sensitive to the size of the local cache. Franklin and Kankanhalli <ref> [FK90] </ref> present a parallel object-space hidden surface removal algorithm which uses the uniform grid technique. In this approach a GxG grid is cast on the eye-space scene. The polygons are sorted into any cells they cover, and are discarded if they are completely invisible.
Reference: [FKU77] <author> H. Fuchs, Z. M. Kedem, and S. P. Uselton. </author> <title> Optimal Surface Reconstruction for Planar Contours. </title> <journal> Communications of the ACM, </journal> <volume> 20, </volume> <year> 1977. </year>
Reference-contexts: As early as the mid-1970s researchers were developing algorithms to generate three-dimensional geometric representations by connecting contour lines of adjacent two-dimensional contour maps <ref> [FKU77, CS78, GD82] </ref>. In 1979 an algorithm was presented that would generate a three-dimensional contour map by operating directly on the three-dimensional data [WH79]. More recently, the marching cubes algorithm [LC87] generates an isosurface by examining the eight vertices of each voxel and determining any surface intersections.
Reference: [Fle88] <author> C. A. J. Fletcher. </author> <title> Computational Techniques for Fluid Dynamics. </title> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: More general grids are commonly used by researchers to generate volumetric datasets. Nomenclature for volumetric grids is hardly standardized; a brief overview of grid types is given in [SK90] and more detailed information can be found in <ref> [Fle88, ZT89] </ref>. We will call a single data point that has been sampled or computed a node. Two neighboring nodes may be said to define an edge, and three or more define a face. <p> In this case, a regular, rectilinear, computational grid has been shaped, i.e. mapped by a smooth function from &lt; 3 to &lt; 3 to give a curved shape, resulting in cells with non-planar faces in physical 4 space <ref> [Fle88] </ref>. These array-organized grids are also called structured grids [SK90]. Very large simulation geometries are sometimes gridded using a multi-block approach [plo89]. In this situation several curvilinear grids are combined in one simulation in order to represent the solution space. <p> Grids may be curved to match the simulation geometry, as in the curvilinear grids commonly used in CFD. A curvilinear grid is defined by a rectilinear computational grid that has been shaped, resulting in cells with non-planar faces in physical space <ref> [Fle88] </ref>. These array-organized grids are also called structured grids [SK90].
Reference: [FPE + 89] <author> Henry Fuchs, John Poulton, John Eyles, Trey Greer, Jack Goldfeather, David Ellsworth, Steve Molnar, Greg Turk, Brice Tebbs, and Laura Israel. </author> <title> Pixel-Planes 5: A Heterogeneous Multiprocessor Graphics System Using Processor-Enhanced Memories. </title> <journal> Computer Graphics, </journal> <volume> 23(3) </volume> <pages> 79-88, </pages> <year> 1989. </year> <booktitle> Proceedings of SIGGRAPH '89. </booktitle> <pages> 128 </pages>
Reference-contexts: These approaches are examined in more detail below and the results are summarized in table 2.3. 23 Levoy has proposed a parallelization of the raycasting approach on the Pixel-Planes 5, a parallel architecture developed for computer graphics <ref> [FPE + 89, Lev89a] </ref>. Pixel-Planes 5 is a MIMD architecture utilizing a ring network. There are two types of processors: 32 MIMD graphics processors (GP), and 512x512 pixel processors (PP) grouped into 16 independently programmable renderers. The 512x512 frame buffer is connected to the ring.
Reference: [Fuc77] <author> Henry Fuchs. </author> <title> Distributing a Visible Surface Algorithm over Multiple Processors. </title> <booktitle> In Proceedings of ACM, </booktitle> <pages> pages 449-451, </pages> <month> October </month> <year> 1977. </year>
Reference-contexts: Several representative approaches are summarized here and will be described in more detail below. Fuchs proposed a technique for distributing the z-buffer hidden surface removal algorithm over a distributed-memory MIMD architecture <ref> [Fuc77] </ref>. Cleary, et al. give an algorithm for raytracing which utilizes a world-space decomposition on a distributed-memory MIMD system [CWBV83]. The rays are represented as messages passed between the processors. Dippe and Swensen extend this approach to achieve better load balancing by using an adaptive world-space decomposition [DS84]. <p> This algorithm depends on an implementation of shared virtual memory with local caching. Whitman explores several image-space decompositions and scheduling strategies on a shared-memory MIMD machine [Whi92]. A detailed analysis of the overhead incurred in the parallelization is presented. Fuchs <ref> [Fuc77] </ref> presents an algorithm for a MIMD architecture with distributed memory. Each processor is responsible for generating some portion of the screen image and part of its local memory will be used for the image and z-buffer.
Reference: [Gar90] <author> Michael P. Garrity. </author> <title> Raytracing Irregular Volume Data. </title> <journal> Computer Graphics, </journal> <volume> 24(5) </volume> <pages> 35-40, </pages> <month> November </month> <year> 1990. </year> <booktitle> Proceedings of the San Diego Workshop on Volume Visualization. </booktitle>
Reference-contexts: Raycasting of curvilinear or unstructured grids is especially time-consuming if no effort is made to reduce the ray/grid intersection testing requirements. One approach to doing this is to intersect external faces of the grid only, and then walk through the grid cell by cell <ref> [Gar90, Koy92] </ref>. Another approach is to sort the grid cells or faces in screen-space, and then test for ray intersection only with those cells or faces that are active at a given pixel [Cha92]. <p> The direct volume rendering approach utilizes a y-bucket sort of the cells to reduce the number of ray/cell intersection tests required. Garrity <ref> [Gar90] </ref> presents an algorithm for volume rendering nonrectilinear datasets which requires that the data be cell-organized in memory so that shared faces are known.
Reference: [GB91] <author> Brent C. Gorda and Eugene D. Brooks III. </author> <title> The MPCI Gang Scheduler. </title> <booktitle> In The 1991 MPCI Yearly Report: The Attack of the Killer Micros, </booktitle> <pages> pages 183-187. </pages> <institution> Lawrence Livermore National Laboratory, </institution> <month> March </month> <year> 1991. </year> <month> UCRL-ID-107022. </month>
Reference-contexts: Currently 18 processors are reserved for the public cluster and these support user logins, editing, compiling, and other such activities. The remaining 110 processors are designated the parallel gang and run under the control of a UNIX daemon called the Gang Scheduler <ref> [GB91] </ref> which provides space and time sharing of the parallel gang. It is in the parallel gang that parallel user jobs run. The Gang Scheduler provides several modes of operation for users in order to accommodate differing requirements.
Reference: [GD82] <author> S. Ganapathy and T. G. Dennehy. </author> <title> A New General Triangulation Method for Planar Contours. </title> <booktitle> In Proceedings of SIGGRAPH '82, </booktitle> <pages> pages 69-75, </pages> <year> 1982. </year>
Reference-contexts: As early as the mid-1970s researchers were developing algorithms to generate three-dimensional geometric representations by connecting contour lines of adjacent two-dimensional contour maps <ref> [FKU77, CS78, GD82] </ref>. In 1979 an algorithm was presented that would generate a three-dimensional contour map by operating directly on the three-dimensional data [WH79]. More recently, the marching cubes algorithm [LC87] generates an isosurface by examining the eight vertices of each voxel and determining any surface intersections.
Reference: [Gie92] <author> Christopher Giertsen. </author> <title> Volume Visualization of Sparse Irregular Meshes. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 12(2) </volume> <pages> 40-48, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Algorithms for rendering both rectilinear and nonrectilinear volumetric datasets are given. 14 Giertsen [GT92] has presented an algorithm for rendering embedded geometrical primitives in unstructured volumetric datasets. The algorithm is an extension of an earlier approach <ref> [Gie92] </ref> to volume rendering which uses a scan-plane buffer to store contributions from each volume cell to the pixels of a given scanline. Geometrical primitives are handled similarly with the use of a multi-layer z-buffer. All rendering proceeds in scanline order. <p> Scan-line methods, which seem to fall somewhere between raycasting and projection approaches, have recently been applied to the rendering of more complex volumetric datasets. 17 Giertsen <ref> [Gie92] </ref> gives an algorithm for rendering sparse unstructured grids which utilizes a scan-plane buffer to store contributions to each pixel from different cells in the grid. Cell intersections with the scan-plane are incrementally computed, discretized, and stored in the buffer.
Reference: [Gla89] <author> Andrew S. Glassner, </author> <title> editor. An Introduction to Ray Tracing. </title> <publisher> Academic Press Limited, </publisher> <year> 1989. </year>
Reference-contexts: Composite into the pixel. Elimination of Small Cells In either of the above algorithms it is possible to have cells which are small enough that their screen-space bounding boxes fall between scanlines or between pixels. This is a form of aliasing that can be reduced by stochastic sampling methods <ref> [Gla89] </ref>, or by volume pyramid approaches such as those described by [SG91]. In the absence of anti-aliasing, these cells can be trivially eliminated from the bucket sorts (and thus not considered for possible intersection with a ray).
Reference: [GO89] <author> David S. Goodsell and Arthur J. Olson. </author> <title> Molecular Applications of Volume Rendering and 3-D Texture Maps. </title> <booktitle> In Proceedings of the Chapel Hill Workshop on Volume Visualization. </booktitle> <institution> Department of Computer Science, University of North Carolina at Chapel Hill, </institution> <year> 1989. </year>
Reference-contexts: Raycasting is an image-space approach in which a ray from the eyepoint is cast through each pixel of the image, intersected with the volume, and sampled along its length <ref> [Lev88, Lev89b, UK88, 12 Sab88, GO89] </ref>. Cell projection and splatting are both object-space algorithms in which cells or nodes are projected to the screen [UK88, Wes89, Wes90, LH91, WV91, ST90, MHC90]. <p> If so, then the color and opacity of the surface are composited into the contribution collected thus far for the ray <ref> [GO89] </ref>. Upson and Keeler generate isosurfaces by using a step function in their opacity transfer function [UK88]. Drebin, Carpenter, and Hanrahan do surface extraction by computing a "surface normal volume" and a "surface strength volume" based on the percentages and densities of each material present in the volume [DCH88].
Reference: [GRB + 85] <author> Samuel M. Goldwasser, R. Anthony Reynolds, Ted Bapty, David Baraff, John Summers, David A. Talton, and Ed Walsh. </author> <title> Physician's Workstation with Real-Time Performance. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 5(12) </volume> <pages> 44-56, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: The specialized architectures that have been proposed or developed for solid modeling applications include: the 3DP 4 [OUT85], Insight [Mea85], the PARCUM II [Jac88], and the RayCasting Engine [EKM + 91]. Architectures designed for medical imaging applications include: the Voxel Processor <ref> [GRB + 85] </ref>, and the Cube [KB88]. All of the approaches described in this section utilize MIMD architectures having either shared or distributed memory. Two use a pipelined approach [OUT85, EKM + 91] with different processors assigned to different tasks in the rendering pipeline. <p> The communication network is programmed to match the tree structure of the CSG model. CCs pass data to the top and left neighbor only. Large models can be processed by making more than one pass. Goldwasser, et al. <ref> [GRB + 85] </ref> describe the Voxel Processor, a MIMD, bus-based, distributed-memory architecture with the goal of real-time (30 frames per second) generation and display of volumetric medical image data. A scaled-down prototype has been built, but no empirical results are given.
Reference: [GT92] <author> Christopher Giertsen and Allan Tuchman. </author> <title> Fast Volume Rendering with Embedded Geometric Primitives. </title> <editor> In T. L. Kunii, editor, </editor> <booktitle> Visual Computing Integrating Computer Graphics and Computer Vision, </booktitle> <pages> pages 253-271. </pages> <publisher> Springer Verlag, </publisher> <year> 1992. </year>
Reference-contexts: We have investigated how object-oriented design and implementation techniques can be used to accomplish an integrated rendering approach [Cha90]. The raycasting algorithm presented addresses the rendering of geometrically defined primitives embedded in a volumetric dataset. Algorithms for rendering both rectilinear and nonrectilinear volumetric datasets are given. 14 Giertsen <ref> [GT92] </ref> has presented an algorithm for rendering embedded geometrical primitives in unstructured volumetric datasets. The algorithm is an extension of an earlier approach [Gie92] to volume rendering which uses a scan-plane buffer to store contributions from each volume cell to the pixels of a given scanline.
Reference: [Gus88] <author> J. L. Gustafson. </author> <title> Reevaluating Amdahl's Law. </title> <journal> Communications of the ACM, </journal> <volume> 31(5) </volume> <pages> 532-533, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: In this case the algorithm is said to be scalable. Scaled speedup is an alternative to the traditional definition of speedup in which the problem size is increased as processors are added <ref> [Gus88] </ref>. It has been shown that it is possible to have speedup greater than n, although this is unusual in general [HM90]. The trend is typically shown by running a given algorithm several times for varying n and graphing the speedup as a function of n.
Reference: [HB85] <author> C. H. Hung and P. G. Buning. </author> <title> Simulation of Blunt-Fin Induced Shock Wave and Turbulent Boundary Layer Interaction. </title> <journal> Journal of Fluid Mechanics, </journal> <volume> 154 </volume> <pages> 163-185, </pages> <year> 1985. </year>
Reference-contexts: Results The parallel algorithms described above have been implemented on the BBN TC2000 and their performance has been measured and analyzed (see table 2.1 for a summary of measures). The algorithms have been benchmarked on the blunt fin data set from NASA Ames Research Center <ref> [HB85] </ref>. This dataset represents a CFD simulation of air flow past a blunt fin on a grid resolution of 40 fi 32 fi 32, or 37479 cells. Images have been created at resolutions of both 256 2 , and 512 2 . <p> Four curvilinear data sets obtained from NASA Ames Research Center were used in this study. The first is the blunt fin dataset <ref> [HB85] </ref>. This dataset represents a CFD simulation of air flow past a blunt fin on a grid resolution of 40 fi 32 fi 32, or 40960 nodes defining 37479 cells. Images of this dataset are presented in figures 6.1 and 6.2.
Reference: [HB86] <author> Donald Hearn and M. Pauline Baker. </author> <title> Computer Graphics. </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1986. </year>
Reference-contexts: This point location problem is trivial for regular rectilinear volumes, but much more complex for curvilinear volumes. Our approach is to reduce the number of intersection calculations required for each ray by utilizing the idea of a bucket sort and scanline algorithm from computer graphics <ref> [FD82, HB86] </ref>. For example, a y-bucket sort lists, for each scanline, the objects which begin on that scanline, and how many scanlines they are active. From this information a list of active objects (objects which may possibly be intersected) can be incrementally maintained from scanline to scanline. <p> the tile and image size, the minimum and maximum pixel extents of the tile are computed. 5.5.2 Tile Rendering Algorithm Within each tile, the approach taken to reduce the number of intersection calculations required at each pixel utilizes the idea of a bucket sort and scanline algorithm from computer graphics <ref> [FD82, HB86] </ref>. The algorithm presented here uses a y-bucket sort followed by an x-bucket sort to create a list of active cell faces for each ray.
Reference: [Hen92] <author> Henry Burkhardt III. </author> <title> Announcing the KSR1 Supercomputer. </title> <note> Article 2946 of comp.parallel, Febuary 1992. </note>
Reference-contexts: The nodes are connected in a 2D mesh topology. At each node, one of the processors is dedicated to application processing and the other to message processing, freeing the application processor from all details of communication services. Operating system support for shared virtual memory is provided. The KSR1 <ref> [Hen92] </ref> developed by Kendall Square Research supports 8 to 1088 RISC-style superscalar 64-bit processors. Their innovative ALLCACHE memory system distributes the memory physically as local caches associated with processors. The network consists of a two-level hierarchy of uni-directional rings.
Reference: [HM90] <author> Dave Helmbold and Charlie McDowell. </author> <title> Modeling Speedup(n) greater than n. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(2) </volume> <pages> 250-256, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Scaled speedup is an alternative to the traditional definition of speedup in which the problem size is increased as processors are added [Gus88]. It has been shown that it is possible to have speedup greater than n, although this is unusual in general <ref> [HM90] </ref>. The trend is typically shown by running a given algorithm several times for varying n and graphing the speedup as a function of n.
Reference: [Hor93] <author> R. Michael Hord. </author> <title> Parallel Supercomputing in MIMD Architectures. </title> <publisher> CRC Press, Inc., </publisher> <year> 1993. </year>
Reference-contexts: An excellent description of many of these parallel architectures, along with a discussion of language and operating system issues, is given by Almasi & Gottlieb [AG89]. Several of the newest highly parallel MIMD architectures are described in <ref> [Hor93] </ref>. 2.2.2 Measurement Techniques In order to assess the efficiency and scalability of various parallel implementations, measurements of performance characteristics are made. Common measures used to analyze 18 n Number of processors. T 1 Serial execution time. T n Execution time on n processors. <p> A survey of more recent highly parallel MIMD architectures is given by Hord <ref> [Hor93] </ref>. Several of the more well-known or interesting architectures are briefly covered here. All of these architectures utilize physically distributed memory. Four recent architectures which do not provide support for shared virtual memory are the Intel iPSC/2, nCUBE, Thinking Machines CM-5, and Fujitsu AP1000.
Reference: [HS89] <author> William Hibbard and David Santek. </author> <title> Interactivity is the Key. </title> <booktitle> In Proceedings of the Chapel Hill Workshop on Volume Visualization. </booktitle> <institution> Department of Computer Science, University of North Carolina at Chapel Hill, </institution> <year> 1989. </year> <month> 129 </month>
Reference-contexts: Many of these algorithms trade image quality for speed, typically under user control. Hibbard and Santek make the case that interactivity is the most important feature in a system for the analysis of volumetric datasets <ref> [HS89] </ref>. They have presented work towards a fast approximating algorithm for rendering volumetric scalar data on a rectilinear grid as a transparent fog. They select the grid planes most perpendicular to the view direction, and render each, in visibility order, as a set of transparent rectangular polygons.
Reference: [Jac88] <author> D. Jackel. </author> <title> Reconstructing Solids from Tomographic Scans The PARCUM II System. </title> <booktitle> In Advances in Computer Graphics Hardware II, </booktitle> <pages> pages 101-109. </pages> <publisher> Springer International, </publisher> <year> 1988. </year>
Reference-contexts: These architectures either do not handle semi-transparent voxels, or they do so at a performance penalty. The specialized architectures that have been proposed or developed for solid modeling applications include: the 3DP 4 [OUT85], Insight [Mea85], the PARCUM II <ref> [Jac88] </ref>, and the RayCasting Engine [EKM + 91]. Architectures designed for medical imaging applications include: the Voxel Processor [GRB + 85], and the Cube [KB88]. All of the approaches described in this section utilize MIMD architectures having either shared or distributed memory. <p> Two use a pipelined approach [OUT85, EKM + 91] with different processors assigned to different tasks in the rendering pipeline. In these cases the connections between memory and processors are specific to the task being executed. Memory may also be specialized to speed the rendering process <ref> [Jac88, KB88] </ref> by allowing simultaneous reads and writes. For the 3DP 4 [OUT85], the goal is a fast solid-model rendering system for interactive use. Solid models are represented by PEARYs, picture element arrays; these are simply rectilinear volumes of voxels which are either opaque or transparent. <p> Efficient techniques for determining the intersection of an octree node (representing part of the volume) with a quadtree node (representing part of the image) are given. This approach has been extended by Doctor and Torborg [DT81] to allow semitransparency of the volumetric object. Jackel <ref> [Jac88] </ref> proposes the PARCUM II, an architecture that seems to be shared-memory MIMD, however the emulation system that has been built utilizes only one processor. It comes from a solid modeling perspective and uses only opaque voxels.
Reference: [JM89] <author> E. Ruth Johnson and Charles E. </author> <title> Mosher. Integration of Volume Rendering and Geometric Graphics. </title> <booktitle> In Proceedings of the Chapel Hill Workshop on Volume Visualization. </booktitle> <institution> Department of Computer Science, University of North Carolina at Chapel Hill, </institution> <year> 1989. </year>
Reference-contexts: Johnson and Mosher address this problem by adding new volumetric primitives to a traditional rendering system <ref> [JM89] </ref>. Volume point, vector, ray, and polygon primitives are incorporated into a typical 3D graphics environment. Each of these new primitives has an associated mapping function which maps the volumetric data to a geometric primitive.
Reference: [KB88] <author> Arie Kaufman and Reuven Bakalash. </author> <title> Memory and Processor Architecture for 3D Voxel-Based Imagery. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 8(11) </volume> <pages> 10-23, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: The specialized architectures that have been proposed or developed for solid modeling applications include: the 3DP 4 [OUT85], Insight [Mea85], the PARCUM II [Jac88], and the RayCasting Engine [EKM + 91]. Architectures designed for medical imaging applications include: the Voxel Processor [GRB + 85], and the Cube <ref> [KB88] </ref>. All of the approaches described in this section utilize MIMD architectures having either shared or distributed memory. Two use a pipelined approach [OUT85, EKM + 91] with different processors assigned to different tasks in the rendering pipeline. <p> Two use a pipelined approach [OUT85, EKM + 91] with different processors assigned to different tasks in the rendering pipeline. In these cases the connections between memory and processors are specific to the task being executed. Memory may also be specialized to speed the rendering process <ref> [Jac88, KB88] </ref> by allowing simultaneous reads and writes. For the 3DP 4 [OUT85], the goal is a fast solid-model rendering system for interactive use. Solid models are represented by PEARYs, picture element arrays; these are simply rectilinear volumes of voxels which are either opaque or transparent. <p> Intensity and depth information is maintained at each pixel. When all processors have completed rendering, the individual images are merged (using depth information) into the output frame buffer. Kaufman and Bakalash <ref> [KB88] </ref> describe the Cube, a shared-memory multiprocessor architecture with two unique features: a skewed memory organization that allows simultaneous access of a full beam (row) of voxels, and a multiple-write bus that allows the nearest opaque voxel to be selected in O (log n) time.
Reference: [KBCY90] <author> Arie Kaufman, Reuven Bakalash, Daniel Cohen, and Roni Yagel. </author> <title> A Survey of Architectures for Volume Rendering. </title> <journal> IEEE Engineering in Medicine and Biology Magazine, </journal> <volume> 9(4) </volume> <pages> 18-23, </pages> <year> 1990. </year>
Reference-contexts: Specialized architectures have been developed to speed rendering in those applications. A survey of some of these systems has been done by Kaufman <ref> [KBCY90] </ref>. Many of these systems were initially designed for rendering solid models and were later applied to medical imaging.
Reference: [KH84] <author> James T. Kajiya and B.P. Von Herzen. </author> <title> Ray Tracing Volume Densities. </title> <journal> Computer Graphics, </journal> <volume> 18(3) </volume> <pages> 165-174, </pages> <year> 1984. </year> <note> Proceeding of SIGGRAPH '84. </note>
Reference-contexts: These representations are combined to give a "shaded color volume" which may then be rotated and resampled using shear transformations, and then projected using a simple compositing scheme. Sabella modifies Kajiya's <ref> [KH84] </ref> raytracing algorithm for computational efficiency by eliminating shadowing in order to render a scalar field as a varying density emitter [Sab88]. <p> Blinn utilized a volume of density values to model clouds and presented a technique for rendering them [Bli82a]. Nelson Max extended his work in various ways [Max86] and Kajiya addressed methods for raytracing such models <ref> [KH84] </ref>.
Reference: [KMS + 92] <author> Jim Kaba, Jim Matey, Gordon Stoll, Herb Taylor, and Pat Hanrahan. </author> <title> Interactive Terrain Rendering and Volume Visualization on the Princeton Engine. </title> <booktitle> In Visualization '92, </booktitle> <pages> pages 349-355. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1992. </year>
Reference-contexts: Design of the reconstruction kernel may be complicated for more complex grids. 1.1.4 Shear Transformations Direct volume rendering using shear transformations is a hybrid approach, rather than being either an image-space or object-space algorithm <ref> [DCH88, SS91, VFR92, KMS + 92] </ref>. The algorithm implements the viewing transformation as a series of one-dimensional shear transformations and resampling of the dataset. The result gives a volume of data in memory that is view aligned. Compositing may then be accomplished simply by striding through the memory. <p> performance statistics for rendering a 128 3 rectilinear dataset to a 128 2 image at 456ms using 16K processors. 22 Machine Data Image Time in Number of Size Size Milliseconds Processors CM-2 MasPar MP-1 [VFR92] 128 3 128 2 456 16K [SS92] 128 3 512 2 923 16K Princeton Engine <ref> [KMS + 92] </ref> 256 3 512 2 500 256 Table 2.2: Results reported on SIMD architectures for rectilinear datasets. More recently Schroder has presented another algorithm which does not rely on shear transforms, but rather steps the rays through the volume [SS92]. <p> All rays are processed in parallel and move in lockstep along a major axis. This algorithm has been implemented on the CM-2 and the Princeton Engine. On the CM-2 a 128 3 dataset can be rendered to a 512 2 image in 923ms using 16K processors. Kaba et al. <ref> [KMS + 92] </ref> discuss techniques for volume rendering on the Princeton Engine Video Supercomputer. In their approach each yz slice is stored on a different processor. Rotation about the x axis can be simply performed using shear transformations on each processor (or direct application of the rotation transformation).
Reference: [Koy92] <author> Koji Koyamada. </author> <title> Fast Traversal of Irregular Volumes. </title> <editor> In T. L. Kunii, editor, </editor> <booktitle> Visual Computing Integrating Computer Graphics and Computer Vision, </booktitle> <pages> pages 295-312. </pages> <publisher> Springer Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Raycasting of curvilinear or unstructured grids is especially time-consuming if no effort is made to reduce the ray/grid intersection testing requirements. One approach to doing this is to intersect external faces of the grid only, and then walk through the grid cell by cell <ref> [Gar90, Koy92] </ref>. Another approach is to sort the grid cells or faces in screen-space, and then test for ray intersection only with those cells or faces that are active at a given pixel [Cha92]. <p> A ray intersection with an exterior face is found, the face through which the ray exits that cell is determined, and the process continues stepping through the volume cell to cell. Koyamada <ref> [Koy92] </ref> presents a raycasting approach for rendering of nonrectilinear volumes which also uses a fast cell traversal. His approach is based on tetrahedra and also involves finding ray intersections with front-facing exterior faces and stepping through the volume from cell to cell.
Reference: [LC87] <author> William E. Lorensen and Harvey E. Cline. </author> <title> Marching Cubes: A High Resolution 3D Surface Construction Algorithm. </title> <journal> Computer Graphics, </journal> <volume> 21(4) </volume> <pages> 163-169, </pages> <year> 1987. </year> <note> Proceedings of SIGGRAPH '87. </note>
Reference-contexts: In 1979 an algorithm was presented that would generate a three-dimensional contour map by operating directly on the three-dimensional data [WH79]. More recently, the marching cubes algorithm <ref> [LC87] </ref> generates an isosurface by examining the eight vertices of each voxel and determining any surface intersections. Intersections along voxel edges are approximated using linear interpolation and a triangle mesh for the isosurface is returned.
Reference: [Lev88] <author> Marc Levoy. </author> <title> Display of Surfaces from Volume Data. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 8(3) </volume> <pages> 29-37, </pages> <year> 1988. </year>
Reference-contexts: Each image sample has an associated implicit location in &lt; 3 . How can such an entity be visualized so as to allow internal structure to be seen while preventing loss of information? This question has led researchers to a technique for rendering volumetric datasets called direct volume rendering <ref> [DCH88, UK88, Sab88, Lev88] </ref>. This approach is called "direct" to differentiate it from other methods, such as isosurface extraction or volume slicing, which utilize only a subset of the data for image creation. <p> Raycasting is an image-space approach in which a ray from the eyepoint is cast through each pixel of the image, intersected with the volume, and sampled along its length <ref> [Lev88, Lev89b, UK88, 12 Sab88, GO89] </ref>. Cell projection and splatting are both object-space algorithms in which cells or nodes are projected to the screen [UK88, Wes89, Wes90, LH91, WV91, ST90, MHC90]. <p> The image is generated using the maximum value for the hue, attenuated intensity for the value, and either distance or center of gravity for saturation. The approach taken by Marc Levoy <ref> [Lev88] </ref> is to use the dataset values to generate both a color volume and an opacity volume. A raycasting algorithm is then applied to acquire a vector of colors and opacities corresponding to the path of a ray from the view point, through a screen pixel, through the volume. <p> Levoy creates an opacity for each volume element as a function of the gradient field of the dataset. This technique is used to produce both isovalue contour surfaces and region boundary surfaces <ref> [Lev88, Lev89b] </ref>. Goodsell and Olson have implemented a raycasting volume renderer which produces isosurfaces by comparing each sample along a ray with the previous sample, checking whether an isosurface has been crossed.
Reference: [Lev89a] <author> Marc Levoy. </author> <title> Design for a Real-Time High-Quality Volume Rendering Workstation. </title> <booktitle> In Proceedings of the Chapel Hill Workshop on Volume Visualization, </booktitle> <pages> pages 85-92. </pages> <institution> Department of Computer Science, University of North Carolina at Chapel Hill, </institution> <year> 1989. </year>
Reference-contexts: These approaches are examined in more detail below and the results are summarized in table 2.3. 23 Levoy has proposed a parallelization of the raycasting approach on the Pixel-Planes 5, a parallel architecture developed for computer graphics <ref> [FPE + 89, Lev89a] </ref>. Pixel-Planes 5 is a MIMD architecture utilizing a ring network. There are two types of processors: 32 MIMD graphics processors (GP), and 512x512 pixel processors (PP) grouped into 16 independently programmable renderers. The 512x512 frame buffer is connected to the ring.
Reference: [Lev89b] <author> Marc Levoy. </author> <title> Display of Surfaces From Volume Data. </title> <type> PhD thesis, </type> <institution> The University of North Carolina at Chapel Hill, </institution> <year> 1989. </year>
Reference-contexts: Raycasting is an image-space approach in which a ray from the eyepoint is cast through each pixel of the image, intersected with the volume, and sampled along its length <ref> [Lev88, Lev89b, UK88, 12 Sab88, GO89] </ref>. Cell projection and splatting are both object-space algorithms in which cells or nodes are projected to the screen [UK88, Wes89, Wes90, LH91, WV91, ST90, MHC90]. <p> Levoy creates an opacity for each volume element as a function of the gradient field of the dataset. This technique is used to produce both isovalue contour surfaces and region boundary surfaces <ref> [Lev88, Lev89b] </ref>. Goodsell and Olson have implemented a raycasting volume renderer which produces isosurfaces by comparing each sample along a ray with the previous sample, checking whether an isosurface has been crossed. <p> Many simulations are done with respect to some fixed geometry (such as fluid flow about an aircraft in CFD); it enhances image understanding to be able to render the geometrically defined object embedded in the flow field it generates. Marc Levoy discusses two approaches in his Ph.D. dissertation <ref> [Lev89b] </ref>. The first is a hybrid raytracing approach in which rays are cast simultaneously into the volumetric and geometric objects. Samples are taken from the volumetric object at equal intervals along the ray. Each polygon making up the geometric object is tested for intersection with the ray. <p> Another technique reduces the number of rays cast by using an adaptive approach to determining where the greatest number of rays are required <ref> [Lev89b] </ref>. The image is subdivided into square sample regions and rays are cast at the four corners of each region. Color differences are used to determine whether each region needs to be recursively subdivided and additional rays cast. Progressive refinement and image interpolation are used to generate the complete image.
Reference: [Lev90] <author> Marc Levoy. </author> <title> Efficient Ray Tracing of Volume Data. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 9(3) </volume> <pages> 245-261, </pages> <year> 1990. </year>
Reference-contexts: To achieve its ultimate usefulness as an exploratory tool, volume rendering must run at interactive speeds. There have been numerous approaches to speeding up the volume rendering process using sequential algorithms <ref> [Wes89, Wes90, LH91, Lev90, WV91, DH92, VW93, Mal93, TL93] </ref>. Many of these algorithms trade image quality for speed, typically under user control. Hibbard and Santek make the case that interactivity is the most important feature in a system for the analysis of volumetric datasets [HS89]. <p> Levoy proposes techniques for increasing the computational efficiency in the raycasting approach to volume rendering. Two of these techniques reduce the cost of tracing each ray: using a hierarchical enumeration of the volumetric dataset, and adaptively terminating the ray processing based on the accumulated opacity of the pixel <ref> [Lev90] </ref>. Another technique reduces the number of rays cast by using an adaptive approach to determining where the greatest number of rays are required [Lev89b]. The image is subdivided into square sample regions and rays are cast at the four corners of each region.
Reference: [LH91] <author> David Laur and Pat Hanrahan. </author> <title> Hierarchical Splatting: A Progressive Refinement Algorithm for Volume Rendering. </title> <journal> Computer Graphics, </journal> <volume> 25(4) </volume> <pages> 285-288, </pages> <year> 1991. </year> <note> Proceedings of SIGGRAPH '91. </note>
Reference-contexts: There are two approaches to the projection method for volume rendering: cell projection [UK88, MHC90, ST90, WV91, Wil92c, SH92, Luc92, VW93] and splatting <ref> [Wes89, Wes90, Neu92, Elv92, LH91] </ref>. Both of these methods begin by creating a visibility sort of the cells or nodes in order to ensure correct ordering of compositing operations. For rectilinear datasets a visibility sort is trivial, however, it is more complex for more general grids. <p> Cell projection and splatting are both object-space algorithms in which cells or nodes are projected to the screen <ref> [UK88, Wes89, Wes90, LH91, WV91, ST90, MHC90] </ref>. These methods require that the cells or nodes be sorted into a visibility ordering and projected either front-to-back or back-to-front. Methods using shear transformations first rotate the volume in memory so that it is view aligned. <p> To achieve its ultimate usefulness as an exploratory tool, volume rendering must run at interactive speeds. There have been numerous approaches to speeding up the volume rendering process using sequential algorithms <ref> [Wes89, Wes90, LH91, Lev90, WV91, DH92, VW93, Mal93, TL93] </ref>. Many of these algorithms trade image quality for speed, typically under user control. Hibbard and Santek make the case that interactivity is the most important feature in a system for the analysis of volumetric datasets [HS89]. <p> Lee Westover has published work in which the goal of interactive rendering is pursued through the use of a splatting algorithm, along with successive refinement of images and table-driven mappings for shading and filtering [Wes89, Wes90]. This approach has been extended by Laur & Hanrahan <ref> [LH91] </ref> to use a pyramidal representation and hierarchical enumeration of the data with progressive refinement to achieve interactivity, but with some degradation in image quality. Cell projection approaches allow more accuracy in the determination of contributions to the image. <p> Shirley and Tuchman [ST90] present an algorithm for efficiently projecting tetrahedral cells in which each cell is represented with hardware renderable semi-transparent triangles. Laur & Han-rahan <ref> [LH91] </ref> combine a pyramidal representation with hierarchical enumeration of the data 15 and the ability to rapidly generate hardware-renderable primitives to represent the projection of different-sized cells. The hardware-renderable primitives are scaled depending on the level of resolution requested by the user. Progressive refinement is utilized to obtain interactive rates.
Reference: [LLG + 92] <author> Daniel Lenoski, James Laudon, Kourosh Gharachorloo, Wolf-Dietrich Weber, Anoop Gupta, John Hennessy, Mark Horowitz, and Monica Lam. </author> <title> The Stanford Dash Multiprocessor. </title> <booktitle> Computer, </booktitle> <pages> pages 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: The memory is physically distributed with the processors and connected via a 3D torus topology. All memory is globally addressable and nonuniform (latency) access. The Stanford Dash Multiprocessor <ref> [LLG + 92] </ref> demonstrates the feasibility of building scalable parallel architectures with a single address space and coherent caches. A prototype based on 4 Silicon Graphics 4D/340 workstations has been developed. Each 4D/340 is considered a base cluster and contains 4 processors.
Reference: [Luc92] <author> Bruce Lucas. </author> <title> A Scientific Visualization Renderer. </title> <booktitle> In Visualization '92, </booktitle> <pages> pages 227-233. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1992. </year> <month> 130 </month>
Reference-contexts: There are two approaches to the projection method for volume rendering: cell projection <ref> [UK88, MHC90, ST90, WV91, Wil92c, SH92, Luc92, VW93] </ref> and splatting [Wes89, Wes90, Neu92, Elv92, LH91]. Both of these methods begin by creating a visibility sort of the cells or nodes in order to ensure correct ordering of compositing operations. <p> Williams [Wil92a, Wil92b, Wil92c] gives algorithms for visibility ordering and rendering of nonrectilinear volumes. The algorithm of Shirley and Tuchman [ST90] for projecting tetrahedral cells is modified using several different approximations which trade image quality for speed and the results are compared. Lucas <ref> [Luc92] </ref> renders irregular grids by visibility ordering the faces of each cell and then scan converting them in order, using a z-buffer to record information which allows the depth through each cell to be used in the compositing operation. <p> In addition, much of the speed of the sequential algorithm is obtained through the use of hardware-renderable primitives. It is not clear how the algorithm would perform on a highly parallel system that does not have hardware support for rendering. Lucas <ref> [Luc92] </ref> briefly describes a parallel direct volume rendering algorithm for irregular grids. The grid is partitioned on input into non-overlapping spatially connected regions. Nodes shared by more than one partition are replicated in each partition. <p> A review of the literature and the initial studies discussed above have suggested the direction taken in this research. Key decisions include the approach to memory management, task generation, and the basic algorithm. A review of the literature shows that image-space decompositions for raycasting <ref> [Cha92, NL92, CM92, Luc92] </ref> have achieved better scalability and levels of performance than object-space decompositions [MPS92]. Implementations of object-space decompositions for projection or splatting algorithms have been shown to be limited in terms of their scalability by synchronization requirements [Cha91, Wil92c, 61 Elv92].
Reference: [LW90] <author> Marc Levoy and Ross Whitaker. </author> <title> Gaze-Directed Volume Rendering. </title> <journal> Computer Graphics, </journal> <volume> 24(2) </volume> <pages> 217-223, </pages> <year> 1990. </year> <booktitle> Proceedings of 1990 Symposium on Interactive 3D Graphics. </booktitle>
Reference-contexts: Color differences are used to determine whether each region needs to be recursively subdivided and additional rays cast. Progressive refinement and image interpolation are used to generate the complete image. Levoy and Whitaker <ref> [LW90] </ref> present a raycasting algorithm in which both the number of rays and the number of samples per ray are reduced in proportion to the distance of the ray from the focus of the user's gaze.
Reference: [Mal93] <author> Tom Malzbender. </author> <title> Fourier Volume Rendering. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 12(3) </volume> <pages> 233-250, </pages> <year> 1993. </year>
Reference-contexts: To achieve its ultimate usefulness as an exploratory tool, volume rendering must run at interactive speeds. There have been numerous approaches to speeding up the volume rendering process using sequential algorithms <ref> [Wes89, Wes90, LH91, Lev90, WV91, DH92, VW93, Mal93, TL93] </ref>. Many of these algorithms trade image quality for speed, typically under user control. Hibbard and Santek make the case that interactivity is the most important feature in a system for the analysis of volumetric datasets [HS89]. <p> Their approach to pyramidal volume traversal makes the time to render an image dependent on the image resolution and independent of volume resolution. Very recently, researchers have presented methods for doing direct volume rendering in the frequency domain, rather than in the spatial domain <ref> [Mal93, TL93] </ref>. This approach is attractive because it reduces the complexity of the rendering process from O (n 3 ) to O (n 2 log n) by making use of the equivalence of the integral of a 1D signal and its spectrum. <p> The Fourier projection slice theorem applies this in higher dimensions and is the basis of Fourier volume rendering <ref> [Mal93] </ref>. The primary drawback of Fourier volume rendering is that occlusion is not supported, thus the resulting images are similar to x-rays.
Reference: [Max86] <author> Nelson Max. </author> <title> Light Diffusion Through Clouds and Haze. Computer Vision Graphics, </title> <booktitle> and Image Processing, </booktitle> <volume> 33 </volume> <pages> 280-292, </pages> <year> 1986. </year>
Reference-contexts: In particular, the attempts at rendering such things as clouds, fog, dust, and particle systems can be considered specific applications of volumetric rendering. Blinn utilized a volume of density values to model clouds and presented a technique for rendering them [Bli82a]. Nelson Max extended his work in various ways <ref> [Max86] </ref> and Kajiya addressed methods for raytracing such models [KH84].
Reference: [Mea82] <author> D. Meagher. </author> <title> Efficient Synthetic Image Generation of Arbitrary 3-D Objects. </title> <booktitle> In Proceedings of the IEEE Computer Society Conference on Pattern Recognition and Image Processing, </booktitle> <month> June </month> <year> 1982. </year>
Reference-contexts: Two case studies are presented. Detailed information about the architecture is not given, but the algorithm is based on rendering an octree representation of a volumetric object to an image that is represented as a quadtree <ref> [Mea82] </ref>. The octree encoding of the volume provides a straightforward method for back-to-front or front-to-back traversal of the volume for hidden surface removal. Efficient techniques for determining the intersection of an octree node (representing part of the volume) with a quadtree node (representing part of the image) are given.
Reference: [Mea85] <author> Dr. Donald J. Meagher. </author> <title> Applying Solids Processing Methods to Medical Planning. </title> <booktitle> In Proceedings of NCGA, </booktitle> <pages> pages 101-109. </pages> <institution> National Computer Graphics Association, </institution> <month> April </month> <year> 1985. </year>
Reference-contexts: These architectures either do not handle semi-transparent voxels, or they do so at a performance penalty. The specialized architectures that have been proposed or developed for solid modeling applications include: the 3DP 4 [OUT85], Insight <ref> [Mea85] </ref>, the PARCUM II [Jac88], and the RayCasting Engine [EKM + 91]. Architectures designed for medical imaging applications include: the Voxel Processor [GRB + 85], and the Cube [KB88]. All of the approaches described in this section utilize MIMD architectures having either shared or distributed memory. <p> The two stage shading processor is next, it first computes the gradient from the z-buffer and then shades the final image. A software implementation of the algorithm has been done, and theoretical timing analysis indicates a throughput of 10 512x512 images per second. Meagher <ref> [Mea85] </ref> gives an overview of some of the features of Insight, a commercially available medical analysis and planning workstation. Two case studies are presented.
Reference: [MHC90] <author> Nelson Max, Pat Hanrahan, and Roger Crawfis. </author> <title> Area and Volume Coherence for Efficient Visualization of 3D Scalar Functions. </title> <journal> Computer Graphics, </journal> <volume> 24(5), </volume> <booktitle> 1990. Proceedings of the San Diego Workshop on Volume Visualization. </booktitle>
Reference-contexts: There are two approaches to the projection method for volume rendering: cell projection <ref> [UK88, MHC90, ST90, WV91, Wil92c, SH92, Luc92, VW93] </ref> and splatting [Wes89, Wes90, Neu92, Elv92, LH91]. Both of these methods begin by creating a visibility sort of the cells or nodes in order to ensure correct ordering of compositing operations. <p> Cell projection and splatting are both object-space algorithms in which cells or nodes are projected to the screen <ref> [UK88, Wes89, Wes90, LH91, WV91, ST90, MHC90] </ref>. These methods require that the cells or nodes be sorted into a visibility ordering and projected either front-to-back or back-to-front. Methods using shear transformations first rotate the volume in memory so that it is view aligned. <p> Cell projection approaches allow more accuracy in the determination of contributions to the image. In this case whole cells are projected rather than regions approximated from single nodes as in splatting. Spatial coherence can be utilized to create efficient projection algorithms. Max, Hanrahan, & Crawfis <ref> [MHC90] </ref> give an algorithm for the projection of any collection of sortable convex polyhedra in which analytic integration is used. Their algorithm is applicable to irregular and scattered data sets. <p> Many of the projection approaches for rectilinear grids can be extended to handle more general grids. The visibility ordering requirements remain the same. Max, Hanrahan, & Crawfis <ref> [MHC90] </ref> give an algorithm for the projection of any collection of sortable convex polyhedra. Shirley and Tuchman [ST90] present an algorithm for efficiently projecting tetrahedral cells in which each cell is represented with hardware renderable semi-transparent triangles. <p> In order to experiment with various parallel volume rendering algorithms, an object-oriented volume renderer [Cha90] was ported to the BBN TC2000. This volume renderer initially used the raycasting algorithm as the method for rendering an image. The code was extended to provide the projection approach as another rendering method <ref> [MHC90] </ref>. The serial version of this volume renderer has provided a starting point for several experiments in parallel direct volume rendering. 4.3.1 Comparison of Decompositions for Rectilinear Grids Some initial investigations into parallelization techniques for volume rendering are presented in [Cha91]. <p> The step size used for the sampling interval is such that every cell is sampled at least once. Code for the projection algorithm was provided by Nelson Max <ref> [MHC90] </ref> and performs scan conversion of the front and back faces of each cell, and provides an analytic method of integrating color and opacity which is equivalent to the limit of compositing more and more closely spaced samples. <p> Each task executes the following operations: * Lock the ready list and attempt to remove a cell for processing. If one is not available, release the ready list, wait for a short period of time, and retry. * Render the cell that was obtained from the ready list <ref> [MHC90] </ref>. * Update the visibility graph using an atomic decrement. If this updating process identifies cells that are ready to be added to the ready list, then that list will need to be locked since additions to the list must also be atomic.
Reference: [MPS92] <author> C. Montani, R. Perego, and R. Scopigno. </author> <title> Parallel Volume Visualization on a Hypercube Architecture. </title> <booktitle> In 1992 Workshop on Volume Visualization, </booktitle> <pages> pages 9-16. </pages> <publisher> ACM, </publisher> <year> 1992. </year>
Reference-contexts: A typical example rendered a 256x256x226 dataset to a 416 2 image using 48 processors in 700ms with a speedup of 40 and an efficiency of 83% for nonadaptive, and 340ms with a speedup of 33 and an efficiency of 69% for adaptive image sampling. Montani et al. <ref> [MPS92] </ref> present a parallel raytracing algorithm for rectilinear volumes on the nCUBE 2, a distributed-memory, message-passing, hypercube architecture. The approach groups the processing nodes into clusters. The dataset is replicated on each cluster. Scanlines of the image are assigned to each cluster in an interleaved fashion for processing. <p> Using the pyramidal volume sampling a 256 3 dataset can be rendered to a 400 2 image in 47 seconds. 25 Machine Data Image Time in Number of Size Size Milliseconds Processors Stanford DASH [NL92] Raycasting 256x256x226 416 2 340 48 nCUBE 2 <ref> [MPS92] </ref> Raycasting 97x97x116 350x250 4750 128 Fujitsu AP1000 [CM92] Raycasting 256x256x109 512 2 54000 127 SGI 4D/380 VGX Scanline 256 3 400 2 47000 8 Pixel-Planes 5 [Neu92] 40 MIMD + Splatting 128x128x124 512 2 263 256K SIMD nCUBE 2 [Elv92] Splatting 256x256x90 200 2 173000 64 Table 2.3: Results reported <p> Of course the most efficient approach would be to store the entire volume at each processor. This is generally not feasible for large datasets. A possible compromise that increases efficiency on some architectures is to distribute multiple copies of the dataset to groups of processors <ref> [MPS92] </ref>. For systems that support virtual shared memory with local caching, another form of partial dataset replication is implicitly achieved. In this particular experiment the volume is stored in globally-shared memory. <p> Key decisions include the approach to memory management, task generation, and the basic algorithm. A review of the literature shows that image-space decompositions for raycasting [Cha92, NL92, CM92, Luc92] have achieved better scalability and levels of performance than object-space decompositions <ref> [MPS92] </ref>. Implementations of object-space decompositions for projection or splatting algorithms have been shown to be limited in terms of their scalability by synchronization requirements [Cha91, Wil92c, 61 Elv92]. The parallel direct volume rendering algorithm described in the next chapter utilizes interleaved globally-shared memory to store the volumetric dataset.
Reference: [MS90] <author> F. W. Martin, Jr. and J. P. Slotnick. </author> <title> Flow Computations for the Space Shuttle in Ascent Mode Using Thin-Layer Navier-Stokes Equations. In P.A. </title> <editor> Henne, editor, </editor> <booktitle> Progress in Astronautics and Aeronautics, </booktitle> <volume> Vol. 125, </volume> <pages> pages 863-886. </pages> <institution> American Institute of Aeronautics and Astronautics, </institution> <address> Washington, D.C., </address> <year> 1990. </year>
Reference-contexts: The third dataset is the delta wing dataset, taken from a study of vorti-cal flow over a delta wing [FGH87]. It contains 91 fi 51 fi 51 grid nodes, or 236691 nodes defining 225000 cells (figures 6.6 and 6.7). The fourth dataset is the shuttle dataset <ref> [MS90] </ref>, a multi-block grid consisting of 9 grids with a total of 941159 nodes defining 885898 cells. This dataset represents flow computations of the space shuttle ascent aerodynamics. Four views of the shuttle dataset have been benchmarked (figures 6.8, 6.9, 6.10, and 6.11).
Reference: [Neu92] <author> Ulrich Neumann. </author> <title> Interactive Volume Rendering on a Multicomputer. </title> <booktitle> In 1992 Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 87-99. </pages> <publisher> ACM, </publisher> <month> March </month> <year> 1992. </year>
Reference-contexts: There are two approaches to the projection method for volume rendering: cell projection [UK88, MHC90, ST90, WV91, Wil92c, SH92, Luc92, VW93] and splatting <ref> [Wes89, Wes90, Neu92, Elv92, LH91] </ref>. Both of these methods begin by creating a visibility sort of the cells or nodes in order to ensure correct ordering of compositing operations. For rectilinear datasets a visibility sort is trivial, however, it is more complex for more general grids. <p> A careful analysis of the virtual memory performance and caching behavior is presented. Raycasting a 256x256x109 dataset to a 512x512 image takes 54 seconds using 127 processors, with an efficiency of 80-85% attained. Neumann <ref> [Neu92] </ref> describes an implementation of a parallel splatting algorithm for rectilinear data on the Pixel-Planes 5. The volume is splatted one slice at a time. The GPs compute coefficients for a quartic kernel. Renderers evaluate and produce the kernel which is then used for splatting into the current slice. <p> 25 Machine Data Image Time in Number of Size Size Milliseconds Processors Stanford DASH [NL92] Raycasting 256x256x226 416 2 340 48 nCUBE 2 [MPS92] Raycasting 97x97x116 350x250 4750 128 Fujitsu AP1000 [CM92] Raycasting 256x256x109 512 2 54000 127 SGI 4D/380 VGX Scanline 256 3 400 2 47000 8 Pixel-Planes 5 <ref> [Neu92] </ref> 40 MIMD + Splatting 128x128x124 512 2 263 256K SIMD nCUBE 2 [Elv92] Splatting 256x256x90 200 2 173000 64 Table 2.3: Results reported on MIMD architectures for rectilinear datasets. All of the above research has been directed towards rendering of rectilinear datasets.
Reference: [NHK + 85] <author> Hitoshi Nishimura, Makato Hirai, Toshiyuki Kawai, Toru Kawata, Isao Shi-rakawa, and Koichi Omura. </author> <title> Object Modelling by Distribution Function and a Method of Image Generation. </title> <journal> Trans. IEICE, </journal> <note> J-68D(4):718-725, 1985. in Japanese. </note>
Reference-contexts: All of these algorithms generate a geometric representation of a subset of the volumetric dataset. Closely related to the techniques for isosurface generation are those used in the generation of implicit surfaces [Nor82, WMW86, Blo88], and in specialized methods for raytracing to a contour surface <ref> [Bli82b, NHK + 85] </ref>. 2.1.2 Direct Volume Rendering One drawback to the use of isosurfaces as a means to visualize the contents of volumetric datasets is the fact that this approach inherently presents a subset of the data, throwing the rest of the information away.
Reference: [NL92] <author> Jason Nieh and Marc Levoy. </author> <title> Volume Rendering on Scalable Shared-Memory MIMD Architectures. </title> <booktitle> In 1992 Workshop on Volume Visualization, </booktitle> <pages> pages 17-24. </pages> <publisher> ACM, </publisher> <year> 1992. </year>
Reference-contexts: Each GP is assigned a group of rays to process, it must request the required voxel information from the PPs. Local caching is suggested where possible to speed rendering time. Hierarchical spatial enumeration, adaptive sampling, and successive refinement are also suggested to speed rendering. Nieh and Levoy <ref> [NL92] </ref> describe the implementation of Marc Levoy's volume rendering algorithms including optimizations of hierarchical opacity enumeration, early ray termination, and adaptive image sampling, on the Stanford DASH Multiprocessor. The DASH consists of clusters of processors connected by a scalable interconnection network. Processors can be added as required to the hierarchy. <p> Using the pyramidal volume sampling a 256 3 dataset can be rendered to a 400 2 image in 47 seconds. 25 Machine Data Image Time in Number of Size Size Milliseconds Processors Stanford DASH <ref> [NL92] </ref> Raycasting 256x256x226 416 2 340 48 nCUBE 2 [MPS92] Raycasting 97x97x116 350x250 4750 128 Fujitsu AP1000 [CM92] Raycasting 256x256x109 512 2 54000 127 SGI 4D/380 VGX Scanline 256 3 400 2 47000 8 Pixel-Planes 5 [Neu92] 40 MIMD + Splatting 128x128x124 512 2 263 256K SIMD nCUBE 2 [Elv92] Splatting <p> A review of the literature and the initial studies discussed above have suggested the direction taken in this research. Key decisions include the approach to memory management, task generation, and the basic algorithm. A review of the literature shows that image-space decompositions for raycasting <ref> [Cha92, NL92, CM92, Luc92] </ref> have achieved better scalability and levels of performance than object-space decompositions [MPS92]. Implementations of object-space decompositions for projection or splatting algorithms have been shown to be limited in terms of their scalability by synchronization requirements [Cha91, Wil92c, 61 Elv92]. <p> This is because the more effective load balancing provides near-linear speedup as n increases. It may be possible to obtain the efficiency gained through the use of large tile sizes while still maintaining good load balancing as n grows large, using a task-adaptive approach to task generation <ref> [Whi92, NL92] </ref>.
Reference: [Nor82] <author> Alan Norton. </author> <title> Generation and Display of Geometric Fractals in 3-D. </title> <booktitle> In Proceedings of SIGGRAPH '82, </booktitle> <year> 1982. </year>
Reference-contexts: All of these algorithms generate a geometric representation of a subset of the volumetric dataset. Closely related to the techniques for isosurface generation are those used in the generation of implicit surfaces <ref> [Nor82, WMW86, Blo88] </ref>, and in specialized methods for raytracing to a contour surface [Bli82b, NHK + 85]. 2.1.2 Direct Volume Rendering One drawback to the use of isosurfaces as a means to visualize the contents of volumetric datasets is the fact that this approach inherently presents a subset of the data,
Reference: [OUT85] <author> Toshiaki Ohashi, Tetsuya Uchiki, and Mario Tokoro. </author> <title> A Three-Dimensional Shaded Display Method for Voxel-Based Representations. </title> <booktitle> In Proceedings of EUROGRAPHICS 1985, </booktitle> <pages> pages 221-232. </pages> <institution> National Computer Graphics Association, </institution> <month> September </month> <year> 1985. </year>
Reference-contexts: These architectures either do not handle semi-transparent voxels, or they do so at a performance penalty. The specialized architectures that have been proposed or developed for solid modeling applications include: the 3DP 4 <ref> [OUT85] </ref>, Insight [Mea85], the PARCUM II [Jac88], and the RayCasting Engine [EKM + 91]. Architectures designed for medical imaging applications include: the Voxel Processor [GRB + 85], and the Cube [KB88]. All of the approaches described in this section utilize MIMD architectures having either shared or distributed memory. <p> Architectures designed for medical imaging applications include: the Voxel Processor [GRB + 85], and the Cube [KB88]. All of the approaches described in this section utilize MIMD architectures having either shared or distributed memory. Two use a pipelined approach <ref> [OUT85, EKM + 91] </ref> with different processors assigned to different tasks in the rendering pipeline. In these cases the connections between memory and processors are specific to the task being executed. Memory may also be specialized to speed the rendering process [Jac88, KB88] by allowing simultaneous reads and writes. <p> In these cases the connections between memory and processors are specific to the task being executed. Memory may also be specialized to speed the rendering process [Jac88, KB88] by allowing simultaneous reads and writes. For the 3DP 4 <ref> [OUT85] </ref>, the goal is a fast solid-model rendering system for interactive use. Solid models are represented by PEARYs, picture element arrays; these are simply rectilinear volumes of voxels which are either opaque or transparent. The rendering algorithm is called the linear interpolating projection method.
Reference: [PD84] <author> Thomas Porter and Tom Duff. </author> <title> Compositing Digital Images. </title> <journal> Computer Graphics, </journal> <volume> 18(3) </volume> <pages> 253-259, </pages> <year> 1984. </year> <note> Proceedings of SIGGRAPH '84. </note>
Reference-contexts: Rendering the volumetric dataset involves sampling the entire dataset in some fashion and mapping each sampled value to a color and opacity. The contribution from each sample must then be composited or accumulated into the image <ref> [PD84] </ref>. There are currently four basic algorithms which are widely used for sampling the entire volume: raycasting, cell projection, splatting, and shear transformations. The decision on whether to support 3 parallel or perspective viewing projections can have implications for sampling and aliasing. <p> Finally, the opacity is used to composite the contribution to the pixel using the standard method described by Porter and Duff <ref> [PD84] </ref>.
Reference: [PFTV86] <author> William H. Press, Brian P. Flannery, Saul A. Teukolsky, and William T. Vetter-ling. </author> <title> Numerical Recipes The Art of Scientific Computing. </title> <publisher> Cambridge University Press, </publisher> <year> 1986. </year> <month> 131 </month>
Reference-contexts: Next, any cell faces that become active on this pixel are added to the x active list. The x-bucket for the current pixel is sorted into descending order by the minimum z value of the face on this scanline using Shell's method (O (n 3=2 )) <ref> [PFTV86] </ref>. The x-bucket is then merged with the current active list. This process maintains the active list in nearly sorted order and greatly reduces the time required to insert intersections on the depth-sorted intersection list when it is generated.
Reference: [plo89] <institution> PLOT3D User's Manual. National Aeronautics and Space Administration, Fluid Dynamics Division, NASA Ames Research Center, </institution> <year> 1989. </year>
Reference-contexts: These array-organized grids are also called structured grids [SK90]. Very large simulation geometries are sometimes gridded using a multi-block approach <ref> [plo89] </ref>. In this situation several curvilinear grids are combined in one simulation in order to represent the solution space. These grids may overlap spatially, and cell faces belonging to two different grids may intersect. <p> Buttons are available to pop up windows providing other functionality, and for requesting an image to be rendered. A text box allows the user to specify a new computational grid (these are stored in Plot3D files <ref> [plo89] </ref> on the host). Buttons along the right side are used to specify which scalar field from the solution file is desired and the histogram of the scalar field is displayed in a window on the left. <p> In the current implementation the file format supported is the Plot3D format generated by CFD applications at NASA Ames Research Center <ref> [plo89] </ref>. Initialization of the cell faces is done in parallel. The task decomposition is by face group and these tasks are dynamically generated.
Reference: [PWD93] <author> Richard J. Procassini, Scott R. Whitman, and William P. Dannevik. </author> <title> Porting a Global Ocean Model Onto a Shared-Memory Multiprocessor: Observations and Guidelines. </title> <journal> Journal of Supercomputing, </journal> <note> 1993. to appear. </note>
Reference-contexts: It could be combined with the sorting phase at the expense of transforming each grid node three times. Alternatively, a method of task generation in which the overhead of going parallel is reduced (i.e. a "split-join" as opposed to a "fork-join" approach <ref> [PWD93, BGWW91] </ref>) would reduce the inefficiency of having three small task phases. The sorting phase did see a speedup for all datasets, although it certainly tails off by 110 processors and is not close to being linear.
Reference: [Ram91] <author> Shankar Ramamoorthy. </author> <title> Curvilinear Grids. </title> <booktitle> In Course Notes 8: State of the Art in Volume Visualization. ACM Siggraph '91 Conference, </booktitle> <year> 1991. </year>
Reference-contexts: Inverse distance weighted interpolation has the advantages of being fairly fast and rotationally invariant, but has the disadvantage that it does not have C 0 continuity along interior faces of the grid <ref> [WCA + 90, Ram91] </ref>. The opacity value obtained by the transfer function mapping of the scalar value to opacity is weighted by the distance along the ray through that cell. Single-phase Algorithm The first algorithm proceeds to collect samples and composite them into the image in a single phase.
Reference: [RKK86] <author> S. E. Rogers, D. Kwak, and U. K. Kaul. </author> <title> A Numerical Study of Three-Dimensional Incompressible Flow Around Multiple Posts, 1986. </title> <type> AIAA Paper 86-0353, </type> <address> Reno, Nevada. </address>
Reference-contexts: This dataset represents a CFD simulation of air flow past a blunt fin on a grid resolution of 40 fi 32 fi 32, or 40960 nodes defining 37479 cells. Images of this dataset are presented in figures 6.1 and 6.2. The second is the post dataset <ref> [RKK86] </ref>, which was obtained from a numerical study of three-dimensional incompressible flow around multiple posts and has a grid resolution of 38 fi 76 fi 38 giving 109744 nodes defining 102675 cells. Three views of this dataset have been benchmarked (figures 6.3, 6.4, and 6.5).
Reference: [RW92] <author> Shankar Ramamoorthy and Jane Wilhelms. </author> <title> An Analysis of Approaches to Ray-Tracing Curvilinear Grids. </title> <type> Technical Report UCSC-CRL-92-07, </type> <institution> University of California, Santa Cruz, </institution> <year> 1992. </year>
Reference-contexts: In general, the approach of stepping cell to cell may require expensive testing to resolve the ambiguity that results from a ray passing through an edge or node of a cell <ref> [RW92] </ref>. An early version of the raycasting algorithm presented in this thesis performed bucket sorts in x and y on the cells of a curvilinear grid to reduce intersection testing requirements [Cha92].
Reference: [Sab88] <author> Paolo Sabella. </author> <title> A Rendering Algorithm for Visualizing 3D Scalar Fields. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 51-58, </pages> <year> 1988. </year> <note> Proceedings of SIGGRAPH '88. </note>
Reference-contexts: Each image sample has an associated implicit location in &lt; 3 . How can such an entity be visualized so as to allow internal structure to be seen while preventing loss of information? This question has led researchers to a technique for rendering volumetric datasets called direct volume rendering <ref> [DCH88, UK88, Sab88, Lev88] </ref>. This approach is called "direct" to differentiate it from other methods, such as isosurface extraction or volume slicing, which utilize only a subset of the data for image creation. <p> Sabella modifies Kajiya's [KH84] raytracing algorithm for computational efficiency by eliminating shadowing in order to render a scalar field as a varying density emitter <ref> [Sab88] </ref>. In one of his rendering schemes, four values are computed for each ray cast through the volume: the maximum value encountered along the ray, the distance to this maximum value, the attenuated intensity, and the center of gravity.
Reference: [SG91] <author> Georgios Sakas and Matthias Gerth. </author> <title> Sampling and Anti-Aliasing of Discrete 3-D Volume Density Textures. </title> <booktitle> In Proceedings of Eurographics '91, </booktitle> <pages> pages 87-102, </pages> <year> 1991. </year>
Reference-contexts: Several raycasting algorithms are presented using volume pyramids and allowing the user to trade image quality for speed. Sakas and Gerth give a method for creating volume pyramids based on perspective views which may then be traversed to avoid aliasing without oversampling <ref> [SG91] </ref>. Their approach to pyramidal volume traversal makes the time to render an image dependent on the image resolution and independent of volume resolution. Very recently, researchers have presented methods for doing direct volume rendering in the frequency domain, rather than in the spatial domain [Mal93, TL93]. <p> This is a form of aliasing that can be reduced by stochastic sampling methods [Gla89], or by volume pyramid approaches such as those described by <ref> [SG91] </ref>. In the absence of anti-aliasing, these cells can be trivially eliminated from the bucket sorts (and thus not considered for possible intersection with a ray). Doing this improves both the absolute time required to render the image, and the load balancing of the parallel decomposition.
Reference: [SH92] <author> Georgios Sakas and Jochen Hartig. </author> <title> Interactive Visualization of Large Scalar Voxel Fields. </title> <booktitle> In Visualization '92, </booktitle> <pages> pages 29-36. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1992. </year>
Reference-contexts: There are two approaches to the projection method for volume rendering: cell projection <ref> [UK88, MHC90, ST90, WV91, Wil92c, SH92, Luc92, VW93] </ref> and splatting [Wes89, Wes90, Neu92, Elv92, LH91]. Both of these methods begin by creating a visibility sort of the cells or nodes in order to ensure correct ordering of compositing operations. <p> The results presented indicate that the speedup for this approach peaks at about 8 processors, severely limiting the scalability of the algorithm. The time to render a 256x256x90 dataset to a 200 2 image was 2 minutes 53 seconds. Sakas <ref> [SH92] </ref> presents several scanline based methods for volume rendering rectilinear volumes and gives results of parallelization on an 8 processor Silicon Graphics 4D/380 VGX.
Reference: [SK90] <author> Don Speray and Steve Kennon. </author> <title> Volume Probes: Interactive Data Exploration on Arbitrary Grids. </title> <journal> Computer Graphics, </journal> <volume> 24(5) </volume> <pages> 5-12, </pages> <month> November </month> <year> 1990. </year> <booktitle> Proceedings of the San Diego Workshop on Volume Visualization. </booktitle>
Reference-contexts: More general grids are commonly used by researchers to generate volumetric datasets. Nomenclature for volumetric grids is hardly standardized; a brief overview of grid types is given in <ref> [SK90] </ref> and more detailed information can be found in [Fle88, ZT89]. We will call a single data point that has been sampled or computed a node. Two neighboring nodes may be said to define an edge, and three or more define a face. <p> In this case, a regular, rectilinear, computational grid has been shaped, i.e. mapped by a smooth function from &lt; 3 to &lt; 3 to give a curved shape, resulting in cells with non-planar faces in physical 4 space [Fle88]. These array-organized grids are also called structured grids <ref> [SK90] </ref>. Very large simulation geometries are sometimes gridded using a multi-block approach [plo89]. In this situation several curvilinear grids are combined in one simulation in order to represent the solution space. These grids may overlap spatially, and cell faces belonging to two different grids may intersect. <p> A curvilinear grid is defined by a rectilinear computational grid that has been shaped, resulting in cells with non-planar faces in physical space [Fle88]. These array-organized grids are also called structured grids <ref> [SK90] </ref>. Computational grids in &lt; 3 that are not array-organized (sometimes called unstructured grids [SK90]) and are made up of tetrahedral or hexahedral cells that have been shaped are also common in 67 computational fluid dynamics and finite element analysis applications [ZT89]. <p> A curvilinear grid is defined by a rectilinear computational grid that has been shaped, resulting in cells with non-planar faces in physical space [Fle88]. These array-organized grids are also called structured grids <ref> [SK90] </ref>. Computational grids in &lt; 3 that are not array-organized (sometimes called unstructured grids [SK90]) and are made up of tetrahedral or hexahedral cells that have been shaped are also common in 67 computational fluid dynamics and finite element analysis applications [ZT89]. Typically the definition of these grids is given as a list of cells, defined by pointers into a list of nodes.
Reference: [SM92] <author> Reese L. Sorenson and Karen McCann. Grapevine: </author> <title> Grids About Anything by Poisson's Equation in a Visually Interactive Networking Environment. </title> <booktitle> In Computational Aerosciences Conference Compendium of Abstracts, </booktitle> <year> 1992. </year> <institution> NASA Ames Research Center. </institution>
Reference-contexts: compressed and sent back to the local workstation for display. 10 The concept of using a distributed approach as described here was inspired by a system using a similar approach for grid generation (also a computationally intensive process), presented at the 1992 Computational Aerosciences Conference at NASA Ames Research Center <ref> [SM92] </ref>.
Reference: [SS89a] <author> Carlo H. Sequin and Eliot K. Smyrl. </author> <title> Parameterized Ray Tracing. </title> <journal> Computer Graphics, </journal> <volume> 23(3) </volume> <pages> 307-314, </pages> <month> July </month> <year> 1989. </year> <note> Proceedings of SIGGRAPH '89. </note>
Reference-contexts: This approach decouples the sampling and compositing phases of rendering, leading to the possibility of fast image update rates for changing transfer functions. A similar approach has previously been utilized to speed computation of successive ray-traced images with changing lighting conditions and surface properties <ref> [SS89a] </ref>. <p> A similar approach has previously been utilized to speed computation of successive ray-traced images with changing lighting conditions and surface properties <ref> [SS89a] </ref>. The basic rendering algorithm proceeds in the same way, but sampling (intersection generation) and compositing have been split into two phases. The motivation for doing this is to attain fast image updates for a changing transfer function.
Reference: [SS89b] <author> J. A. Sethian and James B. Salem. </author> <title> Animation of Interactive Fluid Flow Visualization Tools on a Data Parallel Machine. </title> <journal> The International Journal of Supercomputer Applications, </journal> <volume> 3(2) </volume> <pages> 10-39, </pages> <year> 1989. </year>
Reference-contexts: In many cases, the most time-consuming and difficult part of a given numerical experiment will be the analysis, understanding, and verification of the contents of the voluminous results of the computation <ref> [WCH + 87, SS89b] </ref>. The most useful visualization tools allow a researcher to interactively explore a dataset.
Reference: [SS91] <author> Peter Schroder and James B. Salem. </author> <title> Fast Rotation of Volume Data on Data Parallel Architectures. </title> <booktitle> In Course Notes 8: State of the Art in Volume Visualization. ACM Siggraph '91 Conference, </booktitle> <year> 1991. </year>
Reference-contexts: Design of the reconstruction kernel may be complicated for more complex grids. 1.1.4 Shear Transformations Direct volume rendering using shear transformations is a hybrid approach, rather than being either an image-space or object-space algorithm <ref> [DCH88, SS91, VFR92, KMS + 92] </ref>. The algorithm implements the viewing transformation as a series of one-dimensional shear transformations and resampling of the dataset. The result gives a volume of data in memory that is view aligned. Compositing may then be accomplished simply by striding through the memory. <p> All of the SIMD approaches to direct volume rendering have addressed rectilinear grids only. These approaches are discussed in more detail below and the results are summarized in table 2.2. The first parallel algorithms for direct volume rendering on SIMD architectures utilized shear transformations. Schroder <ref> [SS91] </ref> has presented an algorithm for parallel volume rendering on the Connection Machine (CM-2) in which an important aspect is the communication requirements for rotating the volume in memory to match the requested view.
Reference: [SS92] <author> Peter Schoder and Gordon Stoll. </author> <title> Data Parallel Volume Rendering as Line Drawing. </title> <booktitle> In 1992 Workshop on Volume Visualization, </booktitle> <pages> pages 25-32. </pages> <publisher> ACM, </publisher> <year> 1992. </year>
Reference-contexts: He reports performance statistics for rendering a 128 3 rectilinear dataset to a 128 2 image at 456ms using 16K processors. 22 Machine Data Image Time in Number of Size Size Milliseconds Processors CM-2 MasPar MP-1 [VFR92] 128 3 128 2 456 16K <ref> [SS92] </ref> 128 3 512 2 923 16K Princeton Engine [KMS + 92] 256 3 512 2 500 256 Table 2.2: Results reported on SIMD architectures for rectilinear datasets. More recently Schroder has presented another algorithm which does not rely on shear transforms, but rather steps the rays through the volume [SS92]. <p> <ref> [SS92] </ref> 128 3 512 2 923 16K Princeton Engine [KMS + 92] 256 3 512 2 500 256 Table 2.2: Results reported on SIMD architectures for rectilinear datasets. More recently Schroder has presented another algorithm which does not rely on shear transforms, but rather steps the rays through the volume [SS92]. In this approach, rays are cast at an angle through the volume and the projection information is passed from processor to processor. All rays are processed in parallel and move in lockstep along a major axis. This algorithm has been implemented on the CM-2 and the Princeton Engine. <p> In their approach each yz slice is stored on a different processor. Rotation about the x axis can be simply performed using shear transformations on each processor (or direct application of the rotation transformation). For multiple axis rotation the line drawing projection algorithm given by Schroder <ref> [SS92] </ref> is used. They report rendering times for a 512 2 image and a 256 3 dataset of 125ms to 250ms for x axis rotation using 1024 processors and 500ms for multiple axis rotation using 256 processors.
Reference: [ST90] <author> Peter Shirley and Alan Tuchman. </author> <title> A Polygonal Approximation to Direct Scalar Volume Rendering. </title> <journal> Computer Graphics, </journal> <volume> 24(5) </volume> <pages> 63-70, </pages> <month> November </month> <year> 1990. </year> <booktitle> Proceedings of the San Diego Workshop on Volume Visualization. </booktitle> <pages> 132 </pages>
Reference-contexts: There are two approaches to the projection method for volume rendering: cell projection <ref> [UK88, MHC90, ST90, WV91, Wil92c, SH92, Luc92, VW93] </ref> and splatting [Wes89, Wes90, Neu92, Elv92, LH91]. Both of these methods begin by creating a visibility sort of the cells or nodes in order to ensure correct ordering of compositing operations. <p> Cell projection and splatting are both object-space algorithms in which cells or nodes are projected to the screen <ref> [UK88, Wes89, Wes90, LH91, WV91, ST90, MHC90] </ref>. These methods require that the cells or nodes be sorted into a visibility ordering and projected either front-to-back or back-to-front. Methods using shear transformations first rotate the volume in memory so that it is view aligned. <p> In addition to taking advantage of spatial coherence to create efficient projection algorithms, some researchers have combined these techniques with the production of hardware renderable geometric primitives to further speed the rendering process by taking advantage of the fast rendering hardware available in computer graphics workstations. Shirley and Tuchman <ref> [ST90] </ref> present an algorithm for efficiently projecting tetrahedral cells in which each cell is represented with hardware renderable semi-transparent triangles. Laur & Han-rahan [LH91] combine a pyramidal representation with hierarchical enumeration of the data 15 and the ability to rapidly generate hardware-renderable primitives to represent the projection of different-sized cells. <p> The hardware-renderable primitives are scaled depending on the level of resolution requested by the user. Progressive refinement is utilized to obtain interactive rates. Williams [Wil92a, Wil92b, Wil92c] explores several approximations to the algorithm of of Shirley and Tuchman <ref> [ST90] </ref> for projecting tetrahedral cells which trade image quality for speed and compares the results. Wilhelms and Van Gelder [WV91] describe a projection algorithm for rectilinear volumes in which a template for projection is formed and used to speed the scan conversion of cells. <p> Many of the projection approaches for rectilinear grids can be extended to handle more general grids. The visibility ordering requirements remain the same. Max, Hanrahan, & Crawfis [MHC90] give an algorithm for the projection of any collection of sortable convex polyhedra. Shirley and Tuchman <ref> [ST90] </ref> present an algorithm for efficiently projecting tetrahedral cells in which each cell is represented with hardware renderable semi-transparent triangles. Williams [Wil92a, Wil92b, Wil92c] gives algorithms for visibility ordering and rendering of nonrectilinear volumes. The algorithm of Shirley and Tuchman [ST90] for projecting tetrahedral cells is modified using several different approximations <p> Shirley and Tuchman <ref> [ST90] </ref> present an algorithm for efficiently projecting tetrahedral cells in which each cell is represented with hardware renderable semi-transparent triangles. Williams [Wil92a, Wil92b, Wil92c] gives algorithms for visibility ordering and rendering of nonrectilinear volumes. The algorithm of Shirley and Tuchman [ST90] for projecting tetrahedral cells is modified using several different approximations which trade image quality for speed and the results are compared.
Reference: [TG88] <author> Filippo Tampieri and Donald Greenberg. </author> <title> Experimental Distributed Processing System for Global Illumination Algorithms. </title> <type> Technical report, </type> <institution> Cornell University, </institution> <year> 1988. </year>
Reference-contexts: The rays are represented as messages passed between the processors. Dippe and Swensen extend this approach to achieve better load balancing by using an adaptive world-space decomposition [DS84]. Parallelization of global illumination algorithms in a distributed workstation environment has been addressed by Tampieri and Greenberg <ref> [TG88] </ref>. Parallelization of the raytracing algorithm on a distributed-memory MIMD architecture using an image-space decomposition is presented by Badouel [BP90]. This algorithm depends on an implementation of shared virtual memory with local caching. Whitman explores several image-space decompositions and scheduling strategies on a shared-memory MIMD machine [Whi92]. <p> Processors on the edge of the three-dimensional space have fewer duties, thus are assigned to handle external tasks such as the frame buffer, disk I/O, and the user interface. A simulator has been coded to test these ideas, but no empirical results were presented. Tampieri and Greenberg <ref> [TG88] </ref> give an overview of global illumination algorithms (raytracing, radiosity, progressive refinement radiosity, and monte carlo), and give results of experiments with execution of these algorithms in a distributed workstation environment. Message passing over an ethernet connection is used for communication.
Reference: [TL93] <author> Takashi Totsuka and Marc Levoy. </author> <title> Frequency Domain Volume Rendering. </title> <booktitle> In Proceedings of SIGGRAPH '93, </booktitle> <pages> pages 271-278, </pages> <year> 1993. </year>
Reference-contexts: To achieve its ultimate usefulness as an exploratory tool, volume rendering must run at interactive speeds. There have been numerous approaches to speeding up the volume rendering process using sequential algorithms <ref> [Wes89, Wes90, LH91, Lev90, WV91, DH92, VW93, Mal93, TL93] </ref>. Many of these algorithms trade image quality for speed, typically under user control. Hibbard and Santek make the case that interactivity is the most important feature in a system for the analysis of volumetric datasets [HS89]. <p> Their approach to pyramidal volume traversal makes the time to render an image dependent on the image resolution and independent of volume resolution. Very recently, researchers have presented methods for doing direct volume rendering in the frequency domain, rather than in the spatial domain <ref> [Mal93, TL93] </ref>. This approach is attractive because it reduces the complexity of the rendering process from O (n 3 ) to O (n 2 log n) by making use of the equivalence of the integral of a 1D signal and its spectrum. <p> The primary drawback of Fourier volume rendering is that occlusion is not supported, thus the resulting images are similar to x-rays. Totsuka and Levoy have presented techniques for frequency domain depth cueing and directional shading in an effort to alleviate this problem <ref> [TL93] </ref>. 16 2.1.5 Volume Rendering More Complex Grids Most of the approaches discussed so far addressed volumetric rendering of data on a rectilinear grid. Researchers have recently begun to address volume rendering algorithms for more complex computational grids.
Reference: [UK88] <author> Craig Upson and Michael Keeler. VBUFFER: </author> <title> Visible Volume Rendering. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 59-64, </pages> <year> 1988. </year> <note> Proceedings of SIGGRAPH '88. </note>
Reference-contexts: Each image sample has an associated implicit location in &lt; 3 . How can such an entity be visualized so as to allow internal structure to be seen while preventing loss of information? This question has led researchers to a technique for rendering volumetric datasets called direct volume rendering <ref> [DCH88, UK88, Sab88, Lev88] </ref>. This approach is called "direct" to differentiate it from other methods, such as isosurface extraction or volume slicing, which utilize only a subset of the data for image creation. <p> There are many algorithms for accomplishing this; figure 1.1 shows how lookup tables (commonly called transfer functions) can be used to obtain color and opacity values for a specific scalar data value in the array <ref> [UK88] </ref>. In general, the sample points desired within the data array will not lie directly on those sample points that are given. An interpolation method will be employed to generate the scalar data value at the desired sample point. <p> There are two approaches to the projection method for volume rendering: cell projection <ref> [UK88, MHC90, ST90, WV91, Wil92c, SH92, Luc92, VW93] </ref> and splatting [Wes89, Wes90, Neu92, Elv92, LH91]. Both of these methods begin by creating a visibility sort of the cells or nodes in order to ensure correct ordering of compositing operations. <p> Raycasting is an image-space approach in which a ray from the eyepoint is cast through each pixel of the image, intersected with the volume, and sampled along its length <ref> [Lev88, Lev89b, UK88, 12 Sab88, GO89] </ref>. Cell projection and splatting are both object-space algorithms in which cells or nodes are projected to the screen [UK88, Wes89, Wes90, LH91, WV91, ST90, MHC90]. <p> Cell projection and splatting are both object-space algorithms in which cells or nodes are projected to the screen <ref> [UK88, Wes89, Wes90, LH91, WV91, ST90, MHC90] </ref>. These methods require that the cells or nodes be sorted into a visibility ordering and projected either front-to-back or back-to-front. Methods using shear transformations first rotate the volume in memory so that it is view aligned. <p> Approaches to direct volume rendering have also differed in the techniques used to map the scalar values to color and opacity. This section gives an overview of several of the different approaches that have been taken. In work presented by Upson and Keeler <ref> [UK88] </ref> transfer functions for both color and opacity are defined on the range of the volumetric scalar field. These are then used, along with gradients estimated using finite differences, in shading computations. Both image-space and object-space (raycasting and projection) methods are addressed. <p> If so, then the color and opacity of the surface are composited into the contribution collected thus far for the ray [GO89]. Upson and Keeler generate isosurfaces by using a step function in their opacity transfer function <ref> [UK88] </ref>. Drebin, Carpenter, and Hanrahan do surface extraction by computing a "surface normal volume" and a "surface strength volume" based on the percentages and densities of each material present in the volume [DCH88].
Reference: [VFR92] <author> Guy Vezina, Peter A. Fletcher, and Philip K. Robertson. </author> <title> Volume Rendering on the MasPar MP-1. </title> <booktitle> In 1992 Workshop on Volume Visualization, </booktitle> <pages> pages 3-8. </pages> <publisher> ACM, </publisher> <year> 1992. </year>
Reference-contexts: Design of the reconstruction kernel may be complicated for more complex grids. 1.1.4 Shear Transformations Direct volume rendering using shear transformations is a hybrid approach, rather than being either an image-space or object-space algorithm <ref> [DCH88, SS91, VFR92, KMS + 92] </ref>. The algorithm implements the viewing transformation as a series of one-dimensional shear transformations and resampling of the dataset. The result gives a volume of data in memory that is view aligned. Compositing may then be accomplished simply by striding through the memory. <p> Using 64K processors this algorithm renders a 128 3 rectilinear dataset to a 256 2 image in 821ms. Vezina et al. <ref> [VFR92] </ref> give a similar algorithm using shear transformations and describes its implementation on the MasPar MP-1. <p> He reports performance statistics for rendering a 128 3 rectilinear dataset to a 128 2 image at 456ms using 16K processors. 22 Machine Data Image Time in Number of Size Size Milliseconds Processors CM-2 MasPar MP-1 <ref> [VFR92] </ref> 128 3 128 2 456 16K [SS92] 128 3 512 2 923 16K Princeton Engine [KMS + 92] 256 3 512 2 500 256 Table 2.2: Results reported on SIMD architectures for rectilinear datasets.
Reference: [VW93] <author> Allen Van Gelder and Jane Wilhelms. </author> <title> Rapid Exploration of Curvilinear Grids Using Direct Volume Rendering. </title> <booktitle> In Proceedings of Visualization '93. IEEE, </booktitle> <month> October </month> <year> 1993. </year> <note> to appear. </note>
Reference-contexts: There are two approaches to the projection method for volume rendering: cell projection <ref> [UK88, MHC90, ST90, WV91, Wil92c, SH92, Luc92, VW93] </ref> and splatting [Wes89, Wes90, Neu92, Elv92, LH91]. Both of these methods begin by creating a visibility sort of the cells or nodes in order to ensure correct ordering of compositing operations. <p> To achieve its ultimate usefulness as an exploratory tool, volume rendering must run at interactive speeds. There have been numerous approaches to speeding up the volume rendering process using sequential algorithms <ref> [Wes89, Wes90, LH91, Lev90, WV91, DH92, VW93, Mal93, TL93] </ref>. Many of these algorithms trade image quality for speed, typically under user control. Hibbard and Santek make the case that interactivity is the most important feature in a system for the analysis of volumetric datasets [HS89]. <p> They also compare different approaches to the approximation of the integrals required with respect to speed and image accuracy and quality. Van Gelder and Wilhelms <ref> [VW93] </ref> have also presented techniques which extended this work to handle curvilinear computational grids. Raycasting approaches allow more accurate images to be generated, but tend to be much slower than the other algorithms due to their computational requirements. <p> Lucas [Luc92] renders irregular grids by visibility ordering the faces of each cell and then scan converting them in order, using a z-buffer to record information which allows the depth through each cell to be used in the compositing operation. Van Gelder and Wilhelms <ref> [VW93] </ref> extend their work on fast projection algorithms [WV91] using hardware renderable primitives to handle curvilinear grids. Several methods which trade image quality for speed are presented, along with an algorithm for visibility ordering and a technique for improving the results of using hardware compositing.
Reference: [WCA + 90] <author> Jane Wilhelms, Judy Challinger, Naim Alper, Shankar Ramamoorthy, and Arsi Vaziri. </author> <title> Direct Volume Rendering of Curvilinear Volumes. </title> <journal> Computer Graphics, </journal> <volume> 24(5) </volume> <pages> 41-47, </pages> <month> November </month> <year> 1990. </year> <booktitle> Proceedings of the San Diego Workshop on Volume Visualization. </booktitle>
Reference-contexts: The most important aspect is how to deal with the computational complexity of the ray/cell intersection testing requirements. Approaches taken include interpolating the grid to a rectilinear one, finding the first intersection and then stepping through the cells, and techniques related to scanline algorithms. Wilhelms, et al. <ref> [WCA + 90] </ref> investigate the tradeoffs between resampling a curvilinear grid to a rectilinear one before volume rendering, and direct volume rendering on the curvilinear grid using a raycasting algorithm. <p> Inverse distance weighted interpolation has the advantages of being fairly fast and rotationally invariant, but has the disadvantage that it does not have C 0 continuity along interior faces of the grid <ref> [WCA + 90, Ram91] </ref>. The opacity value obtained by the transfer function mapping of the scalar value to opacity is weighted by the distance along the ray through that cell. Single-phase Algorithm The first algorithm proceeds to collect samples and composite them into the image in a single phase.
Reference: [WCH + 87] <author> Karl-Heinz A. Winkler, Jay W. Chalmers, Stephen W. Hodson, Paul R. Wood-ward, and Norman J. Zabusky. </author> <title> A Numerical Laboratory. </title> <journal> Physics Today, </journal> <pages> pages 28-37, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: In many cases, the most time-consuming and difficult part of a given numerical experiment will be the analysis, understanding, and verification of the contents of the voluminous results of the computation <ref> [WCH + 87, SS89b] </ref>. The most useful visualization tools allow a researcher to interactively explore a dataset.
Reference: [Wes89] <author> Lee Westover. </author> <title> Interactive Volume Rendering. </title> <booktitle> In Conference Proceedings of the Chapel Hill Workshop on Volume Visualization. </booktitle> <institution> Department of Computer Science, University of North Carolina at Chapel Hill, </institution> <year> 1989. </year>
Reference-contexts: There are two approaches to the projection method for volume rendering: cell projection [UK88, MHC90, ST90, WV91, Wil92c, SH92, Luc92, VW93] and splatting <ref> [Wes89, Wes90, Neu92, Elv92, LH91] </ref>. Both of these methods begin by creating a visibility sort of the cells or nodes in order to ensure correct ordering of compositing operations. For rectilinear datasets a visibility sort is trivial, however, it is more complex for more general grids. <p> Cell projection and splatting are both object-space algorithms in which cells or nodes are projected to the screen <ref> [UK88, Wes89, Wes90, LH91, WV91, ST90, MHC90] </ref>. These methods require that the cells or nodes be sorted into a visibility ordering and projected either front-to-back or back-to-front. Methods using shear transformations first rotate the volume in memory so that it is view aligned. <p> To achieve its ultimate usefulness as an exploratory tool, volume rendering must run at interactive speeds. There have been numerous approaches to speeding up the volume rendering process using sequential algorithms <ref> [Wes89, Wes90, LH91, Lev90, WV91, DH92, VW93, Mal93, TL93] </ref>. Many of these algorithms trade image quality for speed, typically under user control. Hibbard and Santek make the case that interactivity is the most important feature in a system for the analysis of volumetric datasets [HS89]. <p> Lee Westover has published work in which the goal of interactive rendering is pursued through the use of a splatting algorithm, along with successive refinement of images and table-driven mappings for shading and filtering <ref> [Wes89, Wes90] </ref>. This approach has been extended by Laur & Hanrahan [LH91] to use a pyramidal representation and hierarchical enumeration of the data with progressive refinement to achieve interactivity, but with some degradation in image quality. Cell projection approaches allow more accuracy in the determination of contributions to the image.
Reference: [Wes90] <author> Lee Westover. </author> <title> Footprint Evaluation for Volume Rendering. </title> <journal> Computer Graphics, </journal> <volume> 24(4), </volume> <year> 1990. </year> <note> Proceedings of SIGGRAPH '90. </note>
Reference-contexts: There are two approaches to the projection method for volume rendering: cell projection [UK88, MHC90, ST90, WV91, Wil92c, SH92, Luc92, VW93] and splatting <ref> [Wes89, Wes90, Neu92, Elv92, LH91] </ref>. Both of these methods begin by creating a visibility sort of the cells or nodes in order to ensure correct ordering of compositing operations. For rectilinear datasets a visibility sort is trivial, however, it is more complex for more general grids. <p> Cell projection and splatting are both object-space algorithms in which cells or nodes are projected to the screen <ref> [UK88, Wes89, Wes90, LH91, WV91, ST90, MHC90] </ref>. These methods require that the cells or nodes be sorted into a visibility ordering and projected either front-to-back or back-to-front. Methods using shear transformations first rotate the volume in memory so that it is view aligned. <p> To achieve its ultimate usefulness as an exploratory tool, volume rendering must run at interactive speeds. There have been numerous approaches to speeding up the volume rendering process using sequential algorithms <ref> [Wes89, Wes90, LH91, Lev90, WV91, DH92, VW93, Mal93, TL93] </ref>. Many of these algorithms trade image quality for speed, typically under user control. Hibbard and Santek make the case that interactivity is the most important feature in a system for the analysis of volumetric datasets [HS89]. <p> Lee Westover has published work in which the goal of interactive rendering is pursued through the use of a splatting algorithm, along with successive refinement of images and table-driven mappings for shading and filtering <ref> [Wes89, Wes90] </ref>. This approach has been extended by Laur & Hanrahan [LH91] to use a pyramidal representation and hierarchical enumeration of the data with progressive refinement to achieve interactivity, but with some degradation in image quality. Cell projection approaches allow more accuracy in the determination of contributions to the image.
Reference: [WH79] <author> Thomas Wright and John Humbrecht. </author> <title> ISOSURF An Algorithm for Plotting Iso-Valued Surfaces of a Function of Three Variables. </title> <booktitle> In Proceedings of SIGGRAPH '79, </booktitle> <pages> pages 182-189, </pages> <year> 1979. </year>
Reference-contexts: As early as the mid-1970s researchers were developing algorithms to generate three-dimensional geometric representations by connecting contour lines of adjacent two-dimensional contour maps [FKU77, CS78, GD82]. In 1979 an algorithm was presented that would generate a three-dimensional contour map by operating directly on the three-dimensional data <ref> [WH79] </ref>. More recently, the marching cubes algorithm [LC87] generates an isosurface by examining the eight vertices of each voxel and determining any surface intersections. Intersections along voxel edges are approximated using linear interpolation and a triangle mesh for the isosurface is returned.
Reference: [Whi92] <author> Scott Whitman. </author> <title> Multiprocessor Methods for Computer Graphics Rendering. </title> <editor> Jones and Bartlett, </editor> <year> 1992. </year>
Reference-contexts: The total execution time over all processors (T n fi n) can be broken down into components which indicate the sources of overhead that contribute to declining efficiency (such as load imbalance) <ref> [Whi92] </ref>. Measures used in this thesis to analyze and present results of parallel algorithm performance are summarized in table 2.1. 2.2.3 Specialized Architectures for Volume Rendering Early efforts to achieve interactive rates for rendering of voxel-based objects come primarily from the medical imaging and solid modeling communities. <p> Processors can be added as required to the hierarchy. The system provides shared memory and several levels of caching. The reported work used a 48 processor system. The basic algorithm is a raycasting algorithm for rectilinear volumes. An approach similar to a task adaptive technique described by Whitman <ref> [Whi92] </ref> is used for task decomposition. The data is distributed among the processors in an interleaved fashion. Allocating portions of the dataset to the processors in round-robin order prevents the formation of hot spots that can occur when several processors attempt to read data that is located on one processor. <p> Parallelization of the raytracing algorithm on a distributed-memory MIMD architecture using an image-space decomposition is presented by Badouel [BP90]. This algorithm depends on an implementation of shared virtual memory with local caching. Whitman explores several image-space decompositions and scheduling strategies on a shared-memory MIMD machine <ref> [Whi92] </ref>. A detailed analysis of the overhead incurred in the parallelization is presented. Fuchs [Fuc77] presents an algorithm for a MIMD architecture with distributed memory. <p> The visible regions in each cell are reconstructed from edge segments. A conflict detection and backoff strategy is given for the parallelization of the reconstruction step. The algorithm was implemented on a Sequent Balance 21000, which has 16 processors and shared memory, with almost linear speedup achieved. Whitman <ref> [Whi92] </ref> explores several decomposition and scheduling schemes for the image-space decomposition of a scan conversion algorithm on the BBN GP1000. The decompositions include static data nonadaptive, data adaptive, and task adaptive. Techniques for determining the components of overhead were developed and empirical results are given for several images. <p> This is because the more effective load balancing provides near-linear speedup as n increases. It may be possible to obtain the efficiency gained through the use of large tile sizes while still maintaining good load balancing as n grows large, using a task-adaptive approach to task generation <ref> [Whi92, NL92] </ref>.
Reference: [Wil92a] <author> Peter L. Williams. </author> <title> Interactive Splatting of Nonrectilinear Volumes. </title> <booktitle> In Visualization '92, </booktitle> <pages> pages 37-44. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1992. </year>
Reference-contexts: The hardware-renderable primitives are scaled depending on the level of resolution requested by the user. Progressive refinement is utilized to obtain interactive rates. Williams <ref> [Wil92a, Wil92b, Wil92c] </ref> explores several approximations to the algorithm of of Shirley and Tuchman [ST90] for projecting tetrahedral cells which trade image quality for speed and compares the results. <p> The visibility ordering requirements remain the same. Max, Hanrahan, & Crawfis [MHC90] give an algorithm for the projection of any collection of sortable convex polyhedra. Shirley and Tuchman [ST90] present an algorithm for efficiently projecting tetrahedral cells in which each cell is represented with hardware renderable semi-transparent triangles. Williams <ref> [Wil92a, Wil92b, Wil92c] </ref> gives algorithms for visibility ordering and rendering of nonrectilinear volumes. The algorithm of Shirley and Tuchman [ST90] for projecting tetrahedral cells is modified using several different approximations which trade image quality for speed and the results are compared. <p> A 256x256 image is rendered in 16 seconds on 110 processors at an efficiency of 57%. Remote memory latency, switch contention, and load imbalance were found to be the primary inefficiencies. This work is described in more detail in section 4.3.2. Williams <ref> [Wil92a, Wil92c] </ref> has presented an algorithm for visibility ordering and projection of nonrectilinear volumes. A parallelization of the algorithm is given and its implementation on a 6 processor Silicon Graphics 4D/360 VGX is discussed. The sequential algorithm is very fast, about 1-3 orders of magnitude faster than raycasting.
Reference: [Wil92b] <author> Peter L. Williams. </author> <title> Visiblity Ordering Meshed Polyhedra. </title> <journal> ACM Transactions on Graphics, </journal> <volume> 11(2) </volume> <pages> 103-126, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: The hardware-renderable primitives are scaled depending on the level of resolution requested by the user. Progressive refinement is utilized to obtain interactive rates. Williams <ref> [Wil92a, Wil92b, Wil92c] </ref> explores several approximations to the algorithm of of Shirley and Tuchman [ST90] for projecting tetrahedral cells which trade image quality for speed and compares the results. <p> The visibility ordering requirements remain the same. Max, Hanrahan, & Crawfis [MHC90] give an algorithm for the projection of any collection of sortable convex polyhedra. Shirley and Tuchman [ST90] present an algorithm for efficiently projecting tetrahedral cells in which each cell is represented with hardware renderable semi-transparent triangles. Williams <ref> [Wil92a, Wil92b, Wil92c] </ref> gives algorithms for visibility ordering and rendering of nonrectilinear volumes. The algorithm of Shirley and Tuchman [ST90] for projecting tetrahedral cells is modified using several different approximations which trade image quality for speed and the results are compared.
Reference: [Wil92c] <author> Peter Lawrence Williams. </author> <title> Interactive Direct Volume Rendering of Curvilinear and Unstructured Data. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1992. </year>
Reference-contexts: There are two approaches to the projection method for volume rendering: cell projection <ref> [UK88, MHC90, ST90, WV91, Wil92c, SH92, Luc92, VW93] </ref> and splatting [Wes89, Wes90, Neu92, Elv92, LH91]. Both of these methods begin by creating a visibility sort of the cells or nodes in order to ensure correct ordering of compositing operations. <p> The hardware-renderable primitives are scaled depending on the level of resolution requested by the user. Progressive refinement is utilized to obtain interactive rates. Williams <ref> [Wil92a, Wil92b, Wil92c] </ref> explores several approximations to the algorithm of of Shirley and Tuchman [ST90] for projecting tetrahedral cells which trade image quality for speed and compares the results. <p> The visibility ordering requirements remain the same. Max, Hanrahan, & Crawfis [MHC90] give an algorithm for the projection of any collection of sortable convex polyhedra. Shirley and Tuchman [ST90] present an algorithm for efficiently projecting tetrahedral cells in which each cell is represented with hardware renderable semi-transparent triangles. Williams <ref> [Wil92a, Wil92b, Wil92c] </ref> gives algorithms for visibility ordering and rendering of nonrectilinear volumes. The algorithm of Shirley and Tuchman [ST90] for projecting tetrahedral cells is modified using several different approximations which trade image quality for speed and the results are compared. <p> A 256x256 image is rendered in 16 seconds on 110 processors at an efficiency of 57%. Remote memory latency, switch contention, and load imbalance were found to be the primary inefficiencies. This work is described in more detail in section 4.3.2. Williams <ref> [Wil92a, Wil92c] </ref> has presented an algorithm for visibility ordering and projection of nonrectilinear volumes. A parallelization of the algorithm is given and its implementation on a 6 processor Silicon Graphics 4D/360 VGX is discussed. The sequential algorithm is very fast, about 1-3 orders of magnitude faster than raycasting. <p> Implementations of object-space decompositions for projection or splatting algorithms have been shown to be limited in terms of their scalability by synchronization requirements <ref> [Cha91, Wil92c, 61 Elv92] </ref>. The parallel direct volume rendering algorithm described in the next chapter utilizes interleaved globally-shared memory to store the volumetric dataset.
Reference: [WM92] <author> Peter L. Williams and Nelson Max. </author> <title> A Volume Density Optical Model. </title> <booktitle> In 1992 Workshop on Volume Visualization, </booktitle> <pages> pages 61-68. </pages> <publisher> ACM, </publisher> <year> 1992. </year>
Reference-contexts: Researchers have recently begun to address volume rendering algorithms for more complex computational grids. Williams and Max <ref> [WM92] </ref> give a rigorous analysis of optical models for volume rendering and present a continuous model of volume density which is particularly suitable for rendering scalar fields on irregular grids. Many of the projection approaches for rectilinear grids can be extended to handle more general grids. <p> These can be minimized by the avoidance of step functions in the transfer function. The volume density optical model proposed by Williams and Max <ref> [WM92] </ref> solves this problem by providing an exact solution to the integral inside a cell for piecewise linear transfer functions. Finally, the opacity is used to composite the contribution to the pixel using the standard method described by Porter and Duff [PD84].
Reference: [WMW86] <author> G. Wyville, C. McPheeters, and B. Wyville. </author> <title> Data Structures for Soft Objects. </title> <journal> The Visual Computer, </journal> <volume> 2(4) </volume> <pages> 227-234, </pages> <year> 1986. </year> <month> 133 </month>
Reference-contexts: All of these algorithms generate a geometric representation of a subset of the volumetric dataset. Closely related to the techniques for isosurface generation are those used in the generation of implicit surfaces <ref> [Nor82, WMW86, Blo88] </ref>, and in specialized methods for raytracing to a contour surface [Bli82b, NHK + 85]. 2.1.2 Direct Volume Rendering One drawback to the use of isosurfaces as a means to visualize the contents of volumetric datasets is the fact that this approach inherently presents a subset of the data,
Reference: [WV91] <author> Jane Wilhelms and Allen Van Gelder. </author> <title> A Coherent Projection Approach for Direct Volume Rendering. </title> <journal> Computer Graphics, </journal> <volume> 25(4), </volume> <year> 1991. </year> <note> Proceedings of SIGGRAPH '91. </note>
Reference-contexts: There are two approaches to the projection method for volume rendering: cell projection <ref> [UK88, MHC90, ST90, WV91, Wil92c, SH92, Luc92, VW93] </ref> and splatting [Wes89, Wes90, Neu92, Elv92, LH91]. Both of these methods begin by creating a visibility sort of the cells or nodes in order to ensure correct ordering of compositing operations. <p> It is possible to utilize coherence principles to approximate the contributions at each pixel, reducing the complexity of the integration step at some loss in accuracy <ref> [WV91] </ref>. The processing for each cell will require access to the node values of the cell, as well as access to the pixels it covers. If we are zoomed in on part of the volume all of the cells will still be processed, even if only to trivially clip them. <p> Cell projection and splatting are both object-space algorithms in which cells or nodes are projected to the screen <ref> [UK88, Wes89, Wes90, LH91, WV91, ST90, MHC90] </ref>. These methods require that the cells or nodes be sorted into a visibility ordering and projected either front-to-back or back-to-front. Methods using shear transformations first rotate the volume in memory so that it is view aligned. <p> To achieve its ultimate usefulness as an exploratory tool, volume rendering must run at interactive speeds. There have been numerous approaches to speeding up the volume rendering process using sequential algorithms <ref> [Wes89, Wes90, LH91, Lev90, WV91, DH92, VW93, Mal93, TL93] </ref>. Many of these algorithms trade image quality for speed, typically under user control. Hibbard and Santek make the case that interactivity is the most important feature in a system for the analysis of volumetric datasets [HS89]. <p> Progressive refinement is utilized to obtain interactive rates. Williams [Wil92a, Wil92b, Wil92c] explores several approximations to the algorithm of of Shirley and Tuchman [ST90] for projecting tetrahedral cells which trade image quality for speed and compares the results. Wilhelms and Van Gelder <ref> [WV91] </ref> describe a projection algorithm for rectilinear volumes in which a template for projection is formed and used to speed the scan conversion of cells. They also compare different approaches to the approximation of the integrals required with respect to speed and image accuracy and quality. <p> Van Gelder and Wilhelms [VW93] extend their work on fast projection algorithms <ref> [WV91] </ref> using hardware renderable primitives to handle curvilinear grids. Several methods which trade image quality for speed are presented, along with an algorithm for visibility ordering and a technique for improving the results of using hardware compositing. Raycasting is also fairly easily extended to handle more complex grids.
Reference: [ZT89] <author> O. C. Zienkiewicz and R. L. Taylor. </author> <title> The Finite Element Method. </title> <publisher> McGraw-Hill Book Company, </publisher> <year> 1989. </year>
Reference-contexts: More general grids are commonly used by researchers to generate volumetric datasets. Nomenclature for volumetric grids is hardly standardized; a brief overview of grid types is given in [SK90] and more detailed information can be found in <ref> [Fle88, ZT89] </ref>. We will call a single data point that has been sampled or computed a node. Two neighboring nodes may be said to define an edge, and three or more define a face. <p> Unstructured computational grids in &lt; 3 made up of a collection of tetrahedral or hexahedral cells that have been shaped are also common in computational fluid dynamics and finite element analysis applications <ref> [ZT89] </ref>. Typically the definition of these grids is given as a list of cells, defined by pointers into a list of nodes. There is no regular rectilinear array of nodes in computational space, as is the case with curvilinear datasets. <p> These array-organized grids are also called structured grids [SK90]. Computational grids in &lt; 3 that are not array-organized (sometimes called unstructured grids [SK90]) and are made up of tetrahedral or hexahedral cells that have been shaped are also common in 67 computational fluid dynamics and finite element analysis applications <ref> [ZT89] </ref>. Typically the definition of these grids is given as a list of cells, defined by pointers into a list of nodes. Thus information on shared faces and neighboring cells is not inherent in the data structure.
References-found: 111

