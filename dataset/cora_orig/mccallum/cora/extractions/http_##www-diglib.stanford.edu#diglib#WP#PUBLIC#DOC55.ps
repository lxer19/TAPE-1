URL: http://www-diglib.stanford.edu/diglib/WP/PUBLIC/DOC55.ps
Refering-URL: http://www.public.iastate.edu/~CYBERSTACKS/Aristotle.htm
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fmarko,shoham,yygirlg@cs.stanford.edu  
Title: An Adaptive Agent for Automated Web Browsing  
Author: Marko Balabanovic Yoav Shoham Yeogirl Yun 
Address: Stanford, CA 94305, USA  
Affiliation: Department of Computer Science, Stanford University,  
Note: Stanford University Digital Library Project Working Paper SIDL-WP-1995-0023 Please Do Not Distribute  
Abstract: The current exponential growth of the Internet precipitates a need for new tools to help people cope with the volume of information. To complement recent work on creating searchable indexes of the WorldWide Web and systems for filtering incoming e-mail and Usenet news articles, we describe a system which learns to browse the Internet on behalf of a user. Every day it presents a selection of interesting Web pages. The user evaluates each page, and given this feedback the system adapts and attempts to produce better pages the following day. After demonstrating that our system is able to learn a model of a user with a single well-defined interest, we present an initial experiment where over the course of 24 days the output of our system was compared to both randomly-selected and human-selected pages. It consistently performed better than the random pages, and was better than the human-selected pages half of the time.
Abstract-found: 1
Intro-found: 1
Reference: [ Armstrong et al., 1995 ] <author> Robert Armstrong, Dayne Freitag, Thorsten Joachims, and Tom Mitchell. Web-Watcher: </author> <title> A learning apprentice for the World-Wide Web. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on Information Gathering from Heterogenous, Distributed Resources, </booktitle> <address> Stanford, CA, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: Due to the recency of this paradigm there has not yet been sufficient experimentation to allow meaningful comparisons with the other approaches described. Assisted browsing systems Rather than providing the user with selected pages, some systems instead assist the user in their browsing. The WebWatcher system <ref> [ Armstrong et al., 1995 ] </ref> requires the user to state a particular goal, and then interactively offers advice on which link to follow next given the page the user is looking at.
Reference: [ Balabanovic and Shoham, 1995 ] <author> Marko Balabanovic and Yoav Shoham. </author> <title> Learning information retrieval agents: Experiments with automaed web browsing. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on Information Gathering from Heterogenous, Distributed Resources, </booktitle> <address> Stanford, CA, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: The domain described is an appropriate testing ground for basic AI techniques, especially search and machine learning algorithms. The problem we tackle was originally set as a term project to an AI programming class at Stanford University, as described in <ref> [ Balabanovic and Shoham, 1995 ] </ref> . In the remainder of this paper we describe our current prototype implementation, and give some early results from initial experiments. 2 Implementation 2.1 Overview The system runs in discrete cycles. The behavior of one cycle can be summarized as follows: 1.
Reference: [ Belkin and Croft, 1992 ] <author> Nicholas J. Belkin and W. Bruce Croft. </author> <title> Information filtering and information retrieval: </title> <journal> Two sides of the same coin? Communications of the ACM, </journal> <volume> 35(12) </volume> <pages> 29-38, </pages> <month> December </month> <year> 1992. </year>
Reference: [ Berners-Lee et al., 1992 ] <author> T. Berners-Lee, R. Cailliau, J-F. Groff, and B. Pollermann. </author> <title> World-Wide Web: The information universe. </title> <journal> Electronic Networking: Research, Applications and Policy, </journal> <volume> 1(2) </volume> <pages> 52-58, </pages> <month> Spring </month> <year> 1992. </year>
Reference-contexts: 1 Introduction It is becoming a cliche to talk about the explosion of information available on the Internet, and the corresponding increase in usage. This is particularly true of the World-Wide Web <ref> [ Berners-Lee et al., 1992 ] </ref> and its associated browsers, which provide easy access to a wider audience. The inevitable result of this growth is that current technologies for accessing information on the Web are inadequate.
Reference: [ Buckley et al., 1995 ] <author> Chris Buckley, Gerard Salton, James Allan, and Amit Singhal. </author> <title> Automatic query expansion using SMART: </title> <booktitle> TREC-3. In Proceedings of the 3 rd Text REtrieval Conference, </booktitle> <address> Gaithersburg, MD, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: For computational reasons the prototype described here used vectors truncated to contain only the 10 highest weighted terms. Recent experiments have shown that both retaining many terms for massive query expansion <ref> [ Buckley et al., 1995 ] </ref> and carefully selecting a smaller number of terms [ Yochum, 1995 ] can yield comparably good results.
Reference: [ Davis, 1994 ] <author> Glenn Davis. </author> <title> Cool site of the day, </title> <note> 1994. http://www.infi.net/cool.html. </note>
Reference-contexts: In this way neither the user nor the experimenter knew which page comes from which source. A log was kept of the evaluations received for each of the three sources. The human-selected page described is the "Cool Site of the Day" link <ref> [ Davis, 1994 ] </ref> . Note that this is not tuned to a particular user. The random pages are selected from a static list of several hundred thousand URLs, checked for accessibility. The system does not use the evaluations of these control pages to update its weights.
Reference: [ Foltz and Dumais, 1992 ] <author> Peter W. Foltz and Susan T. Dumais. </author> <title> Personalized information delivery: An analysis of information filtering methods. </title> <journal> Communications of the ACM, </journal> <volume> 35(12) </volume> <pages> 51-60, </pages> <month> December </month> <year> 1992. </year>
Reference: [ Frakes, 1992 ] <author> William B. Frakes. </author> <title> Stemming algorithms. </title> <editor> In William B. Frakes and Ricardo Baeza-Yates, editors, </editor> <booktitle> Information Retrieval Data Structures and Algorithms, </booktitle> <pages> pages 131-160. </pages> <publisher> Prentice Hall, Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992. </year>
Reference-contexts: This reduces words to their `stems', and thus decreases redundancy. For instance, computer, computers, computing and computability all reduce to comput. We use the Porter suffix-stripping algorithm [ Porter, 1980 ] , as implemented in <ref> [ Frakes, 1992 ] </ref> . We calculate word weights using a TFIDF 1 scheme, normalizing for document length, following recommendations in [ Salton and Buckley, 1988 ] .
Reference: [ Goldberg et al., 1992 ] <author> David Goldberg, David Nichols, Brain M. Oki, and Douglas Terry. </author> <title> Using collaborative filtering to weave an information tapestry. </title> <journal> Communications of the ACM, </journal> <volume> 35(12) </volume> <pages> 61-70, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: The key process here is to match up similar users, and make use of evaluations or annotations supplied by others. Examples of such systems are Tapestry <ref> [ Goldberg et al., 1992 ] </ref> for e-mail, Firefly 4 for music and Webhunter [ Lashkari, 1995 ] for Web pages. Due to the recency of this paradigm there has not yet been sufficient experimentation to allow meaningful comparisons with the other approaches described.
Reference: [ Harman, 1995 ] <author> Donna Harman. </author> <booktitle> Overview of the third Text REtrieval Conference (TREC-3). In Proceedings of the 3 rd Text REtrieval Conference, </booktitle> <address> Gaithersburg, MD, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: Thus it is more important not only that the agent have a model of the user but also that the user has a model of the agent, in order to build up trust. 3 As characterized by the "ad-hoc" queries in the TREC conferences <ref> [ Harman, 1995 ] </ref> . 9 Social or collaborative filtering systems Social filtering systems share our goal described in section 5 of capitalizing on the shared interests of users. The key process here is to match up similar users, and make use of evaluations or annotations supplied by others. <p> More recently experiments in the TREC-3 conference showed similar results, with automatically generated profiles for the routing task outperforming even skilled human searchers using an interactive IR system <ref> [ Harman, 1995 ] </ref> .
Reference: [ Kibler and Aha, 1987 ] <author> Dennis Kibler and David W. Aha. </author> <title> Learning representative exemplars of concepts: An initial case study. </title> <booktitle> In Proceedings of the 4 th International Workshop on Machine Learning, </booktitle> <address> Irvine, CA, </address> <year> 1987. </year>
Reference-contexts: In machine learning terms this is a very simple variant of an exemplar-based scheme <ref> [ Kibler and Aha, 1987 ] </ref> , where we incrementally move a single prototype point and classify instances according to their distance from this point. 2.5 User Interface The primary way of accessing the system is through HTML forms.
Reference: [ Lashkari, 1995 ] <author> Yezdi Lashkari. </author> <title> Feature guided automated collaborative filtering. </title> <type> Master's thesis, </type> <institution> MIT Department of Media Arts and Sciences, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: The key process here is to match up similar users, and make use of evaluations or annotations supplied by others. Examples of such systems are Tapestry [ Goldberg et al., 1992 ] for e-mail, Firefly 4 for music and Webhunter <ref> [ Lashkari, 1995 ] </ref> for Web pages. Due to the recency of this paradigm there has not yet been sufficient experimentation to allow meaningful comparisons with the other approaches described. Assisted browsing systems Rather than providing the user with selected pages, some systems instead assist the user in their browsing.
Reference: [ Maes and Kozierok, 1993 ] <editor> Pattie Maes and Robyn Kozierok. </editor> <booktitle> Learning interface agents. In Proccedings of the 11 th National Conference on Artificial Intelligence, </booktitle> <pages> pages 459-465, </pages> <address> Washington, DC, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Lastly, filtering is the act of removing irrelevant items from this stream, whereas IR is the act of finding relevant items in the database. Information filtering as been applied to e-mail <ref> [ Maes and Kozierok, 1993 ] </ref> and Usenet news groups [ Sheth and Maes, 1993; Yan and Garcia-Molina, 1995 ] , using relevance feedback to build user profiles. Several commercial services now offer simple filtering systems for proprietary collections of documents (e.g.
Reference: [ Mauldin and Leavitt, 1994 ] <author> Michael L. Mauldin and John R.R. </author> <title> Leavitt. </title> <booktitle> Web-agent related research at the CMT. In Proceedings of the ACM Special Interest Group on Networked Information Discovery and Retrieval (SIGNIDR-94), </booktitle> <address> McLean, VA, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: The index is built over a collection of documents found by a Web search process, which typically searches exhaustively rather than to fulfill a particular query. Examples of publicly available indexes are Lycos <ref> [ Mauldin and Leavitt, 1994 ] </ref> and WebCrawler (originally described in [ Pinkerton, 1994 ] ). It is not common for Web indexes to provide a relevance feedback facility.
Reference: [ Pinkerton, 1994 ] <author> Brian Pinkerton. </author> <title> Finding what people want: Experiences with the WebCrawler. </title> <booktitle> In The Second International WWW Conference: Mosaic and the Web, </booktitle> <address> Chicago, IL, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: The index is built over a collection of documents found by a Web search process, which typically searches exhaustively rather than to fulfill a particular query. Examples of publicly available indexes are Lycos [ Mauldin and Leavitt, 1994 ] and WebCrawler (originally described in <ref> [ Pinkerton, 1994 ] </ref> ). It is not common for Web indexes to provide a relevance feedback facility. Information filtering systems Although information filtering shares many techniques with retrospective information retrieval, three primary differences were elucidated by Belkin and Croft [ 1992 ] .
Reference: [ Porter, 1980 ] <author> M.F. Porter. </author> <title> An algorithm for suffix stripping. </title> <booktitle> Program, </booktitle> <volume> 14(3) </volume> <pages> 130-137, </pages> <month> July </month> <year> 1980. </year>
Reference-contexts: This reduces words to their `stems', and thus decreases redundancy. For instance, computer, computers, computing and computability all reduce to comput. We use the Porter suffix-stripping algorithm <ref> [ Porter, 1980 ] </ref> , as implemented in [ Frakes, 1992 ] . We calculate word weights using a TFIDF 1 scheme, normalizing for document length, following recommendations in [ Salton and Buckley, 1988 ] .
Reference: [ Rocchio, 1971 ] <author> J.J. Rocchio, Jr. </author> <title> Relevance feedback in information retrieval. In The Smart System| Experiments in Automatic Document Processing, </title> <address> pages 313-323. </address> <publisher> Prentice Hall Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1971. </year>
Reference-contexts: Given this information we update the weights of ~ M by a simple addition: ~ M ~ M + i=1 In the IR literature this is referred to as relevance feedback <ref> [ Rocchio, 1971 ] </ref> . The update rule we use is equivalent to the "Ide regular" rule [ Salton and Buckley, 1990 ] with additional weighting from the users' evaluations.
Reference: [ Salton and Buckley, 1988 ] <author> Gerard Salton and Chris Buckley. </author> <title> Term weighting approaches in automatic text retrieval. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 24(5) </volume> <pages> 513-523, </pages> <year> 1988. </year>
Reference-contexts: For instance, computer, computers, computing and computability all reduce to comput. We use the Porter suffix-stripping algorithm [ Porter, 1980 ] , as implemented in [ Frakes, 1992 ] . We calculate word weights using a TFIDF 1 scheme, normalizing for document length, following recommendations in <ref> [ Salton and Buckley, 1988 ] </ref> .
Reference: [ Salton and Buckley, 1990 ] <author> Gerard Salton and Chris Buckley. </author> <title> Improving retrieval performance by relevance feedback. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41(4) </volume> <pages> 288-297, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Given this information we update the weights of ~ M by a simple addition: ~ M ~ M + i=1 In the IR literature this is referred to as relevance feedback [ Rocchio, 1971 ] . The update rule we use is equivalent to the "Ide regular" rule <ref> [ Salton and Buckley, 1990 ] </ref> with additional weighting from the users' evaluations. In fact Salton and Buckley found that the "Ide dec-hi" rule generally gave better performance, where only one negative-scoring document is included. <p> Any system using relevance feedback will exhibit these advantages to some degree <ref> [ Salton and Buckley, 1990 ] </ref> , so it is surprising that so few of the available Web indexes include this feature. 7 Conclusions Our research was motivated by two beliefs: 1. The rapid expansion of the World-Wide Web necessitates new tools for information discovery. 2.
Reference: [ Salton and McGill, 1983 ] <author> Gerard Salton and Michael J. McGill. </author> <title> An Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: Although this has obvious limitations, in practice many information retrieval systems use single-word schemes successfully, and in any case this is a good place to start. In the vector space information retrieval paradigm documents are represented as vectors <ref> [ Salton and McGill, 1983 ] </ref> . Assume some dictionary vector ~ D, where each element d i is a word. Each document then has a vector ~ V, where element v i is the weight of word d i for that document.
Reference: [ Sheth and Maes, 1993 ] <author> Beerud Sheth and Pattie Maes. </author> <title> Evolving agents for personalized information filtering. </title> <booktitle> In Proceedings of the 9 th IEEE Conference on Artificial Intelligence for Applications, </booktitle> <address> Orlando, FL, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: Lastly, filtering is the act of removing irrelevant items from this stream, whereas IR is the act of finding relevant items in the database. Information filtering as been applied to e-mail [ Maes and Kozierok, 1993 ] and Usenet news groups <ref> [ Sheth and Maes, 1993; Yan and Garcia-Molina, 1995 ] </ref> , using relevance feedback to build user profiles. Several commercial services now offer simple filtering systems for proprietary collections of documents (e.g. Ziff-Davis' Personal View, the San Jose Mercury News' NewsHound). This kind of application is inherently more risky.
Reference: [ Yan and Garcia-Molina, 1995 ] <author> Tak W. Yan and Hector Garcia-Molina. </author> <title> SIFT|a tool for wide-area information dissemination. </title> <booktitle> In Proceedings of the USENIX Technical Conference, </booktitle> <pages> pages 177-186, </pages> <address> New Orleans, LA, </address> <month> January </month> <year> 1995. </year>
Reference-contexts: Lastly, filtering is the act of removing irrelevant items from this stream, whereas IR is the act of finding relevant items in the database. Information filtering as been applied to e-mail [ Maes and Kozierok, 1993 ] and Usenet news groups <ref> [ Sheth and Maes, 1993; Yan and Garcia-Molina, 1995 ] </ref> , using relevance feedback to build user profiles. Several commercial services now offer simple filtering systems for proprietary collections of documents (e.g. Ziff-Davis' Personal View, the San Jose Mercury News' NewsHound). This kind of application is inherently more risky.
Reference: [ Yochum, 1995 ] <author> Julian A. Yochum. </author> <title> Research in automatic profile creation and relevance ranking with LMDS. </title> <booktitle> In Proceedings of the 3 rd Text REtrieval Conference, </booktitle> <address> Gaithersburg, MD, </address> <month> November </month> <year> 1995. </year> <month> 12 </month>
Reference-contexts: For computational reasons the prototype described here used vectors truncated to contain only the 10 highest weighted terms. Recent experiments have shown that both retaining many terms for massive query expansion [ Buckley et al., 1995 ] and carefully selecting a smaller number of terms <ref> [ Yochum, 1995 ] </ref> can yield comparably good results. We intend to perform our own set of experiments to see what works best for this domain. 2.3 Search There is a clear mapping between the problem of searching the Web and the classic AI search paradigm.
References-found: 23

