URL: http://www.cs.umn.edu/Users/dept/users/kumar/final.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Abstract: Contents Project Summary 3 Results from Prior NSF Support 4 1 Introduction 7 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Database mining: A performance perspective. </title> <journal> IEEE Transactions on Knowledge and Data Engg., </journal> <volume> 5(6) </volume> <pages> 914-925, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Classification-rule learning involves finding rules or decision trees that partition the given data into predefined classes. For any realistic problem domain of the classification-rule learning, the set of possible decision trees is too large to be searched exhaustively. All of the existing algorithms, like C4.5 [36] and CDP <ref> [1] </ref>, use local heuristics to construct the decision trees. The computational complexity of these algorithms ranges from O (n log n) with discrete data attributes only, to O (n log 2 n) with continuous data attributes. We have improved the performance of these algorithms and explored their parallel formulations [2].
Reference: [2] <author> M. Ganesh, E.H. Han, V. Kumar, S. Shekhar, and J. Srivastava. </author> <title> Visual data mining: Framework and algorithm development. </title> <type> Technical Report TR-96-021, </type> <institution> Department of Computer Science, University of Min-nesota, Minneapolis, </institution> <year> 1996. </year>
Reference-contexts: The computational complexity of these algorithms ranges from O (n log n) with discrete data attributes only, to O (n log 2 n) with continuous data attributes. We have improved the performance of these algorithms and explored their parallel formulations <ref> [2] </ref>. We can map the classification-learning algorithms based on ID3, like C4.5, on the proposed architecture nicely. The C4.5 algorithm generates a decision tree for the given training data set by recursive partitioning the data. <p> A problem of this size can be solved in approximately half an hour on a 100 teraOps machine. The impact of this capability is tremendous. Very often, the discovery process in data mining has to be guided using visualization tools <ref> [2] </ref>. In such cases, a short turnaround from the mining process is critical. 7 Summary of Proposed Research In this proposal, we have outlined a hierarchical architecture for machines capable of over 100 teraOpS in a 10 year timeframe.
Reference: [3] <author> Ananth Grama, Anshul Gupta, and Vipin Kumar. </author> <title> Isoefficiency function: A scalability metric for parallel algorithms and architectures. </title> <journal> IEEE Parallel and Distributed Technology, Special Issue on Parallel and Distributed Systems: From Theory to Practice, </journal> <volume> 1 </volume> (3):12-21, 1993. Also available as Technical Report TR-93-24, Department of Computer Science, University of Minnesota and from anonymous ftp site ftp.cs.umn.edu, file users/kumar/isoeff-tutorial.ps. 
Reference-contexts: A significant part of applied and analytical parallel computing deals with performance properties up to hundreds of processors. This must be extended to the range of processors in the proposed architecture. Clearly, as the number of processors is increased, the problem size must be increased to maintain efficiency <ref> [3, 32] </ref>. This implies a certain growth rate for the total memory in the system. Furthermore, the solution time may also increase with increasing number of processors. Since we cannot expect to allow arbitrary solution times, this must be factored into the scalability analysis. <p> We refer to such systems as efficiency-scalable. The rate at which the problem size must be increased with increasing number of processors to maintain the efficiency constant is an excellent measure of the scalability of the system <ref> [35, 3] </ref>. We refer to this rate of increase in problem size as the isoefficiency of the parallel system. We have demonstrated the utility of the isoefficiency metric in the context of a variety of problems [32, 15, 11, 14, 33, 29, 27]. <p> The scalability issues for such problems have been explored by Worley [46], Gustafson [17], and Sun and Ni [40]. We have studied these and other scalability metrics extensively <ref> [35, 12, 3] </ref>. We will evaluate the suit 14 ability of these metrics in the context of the proposed architecture.
Reference: [4] <author> Ananth Grama, Vipin Kumar, and Ahmad Sameh. </author> <title> Scalable parallel formulations of the barnes-hut method for n-body simulations. </title> <booktitle> In Supercomputing '94 Proceedings, </booktitle> <year> 1994. </year>
Reference-contexts: Simulations of this magnitude are very useful for understanding various physical phenomena and in applications such as protein synthesis, drug design etc. We have studied parallel formulations of treecodes for particle dynamics on conventional MPPs extensively <ref> [7, 4, 6] </ref> and have demonstrated excellent scalability and performance. Many other applications of hierarchical methods have similar computational requirements. These applications include a variety of inverse problems arising in the solution of integral equations. The dense linear systems in these methods are solved using iterative solvers.
Reference: [5] <author> Ananth Grama, Vipin Kumar, and Ahmad Sameh. </author> <title> Parallel iterative solvers and preconditioners using approximate hierarchical methods. </title> <booktitle> In Proceedings of the Copper Mountain Conference on Iterative Methods, </booktitle> <year> 1996. </year>
Reference-contexts: This corresponds to a large number of variables. Solving for discretizations corresponding to a million boundary elements are desirable. The convergence of these solvers is accelerated using scalable preconditioning techniques. We have used our parallel formulations of hierarchical methods for developing dense solvers and preconditioners <ref> [5, 6] </ref>. We have demonstrated the excellent performance and scalability of these methods. Parallel formulations of hierarchical methods map naturally to the hierarchical architecture proposed. The top level nodes of the tree are duplicated across the processors.
Reference: [6] <author> Ananth Grama, Vipin Kumar, and Ahmad Sameh. </author> <title> Parallel matrix-vector product using hierarchical methods. </title> <booktitle> In Proceedings of Supercomputing '95, </booktitle> <address> San Diego, CA, </address> <year> 1995. </year>
Reference-contexts: Simulations of this magnitude are very useful for understanding various physical phenomena and in applications such as protein synthesis, drug design etc. We have studied parallel formulations of treecodes for particle dynamics on conventional MPPs extensively <ref> [7, 4, 6] </ref> and have demonstrated excellent scalability and performance. Many other applications of hierarchical methods have similar computational requirements. These applications include a variety of inverse problems arising in the solution of integral equations. The dense linear systems in these methods are solved using iterative solvers. <p> This corresponds to a large number of variables. Solving for discretizations corresponding to a million boundary elements are desirable. The convergence of these solvers is accelerated using scalable preconditioning techniques. We have used our parallel formulations of hierarchical methods for developing dense solvers and preconditioners <ref> [5, 6] </ref>. We have demonstrated the excellent performance and scalability of these methods. Parallel formulations of hierarchical methods map naturally to the hierarchical architecture proposed. The top level nodes of the tree are duplicated across the processors.
Reference: [7] <author> Ananth Grama, Vipin Kumar, and Ahmed Sameh. </author> <title> On n-body simulations using message passing parallel computers. </title> <booktitle> In Proceedings of the SIAM Conference on Parallel Processing, </booktitle> <address> San Francisco, </address> <year> 1995. </year>
Reference-contexts: Simulations of this magnitude are very useful for understanding various physical phenomena and in applications such as protein synthesis, drug design etc. We have studied parallel formulations of treecodes for particle dynamics on conventional MPPs extensively <ref> [7, 4, 6] </ref> and have demonstrated excellent scalability and performance. Many other applications of hierarchical methods have similar computational requirements. These applications include a variety of inverse problems arising in the solution of integral equations. The dense linear systems in these methods are solved using iterative solvers.
Reference: [8] <author> Ananth Y. Grama, V. Kumar, S. Ranka, and V. Singh. </author> <title> On architecture independent design and analysis of parallel programs. </title> <type> Technical report, </type> <institution> University of Minnesota, </institution> <address> Minneapolis, 55455, </address> <year> 1996. </year>
Reference-contexts: A variety of promising technologies will be explored as a part of this research. Realistic machine models will be developed for VLIW compilation. A key observation that can be made from optimized codes today is the fact that efficient serial algorithms are based on efficient parallel algorithms <ref> [8] </ref>. For example, most matrix algorithms are based on blocking the matrix, much the same as parallel algorithms for the same problem [11]. This is expected, since the core objective of localizing remote accesses is common to both serial and parallel algorithms. <p> The scope of these models in the space of architectures and algorithms is limited. None of these models are designed to handle hierarchical architecture models. We propose to develop abstract models for hierarchical machines <ref> [8] </ref>. 13 5.2 Metrics for Algorithm Analysis The large number of PEs in the system imposes significant requirements on the scalability of the algorithm-architecture combination [35, 12]. A significant part of applied and analytical parallel computing deals with performance properties up to hundreds of processors.
Reference: [9] <author> Anshul Gupta, George Karypis, and Vipin Kumar. </author> <title> Highly scalable parallel algorithms for sparse matrix factorization. </title> <type> Technical Report 94-63, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN, </institution> <year> 1994. </year> <note> Submitted for publication in IEEE Transactions on Parallel and Distributed Computing. Available on WWW at URL http://www.cs.umn.edu/~karypis/papers/sparse-cholesky.ps. </note>
Reference-contexts: One way of providing robust preconditioners is to combine the strengths of iterative methods (smaller memory requirement, faster solution time), with the power of direct methods (robustness); thus creating hierarchical preconditioning methods. We have studied various aspects of sparse linear system solvers on conventional parallel computers <ref> [9, 15, 28, 26, 22, 19, 23, 24, 20] </ref>. One such preconditioning technique can be based on the algorithm developed by Hu, Lou and Sameh [18] that uses a domain decomposition into overlapping domains to produce robust preconditioners that significantly outperform preconditioners based on incomplete LU factorization.
Reference: [10] <author> Anshul Gupta, George Karypis, and Vipin Kumar. </author> <title> A highly scalable parallel algorithm for sparse matrix factorization. </title> <journal> IEEE Transactions on Parallel and Distributed Systems (Submitted), </journal> <note> 1995. A short version of this paper won the Outstanding Student Paper Award from the Supercomputing 94 conference. </note>
Reference: [11] <author> Anshul Gupta and Vipin Kumar. </author> <title> The scalability of Matrix Multiplication Algorithms on parallel computers. </title> <type> Technical Report TR 91-54, </type> <institution> Computer Science Department, University of Minnesota, Minneapolis, MN, </institution> <year> 1991. </year> <note> A short version appears in Proceedings of International Conference on Parallel Processing, pages III-115-III-119, 1993. Available via anonymous ftp from ftp.cs.umn.edu at users/kumar/matrix.ps. </note>
Reference-contexts: A key observation that can be made from optimized codes today is the fact that efficient serial algorithms are based on efficient parallel algorithms [8]. For example, most matrix algorithms are based on blocking the matrix, much the same as parallel algorithms for the same problem <ref> [11] </ref>. This is expected, since the core objective of localizing remote accesses is common to both serial and parallel algorithms. This lends hope to the development of a machine model for the development of fast serial algorithms. Efficient compilers can then be built around this abstract machine model. <p> We refer to this rate of increase in problem size as the isoefficiency of the parallel system. We have demonstrated the utility of the isoefficiency metric in the context of a variety of problems <ref> [32, 15, 11, 14, 33, 29, 27] </ref>. We have also established the relationship of the isoefficiency metric to other fixed time and fixed memory metrics. Memory Scaling Metrics The rate of growth of problem size may also be constrained by the amount of memory in the parallel computer.
Reference: [12] <author> Anshul Gupta and Vipin Kumar. </author> <title> Performance properties of large scale parallel systems. </title> <journal> Journal of Parallel and Distributed Computing (special issue on supercomputer performance), </journal> <volume> 19(3), </volume> <month> November </month> <year> 1993. </year> <note> Also available as Technical Report 92-32, </note> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN. </institution> <note> Available via anonymous ftp from ftp.cs.umn.edu at users/kumar/performance.ps. </note>
Reference-contexts: None of these models are designed to handle hierarchical architecture models. We propose to develop abstract models for hierarchical machines [8]. 13 5.2 Metrics for Algorithm Analysis The large number of PEs in the system imposes significant requirements on the scalability of the algorithm-architecture combination <ref> [35, 12] </ref>. A significant part of applied and analytical parallel computing deals with performance properties up to hundreds of processors. This must be extended to the range of processors in the proposed architecture. <p> The scalability issues for such problems have been explored by Worley [46], Gustafson [17], and Sun and Ni [40]. We have studied these and other scalability metrics extensively <ref> [35, 12, 3] </ref>. We will evaluate the suit 14 ability of these metrics in the context of the proposed architecture.
Reference: [13] <author> Anshul Gupta and Vipin Kumar. </author> <title> A scalable parallel algorithm for sparse matrix factorization. </title> <type> Technical Report 94-19, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN, </institution> <year> 1994. </year> <note> A shorter version appears in Supercomputing '94. TR available in users/kumar/sparse-cholesky.ps at anonymous FTP site ftp.cs.umn.edu. </note>
Reference: [14] <author> Anshul Gupta and Vipin Kumar. </author> <title> The scalability of FFT on parallel computers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(8) </volume> <pages> 922-932, </pages> <month> August </month> <year> 1993. </year> <note> Available as a Technical Report TR 90-53, </note> <institution> Computer Science Department, University of Minnesota. </institution> <note> Available via anonymous ftp from ftp.cs.umn.edu at users/kumar/fft.ps. 19 </note>
Reference-contexts: We refer to this rate of increase in problem size as the isoefficiency of the parallel system. We have demonstrated the utility of the isoefficiency metric in the context of a variety of problems <ref> [32, 15, 11, 14, 33, 29, 27] </ref>. We have also established the relationship of the isoefficiency metric to other fixed time and fixed memory metrics. Memory Scaling Metrics The rate of growth of problem size may also be constrained by the amount of memory in the parallel computer.
Reference: [15] <author> Anshul Gupta, Vipin Kumar, and A. H. Sameh. </author> <title> Performance and scalability of preconditioned conjugate gradient methods on parallel computers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <note> 1995 (To Appear). Also available as Technical Report TR 92-64, </note> <institution> Department of Computer Science, University of Minnesota, </institution> <address> Minneapolis, MN. </address> <booktitle> A short version appears in Proceedings of the Sixth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 664-674, </pages> <year> 1993. </year>
Reference-contexts: We refer to this rate of increase in problem size as the isoefficiency of the parallel system. We have demonstrated the utility of the isoefficiency metric in the context of a variety of problems <ref> [32, 15, 11, 14, 33, 29, 27] </ref>. We have also established the relationship of the isoefficiency metric to other fixed time and fixed memory metrics. Memory Scaling Metrics The rate of growth of problem size may also be constrained by the amount of memory in the parallel computer. <p> One way of providing robust preconditioners is to combine the strengths of iterative methods (smaller memory requirement, faster solution time), with the power of direct methods (robustness); thus creating hierarchical preconditioning methods. We have studied various aspects of sparse linear system solvers on conventional parallel computers <ref> [9, 15, 28, 26, 22, 19, 23, 24, 20] </ref>. One such preconditioning technique can be based on the algorithm developed by Hu, Lou and Sameh [18] that uses a domain decomposition into overlapping domains to produce robust preconditioners that significantly outperform preconditioners based on incomplete LU factorization.
Reference: [16] <author> Anshul Gupta, Vipin Kumar, and Ahmed Sameh. </author> <title> Performance and scalability of preconditioned conjugate gradient methods on parallel computers. </title> <type> Technical Report TR 92-64, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN, </institution> <year> 1992. </year> <booktitle> A short version appears in the Proceedings of the Sixth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 664-674, </pages> <year> 1993. </year> <note> Available via anonymous ftp from ftp.cs.umn.edu at users/kumar/conjugate-gradient.ps. </note>
Reference: [17] <author> John L. Gustafson. </author> <title> Reevaluating Amdahl's law. </title> <journal> Communications of the ACM, </journal> <volume> 31(5) </volume> <pages> 532-533, </pages> <year> 1988. </year>
Reference-contexts: The memory scaling characteristics of the application determine the overall memory available in the system. The problem size is increased at the fastest rate allowed by the available memory. The resulting performance characteristics determine the scalability of the system. These metrics have been investigated by Worley [46], Gustafson <ref> [17] </ref> and Sun and Ni [40]. Fixed Time Metrics In many situations, the rate of growth of problem size is dictated by the time available on the machine to solve the problem. <p> In these cases, the problem size is increased with number of processors in such a way that the parallel runtime remains constant. The scalability issues for such problems have been explored by Worley [46], Gustafson <ref> [17] </ref>, and Sun and Ni [40]. We have studied these and other scalability metrics extensively [35, 12, 3]. We will evaluate the suit 14 ability of these metrics in the context of the proposed architecture.
Reference: [18] <author> Dan Hu, Felix Lou, and Ahmed Sameh. </author> <title> Parallel iterative solvers for almost block-diagonal linear systems. </title> <type> Technical Report CS-96-000, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1996. </year>
Reference-contexts: We have studied various aspects of sparse linear system solvers on conventional parallel computers [9, 15, 28, 26, 22, 19, 23, 24, 20]. One such preconditioning technique can be based on the algorithm developed by Hu, Lou and Sameh <ref> [18] </ref> that uses a domain decomposition into overlapping domains to produce robust preconditioners that significantly outperform preconditioners based on incomplete LU factorization. This algorithm, decomposes the domain into k overlapping domains. Let M be the matrix that corresponds to the overlap.
Reference: [19] <author> G. Karypis and V. Kumar. </author> <title> Analysis of multilevel graph partitioning. </title> <type> Technical Report TR 95-037, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/~karypis/papers/mlevel analysis.ps. </note>
Reference-contexts: One way of providing robust preconditioners is to combine the strengths of iterative methods (smaller memory requirement, faster solution time), with the power of direct methods (robustness); thus creating hierarchical preconditioning methods. We have studied various aspects of sparse linear system solvers on conventional parallel computers <ref> [9, 15, 28, 26, 22, 19, 23, 24, 20] </ref>. One such preconditioning technique can be based on the algorithm developed by Hu, Lou and Sameh [18] that uses a domain decomposition into overlapping domains to produce robust preconditioners that significantly outperform preconditioners based on incomplete LU factorization.
Reference: [20] <author> G. Karypis and V. Kumar. </author> <title> A fast and high quality multilevel scheme for partitioning irregular graphs. </title> <type> Technical Report TR 95-035, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/~karypis/papers/mlevel serial.ps. A short version appears in Intl. Conf. on Parallel Processing 1995. </note>
Reference-contexts: One way of providing robust preconditioners is to combine the strengths of iterative methods (smaller memory requirement, faster solution time), with the power of direct methods (robustness); thus creating hierarchical preconditioning methods. We have studied various aspects of sparse linear system solvers on conventional parallel computers <ref> [9, 15, 28, 26, 22, 19, 23, 24, 20] </ref>. One such preconditioning technique can be based on the algorithm developed by Hu, Lou and Sameh [18] that uses a domain decomposition into overlapping domains to produce robust preconditioners that significantly outperform preconditioners based on incomplete LU factorization. <p> On the proposed architecture with P 1 supernodes each containing P 2 nodes, and each node corresponding to P 3 processors, such a hierarchical preconditioner can be applied as follows: The mesh with N elements is decomposed into P 1 overlapping domain <ref> [20, 23, 24] </ref> each of size N=P 1 , and let M 1 be the matrix that corresponds to the overlap. Since iterating on M 1 requires the solution of systems involving the subdomains, each such system is solved in a similar hierarchical fashion as follows.
Reference: [21] <author> G. Karypis and V. Kumar. Metis: </author> <title> Unstructured graph partitioning and sparse matrix ordering system. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Available on the WWW at URL http://www.cs.umn.edu/~karypis/metis/metis.html. </note>
Reference: [22] <author> G. Karypis and V. Kumar. </author> <title> Multilevel graph partition and sparse matrix ordering. </title> <booktitle> In Intl. Conf. on Parallel Processing, </booktitle> <year> 1995. </year> <note> Available on WWW at URL http://www.cs.umn.edu/~karypis/papers/mlevel serial.ps. </note>
Reference-contexts: One way of providing robust preconditioners is to combine the strengths of iterative methods (smaller memory requirement, faster solution time), with the power of direct methods (robustness); thus creating hierarchical preconditioning methods. We have studied various aspects of sparse linear system solvers on conventional parallel computers <ref> [9, 15, 28, 26, 22, 19, 23, 24, 20] </ref>. One such preconditioning technique can be based on the algorithm developed by Hu, Lou and Sameh [18] that uses a domain decomposition into overlapping domains to produce robust preconditioners that significantly outperform preconditioners based on incomplete LU factorization.
Reference: [23] <author> G. Karypis and V. Kumar. </author> <title> Multilevel k-way partitioning scheme for irregular graphs. </title> <type> Technical Report TR 95-064, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/~karypis/papers/mlevel kway.ps. </note>
Reference-contexts: One way of providing robust preconditioners is to combine the strengths of iterative methods (smaller memory requirement, faster solution time), with the power of direct methods (robustness); thus creating hierarchical preconditioning methods. We have studied various aspects of sparse linear system solvers on conventional parallel computers <ref> [9, 15, 28, 26, 22, 19, 23, 24, 20] </ref>. One such preconditioning technique can be based on the algorithm developed by Hu, Lou and Sameh [18] that uses a domain decomposition into overlapping domains to produce robust preconditioners that significantly outperform preconditioners based on incomplete LU factorization. <p> On the proposed architecture with P 1 supernodes each containing P 2 nodes, and each node corresponding to P 3 processors, such a hierarchical preconditioner can be applied as follows: The mesh with N elements is decomposed into P 1 overlapping domain <ref> [20, 23, 24] </ref> each of size N=P 1 , and let M 1 be the matrix that corresponds to the overlap. Since iterating on M 1 requires the solution of systems involving the subdomains, each such system is solved in a similar hierarchical fashion as follows.
Reference: [24] <author> G. Karypis and V. Kumar. </author> <title> Parallel multilevel graph partitioning. </title> <type> Technical Report TR 95-036, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/~karypis/papers/mlevel parallel.ps. </note>
Reference-contexts: One way of providing robust preconditioners is to combine the strengths of iterative methods (smaller memory requirement, faster solution time), with the power of direct methods (robustness); thus creating hierarchical preconditioning methods. We have studied various aspects of sparse linear system solvers on conventional parallel computers <ref> [9, 15, 28, 26, 22, 19, 23, 24, 20] </ref>. One such preconditioning technique can be based on the algorithm developed by Hu, Lou and Sameh [18] that uses a domain decomposition into overlapping domains to produce robust preconditioners that significantly outperform preconditioners based on incomplete LU factorization. <p> On the proposed architecture with P 1 supernodes each containing P 2 nodes, and each node corresponding to P 3 processors, such a hierarchical preconditioner can be applied as follows: The mesh with N elements is decomposed into P 1 overlapping domain <ref> [20, 23, 24] </ref> each of size N=P 1 , and let M 1 be the matrix that corresponds to the overlap. Since iterating on M 1 requires the solution of systems involving the subdomains, each such system is solved in a similar hierarchical fashion as follows. <p> Since iterating on M 1 requires the solution of systems involving the subdomains, each such system is solved in a similar hierarchical fashion as follows. Each subdomain to be solved by each supernode, is recursively decomposed into P 2 subdomains <ref> [24] </ref>, each of size N=(P 1 flP 2 ). At this point, each subdomain is solved using direct methods on each node.
Reference: [25] <author> George Karypis, Anshul Gupta, and Vipin Kumar. </author> <title> Ordering and load balancing for parallel factorization of sparse matrices. </title> <note> Technical Report (in preparation), </note> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN, </institution> <year> 1994. </year>
Reference: [26] <author> George Karypis, Anshul Gupta, and Vipin Kumar. </author> <title> A highly parallel interior point algorithm. </title> <booktitle> In Proceedings of the seventh SIAM conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 110-112, </pages> <year> 1995. </year>
Reference-contexts: One way of providing robust preconditioners is to combine the strengths of iterative methods (smaller memory requirement, faster solution time), with the power of direct methods (robustness); thus creating hierarchical preconditioning methods. We have studied various aspects of sparse linear system solvers on conventional parallel computers <ref> [9, 15, 28, 26, 22, 19, 23, 24, 20] </ref>. One such preconditioning technique can be based on the algorithm developed by Hu, Lou and Sameh [18] that uses a domain decomposition into overlapping domains to produce robust preconditioners that significantly outperform preconditioners based on incomplete LU factorization.
Reference: [27] <author> George Karypis and Vipin Kumar. </author> <title> Efficient parallel mappings of a dynamic programming algorithm: A su mmary of results. </title> <booktitle> In 7th International Parallel Processing Symposium, </booktitle> <pages> pages 563-568, </pages> <year> 1993. </year>
Reference-contexts: We refer to this rate of increase in problem size as the isoefficiency of the parallel system. We have demonstrated the utility of the isoefficiency metric in the context of a variety of problems <ref> [32, 15, 11, 14, 33, 29, 27] </ref>. We have also established the relationship of the isoefficiency metric to other fixed time and fixed memory metrics. Memory Scaling Metrics The rate of growth of problem size may also be constrained by the amount of memory in the parallel computer.
Reference: [28] <author> George Karypis and Vipin Kumar. </author> <title> Fast sparse Cholesky factorization on scalable parallel computers. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN, </institution> <year> 1994. </year> <note> A short version appears in the Eighth Symposium on the Frontiers of Massively Parallel Computation, 1995. Available on WWW at URL http://www.cs.umn.edu/~karypis/papers/frontiers95.ps. </note>
Reference-contexts: One way of providing robust preconditioners is to combine the strengths of iterative methods (smaller memory requirement, faster solution time), with the power of direct methods (robustness); thus creating hierarchical preconditioning methods. We have studied various aspects of sparse linear system solvers on conventional parallel computers <ref> [9, 15, 28, 26, 22, 19, 23, 24, 20] </ref>. One such preconditioning technique can be based on the algorithm developed by Hu, Lou and Sameh [18] that uses a domain decomposition into overlapping domains to produce robust preconditioners that significantly outperform preconditioners based on incomplete LU factorization.
Reference: [29] <author> George Karypis and Vipin Kumar. </author> <title> Unstructured Tree Search on SIMD Parallel Computers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(10) </volume> <pages> 1057-1072, </pages> <month> October </month> <year> 1994. </year> <note> available as Technical Report TR 92-21, </note> <institution> Computer Science Department, Un iversity of Minnesota. </institution> <month> 20 </month>
Reference-contexts: We refer to this rate of increase in problem size as the isoefficiency of the parallel system. We have demonstrated the utility of the isoefficiency metric in the context of a variety of problems <ref> [32, 15, 11, 14, 33, 29, 27] </ref>. We have also established the relationship of the isoefficiency metric to other fixed time and fixed memory metrics. Memory Scaling Metrics The rate of growth of problem size may also be constrained by the amount of memory in the parallel computer.
Reference: [30] <author> Peter M. Kogge. </author> <title> EXECUBE anew architecture for scalable mpps. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages I77-I84, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: With processor speeds far exceeding memory speeds, it is logical to place the processing elements in the memory itself where a significantly higher bandwidth is available. Such architectures are referred to as processor-in-memory (PIM) architectures. PIM architectures have been extensively explored in the EXECUBE <ref> [30, 31] </ref> project, and its variants have been developed by NEC [47], TI and various other chip designers. There are however several issues that need to be addressed before PIMs can be accepted as an economically viable concept.
Reference: [31] <author> Peter M. Kogge, Toshio Sunaga, Hisatada Miyataka, Koji Kitamura, and Eric Retter. </author> <title> Combined DRAM and logic for massively parallel systems. </title> <booktitle> In Conference on Advanced Research in VLSI, </booktitle> <pages> pages 4-16, </pages> <address> Chapel Hill, NC, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: With processor speeds far exceeding memory speeds, it is logical to place the processing elements in the memory itself where a significantly higher bandwidth is available. Such architectures are referred to as processor-in-memory (PIM) architectures. PIM architectures have been extensively explored in the EXECUBE <ref> [30, 31] </ref> project, and its variants have been developed by NEC [47], TI and various other chip designers. There are however several issues that need to be addressed before PIMs can be accepted as an economically viable concept.
Reference: [32] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Algorithm Design and Analysis. </title> <publisher> Benjamin Cummings/ Addison Wesley, </publisher> <address> Redwod City, </address> <year> 1994. </year>
Reference-contexts: While low degree networks scale well in terms of hardware, they are not ideal for scalable sustained performance. At the other end of the spectrum, completely connected networks such as crossbars are highly desirable but are very expensive to construct for larger number of processors <ref> [32] </ref>. Exotic technologies such as 8 free space optical interconnects have not matured enough to warrant commitment in a closed-ended project. * Feasibility: Non-blocking switches are technologically feasible for a small number of processors. Aggregates can be constructed by using these switches in multistage networks. <p> A significant part of applied and analytical parallel computing deals with performance properties up to hundreds of processors. This must be extended to the range of processors in the proposed architecture. Clearly, as the number of processors is increased, the problem size must be increased to maintain efficiency <ref> [3, 32] </ref>. This implies a certain growth rate for the total memory in the system. Furthermore, the solution time may also increase with increasing number of processors. Since we cannot expect to allow arbitrary solution times, this must be factored into the scalability analysis. <p> We refer to this rate of increase in problem size as the isoefficiency of the parallel system. We have demonstrated the utility of the isoefficiency metric in the context of a variety of problems <ref> [32, 15, 11, 14, 33, 29, 27] </ref>. We have also established the relationship of the isoefficiency metric to other fixed time and fixed memory metrics. Memory Scaling Metrics The rate of growth of problem size may also be constrained by the amount of memory in the parallel computer.
Reference: [33] <author> Vipin Kumar, Ananth Grama, and V. Nageshwara Rao. </author> <title> Scalable load balancing techniques for parallel computers. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 22(1) </volume> <pages> 60-79, </pages> <month> July </month> <year> 1994. </year> <note> Also available as Technical Report 91-55 (November 1991), </note> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN. </institution> <note> Available via anonymous ftp from ftp.cs.umn.edu at users/kumar/lb-MIMD.ps. </note>
Reference-contexts: We refer to this rate of increase in problem size as the isoefficiency of the parallel system. We have demonstrated the utility of the isoefficiency metric in the context of a variety of problems <ref> [32, 15, 11, 14, 33, 29, 27] </ref>. We have also established the relationship of the isoefficiency metric to other fixed time and fixed memory metrics. Memory Scaling Metrics The rate of growth of problem size may also be constrained by the amount of memory in the parallel computer.
Reference: [34] <author> Vipin Kumar and Anshul Gupta. </author> <title> Analyzing the scalability of parallel algorithms and architectures: A survey. </title> <booktitle> In Proceedings of the 1991 International Conference on Supercomputing, </booktitle> <year> 1991. </year> <note> Also appears in September 1994 issue of JPDC. Available via anonymous ftp from ftp.cs.umn.edu at users/kumar/survey-scalability.ps. </note>
Reference: [35] <author> Vipin Kumar and Anshul Gupta. </author> <title> Analyzing scalability of parallel algorithms and architectures. </title> <journal> Journal of Parallel and Distributed Computing (special issue on scalability), </journal> <volume> 22(3) </volume> <pages> 379-391, </pages> <month> September </month> <year> 1994. </year> <note> A short version of the paper appears in the Proceedings of the 1991 International Conference on Supercomputing. Available via anonymous ftp from ftp.cs.umn.edu at users/kumar/survey-scalability.ps. </note>
Reference-contexts: None of these models are designed to handle hierarchical architecture models. We propose to develop abstract models for hierarchical machines [8]. 13 5.2 Metrics for Algorithm Analysis The large number of PEs in the system imposes significant requirements on the scalability of the algorithm-architecture combination <ref> [35, 12] </ref>. A significant part of applied and analytical parallel computing deals with performance properties up to hundreds of processors. This must be extended to the range of processors in the proposed architecture. <p> We refer to such systems as efficiency-scalable. The rate at which the problem size must be increased with increasing number of processors to maintain the efficiency constant is an excellent measure of the scalability of the system <ref> [35, 3] </ref>. We refer to this rate of increase in problem size as the isoefficiency of the parallel system. We have demonstrated the utility of the isoefficiency metric in the context of a variety of problems [32, 15, 11, 14, 33, 29, 27]. <p> The scalability issues for such problems have been explored by Worley [46], Gustafson [17], and Sun and Ni [40]. We have studied these and other scalability metrics extensively <ref> [35, 12, 3] </ref>. We will evaluate the suit 14 ability of these metrics in the context of the proposed architecture.
Reference: [36] <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Classification-rule learning involves finding rules or decision trees that partition the given data into predefined classes. For any realistic problem domain of the classification-rule learning, the set of possible decision trees is too large to be searched exhaustively. All of the existing algorithms, like C4.5 <ref> [36] </ref> and CDP [1], use local heuristics to construct the decision trees. The computational complexity of these algorithms ranges from O (n log n) with discrete data attributes only, to O (n log 2 n) with continuous data attributes.
Reference: [37] <author> Thomas Sterling and Michael MacDonald. </author> <title> The proceedings of the petaflops frontier workshop. </title> <type> Technical Report TR-95-161, </type> <institution> Center of Excellence in Space Data and Information Science, Goddard Space Flight Center, Greenbelt, MD, </institution> <year> 1995. </year>
Reference-contexts: These provide the underlying motivation for a study of enabling and desirable technologies for next generation parallel computers. From the petaFLOPS architectures workshop at Pasadena, the petaFLOPS forum at Frontiers '95 and the petaFLOPS summer study at Bodega Bay <ref> [37, 38] </ref>, it became apparent that a lack of new architecture models restricts us to architectures that can be defined in terms of conventional concepts. However, the workshops served the very important purpose of consolidating design options and application requirements.
Reference: [38] <author> Thomas Sterling, Paul Messina, and Paul Smith. </author> <title> Enabling Technologies for Petaflops Computing. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: These provide the underlying motivation for a study of enabling and desirable technologies for next generation parallel computers. From the petaFLOPS architectures workshop at Pasadena, the petaFLOPS forum at Frontiers '95 and the petaFLOPS summer study at Bodega Bay <ref> [37, 38] </ref>, it became apparent that a lack of new architecture models restricts us to architectures that can be defined in terms of conventional concepts. However, the workshops served the very important purpose of consolidating design options and application requirements.
Reference: [39] <author> M. Stonebraker, R. Agrawal, U. Dayal, E. J. Neuhold, and A. Reuter. </author> <title> Dbms research at a crossroads: The vienna update. </title> <booktitle> In Proc. of the 19th VLDB Conference, </booktitle> <pages> pages 688-692, </pages> <address> Dublin, Ireland, </address> <year> 1993. </year>
Reference-contexts: It is anticipated that by the year 1997, the turnover of the data-mining software industry itself (not including associated hardware) will exceed five billion dollars. This is more than the entire supercomputing industry currently. One of the important problems in data mining <ref> [39] </ref> is the classification-rule learning. Classification-rule learning involves finding rules or decision trees that partition the given data into predefined classes. For any realistic problem domain of the classification-rule learning, the set of possible decision trees is too large to be searched exhaustively.
Reference: [40] <author> Xian-He Sun and L. M. Ni. </author> <title> Another view of parallel speedup. </title> <booktitle> In Supercomputing '90 Proceedings, </booktitle> <pages> pages 324-333, </pages> <year> 1990. </year>
Reference-contexts: The problem size is increased at the fastest rate allowed by the available memory. The resulting performance characteristics determine the scalability of the system. These metrics have been investigated by Worley [46], Gustafson [17] and Sun and Ni <ref> [40] </ref>. Fixed Time Metrics In many situations, the rate of growth of problem size is dictated by the time available on the machine to solve the problem. In these cases, the problem size is increased with number of processors in such a way that the parallel runtime remains constant. <p> In these cases, the problem size is increased with number of processors in such a way that the parallel runtime remains constant. The scalability issues for such problems have been explored by Worley [46], Gustafson [17], and Sun and Ni <ref> [40] </ref>. We have studied these and other scalability metrics extensively [35, 12, 3]. We will evaluate the suit 14 ability of these metrics in the context of the proposed architecture.
Reference: [41] <author> D. M. Tullsen, S. J. Eggers, J. S. Emer, H. M. Levy, J. L. Lo, and R. L. Stamm. </author> <title> Exploiting choice: Instruction fetch and issue on an implementable simultaneous multithreading processor. </title> <booktitle> In In 23rd Annual International Symposium on Computer Architecture, </booktitle> <month> May, </month> <year> 1996. </year>
Reference-contexts: Multi-threaded architectures have been extensively explored since the days of the HEP Denelcor. Threads are a very effective means of expressing concurrency. This concurrency can be used in the parallel as well as serial context for hiding memory latency and scheduling on multiple functional units <ref> [41, 44, 43, 42, 45] </ref>. Currently, the two most popular architectures for incorporating multiple functional units into microprocessors are superscalar units and very long instruction words. Superscalar processors use multiple pipelines operating in parallel. Almost all current off-the-shelf processors utilize superscalar execution.
Reference: [42] <author> D.M. Tullsen and S.J. Eggers. </author> <title> Limitations of cache prefetching on a bus-based multiprocessor. </title> <booktitle> In In 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 278-288, </pages> <year> 1993. </year>
Reference-contexts: Multi-threaded architectures have been extensively explored since the days of the HEP Denelcor. Threads are a very effective means of expressing concurrency. This concurrency can be used in the parallel as well as serial context for hiding memory latency and scheduling on multiple functional units <ref> [41, 44, 43, 42, 45] </ref>. Currently, the two most popular architectures for incorporating multiple functional units into microprocessors are superscalar units and very long instruction words. Superscalar processors use multiple pipelines operating in parallel. Almost all current off-the-shelf processors utilize superscalar execution.
Reference: [43] <author> D.M. Tullsen and S.J. Eggers. </author> <title> Effective cache prefetching on bus-based multiprocessors. </title> <journal> ACM Transactions on Computer Systems, </journal> <pages> pages 57-88, </pages> <month> February, </month> <year> 1995. </year>
Reference-contexts: Multi-threaded architectures have been extensively explored since the days of the HEP Denelcor. Threads are a very effective means of expressing concurrency. This concurrency can be used in the parallel as well as serial context for hiding memory latency and scheduling on multiple functional units <ref> [41, 44, 43, 42, 45] </ref>. Currently, the two most popular architectures for incorporating multiple functional units into microprocessors are superscalar units and very long instruction words. Superscalar processors use multiple pipelines operating in parallel. Almost all current off-the-shelf processors utilize superscalar execution.
Reference: [44] <author> D.M. Tullsen, S.J. Eggers, and H.M. Levy. </author> <title> Simultaneous multithreading: Maximizing on-chip parallelism. </title> <booktitle> In In 22nd Annual International Symposium on Computer Architecture, </booktitle> <month> June, </month> <year> 1995. </year>
Reference-contexts: Multi-threaded architectures have been extensively explored since the days of the HEP Denelcor. Threads are a very effective means of expressing concurrency. This concurrency can be used in the parallel as well as serial context for hiding memory latency and scheduling on multiple functional units <ref> [41, 44, 43, 42, 45] </ref>. Currently, the two most popular architectures for incorporating multiple functional units into microprocessors are superscalar units and very long instruction words. Superscalar processors use multiple pipelines operating in parallel. Almost all current off-the-shelf processors utilize superscalar execution.
Reference: [45] <author> D.M. Tullsen and M.D. Ercegovac. </author> <title> Design and vlsi implementation of an online algorithm. In Real Time Signal Processing IX, </title> <month> August, </month> <year> 1988. </year>
Reference-contexts: Multi-threaded architectures have been extensively explored since the days of the HEP Denelcor. Threads are a very effective means of expressing concurrency. This concurrency can be used in the parallel as well as serial context for hiding memory latency and scheduling on multiple functional units <ref> [41, 44, 43, 42, 45] </ref>. Currently, the two most popular architectures for incorporating multiple functional units into microprocessors are superscalar units and very long instruction words. Superscalar processors use multiple pipelines operating in parallel. Almost all current off-the-shelf processors utilize superscalar execution.
Reference: [46] <author> Patrick H. Worley. </author> <title> The effect of time constraints on scaled speedup. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 11(5) </volume> <pages> 838-858, </pages> <year> 1990. </year>
Reference-contexts: The memory scaling characteristics of the application determine the overall memory available in the system. The problem size is increased at the fastest rate allowed by the available memory. The resulting performance characteristics determine the scalability of the system. These metrics have been investigated by Worley <ref> [46] </ref>, Gustafson [17] and Sun and Ni [40]. Fixed Time Metrics In many situations, the rate of growth of problem size is dictated by the time available on the machine to solve the problem. <p> In these cases, the problem size is increased with number of processors in such a way that the parallel runtime remains constant. The scalability issues for such problems have been explored by Worley <ref> [46] </ref>, Gustafson [17], and Sun and Ni [40]. We have studied these and other scalability metrics extensively [35, 12, 3]. We will evaluate the suit 14 ability of these metrics in the context of the proposed architecture.

References-found: 46

