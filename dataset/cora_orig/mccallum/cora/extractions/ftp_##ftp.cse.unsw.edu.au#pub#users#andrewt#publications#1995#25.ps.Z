URL: ftp://ftp.cse.unsw.edu.au/pub/users/andrewt/publications/1995/25.ps.Z
Refering-URL: http://www.cse.unsw.edu.au/school/publications/1995/SCSE_publications.html
Root-URL: http://www.cse.unsw.edu.au
Email: mann@cse.unsw.edu.au  
Title: What Conceptual Graph Workbenches Need for Natural Language Processing  
Author: Graham A. Mann 
Address: Sydney 2052, Australia  
Affiliation: School of Computer Science Engineering, University of New South Wales  
Abstract: An important capability of the conceptual graph knowledge engineering tools now under development will be the transformation of natural language texts into graphs (conceptual parsing) and its reverse, the production of text from graphs (conceptual generation). Are the existing basic designs adequate for these tasks? Experience developing the BEELINE system's natural language capabilities suggests that good entry/editing tools, a generous but not unlimited storage capacity and efficient, bidirectional lexical access techniques are needed to support the supply of data structures at both the linguistic and conceptual knowledge levels. An active formalism capable of supporting declarative and procedural programs containing both linguistic and knowledge level terms is also important. If these requirements are satisfied, future text-readers can be included as part of a conceptual knowledge workbench without unexpected problems. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Bell, J.R. & Joyce, </author> <title> R.C. (1989) Mapping conceptual graphs onto natural language. </title> <type> Technical Report #89/6, </type> <institution> Dept. of Computer Science, James Cook University of North Queensland. </institution>
Reference: 2. <author> Berwick, </author> <title> R.C. </title> <booktitle> (1987) Intelligent natural language processing: current trends and future prospects. In W.E.L. Grimson & Patil, R.S. (Ed.s) AI in the 1980s and Beyond. </booktitle> <address> Cambridge, Mass, </address> <publisher> MIT Press. </publisher>
Reference-contexts: For example, only 6 rules account for spelling changes required to map stems and suffixes (e.g. try + s -&gt; tries, strap + ing -&gt; strapping, etc.). With such a small number of rules it is practical the encoding of such transformations as finite state automata for maximum efficiency <ref> [2] </ref>, or as simple functions.
Reference: 3. <author> Briscoe, E., Grover, C., Boguraev, B. & Carroll, J. </author> <title> (1987) A formalism and environment for the development of a large grammar of English, </title> <booktitle> Proceedings of the 10th International Joint Conference on Artificial Intelligence. </booktitle> <address> Milan, Italy, </address> <year> 1987, </year> <pages> 703-708. </pages>
Reference-contexts: Another example is the Alvey Natural Language Tools project <ref> [3] </ref>, which provides a standard, wide-coverage morphological and syntactical analyser for English. It includes a development environment which can be used to build generalised phrase structure grammars (GPSGs), but with a 782-rule broad coverage grammar provided; a morphological analyser; a chart parser, an LALR parser, and a 63,000 entry lexicon.
Reference: 4. <author> Dogru, S. & Slagle, J.R. </author> <title> (1992) A system that translates conceptual structures into English. </title> <booktitle> Proceedings 7th Annual Workshop on Conceptual Graphs, </booktitle> <address> Las Cruces, New Mexico State University, </address> <pages> 167-176. </pages>
Reference: 5. <author> Ellis G. & Levinson, R. </author> <title> (1992) The birth of PEIRCE: A conceptual graphs workbench, </title> <booktitle> Proceedings 1st International Workshop on PEIRCE. </booktitle> <address> Las Cruces, New Mexico State University, </address> <month> July, </month> <pages> 149-156. </pages>
Reference-contexts: 1 Introduction From the large number of experimental software systems designed to realise the power of conceptual graph (CG) theory, a few have emerged as contenders for the 'standard' workbench. Three such workbenches will be discussed here: the Loughborough toolset [9], the PEIRCE project <ref> [5] </ref> and the objectoriented UNE-CG-KEE environment [11].
Reference: 6. <author> Eklund, P.W., Leane, J. & Nowak, C. </author> <title> (1994) GRIT: An implementation of a graphical user interface for conceptual structures. </title> <type> Technical Report TR94-03, </type> <institution> Dept. of Computer Science, University of Adelaide, </institution> <month> February, </month> <year> 1994. </year>
Reference-contexts: The PEIRCE interface seems a reasonable compromise between simplicity and integrity checking; it accepts graphs in the standard linear form, does less checking, and is consequently much faster. PEIRCE is also adopting GRIT, a sophisticated graphical I/O tool <ref> [6] </ref>, which could solve many problems of finding, modifying and displaying complex graphs. How many graphs will be needed for word definitions? As indicated in Figure 1, there is a one-to - many relationship between each lexicon entry and the conceptual graphs that represent the meanings of its word senses.
Reference: 7. <author> Jensen, K. & Heidorn, G.E. </author> <title> (1983) The fitted parse: 100% parsing capability in a syntactic grammar of English. </title> <booktitle> Proceedings of the Conference on Applied Natural Language Processing, </booktitle> <address> Santa Monica, California, </address> <booktitle> ACL, </booktitle> <pages> 93-98. </pages>
Reference-contexts: Good NLP toolsets come equipped with their own dictionaries, parsers and morphologies as well as formalisms for specifying lexical entries, morphological transformations, grammars and other types of information. Sowa & Way [15] developed a conceptual graph parser using the PNLP system <ref> [7] </ref>, which provided a dictionary of over 70,000 words, an English syntactical parser using a comprehensive augmented phrase structure grammar, frame-like record structures suitable for representing conceptual graphs and a high-level language capable of interpreting production rules or procedural programs.
Reference: 8. <author> Jung, C. </author> <title> (1994) The Natural Language Software Registry, </title> <note> WWW database. URL = http://www.dfki.uni sb.de/cl/registry/draft.html, DFKI GmBH. </note>
Reference-contexts: The system generates highly readable structures which could be easily be imported into a CG workbench. However, both these systems run in LISP, which is incompatible with the workbenches in question. For up-to-date details of existing tools, consult <ref> [8] </ref>. 3 Knowledge Level Provisions All practical CG systems need some way of entering and altering the graphs that constitute their knowledge bases. To enter graphs into the Loughborough toolset, for example, one types conceptual graphs in linear form into the terminal.
Reference: 9. <author> Kocura, P., Ho, K.K., Moorehouse, D. & Sharpe, G. </author> <title> (1991) Aspects of conceptual graphs processor design. </title> <booktitle> Proceedings 6th Annual Workshop on Conceptual Graphs. Binghamton, </booktitle> <address> New York, </address> <month> July, </month> <year> 1991, </year> <pages> 317-329. </pages>
Reference-contexts: 1 Introduction From the large number of experimental software systems designed to realise the power of conceptual graph (CG) theory, a few have emerged as contenders for the 'standard' workbench. Three such workbenches will be discussed here: the Loughborough toolset <ref> [9] </ref>, the PEIRCE project [5] and the objectoriented UNE-CG-KEE environment [11]. <p> In the Loughborough toolset, canonical graphs which would form word definitions are part of a complex set of interdependencies between other components of the knowledge base. <ref> [9] </ref> does not give details of how canonical graphs are represented or searched, so no indication of how to add a lexicon can be given. Presumably, pairs of pointers could bidirectionally link lexicon entries and particular graphs at some point within the complex.
Reference: 10. <author> Mann, </author> <title> G.A. (1995) BEELINE - A Situated, Bounded Conceptual Knowledge System. </title> <journal> Systems Research and Information Science , forthcoming issue. </journal>
Reference-contexts: Even a fairly simple text parser would be a good 'selling point'. What special requirements do language modules have for workbench design? How can the engineer ensure that a system will at least be able to support future language modules? Experience with BEELINE <ref> [10] </ref>, a CG-based agent capable of parsing paragraphs of real text, will be used to identify the key points at which design might be affected.
Reference: 11. <author> Munday, C., Sobora, F. & Lukose, D. </author> <year> (1994) </year> <month> UNE-CG-KEE: </month> <title> next generation knowledge engineering environment. </title> <booktitle> Proceedings 1st Australian Conceptual Structures Workshop. </booktitle> <address> Armidale, Australia, </address> <month> November, </month> <year> 1994, </year> <pages> 103-117. </pages>
Reference-contexts: 1 Introduction From the large number of experimental software systems designed to realise the power of conceptual graph (CG) theory, a few have emerged as contenders for the 'standard' workbench. Three such workbenches will be discussed here: the Loughborough toolset [9], the PEIRCE project [5] and the objectoriented UNE-CG-KEE environment <ref> [11] </ref>. These projects are serious attempts to apply good software engineering methods to supply the reliable, efficient and expandable knowledge engineering tools that the CG community so badly needs; with the basic CG processing machinery in hand, future experimental work can get on with higher-level knowledge structures, operators and applications. <p> In the UNE-CG-KEE system, lexical access could be accomplished by means of pointers from the lexicon entries to definition graphs, in the manner like that described in section 3.3 of <ref> [11] </ref> for schemas, prototypes and composite individuals. This access would be efficiently reversible if a second pointer from the graph back to the lexicon were added. The software development language (C++ for all three workbenches under consideration here) could at a minimum be used as a basic active formalism. <p> To enter graphs into the Loughborough toolset, for example, one types conceptual graphs in linear form into the terminal. The graphs are then extensively checked against the existing graphs in the knowledge base, ensuring consistency. According to Munday, Sobora & Lukose <ref> [11] </ref>, this process is a thorough, but very slow way of building the knowledge base. This would present an obstacle to the entry of large numbers of word definitions.
Reference: 12. <author> Nogier, J-F. & Zock, M. </author> <title> (1990) Lexical choice as a process of matching word definitions on an utterance graph. </title> <booktitle> Proceedings 5th Annual Workshop on Conceptual Graphs. </booktitle> <address> Stockholm, Sweden, </address> <month> August, E.03. </month>
Reference-contexts: If a projection of some wordsense definition could be found in the complex graph, then the associated word would be available to account for the entire cluster <ref> [12] </ref>, provided there was a path back from the definition to the word. Effectively, another type of contraction operation becomes available. Besides better quality of generation, such a definitional contraction might be useful for analogical reasoning, by exploiting the conceptual relationships between different senses of a given word.
Reference: 13. <author> Oh, J.C. et. al. </author> <title> (1992) NLP: Natural language parsers and generators. </title> <booktitle> Proceedings 1st International Workshop on PEIRCE. </booktitle> <address> Las Cruces, New Mexico State University, </address> <month> July, </month> <pages> 41-49. </pages>
Reference-contexts: Although only the PEIRCE project has such capabilities as stated goals (and has begun a processes of specification <ref> [13] </ref>), the provision of such language modules could make an important difference of whether or not a given system would be widely adopted. Even a fairly simple text parser would be a good 'selling point'. <p> In PEIRCE, conceptual graphs can be associated with unique bit codes, which makes search very efficient. Words could be hashed into such bit codes, but the hashing method would need to be reversible. Note that the scheme described in <ref> [13] </ref>, in which words are defined by packets of procedural information designed to create new structures and modify existing ones, is not simply or efficiently reversible for generation.
Reference: 14. <author> Russell, G., Pulman, S., Ritchie, G. and Black, A. </author> <title> (1986) A dictionary and morphological analyser for English, </title> <booktitle> Proceedings of the 11th International Conference on Computational Linguistics. </booktitle> <address> Bonn, Germany, </address> <pages> 277-279. </pages>
Reference-contexts: In LISP-based systems like Alvey and BEELINE, this can be achieved by making word strings access a hash table of lexical entries directly <ref> [14, 16] </ref>. What is not so clear is that the path from word to conceptual graph needs to be easily reversible . In generating well-formed language from conceptual graphs, methods based on the traversal of graphs have been suggested [1,4].
Reference: 15. <author> Sowa, J.F. </author> & <title> Way, E.C. (1986) Implementing a semantic interpreter using conceptual graphs. </title> <journal> IBM Journal of Research & Development , 30, </journal> <volume> 1, </volume> <pages> 57-96. </pages>
Reference-contexts: Good NLP toolsets come equipped with their own dictionaries, parsers and morphologies as well as formalisms for specifying lexical entries, morphological transformations, grammars and other types of information. Sowa & Way <ref> [15] </ref> developed a conceptual graph parser using the PNLP system [7], which provided a dictionary of over 70,000 words, an English syntactical parser using a comprehensive augmented phrase structure grammar, frame-like record structures suitable for representing conceptual graphs and a high-level language capable of interpreting production rules or procedural programs.
Reference: 16. <author> Steel, </author> <title> G.C. (1990) Common LISP: </title> <booktitle> The language. 2nd Edition. </booktitle> <address> Reading, Mass: </address> <publisher> Digital Press, </publisher> <address> p. </address> <month> 435. </month>
Reference-contexts: In LISP-based systems like Alvey and BEELINE, this can be achieved by making word strings access a hash table of lexical entries directly <ref> [14, 16] </ref>. What is not so clear is that the path from word to conceptual graph needs to be easily reversible . In generating well-formed language from conceptual graphs, methods based on the traversal of graphs have been suggested [1,4].
Reference: 17. <author> Williams, C.B. </author> <title> (1970) Style and Vocabulary: Numerical Studies. </title> <publisher> Bristol, Griffin & Co., </publisher> <pages> pp. 66-67. </pages>
Reference-contexts: What are the strorage requirements for the lexicon? Williams <ref> [17] </ref>, estimates that a working human vocabulary includes from 500 to 40,000 words, depending on the age, language aptitude, and education of the individual. The original lexicon employed in the BEELINE system contained approximately 32,000 entries; only a small fraction of which have since been actually defined with conceptual graphs.
Reference: 18. <editor> Wilks, Y., et. al. </editor> <title> (1988) Machine tractable dictionaries as tools and resources for natural language processing. </title> <booktitle> Proceedings of the 12th International Conference on Computational Linguistics. </booktitle> <address> Budapest, Hungary, </address> <month> August, </month> <year> 1988, </year> <pages> 750-755. </pages>
Reference-contexts: Nor should availability: a number of comprehensive lexicons, including Merriam-Webster's Concise Electronic Dictionary (80,000 entires) and the Longman Dictionary Of Contemporary English have been commercially available in machine readable form since the eighties <ref> [18] </ref>. For the lexicon it is convenient to have search and edit functions, and the ability to modify individual entries without rereading the entire lexicon.
References-found: 18

