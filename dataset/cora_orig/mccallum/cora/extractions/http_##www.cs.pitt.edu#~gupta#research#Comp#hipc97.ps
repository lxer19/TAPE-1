URL: http://www.cs.pitt.edu/~gupta/research/Comp/hipc97.ps
Refering-URL: http://www.cs.pitt.edu/~gupta/research/scheduling.html
Root-URL: 
Email: gupta@cs.pitt.edu  
Title: Code Optimization as a Side Effect of Instruction Scheduling  
Author: Rajiv Gupta 
Keyword: code hoisting, code sinking, code optimization, compensation code, redundancy elimination, dead code removal.  
Address: Pittsburgh Pittsburgh PA 15260  
Affiliation: Department of Computer Science University of  
Abstract: An instruction scheduler utilizes code reordering techniques for generating schedules in which instructions can be issued without delays. In order to perform code reordering across branches, code motion is performed that hoists some instructions above branches and sinks others below branches. Following code reordering, compensation code must be introduced in order to preserve program semantics. In this paper we demonstrate that several important code optimizations can be performed as a side effect of generating compensation code. These optimizations include partial redundancy elimination, partial dead code elimination, elimination of redundant loads, and elimination of dead stores. We demonstrate how existing data flow frameworks for these optimizations can be extended for generating optimized compensation code. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Novack and A. Nicolau, </author> <title> "Mutation Scheduling: A Unified Approach to Compiling for Fine-grain Parallelism," </title> <booktitle> Proc. Languages and Compilers for Parallel Computing, LNCS 892, </booktitle> <year> 1994. </year>
Reference-contexts: Furthermore, we have shown that this approach can be used both during acyclic and cyclic scheduling. In previous work it has been shown that several DAG restructuring transformations [3] and instruction selection techniques <ref> [1] </ref> can be integrated with acyclic scheduling. In recent work we have developed new techniques for conditional branch deletion [5] and PDE [4] that aggressively apply control flow restructuring techniques to enable optimization opportunities available along selected paths.
Reference: [2] <author> V. Kathail, M. Schlansker, and B. Rau, </author> <title> HPL Play-Doh Architecture Specification: </title> <note> Version 1.0, HPL-93-80, </note> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: In particular, we consider the integration of an extended form of circular scheduling [10] with load/store elimination. We consider only nonspeculative execution of loads and stores. However, our techniques can be extended to consider speculation for advanced architectures <ref> [2] </ref>. The circular scheduling technique was originally designed for loops whose bodies are formed by straightline code. Thus when inter iteration code motion was applied to generate good schedules, no compensation code was ever generated within the loop. <p> As a result the resulting live range ends at nodes 4 and 7. So far we did not consider speculative motion of loads which is supported by some architectures such as Playdoh <ref> [2] </ref>.
Reference: [3] <author> D. Berson, P. Chang, R. Gupta and M.L. Soffa, </author> <title> "Integrating Program Optimizations and Transformations with the Scheduling of Instruction Level Parallelism," </title> <booktitle> Ninth Annual Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, Cal-ifornia, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: In this approach the scheduler may undo many of the optimizations that were performed by the optimizer. Meanwhile new optimization opportunities may become available due to code reordering performed by the instruction scheduler <ref> [3] </ref>. These opportunities go unexploited. In this paper an approach that integrates code optimizations into an instruction scheduler is presented. Code optimizations that involve code motion are not performed prior to instruction scheduling. Instead they are incorporated into the task of compensation code generation. <p> Furthermore, we have shown that this approach can be used both during acyclic and cyclic scheduling. In previous work it has been shown that several DAG restructuring transformations <ref> [3] </ref> and instruction selection techniques [1] can be integrated with acyclic scheduling. In recent work we have developed new techniques for conditional branch deletion [5] and PDE [4] that aggressively apply control flow restructuring techniques to enable optimization opportunities available along selected paths.
Reference: [4] <author> R. Bodik and R. Gupta, </author> <title> "Partial Dead Code Elimination using Slicing Transformations," </title> <booktitle> ACM SIG-PLAN Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 575-586, </pages> <address> Las Vegas, Nevada, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: In previous work it has been shown that several DAG restructuring transformations [3] and instruction selection techniques [1] can be integrated with acyclic scheduling. In recent work we have developed new techniques for conditional branch deletion [5] and PDE <ref> [4] </ref> that aggressively apply control flow restructuring techniques to enable optimization opportunities available along selected paths. We are examining the integration of these optimizations with code reordering along a trace.
Reference: [5] <author> R. Bodik, R. Gupta, </author> <title> and M.L. Soffa, "Interproce-dural Conditional Branch Elimination," </title> <booktitle> ACM SIG-PLAN Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 146-158, </pages> <address> Las Vegas, Nevada, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: In previous work it has been shown that several DAG restructuring transformations [3] and instruction selection techniques [1] can be integrated with acyclic scheduling. In recent work we have developed new techniques for conditional branch deletion <ref> [5] </ref> and PDE [4] that aggressively apply control flow restructuring techniques to enable optimization opportunities available along selected paths. We are examining the integration of these optimizations with code reordering along a trace.
Reference: [6] <author> R. Bodik and R. Gupta, </author> <title> "Array Data-Flow Analysis for Load-Store Optimizations in Superscalar Architectures," </title> <journal> Intl. Journal of Parallel Programming, </journal> <volume> 24(6) </volume> <pages> 481-512, </pages> <year> 1996. </year>
Reference-contexts: The prologue of the resulting loop contains the load hoisted out of the first loop iteration. The load elimination algorithm presented in <ref> [6] </ref> can be adapted for generating optimized placement of compensation loads. The algorithm in [6] consists of the following steps. It identifies the group of array references that reference the same array element over a series of loop iterations. <p> The prologue of the resulting loop contains the load hoisted out of the first loop iteration. The load elimination algorithm presented in <ref> [6] </ref> can be adapted for generating optimized placement of compensation loads. The algorithm in [6] consists of the following steps. It identifies the group of array references that reference the same array element over a series of loop iterations. For example in Figure 3a references to A [i + 1] and A [i] reference the same array element over two successive loop iterations. <p> In this resulting code, unlike the original code, along every path through a loop iteration a single store is issued. The epilogue of the resulting loop issues the store that was sunk out of the last loop iteration. An algorithm for store placement can be found in <ref> [6] </ref>. While the load placement algorithm requires backward anticipatability and forward availability to construct the relevant live range, the placement of stores requires forward anticipatability and backward availability analysis of definitions that refer to the same array element over a series of loop iterations.
Reference: [7] <author> K. Ebcioglu et al., </author> <title> "VLIW Compilation Techniques in a Superscalar Environment," </title> <booktitle> ACM SIGPLAN Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 36-48, </pages> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Compensation code for other statements can be generated using traditional approaches [8, 9]. The optimizations that we present include: (a) partial redundancy elimination [13, 11] of hoisted expressions involving scalar variables and floating point operations during acyclic scheduling; (b) partial dead code elimination <ref> [12, 7] </ref> of sunk assignments involving scalar variables and floating point operations during acyclic scheduling; (c) elimination of partially redundant loads during cyclic scheduling; and (d) elimination of partially dead stores during cyclic scheduling.
Reference: [8] <author> J.A. Fisher, </author> <title> "Trace Scheduling: A Technique for Global Microcode Compaction," </title> <journal> IEEE Transactions on Computers, </journal> <volume> 30(7), </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: Since maximum benefit can be derived by optimizing long latency operations, we assume that the instructions involving such operations are the target of optimization during compensation code generation. Compensation code for other statements can be generated using traditional approaches <ref> [8, 9] </ref>. <p> In our discussion we assume that instruction scheduling is being performed along acyclic paths using a trace scheduler <ref> [8] </ref> although the techniques are applicable to other types of acyclic schedulers. <p> Consider the example flow graph of Figure 1a. Assume that the path 1-2-7-8-10 through the acyclic flow graph is the most frequently executed and therefore is the object of code reordering being performed by the trace scheduler <ref> [8] </ref>. Along this path the evaluation of expression x fl y, that is, the value of a, immediately precedes the use of a.
Reference: [9] <author> R. Gupta and M.L. Soffa, </author> <title> "Region Scheduling: An Approach for detecting and redistributing Parallelism," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(4) </volume> <pages> 421-431, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Since maximum benefit can be derived by optimizing long latency operations, we assume that the instructions involving such operations are the target of optimization during compensation code generation. Compensation code for other statements can be generated using traditional approaches <ref> [8, 9] </ref>.
Reference: [10] <author> S. Jain, </author> <title> "Circular Scheduling: A New technique to Perform Software Pipelining," </title> <booktitle> ACM SIGPLAN Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 219-228, </pages> <year> 1991. </year>
Reference-contexts: Furthermore these opportunities arise when code hoisting and sinking is being applied to achieve inter iteration code motion in loops. In particular, we consider the integration of an extended form of circular scheduling <ref> [10] </ref> with load/store elimination. We consider only nonspeculative execution of loads and stores. However, our techniques can be extended to consider speculation for advanced architectures [2]. The circular scheduling technique was originally designed for loops whose bodies are formed by straightline code.
Reference: [11] <author> J. Knoop, O. Ruthing, and B. Steffen, </author> <title> "Lazy Code Motion," </title> <booktitle> ACM SIGPLAN Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 224-234, </pages> <year> 1992. </year>
Reference-contexts: Compensation code for other statements can be generated using traditional approaches [8, 9]. The optimizations that we present include: (a) partial redundancy elimination <ref> [13, 11] </ref> of hoisted expressions involving scalar variables and floating point operations during acyclic scheduling; (b) partial dead code elimination [12, 7] of sunk assignments involving scalar variables and floating point operations during acyclic scheduling; (c) elimination of partially redundant loads during cyclic scheduling; and (d) elimination of partially dead stores <p> This example illustrates that PRE opportunities can be exploited by appropriate placement of compensation code. Next we develop an algorithm for compensation code placement which performs PRE. This algorithm is an extension of the PRE algorithm proposed by Knoop et al. <ref> [11] </ref>. The key points that must be addressed by the compensation code placement algorithm are as follows: 1. Speculation based Scheduling: The scheduler may perform speculative code motion as illustrated by the example in Figure 1. Knoop's algorithm cannot perform speculative code motion. <p> If multiple expressions are to be considered, then a bit vector can be performed in which each bit corresponds to a unique expression. 2. Earliestness Analysis: This forward analysis phase is identical to the one proposed by Knoop et al. <ref> [11] </ref>. It identifies the earliest code placement points which are down-safe. The down-safety analysis discussed above guarantees that the target e node will be one of the earliest points. All remaining points are points at which compensation code is placed. 3. <p> This approach leads to the reduction in the size of the lifetime of the computed expressions by the compensation code. This step is similar to the implementation described by Knoop et al. in <ref> [11] </ref> except for one simple modification. The placement of the expression by the scheduler at the node target e cannot be delayed. Let us revisit the example in Figure 1.
Reference: [12] <author> J. Knoop, O. Ruthing, and B. Steffen, </author> <title> "Partial Dead Code Elimination," </title> <booktitle> ACM SIGPLAN Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 147-158, </pages> <year> 1994. </year>
Reference-contexts: Compensation code for other statements can be generated using traditional approaches [8, 9]. The optimizations that we present include: (a) partial redundancy elimination [13, 11] of hoisted expressions involving scalar variables and floating point operations during acyclic scheduling; (b) partial dead code elimination <ref> [12, 7] </ref> of sunk assignments involving scalar variables and floating point operations during acyclic scheduling; (c) elimination of partially redundant loads during cyclic scheduling; and (d) elimination of partially dead stores during cyclic scheduling. <p> One approach to this optimization is to sink the partially dead assignment to a set of program points such that at some of these points the statement is fully dead and hence its execution can be removed <ref> [12] </ref>. Opportunities for PDE arise if the instruction scheduler performs code sinking to generate a good schedule. Consider the example flow graph of Figure 2a. Assume that the path 10-1-2-3-8 through the acyclic flow graph is the most frequently executed and therefore is the object of code reordering. <p> The above examples illustrate that PDE opportunities can be exploited by appropriate placement of compensation code. Next we develop an algorithm for compensation code placement which performs PDE. This algorithm is an extension of the PDE algorithm proposed by Knoop et al. <ref> [12] </ref>. The key points that must be addressed by the compensation code placement algorithm are as follows: 1. Predication based Scheduling: The scheduler may perform predication enabled code sinking as illustrated by the example in Figure 2. Knoop's algorithm cannot perform such code motion. <p> If multiple assignments are to be considered, then a bit vector can be used in which each bit corresponds to a unique assignment. 2. Insertion Point Computation: This step is identical to the one proposed by Knoop et al. <ref> [12] </ref>. It identifies the code placement points for the assignment. As mentioned earlier, our formulation of delayability analysis is guaranteed to result in node target s being selected as an insertion point. All remaining points are points at which compensation code are placed. 3.
Reference: [13] <author> E. Morel and C. </author> <title> Renvoise, "Global Optimization by Supression of Partial Redundancies," </title> <journal> Communications of the ACM, </journal> <volume> 22(2) </volume> <pages> 96-103, </pages> <month> Feb. </month> <year> 1979. </year>
Reference-contexts: Compensation code for other statements can be generated using traditional approaches [8, 9]. The optimizations that we present include: (a) partial redundancy elimination <ref> [13, 11] </ref> of hoisted expressions involving scalar variables and floating point operations during acyclic scheduling; (b) partial dead code elimination [12, 7] of sunk assignments involving scalar variables and floating point operations during acyclic scheduling; (c) elimination of partially redundant loads during cyclic scheduling; and (d) elimination of partially dead stores
Reference: [14] <author> M.S. Schlansker and V.Kathail, </author> <title> "Critical Path Reduction for Scalar Programs," </title> <booktitle> 28th Annual IEEE/ACM Intl. Symp. on Microarchitecture, </booktitle> <address> Ann Arbor, Michigan, </address> <month> Nov. </month> <year> 1995. </year>
Reference-contexts: It is possible that the partially dead statement being sunk is dead along the trace. In such situations acyclic schedulers sink the statement to the point where the statement becomes fully dead and hence can be entirely eliminated from the trace <ref> [14] </ref>. For example, if the use of x from node 8 is removed, the partially dead assignment x = a fl b is dead along the trace 10-1-2-3-8. In this case if the scheduler sinks the assignment to node 3 as before, it can be entirely eliminated.
References-found: 14

