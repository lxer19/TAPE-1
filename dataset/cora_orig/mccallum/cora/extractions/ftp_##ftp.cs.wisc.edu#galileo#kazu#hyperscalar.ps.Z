URL: ftp://ftp.cs.wisc.edu/galileo/kazu/hyperscalar.ps.Z
Refering-URL: http://www.cs.wisc.edu/~kazuaki/kazuaki.html
Root-URL: 
Email: fmurakami, miyajimag@is.kyushu-u.ac.jp  
Title: Hyperscalar Processor Architecture  
Author: Kazuaki Murakami Hiroshi Miyajima Yasuhiko Saitoh Tetsuo Hironaka Satoru Shirakawa 
Address: 6-1 Kasuga-Koen Kasuga, Fukuoka 816 JAPAN  
Affiliation: Department of Information Systems Interdisciplinary Graduate School of Engineering Sciences Kyushu University  
Abstract: This paper describes a novel processor architecture, called hyperscalar processor architecture, which encompasses the advantages of superscalar, VLIW, and vector processor architectures and exculdes their disadvantages. In brief, hyper-scalar is a processor; i) whose instruction size and instruction-fetch bandwidth are the same as those of superscalar, ii) whose datapath is as large as that of VLIW, iii) which provides every independent functional unit with one or more compiler-visible registers, called instruction registers, and iv) which allows the program itself to load the instruction registers with instructions fetched from the memory and to execute them as a subroutine. As compiler techniques for creating an object code placed in the instruction registers, this paper proposes pseudo vector processing and software pipelining , and further discusses several issues on applying software pipeling to hyperscalar processors. This paper evaluates the performance attainable in hyperscalar processors, and then concludes that hyperscalar processors can outperform conventional superscalar, VLIW, and vector processors in terms of cost/performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Hashimoto, T., Murakami, K., Hironaka, T., and Yasuura, H., </author> <title> "A Micro-vectorprocessor Architecture | Performance Modeling and Benchmarking |," Proc. </title> <booktitle> 1993 Int'l. Conf. on Supercomputing , pp.308-317, </booktitle> <month> July </month> <year> 1993. </year>
Reference-contexts: Assuming that the number of functional units is f and the number of instruction registers per functional unit is r, f fi r instruction registers exist in a hyperscalar processor in total. f 1). Every row and column are denoted as IR i = fIR [i; 0]; IR <ref> [i; 1] </ref>; : : : ; IR [r 1; j]g and IR j = fIR [0; j]; IR [1; j]; : : :; IR [r 1; j]g, respectively. <p> Every row and column are denoted as IR i = fIR [i; 0]; IR [i; 1]; : : : ; IR [r 1; j]g and IR j = fIR [0; j]; IR <ref> [1; j] </ref>; : : :; IR [r 1; j]g, respectively. <p> The IR index register IRXR is reset to some value (e.g., 0). 4. In the turbo mode, the hyperscalar processor seems to execute a VLIW code of s VLIW instructions stored in IR i = fIR [i; 0]; IR <ref> [i; 1] </ref>; : : :; IR [i; f 1]g (0 i s 1 r 1). The IR index register IRXR works as the program counter. <p> Providing vector registers does not necessarily mean providing vector instructions as the instruction-set architecture. As pointed out in <ref> [1] </ref>, even though vector instructions are not provided, a sequence of scalar instructions (or, VLIW instructions) can operate on vector data stored in vector registers in a pseudo-vector-processing or software-pipelined manner (see Section 4). 4 Hyperscalar Compiler Compilers for hyperscalar processors should create object codes stored in IRs. <p> VP : A conventional vector processor with the computational throughput of 2FLOPC (floating-point operations per clock cycle). 6. VP+M+F : An extended model of the model VP , which introduces a mul-tithreading facility at vector-instruction level and allows vector registers to work as ring FIFO buffers <ref> [1] </ref>. The datapaths of the evaluation models SP , SSP , HSP , and VLIW are identical and based on that of the hyperscalar processor prototype, except that the model HSP+VR provides vector registers. <p> The datapaths of the evaluation models VP and VP+M+F are identical and based on that of the model Base 2 2 in <ref> [1] </ref>. For the evaluation models HSP , we assumed that the number of instruction registers IR i is infinite.
Reference: [2] <author> Hironaka, T., Saitoh, Y., and Murakami, K., </author> <title> "Hyperscalar Processor Architecture | Performance of Software Pipelining | (in Japanese)," </title> <type> IEICE Technical Report , VLD93-89, </type> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: IR [0; 0] : LD B (SR1) ! VR1 IR <ref> [0; 2] </ref> : ADD VR1 + VR2 ! VR3 IR [0; 4] : if VRXR (VR1)=31 then return to normal mode else branch to 0 Here, we assumed that load/store instructions (LD/ST) provide some scale-indexed addressing mode with post-increment for index registers (SR1, SR2, and SR3). <p> LD A (0) ! SR13 ADD SR13 + VR1 ! SR13 2. Steady state: The processor enters the turbo mode, and then executes the following VLIW code in IRs until the exit condition is satisified. IR [0; 0] : LD B (SR1) ! VR1 IR <ref> [0; 2] </ref> : ADD SR13 + VR1 ! SR13 IR [0; 4] : if SR1=30 then return to normal mode else branch to 0 3. Epilog: The processor exits the turbo mode, and then executes the fol lowing epilog code in the normal mode. <p> On the other hand, introducing vector registers into hyperscalar processors is not necessarily cost-effective. We therefore have proposed another method, called stage balancing <ref> [2] </ref>, which is suitable for hyperscalar processors. to keep all the register lifetimes shorter than a given III by spliting every longer lifetime into several shorter lifetime.
Reference: [3] <author> Hironaka, T., Saitoh, Y., Miyajima, H. and Murakami, K., </author> <title> "Hyperscalar Processor Architecture | Design and Performance Evaluation of the Prototype Processor |(in Japanese)," </title> <booktitle> Proc. 1994 Joint Symp. on Parallel Processing , pp.9-16., </booktitle> <month> May </month> <year> 1994. </year>
Reference: [4] <author> Jouppi, N. P., </author> <title> "The Nonuniform Distribution of Instruction-Level and Machine Parallelism and Its Effect on Performance," </title> <journal> IEEE Trans. Comput., vol.37, no.12, pp.1645-1658, Dec.1989. </journal>
Reference-contexts: A superpipelined processor with the clock rate m times higher than the original pipelined processor is said to provide the superpipeline degree of m <ref> [4] </ref>. A disadvantage of the superpipelined approach is that its performance improvement depends heavily on the growth of clock rate. <p> The number of instructions issued per clock cycle is called superscalar degree <ref> [4] </ref>. The performance of a superpipelined processor with the 3 superpipeline degree of m is theoretically equal to that of a superscalar processor with the superscalar degree n, if m = n. <p> IR [0; 0] : LD B (SR1) ! VR1 IR [0; 2] : ADD VR1 + VR2 ! VR3 IR <ref> [0; 4] </ref> : if VRXR (VR1)=31 then return to normal mode else branch to 0 Here, we assumed that load/store instructions (LD/ST) provide some scale-indexed addressing mode with post-increment for index registers (SR1, SR2, and SR3). And, VRXR (VR1) stands for the vector-register index-register for VR1. <p> Steady state: The processor enters the turbo mode, and then executes the following VLIW code in IRs until the exit condition is satisified. IR [0; 0] : LD B (SR1) ! VR1 IR [0; 2] : ADD SR13 + VR1 ! SR13 IR <ref> [0; 4] </ref> : if SR1=30 then return to normal mode else branch to 0 3. Epilog: The processor exits the turbo mode, and then executes the fol lowing epilog code in the normal mode.
Reference: [5] <author> Lam, M. S., </author> <title> A Systolic Array Optimizing Compiler , Kluwer Academic Publishers, </title> <address> pp.83-124, </address> <year> 1989. </year>
Reference-contexts: addition of B (0)+C (0) before entering the turbo mode, * addition of B (31)+C (31) after exiting the turbo mode, and * storing of A (30) and A (31). 4.2 Software Pipelining Software pipelining is a loop transformation technique which exploits instruction-level parallelism across consecutive iterations of a loop <ref> [5] </ref>. Pseudo vector processing described in Section 4.1 is also a kind of software pipelining. Pseudo vectorization can apply to vectorizable loops only, but software pipelining can also apply to non-vectorizable loops. <p> The processor resources include functional units and registers. For hyperscalar processors, when software pipelining is applied to the VLIW code stored in IRs, the resource constraints include the instruction registers. Modulo scheduling <ref> [5] </ref>, one of software pipelining algorithms, aims at minimizing the iteration initiation interval (III) of a target loop while satisfying the above constraints. If the obtained III is not smaller than the original III, then software pipelining for the loop failed. <p> Among them, anti-dependences which are caused by registers allocated 15 to data with long lifetime produce a detrimental effect on the III. There are the following conventional methods for relieving the effect of anti-dependences. * Modulo variable expansion <ref> [5] </ref>: Anti-dependences at issue occur when an iteration writes into a register before the preceeding iteration does not read the same register. If we allocate different registers, rather than a single register, to different iterations, we can resolve these anti-dependences.
Reference: [6] <author> Miyajima, H., Saitoh, Y., Hironaka, T. and Murakami, K., </author> <title> "Hyperscalar Processor Architecture | Design and Performance of High-Performance-Prototype Processor | (in Japanese)," </title> <type> IPSJ Technical Report, </type> <institution> ARC-105-7, </institution> <month> Mar. </month> <year> 1994. </year> <month> 22 </month>
Reference: [7] <author> Miyajima, H. and Murakami, K., </author> <title> "Hyperscalar Processor Architecture (in Japanese)," </title> <type> IPSJ Technical Report , ARC-107-4, </type> <month> Jul. </month> <year> 1994. </year>
Reference-contexts: performed by inserting several move register instructions at appropriate points during a long register lifetime for transmitting data from one register to another register continuously. 5 Performance Evaluation We evaluate the performance attainable in hyperscalar processors. 5.1 Evaluation Models We compare the performance of a hyperscalar processor prototype under development <ref> [7] </ref> with that of the following counterparts: * pipelined processor, * superscalar processor, 16 * VLIW processor, and * vector processor.
Reference: [8] <author> Murakami, K., </author> <title> "Hyperscalar Processor Architecture | The Fifth Approach to Instruction-Level Parallel Processing | (in Japanese)," </title> <booktitle> Proc. 1991 Joint Symp. on Parallel Processing , pp.133-140, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Hyperscalar processor architecture <ref> [8] </ref> is a "post-superscalar" architecture, which encompasses the advantages of (RISC-type) superscalar, VLIW (Very Long In fl This is an internal technical report describing research done at the Department of Information Systems of Kyushu University. 1 struction Word), and vector processor architectures and exculdes their disad- vantages.
Reference: [9] <author> Nakamura, H. et al., </author> <title> "A Scalar Architecture for Pseudo Vector Processing based on Slide-Windowd Registers," </title> <booktitle> Proc. 1993 Int'l. Conf. on Supercomputing, </booktitle> <address> pp.298-307, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: The following two methods are possible for transforming loops into object codes stored in IRs: * Pseudo vector processing * Software pipelining 10 4.1 Pseudo Vector Processing We refer to simulating a sequence of vector instructions by means of scalar or VLIW instructions as pseudo vector processing <ref> [9] </ref>. Let's use the following simple example for explaining the concept of pseudo vector processing in hyperscalar processors. do I=0, 31 do end Conventional vector processors execute this loop by means of the following sequence of vector instructions.
Reference: [10] <author> Rau, B. R. et al., </author> <title> "The Cydra 5 Departmental Supercomputer: Design Philosophies, Decisions, and Trade-offs," </title> <booktitle> Computer, </booktitle> <address> vol.22, no.1, pp.12-35, Jan.1989. </address>
Reference-contexts: If scalar instructions are allowed to access vector registers for computation, a more flexible loop-transformation technique than vectorization, i.e., software pipelining can be used. This is a disadvantage of vector processors against scalar or VLIW processors with a large register file, such as WM computer [11], Cydra5 <ref> [10] </ref>. 3 Hyperscalar Processor Architecture Hyperscalar processor architecture tries to include the above-mentioned advantages and exclude the disadvantages of superscalar, VLIW, and vector processor architectures. 4 3.1 Instruction Registers those of superscalar processors. For example, the instruction size might be 32 or 64 bits as in today's superscalar processors.
Reference: [11] <author> Wulf, W. A., </author> <title> "The WM Computer Architecture," </title> <journal> ACM SIGARCH Com-put. Architect. News, vol.16, no.1, pp.70-84, Mar.1988. </journal> <volume> 23 </volume>
Reference-contexts: If scalar instructions are allowed to access vector registers for computation, a more flexible loop-transformation technique than vectorization, i.e., software pipelining can be used. This is a disadvantage of vector processors against scalar or VLIW processors with a large register file, such as WM computer <ref> [11] </ref>, Cydra5 [10]. 3 Hyperscalar Processor Architecture Hyperscalar processor architecture tries to include the above-mentioned advantages and exclude the disadvantages of superscalar, VLIW, and vector processor architectures. 4 3.1 Instruction Registers those of superscalar processors.
References-found: 11

