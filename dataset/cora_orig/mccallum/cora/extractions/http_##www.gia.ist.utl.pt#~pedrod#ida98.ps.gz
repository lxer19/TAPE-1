URL: http://www.gia.ist.utl.pt/~pedrod/ida98.ps.gz
Refering-URL: http://www.gia.ist.utl.pt/~pedrod/
Root-URL: 
Email: E-mail: pedrod@gia.ist.utl.pt  
Title: Knowledge Discovery Via Multiple Models  
Author: Pedro Domingos 
Keyword: Classification, multiple models, meta-learning, comprehensible models, sta bility.  
Address: Lisbon 1096, Portugal  
Affiliation: Sec. Sistemas, Dept. Eng. Mec^anica Instituto Superior Tecnico Av. Rovisco Pais  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Andrews and J. Diederich, </author> <title> editors. Proceedings of the NIPS-96 Workshop on Rule Extraction from Trained Artificial Neural Networks. NIPS Foundation, </title> <publisher> Snowmass, CO, </publisher> <year> 1996. </year>
Reference-contexts: CMM is an example of a method for extracting comprehensible output from a learned model (in this case, a bagged ensemble of models). Substantial research has been carried out for the case where the model is a neural network (e.g., <ref> [31, 1] </ref>). Algorithms based on queries to an oracle are also relevant to this problem, and have been the object of much study in the theoretical community (e.g., [2]).
Reference: [2] <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 319-342, </pages> <year> 1988. </year>
Reference-contexts: Substantial research has been carried out for the case where the model is a neural network (e.g., [31, 1]). Algorithms based on queries to an oracle are also relevant to this problem, and have been the object of much study in the theoretical community (e.g., <ref> [2] </ref>). Although oracle-based algorithms are generally of limited usefulness when learning directly from real data, they can be applied more easily in the meta-learning phase, using the previously-learned model (or model ensemble) as the oracle (e.g., [10]).
Reference: [3] <author> L. Breiman. </author> <title> Bagging predictors. </title> <journal> Machine Learning, </journal> <volume> 24 </volume> <pages> 123-140, </pages> <year> 1996. </year>
Reference-contexts: It consists of learning several (say, fifty) different models by means of variations in the learner or the data, and then combining these models in some way to make predictions. Different forms of this "multiple models" approach include bagging <ref> [3] </ref>, boosting [18], stacking [34], Bayesian averaging [4], error-correcting output coding [22], combiner trees [7], and others. This approach has been found to be quite effective in practice [14, 29], and also has substantial theoretical foundations [23, 19]. <p> C4.5RULES also has the advantage of being widely used, and thus constituting a good standard for empirical comparisons. In this system, rules are extracted from a previously-learned decision tree, and are ordered (i.e., if more than one rule applies, the one appearing first in the ordering prevails). Bagging <ref> [3] </ref> was used as the multiple-model methodology, on account of being perhaps the simplest one available, and of its effectiveness with decision trees being well established [3, 29]. <p> Bagging [3] was used as the multiple-model methodology, on account of being perhaps the simplest one available, and of its effectiveness with decision trees being well established <ref> [3, 29] </ref>. In the bagging procedure, given a training set of size s, a "bootstrap" replicate of it is constructed by taking s samples with replacement from the training set. <p> This procedure is repeated m times, and the resulting m models are aggregated by uniform voting (i.e., when a test example is presented, the class that is predicted by the greatest number of models is predicted; if a tie occurs, the lowest-ordered class is chosen, as in <ref> [3] </ref>). 4 Examples for meta-learning are generated using the probability distribution implicit in the rule sets produced by C4.5RULES. <p> The results are shown in Figure 1, as averages over all datasets. m = 50 was found to produce no significant gains over m = 25, but m = 10 led to poor results. This suggests some atypicality in Breiman's <ref> [3] </ref> results on the (artificial) waveform domain, where he studied the effect of m and found most of the gain in accuracy to be obtained with 10 replicates, and also suggests that Quinlan [29] might have obtained even better results for bagging if more replicates had been used. m = 25 <p> Given that the randomly generated examples are added to the original ones, this implies that the training set size for meta-learning will always be at least twice the size of the original training set. An experimental methodology similar to that of <ref> [3] </ref> was followed, with 20 runs instead 6 of 100, due to the large number of datasets used. In each run, 90% of the examples in the dataset were randomly chosen for training, and the remainder were used for testing. Table 2 shows the resulting average accuracies and standard deviations.
Reference: [4] <author> W. L. Buntine. </author> <title> A Theory of Learning Classification Rules. </title> <type> PhD thesis, </type> <institution> School of Computing Science, University of Technology, </institution> <address> Sydney, Australia, </address> <year> 1990. </year>
Reference-contexts: It consists of learning several (say, fifty) different models by means of variations in the learner or the data, and then combining these models in some way to make predictions. Different forms of this "multiple models" approach include bagging [3], boosting [18], stacking [34], Bayesian averaging <ref> [4] </ref>, error-correcting output coding [22], combiner trees [7], and others. This approach has been found to be quite effective in practice [14, 29], and also has substantial theoretical foundations [23, 19]. <p> Work by Catlett [5] (Chapter 5), Quinlan [28] (Chapter 5), Evans and Fisher [16], and Fayyad, Djorgovski and Weir [17] has this flavor. Quinlan [27] briefly describes merging all branches from multiple decision trees into a single rule set and extracting the "best" rules, with promising results. Buntine <ref> [4] </ref> considers the extraction of a single "good" tree from an option tree (a compact representation of multiple trees) to be an important problem for future research. Kong and Dietterich [22] make a similar statement for error-correcting output coding and other multiple-model schemes.
Reference: [5] <author> J. Catlett. </author> <title> Megainduction: Machine Learning on Very Large Databases. </title> <type> PhD thesis, </type> <institution> Basser Department of Computer Science, University of Sydney, </institution> <address> Sydney, Australia, </address> <year> 1991. </year>
Reference-contexts: Apart from its effect on accuracy, pruning of decision trees and rule sets can be viewed as an attempt to extract a simpler, more comprehensible model from an overly complex one. Work by Catlett <ref> [5] </ref> (Chapter 5), Quinlan [28] (Chapter 5), Evans and Fisher [16], and Fayyad, Djorgovski and Weir [17] has this flavor. Quinlan [27] briefly describes merging all branches from multiple decision trees into a single rule set and extracting the "best" rules, with promising results.
Reference: [6] <author> P. Chan, S. Stolfo, and D. Wolpert, </author> <title> editors. Proceedings of the AAAI-96 Workshop on Integrating Multiple Learned Models for Improving and Scaling Machine Learning Algorithms. </title> <publisher> AAAI Press, </publisher> <address> Portland, OR, </address> <year> 1996. </year>
Reference-contexts: Other researchers have also noted the negative impact of instability on learners' ability to produce knowledge [12]. Recently, an approach that mitigates this problem has been the object of much research (see, for example, <ref> [6] </ref>). It consists of learning several (say, fifty) different models by means of variations in the learner or the data, and then combining these models in some way to make predictions.
Reference: [7] <author> P. K. Chan and S. J. Stolfo. </author> <title> A comparative evaluation of voting and meta-learning on partitioned data. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pages 90-98, </pages> <address> Tahoe City, CA, 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Different forms of this "multiple models" approach include bagging [3], boosting [18], stacking [34], Bayesian averaging [4], error-correcting output coding [22], combiner trees <ref> [7] </ref>, and others. This approach has been found to be quite effective in practice [14, 29], and also has substantial theoretical foundations [23, 19].
Reference: [8] <author> P. Clark and T. Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 261-283, </pages> <year> 1989. </year>
Reference-contexts: This is as desired, and leads to CMM's complexity staying below 250 for almost all domains. Thus, by this measure, CMM can be considered to produce comprehensible output in almost all cases, assuming C4.5RULES does. As a further comparison, another widely-used rule learner, CN2 <ref> [8] </ref>, was run on these datasets. While being on average less accurate than C4.5RULES and CMM, CN2 has an output complexity that is often greater than CMM's. This is further evidence that CMM is broadly competitive with single-model rule learners in its ability to produce comprehensible results.
Reference: [9] <author> D. Cohn, L. Atlas, and R. Ladner. </author> <title> Improving generalization with active learning. </title> <journal> Machine Learning, </journal> <volume> 15 </volume> <pages> 201-221, </pages> <year> 1994. </year>
Reference-contexts: Although oracle-based algorithms are generally of limited usefulness when learning directly from real data, they can be applied more easily in the meta-learning phase, using the previously-learned model (or model ensemble) as the oracle (e.g., [10]). More generally, many forms of active learning <ref> [9] </ref>, where the learner has some degree of control over the information it obtains from the environment, are potentially applicable to this problem. 5 Future Work Several directions for future research are readily apparent, apart from those already mentioned in previous sections.
Reference: [10] <author> M. W. Craven. </author> <title> Extracting Comprehensible Models from Trained Neural Networks. </title> <type> PhD thesis, </type> <institution> Department of Computer Sciences, University of Wisconsin - Madison, Madison, WI, </institution> <year> 1996. </year>
Reference-contexts: Although oracle-based algorithms are generally of limited usefulness when learning directly from real data, they can be applied more easily in the meta-learning phase, using the previously-learned model (or model ensemble) as the oracle (e.g., <ref> [10] </ref>). More generally, many forms of active learning [9], where the learner has some degree of control over the information it obtains from the environment, are potentially applicable to this problem. 5 Future Work Several directions for future research are readily apparent, apart from those already mentioned in previous sections.
Reference: [11] <author> P. Datta and D. Kibler. </author> <title> Learning prototypical concept descriptions. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pages 158-166, </pages> <address> Tahoe City, CA, 1995. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 16 </pages>
Reference-contexts: Datta and Kibler <ref> [11] </ref> have sought to develop single-model classifiers that are more stable than standard machine learning algorithms, but have so far not attempted to evaluate the comprehensibility of the prototype-based representation they use.
Reference: [12] <author> T. G. Dietterich. </author> <title> Editorial. </title> <journal> Machine Learning, </journal> <volume> 24 </volume> <pages> 91-93, </pages> <year> 1996. </year>
Reference-contexts: The engineers lose confidence in the decision trees, even when we can demonstrate that the trees have high predictive accuracy." [32]. Other researchers have also noted the negative impact of instability on learners' ability to produce knowledge <ref> [12] </ref>. Recently, an approach that mitigates this problem has been the object of much research (see, for example, [6]). It consists of learning several (say, fifty) different models by means of variations in the learner or the data, and then combining these models in some way to make predictions.
Reference: [13] <author> P. Domingos. </author> <title> Linear-time rule induction. </title> <booktitle> In Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pages 96-101, </pages> <address> Portland, OR, 1996. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: The number n of examples generated randomly for meta-learning was set to 1000. This value reflects the knowledge that C4.5RULES tends to produce rule sets whose size grows approximately linearly with training set size <ref> [13, 25] </ref>, and thus that using a very large n is likely to lead to unnecessarily complex models. Within this constraint, n was chosen to be larger than any of the dataset sizes present.
Reference: [14] <author> H. Drucker, C. Cortes, L. D. Jackel, Y. LeCun, and V. Vapnik. </author> <title> Boosting and other machine learning algorithms. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pages 53-61, </pages> <address> New Brunswick, NJ, 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Different forms of this "multiple models" approach include bagging [3], boosting [18], stacking [34], Bayesian averaging [4], error-correcting output coding [22], combiner trees [7], and others. This approach has been found to be quite effective in practice <ref> [14, 29] </ref>, and also has substantial theoretical foundations [23, 19].
Reference: [15] <author> R. O. Duda and P. E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <address> New York, NY, </address> <year> 1973. </year>
Reference-contexts: More precisely, if x is an unclassified example and c its class, since the "true" probability distribution P r (x) is usually unknown, it should be estimated as closely as possible. While many general methods exist for approximately solving this problem (e.g., Parzen windows <ref> [15] </ref>), in the implementation described below the approach followed is one of replicating the way the learner L implicitly models P r (x). This avoids a mismatch between the bias of L and that of the probability estimation procedure.
Reference: [16] <author> B. Evans and D. Fisher. </author> <title> Process delay analysis using decision tree induction. </title> <journal> IEEE Expert, </journal> <volume> 9(1) </volume> <pages> 60-66, </pages> <year> 1994. </year>
Reference-contexts: Apart from its effect on accuracy, pruning of decision trees and rule sets can be viewed as an attempt to extract a simpler, more comprehensible model from an overly complex one. Work by Catlett [5] (Chapter 5), Quinlan [28] (Chapter 5), Evans and Fisher <ref> [16] </ref>, and Fayyad, Djorgovski and Weir [17] has this flavor. Quinlan [27] briefly describes merging all branches from multiple decision trees into a single rule set and extracting the "best" rules, with promising results.
Reference: [17] <author> U. M. Fayyad, G. Piatetsky-Shapiro, and P. Smyth. </author> <title> From data mining to knowledge discovery: An overview. </title> <editor> In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining, </booktitle> <pages> pages 1-34. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1996. </year>
Reference-contexts: Work by Catlett [5] (Chapter 5), Quinlan [28] (Chapter 5), Evans and Fisher [16], and Fayyad, Djorgovski and Weir <ref> [17] </ref> has this flavor. Quinlan [27] briefly describes merging all branches from multiple decision trees into a single rule set and extracting the "best" rules, with promising results.
Reference: [18] <author> Y. Freund and R. E. Schapire. </author> <title> Experiments with a new boosting algorithm. </title> <booktitle> In Proceedings of the Thirteenth International Conference on Machine Learning, </booktitle> <pages> pages 148-156, </pages> <address> Bari, Italy, 1996. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: It consists of learning several (say, fifty) different models by means of variations in the learner or the data, and then combining these models in some way to make predictions. Different forms of this "multiple models" approach include bagging [3], boosting <ref> [18] </ref>, stacking [34], Bayesian averaging [4], error-correcting output coding [22], combiner trees [7], and others. This approach has been found to be quite effective in practice [14, 29], and also has substantial theoretical foundations [23, 19]. <p> be made as large as desired, subject to computational resource constraints, it should be possible to obtain a meta-learned model that is more accurate and stable than the base models. 1 Where two different training sets can be composed of the same instances, but with different weights, as in boosting <ref> [18] </ref>. 2 Which, in the limit, can be m different learners, as is typically done in stacking [34]. 3 Table 1: The CMM meta-learning algorithm.
Reference: [19] <author> J. H. Friedman. </author> <title> On bias, variance, 0/1 loss, and the curse-of-dimensionality. </title> <type> Technical report, </type> <institution> Department of Statistics and Stanford Linear Accelerator Center, Stanford University, Stanford, </institution> <address> CA, </address> <year> 1996. </year> <month> ftp://playfair.stanford.edu/pub/friedman/kdd.ps.Z. </month>
Reference-contexts: Different forms of this "multiple models" approach include bagging [3], boosting [18], stacking [34], Bayesian averaging [4], error-correcting output coding [22], combiner trees [7], and others. This approach has been found to be quite effective in practice [14, 29], and also has substantial theoretical foundations <ref> [23, 19] </ref>. However, the focus of this line of research has been on reducing instability as a means to improving accuracy; from the point of view of knowledge acquisition, it in fact represents a setback, because it gives up the essential goal of output comprehensibility.
Reference: [20] <author> D. Jensen. </author> <title> Adjusting for multiple testing in decision tree pruning. </title> <booktitle> In Preliminary Papers of the Sixth International Workshop on Artificial Intelligence and Statistics, </booktitle> <pages> pages 295-302, </pages> <address> Fort Lauderdale, FL, </address> <year> 1997. </year> <journal> Society for Artificial Intelligence and Statistics. </journal>
Reference: [21] <author> R. Kohavi and D. H. Wolpert. </author> <title> Bias plus variance decomposition for zero-one loss functions. </title> <booktitle> In Proceedings of the Thirteenth International Conference on Machine Learning, </booktitle> <pages> pages 275-283, </pages> <address> Bari, Italy, 1996. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, and crucially, because the accuracy and stability of learned models tend to increase with training set size (due to decreasing variance <ref> [21] </ref>), and the training set size for the meta-learning step can be made as large as desired, subject to computational resource constraints, it should be possible to obtain a meta-learned model that is more accurate and stable than the base models. 1 Where two different training sets can be composed of
Reference: [22] <author> E. B. Kong and T. G. Dietterich. </author> <title> Error-correcting output coding corrects bias and variance. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pages 313-321, </pages> <address> Tahoe City, CA, 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Different forms of this "multiple models" approach include bagging [3], boosting [18], stacking [34], Bayesian averaging [4], error-correcting output coding <ref> [22] </ref>, combiner trees [7], and others. This approach has been found to be quite effective in practice [14, 29], and also has substantial theoretical foundations [23, 19]. <p> Buntine [4] considers the extraction of a single "good" tree from an option tree (a compact representation of multiple trees) to be an important problem for future research. Kong and Dietterich <ref> [22] </ref> make a similar statement for error-correcting output coding and other multiple-model schemes. Shannon and Banks [30] have recently proposed a method for combining multiple decision trees into one, based on measuring distances between them and finding the "median" tree.
Reference: [23] <author> D. Madigan, A. E. Raftery, C. T. Volinsky, and J. A. Hoeting. </author> <title> Bayesian model averaging. </title> <booktitle> In Proceedings of the AAAI-96 Workshop on Integrating Multiple Learned Models for Improving and Scaling Machine Learning Algorithms, </booktitle> <pages> pages 77-83, </pages> <address> Port-land, OR, 1996. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Different forms of this "multiple models" approach include bagging [3], boosting [18], stacking [34], Bayesian averaging [4], error-correcting output coding [22], combiner trees [7], and others. This approach has been found to be quite effective in practice [14, 29], and also has substantial theoretical foundations <ref> [23, 19] </ref>. However, the focus of this line of research has been on reducing instability as a means to improving accuracy; from the point of view of knowledge acquisition, it in fact represents a setback, because it gives up the essential goal of output comprehensibility.
Reference: [24] <author> C. J. Merz, P. M. Murphy, and D. W. Aha. </author> <title> UCI repository of machine learning databases. Machine-readable data repository, </title> <institution> Department of Information and Computer Science, University of California at Irvine, </institution> <address> Irvine, CA, </address> <year> 1997. </year> <month> 17 </month>
Reference-contexts: To this end, experiments were carried out using a varied and representative sample of 26 datasets from the Irvine repository <ref> [24] </ref>. A value for m (the number of component models) was determined by comparing the accuracies obtained with m = 10, 25 and 50 on a subset of the datasets.
Reference: [25] <author> T. Oates and D. Jensen. </author> <title> The effects of training set size on decision tree complexity. </title> <booktitle> In Preliminary Papers of the Sixth International Workshop on Artificial Intelligence and Statistics, </booktitle> <pages> pages 379-390, </pages> <address> Fort Lauderdale, FL, </address> <year> 1997. </year> <journal> Society for Artificial Intelligence and Statistics. </journal>
Reference-contexts: The number n of examples generated randomly for meta-learning was set to 1000. This value reflects the knowledge that C4.5RULES tends to produce rule sets whose size grows approximately linearly with training set size <ref> [13, 25] </ref>, and thus that using a very large n is likely to lead to unnecessarily complex models. Within this constraint, n was chosen to be larger than any of the dataset sizes present.
Reference: [26] <author> M. Pazzani, S. Mani, and W. R. Shankle. </author> <title> Comprehensible knowledge discovery in databases. </title> <booktitle> In Proceedings of the Ninenteenth Annual Conference of the Cognitive Science Society, </booktitle> <address> Stanford, CA, 1997. </address> <publisher> Erlbaum. </publisher>
Reference-contexts: A limitation of the work described here is that it uses a somewhat naive notion of comprehensibility, equating it with simplicity. In reality, many other factors are involved, and will vary from one user group to another (e.g., <ref> [26] </ref>). Although arriving at a better definition of comprehensibility is a difficult task due to the subjective component involved, much progress should result from seeking a deeper understanding of what makes a model comprehensible, and using the results to guide algorithms like CMM.
Reference: [27] <author> J. R. Quinlan. </author> <title> Generating production rules from decision trees. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 304-307, </pages> <address> Milan, Italy, 1987. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Work by Catlett [5] (Chapter 5), Quinlan [28] (Chapter 5), Evans and Fisher [16], and Fayyad, Djorgovski and Weir [17] has this flavor. Quinlan <ref> [27] </ref> briefly describes merging all branches from multiple decision trees into a single rule set and extracting the "best" rules, with promising results.
Reference: [28] <author> J. R. Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: C4.5RULES <ref> [28] </ref> release 8 was used as the base learner. C4.5RULES produces propositional rule sets, which we believe to be the most easily understood of all representations currently in use. C4.5RULES also has the advantage of being widely used, and thus constituting a good standard for empirical comparisons. <p> Apart from its effect on accuracy, pruning of decision trees and rule sets can be viewed as an attempt to extract a simpler, more comprehensible model from an overly complex one. Work by Catlett [5] (Chapter 5), Quinlan <ref> [28] </ref> (Chapter 5), Evans and Fisher [16], and Fayyad, Djorgovski and Weir [17] has this flavor. Quinlan [27] briefly describes merging all branches from multiple decision trees into a single rule set and extracting the "best" rules, with promising results.
Reference: [29] <author> J. R. Quinlan. Bagging, </author> <title> boosting, </title> <booktitle> and C4.5. In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 725-730, </pages> <address> Portland, OR, 1996. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Different forms of this "multiple models" approach include bagging [3], boosting [18], stacking [34], Bayesian averaging [4], error-correcting output coding [22], combiner trees [7], and others. This approach has been found to be quite effective in practice <ref> [14, 29] </ref>, and also has substantial theoretical foundations [23, 19]. <p> Bagging [3] was used as the multiple-model methodology, on account of being perhaps the simplest one available, and of its effectiveness with decision trees being well established <ref> [3, 29] </ref>. In the bagging procedure, given a training set of size s, a "bootstrap" replicate of it is constructed by taking s samples with replacement from the training set. <p> This suggests some atypicality in Breiman's [3] results on the (artificial) waveform domain, where he studied the effect of m and found most of the gain in accuracy to be obtained with 10 replicates, and also suggests that Quinlan <ref> [29] </ref> might have obtained even better results for bagging if more replicates had been used. m = 25 was used throughout the studies reported below. The number n of examples generated randomly for meta-learning was set to 1000.
Reference: [30] <author> W. D. Shannon and D. </author> <title> Banks. A distance metric for classification trees. </title> <booktitle> In Preliminary Papers of the Sixth International Workshop on Artificial Intelligence and Statistics, </booktitle> <pages> pages 457-464, </pages> <address> Fort Lauderdale, FL, </address> <year> 1997. </year> <journal> Society for Artificial Intelligence and Statistics. </journal>
Reference-contexts: Buntine [4] considers the extraction of a single "good" tree from an option tree (a compact representation of multiple trees) to be an important problem for future research. Kong and Dietterich [22] make a similar statement for error-correcting output coding and other multiple-model schemes. Shannon and Banks <ref> [30] </ref> have recently proposed a method for combining multiple decision trees into one, based on measuring distances between them and finding the "median" tree. Their approach is considerably more complex than CMM, and has not yet been implemented, or shown to improve on the accuracy and stability of single trees.
Reference: [31] <author> G. G. Towell and J. W. Shavlik. </author> <title> Extracting refined rules from knowledge-based neural networks. </title> <journal> Machine Learning, </journal> <volume> 13 </volume> <pages> 71-101, </pages> <year> 1993. </year>
Reference-contexts: CMM is an example of a method for extracting comprehensible output from a learned model (in this case, a bagged ensemble of models). Substantial research has been carried out for the case where the model is a neural network (e.g., <ref> [31, 1] </ref>). Algorithms based on queries to an oracle are also relevant to this problem, and have been the object of much study in the theoretical community (e.g., [2]).
Reference: [32] <author> P. Turney. </author> <title> Bias and the quantification of stability. </title> <journal> Machine Learning, </journal> <volume> 20 </volume> <pages> 23-33, </pages> <year> 1995. </year>
Reference-contexts: The engineers lose confidence in the decision trees, even when we can demonstrate that the trees have high predictive accuracy." <ref> [32] </ref>. Other researchers have also noted the negative impact of instability on learners' ability to produce knowledge [12]. Recently, an approach that mitigates this problem has been the object of much research (see, for example, [6]). <p> This is a matter for future research. Stability was measured following the ideas contained in <ref> [32] </ref>, and taking advantage of the models produced in the train-test runs carried out. The stability of a system is defined as the (estimated) probability that models generated by the system from different training sets will agree on an arbitrary example. <p> The use of a uniform distribution reflects a deeper notion of stability than that implicit in using some estimate of the dataset's distribution <ref> [32] </ref>. Note that, because the different models are not generated from independent training sets, the empirical measure above will tend to overestimate stability. The results are shown in Table 3. On average, bagging is 6% more stable than a single run of C4.5RULES.
Reference: [33] <author> J. Utans. </author> <title> Weight averaging for neural networks and local resampling schemes. </title> <booktitle> In Proceedings of the AAAI-96 Workshop on Integrating Multiple Learned Models for Improving and Scaling Machine Learning Algorithms, </booktitle> <pages> pages 133-138, </pages> <address> Portland, OR, 1996. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: 70.51.3 Horse colic 86.3 85.81.2 84.71.2 Heart disease 81.8 79.01.7 80.01.6 Solar flare 69.2 69.11.4 69.41.4 Primary tumor 43.4 40.12.0 39.32.2 Liver disease 66.0 67.31.9 64.91.3 Voting records 95.5 95.60.7 95.10.7 Credit 87.5 86.20.8 86.70.8 Pima diabetes 75.5 75.20.7 74.50.9 Annealing 96.2 85.60.9 96.10.5 Average 77.4 74.9 76.3 12 13 <ref> [33] </ref> combined multiple neural networks into one by averaging parameters, with the goal of achieving performance-time computational savings; the output still suffers from the opaqueness of a neural network.
Reference: [34] <author> D. Wolpert. </author> <title> Stacked generalization. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 241-259, </pages> <year> 1992. </year> <month> 18 </month>
Reference-contexts: It consists of learning several (say, fifty) different models by means of variations in the learner or the data, and then combining these models in some way to make predictions. Different forms of this "multiple models" approach include bagging [3], boosting [18], stacking <ref> [34] </ref>, Bayesian averaging [4], error-correcting output coding [22], combiner trees [7], and others. This approach has been found to be quite effective in practice [14, 29], and also has substantial theoretical foundations [23, 19]. <p> a meta-learned model that is more accurate and stable than the base models. 1 Where two different training sets can be composed of the same instances, but with different weights, as in boosting [18]. 2 Which, in the limit, can be m different learners, as is typically done in stacking <ref> [34] </ref>. 3 Table 1: The CMM meta-learning algorithm. Inputs: S is the training set, L is a learning algorithm, C is a procedure for combining models, m is the no. of component models to generate, n is the no. of new examples to generate.
References-found: 34

