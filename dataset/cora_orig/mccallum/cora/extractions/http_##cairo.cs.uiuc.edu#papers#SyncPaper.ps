URL: http://cairo.cs.uiuc.edu/papers/SyncPaper.ps
Refering-URL: http://cairo.cs.uiuc.edu/papers.html
Root-URL: http://www.cs.uiuc.edu
Title: Lip Synchronization within an Adaptive VOD System  
Author: Lintian Qiao and Klara Nahrstedt 
Affiliation: Computer Science Department, University of Illinois  
Abstract: Many current distributed multimedia applications such as Video on Demand (VOD) are designed, implemented and used on top of general purpose OS and network platforms (e.g., UNIX/Internet)). Within this `best-effort' environment to achieve user acceptance for lip synchronization of the audio-visual information, applications must use adaptive synchronization protocols and balance non-deterministic behavior of the underlying OS/network subsystem. We have designed, implemented and validated an adaptive synchronization scheme integrating adaptive services and synchronization protocols to provide lip synchronization within a VOD system. Our results show most of the synchronization skew values (85 %) in the user desirable range of (-80, 80) ms and the remaining skew values in the user acceptable range of (-160, 160) ms.
Abstract-found: 1
Intro-found: 1
Reference: [AFKN95] <author> R. T. Apteker, J. A. Fisher, V. S. Kisimov, and H. Neishlos. </author> <title> Video Acceptability and Frame Rate. </title> <booktitle> IEEE Multimedia, </booktitle> <address> FALL:32-40, </address> <year> 1995. </year>
Reference-contexts: According to the experimental results in <ref> [AFKN95] </ref>, reducing video frame rate from the normal rate 30 fps to even 10 fps is acceptable, especially in a multitasking windowed environment.
Reference: [AH91] <author> D.P. Anderson and G. Homsy. </author> <title> A Continuous Media I/O Server and its Synchronization Mechanism. </title> <journal> IEEE Computer, </journal> <volume> 24(10) </volume> <pages> 51-57, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: From the synchronization specification, the internal system derives presentation sched-ulers and local synchronizers. Examples of systems which include this type of schedulers are MODE [Bla93], multimedia teleorchestra [LKG94], continuous media I/O server <ref> [AH91] </ref> or ACME [AH91] systems. These systems rely on special purpose stream schedulers/schemes to achieve local synchronization with low jitters and skews. Within a distributed environment, protocol-based techniques are applied. <p> From the synchronization specification, the internal system derives presentation sched-ulers and local synchronizers. Examples of systems which include this type of schedulers are MODE [Bla93], multimedia teleorchestra [LKG94], continuous media I/O server <ref> [AH91] </ref> or ACME [AH91] systems. These systems rely on special purpose stream schedulers/schemes to achieve local synchronization with low jitters and skews. Within a distributed environment, protocol-based techniques are applied. Shephers's scheme [SS90] suggests two different techniques for inter-stream synchronization, the synchronization marker (SM) for indication of synchronization points and the synchronization channel.
Reference: [Bla93] <author> G. Blakowski. </author> <title> Development and Runtime Support for Distributed Multimedia Applications. </title> <publisher> Verlag Shaker, </publisher> <address> German edition, </address> <year> 1993. </year>
Reference-contexts: Known synchronization specifications are time-axis based specification, timed petri nets, interval-based specification, or time flow graphs ([SN95, Lit93, LKG94, WR94, PLL96], etc.). From the synchronization specification, the internal system derives presentation sched-ulers and local synchronizers. Examples of systems which include this type of schedulers are MODE <ref> [Bla93] </ref>, multimedia teleorchestra [LKG94], continuous media I/O server [AH91] or ACME [AH91] systems. These systems rely on special purpose stream schedulers/schemes to achieve local synchronization with low jitters and skews. Within a distributed environment, protocol-based techniques are applied.
Reference: [CTCL95] <author> Z. Chen, S-M. Tan, R.H. Campbell, and Y. Li. </author> <title> Real Time Video and Audio in the World Wide Web. </title> <note> In WWW 95, </note> <year> 1995. </year>
Reference-contexts: In our system, we do not assume global synchronized clocks, and we consider lip synchronization when adaptive application gets insufficient resources from the underlying system. Some of these services/protocols can be found in protocols such as vat, nv, vic, VDP <ref> [Moo94, CTCL95, RRV93] </ref>, and others. However, these protocols do not yet support lip synchronization. The protocols do, however, include intra-stream adaptation towards the system changes by dropping information within a stream if system resources are not available. 3.1 Rate Specification Each continuous stream includes spatial and temporal synchronization information.
Reference: [EDP92] <author> J. Escobar, D. Deutsch, and C. Patridge. </author> <title> Flow Synchronization Protocol. </title> <booktitle> In Proceedings of IEEE Globecom, </booktitle> <pages> pages 1381-1387, </pages> <year> 1992. </year> <note> vol. 3. </note>
Reference-contexts: SDS performs the synchronization recovery at the multimedia receiver before the playback and employs the synchronization parameters to guarantee the 2 control for the different types of data streams. The protocol-based synchronization techniques must deal with system changes such as network delays. Escobar's flow synchronization protocol <ref> [EDP92] </ref> takes into account the dynamic changes in network delays by monitoring the jitter and re-synchronizing at the receiver if necessary. However, it assumes the presence of global clock in a distributed environment at all time. Similar approach is taken in the Rothemel's adaptive synchronization protocol [RH95].
Reference: [Lit93] <author> T. D. C. Little. </author> <title> A Framework for Synchronous Delivery of Time-Dependent Multimedia Data. </title> <journal> Multimedia Systems, </journal> <volume> 1(2) </volume> <pages> 87-94, </pages> <year> 1993. </year>
Reference: [LKG94] <author> L. Li, A. Karmouch, and N. Georganas. </author> <title> Multimedia Tele-orchestra with Independent Sources: Part 2 Synchronization Algorithm. </title> <journal> Multimedia Systems, </journal> <volume> 1(4) </volume> <pages> 154-165, </pages> <year> 1994. </year>
Reference-contexts: Known synchronization specifications are time-axis based specification, timed petri nets, interval-based specification, or time flow graphs ([SN95, Lit93, LKG94, WR94, PLL96], etc.). From the synchronization specification, the internal system derives presentation sched-ulers and local synchronizers. Examples of systems which include this type of schedulers are MODE [Bla93], multimedia teleorchestra <ref> [LKG94] </ref>, continuous media I/O server [AH91] or ACME [AH91] systems. These systems rely on special purpose stream schedulers/schemes to achieve local synchronization with low jitters and skews. Within a distributed environment, protocol-based techniques are applied. <p> Nicolau's scheme [Nic90] identifies two levels of data elements for defining synchronization points. The logical synchronization frames (LSF) are defined as the unit of synchronization for the control application while physical synchronization frames (PSF) are for the communication subsystem. Li <ref> [LKG94] </ref> presents a multimedia segment delivery scheme (SDS) for the simultaneous delivery of multimedia streams belonging to the same time interval. SDS performs the synchronization recovery at the multimedia receiver before the playback and employs the synchronization parameters to guarantee the 2 control for the different types of data streams.
Reference: [Moo94] <author> G. Moon. </author> <title> New video and multimedia products. Internet Electronic Mail, </title> <month> February </month> <year> 1994. </year> <title> from rem-conf&.es.net news group. </title>
Reference-contexts: In our system, we do not assume global synchronized clocks, and we consider lip synchronization when adaptive application gets insufficient resources from the underlying system. Some of these services/protocols can be found in protocols such as vat, nv, vic, VDP <ref> [Moo94, CTCL95, RRV93] </ref>, and others. However, these protocols do not yet support lip synchronization. The protocols do, however, include intra-stream adaptation towards the system changes by dropping information within a stream if system resources are not available. 3.1 Rate Specification Each continuous stream includes spatial and temporal synchronization information.
Reference: [Nic90] <author> C. Nicolau. </author> <title> An Architecture for Real-Time Multimedia Communication Systems. </title> <journal> IEEE JSAC, </journal> <volume> 8 </volume> <pages> 391-400, </pages> <month> April </month> <year> 1990. </year> <title> 14 , shows the occurrence results for Test 2. </title>
Reference-contexts: Within a distributed environment, protocol-based techniques are applied. Shephers's scheme [SS90] suggests two different techniques for inter-stream synchronization, the synchronization marker (SM) for indication of synchronization points and the synchronization channel. The synchronization markers are transmitted over a separate synchronization channel. Nicolau's scheme <ref> [Nic90] </ref> identifies two levels of data elements for defining synchronization points. The logical synchronization frames (LSF) are defined as the unit of synchronization for the control application while physical synchronization frames (PSF) are for the communication subsystem.
Reference: [NQ96] <author> K. Nahrstedt and L. Qiao. </author> <title> A Tuning System for Distributed Multimedia Applications. </title> <type> Technical Report UIUCDCS-R-96-1958, CS, </type> <institution> University of Illinois, Urbana, IL, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: The recording rate is determined during the recording phase when the audio and video are digitized and MPEG compressed. This rate is important because of synchronization between audio and video streams. The system rate is determined during the call establishment phase where we use probe-based algorithm <ref> [NQ96] </ref>. This algorithm uses a probe a continuous clip from the beginning of the stream to determine what is the possible system rate at the client side. <p> If it's not sufficient, we apply the same strategy to P frames and then I frames. This also implies a B, P, I priority in increasing order. The algorithm's details and experimental validation in UNIX/Internet environment are described in <ref> [NQ96] </ref>. 4 Lip Synchronization To address the lip synchronization problem within an adaptive application there are two important observations to note: First, human perception of changing sampling rate depends on the media. <p> The monitoring and adaptation services at the server and client side are tightly coupled in a tuning system and create a complex adaptive/feedback control loop to adapt against changes introduced by the user, by the network/OS, or between application resources available during recording and playback phases <ref> [NQ96] </ref>. 5.2 Experimental Setup Our VOD application with its clients and server are implemented on SGI Indy machines. The client and the server are connected via 10 Mbps Ethernet. The adaptive synchronization protocol has been tested on various video clips. We have selected two representative movies to show our results. <p> It is important to note that our adaptive scheme is scalable and works for various rate changes between the recording and the system rate (e.g., change from requested 20 fps to system rate of 7 or 5 fps, depending on available resources). Extensive tests and results are shown in <ref> [NQ96] </ref>. The second clip (lect-iso.mpg and lect-iso.mp2) is played in black-and-white color.
Reference: [Org93] <author> International Standards Organization. </author> <title> Information technology Coding of Moving Pictures and Associated Audio for Digital Storage Media at up to about 1.5 mbit/s Part 1: </title> <journal> Systems. </journal> <note> International Standard ISO/IEC IS 11172-1, </note> <year> 1993. </year>
Reference-contexts: Based on these observations, we set as a policy that no intentional adaptation of MPEG-1 compressed audio data will be considered in our scheme. When less system resources are available, only MPEG-1 compressed video data are to be dropped. MPEG-1 system standard ISO/IEC 11172-1 <ref> [Org93] </ref> specifies synchronization relations between audio and video objects, but it cannot be used in our approach.
Reference: [PLL96] <author> M. J. Perez-Luque and T. D. C. Little. </author> <title> A Temporal Reference Framework for Multimedia Synchronization. </title> <journal> Journal on Selected Areas in Communication, </journal> <volume> 14(1) </volume> <pages> 36-51, </pages> <month> January </month> <year> 1996. </year>
Reference: [RH95] <author> K. Rothemel and T. Helbig. </author> <title> An adaptive synchronization protocol. </title> <booktitle> In Proceedings of NOSDAV, </booktitle> <address> Durham, New Hampshire, </address> <year> 1995. </year>
Reference-contexts: However, it assumes the presence of global clock in a distributed environment at all time. Similar approach is taken in the Rothemel's adaptive synchronization protocol <ref> [RH95] </ref>. Another approach to re-synchronize is to send feedback. An example is Ramanathan's feedback technique [RVR92]. The multimedia server provides distribution of video streams over BISDN to mediaphones which are devices that have minimum capability to playback media and lack the sophistication to run any type of synchronization mechanism.
Reference: [RKR96] <author> P. V. Rangan, S. S. Kumar, , and S. Rajan. </author> <title> Continuity and Synchronization in MPEG. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 14(1) </volume> <pages> 52-60, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: The intra-stream and inter-stream synchronization are maintained by mediaphone's sending feedback units (lightweight messages) to the server. Bounded buffering and feedback from all devices are used for inter-media synchronization. With the compression of video streams, the intra-stream synchronization must be controlled closer. Ran-gan <ref> [RKR96] </ref> discusses the continuity and synchronization issues in MPEG compressed video streams. 3 Assumptions and Basic Concepts Our adaptive distributed applications are VOD systems (Figure 1). <p> MPEG-1 system standard ISO/IEC 11172-1 [Org93] specifies synchronization relations between audio and video objects, but it cannot be used in our approach. The reason is that our adaptive scheme manipulates video streams at their frame level, and the interleaving and packetizing structure <ref> [RKR96] </ref> of MPEG-1 system standard would require that we introduce too much overhead to access individual video frames.
Reference: [RRV93] <author> S. Ramanathan, P. V. Rangan, and H.M. Vin. </author> <title> Frame-Induced Packet Discarding: An Efficient Strategy for Video Networking. </title> <booktitle> In Proceedings of NOSDAV, </booktitle> <address> Lancaster, England, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: In our system, we do not assume global synchronized clocks, and we consider lip synchronization when adaptive application gets insufficient resources from the underlying system. Some of these services/protocols can be found in protocols such as vat, nv, vic, VDP <ref> [Moo94, CTCL95, RRV93] </ref>, and others. However, these protocols do not yet support lip synchronization. The protocols do, however, include intra-stream adaptation towards the system changes by dropping information within a stream if system resources are not available. 3.1 Rate Specification Each continuous stream includes spatial and temporal synchronization information.
Reference: [RS92] <author> L.A. Rowe and B.C. Smith. </author> <title> Continuous media player. </title> <booktitle> In Proceedings of NOSDAV, </booktitle> <address> San Diego, CA, </address> <year> 1992. </year>
Reference-contexts: The data in the buffer is queued in data's time stamp order. In doing so, we can manage the out-of-order arriving data by insert the late data into correct position if not too late. MPEG-1 video stream is decoded using software-based MPEG decoder based on Berkeley's MPEG-Player <ref> [RS92] </ref>. The decoded MPEG-1 audio stream is sent to audio device which then fully controls the playback of audio data in its buffer (audio device buffer, different from the client audio ring buffer). The server system uses RAID for retrieval of video and audio data.
Reference: [RVR92] <author> P. V. Rangan, H.M. Vin, and S. Ramanathan. </author> <title> Designing an On-Demand Multimedia Service. </title> <journal> IEEE Communications Magazine, </journal> <volume> 30(7) </volume> <pages> 56-65, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: However, it assumes the presence of global clock in a distributed environment at all time. Similar approach is taken in the Rothemel's adaptive synchronization protocol [RH95]. Another approach to re-synchronize is to send feedback. An example is Ramanathan's feedback technique <ref> [RVR92] </ref>. The multimedia server provides distribution of video streams over BISDN to mediaphones which are devices that have minimum capability to playback media and lack the sophistication to run any type of synchronization mechanism.
Reference: [SN95] <author> R. Steinmetz and K. Nahrstedt. Multimedia:Computing, </author> <title> Communications, and Applications. </title> <publisher> Prentice Hall, Inc., </publisher> <year> 1995. </year>
Reference-contexts: Our experiments show skews within the limit of 80 ms between audio and video, which is considered as user desirable skew <ref> [SN95] </ref>. The paper is outlined as follows: Section 2 discusses relevant related work in the area of multimedia synchronization. Section 3 briefly presents our video adaptation within a VOD system. Section 4 discusses the adaptive synchronization scheme. <p> The major requirements for audio/video synchronization in multimedia systems are bounded jitters within a continuous stream and minimal and acceptable skews among dependent streams. Steinmetz's experiments <ref> [SN95] </ref> measured audio-visual skews within an analog environment that are perceived as "out-of-sync". A desired lip synchronization skew should be 80 ms. Between 80 ms and 160 ms the skew was found acceptable. However, beyond 160 ms skew is perceived as annoying. <p> It is a simple but effective way to provide good synchronization abstraction for media contents. All single medium objects are attached to a time axis that presents an abstraction of real-time <ref> [SN95] </ref>. During the recording phase, each audio and video LDU (Logical Data Unit) is time-stamped 1 with the starting playout time within the stream. Due to audio loss sensitivity, audio stream is used as the time-axis divider and the master stream to control the playout. <p> For the waiting operation, we follow the concept of Restricted Blocking which was introduced by Steinmetz <ref> [SN95] </ref>. While waiting for audio segment to finish playback, the system performs other actions, like reading network (receive more data from server), de-multiplexing, and monitoring system status. 5 Implementation and Experiments 5.1 Implementation Issues The communication flow between the client and the server uses two communication channels.
Reference: [SS90] <author> M. Salmony and D. Shepherd. </author> <title> Extending OSI to Support Synchronization Required by Multimedia Applications. </title> <journal> Computer Communication, </journal> <volume> 13 </volume> <pages> 399-406, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: These systems rely on special purpose stream schedulers/schemes to achieve local synchronization with low jitters and skews. Within a distributed environment, protocol-based techniques are applied. Shephers's scheme <ref> [SS90] </ref> suggests two different techniques for inter-stream synchronization, the synchronization marker (SM) for indication of synchronization points and the synchronization channel. The synchronization markers are transmitted over a separate synchronization channel. Nicolau's scheme [Nic90] identifies two levels of data elements for defining synchronization points.
Reference: [WR94] <author> T. Wahl and K. Rothermel. </author> <title> Representing Time in Multimedia Systems. </title> <booktitle> In Proceedings of Multimedia Computing and Systems, </booktitle> <pages> pages 538-543, </pages> <address> Boston,MA, </address> <month> May </month> <year> 1994. </year> <month> 15 </month>
References-found: 20

