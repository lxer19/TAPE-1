URL: ftp://cns.brown.edu/nin/papers/3dreal-3.ps.Z
Refering-URL: http://www.math.tau.ac.il/~nin/research.html
Root-URL: 
Phone: 1843,  
Title: Three-Dimensional Object Recognition Using an Unsupervised BCM Network: The Usefulness of Distinguishing Features  
Author: Nathan Intrator Joshua I. Gold 
Keyword: unsupervised learning, feature extraction, dimensionality reduction, object recogni tion.  
Note: To Appear in Neural Computation Research was supported by the National Science Foundation, the Army Research Office, and the Office of Naval Research.  
Date: May 26, 1992  
Address: Box  Providence, RI 02912  
Affiliation: Center for Neural Science  Brown University  
Abstract: We propose an object recognition scheme based on a method for feature extraction from gray level images that corresponds to recent statistical theory, called projection pursuit, and is derived from a biologically motivated feature extracting neuron. To evaluate the performance of this method we use a set of very detailed psychophysical 3D object recognition experiments (Bulthoff and Edelman, 1992). 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bear, M. F. and Cooper, L. N. </author> <year> (1990). </year> <title> Molecular mechanisms for synaptic modification in the visual cortex: Interaction between theory and experiment. </title> <editor> In Gluck, M. and Rumelhart, D., editors, </editor> <booktitle> Neuroscience and Connectionist Theory, </booktitle> <pages> pages 65-94. </pages> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, New Jersey. </address>
Reference: <author> Bear, M. F., Cooper, L. N., and Ebner, F. F. </author> <year> (1987). </year> <title> A physiological basis for a theory of synapse modification. </title> <journal> Science, </journal> <volume> 237 </volume> <pages> 42-48. </pages>
Reference: <author> Bienenstock, E. L., Cooper, L. N., and Munro, P. W. </author> <year> (1982). </year> <title> Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex. </title> <journal> Journal Neuroscience, </journal> <volume> 2 </volume> <pages> 32-48. </pages>
Reference-contexts: The projection index usually measures some form of deviation from normality of the projected distribution. 4 Intrator (1990) presented a multiple feature extraction method that seeks multi-modality in the projected distributions. This method is based on a modified version of the BCM neuron <ref> (Bienenstock et al., 1982) </ref>. The biological relevance of this neuron has been extensively studied (Bear et al., 1987; Bear and Cooper, 1990; Gold, 1991), and it was shown that results of this method are in agreement with classical visual deprivation experiments (Clothiaux et al., 1991).
Reference: <author> Bulthoff, H. H. and Edelman, S. </author> <year> (1992). </year> <title> Psychophysical support for a 2-D view interpolation theory of object recognition. </title> <booktitle> Proceedings of the National Academy of Science, </booktitle> <volume> 89 </volume> <pages> 60-64. </pages>
Reference-contexts: To evaluate the performance of this method based on the above criteria we use a set of very detailed psychophysical 3D object recognition experiments <ref> (Bulthoff and Edelman, 1992) </ref>.
Reference: <author> Clothiaux, E. E., Cooper, L. N., and Bear, M. F. </author> <year> (1991). </year> <title> Synaptic plasticity in visual cortex: Comparison of theory with experiment. </title> <journal> Journal of Neurophysiology, </journal> <volume> 66 </volume> <pages> 1785-1804. </pages>
Reference-contexts: The biological relevance of this neuron has been extensively studied (Bear et al., 1987; Bear and Cooper, 1990; Gold, 1991), and it was shown that results of this method are in agreement with classical visual deprivation experiments <ref> (Clothiaux et al., 1991) </ref>.
Reference: <author> Duda, R. O. and Hart, P. E. </author> <year> (1973). </year> <title> Pattern Classification and Scene Analysis. </title> <publisher> John Wiley, </publisher> <address> New York. </address>
Reference-contexts: appropriate for testing the usefulness of our features of recognition. 2 A new model for object recognition based on a novel set of features Many feature extraction theories for object recognition are based on the assumption that objects are represented by clusters of points in a high dimensional feature space. <ref> (Duda and Hart, 1973) </ref>. However, finding clusters in very high dimensional space suffers from the inherent sparsity of such space, and therefore can not be directly approached by classical methods such as cluster analysis (Duda and Hart, 1973), discriminant analysis (Fisher, 1936; Sebestyen, 1962), or factor analysis (Harman, 1967). <p> the assumption that objects are represented by clusters of points in a high dimensional feature space. <ref> (Duda and Hart, 1973) </ref>. However, finding clusters in very high dimensional space suffers from the inherent sparsity of such space, and therefore can not be directly approached by classical methods such as cluster analysis (Duda and Hart, 1973), discriminant analysis (Fisher, 1936; Sebestyen, 1962), or factor analysis (Harman, 1967). <p> to find different projections (i.e., features), combined with the simplicity of the projection index, make this method computationally practical for multiple feature extraction in high dimensional spaces 2 See (Intrator and Cooper, 1992) for a discussion of the difference. 3 Principal components may not retain enough structure needed for classification <ref> (Duda and Hart, 1973, p. 212) </ref>. 4 For a discussion on various projection indices, see Huber (1985), Jones and Sibson (1987), Intrator and Cooper (1992). <p> We, on the other hand, want to concentrate on the examination of the properties of our proposed feature extraction method and therefore in this study have chosen to use a classical, well-known classifier, based on the k-nearest-neighbor-rule 5 <ref> (see for example, Duda and Hart, 1973) </ref>. In addition to the type of classifier used, the recognition paradigm with which the system is tested is a vital component in determining the usefulness of the features extracted.
Reference: <author> Edelman, S. </author> <year> (1991). </year> <title> Features of recognition. </title> <type> CS-TR 10, </type> <institution> Weizmann Institute of Science. </institution>
Reference-contexts: The dimensionality reducing transformation is based on projecting the pixel image onto a set of object features. The actual form of object features, and methods of extracting them, are not at all clear and are subject to current research in many disciplines <ref> (Edelman, 1991) </ref>. We propose to use a method for feature extraction which corresponds to recent statistical theory (Friedman and Tukey, 1974; Friedman, 1987) and is based on a biologically motivated feature extracting neuron. <p> when generalization was required along the horizontal, as opposed to the vertical, plane. 3.2 Experimental Paradigm In the first part of the study, the network was tested on a 63 by 63 array of 8-bit gray-scale values with a paradigm nearly identical to the one used in the psychophysical investigation <ref> (Edelman and Bulthoff, 1991) </ref>. The procedure was modified slightly in that training was performed with two wires, since the k-NN classifier would yield meaningless results if trained on only a single wire.
Reference: <author> Edelman, S. and Bulthoff, H. H. </author> <year> (1991). </year> <title> Orientation dependence in the recognition of familiar and novel views of 3D objects. </title> <journal> Vision Research. </journal> <note> submitted. </note>
Reference-contexts: The dimensionality reducing transformation is based on projecting the pixel image onto a set of object features. The actual form of object features, and methods of extracting them, are not at all clear and are subject to current research in many disciplines <ref> (Edelman, 1991) </ref>. We propose to use a method for feature extraction which corresponds to recent statistical theory (Friedman and Tukey, 1974; Friedman, 1987) and is based on a biologically motivated feature extracting neuron. <p> when generalization was required along the horizontal, as opposed to the vertical, plane. 3.2 Experimental Paradigm In the first part of the study, the network was tested on a 63 by 63 array of 8-bit gray-scale values with a paradigm nearly identical to the one used in the psychophysical investigation <ref> (Edelman and Bulthoff, 1991) </ref>. The procedure was modified slightly in that training was performed with two wires, since the k-NN classifier would yield meaningless results if trained on only a single wire.
Reference: <author> Edelman, S. and Poggio, T. </author> <year> (1990). </year> <title> Bringing the Grandmother back into the picture: a memory-based view of object recognition. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1181, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology. </institution> <note> to appear in Int. </note> <author> J. </author> <title> Pattern Recog. Artif. Intell. Intrator and Gold 3-D Object Recognition 10 Edelman, </title> <editor> S. and Weinshall, D. </editor> <year> (1991). </year> <title> A self-organizing multiple-view representation of 3D objects. </title> <journal> Biological Cybernetics, </journal> <volume> 64 </volume> <pages> 209-219. </pages>
Reference: <author> Fisher, R. A. </author> <year> (1936). </year> <title> The use of multiple measurements in taxonomic problems. </title> <journal> Annals of Eugenics, </journal> <volume> 7 </volume> <pages> 179-188. </pages>
Reference: <author> Friedman, J. H. </author> <year> (1987). </year> <title> Exploratory projection pursuit. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 82 </volume> <pages> 249-266. </pages>
Reference: <author> Friedman, J. H. and Tukey, J. W. </author> <year> (1974). </year> <title> A projection pursuit algorithm for exploratory data analysis. </title> <journal> IEEE Transactions on Computers, C(23):881-889. </journal>
Reference: <author> Gold, J. I. </author> <year> (1991). </year> <title> A model of dendritic spine head [Ca ++ ]: Exploring the biological mechanisms underlying a theory for synaptic plasticity. </title> <type> Unpublished honors thesis, </type> <institution> Brown University. </institution>
Reference: <author> Harman, H. H. </author> <year> (1967). </year> <title> Modern Factor Analysis. </title> <publisher> University of Chicago Press, </publisher> <address> Second Edition, Chicago and London. </address>
Reference-contexts: However, finding clusters in very high dimensional space suffers from the inherent sparsity of such space, and therefore can not be directly approached by classical methods such as cluster analysis (Duda and Hart, 1973), discriminant analysis (Fisher, 1936; Sebestyen, 1962), or factor analysis <ref> (Harman, 1967) </ref>. <p> In this paper we concentrate on a specific form of unsupervised dimensionality reduction/feature extraction. This form relies on the notion of distinguishing features which focus on discrimination among classes and not faithful representation of the data. Thus, this form is different 2 from classical methods such as factor analysis <ref> (Harman, 1967, for review) </ref> which tend to combine features that seem to have high correlation, or principal component analysis which seeks directions that maximize the variance of the projected distribution. 3 A general framework for feature extraction is Projection Pursuit, and its unsupervised version Exploratory Projection Pursuit (Kruskal, 1969; Friedman and
Reference: <author> Huber, P. J. </author> <year> (1985). </year> <title> Projection pursuit. (with discussion). </title> <journal> The Annals of Statistics, </journal> <volume> 13 </volume> <pages> 435-475. </pages>
Reference-contexts: the large number of parameters involved, a feature extraction method that uses the class labels of the data may miss important structure that is not exhibited in the class labels, and therefore be more biased to the training data than a feature extractor that relies on the high dimensional structure <ref> (Huber, 1985) </ref>. This suggests that an unsupervised feature extraction method may have better generalization properties in high dimensional problems. In this paper we concentrate on a specific form of unsupervised dimensionality reduction/feature extraction.
Reference: <author> Hughes, A. </author> <year> (1977). </year> <title> The topography of vision in mammals of contrasting live style: Comparative optics and retinal organisation. </title> <editor> In Crescitelli, F., editor, </editor> <booktitle> The Visual System in Vertebrates, Handbook of Sensory Physiology VII/5, </booktitle> <pages> pages 613-756. </pages> <publisher> Springer Verlag, </publisher> <address> Berlin. </address>
Reference-contexts: In contrast, when the task was recognition of six wires the extracted features emphasized small patches of several images or views, namely, areas that either remain relatively invariant under the 6 There is, in fact, limited evidence for visual field elongation in the horizontal plane <ref> (Hughes, 1977) </ref>. Intrator and Gold 3-D Object Recognition 7 rotation performed during training or represented a major differentiating characteristic of a specific wire (Figure 4).
Reference: <author> Intrator, N. </author> <year> (1990). </year> <title> A neural network for feature extraction. </title> <editor> In Touretzky, D. S. and Lippmann, R. P., editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 2, </volume> <pages> pages 719-726. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Intrator, N. </author> <year> (1992). </year> <title> Feature extraction using an unsupervised neural network. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 98-107. </pages>
Reference-contexts: which are organized in a lateral inhibition architecture (In-trator, 1990; Intrator and Cooper, 1992), which forces different neurons in the network to find different projections (i.e., features), combined with the simplicity of the projection index, make this method computationally practical for multiple feature extraction in high dimensional spaces 2 See <ref> (Intrator and Cooper, 1992) </ref> for a discussion of the difference. 3 Principal components may not retain enough structure needed for classification (Duda and Hart, 1973, p. 212). 4 For a discussion on various projection indices, see Huber (1985), Jones and Sibson (1987), Intrator and Cooper (1992). <p> Intrator and Gold 3-D Object Recognition 4 <ref> (Intrator, 1992) </ref>. 3 Application of the Model to 3D Object Recognition The combined unsupervised feature extraction/classification method used in these experiments is described in Intrator (1992). In general, the generalization properties of hybrid feature extraction/classification method depend on the feature extraction as well as the classification method used.
Reference: <author> Intrator, N. and Cooper, L. N. </author> <year> (1992). </year> <title> Objective function formulation of the BCM theory of visual cortical plasticity: Statistical connections, stability conditions. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 3-17. </pages>
Reference-contexts: which are organized in a lateral inhibition architecture (In-trator, 1990; Intrator and Cooper, 1992), which forces different neurons in the network to find different projections (i.e., features), combined with the simplicity of the projection index, make this method computationally practical for multiple feature extraction in high dimensional spaces 2 See <ref> (Intrator and Cooper, 1992) </ref> for a discussion of the difference. 3 Principal components may not retain enough structure needed for classification (Duda and Hart, 1973, p. 212). 4 For a discussion on various projection indices, see Huber (1985), Jones and Sibson (1987), Intrator and Cooper (1992). <p> Intrator and Gold 3-D Object Recognition 4 <ref> (Intrator, 1992) </ref>. 3 Application of the Model to 3D Object Recognition The combined unsupervised feature extraction/classification method used in these experiments is described in Intrator (1992). In general, the generalization properties of hybrid feature extraction/classification method depend on the feature extraction as well as the classification method used.
Reference: <author> Intrator, N., Gold, J. I., Bulthoff, H. H., and Edelman, S. </author> <year> (1991). </year> <title> Three-dimensional object recognition using an unsupervised neural network: Understanding the distinguishing features. </title> <editor> In Feldman, Y. and Bruckstein, A., editors, </editor> <booktitle> Proceedings of the 8th Israeli Conference on AICV, </booktitle> <pages> pages 113-123. </pages> <publisher> Elsevier. </publisher>
Reference: <author> Jones, M. C. and Sibson, R. </author> <year> (1987). </year> <title> What is projection pursuit? (with discussion). </title> <journal> J. Roy. Statist. Soc., Ser. A(150):1-36. </journal>
Reference: <author> Kruskal, J. B. </author> <year> (1969). </year> <title> Toward a practical method which helps uncover the structure of the set of multivariate observations by finding the linear transformation which optimizes a new 'index of condensation'. </title> <editor> In Milton, R. C. and Nelder, J. A., editors, </editor> <title> Statistical Computation. </title> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: <author> Lowe, D. G. </author> <year> (1986). </year> <title> Perceptual organization and visual recognition. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA. </address>
Reference: <author> Moody, J. and Darken, C. </author> <year> (1989). </year> <title> Fast learning in networks of locally tuned processing units. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 281-289. </pages>
Reference: <author> Poggio, T. and Edelman, S. </author> <year> (1990). </year> <title> A network that learns to recognize three-dimensional objects. </title> <journal> Nature, </journal> <volume> 343 </volume> <pages> 263-266. </pages>
Reference: <author> Poggio, T. and Girosi, F. </author> <year> (1990). </year> <title> Networks for approximation and learning. </title> <journal> IEEE Proceedings, </journal> <volume> 78(9) </volume> <pages> 1481-1497. </pages>
Reference: <author> Sebestyen, G. </author> <year> (1962). </year> <title> Decision Making Processes in Pattern Recognition. Macmillan, New York. Intrator and Gold 3-D Object Recognition 11 Sejnowski, </title> <editor> T. J. </editor> <year> (1986). </year> <title> Open questions about computation in Cerebral Cortex. </title> <editor> In McClelland, J. L. and Rumelhart, D. E., editors, </editor> <booktitle> Parallel Distributed Processing, </booktitle> <volume> volume 2, </volume> <pages> pages 372-389. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Sklar, E., Intrator, N., Gold, J. J., Edelman, S. Y., and Bulthoff, H. H. </author> <year> (1991). </year> <title> A hierarchical model for 3D object recognition based on 2D visual representation. In Neurosci. </title> <publisher> Soc. Abs. </publisher>
Reference: <author> Thompson, D. W. and Mundy, J. L. </author> <year> (1987). </year> <title> Three-dimensional model matching from an unconstrained viewpoint. </title> <booktitle> In Proceedings of IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 208-220, </pages> <address> Raleigh, NC. </address>
Reference: <author> Ullman, S. </author> <year> (1989). </year> <title> Aligning pictoral descriptions: an approach to object recognition. Cognition, 13:13 - 254. Intrator and Gold 3-D Object Recognition 12 plane. Note the degradation in performance in the Inter orientations. plane with no asymmetry. experience (views). </title>
Reference-contexts: 1 Introduction A system which performs recognition of three-dimensional objects in visual space must transform a complex pattern of visual inputs to an appropriate categorization. Such recognition is possible, for example, by template matching once the object and its templates are brought into register <ref> (Ullman, 1989) </ref>. Other similar schemes (Lowe, 1986; Thompson and Mundy, 1987) base the recognition on viewpoint consistency, which relate projected locations of key features of a model to its 3D structure given a hypothesized view point.
References-found: 30

