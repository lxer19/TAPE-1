URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/ljuca/www/kpap.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/ljuca/www/home.html
Root-URL: 
Title: A sub-exponential time algorithm for approximating the number of solutions to a multidimensional knapsack problem  
Author: Martin Dyer Alan Frieze Ravi Kannan Ajai Kapoor Ljubomir Perkovic Umesh Vazirani 
Date: December 29, 1996  
Address: Leeds LS2 9JT UK  Pittsburgh PA15213 USA  Berkeley CA94320 USA  
Affiliation: University of Leeds  Carnegie Mellon University  University of California  
Abstract: We describe an O(2 O(r p n(logn) 5=2 ) * 2 ) time randomized algorithm which estimates the number of feasible solutions of a multidimensional knapsack problem within 1 * of the exact number. (Here r is the number of constraints and n is the number of integer variables.) The 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Applegate and R. Kannan, </author> <title> Sampling and integration of near log-concave functions Proc. </title> <booktitle> 23rd ACM Symposium on Theory of Computing, </booktitle> <year> 1991, </year> <pages> pp. 156-163. </pages>
Reference-contexts: The counting problem seems to be even harder. This asks for jKj. This problem is #P-complete, again even for r = 1 and zero-one variables. Markov chains have been successfully used to approximately solve several #P-complete problems <ref> [1, 2, 3, 4, 6, 7, 10, 12, 14] </ref>. In all of these problems the running time of the algorithm is polynomial in problem size and relative error. <p> Indeed if A 0 x 0 (1 + t)b then A 0 (x 0 + 1) 1 + t + n b: (21) Walks of this type were studied in Applegate and Kannan <ref> [1] </ref> (see also Dyer and Frieze [3] or Lovasz and Simonovits [13] for some improvements.) The function T is log-concave and log T has a Lipschitz constant of O (n).
Reference: [2] <author> A. Z. Broder, </author> <title> How hard is it to marry at random? (On the approximation of the permanent), </title> <booktitle> Proceedings of the 18th Annual ACM Symposium on Theory of Computing (1986), </booktitle> <pages> 50-58. </pages> <booktitle> Erratum in Proceedings of the 20th Annual ACM Symposium on Theory of Computing (1988), </booktitle> <pages> 551. </pages>
Reference-contexts: The counting problem seems to be even harder. This asks for jKj. This problem is #P-complete, again even for r = 1 and zero-one variables. Markov chains have been successfully used to approximately solve several #P-complete problems <ref> [1, 2, 3, 4, 6, 7, 10, 12, 14] </ref>. In all of these problems the running time of the algorithm is polynomial in problem size and relative error.
Reference: [3] <author> M. E. Dyer and A. M. Frieze, </author> <title> Computing the volume of convex bodies: a case where randomness provably helps, in Probabilistic Combinatorics and its Applications (B. Bollobas, </title> <editor> Ed.), </editor> <booktitle> AMS Proceedings of Symposia in Applied Mathematics 44 (1991), </booktitle> <pages> 123-169. 18 </pages>
Reference-contexts: The counting problem seems to be even harder. This asks for jKj. This problem is #P-complete, again even for r = 1 and zero-one variables. Markov chains have been successfully used to approximately solve several #P-complete problems <ref> [1, 2, 3, 4, 6, 7, 10, 12, 14] </ref>. In all of these problems the running time of the algorithm is polynomial in problem size and relative error. <p> Indeed if A 0 x 0 (1 + t)b then A 0 (x 0 + 1) 1 + t + n b: (21) Walks of this type were studied in Applegate and Kannan [1] (see also Dyer and Frieze <ref> [3] </ref> or Lovasz and Simonovits [13] for some improvements.) The function T is log-concave and log T has a Lipschitz constant of O (n).
Reference: [4] <author> M. E. Dyer, A. M. Frieze and R. </author> <title> Kannan,A random polynomial time algorithm for approximating the volume of convex bodies, </title> <journal> Journal of the Association for Computing Machinery 38 (1991), </journal> <pages> 1-17. </pages>
Reference-contexts: The counting problem seems to be even harder. This asks for jKj. This problem is #P-complete, again even for r = 1 and zero-one variables. Markov chains have been successfully used to approximately solve several #P-complete problems <ref> [1, 2, 3, 4, 6, 7, 10, 12, 14] </ref>. In all of these problems the running time of the algorithm is polynomial in problem size and relative error. <p> If d j n 2 ; j = 1; 2; : : : ; n, then we can construct a fully polynomial randomized approximation scheme for jKj. Thus such cases are "easy", the reason being that the counting closely resembles volume computation <ref> [4] </ref>. We can use the above scaling to "round" the feasible polytope K to K 0 . Then we have B (n=2) K 0 B (n 3 ), where B (-) = f0 x 0 -1g.
Reference: [5] <author> W. Hoeffding, </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association 58 (1963), </journal> <pages> 13-30. </pages>
Reference: [6] <author> M. R. Jerrum and A. J. Sinclair, </author> <title> Approximating the permanent, </title> <journal> SIAM Journal on Computing 18 (1989), </journal> <pages> 1149-1178. </pages>
Reference-contexts: The counting problem seems to be even harder. This asks for jKj. This problem is #P-complete, again even for r = 1 and zero-one variables. Markov chains have been successfully used to approximately solve several #P-complete problems <ref> [1, 2, 3, 4, 6, 7, 10, 12, 14] </ref>. In all of these problems the running time of the algorithm is polynomial in problem size and relative error. <p> (2), assuming that d max is suitably bounded as a function of n, this will then follow from (S) = 2 O (r n (log n) 5=2 ) for all S K; jSj N=2: (4) We will use a variation on the canonical path argument introduced by Jerrum and Sinclair <ref> [6] </ref>. Fix S K; jSj N=2,. We will define a set T = T (S) S fi S with jT j 2 We will also define a canonical path P x;y in from x to y for every (x; y) 2 T .
Reference: [7] <author> M. R. Jerrum and A. J. Sinclair, </author> <title> Polynomial-time approximation algorithms for the Ising model, </title> <institution> Department of Computer Science, Edinburgh University, </institution> <year> 1989. </year>
Reference-contexts: The counting problem seems to be even harder. This asks for jKj. This problem is #P-complete, again even for r = 1 and zero-one variables. Markov chains have been successfully used to approximately solve several #P-complete problems <ref> [1, 2, 3, 4, 6, 7, 10, 12, 14] </ref>. In all of these problems the running time of the algorithm is polynomial in problem size and relative error.
Reference: [8] <author> M. R. Jerrum, L. G. Valiant, and V. V. </author> <title> Vazirani,Random generation of combinatorial structures from a uniform distribution. </title> <booktitle> Theoretical Computer Science, 43 (1986), </booktitle> <pages> 169-188. </pages>
Reference-contexts: Finally, we consider the general problem in section 5. 2 Rapidly Mixing Markov Chains It is well known that the approximate counting of combinatorial objects is intimately related to their near uniform generation-see Jerrum, Valiant and Vazirani <ref> [8] </ref> for a formal statement of this relation.
Reference: [9] <author> M. R. Jerrum and U. Vazirani, </author> <title> A mildly exponential approximation algorithm for the permanent, </title> <institution> Department of Computer Science, Edinburgh University, </institution> <year> 1991. </year>
Reference-contexts: In all of these problems the running time of the algorithm is polynomial in problem size and relative error. On the other hand, the general zero-one permanent still resists polynomial time approximation, but Jerrum and Vazirani <ref> [9] </ref> have reduced the time complexity to O (2 O ( p n (log n) 2 ) * 2 ) for computing an *-approximation. In this paper we make similar progress in approximating jKj.
Reference: [10] <author> A. Karzanov and L. Khachiyan, </author> <title> On the conductance of order Markov chains, </title> <type> Technical Report DCS TR 268, </type> <institution> Rutgers University (1990). </institution>
Reference-contexts: The counting problem seems to be even harder. This asks for jKj. This problem is #P-complete, again even for r = 1 and zero-one variables. Markov chains have been successfully used to approximately solve several #P-complete problems <ref> [1, 2, 3, 4, 6, 7, 10, 12, 14] </ref>. In all of these problems the running time of the algorithm is polynomial in problem size and relative error.
Reference: [11] <author> L. Lovasz, </author> <title> Combinatorial problems and exercises, </title> <publisher> North Holland, </publisher> <address> Ams-terdam, </address> <year> 1979. </year>
Reference-contexts: But for each x; y there is an offset u fl = u fl (x; y) such that Q x;y ( fl ; u fl ) is feasible (see Lovasz <ref> [11] </ref>, Problem 3.21). Thus there exists a set T fl S fi S such that jT fl j jSj j Sj (1 O (n 2 )) (13) and P x;y = Q x;y ( fl ; u fl ) is feasible for all (x; y) 2 T fl .
Reference: [12] <author> L. Lovasz and M. Simonovits, </author> <title> The mixing rate of Markov chains, an isoperimetric inequality and computing the volume, </title> <booktitle> Proceedings of the 31st Annual IEEE Symposium on Foundations of Computer Science (1990), </booktitle> <pages> 346-354. </pages>
Reference-contexts: The counting problem seems to be even harder. This asks for jKj. This problem is #P-complete, again even for r = 1 and zero-one variables. Markov chains have been successfully used to approximately solve several #P-complete problems <ref> [1, 2, 3, 4, 6, 7, 10, 12, 14] </ref>. In all of these problems the running time of the algorithm is polynomial in problem size and relative error.
Reference: [13] <author> L. Lovasz and M. Simonovits, </author> <title> Random walks in a convex body and an improved volume algorithm Proceedings of the 33rd Annual IEEE Symposium on Foundations of Computer Science (1992). </title>
Reference-contexts: Indeed if A 0 x 0 (1 + t)b then A 0 (x 0 + 1) 1 + t + n b: (21) Walks of this type were studied in Applegate and Kannan [1] (see also Dyer and Frieze [3] or Lovasz and Simonovits <ref> [13] </ref> for some improvements.) The function T is log-concave and log T has a Lipschitz constant of O (n).
Reference: [14] <author> M. Mihail and P. Winkler, </author> <title> On the number of Euler orientations of a graph, </title> <booktitle> Proceedings of the 3rd Annual ACM-SIAM Symposium on Discrete Algorithms (1992), </booktitle> <pages> 138-145. 19 </pages>
Reference-contexts: The counting problem seems to be even harder. This asks for jKj. This problem is #P-complete, again even for r = 1 and zero-one variables. Markov chains have been successfully used to approximately solve several #P-complete problems <ref> [1, 2, 3, 4, 6, 7, 10, 12, 14] </ref>. In all of these problems the running time of the algorithm is polynomial in problem size and relative error.
Reference: [15] <author> A. J. Sinclair and M. R. Jerrum, </author> <title> Approximate counting, uniform gener-ation and rapidly mixing Markov chains, </title> <booktitle> Information and Computation 82 (1989), </booktitle> <pages> 93-133. </pages>
Reference-contexts: If we let E S: S = f (x; y) 2 E : x 2 S; y 62 Sg and (S) = jE S: S j=jSj then = min jSjN=2 ( 2nd max (2) Now, letting N = jKj, it follows from results in Sinclair and Jerrum <ref> [15] </ref> that for all x 2 K p 4 Thus our claim about near uniform generation can be justified by showing that the conductance of M satisfies = 2 O (r n (log n) 5=2 ) : (3) In view of (2), assuming that d max is suitably bounded as a <p> This leads to the idea of the complementary point w 0 = (x 1 ; : : : ; x t ; y t+1 ; : : : ; y n ) of w from Jerrum and Sinclair <ref> [15] </ref>. Let W 0 = W 0 (x; y) be the set of complementary points w 0 such that w is on Q x;y .
References-found: 15

