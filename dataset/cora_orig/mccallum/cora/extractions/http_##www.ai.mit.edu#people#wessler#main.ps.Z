URL: http://www.ai.mit.edu/people/wessler/main.ps.Z
Refering-URL: http://www.ai.mit.edu/people/las/cv.html
Root-URL: 
Title: A Modular Visual Tracking System  
Author: by Mike Wessler Lynn Andrea Stein 
Degree: (1992) Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Master of Science in Electrical Engineering and Computer Science at the  Signature of Author  Certified by  Class of 1957 Associate Professor of Computer Science Thesis Supervisor Accepted by Frederic R. Morgenthaler Chairman, Departmental Committee on Graduate Students  
Note: c Massachusetts Institute of Technology  
Date: June 1995  1995  May 26, 1995  
Affiliation: A.B., Harvard University  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [ BCS92 ] <author> Christopher Brown, David Coombs, and John Soong. </author> <title> Real-time smooth pursuit tracking. </title> <editor> In Andrew Blake and Alan Yuille, editors, </editor> <title> Active Vision, chapter 8. </title> <publisher> The MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: The more realistic-looking method of moving the cameras to keep the attention window centered in the view will be discussed in Chapter 5. 3.1 Prior work Several techniques have been developed to track moving objects in real time. <ref> [ ITI92, BCS92, Kam93, RM93 ] </ref> The systems tend to fall into three broad categories: the filter and follow method, the image correlation method, and the feature correlation method. <p> As each vehicle enters, its color histogram is noted and used in subsequent frames to highlight its new location. This system works for the most part because cars and trucks tend to have large areas of bright solid color. Coombs et al. <ref> [ BCS92 ] </ref> used a more complex stereo filter that didn't require the objects to be visually distinctive. Their system requires two cameras, and uses a cepstral filter to highlight the portions of the scene that have zero disparity between the two cameras.
Reference: [ Bey94 ] <author> David J. Beymer. </author> <title> Face recognition under varying pose. </title> <booktitle> In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 756-761, </pages> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: It is still extremely unclear how object recognition works in the brain. Computational models tend to require some kinds of segmentation or alignment prior to the actual recognition, especially for objects like faces <ref> [ Bey94 ] </ref> which do not yield readily to simpler techniques.
Reference: [ BGDE94 ] <author> S.A. Brock-Gunn, G.R. Dowling, and T.J. Ellis. </author> <title> Tracking using colour information. </title> <type> Technical Report TCU/CS/1994/7, </type> <institution> City University London, </institution> <year> 1994. </year>
Reference-contexts: They don't work well for most ordinary objects. A slightly more complex color filter was used in <ref> [ BGDE94 ] </ref> to track vehicles that passed through an intersection. As each vehicle enters, its color histogram is noted and used in subsequent frames to highlight its new location. This system works for the most part because cars and trucks tend to have large areas of bright solid color.
Reference: [ BS93 ] <author> Rodney Brooks and Lynn A. Stein. </author> <title> Building brains for bodies. </title> <type> AI Memo 1439, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: This chapter concludes with intended directions for adding some of these pieces. 16 Chapter 2 Background Reubens was designed to become the basic visual system for a humanoid robot called Cog <ref> [ BS93 ] </ref> . The goals for the humanoid robot became the driving goals for Reubens. In particular, Cog is meant to interact in a human-like manner with people in real time.
Reference: [ Cha90 ] <author> David Chapman. </author> <title> Vision, instruction and action. </title> <type> Technical Report 1204, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: As each region is examined, the corresponding marker is inhibited, until all regions have been examined. The markers also serve as signposts, so a visual location can be described as "15 pixels left of the marker." Ullman calls these simple algorithms visual routines. David Chapman <ref> [ Cha90 ] </ref> , and more recently Ian Horswill [ Hor95 ] have taken Ull-man's original idea and extended it. <p> This conglomeration of filters is much like that discussed in Ullman [ Ull83 ] . The filters might Ian Horswill has demonstrated a visual reasoning system based on this idea and Chapman's <ref> [ Cha90 ] </ref> 78 thesis, with a prolog-like front end. It was demonstrated on a processor very similar to that running Reubens [ Hor95 ] , which would make integration even easier. The second improvement comes in adding higher level reasoning to direct the attention shift system.
Reference: [ Gou85 ] <author> Peter Gouras. </author> <title> Oculomotor system. </title> <editor> In Eric R. Kandel and James H. Schwartz, editors, </editor> <booktitle> Principles of Neural Science. </booktitle> <publisher> Elsevier, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: The motor control system performs the 54 saccade command blind; tracking does not start up again until after the saccade has completed. This is similar to the human system, where the eye will correctly foveate the location of a stimulus, even if the stimulus is removed in mid-saccade. <ref> [ Gou85 ] </ref> 5.2 Calibration Most robotics systems with feedback eventually have to worry about calibration. In Reubens' case, we were able to avoid the issue for motor control during tracking by opting for a completely reactive control.
Reference: [ Hor95 ] <author> Ian Horswill. </author> <title> Visual routines and visual search: a real-time implementation and an automata-theoretic analysis. </title> <booktitle> In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year> <month> 80 </month>
Reference-contexts: The markers also serve as signposts, so a visual location can be described as "15 pixels left of the marker." Ullman calls these simple algorithms visual routines. David Chapman [ Cha90 ] , and more recently Ian Horswill <ref> [ Hor95 ] </ref> have taken Ull-man's original idea and extended it. In the new systems, the set of simultaneous filters still exists, but now each filter passes on a gray scale salience map, which is combined in a weighted average with the salience maps for the other filters. <p> The filters might Ian Horswill has demonstrated a visual reasoning system based on this idea and Chapman's [ Cha90 ] 78 thesis, with a prolog-like front end. It was demonstrated on a processor very similar to that running Reubens <ref> [ Hor95 ] </ref> , which would make integration even easier. The second improvement comes in adding higher level reasoning to direct the attention shift system. Horswill's system is one possibility.
Reference: [ ITI92 ] <author> Hirochika Inoue, Tetsuya Tachikawa, and Masayuki Inaba. </author> <title> Robot vision system with a correlation chip for real time tracking, optical flow and depth map generation. </title> <booktitle> In Proceedings of the 1992 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 1621-1626, </pages> <address> Nice, France, </address> <month> May </month> <year> 1992. </year> <journal> IEEE Computer Society. </journal>
Reference-contexts: The more realistic-looking method of moving the cameras to keep the attention window centered in the view will be discussed in Chapter 5. 3.1 Prior work Several techniques have been developed to track moving objects in real time. <ref> [ ITI92, BCS92, Kam93, RM93 ] </ref> The systems tend to fall into three broad categories: the filter and follow method, the image correlation method, and the feature correlation method. <p> It is impossible to tell from the given data whether the bar moved up, to the left, or some combination of the two directions. There must be extra features in the image to lock the fixation point in space. 31 Inoue <ref> [ ITI92 ] </ref> uses the correlation method to track multiple regions in the image. He employs a special correlation processor, originally designed to help with MPEG compression, to track up to 20 regions in the frame simultaneously.
Reference: [ Kal60 ] <author> R. E. </author> <title> Kalman. A new approach to linear filtering and prediction problems. </title> <journal> In Trans. ASME J. of Basic Engineering, </journal> <year> 1960. </year>
Reference-contexts: This suggests that a simple guess location based on the motion from the previous frame should be adequate for most cases. In a busier or noisier environment, a Kalman filter can be used to filter out some of the noise to produce a smoother, more accurate guess. <ref> [ Kal60 ] </ref> 3.2.3 Image preprocessing The image grabbed from the camera is full color. Before any correlations are performed, there is an opportunity to preprocess the image.
Reference: [ Kam93 ] <author> Johnny Wai Yee Kam. </author> <title> A real-time 3d motion tracking system. </title> <type> Technical Report TR-93-16, </type> <institution> University of British Columbia, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: The more realistic-looking method of moving the cameras to keep the attention window centered in the view will be discussed in Chapter 5. 3.1 Prior work Several techniques have been developed to track moving objects in real time. <ref> [ ITI92, BCS92, Kam93, RM93 ] </ref> The systems tend to fall into three broad categories: the filter and follow method, the image correlation method, and the feature correlation method.
Reference: [ KK92 ] <author> Stephen M. Kosslyn and Olivier Koenig. </author> <title> Wet Mind: The New Cognitive Neuroscience. </title> <publisher> The Free Press, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Figure 2-1 shows a model abstracted from one designed by Kosslyn and Koenig <ref> [ KK92 ] </ref> that was developed with this method. The figure shows the brain and eye of a head facing to the right. The functional units have been placed roughly in their corresponding regions of the brain. In the beginning, there is light. <p> The attention window can be irregularly shaped, it can scale to different sizes, and it can move about the entire field of view. In other words, you do not have to look directly at an object to which you are attending. <ref> [ KK92 ] </ref> Because of the loss of visual acuity at the periphery of the eye, however, an object seen out of the corner of your eye will not be in focus, and you must look directly at it to get all the details. 2.1.3 Object recognition ("What") The object recognition <p> Kosslyn suggests that the human attention window is actually able to grow, shrink, and deform into odd shapes to help segment the image being fed to the object recognition system. The number of connections running from V1 to the object recognition system, however, remains constant. <ref> [ KK92 ] </ref> 3.2.2 Guessing a new location In order to keep the search range down to a small radius, it is necessary to guess the location of the new attention window in each new frame. <p> The attention window itself should be scalable and shapable, as the human attention window appears to be. <ref> [ KK92 ] </ref> A larger attention window subsamples the visual buffer so that the number of pixels involved remains constant and the running time does not change. Such a window can resize to adapt to the scale of the object being tracked.
Reference: [ KS92 ] <author> H. Kimura and J. J. E. Slotine. </author> <title> Adaptive visual tracking and caussian network algorithms for robotic catching. </title> <booktitle> In Advances in Robust and Nonlinear Control Systems, </booktitle> <pages> pages 67-74, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: High-speed filters can be made using simple brightness or color segmentation. For example, the WAM arm at MIT uses a high speed filter to find and catch bright orange balls thrown to it. <ref> [ Wri93, KS92 ] </ref> Unfortunately, filters like these require that the object being tracked is visually distinctive. They don't work well for most ordinary objects. A slightly more complex color filter was used in [ BGDE94 ] to track vehicles that passed through an intersection.
Reference: [ MAGN86 ] <author> J. A. Movshon, E. H. Adelson, M. S. Gizzi, and W. T. Newsome. </author> <title> The analysis of moving patterns. </title> <editor> In C. Chagas, R. Gattass, and C. Gross, editors, </editor> <booktitle> Pattern Recognition Mechanisms, </booktitle> <pages> pages 117-151. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1986. </year>
Reference-contexts: Correlations are more general than the filter and follow methods in the sense that any piece of image may become the patch to find in the next frame. Objects to track don't need to have special features or coloring. However, local area correlations suffer from the aperture problem. <ref> [ MAGN86 ] </ref> Figure 3-1 shows three different interpretations of a diagonal line moving underneath a circular hole. The light gray band represents the old location; the dark band is the current location.
Reference: [ Mel95 ] <author> Joshua Benjamin Melnick. </author> <type> personal communication, </type> <month> May </month> <year> 1995. </year>
Reference-contexts: Distraction is good. 1 Were it not for the attention shift commands, the entire visual system would experience extreme tunnel vision, remaining locked onto a single region of space. The activity of the attention shift mechanism is very easy to note in young children. <ref> [ Mel95 ] </ref> They are very easily distracted by motion, and will saccade towards waving hands, waggling eyebrows, and other rapid movements. Clearly, a very useful filter to have is a motion detector.
Reference: [ ML81 ] <author> F.A. Miles and S. G. Lisberger. </author> <title> Plasticity in the vestibulo-ocular reflex: A new hypothesis. </title> <journal> Ann. Rev. </journal> <volume> Neurosci., </volume> <pages> pages 273-299, </pages> <year> 1981. </year>
Reference-contexts: Such adaptive control must come from coordination between motor control and spatial relations. Other forms of motor control include the VOR reflex, which causes the eyes to turn automatically in response to inertial motion sensors in the inner ear. <ref> [ ML81 ] </ref> This reflex causes the eyes to move when the head is turned, even if the environment is completely dark. 2.1.6 Attention shift The attention shift system drives the attention window. It identifies the next position for the attention window, and then coordinates the move to that location.
Reference: [ RM93 ] <author> Ian D. Reid and David W. Murray. </author> <title> Tracking foveated corner clusters using affine structure. </title> <booktitle> In Proceedings of the Fourth International Conference on Computer Vision, </booktitle> <pages> pages 76-83, </pages> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year> <journal> IEEE Computer Society. </journal>
Reference-contexts: The more realistic-looking method of moving the cameras to keep the attention window centered in the view will be discussed in Chapter 5. 3.1 Prior work Several techniques have been developed to track moving objects in real time. <ref> [ ITI92, BCS92, Kam93, RM93 ] </ref> The systems tend to fall into three broad categories: the filter and follow method, the image correlation method, and the feature correlation method. <p> Tracking is performed by correlating the locations of the feature points from one frame to the next. Reid and Murray <ref> [ RM93 ] </ref> demonstrate a robot head named Yorick that uses the feature correlation method to track objects. Reid and Murray's feature filter identifies locations in the image that look like corners.
Reference: [ TG80 ] <author> Anne M. Treisman and Garry Gelade. </author> <title> A feature integration theory of attention. </title> <journal> Cognitive Psychology, </journal> <volume> 12 </volume> <pages> 97-136, </pages> <year> 1980. </year> <month> 81 </month>
Reference-contexts: But human beings are not that simple. Even young babies show preferences for looking at faces. Studies by Treisman and others <ref> [ TG80 ] </ref> show that the human visual system is extremely good at identifying certain characteristics without search. Find the odd shape in the left cluster in Figure 4-1.
Reference: [ Ull83 ] <author> Shimon Ullman. </author> <title> Visual routines. </title> <type> AI Memo 723, </type> <institution> MIT Artificial Intelli--gence Laboratory, </institution> <month> June </month> <year> 1983. </year>
Reference-contexts: However, conjunctions of individual popout properties do not combine. The single light bar is difficult to find. When asked to find the light bar, however, most people spot it very quickly. Shimon Ullman <ref> [ Ull83 ] </ref> takes the psychological evidence of popouts and suggests a possible implementation. He proposes a set of several filters that are run over the image in parallel. <p> The current module contains only the motion detector. A more reasonable module would consist of an entire suite of detectors, each tuned to a particular aspect of the visual buffer, like orientation, color, or texture. This conglomeration of filters is much like that discussed in Ullman <ref> [ Ull83 ] </ref> . The filters might Ian Horswill has demonstrated a visual reasoning system based on this idea and Chapman's [ Cha90 ] 78 thesis, with a prolog-like front end.
Reference: [ Vio90 ] <author> Paul Viola. </author> <title> Adaptive gaze control. </title> <type> Master's thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1990. </year>
Reference-contexts: Any changes in the system will cause errors at first, but the errors will gradually disappear as the system learns the new configuration. 5.2.1 Inspiration: A-eye Reubens' calibration system works much like a system called A-eye developed by Paul Viola. <ref> [ Vio90 ] </ref> A-eye contains a large array of values, corresponding to the pan and tilt commands required to foveate an object at a particular location in the image. 55 The A-eye system assumes that there will be one object moving during training, that it moves randomly throughout the visual field,
Reference: [ Wri93 ] <author> Anne Wright. </author> <title> A high speed low latency portable vision sensing system. </title> <editor> In David P. Casasent, editor, </editor> <booktitle> Intelligent Robots and Computer Vision XII: Algorithms and Techniques, volume 2055, </booktitle> <pages> pages 263-270. SPIE, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: High-speed filters can be made using simple brightness or color segmentation. For example, the WAM arm at MIT uses a high speed filter to find and catch bright orange balls thrown to it. <ref> [ Wri93, KS92 ] </ref> Unfortunately, filters like these require that the object being tracked is visually distinctive. They don't work well for most ordinary objects. A slightly more complex color filter was used in [ BGDE94 ] to track vehicles that passed through an intersection.
Reference: [ Yar67 ] <author> A. L. Yarbus. </author> <title> Eye Movements and Vision. </title> <publisher> Plenum Press, </publisher> <year> 1967. </year> <month> 82 </month>
Reference-contexts: Saccades tend to be driven by higher level reasoning. A person will scan a picture in a completely different way depending on the goal of the use of vision <ref> [ Yar67 ] </ref> . This kind of higher level reasoning is outside the scope of this thesis. To simplify matters, we can model the saccades of an infant. Babies tend to saccade to simple cues like motion. <p> The second improvement comes in adding higher level reasoning to direct the attention shift system. Horswill's system is one possibility. Another is to implement goal directed vision, where the location the system saccades to next depends highly on the task that is being accomplished. <ref> [ Yar67 ] </ref> This kind of module would also make extended use of the calibration system.
References-found: 21

