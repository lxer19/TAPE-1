URL: http://www.sls.lcs.mit.edu/flammia/flammia-98.ps.gz
Refering-URL: http://www.sls.lcs.mit.edu/flammia/publications.html
Root-URL: 
Title: Discourse Segmentation Of Spoken Dialogue: An Empirical Approach  
Author: by Giovanni Flammia Victor W. Zue Arthur C. Smith 
Degree: (1991) Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Doctor of Philosophy in Computer Science and Engineering at the  All rights reserved. Author  Certified by  Thesis Supervisor Accepted by  Chairman, Departmental Committee on Graduate Students  
Date: (1988)  May 1998  May 20, 1998  
Address: La Sapienza  
Affiliation: Laurea, Universita di Roma,  S.M., McGill University  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  c Massachusetts Institute of Technology 1998.  Department of Electrical Engineering and Computer Science  Senior Research Scientist, Laboratory for Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. Allen. </author> <title> Natural Language Understanding (Second Edition). </title> <publisher> Benjamin Cummings, </publisher> <address> Redwood City, CA, </address> <year> 1994. </year>
Reference-contexts: For example, at the syntactic level, pronouns might be annotated along with the definite noun phrases they refer to [19, 44] and at the intentional level, sentences might be annotated with the speaker intentions (e.g. whether the sentence is a request for information, an acknowledgment) <ref> [92, 93, 1] </ref>. Annotation of some linguistic phenomena such as phonetic variants and disfluencies are relatively straightforward, since agreement on the choices of units and conventions can often be reached [55, 96]. <p> In this thesis, we focus on task-oriented spoken dialogue because it is a genre applicable to building spoken language systems. In this case, discourse analysis is mostly focused on determining relations between sentences spoken by different speakers across dialogue turns. In particular, we focus on intentional relations (e.g., <ref> [1, 38, 39, 92, 93] </ref>). For example, in this framework the first sentence of the above dialogue exchange 27 (I'm trying to find out where the Lion King is located) is not interpreted solely as a declarative, but rather as a communicative act: a request for some specific information. <p> Larger segment units driven by task-related purposes, such as List Movies Playing At Theater, typically contain one or more nested discourse contributions. 2.1.3 Communicative Acts The third type of discourse unit is called a speech act, communicative act, or act for short <ref> [92, 93, 1] </ref>. An act is an abstract label that is attached to one or more clauses in a dialogue turn. It attempts to summarize the intention that the speaker wants to communicate to the listener. <p> The list of communicative acts is displayed in Table 5.2. The list is a subset of acts which are frequently used in discourse analysis <ref> [92, 93, 1] </ref>. On average, a dialogue turn is composed of one to three clauses. Each clause has been annotated with a separate communicative act. In our annotated data, 74.5% of the dialogue turns are a single clause.
Reference: [2] <author> J Allen, K. Lenhart, and K. Schubert. </author> <title> The TRAINS project. </title> <type> Technical Report 382, </type> <institution> Dep. of Computer Science. University of Rochester, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: The corpus used for this thesis is similar in nature to the directory assistance portion of the London-Lund corpus. in domain and conversational style. The Trains corpus was collected at the University of Rochester <ref> [2] </ref>. It is a collection of 98 dialogues recorded in a laboratory. In each one of the dialogues, one speaker plays the role of user and another one plays the role of the assistant.
Reference: [3] <author> A.H. Anderson et al. </author> <title> The HCRC map task corpus. </title> <journal> Language and Speech, </journal> <volume> 34(4) </volume> <pages> 351-366, </pages> <year> 1992. </year>
Reference-contexts: The assistant helps the user in accomplishing a task involving the manufacturing and shipment of goods in a hypothetical railroad freight system. The Map Task Corpus collected at the University of Edinburgh, England consists of 128 spontaneous face-to-face dialogues also collected in a laboratory setting <ref> [3, 16] </ref>. In each dialogue, each of the two speakers has a map, one with a route marked and one without. The goal is for the route follower to draw the route from the instructions of the route giver.
Reference: [4] <author> F. Andry. </author> <title> Static and dynamic predictions: A method to improve speech understanding in cooperative dialogues. </title> <booktitle> In Proc. Int. Conf. on Spoken Language Processing, </booktitle> <pages> pages 639-642, </pages> <address> Banff, Canada, </address> <year> 1992. </year>
Reference-contexts: Finite state machines and context-free grammars have been used to model graphical user interfaces [76], typed natural language interfaces [108, 29] and spoken language interfaces <ref> [4, 8, 18, 70] </ref>. They have been used to model natural language interactions in Wizard-of-Oz studies, in which users talked to a system simulated by an engineer, before the system is fully developed [98, 29], and sequences of communicative acts in spontaneous telephone conversations of the Switchboard corpus [51].
Reference: [5] <author> C. Aone and S. Bennett. </author> <title> Evaluating annotated and manual acquisition of anaphora resolu-tion strategies. </title> <booktitle> In Proc. of the 33rd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 122-129, </pages> <year> 1995. </year> <booktitle> ACL. </booktitle>
Reference-contexts: The series of MUC conferences [19] used the co-reference annotation tool called DDTool developed at SRA labs <ref> [5] </ref>. The DDTool allows users to display chains of co-referent nouns and noun phrases by linking them with colored straight lines.
Reference: [6] <author> R. Bakeman and J.M. Gottman. </author> <title> Observing Interaction: an Introduction to Sequential Analysis. </title> <publisher> Cambridge University Press, </publisher> <year> 1986. </year>
Reference-contexts: In this section, we review how to compute four metrics for measuring inter-coder agreement: precision, recall, percent agreement and the kappa coefficient. A discussion of evaluation metrics can also be found in <ref> [53, 6, 104, 14] </ref>. 2.3.1 Precision and Recall When comparing two different annotations of the same text, we may select one as the reference and the other one as the test. <p> Recent empirical work on discourse coding has overcome the text size sensitivity problem by either reporting the agreement on the most critical categories (i.e., Segment Boundary) [46] or by reporting the kappa coefficient, , a measure of agreement that is used in experimental psychology <ref> [53, 6, 14] </ref>. This measure corrects the observed agreement by subtracting the estimated chance agreement P c one expects a priori from the marginal distributions of the coded categories. <p> The experimental psychology literature reports that a value of greater than 0:6 indicates statistical correlation among coders and greater than 0:7 can be interpreted as an indication of replicable agreement among coders <ref> [6] </ref>. In our example, the values of the coefficients confirm that the agreement among the two coders is significantly more reliable for the longer text.
Reference: [7] <author> N. O. Bernsen, L. Dybkjaer, and H. Dybkjaer. </author> <title> Cooperativity in human-machine and humanhuman spoken dialogue. </title> <booktitle> Discourse Processes, </booktitle> <volume> 21(2) </volume> <pages> 213-236, </pages> <year> 1996. </year>
Reference-contexts: To overcome these challenges, the design of better spoken applications may be based on analyses of human-to-human dialogues <ref> [112, 7] </ref>. However, designing user interfaces based on human-to-human interaction is a controversial issue. In a debate between direct manipulation vs. interface agents, B. Schneiderman stated ([95], page 56): 16 I am concerned about the confusion of human and machine capa-bilities. <p> While a machine may apply the same principles of co-operative behavior as a human agent, many dialogue system designers argue that it may more appropriate to employ more explicit prompts and feedback responses <ref> [7, 40, 110, 12, 30] </ref>.
Reference: [8] <author> E. Bilange. </author> <title> A task independent oral dialogue model. </title> <booktitle> In Proceedings of the Fifth Conference of the European Chapter of the Association for Computational Linguistics, </booktitle> <address> Berlin, Germany, </address> <year> 1991. </year>
Reference-contexts: Finite state machines and context-free grammars have been used to model graphical user interfaces [76], typed natural language interfaces [108, 29] and spoken language interfaces <ref> [4, 8, 18, 70] </ref>. They have been used to model natural language interactions in Wizard-of-Oz studies, in which users talked to a system simulated by an engineer, before the system is fully developed [98, 29], and sequences of communicative acts in spontaneous telephone conversations of the Switchboard corpus [51].
Reference: [9] <author> E. Black. </author> <title> Parsing English by computer: </title> <booktitle> the state of the art. In Proc. ISSD-93 International symposium on spoken dialogue, </booktitle> <pages> pages 77-81, </pages> <address> Tokyo, </address> <year> 1993. </year>
Reference-contexts: While there were some initial doubts regarding the ultimate utility of such an annotation scheme, they were largely put to rest once researchers had a chance to make use of the corpus. The Penn Treebank has been instrumental in facilitating the comparison of several general English parsers <ref> [9, 10] </ref>. In this thesis we apply the same paradigm to evaluate agreement between different segmentations of the same text. 1.2 Overview of the Corpus In this section, we briefly present some characteristics of natural dialogues that have been extracted from the corpus used for this thesis.
Reference: [10] <author> E. Black et al. </author> <title> A procedure for quantitatively comparing the syntatic coverage of English grammars. </title> <booktitle> In Proc. Speech and Natural Language Workshop 1991, </booktitle> <pages> pages 306-311, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kauffmann. </publisher> <pages> 144 </pages>
Reference-contexts: While there were some initial doubts regarding the ultimate utility of such an annotation scheme, they were largely put to rest once researchers had a chance to make use of the corpus. The Penn Treebank has been instrumental in facilitating the comparison of several general English parsers <ref> [9, 10] </ref>. In this thesis we apply the same paradigm to evaluate agreement between different segmentations of the same text. 1.2 Overview of the Corpus In this section, we briefly present some characteristics of natural dialogues that have been extracted from the corpus used for this thesis.
Reference: [11] <author> S.E. Brennan. </author> <title> The grounding problem in conversation with and through computers. In Social and cognitive psychological approaches to interpersonal communication, </title> <address> Mahwah, NJ, 1997. </address> <publisher> Lawrence Erlbaum. </publisher>
Reference-contexts: The acceptance phase is necessary for accomplishing mutual understanding (i.e., grounding <ref> [11] </ref>) between the speakers, and may involve nested discourse contributions. Grounding is a crucial issue for spoken dialogue because speech is a transient medium which is also hidden.
Reference: [12] <author> S.E. Brennan and E. Hulteen. </author> <title> Interaction and feedback in a spoken language system: A theoretical framework. </title> <journal> Knowledge-Based Systems, </journal> <volume> 8 </volume> <pages> 143-151, </pages> <year> 1995. </year>
Reference-contexts: While a machine may apply the same principles of co-operative behavior as a human agent, many dialogue system designers argue that it may more appropriate to employ more explicit prompts and feedback responses <ref> [7, 40, 110, 12, 30] </ref>.
Reference: [13] <author> G. Brown and G. Yule. </author> <title> Discourse Analysis. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1983. </year>
Reference-contexts: Segments can be defined as sections of the dialogue about the same topic or subtopic, independently of the speaker's intentions <ref> [13, 67, 41] </ref>. This alternative definition of segment is useful for information retrieval and indexing of text and speech, where it is desirable to extract from long documents paragraph-like sections that are about a particular topic, and it is not necessary to infer the speaker's intentions.
Reference: [14] <author> J. Carletta. </author> <title> Assessing agreement on classification tasks: </title> <journal> the kappa statistics. Computational Linguistics, </journal> <volume> 22(2) </volume> <pages> 249-254, </pages> <year> 1996. </year>
Reference-contexts: In this section, we review how to compute four metrics for measuring inter-coder agreement: precision, recall, percent agreement and the kappa coefficient. A discussion of evaluation metrics can also be found in <ref> [53, 6, 104, 14] </ref>. 2.3.1 Precision and Recall When comparing two different annotations of the same text, we may select one as the reference and the other one as the test. <p> Recent empirical work on discourse coding has overcome the text size sensitivity problem by either reporting the agreement on the most critical categories (i.e., Segment Boundary) [46] or by reporting the kappa coefficient, , a measure of agreement that is used in experimental psychology <ref> [53, 6, 14] </ref>. This measure corrects the observed agreement by subtracting the estimated chance agreement P c one expects a priori from the marginal distributions of the coded categories. <p> In contrast, reliability studies in discourse analysis have explored more specific contexts [27, 72, 107, 59, 15]. Some of the topics studied by empirical work in discourse analysis include defining and evaluating the consistency of coding schemes for speech act tags (e.g., <ref> [14, 27] </ref>), frequency analysis and models for speech repairs, grounding contributions and other spontaneous speech phenomena such as repairs (e.g., [103, 42]), correlation analysis between prosodic cues and discourse segment boundaries (e.g., [46, 36, 45]), evaluating the agreement among subjects in placing discourse boundaries in transcriptions of monologues [72], and evaluating
Reference: [15] <author> J. Carletta, N. Dahlback, N. Reithinger, and M. Walker. </author> <title> Standards for dialogue coding in natural language processing. </title> <booktitle> Report on the Dagstuhl-Seminar 167, DFKI, </booktitle> <address> Dagstuhl Castle, Germany, </address> <year> 1997. </year>
Reference-contexts: In the Map Task coding scheme, transactions and games correspond to discourse segments and subsegments. The communicative act tags are organized into segment initiatives (commands, questions) and responses (replies and acknowledgments). In 1996 and 1997, two workshops were organized by the Discourse Resource Initiative <ref> [59, 15] </ref>. The major outcome of the workshops was an instruction manual for communicative acts called dialogue acts in multiple layers (DAMSL) [28]. The manual specifies independent dimensions for tagging forward looking acts and backward looking acts. Forward looking acts correspond to intentional speech acts, such as Statement and Request. <p> After the release of Nb , the Discourse Resource Initiative project developed a tool for tagging multiple layers of communicative acts called DAT. The tool has been designed to work with one particular coding manual, the DAMSL coding manual <ref> [15, 28] </ref>. A team of five natural language researchers at MITRE is developing a generic annotation tool called the Alembic Workbench [44]. <p> Agreed upon units include phonemes and phonetic variants [25], intonation labels [96], and syntactic parse trees [64]. In contrast, reliability studies in discourse analysis have explored more specific contexts <ref> [27, 72, 107, 59, 15] </ref>.
Reference: [16] <author> J. Carletta et al. </author> <title> The reliability of a dialogue structure coding scheme. </title> <journal> Computational Linguistics, </journal> <volume> 23(1) </volume> <pages> 13-31, </pages> <year> 1997. </year>
Reference-contexts: We have assessed inter-coder agreement using the metrics of precision, recall and the kappa coefficient. The reliability results are competitive with other published work on discourse segmentation <ref> [107, 41, 45, 80, 16] </ref>, and lend empirical support to the notion that discourse segmentation can be done as reliably as annotating other types of discourse units, such as communicative acts. <p> Whereas the reliability of annotating phonological, syntactic and intonation units in sentences has been extensively studied [54, 64, 96], a discussion of the issues in annotating discourse units in dialogue has only begun to emerge in last three years <ref> [107, 16, 28] </ref>. In the rest of this chapter, we define the concept of discourse segment structure and we compare it to other proposed units of discourse analysis. <p> For example, the dialogue exchange listed at the beginning of the chapter may be labeled with a segment purpose entitled: Find theaters playing the movie The Lion King. 2.1.1 Discourse Segment Structure The theories of intentional structure of discourse and shared plans [38, 39], dialogue games and transactions <ref> [17, 16] </ref> and contributions to discourse [21, 22] assume that task-oriented dialogue is a joint activity in which participants always select a move that is in the direction of accomplishing some mutually agreed upon purpose. <p> While the sequence of communicative acts provides a flat annotation structure, the point of view taken in discourse segmentation is top down, with discourse segments containing sequences of one or more related communicative acts. Some discourse segmentation theories correlate specific communicative act labels with discourse segment initiatives <ref> [17, 16] </ref>. <p> The assistant helps the user in accomplishing a task involving the manufacturing and shipment of goods in a hypothetical railroad freight system. The Map Task Corpus collected at the University of Edinburgh, England consists of 128 spontaneous face-to-face dialogues also collected in a laboratory setting <ref> [3, 16] </ref>. In each dialogue, each of the two speakers has a map, one with a route marked and one without. The goal is for the route follower to draw the route from the instructions of the route giver. <p> The Map Task group at the University of Edinburgh has developed annotation instructions for a small set of communicative act tags and segment tags called transactions, games, and moves <ref> [16] </ref>. In the Map Task coding scheme, transactions and games correspond to discourse segments and subsegments. The communicative act tags are organized into segment initiatives (commands, questions) and responses (replies and acknowledgments). In 1996 and 1997, two workshops were organized by the Discourse Resource Initiative [59, 15]. <p> [41] 81.6 71.4 0.67 Discourse Segmentation Hirschberg and of spoken directions from text Nakatani 96 [45] 0.63 Discourse Segmentation Hirschberg and of directions from text and speech Nakatani 96 0.80 Discourse Segmentation Passonneau and of spoken stories Litman 97 [80] 63.3 70.6 Map Task Move Boundaries Carletta et al. 97 <ref> [16] </ref> 89.0 0.92 Map Task Transaction Segments Carletta at al. 97 0.59 Communicative Acts DAMSL Forward looking Core and Speech Act labels Allen 97 [28] 82 - 93 0.15 - 0.70 DAMSL Backward looking Core and Function labels Allen 97 78 - 95 0.57 - 0.77 DAMSL Forward Acts Jurafsky adapted <p> the following values: * Introduce Name * Introduce Position * Introduce Location * Request Suggest Data * Request Suggest Duration * Request Suggest Location The third coding scheme was the Map Task coding scheme, which was developed for analyzing cooperative route finding dialogues based on the theory of dialogue games <ref> [16] </ref>. In this coding scheme, dialogues were annotated with two layers of related tags. <p> Recall from Chapter 2 that while there are many valuable theories of spoken dialogue, the problems in segmenting it reliably have largely remained unexplored. Only one coding scheme has reported a reliability score (0.59) for segmenting the Map Task dialogues <ref> [16] </ref>. In contrast, two communicative act coding schemes report reliability levels of better than 0.80 for annotating the Map Task and the Switchboard corpora [16, 51]. Three out of four published segmentation schemes, applied to monologues and science articles, report lower reliability scores, between 0.59 and 0.67 [45, 16, 41]. <p> Only one coding scheme has reported a reliability score (0.59) for segmenting the Map Task dialogues [16]. In contrast, two communicative act coding schemes report reliability levels of better than 0.80 for annotating the Map Task and the Switchboard corpora <ref> [16, 51] </ref>. Three out of four published segmentation schemes, applied to monologues and science articles, report lower reliability scores, between 0.59 and 0.67 [45, 16, 41]. <p> In contrast, two communicative act coding schemes report reliability levels of better than 0.80 for annotating the Map Task and the Switchboard corpora [16, 51]. Three out of four published segmentation schemes, applied to monologues and science articles, report lower reliability scores, between 0.59 and 0.67 <ref> [45, 16, 41] </ref>. The best reliability score (0.80) has been obtained by three expert coders annotating spoken monologues using intentional discourse structure theory, by looking at the text transcription as well as listening to the corresponding speech signal [45]. <p> This coding scheme combines the theory of intentional discourse structure (i.e., top-level segment purposes) [39] with the theory of discourse contributions [22] (i.e., requests, responses, presentations and acceptances). It is also related to the Map Task coding scheme <ref> [16] </ref>, in which top-level segments correspond to Transactions, and nested contributions corresponding to Games. However, we have made one important simplification.
Reference: [17] <author> L. Carlson. </author> <title> Dialogue games: an approach to discourse analysis. </title> <address> D. </address> <publisher> Reidel Pub. Co., Dordrecht, Holland, </publisher> <year> 1983. </year>
Reference-contexts: For example, the dialogue exchange listed at the beginning of the chapter may be labeled with a segment purpose entitled: Find theaters playing the movie The Lion King. 2.1.1 Discourse Segment Structure The theories of intentional structure of discourse and shared plans [38, 39], dialogue games and transactions <ref> [17, 16] </ref> and contributions to discourse [21, 22] assume that task-oriented dialogue is a joint activity in which participants always select a move that is in the direction of accomplishing some mutually agreed upon purpose. <p> While the sequence of communicative acts provides a flat annotation structure, the point of view taken in discourse segmentation is top down, with discourse segments containing sequences of one or more related communicative acts. Some discourse segmentation theories correlate specific communicative act labels with discourse segment initiatives <ref> [17, 16] </ref>.
Reference: [18] <author> R. Carlson and S. Hunnicutt. </author> <title> Generic and domain-specific aspects of the waxholm NLP and dialog modules. </title> <booktitle> In Proceedings of ICSLP-96, 4th International Conference on Spoken Language Processing, </booktitle> <pages> pages 677-680, </pages> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: Finite state machines and context-free grammars have been used to model graphical user interfaces [76], typed natural language interfaces [108, 29] and spoken language interfaces <ref> [4, 8, 18, 70] </ref>. They have been used to model natural language interactions in Wizard-of-Oz studies, in which users talked to a system simulated by an engineer, before the system is fully developed [98, 29], and sequences of communicative acts in spontaneous telephone conversations of the Switchboard corpus [51].
Reference: [19] <author> N.A. Chinchor and B. Sundheim. </author> <title> Message understanding conference MUC tests of discourse processing. </title> <booktitle> In AAAI 95 Spring Symposium on Empirical Methods in Discourse Interpretation and Generation, </booktitle> <pages> pages 21-26, </pages> <institution> Stanford University, </institution> <year> 1995. </year>
Reference-contexts: The annotation units and the conventions form what is called a coding scheme. For example, at the syntactic level, pronouns might be annotated along with the definite noun phrases they refer to <ref> [19, 44] </ref> and at the intentional level, sentences might be annotated with the speaker intentions (e.g. whether the sentence is a request for information, an acknowledgment) [92, 93, 1]. <p> Corpus-based analyses of co-reference try to establish the semantic relations that exist between definite noun phrases and pronouns <ref> [19, 44] </ref>. Resolving co-reference is an important function of the understanding component of a spoken dialogue system. This function is non trivial. For example, a resolution algorithm should be able to detect that in line 5, the pronoun they (in they're supposed to...) does not have an antecedent. <p> However, presently, Nb is not the only discourse annotation tool available. Because it is difficult to design an annotation tool that is appropriate to handle many different coding schemes, all tools with one exception have been developed to comply with one specific coding scheme. The series of MUC conferences <ref> [19] </ref> used the co-reference annotation tool called DDTool developed at SRA labs [5]. The DDTool allows users to display chains of co-referent nouns and noun phrases by linking them with colored straight lines. <p> Pronouns and noun phrases Hirschman 80 - 90 85 - 90 in newswire text et al 98 [44] Aligning content words in 90 - 92 English-to-French translations Melamed [66] Table 2.1: Some representative studies in inter-coder agreement in annotating units in text and speech. co-referent noun phrases in newswire text <ref> [19, 44] </ref>. Table 2.1 illustrates the state of the art in evaluating text analysis units by listing some repre <p>- sentative inter-coder agreement studies that have been published in the last few years. The list is not exhaustive. <p> In the area of text processing, text corpora annotated with co-referent nouns and noun phrases have been instrumental in monitoring the progress in automatic information extraction algorithms developed for the series of Message Understanding Conferences (MUC) <ref> [19, 44] </ref>. Once a corpus is made available for research, a good set of annotation tools can greatly facilitate the annotation process, both in throughput, accuracy, and consistency, thereby leading to useful data that can serve the needs of the research community.
Reference: [20] <author> H.H. Clark. </author> <title> Managing problems in speaking. Speech Communication, </title> <address> 15(3-4):231-242, </address> <year> 1994. </year>
Reference-contexts: Repairs Repairs can be self-repairs, involving only one speaker and one dialogue turn, or they may involve both participants for a few dialogue turns. They are also local discourse phenomena: as soon as the speaker or hearer detects an error in the speech stream, she tries to repair it <ref> [90, 56, 47, 89, 73, 20] </ref>. The instructions specified that in case of speech repairs, segment boundaries should be placed before complete clauses that could be fully understood as switches in segment purposes. However, some spontaneous repairs could not be handled consistently by this rule. <p> In a fresh start, the first two partial questions and their intention are abandoned to be replaced by the last one. Researchers have pointed out that one effective repair strategy is using the same syntax (i.e. what time) to signal to the listener exactly what she is replacing <ref> [56, 20] </ref>. Some coders placed a segment boundary at the first or second question, while others placed it at the complete question What time is The Client playing?. <p> This constraint is motivated by previous empirical studies in speech repairs which indicated that repairs occur sooner rather than later <ref> [90, 56, 89, 20] </ref>. In particular, this constraint is consistent with Clark's principle of repair [21]: 130 When agents detect a problem serious enough to warrant a repair, they try to initiate and repair the problem at the first opportunity after detecting it. <p> OK) tend to be spoken with a falling intonation contour, and do not require that the agent further explain or repeat the information. 6.2.3 Collaborative Timing Spoken dialogue is a real-time collaborative process in which speakers take the initiative at specific instant in time <ref> [20, 21, 85] </ref>. <p> If a text corpus is time aligned to the corresponding speech signal, it is possible to conduct empirical studies that can provide precise answers about the timing, size and type of simultaneous contributions <ref> [20] </ref>. 132 Appendix A The Group-wise Kappa Coefficient The coefficient can be derived from the observed agreement P o and the chance agreement P c : = 1 P c In chapter 2, we demonstrate how to compute for the simple case of two coders annotating two categories.
Reference: [21] <author> H.H. Clark. </author> <title> Using Language. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, England, </address> <year> 1996. </year>
Reference-contexts: Discourse segments may be initiated by any participant in the conversation with the purpose either of finding a mutually satisfactory solution to a task [39, 37, 57, 58] or of repairing and preventing misunderstanding <ref> [21, 22, 23] </ref>. An example of a discourse segmentation is displayed in Figure 1-1. Segments are sequences of one or more related communicative acts which accomplish a specific purpose (or goal) in common between the conversation participants. <p> The data annotated with Nb have provided substantial empirical evidence about the discourse segment structure of natural dialogue and the internal organization of segments. The annotated data provide substantial support for the theories of intentional structure of discourse [39, 37, 57, 58] and of contributions to discourse <ref> [21, 22, 23] </ref> which view dialogue as a co-operative or joint activity driven by the speakers' intentions. The annotated data have also provided the basis for evaluating empirically which computational device is appropriate to process natural dialogues. <p> exchange listed at the beginning of the chapter may be labeled with a segment purpose entitled: Find theaters playing the movie The Lion King. 2.1.1 Discourse Segment Structure The theories of intentional structure of discourse and shared plans [38, 39], dialogue games and transactions [17, 16] and contributions to discourse <ref> [21, 22] </ref> assume that task-oriented dialogue is a joint activity in which participants always select a move that is in the direction of accomplishing some mutually agreed upon purpose. From a computational perspective, speakers seem to behave as if trying to maximize a goal-oriented utility criterion. <p> get all the different theaters? 5 A: I can give you that information 6 C: You can? 7 C: Okay, in Snellville, Septum movies The variability in determining the exact location of the start of the task-related conversation can be explained by what some researchers have called preliminaries, or pre-sequences <ref> [91, 85, 21, 48] </ref>. Pre-sequences are discourse transitions that are used by conversation participants to set a general common ground before committing to a more specific task. Transitional pre-closing statements also posed some problems in locating the end of the task-oriented part of the conversation. <p> Incidentally, it is not by chance that each turn in the second segment is much shorter than the corresponding turn in the first segment. According to Clark, contributions are made with the participants obeying the rule of least effort <ref> [21] </ref>. This rule is consistent with Grice's conversational maxim stating that dialogue participants should avoid unnecessary verbosity [34]. <p> It is possible that a different set of labels for subsegments and more extensive instructions might yield different results. For example, Grosz and Sidner [38, 39] and Clark <ref> [21] </ref> among others, point out that subsegments tend to play a specific role in the task structure. Typically, a subsegment might represent either a sub-task or a digression. A sub-task contributes a clarification, an explanation or a confirmation necessary for the completion of the top-level segment purpose. <p> Unlike communicative act labels, purpose labels do not encode the individual intentions of the speakers. Instead, we consider the purposes as being joint projects, or shared plans, between the customer and the agent <ref> [39, 21, 22, 37, 57, 58] </ref>. Each segment is a sequence of agent and customer actions that co-operate to accomplish the purpose. This type of linear segmentation is the one that produced the highest inter-coder agreement in the experiments presented in Chapter 4. <p> On the other hand, topics and intentions can be recognized independently of each other. If the agent needs to clarify both the intentions and the topic, she may select the order based on a particular dialogue strategy. In the theory of discourse contributions <ref> [21, 22, 23] </ref>, the initial customer sentence is the presentation contribution, and the segments at the leaves of the tree correspond to different acceptance contributions. Failure at any one of the reasoning steps results in a different type of repair segment initiated by the agent. <p> This taxonomy combines the types considered in the intentional theory of discourse [39, 58] with the ones considered in the theories of discourse contributions <ref> [21, 22] </ref> and of turn-taking in conversations [85, 48]. A preliminary segment (or pre-sequence) has a generic purpose which is the introduction to a more specific, task-oriented purpose. A preliminary purpose is a pre-condition to the purpose that follows it. <p> of their transitory nature, the exact boundary locations for preliminaries and repairs is annotated less reliably using linear annotations. 5.4.2 Model: A Stack with Extended Operations Is Still A Stack The model we consider for segment transitions is an extension of the stack model proposed by [35] and reviewed in <ref> [21] </ref>. In this section we present the extended model and discuss how closely it is related to the original model. In the original model, a stack provides a priority list of all of the segment purposes. <p> Sub- tasks and digressions are processed by push and pop. Multiple active purposes are processed by swap, and fresh starts and repairs by replace. A more formal treatment of an underlying computational model migth based on the foundations set forth by [39] and <ref> [21] </ref>. <p> Rather than postulating a theory first, and then seeking evidence to support it, we first let many coders annotate text transcriptions with limited instructions. We were then able to correlate the segmentations proposed by a majority of coders with theories that model conversation as a highly structured collaborative process <ref> [21, 39] </ref>. 6.1.1 Discourse Segmentation from Text Can Be Performed Reliably For a long time, the reliability of discourse segmentation of text has been a controversial issue. <p> This constraint is motivated by previous empirical studies in speech repairs which indicated that repairs occur sooner rather than later [90, 56, 89, 20]. In particular, this constraint is consistent with Clark's principle of repair <ref> [21] </ref>: 130 When agents detect a problem serious enough to warrant a repair, they try to initiate and repair the problem at the first opportunity after detecting it. We argue that switching between segment purposes is also constrained by cognitive processes (e.g., limited memory for spoken words). <p> OK) tend to be spoken with a falling intonation contour, and do not require that the agent further explain or repeat the information. 6.2.3 Collaborative Timing Spoken dialogue is a real-time collaborative process in which speakers take the initiative at specific instant in time <ref> [20, 21, 85] </ref>.
Reference: [22] <author> H.H. Clark and E.F. Schaefer. </author> <title> Contributing to discourse. </title> <journal> Cognitive Science, </journal> <volume> 13 </volume> <pages> 259-294, </pages> <year> 1989. </year>
Reference-contexts: Discourse segments may be initiated by any participant in the conversation with the purpose either of finding a mutually satisfactory solution to a task [39, 37, 57, 58] or of repairing and preventing misunderstanding <ref> [21, 22, 23] </ref>. An example of a discourse segmentation is displayed in Figure 1-1. Segments are sequences of one or more related communicative acts which accomplish a specific purpose (or goal) in common between the conversation participants. <p> The data annotated with Nb have provided substantial empirical evidence about the discourse segment structure of natural dialogue and the internal organization of segments. The annotated data provide substantial support for the theories of intentional structure of discourse [39, 37, 57, 58] and of contributions to discourse <ref> [21, 22, 23] </ref> which view dialogue as a co-operative or joint activity driven by the speakers' intentions. The annotated data have also provided the basis for evaluating empirically which computational device is appropriate to process natural dialogues. <p> exchange listed at the beginning of the chapter may be labeled with a segment purpose entitled: Find theaters playing the movie The Lion King. 2.1.1 Discourse Segment Structure The theories of intentional structure of discourse and shared plans [38, 39], dialogue games and transactions [17, 16] and contributions to discourse <ref> [21, 22] </ref> assume that task-oriented dialogue is a joint activity in which participants always select a move that is in the direction of accomplishing some mutually agreed upon purpose. From a computational perspective, speakers seem to behave as if trying to maximize a goal-oriented utility criterion. <p> Insertions and omissions of embedded subtask and digression segments accounted for about 30% of the minority lists, indicating that different coders applied different levels of detail in annotating segments and subsegments. 75 Contributions to Discourse According to Clark and Schaefer's theory of dialogue <ref> [22] </ref> conversations are organized into nested sequences of contributions. A contribution can be viewed as the smallest possible discourse segment unit. <p> The organization of each contribution followed the principles of cooperative dialogue: the content was presented by one speaker (i.e., a statement or a question) and evaluated by the other speaker with an acknowledgment or some other appropriate response <ref> [22] </ref>. Here is a typical example: 82 are placed at changes in the task structure of the dialogue. 83 84 13 A: [uh-uh] Did you need times for matinee or evening showings? Present. Request 14 C: Evenings. <p> The patterns of agreement among coders indicate that it is possible to reliably annotate discourse segments that are defined by their intentional purpose [38]. In addition, the internal structure of each annotated segment is consistent with the theory of cooperative discourse contributions <ref> [22] </ref>. The patterns of disagreement were located around dialogue phenomena that could not be covered adequately by a simple linear segment model, such as speech and dialogue repairs and multiple concurrent purposes. Nevertheless, such events constituted the exception rather than the rule in the dialogues. <p> In the second segment, the request is absent, because the agent volunteers some information that was not explicitly requested by the customer. This coding scheme combines the theory of intentional discourse structure (i.e., top-level segment purposes) [39] with the theory of discourse contributions <ref> [22] </ref> (i.e., requests, responses, presentations and acceptances). It is also related to the Map Task coding scheme [16], in which top-level segments correspond to Transactions, and nested contributions corresponding to Games. However, we have made one important simplification. <p> Unlike communicative act labels, purpose labels do not encode the individual intentions of the speakers. Instead, we consider the purposes as being joint projects, or shared plans, between the customer and the agent <ref> [39, 21, 22, 37, 57, 58] </ref>. Each segment is a sequence of agent and customer actions that co-operate to accomplish the purpose. This type of linear segmentation is the one that produced the highest inter-coder agreement in the experiments presented in Chapter 4. <p> Some other segments contain only the response contribution, if the agent volunteers the information without a specific request, or if another segment separates the request from the corresponding response. Each request and response has been further divided into presentation and acceptance <ref> [22] </ref>. The presentation is the first communicative act of each contribution. In the presentation contribution one speaker presents some content to be evaluated (for example, a Request or an Inform act). <p> On the other hand, topics and intentions can be recognized independently of each other. If the agent needs to clarify both the intentions and the topic, she may select the order based on a particular dialogue strategy. In the theory of discourse contributions <ref> [21, 22, 23] </ref>, the initial customer sentence is the presentation contribution, and the segments at the leaves of the tree correspond to different acceptance contributions. Failure at any one of the reasoning steps results in a different type of repair segment initiated by the agent. <p> This taxonomy combines the types considered in the intentional theory of discourse [39, 58] with the ones considered in the theories of discourse contributions <ref> [21, 22] </ref> and of turn-taking in conversations [85, 48]. A preliminary segment (or pre-sequence) has a generic purpose which is the introduction to a more specific, task-oriented purpose. A preliminary purpose is a pre-condition to the purpose that follows it. <p> Collectively, the findings presented in this chapter provide substantial empirical evidence for theories of dialogue as a joint activity in which discourse segments are initiated by either speaker with the purpose of either finding a solution to the task at hand [39] or repairing and preventing misunderstandings <ref> [22] </ref>. In addition, the statistics reported here are consistent with at least two other empirical studies conducted on a similar corpus of British-English telephone conversations, the London-Lund corpus [99] analyzed by Orestrom [78] and by Clark and Schaefer [22]. <p> solution to the task at hand [39] or repairing and preventing misunderstandings <ref> [22] </ref>. In addition, the statistics reported here are consistent with at least two other empirical studies conducted on a similar corpus of British-English telephone conversations, the London-Lund corpus [99] analyzed by Orestrom [78] and by Clark and Schaefer [22]. The movie schedule domain is within reach of state-of-the-art spoken dialogue systems.
Reference: [23] <author> H.H. Clark and D. Wilkes-Gibbs. </author> <title> Referring as a collaborative process. </title> <journal> Cognition, </journal> <volume> 22 </volume> <pages> 1-39, </pages> <year> 1986. </year>
Reference-contexts: Discourse segments may be initiated by any participant in the conversation with the purpose either of finding a mutually satisfactory solution to a task [39, 37, 57, 58] or of repairing and preventing misunderstanding <ref> [21, 22, 23] </ref>. An example of a discourse segmentation is displayed in Figure 1-1. Segments are sequences of one or more related communicative acts which accomplish a specific purpose (or goal) in common between the conversation participants. <p> The data annotated with Nb have provided substantial empirical evidence about the discourse segment structure of natural dialogue and the internal organization of segments. The annotated data provide substantial support for the theories of intentional structure of discourse [39, 37, 57, 58] and of contributions to discourse <ref> [21, 22, 23] </ref> which view dialogue as a co-operative or joint activity driven by the speakers' intentions. The annotated data have also provided the basis for evaluating empirically which computational device is appropriate to process natural dialogues. <p> On the other hand, topics and intentions can be recognized independently of each other. If the agent needs to clarify both the intentions and the topic, she may select the order based on a particular dialogue strategy. In the theory of discourse contributions <ref> [21, 22, 23] </ref>, the initial customer sentence is the presentation contribution, and the segments at the leaves of the tree correspond to different acceptance contributions. Failure at any one of the reasoning steps results in a different type of repair segment initiated by the agent.
Reference: [24] <author> P.R. Cohen and H.J. Levesque. </author> <title> Preliminaries to a collaborative model of dialogue. Speech Communication, </title> <address> 15(3-4):265-274, </address> <year> 1994. </year>
Reference-contexts: Critics of the structural model approach have argued that such models may be appropriate only for IVR and question-answer systems in which the sequence of the interactions is essentially defined a priori (e.g., <ref> [24, 87] </ref>). They argue that the number of states and state transitions would become too large if one wished to model co-operative dialogues with clarifications, confirmations, switches in intentions initiated by either speaker, and purposes that can be completed out of order. <p> A finite language model such as a trigram may be useful in predicting the customer's next action from the few preceding actions, but it seems inappropriate in helping to predict the agent's behavior. One alternative to finite state models is the co-operative plan-based approach (see <ref> [39, 37, 57, 58, 24, 86, 87] </ref>, among others). In this approach, the dialogue state and sentence meaning are represented by a set of logical predicates. Communicative acts are operators which have predicate pre-conditions 124 and side effects they may add or delete predicates to the dialogue state.
Reference: [25] <author> R. Cole et al. </author> <title> Speech as patterns on paper. </title> <booktitle> In Perception and Production of Fluent Speech, </booktitle> <pages> pages 3-50. </pages> <publisher> Erlbaum, </publisher> <year> 1980. </year> <month> 145 </month>
Reference-contexts: Inter-coder 41 and 9 in segmentation 2 do not agree. The overall agreement depends on the actual length of the text. agreement has been found to be 80-85% on phonetic transcription tasks <ref> [25] </ref>. In this section, we review how to compute four metrics for measuring inter-coder agreement: precision, recall, percent agreement and the kappa coefficient. <p> Agreed upon units include phonemes and phonetic variants <ref> [25] </ref>, intonation labels [96], and syntactic parse trees [64]. In contrast, reliability studies in discourse analysis have explored more specific contexts [27, 72, 107, 59, 15].
Reference: [26] <author> S. Condon and C. Cech. </author> <title> Manual for coding decision-making interactions. </title> <type> Technical report, </type> <institution> University of Southwestern Louisiana, Discourse Intervention Project, </institution> <note> 1992 (revised 1995). </note>
Reference-contexts: Responses were divided into Acknowledgment, Clarify, Reply-y, Reply-n and Reply-w. Preparation moves were tagged as Ready. A preparation move was a sentence such as let's see and just a minute. The fourth coding scheme, developed by Condon and Chech <ref> [26] </ref>, was organized into three independent functions. In this scheme, each clause was to be annotated using one, two or three different mark-up tags, called Move, Response, and Other.
Reference: [27] <author> S. Condon and C. Cech. </author> <title> Problems for reliable discourse coding systems. </title> <booktitle> In AAAI 95 Spring Symposium on Empirical Methods in Discourse Interpretation and Generation, </booktitle> <pages> pages 27-33, </pages> <institution> Stanford University, </institution> <year> 1995. </year>
Reference-contexts: Agreed upon units include phonemes and phonetic variants [25], intonation labels [96], and syntactic parse trees [64]. In contrast, reliability studies in discourse analysis have explored more specific contexts <ref> [27, 72, 107, 59, 15] </ref>. <p> In contrast, reliability studies in discourse analysis have explored more specific contexts [27, 72, 107, 59, 15]. Some of the topics studied by empirical work in discourse analysis include defining and evaluating the consistency of coding schemes for speech act tags (e.g., <ref> [14, 27] </ref>), frequency analysis and models for speech repairs, grounding contributions and other spontaneous speech phenomena such as repairs (e.g., [103, 42]), correlation analysis between prosodic cues and discourse segment boundaries (e.g., [46, 36, 45]), evaluating the agreement among subjects in placing discourse boundaries in transcriptions of monologues [72], and evaluating
Reference: [28] <author> M. Core and J. Allen. </author> <title> Coding dialogs with the damsl annotation scheme. </title> <booktitle> In AAAI Fall Symposium on Communicative Action in Humans and Machines, </booktitle> <address> Boston, MA, </address> <year> 1997. </year> <journal> American Association of Artificial Intelligence. </journal>
Reference-contexts: Whereas the reliability of annotating phonological, syntactic and intonation units in sentences has been extensively studied [54, 64, 96], a discussion of the issues in annotating discourse units in dialogue has only begun to emerge in last three years <ref> [107, 16, 28] </ref>. In the rest of this chapter, we define the concept of discourse segment structure and we compare it to other proposed units of discourse analysis. <p> In 1996 and 1997, two workshops were organized by the Discourse Resource Initiative [59, 15]. The major outcome of the workshops was an instruction manual for communicative acts called dialogue acts in multiple layers (DAMSL) <ref> [28] </ref>. The manual specifies independent dimensions for tagging forward looking acts and backward looking acts. Forward looking acts correspond to intentional speech acts, such as Statement and Request. Backward looking acts indicate the relationship between the current act and the dialogue history, such as Respond and Agreement. <p> After the release of Nb , the Discourse Resource Initiative project developed a tool for tagging multiple layers of communicative acts called DAT. The tool has been designed to work with one particular coding manual, the DAMSL coding manual <ref> [15, 28] </ref>. A team of five natural language researchers at MITRE is developing a generic annotation tool called the Alembic Workbench [44]. <p> text and speech Nakatani 96 0.80 Discourse Segmentation Passonneau and of spoken stories Litman 97 [80] 63.3 70.6 Map Task Move Boundaries Carletta et al. 97 [16] 89.0 0.92 Map Task Transaction Segments Carletta at al. 97 0.59 Communicative Acts DAMSL Forward looking Core and Speech Act labels Allen 97 <ref> [28] </ref> 82 - 93 0.15 - 0.70 DAMSL Backward looking Core and Function labels Allen 97 78 - 95 0.57 - 0.77 DAMSL Forward Acts Jurafsky adapted to Switchboard at al. 97 [51] 84 0.80 Map Task Move Speech Acts Carletta et al. 97 0.83 Rhetorical Relations Selection of prominent sentences
Reference: [29] <author> N. Dahlback and A. Jonsson. </author> <title> An empirically based computationally tractable dialogue model. </title> <booktitle> In Proceedings of Fourteenth Annual Meeting of The Cognitive Science Society, </booktitle> <pages> pages 785-790, </pages> <address> Bloomington, Indiana, </address> <year> 1992. </year>
Reference-contexts: Using a grammar-based approach has been motivated by the observation that sequences of communicative acts tend to appear in adjacency pairs such as Statement- Acknowledgment and Question-Answer [91]. Finite state machines and context-free grammars have been used to model graphical user interfaces [76], typed natural language interfaces <ref> [108, 29] </ref> and spoken language interfaces [4, 8, 18, 70]. <p> They have been used to model natural language interactions in Wizard-of-Oz studies, in which users talked to a system simulated by an engineer, before the system is fully developed <ref> [98, 29] </ref>, and sequences of communicative acts in spontaneous telephone conversations of the Switchboard corpus [51]. They have also been used to provide a predictive dialogue model for human-to-human spoken interaction within a speech translation system [50].
Reference: [30] <author> M. Danieli. </author> <title> On the use of expectations for detecting and repairing human-machine miscommu-nication. In Detecting, Repairing and Preventing Human-Machine Miscommunication, </title> <booktitle> Notes from the AAAI-96 Workshop, </booktitle> <address> Portland, Oregon, </address> <year> 1996. </year> <journal> American Association of Artificial Intelligence. </journal>
Reference-contexts: In order to circumvent the state space explosion problem faced by finite state models, another alternative has been to represent the state space by equivalence classes that contains several individual states at once. Systems such as CSELT DIALOGOS <ref> [30] </ref>, AT&T Amica [81] and MIT Bianca [94] apply the principles of propositional production systems [76, 77]. According to Olsen's definition [77], a propositional production system consists of a state space of equivalent classes and a set of rules. <p> While a machine may apply the same principles of co-operative behavior as a human agent, many dialogue system designers argue that it may more appropriate to employ more explicit prompts and feedback responses <ref> [7, 40, 110, 12, 30] </ref>.
Reference: [31] <author> G. Flammia and V. Zue. </author> <title> Empirical evaluation of human performance and agreement in parsing discourse constituents in spoken dialogue. </title> <booktitle> In Proc. Euroospeech-95, </booktitle> <volume> volume 3, </volume> <pages> pages 1965-1968, </pages> <address> Madrid, Spain, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: In Chapter 4, we discuss in detail four different discourse segmentation experiments which have involved many different coders, and we report under which condition we have obtained reliable discourse segmentations from many trained coders. This chapter substantially revises and extends some of the results that we reported in <ref> [31, 33] </ref>. In Chapter 5 we present a case study of conversation analysis which has been made possible by annotating a corpus of 190 different dialogue transcriptions using Nb . We have annotated a set of movie schedule dialogues with intentional units such as discourse segments and communicative acts. <p> The results of the first experiment have been reported in <ref> [31] </ref> and the results for second experiment have been reported in [33]. This chapter is a substantial revision and extension of the work reported there. In each experiment, the training consisted of reading some instructions and annotating the dialogue transcriptions using the Nb annotation tool.
Reference: [32] <author> G. Flammia and V. Zue. </author> <title> Nb: a graphical user interface for annotating spoken dialogue. </title> <booktitle> In AAAI 95 Spring Symposium on Empirical Methods in Discourse Interpretation and Generation, </booktitle> <pages> pages 40-46, </pages> <institution> Stanford University, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: In Chapter 3, we report on how we developed and evaluated the three releases of Nb , the annotation tool that we have used for designing and assessing the reliability of discourse segmentation schemes. The first release of Nb is also described in <ref> [32] </ref>. In Chapter 4, we discuss in detail four different discourse segmentation experiments which have involved many different coders, and we report under which condition we have obtained reliable discourse segmentations from many trained coders. <p> The first release, completed in 1995 and reported in <ref> [32] </ref>, was an X/Motif graphical user interface written in C that allowed users to annotate discourse segments and dialogue acts line by line. At that time, Nb ran only under the Sun OS Unix operating system.
Reference: [33] <author> G. Flammia and V. Zue. </author> <title> Learning the structure of mixed-initiative dialogues from a corpus of annotated conversations. </title> <booktitle> In Proc. Euroospeech-97, </booktitle> <volume> volume 4, </volume> <pages> pages 1871-1874, </pages> <address> Rhodes, Greece, </address> <month> September </month> <year> 1997. </year>
Reference-contexts: In Chapter 4, we discuss in detail four different discourse segmentation experiments which have involved many different coders, and we report under which condition we have obtained reliable discourse segmentations from many trained coders. This chapter substantially revises and extends some of the results that we reported in <ref> [31, 33] </ref>. In Chapter 5 we present a case study of conversation analysis which has been made possible by annotating a corpus of 190 different dialogue transcriptions using Nb . We have annotated a set of movie schedule dialogues with intentional units such as discourse segments and communicative acts. <p> The results of the first experiment have been reported in [31] and the results for second experiment have been reported in <ref> [33] </ref>. This chapter is a substantial revision and extension of the work reported there. In each experiment, the training consisted of reading some instructions and annotating the dialogue transcriptions using the Nb annotation tool. The objectives of the inter-coder agreement experiments are twofold.
Reference: [34] <author> H. Grice. </author> <title> Logic and conversation. In Syntax and Semantics: </title> <journal> Speech Acts, </journal> <volume> volume 3. </volume> <publisher> Academic Press, </publisher> <year> 1975. </year>
Reference-contexts: According to Clark, contributions are made with the participants obeying the rule of least effort [21]. This rule is consistent with Grice's conversational maxim stating that dialogue participants should avoid unnecessary verbosity <ref> [34] </ref>. <p> In general, dividing the information into multiple short turns and breaking down the information from the generic to the specific is consistent with Grice's conversational maxims <ref> [34] </ref>. Grice enumerated generic guidelines of what should be said and how it should be said when reporting some information. Four of the maxims are: 1. Make your contribution as informative as is required (for the current purposes of the exchange). 2.
Reference: [35] <author> B. Grosz. </author> <title> Focusing and description in natural language dialogue. </title> <editor> In B. Webber, A. Joshi, and I. Sag, editors, </editor> <booktitle> Elements Of Discourse Understanding, </booktitle> <address> Cambridge, England, 1981. </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: On the other hand, we argue that a relatively simple hierarchical data structure (i.e., a stack, as proposed by <ref> [35] </ref>) is sufficient to model segment purpose switches in natural dialogues, including apparently irregular phenomena such as repairs, fresh starts and multiple concurrent active purposes. 25 1.4 Overview of the Thesis The rest of the thesis is organized as follows. <p> In theory, these relations should be a small set of mutually exclusive classes (e.g., is same as, is element of, contains...). The list of active entities that can be mentioned at any point in the dialogue constitutes the focus of attention, or the attentional state of the dialogue participants <ref> [35] </ref>. To conduct a cooperative dialogue, it is necessary for the participants to share a common attentional state. The purpose of the clarification segment The Disney movie?-Yes is precisely to ensure that both participants are talking about the same movie. <p> 4 indicated that, because of their transitory nature, the exact boundary locations for preliminaries and repairs is annotated less reliably using linear annotations. 5.4.2 Model: A Stack with Extended Operations Is Still A Stack The model we consider for segment transitions is an extension of the stack model proposed by <ref> [35] </ref> and reviewed in [21]. In this section we present the extended model and discuss how closely it is related to the original model. In the original model, a stack provides a priority list of all of the segment purposes. <p> We have argued that the stack data structure proposed in <ref> [35] </ref> is appropriate to model the focus of attention of the conversation participants during all of the examples which have been observed empirically.
Reference: [36] <author> B. Grosz and J. Hirshberg. </author> <title> Some intonational characteristics of discourse structure. </title> <booktitle> In Proc. Int. Conf. on Spoken Language Processing, </booktitle> <pages> pages 429-432, </pages> <address> Banff, Canada, </address> <year> 1992. </year> <month> 146 </month>
Reference-contexts: work in discourse analysis include defining and evaluating the consistency of coding schemes for speech act tags (e.g., [14, 27]), frequency analysis and models for speech repairs, grounding contributions and other spontaneous speech phenomena such as repairs (e.g., [103, 42]), correlation analysis between prosodic cues and discourse segment boundaries (e.g., <ref> [46, 36, 45] </ref>), evaluating the agreement among subjects in placing discourse boundaries in transcriptions of monologues [72], and evaluating human and algorithmic performance in annotating 46 Annotation Task Citation % Agree Recall Precision Kappa Discourse Segments Subtopic Segmentation of written science articles Hearst 97 [41] 81.6 71.4 0.67 Discourse Segmentation Hirschberg <p> Finally, discourse segment structure is correlated with specific acoustic and prosodic cues such as changes in pause duration, speech signal amplitude and pitch contour <ref> [82, 36, 46, 52] </ref>. For example, Hirshberg and Nakatani report an increase of the kappa coefficient from 0.67 to 0.80 when trained coders were able to listen to the speech signal as well as read the transcription [45]. <p> However, speakers convey changes in their intentional and attentional state using a combination of lexical, acoustic and prosodic cues such as discourse cue words, pause duration, speech signal amplitude and pitch contour <ref> [82, 46, 100, 36, 72, 52] </ref>. Hirshberg and Nakatani report very reliable results in annotating segments by listening to the speech signal as well as reading the text transcription [45].
Reference: [37] <author> B. Grosz and S. Kraus. </author> <title> Collaborative plans for complex group action. </title> <journal> Artificial Intelligence, </journal> <volume> 86(2) </volume> <pages> 269-357, </pages> <year> 1996. </year>
Reference-contexts: In particular, some models assume that human-to-human task-oriented dialogue can be modeled as a sequence of related discourse segments. Discourse segments may be initiated by any participant in the conversation with the purpose either of finding a mutually satisfactory solution to a task <ref> [39, 37, 57, 58] </ref> or of repairing and preventing misunderstanding [21, 22, 23]. An example of a discourse segmentation is displayed in Figure 1-1. Segments are sequences of one or more related communicative acts which accomplish a specific purpose (or goal) in common between the conversation participants. <p> The data annotated with Nb have provided substantial empirical evidence about the discourse segment structure of natural dialogue and the internal organization of segments. The annotated data provide substantial support for the theories of intentional structure of discourse <ref> [39, 37, 57, 58] </ref> and of contributions to discourse [21, 22, 23] which view dialogue as a co-operative or joint activity driven by the speakers' intentions. The annotated data have also provided the basis for evaluating empirically which computational device is appropriate to process natural dialogues. <p> The third one is the intentional structure, which lists the relations among the purposes being accomplished by the sequences of dialogue turns called discourse segments. This three-layered model has provided the seed for the model of dialogue as shared planning activity <ref> [39, 37, 57, 58] </ref>. 30 semantic entities that need to be communicated between the conversation participants. Edges are directed from purposes to dependent entities. For simple information retrieval domains it is possible to quickly develop a list of specific purposes, at least from the agent's perspective. <p> Unlike communicative act labels, purpose labels do not encode the individual intentions of the speakers. Instead, we consider the purposes as being joint projects, or shared plans, between the customer and the agent <ref> [39, 21, 22, 37, 57, 58] </ref>. Each segment is a sequence of agent and customer actions that co-operate to accomplish the purpose. This type of linear segmentation is the one that produced the highest inter-coder agreement in the experiments presented in Chapter 4. <p> This type of reasoning goes beyond a probabilistic finite state model. involved in specifying the initial request I'm looking for the Buford Cinema. The four reasoning steps are the internal nodes of the tree and correspond to knowledge pre-conditions in the intentional theory of discourse <ref> [39, 37, 57, 58] </ref>. The steps are partially ordered. Recognizing the customer's words is a pre-condition to recognizing her intentions and topics. On the other hand, topics and intentions can be recognized independently of each other. <p> A finite language model such as a trigram may be useful in predicting the customer's next action from the few preceding actions, but it seems inappropriate in helping to predict the agent's behavior. One alternative to finite state models is the co-operative plan-based approach (see <ref> [39, 37, 57, 58, 24, 86, 87] </ref>, among others). In this approach, the dialogue state and sentence meaning are represented by a set of logical predicates. Communicative acts are operators which have predicate pre-conditions 124 and side effects they may add or delete predicates to the dialogue state.
Reference: [38] <author> B. Grosz and C. Sidner. </author> <title> Attentions, intentions and the structure of discourse. </title> <journal> Computational Linguistics, </journal> <volume> 12(3) </volume> <pages> 175-204, </pages> <year> 1986. </year>
Reference-contexts: In this thesis, we focus on task-oriented spoken dialogue because it is a genre applicable to building spoken language systems. In this case, discourse analysis is mostly focused on determining relations between sentences spoken by different speakers across dialogue turns. In particular, we focus on intentional relations (e.g., <ref> [1, 38, 39, 92, 93] </ref>). For example, in this framework the first sentence of the above dialogue exchange 27 (I'm trying to find out where the Lion King is located) is not interpreted solely as a declarative, but rather as a communicative act: a request for some specific information. <p> For example, the dialogue exchange listed at the beginning of the chapter may be labeled with a segment purpose entitled: Find theaters playing the movie The Lion King. 2.1.1 Discourse Segment Structure The theories of intentional structure of discourse and shared plans <ref> [38, 39] </ref>, dialogue games and transactions [17, 16] and contributions to discourse [21, 22] assume that task-oriented dialogue is a joint activity in which participants always select a move that is in the direction of accomplishing some mutually agreed upon purpose. <p> Later in this chapter, we describe another type of relation which may exist between segments: rhetorical relations. Intention-based segmentation recognizes three related analysis structures <ref> [38] </ref>. The first one is the linguistic structure which corresponds to acoustic and lexical features of individual sentences and phrases. These features include intonation contours and discourse cue words which are correlated with segment transitions [82, 46, 45, 100]. <p> At Harvard University, Nb has been used to annotate the discourse of direction giving monologues, by examining text transcriptions as well as listening to the corresponding speech signals. This coding scheme was rooted in the intentional theory of discourse structure proposed by Grosz and Sidner <ref> [38, 71, 45] </ref>. <p> The acknowledgment should be part of the preceding segment, while the signal serves as an opening for the next segment. 74 Task-Subtask Structure The segment boundaries produced by the majority lists were located before changes in the task structure of the dialogue, as predicted by discourse structure theory <ref> [38, 39] </ref>. For example, the majority segmentation of the flight information dialogue displayed in Figure 4-2 is consistent with the following task-subtask structure: 1. <p> The constrained annotation task greatly reduced the cognitive load for the coders. The patterns of agreement among coders indicate that it is possible to reliably annotate discourse segments that are defined by their intentional purpose <ref> [38] </ref>. In addition, the internal structure of each annotated segment is consistent with the theory of cooperative discourse contributions [22]. <p> It is possible that a different set of labels for subsegments and more extensive instructions might yield different results. For example, Grosz and Sidner <ref> [38, 39] </ref> and Clark [21] among others, point out that subsegments tend to play a specific role in the task structure. Typically, a subsegment might represent either a sub-task or a digression.
Reference: [39] <author> B. Grosz and C. Sidner. </author> <title> Plans for discourse. In Intentions In Communication, </title> <address> Cambridge, MA, 1990. </address> <publisher> MIT Press. </publisher>
Reference-contexts: In particular, some models assume that human-to-human task-oriented dialogue can be modeled as a sequence of related discourse segments. Discourse segments may be initiated by any participant in the conversation with the purpose either of finding a mutually satisfactory solution to a task <ref> [39, 37, 57, 58] </ref> or of repairing and preventing misunderstanding [21, 22, 23]. An example of a discourse segmentation is displayed in Figure 1-1. Segments are sequences of one or more related communicative acts which accomplish a specific purpose (or goal) in common between the conversation participants. <p> The data annotated with Nb have provided substantial empirical evidence about the discourse segment structure of natural dialogue and the internal organization of segments. The annotated data provide substantial support for the theories of intentional structure of discourse <ref> [39, 37, 57, 58] </ref> and of contributions to discourse [21, 22, 23] which view dialogue as a co-operative or joint activity driven by the speakers' intentions. The annotated data have also provided the basis for evaluating empirically which computational device is appropriate to process natural dialogues. <p> In this thesis, we focus on task-oriented spoken dialogue because it is a genre applicable to building spoken language systems. In this case, discourse analysis is mostly focused on determining relations between sentences spoken by different speakers across dialogue turns. In particular, we focus on intentional relations (e.g., <ref> [1, 38, 39, 92, 93] </ref>). For example, in this framework the first sentence of the above dialogue exchange 27 (I'm trying to find out where the Lion King is located) is not interpreted solely as a declarative, but rather as a communicative act: a request for some specific information. <p> For example, the dialogue exchange listed at the beginning of the chapter may be labeled with a segment purpose entitled: Find theaters playing the movie The Lion King. 2.1.1 Discourse Segment Structure The theories of intentional structure of discourse and shared plans <ref> [38, 39] </ref>, dialogue games and transactions [17, 16] and contributions to discourse [21, 22] assume that task-oriented dialogue is a joint activity in which participants always select a move that is in the direction of accomplishing some mutually agreed upon purpose. <p> The third one is the intentional structure, which lists the relations among the purposes being accomplished by the sequences of dialogue turns called discourse segments. This three-layered model has provided the seed for the model of dialogue as shared planning activity <ref> [39, 37, 57, 58] </ref>. 30 semantic entities that need to be communicated between the conversation participants. Edges are directed from purposes to dependent entities. For simple information retrieval domains it is possible to quickly develop a list of specific purposes, at least from the agent's perspective. <p> The acknowledgment should be part of the preceding segment, while the signal serves as an opening for the next segment. 74 Task-Subtask Structure The segment boundaries produced by the majority lists were located before changes in the task structure of the dialogue, as predicted by discourse structure theory <ref> [38, 39] </ref>. For example, the majority segmentation of the flight information dialogue displayed in Figure 4-2 is consistent with the following task-subtask structure: 1. <p> It is possible that a different set of labels for subsegments and more extensive instructions might yield different results. For example, Grosz and Sidner <ref> [38, 39] </ref> and Clark [21] among others, point out that subsegments tend to play a specific role in the task structure. Typically, a subsegment might represent either a sub-task or a digression. <p> In the second segment, the request is absent, because the agent volunteers some information that was not explicitly requested by the customer. This coding scheme combines the theory of intentional discourse structure (i.e., top-level segment purposes) <ref> [39] </ref> with the theory of discourse contributions [22] (i.e., requests, responses, presentations and acceptances). It is also related to the Map Task coding scheme [16], in which top-level segments correspond to Transactions, and nested contributions corresponding to Games. However, we have made one important simplification. <p> Unlike communicative act labels, purpose labels do not encode the individual intentions of the speakers. Instead, we consider the purposes as being joint projects, or shared plans, between the customer and the agent <ref> [39, 21, 22, 37, 57, 58] </ref>. Each segment is a sequence of agent and customer actions that co-operate to accomplish the purpose. This type of linear segmentation is the one that produced the highest inter-coder agreement in the experiments presented in Chapter 4. <p> This type of reasoning goes beyond a probabilistic finite state model. involved in specifying the initial request I'm looking for the Buford Cinema. The four reasoning steps are the internal nodes of the tree and correspond to knowledge pre-conditions in the intentional theory of discourse <ref> [39, 37, 57, 58] </ref>. The steps are partially ordered. Recognizing the customer's words is a pre-condition to recognizing her intentions and topics. On the other hand, topics and intentions can be recognized independently of each other. <p> Second, we define the extended stack model. Third, we report a preliminary empirical evaluation of the model against the annotated data. 5.4.1 Data: Six Types of Segment Transitions corpus of movie schedule dialogues. This taxonomy combines the types considered in the intentional theory of discourse <ref> [39, 58] </ref> with the ones considered in the theories of discourse contributions [21, 22] and of turn-taking in conversations [85, 48]. A preliminary segment (or pre-sequence) has a generic purpose which is the introduction to a more specific, task-oriented purpose. <p> Sub- tasks and digressions are processed by push and pop. Multiple active purposes are processed by swap, and fresh starts and repairs by replace. A more formal treatment of an underlying computational model migth based on the foundations set forth by <ref> [39] </ref> and [21]. <p> A finite language model such as a trigram may be useful in predicting the customer's next action from the few preceding actions, but it seems inappropriate in helping to predict the agent's behavior. One alternative to finite state models is the co-operative plan-based approach (see <ref> [39, 37, 57, 58, 24, 86, 87] </ref>, among others). In this approach, the dialogue state and sentence meaning are represented by a set of logical predicates. Communicative acts are operators which have predicate pre-conditions 124 and side effects they may add or delete predicates to the dialogue state. <p> Collectively, the findings presented in this chapter provide substantial empirical evidence for theories of dialogue as a joint activity in which discourse segments are initiated by either speaker with the purpose of either finding a solution to the task at hand <ref> [39] </ref> or repairing and preventing misunderstandings [22]. In addition, the statistics reported here are consistent with at least two other empirical studies conducted on a similar corpus of British-English telephone conversations, the London-Lund corpus [99] analyzed by Orestrom [78] and by Clark and Schaefer [22]. <p> Rather than postulating a theory first, and then seeking evidence to support it, we first let many coders annotate text transcriptions with limited instructions. We were then able to correlate the segmentations proposed by a majority of coders with theories that model conversation as a highly structured collaborative process <ref> [21, 39] </ref>. 6.1.1 Discourse Segmentation from Text Can Be Performed Reliably For a long time, the reliability of discourse segmentation of text has been a controversial issue.
Reference: [40] <author> B. Hansen, D. Novick, and S. Sutton. </author> <title> Systematic design of spoken prompts. </title> <booktitle> In Proceedings of CHI'96: Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 157-164, </pages> <address> Vancouver, BC, </address> <year> 1996. </year>
Reference-contexts: While a machine may apply the same principles of co-operative behavior as a human agent, many dialogue system designers argue that it may more appropriate to employ more explicit prompts and feedback responses <ref> [7, 40, 110, 12, 30] </ref>.
Reference: [41] <author> M. Hearst. TextTiling: </author> <title> Segmenting text into multi-paragraph subtopic passages. </title> <journal> Computational Linguistics, </journal> <volume> 23(1) </volume> <pages> 33-64, </pages> <year> 1997. </year>
Reference-contexts: We have assessed inter-coder agreement using the metrics of precision, recall and the kappa coefficient. The reliability results are competitive with other published work on discourse segmentation <ref> [107, 41, 45, 80, 16] </ref>, and lend empirical support to the notion that discourse segmentation can be done as reliably as annotating other types of discourse units, such as communicative acts. <p> Segments can be defined as sections of the dialogue about the same topic or subtopic, independently of the speaker's intentions <ref> [13, 67, 41] </ref>. This alternative definition of segment is useful for information retrieval and indexing of text and speech, where it is desirable to extract from long documents paragraph-like sections that are about a particular topic, and it is not necessary to infer the speaker's intentions. <p> Algorithms for subtopic segmentation rely on co-occurrence of lexical items that are related to each other by co-reference relations [67], or more simply by co-occurrence relations <ref> [41] </ref>. These algorithms assume that within a segment there are many lexical terms (e.g., nouns and proper nouns) that are related to each other with co-reference relations. The density of these related terms should be minimal across segment boundaries. <p> cues and discourse segment boundaries (e.g., [46, 36, 45]), evaluating the agreement among subjects in placing discourse boundaries in transcriptions of monologues [72], and evaluating human and algorithmic performance in annotating 46 Annotation Task Citation % Agree Recall Precision Kappa Discourse Segments Subtopic Segmentation of written science articles Hearst 97 <ref> [41] </ref> 81.6 71.4 0.67 Discourse Segmentation Hirschberg and of spoken directions from text Nakatani 96 [45] 0.63 Discourse Segmentation Hirschberg and of directions from text and speech Nakatani 96 0.80 Discourse Segmentation Passonneau and of spoken stories Litman 97 [80] 63.3 70.6 Map Task Move Boundaries Carletta et al. 97 [16] <p> In contrast, two communicative act coding schemes report reliability levels of better than 0.80 for annotating the Map Task and the Switchboard corpora [16, 51]. Three out of four published segmentation schemes, applied to monologues and science articles, report lower reliability scores, between 0.59 and 0.67 <ref> [45, 16, 41] </ref>. The best reliability score (0.80) has been obtained by three expert coders annotating spoken monologues using intentional discourse structure theory, by looking at the text transcription as well as listening to the corresponding speech signal [45].
Reference: [42] <author> P.A. Heeman. </author> <title> Spoken dialogue understanding and local context. </title> <type> Technical report 523, </type> <institution> University of Rochester, Computer Science department, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: Some of the topics studied by empirical work in discourse analysis include defining and evaluating the consistency of coding schemes for speech act tags (e.g., [14, 27]), frequency analysis and models for speech repairs, grounding contributions and other spontaneous speech phenomena such as repairs (e.g., <ref> [103, 42] </ref>), correlation analysis between prosodic cues and discourse segment boundaries (e.g., [46, 36, 45]), evaluating the agreement among subjects in placing discourse boundaries in transcriptions of monologues [72], and evaluating human and algorithmic performance in annotating 46 Annotation Task Citation % Agree Recall Precision Kappa Discourse Segments Subtopic Segmentation of
Reference: [43] <author> L. Hirschman et al. </author> <title> Multi-site data collection and evaluation in spoken language understanding. </title> <editor> In Bates M., editor, </editor> <booktitle> Proc. Human Language Technology Workshop, </booktitle> <pages> pages 19-24, </pages> <address> Princeton, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: 48 Chapter 3 Efficient Discourse Annotation with Nb Annotated corpora can help researchers understand the regularity and variability of linguistic phenomena under investigation, propose computational models to mimic their behavior, estimate the parameters of the models, and evaluate the effectiveness of either the models or systems that embed these models <ref> [43] </ref>. When a corpus is annotated by more than one trained coder, assessing where coders disagree is crucial for understanding the difficulty or linguistic ambiguity of the task.
Reference: [44] <author> L. Hirschman et al. </author> <title> Automating coreference: The role of annotated training data. </title> <booktitle> In AAAI Spring Symposium on Applying Machine Learning to Discourse Processing, </booktitle> <address> Menlo Park, CA, </address> <year> 1998. </year> <journal> American Association of Artificial Intelligence. </journal>
Reference-contexts: The annotation units and the conventions form what is called a coding scheme. For example, at the syntactic level, pronouns might be annotated along with the definite noun phrases they refer to <ref> [19, 44] </ref> and at the intentional level, sentences might be annotated with the speaker intentions (e.g. whether the sentence is a request for information, an acknowledgment) [92, 93, 1]. <p> Corpus-based analyses of co-reference try to establish the semantic relations that exist between definite noun phrases and pronouns <ref> [19, 44] </ref>. Resolving co-reference is an important function of the understanding component of a spoken dialogue system. This function is non trivial. For example, a resolution algorithm should be able to detect that in line 5, the pronoun they (in they're supposed to...) does not have an antecedent. <p> The tool has been designed to work with one particular coding manual, the DAMSL coding manual [15, 28]. A team of five natural language researchers at MITRE is developing a generic annotation tool called the Alembic Workbench <ref> [44] </ref>. The goal of the Alembic Workbench is to provide graphical authoring tools to annotate textual data with fully customizable tag sets, machine learning tools to bootstrap the annotation process, and evaluation tools to analyze annotated data using measures such as precision and recall. <p> [51] 84 0.80 Map Task Move Speech Acts Carletta et al. 97 0.83 Rhetorical Relations Selection of prominent sentences in written science articles Marcu 97 [63] 71 55.5 66.6 Co-referent Words and Phrases Pronouns and noun phrases Hirschman 80 - 90 85 - 90 in newswire text et al 98 <ref> [44] </ref> Aligning content words in 90 - 92 English-to-French translations Melamed [66] Table 2.1: Some representative studies in inter-coder agreement in annotating units in text and speech. co-referent noun phrases in newswire text [19, 44]. <p> Pronouns and noun phrases Hirschman 80 - 90 85 - 90 in newswire text et al 98 [44] Aligning content words in 90 - 92 English-to-French translations Melamed [66] Table 2.1: Some representative studies in inter-coder agreement in annotating units in text and speech. co-referent noun phrases in newswire text <ref> [19, 44] </ref>. Table 2.1 illustrates the state of the art in evaluating text analysis units by listing some repre <p>- sentative inter-coder agreement studies that have been published in the last few years. The list is not exhaustive. <p> For example, the highest value of precision and recall in annotating co-referent phrases has been obtained in a pilot experiment by two expert coders annotating three texts <ref> [44] </ref>, and the highest agreement for segmental units has been obtained for segmenting individual dialogue turns into one or more communicative acts (i.e., dialogue moves, or conversational clauses). <p> In the area of text processing, text corpora annotated with co-referent nouns and noun phrases have been instrumental in monitoring the progress in automatic information extraction algorithms developed for the series of Message Understanding Conferences (MUC) <ref> [19, 44] </ref>. Once a corpus is made available for research, a good set of annotation tools can greatly facilitate the annotation process, both in throughput, accuracy, and consistency, thereby leading to useful data that can serve the needs of the research community.
Reference: [45] <author> J. Hirshberg and C.H. Nakatani. </author> <title> A prosodic analysis of discourse segments in directiongiving monologues. </title> <booktitle> In Proceedings of the Annual Meeting of the Association for Computational Linguistics, </booktitle> <year> 1996. </year>
Reference-contexts: We have assessed inter-coder agreement using the metrics of precision, recall and the kappa coefficient. The reliability results are competitive with other published work on discourse segmentation <ref> [107, 41, 45, 80, 16] </ref>, and lend empirical support to the notion that discourse segmentation can be done as reliably as annotating other types of discourse units, such as communicative acts. <p> Intention-based segmentation recognizes three related analysis structures [38]. The first one is the linguistic structure which corresponds to acoustic and lexical features of individual sentences and phrases. These features include intonation contours and discourse cue words which are correlated with segment transitions <ref> [82, 46, 45, 100] </ref>. The second one is the attentional structure, or focus of attention, which is a data structure that records the salient semantic entities that the dialogue participants can refer to in the dialogue (e.g., movie titles, theater locations, show times). <p> To date, at least four task-oriented human-to-human dialogue corpora and one large corpus of casual conversations have been used for empirical studies in British and American English. In addition, at least one corpus of spoken monologues has been used to conduct discourse segmentation studies (i.e., the Boston Direction Corpus <ref> [45] </ref>). The London-Lund corpus has been a pioneering effort in collecting and transcribing spontaneous speech, including some task-oriented telephone conversations [99]. The corpus contains 500,000 words of spoken British English recorded from 1953 to 1987. It consists of 100 text samples. <p> Some researchers suggest first to evaluate where coders agree in placing segment initiatives, and then to evaluate if they also agree on segment closings for the segments in which they agree on the initiatives <ref> [45, 80] </ref>. One important feature of the kappa coefficient is that it can be extended to experimental conditions with multiple coders, more than two annotated categories and missing annotated data. In such cases it becomes the group-wise kappa coefficient. <p> work in discourse analysis include defining and evaluating the consistency of coding schemes for speech act tags (e.g., [14, 27]), frequency analysis and models for speech repairs, grounding contributions and other spontaneous speech phenomena such as repairs (e.g., [103, 42]), correlation analysis between prosodic cues and discourse segment boundaries (e.g., <ref> [46, 36, 45] </ref>), evaluating the agreement among subjects in placing discourse boundaries in transcriptions of monologues [72], and evaluating human and algorithmic performance in annotating 46 Annotation Task Citation % Agree Recall Precision Kappa Discourse Segments Subtopic Segmentation of written science articles Hearst 97 [41] 81.6 71.4 0.67 Discourse Segmentation Hirschberg <p> placing discourse boundaries in transcriptions of monologues [72], and evaluating human and algorithmic performance in annotating 46 Annotation Task Citation % Agree Recall Precision Kappa Discourse Segments Subtopic Segmentation of written science articles Hearst 97 [41] 81.6 71.4 0.67 Discourse Segmentation Hirschberg and of spoken directions from text Nakatani 96 <ref> [45] </ref> 0.63 Discourse Segmentation Hirschberg and of directions from text and speech Nakatani 96 0.80 Discourse Segmentation Passonneau and of spoken stories Litman 97 [80] 63.3 70.6 Map Task Move Boundaries Carletta et al. 97 [16] 89.0 0.92 Map Task Transaction Segments Carletta at al. 97 0.59 Communicative Acts DAMSL Forward <p> At Harvard University, Nb has been used to annotate the discourse of direction giving monologues, by examining text transcriptions as well as listening to the corresponding speech signals. This coding scheme was rooted in the intentional theory of discourse structure proposed by Grosz and Sidner <ref> [38, 71, 45] </ref>. <p> At Harvard, Nb has been used for discourse segmentation using text and acoustic cues from written instructions, with very encouraging reliability results <ref> [71, 45] </ref>. When users were able to listen to the corresponding speech signal as well as browse the corresponding text, the kappa coefficient was found to be 0.83. <p> In contrast, two communicative act coding schemes report reliability levels of better than 0.80 for annotating the Map Task and the Switchboard corpora [16, 51]. Three out of four published segmentation schemes, applied to monologues and science articles, report lower reliability scores, between 0.59 and 0.67 <ref> [45, 16, 41] </ref>. The best reliability score (0.80) has been obtained by three expert coders annotating spoken monologues using intentional discourse structure theory, by looking at the text transcription as well as listening to the corresponding speech signal [45]. <p> The best reliability score (0.80) has been obtained by three expert coders annotating spoken monologues using intentional discourse structure theory, by looking at the text transcription as well as listening to the corresponding speech signal <ref> [45] </ref>. Second, we want to provide concrete examples of where coders disagree and where they agree in placing segment boundaries. <p> For example, Hirshberg and Nakatani report an increase of the kappa coefficient from 0.67 to 0.80 when trained coders were able to listen to the speech signal as well as read the transcription <ref> [45] </ref>. All of the annotations reported in this thesis are based on text alone. We leave the issue of segmenting dialogues from a combination of text and speech to future work. <p> Hirshberg and Nakatani report very reliable results in annotating segments by listening to the speech signal as well as reading the text transcription <ref> [45] </ref>. The EVAR system, described in [52], illustrates how prosodic cues have been 131 successfully integrated into a spoken dialogue system precisely to interpret the speaker's intentions. For example, consider the following dialogue exchange, extracted from Chapter 5: A: Seven six two, nine six three six.
Reference: [46] <author> J. Hirshberg, C.H. Nakatani, and B. Grosz. </author> <title> Conveying discourse structure through intonation variation. </title> <booktitle> In Proc. ESCA Workshop on Spoken Dialogues Systems, </booktitle> <pages> pages 189-192, </pages> <address> Vigso, Denmark, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Intention-based segmentation recognizes three related analysis structures [38]. The first one is the linguistic structure which corresponds to acoustic and lexical features of individual sentences and phrases. These features include intonation contours and discourse cue words which are correlated with segment transitions <ref> [82, 46, 45, 100] </ref>. The second one is the attentional structure, or focus of attention, which is a data structure that records the salient semantic entities that the dialogue participants can refer to in the dialogue (e.g., movie titles, theater locations, show times). <p> In particular, in a long text, most of the clauses will be classified as non boundary by both coders. Recent empirical work on discourse coding has overcome the text size sensitivity problem by either reporting the agreement on the most critical categories (i.e., Segment Boundary) <ref> [46] </ref> or by reporting the kappa coefficient, , a measure of agreement that is used in experimental psychology [53, 6, 14]. This measure corrects the observed agreement by subtracting the estimated chance agreement P c one expects a priori from the marginal distributions of the coded categories. <p> work in discourse analysis include defining and evaluating the consistency of coding schemes for speech act tags (e.g., [14, 27]), frequency analysis and models for speech repairs, grounding contributions and other spontaneous speech phenomena such as repairs (e.g., [103, 42]), correlation analysis between prosodic cues and discourse segment boundaries (e.g., <ref> [46, 36, 45] </ref>), evaluating the agreement among subjects in placing discourse boundaries in transcriptions of monologues [72], and evaluating human and algorithmic performance in annotating 46 Annotation Task Citation % Agree Recall Precision Kappa Discourse Segments Subtopic Segmentation of written science articles Hearst 97 [41] 81.6 71.4 0.67 Discourse Segmentation Hirschberg <p> Speech corpora annotated with the ToBI prosodic labels have been crucial in fostering progress in modeling suprasegmental acoustic features [96] and in the study of the correlation between prosody and discourse segment structure <ref> [46, 100] </ref>. In the area of text processing, text corpora annotated with co-referent nouns and noun phrases have been instrumental in monitoring the progress in automatic information extraction algorithms developed for the series of Message Understanding Conferences (MUC) [19, 44]. <p> Finally, discourse segment structure is correlated with specific acoustic and prosodic cues such as changes in pause duration, speech signal amplitude and pitch contour <ref> [82, 36, 46, 52] </ref>. For example, Hirshberg and Nakatani report an increase of the kappa coefficient from 0.67 to 0.80 when trained coders were able to listen to the speech signal as well as read the transcription [45]. <p> However, speakers convey changes in their intentional and attentional state using a combination of lexical, acoustic and prosodic cues such as discourse cue words, pause duration, speech signal amplitude and pitch contour <ref> [82, 46, 100, 36, 72, 52] </ref>. Hirshberg and Nakatani report very reliable results in annotating segments by listening to the speech signal as well as reading the text transcription [45].
Reference: [47] <author> G. Hirst et al. </author> <title> Repairing conversational misunderstandings and non-understandings. Speech Communication, </title> <address> 15(3-4):213-229, </address> <year> 1994. </year>
Reference-contexts: Repairs Repairs can be self-repairs, involving only one speaker and one dialogue turn, or they may involve both participants for a few dialogue turns. They are also local discourse phenomena: as soon as the speaker or hearer detects an error in the speech stream, she tries to repair it <ref> [90, 56, 47, 89, 73, 20] </ref>. The instructions specified that in case of speech repairs, segment boundaries should be placed before complete clauses that could be fully understood as switches in segment purposes. However, some spontaneous repairs could not be handled consistently by this rule.
Reference: [48] <author> R. Hopper. </author> <title> Telephone Conversations. </title> <publisher> Indiana University Press, </publisher> <address> Bloomington, IN, </address> <year> 1992. </year>
Reference-contexts: get all the different theaters? 5 A: I can give you that information 6 C: You can? 7 C: Okay, in Snellville, Septum movies The variability in determining the exact location of the start of the task-related conversation can be explained by what some researchers have called preliminaries, or pre-sequences <ref> [91, 85, 21, 48] </ref>. Pre-sequences are discourse transitions that are used by conversation participants to set a general common ground before committing to a more specific task. Transitional pre-closing statements also posed some problems in locating the end of the task-oriented part of the conversation. <p> Psycho-linguists have argued that these opportunities for switches in speaker tend to occur at specific syntactic, semantic and intentional boundaries, (e.g., just after reporting an item in a list) and may be indicated by the agent with acoustic correlates such as pauses and raising intonation contours <ref> [85, 48] </ref>. The examples also illustrate the fact that such turn-switching opportunities exist even while the agent is speaking, whether or not she indicates them to the customer. <p> This taxonomy combines the types considered in the intentional theory of discourse [39, 58] with the ones considered in the theories of discourse contributions [21, 22] and of turn-taking in conversations <ref> [85, 48] </ref>. A preliminary segment (or pre-sequence) has a generic purpose which is the introduction to a more specific, task-oriented purpose. A preliminary purpose is a pre-condition to the purpose that follows it. In the movie schedule domain, a new task corresponds 118 A.
Reference: [49] <author> E.H. Hovy. </author> <title> Automated discourse generation using discourse structure relations. </title> <journal> Artificial Intelligence, </journal> <volume> 63 </volume> <pages> 341-385, </pages> <year> 1992. </year> <month> 147 </month>
Reference-contexts: For example, a discourse segment or subsegment may start with specific dialogue acts such as requests for information, requests for clarification and other direct questions. 2.1.4 Rhetorical Relations The fourth type of discourse unit is rhetorical relations that exist between pairs of clauses, or pairs of speech acts <ref> [60, 49, 62, 61, 69] </ref>. Rhetorical relationship theories are motivated by the observation that clauses in text and speech do not occur in isolation. Instead, there is a small set of relationships that can be established between pairs of units (e.g., elaboration, background, motivation). our example dialogue. <p> Rhetorical parsing of text has been used to provide summaries of texts with very encouraging results [63, 62, 61], or to automatically generate coherent explanatory texts <ref> [49] </ref>. One important contribution of [63] is the development and empirical evaluation of a full-blown discourse-level parser based on the principles of rhetorical relations. Discourse segments are complementary to rhetorical relations [69]. <p> As a consequence, spoken dialogue systems must incorporate computational models that specify how to break textual information into multiple short discourse contributions. While computational models of speech generation in dialogue systems can be inspired by text planning and generation algorithms <ref> [49, 62, 61] </ref>, the analysis of human-to- human dialogues is instrumental in determining the size and type of discourse contributions that are appropriate in the context of interactive spoken communication. 6.2.2 Intonational Contours and Discourse Cues Perhaps the biggest limitation of this thesis has been that discourse annotation has been performed
Reference: [50] <author> S. Jekat et al. </author> <title> Dialogue acts in VERBMOBIL. </title> <type> Technical Report 65, </type> <institution> BMBF Verbmobil, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: The goal is for the route follower to draw the route from the instructions of the route giver. Verbmobil is a bi-lingual corpus, with some portions in American-English and some in German. The American- English only portion of the Verbmobil corpus was collected at Carnegie Mellon University <ref> [50] </ref>. The data include 313 dialogues in an appointment scheduling task. Finally, the Switchboard corpus is a collection of 2400 casual telephone conversations between speakers from all areas of the United States [51]. <p> The first coding scheme was the segmentation scheme mentioned above, proposed by Nakatani et al. from Harvard University. The second coding scheme was the Verbmobil set of 12 speech acts, or dialogue moves appropriate for describing meeting scheduling dialogues <ref> [50] </ref>. The dialogue moves were organized in a hierarchy. At the top level, there were abstract dialogue moves appropriate for negotiating dialogues, which are listed in Table 3.1. Each one of the domain-independent moves were further specified with domain dependent values. <p> They have also been used to provide a predictive dialogue model for human-to-human spoken interaction within a speech translation system <ref> [50] </ref>. One important feature of finite state machines and context free grammars is that state transitions can be weighted by probabilities. It is therefore possible to estimate numerically the most likely next dialogue state given the current state, using relatively simple computational techniques such 99 as dynamic programming.
Reference: [51] <author> D. Jurafsky et al. </author> <title> Automatic detection of discourse structure for speech recognition and understanding. </title> <booktitle> In IEEE Workshop on Speech Recognition and Understanding. IEEE, </booktitle> <year> 1997. </year>
Reference-contexts: The American- English only portion of the Verbmobil corpus was collected at Carnegie Mellon University [50]. The data include 313 dialogues in an appointment scheduling task. Finally, the Switchboard corpus is a collection of 2400 casual telephone conversations between speakers from all areas of the United States <ref> [51] </ref>. At the start of each conversation, speakers were prompted to talk casually about one of 70 different everyday topics (e.g., how to buy a car). <p> A dialogue turn can be tagged with multiple labels, one per independent dimension. Corpus specific tags can be specified as subclasses of the abstract tags. The DAMSL tag set has been adapted to tag the Switchboard corpus using a set of 42 mutually exclusive speech act tags <ref> [51] </ref>. The papers by Mann and Thompson [60], by Moser, Moore and Glendening [69] and Marcu's doctoral thesis [62, 61] list a set of rhetorical relations that can be used for rhetorical parsing of text. <p> Segments Carletta at al. 97 0.59 Communicative Acts DAMSL Forward looking Core and Speech Act labels Allen 97 [28] 82 - 93 0.15 - 0.70 DAMSL Backward looking Core and Function labels Allen 97 78 - 95 0.57 - 0.77 DAMSL Forward Acts Jurafsky adapted to Switchboard at al. 97 <ref> [51] </ref> 84 0.80 Map Task Move Speech Acts Carletta et al. 97 0.83 Rhetorical Relations Selection of prominent sentences in written science articles Marcu 97 [63] 71 55.5 66.6 Co-referent Words and Phrases Pronouns and noun phrases Hirschman 80 - 90 85 - 90 in newswire text et al 98 [44] <p> Only one coding scheme has reported a reliability score (0.59) for segmenting the Map Task dialogues [16]. In contrast, two communicative act coding schemes report reliability levels of better than 0.80 for annotating the Map Task and the Switchboard corpora <ref> [16, 51] </ref>. Three out of four published segmentation schemes, applied to monologues and science articles, report lower reliability scores, between 0.59 and 0.67 [45, 16, 41]. <p> They have been used to model natural language interactions in Wizard-of-Oz studies, in which users talked to a system simulated by an engineer, before the system is fully developed [98, 29], and sequences of communicative acts in spontaneous telephone conversations of the Switchboard corpus <ref> [51] </ref>. They have also been used to provide a predictive dialogue model for human-to-human spoken interaction within a speech translation system [50]. One important feature of finite state machines and context free grammars is that state transitions can be weighted by probabilities. <p> This measure is used frequently to evaluate the predictive power of structural dialogue models for human-to-computer spoken language systems (e.g., <ref> [70, 51] </ref>). Perplexity is an empirical measure which estimates the average number of likely communicative acts at a particular point in time, given one or two preceding communicative acts. We distinguish between training set perplexity, test set perplexity and Markov model perplexity.
Reference: [52] <author> R. Kompe. </author> <title> Prosody in Speech Understanding Systems. Springer-Verlag: </title> <booktitle> Lecture Notes in Artificial Intelligence, </booktitle> <address> Berlin, </address> <year> 1997. </year>
Reference-contexts: Finally, discourse segment structure is correlated with specific acoustic and prosodic cues such as changes in pause duration, speech signal amplitude and pitch contour <ref> [82, 36, 46, 52] </ref>. For example, Hirshberg and Nakatani report an increase of the kappa coefficient from 0.67 to 0.80 when trained coders were able to listen to the speech signal as well as read the transcription [45]. <p> However, speakers convey changes in their intentional and attentional state using a combination of lexical, acoustic and prosodic cues such as discourse cue words, pause duration, speech signal amplitude and pitch contour <ref> [82, 46, 100, 36, 72, 52] </ref>. Hirshberg and Nakatani report very reliable results in annotating segments by listening to the speech signal as well as reading the text transcription [45]. <p> Hirshberg and Nakatani report very reliable results in annotating segments by listening to the speech signal as well as reading the text transcription [45]. The EVAR system, described in <ref> [52] </ref>, illustrates how prosodic cues have been 131 successfully integrated into a spoken dialogue system precisely to interpret the speaker's intentions. For example, consider the following dialogue exchange, extracted from Chapter 5: A: Seven six two, nine six three six.
Reference: [53] <author> K. Krippendorff. </author> <title> Content Analysis: An introduction to its methodology. </title> <publisher> Sage Publications, </publisher> <year> 1980. </year>
Reference-contexts: In this section, we review how to compute four metrics for measuring inter-coder agreement: precision, recall, percent agreement and the kappa coefficient. A discussion of evaluation metrics can also be found in <ref> [53, 6, 104, 14] </ref>. 2.3.1 Precision and Recall When comparing two different annotations of the same text, we may select one as the reference and the other one as the test. <p> Recent empirical work on discourse coding has overcome the text size sensitivity problem by either reporting the agreement on the most critical categories (i.e., Segment Boundary) [46] or by reporting the kappa coefficient, , a measure of agreement that is used in experimental psychology <ref> [53, 6, 14] </ref>. This measure corrects the observed agreement by subtracting the estimated chance agreement P c one expects a priori from the marginal distributions of the coded categories.
Reference: [54] <author> L. Lamel, R. Kassel, and S. Seneff. </author> <title> Speech database development: design and analysis of the acoustic-phonetic corpus. </title> <booktitle> In Proc. DARPA Speech Recognition Workshop, </booktitle> <pages> pages 100-109. </pages> <note> Report No. SAIC-86/1546, </note> <month> February </month> <year> 1986. </year>
Reference-contexts: One crucial issue of discourse annotation is whether or not it can be performed reliably by trained coders who do not necessarily have extensive prior knowledge of the discourse theories. Whereas the reliability of annotating phonological, syntactic and intonation units in sentences has been extensively studied <ref> [54, 64, 96] </ref>, a discussion of the issues in annotating discourse units in dialogue has only begun to emerge in last three years [107, 16, 28]. <p> When a corpus is annotated by more than one trained coder, assessing where coders disagree is crucial for understanding the difficulty or linguistic ambiguity of the task. To develop phonetic recognition algorithms, for example, researchers in the US have relied on the timit corpus <ref> [54] </ref> to understand the acoustic realizations of phonemes under varying phonetic environments and to develop phonetic models to capture such contextual variations [55].
Reference: [55] <author> K.F. Lee and H.W. Hon. </author> <title> Speaker-independent phone recognition using hidden Markov models. </title> <journal> IEEE Trans. ASSP, </journal> <volume> 37(11) </volume> <pages> 1641-1648, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: Annotation of some linguistic phenomena such as phonetic variants and disfluencies are relatively straightforward, since agreement on the choices of units and conventions can often be reached <ref> [55, 96] </ref>. As a result, the task of annotation can often be shared across site, and the aggregate corpora are larger and more useful to a wider community. As we move up the linguistic chain, however, the 19 picture can rapidly deteriorate. <p> To develop phonetic recognition algorithms, for example, researchers in the US have relied on the timit corpus [54] to understand the acoustic realizations of phonemes under varying phonetic environments and to develop phonetic models to capture such contextual variations <ref> [55] </ref>. Speech corpora annotated with the ToBI prosodic labels have been crucial in fostering progress in modeling suprasegmental acoustic features [96] and in the study of the correlation between prosody and discourse segment structure [46, 100].
Reference: [56] <author> W.J.M. Levelt. </author> <title> Monitoring and self-repairs in speech. </title> <journal> Cognition, </journal> <volume> 14 </volume> <pages> 41-104, </pages> <year> 1983. </year>
Reference-contexts: Repairs Repairs can be self-repairs, involving only one speaker and one dialogue turn, or they may involve both participants for a few dialogue turns. They are also local discourse phenomena: as soon as the speaker or hearer detects an error in the speech stream, she tries to repair it <ref> [90, 56, 47, 89, 73, 20] </ref>. The instructions specified that in case of speech repairs, segment boundaries should be placed before complete clauses that could be fully understood as switches in segment purposes. However, some spontaneous repairs could not be handled consistently by this rule. <p> In a fresh start, the first two partial questions and their intention are abandoned to be replaced by the last one. Researchers have pointed out that one effective repair strategy is using the same syntax (i.e. what time) to signal to the listener exactly what she is replacing <ref> [56, 20] </ref>. Some coders placed a segment boundary at the first or second question, while others placed it at the complete question What time is The Client playing?. <p> This constraint is motivated by previous empirical studies in speech repairs which indicated that repairs occur sooner rather than later <ref> [90, 56, 89, 20] </ref>. In particular, this constraint is consistent with Clark's principle of repair [21]: 130 When agents detect a problem serious enough to warrant a repair, they try to initiate and repair the problem at the first opportunity after detecting it.
Reference: [57] <author> K. Lochbaum. </author> <title> Using collaborative plans to model the intentional structure of discourse. </title> <type> Phd thesis, </type> <institution> Harvard University, </institution> <year> 1994. </year>
Reference-contexts: In particular, some models assume that human-to-human task-oriented dialogue can be modeled as a sequence of related discourse segments. Discourse segments may be initiated by any participant in the conversation with the purpose either of finding a mutually satisfactory solution to a task <ref> [39, 37, 57, 58] </ref> or of repairing and preventing misunderstanding [21, 22, 23]. An example of a discourse segmentation is displayed in Figure 1-1. Segments are sequences of one or more related communicative acts which accomplish a specific purpose (or goal) in common between the conversation participants. <p> The data annotated with Nb have provided substantial empirical evidence about the discourse segment structure of natural dialogue and the internal organization of segments. The annotated data provide substantial support for the theories of intentional structure of discourse <ref> [39, 37, 57, 58] </ref> and of contributions to discourse [21, 22, 23] which view dialogue as a co-operative or joint activity driven by the speakers' intentions. The annotated data have also provided the basis for evaluating empirically which computational device is appropriate to process natural dialogues. <p> The third one is the intentional structure, which lists the relations among the purposes being accomplished by the sequences of dialogue turns called discourse segments. This three-layered model has provided the seed for the model of dialogue as shared planning activity <ref> [39, 37, 57, 58] </ref>. 30 semantic entities that need to be communicated between the conversation participants. Edges are directed from purposes to dependent entities. For simple information retrieval domains it is possible to quickly develop a list of specific purposes, at least from the agent's perspective. <p> Unlike communicative act labels, purpose labels do not encode the individual intentions of the speakers. Instead, we consider the purposes as being joint projects, or shared plans, between the customer and the agent <ref> [39, 21, 22, 37, 57, 58] </ref>. Each segment is a sequence of agent and customer actions that co-operate to accomplish the purpose. This type of linear segmentation is the one that produced the highest inter-coder agreement in the experiments presented in Chapter 4. <p> This type of reasoning goes beyond a probabilistic finite state model. involved in specifying the initial request I'm looking for the Buford Cinema. The four reasoning steps are the internal nodes of the tree and correspond to knowledge pre-conditions in the intentional theory of discourse <ref> [39, 37, 57, 58] </ref>. The steps are partially ordered. Recognizing the customer's words is a pre-condition to recognizing her intentions and topics. On the other hand, topics and intentions can be recognized independently of each other. <p> A finite language model such as a trigram may be useful in predicting the customer's next action from the few preceding actions, but it seems inappropriate in helping to predict the agent's behavior. One alternative to finite state models is the co-operative plan-based approach (see <ref> [39, 37, 57, 58, 24, 86, 87] </ref>, among others). In this approach, the dialogue state and sentence meaning are represented by a set of logical predicates. Communicative acts are operators which have predicate pre-conditions 124 and side effects they may add or delete predicates to the dialogue state.
Reference: [58] <author> K. Lochbaum. </author> <title> The use of knowledge preconditions in language processing. </title> <booktitle> In Proceedings of the 1995 International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1260-1266, </pages> <address> Montreal, Canada, </address> <year> 1995. </year>
Reference-contexts: In particular, some models assume that human-to-human task-oriented dialogue can be modeled as a sequence of related discourse segments. Discourse segments may be initiated by any participant in the conversation with the purpose either of finding a mutually satisfactory solution to a task <ref> [39, 37, 57, 58] </ref> or of repairing and preventing misunderstanding [21, 22, 23]. An example of a discourse segmentation is displayed in Figure 1-1. Segments are sequences of one or more related communicative acts which accomplish a specific purpose (or goal) in common between the conversation participants. <p> The data annotated with Nb have provided substantial empirical evidence about the discourse segment structure of natural dialogue and the internal organization of segments. The annotated data provide substantial support for the theories of intentional structure of discourse <ref> [39, 37, 57, 58] </ref> and of contributions to discourse [21, 22, 23] which view dialogue as a co-operative or joint activity driven by the speakers' intentions. The annotated data have also provided the basis for evaluating empirically which computational device is appropriate to process natural dialogues. <p> The third one is the intentional structure, which lists the relations among the purposes being accomplished by the sequences of dialogue turns called discourse segments. This three-layered model has provided the seed for the model of dialogue as shared planning activity <ref> [39, 37, 57, 58] </ref>. 30 semantic entities that need to be communicated between the conversation participants. Edges are directed from purposes to dependent entities. For simple information retrieval domains it is possible to quickly develop a list of specific purposes, at least from the agent's perspective. <p> Unlike communicative act labels, purpose labels do not encode the individual intentions of the speakers. Instead, we consider the purposes as being joint projects, or shared plans, between the customer and the agent <ref> [39, 21, 22, 37, 57, 58] </ref>. Each segment is a sequence of agent and customer actions that co-operate to accomplish the purpose. This type of linear segmentation is the one that produced the highest inter-coder agreement in the experiments presented in Chapter 4. <p> This type of reasoning goes beyond a probabilistic finite state model. involved in specifying the initial request I'm looking for the Buford Cinema. The four reasoning steps are the internal nodes of the tree and correspond to knowledge pre-conditions in the intentional theory of discourse <ref> [39, 37, 57, 58] </ref>. The steps are partially ordered. Recognizing the customer's words is a pre-condition to recognizing her intentions and topics. On the other hand, topics and intentions can be recognized independently of each other. <p> Second, we define the extended stack model. Third, we report a preliminary empirical evaluation of the model against the annotated data. 5.4.1 Data: Six Types of Segment Transitions corpus of movie schedule dialogues. This taxonomy combines the types considered in the intentional theory of discourse <ref> [39, 58] </ref> with the ones considered in the theories of discourse contributions [21, 22] and of turn-taking in conversations [85, 48]. A preliminary segment (or pre-sequence) has a generic purpose which is the introduction to a more specific, task-oriented purpose. <p> A finite language model such as a trigram may be useful in predicting the customer's next action from the few preceding actions, but it seems inappropriate in helping to predict the agent's behavior. One alternative to finite state models is the co-operative plan-based approach (see <ref> [39, 37, 57, 58, 24, 86, 87] </ref>, among others). In this approach, the dialogue state and sentence meaning are represented by a set of logical predicates. Communicative acts are operators which have predicate pre-conditions 124 and side effects they may add or delete predicates to the dialogue state.
Reference: [59] <author> S. Luperfoy et al. </author> <title> Discourse resource initiative. </title> <note> URL, Georgetown University, http://www.georgetown.edu/luperfoy/Discourse-Treebank/dri-home.html, 1996. </note>
Reference-contexts: In the Map Task coding scheme, transactions and games correspond to discourse segments and subsegments. The communicative act tags are organized into segment initiatives (commands, questions) and responses (replies and acknowledgments). In 1996 and 1997, two workshops were organized by the Discourse Resource Initiative <ref> [59, 15] </ref>. The major outcome of the workshops was an instruction manual for communicative acts called dialogue acts in multiple layers (DAMSL) [28]. The manual specifies independent dimensions for tagging forward looking acts and backward looking acts. Forward looking acts correspond to intentional speech acts, such as Statement and Request. <p> Agreed upon units include phonemes and phonetic variants [25], intonation labels [96], and syntactic parse trees [64]. In contrast, reliability studies in discourse analysis have explored more specific contexts <ref> [27, 72, 107, 59, 15] </ref>. <p> At the first DRI workshop, Nb was used to annotate five transcriptions of natural dialogues and two transcriptions of monologues, using seven different discourse coding schemes <ref> [59] </ref>. The five dialogues were extracted from the following corpora: Verbmobil (an appointment scheduling dialogue), Map Task (route finding on a map), Trains (shipping and transportation problem), and the corpus used for this thesis (a flight reservation dialogue and a yellow pages inquiry).
Reference: [60] <author> W. C. Mann and S. A. Thompson. </author> <title> Rhetorical structure theory: Toward a functional theory of text organization. </title> <booktitle> Text, </booktitle> <volume> 8(3) </volume> <pages> 243-281, </pages> <year> 1988. </year>
Reference-contexts: For example, a discourse segment or subsegment may start with specific dialogue acts such as requests for information, requests for clarification and other direct questions. 2.1.4 Rhetorical Relations The fourth type of discourse unit is rhetorical relations that exist between pairs of clauses, or pairs of speech acts <ref> [60, 49, 62, 61, 69] </ref>. Rhetorical relationship theories are motivated by the observation that clauses in text and speech do not occur in isolation. Instead, there is a small set of relationships that can be established between pairs of units (e.g., elaboration, background, motivation). our example dialogue. <p> Corpus specific tags can be specified as subclasses of the abstract tags. The DAMSL tag set has been adapted to tag the Switchboard corpus using a set of 42 mutually exclusive speech act tags [51]. The papers by Mann and Thompson <ref> [60] </ref>, by Moser, Moore and Glendening [69] and Marcu's doctoral thesis [62, 61] list a set of rhetorical relations that can be used for rhetorical parsing of text.
Reference: [61] <author> D. Marcu. </author> <title> From discourse structures to text summaries. </title> <booktitle> In he Proceedings of the ACL'97/EACL'97 Workshop on Intelligent Scalable Text Summarization, </booktitle> <pages> pages 82-88, </pages> <address> Madrid, Spain, </address> <year> 1997. </year>
Reference-contexts: For example, a discourse segment or subsegment may start with specific dialogue acts such as requests for information, requests for clarification and other direct questions. 2.1.4 Rhetorical Relations The fourth type of discourse unit is rhetorical relations that exist between pairs of clauses, or pairs of speech acts <ref> [60, 49, 62, 61, 69] </ref>. Rhetorical relationship theories are motivated by the observation that clauses in text and speech do not occur in isolation. Instead, there is a small set of relationships that can be established between pairs of units (e.g., elaboration, background, motivation). our example dialogue. <p> Rhetorical parsing of text has been used to provide summaries of texts with very encouraging results <ref> [63, 62, 61] </ref>, or to automatically generate coherent explanatory texts [49]. One important contribution of [63] is the development and empirical evaluation of a full-blown discourse-level parser based on the principles of rhetorical relations. Discourse segments are complementary to rhetorical relations [69]. <p> The DAMSL tag set has been adapted to tag the Switchboard corpus using a set of 42 mutually exclusive speech act tags [51]. The papers by Mann and Thompson [60], by Moser, Moore and Glendening [69] and Marcu's doctoral thesis <ref> [62, 61] </ref> list a set of rhetorical relations that can be used for rhetorical parsing of text. In the area of discourse segmentation, the group led by Grosz at Harvard has published a manual for annotating direction giving monologues according to discourse segment purposes [71]. <p> As a consequence, spoken dialogue systems must incorporate computational models that specify how to break textual information into multiple short discourse contributions. While computational models of speech generation in dialogue systems can be inspired by text planning and generation algorithms <ref> [49, 62, 61] </ref>, the analysis of human-to- human dialogues is instrumental in determining the size and type of discourse contributions that are appropriate in the context of interactive spoken communication. 6.2.2 Intonational Contours and Discourse Cues Perhaps the biggest limitation of this thesis has been that discourse annotation has been performed
Reference: [62] <author> D. Marcu. </author> <title> The rhetorical parsing of natural language texts. </title> <booktitle> In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, (ACL'97/EACL'97), </booktitle> <pages> pages 96-103, </pages> <address> Madrid, Spain, </address> <year> 1997. </year>
Reference-contexts: For example, a discourse segment or subsegment may start with specific dialogue acts such as requests for information, requests for clarification and other direct questions. 2.1.4 Rhetorical Relations The fourth type of discourse unit is rhetorical relations that exist between pairs of clauses, or pairs of speech acts <ref> [60, 49, 62, 61, 69] </ref>. Rhetorical relationship theories are motivated by the observation that clauses in text and speech do not occur in isolation. Instead, there is a small set of relationships that can be established between pairs of units (e.g., elaboration, background, motivation). our example dialogue. <p> Rhetorical parsing of text has been used to provide summaries of texts with very encouraging results <ref> [63, 62, 61] </ref>, or to automatically generate coherent explanatory texts [49]. One important contribution of [63] is the development and empirical evaluation of a full-blown discourse-level parser based on the principles of rhetorical relations. Discourse segments are complementary to rhetorical relations [69]. <p> The DAMSL tag set has been adapted to tag the Switchboard corpus using a set of 42 mutually exclusive speech act tags [51]. The papers by Mann and Thompson [60], by Moser, Moore and Glendening [69] and Marcu's doctoral thesis <ref> [62, 61] </ref> list a set of rhetorical relations that can be used for rhetorical parsing of text. In the area of discourse segmentation, the group led by Grosz at Harvard has published a manual for annotating direction giving monologues according to discourse segment purposes [71]. <p> As a consequence, spoken dialogue systems must incorporate computational models that specify how to break textual information into multiple short discourse contributions. While computational models of speech generation in dialogue systems can be inspired by text planning and generation algorithms <ref> [49, 62, 61] </ref>, the analysis of human-to- human dialogues is instrumental in determining the size and type of discourse contributions that are appropriate in the context of interactive spoken communication. 6.2.2 Intonational Contours and Discourse Cues Perhaps the biggest limitation of this thesis has been that discourse annotation has been performed
Reference: [63] <author> D. Marcu. </author> <title> The rhetorical parsing, summarization, and generation of natural language texts. </title> <type> Phd Thesis CSRG-371, </type> <institution> Computer Systems Research Group, Department of Computer Science, University of Toronto, </institution> <month> December </month> <year> 1997. </year> <month> 148 </month>
Reference-contexts: Rhetorical parsing of text has been used to provide summaries of texts with very encouraging results <ref> [63, 62, 61] </ref>, or to automatically generate coherent explanatory texts [49]. One important contribution of [63] is the development and empirical evaluation of a full-blown discourse-level parser based on the principles of rhetorical relations. Discourse segments are complementary to rhetorical relations [69]. <p> Rhetorical parsing of text has been used to provide summaries of texts with very encouraging results [63, 62, 61], or to automatically generate coherent explanatory texts [49]. One important contribution of <ref> [63] </ref> is the development and empirical evaluation of a full-blown discourse-level parser based on the principles of rhetorical relations. Discourse segments are complementary to rhetorical relations [69]. <p> DAMSL Backward looking Core and Function labels Allen 97 78 - 95 0.57 - 0.77 DAMSL Forward Acts Jurafsky adapted to Switchboard at al. 97 [51] 84 0.80 Map Task Move Speech Acts Carletta et al. 97 0.83 Rhetorical Relations Selection of prominent sentences in written science articles Marcu 97 <ref> [63] </ref> 71 55.5 66.6 Co-referent Words and Phrases Pronouns and noun phrases Hirschman 80 - 90 85 - 90 in newswire text et al 98 [44] Aligning content words in 90 - 92 English-to-French translations Melamed [66] Table 2.1: Some representative studies in inter-coder agreement in annotating units in text and
Reference: [64] <author> M. Marcus, S. Santorini, and M. Marcinkiewicz. </author> <title> Building a large annotated corpus of English: the Penn Treebank. </title> <journal> Computational Linguistics, </journal> <volume> 19(2) </volume> <pages> 313-330, </pages> <year> 1993. </year>
Reference-contexts: Therefore, corpora annotated by one site may not be useful to researchers from other sites, leading to duplication of effort and inhibiting cross-system comparisons. One approach to dealing with this problem is to provide a set of minimal, theory-neutral evaluation metrics. The Penn Treebank <ref> [64] </ref> is an excellent example of linguistic data annotated using this approach. Syntactic structure of sentences is implicitly described by bracketing major constituents without actually attaching labels to them. <p> One crucial issue of discourse annotation is whether or not it can be performed reliably by trained coders who do not necessarily have extensive prior knowledge of the discourse theories. Whereas the reliability of annotating phonological, syntactic and intonation units in sentences has been extensively studied <ref> [54, 64, 96] </ref>, a discussion of the issues in annotating discourse units in dialogue has only begun to emerge in last three years [107, 16, 28]. <p> Agreed upon units include phonemes and phonetic variants [25], intonation labels [96], and syntactic parse trees <ref> [64] </ref>. In contrast, reliability studies in discourse analysis have explored more specific contexts [27, 72, 107, 59, 15].
Reference: [65] <author> J.D. McCawley. </author> <title> The Syntactic Phenomena of English. </title> <publisher> University of Chicago Press, </publisher> <address> Chicago, </address> <year> 1988. </year>
Reference-contexts: Examples of structural models are finite state machines, transition networks and context-free grammars. They are rooted in syntactic and semantic analysis of sentences. In analogy with syntactic models for individual sentences, structural models have been proposed to model the observed sequence of communicative acts in natural spoken dialogue <ref> [97, 65, 108] </ref>. Using a grammar-based approach has been motivated by the observation that sequences of communicative acts tend to appear in adjacency pairs such as Statement- Acknowledgment and Question-Answer [91].
Reference: [66] <author> I.D. Melamed. </author> <title> Manual annotation of translational equivalence: The BLINKER project. </title> <type> Technical Report IRCS 98-07, </type> <institution> Department of Computer and Information Sciences, University of Pennsylvania, </institution> <address> Philadelphia, PA, </address> <month> Winter </month> <year> 1998. </year>
Reference-contexts: In addition to the DDTool, Melamed developed at the University of Pennsylvania another word annotation tool called Blinker, with the purpose of annotating corresponding words between English and French translations of the Bible <ref> [66] </ref>. After the release of Nb , the Discourse Resource Initiative project developed a tool for tagging multiple layers of communicative acts called DAT. The tool has been designed to work with one particular coding manual, the DAMSL coding manual [15, 28]. <p> 97 0.83 Rhetorical Relations Selection of prominent sentences in written science articles Marcu 97 [63] 71 55.5 66.6 Co-referent Words and Phrases Pronouns and noun phrases Hirschman 80 - 90 85 - 90 in newswire text et al 98 [44] Aligning content words in 90 - 92 English-to-French translations Melamed <ref> [66] </ref> Table 2.1: Some representative studies in inter-coder agreement in annotating units in text and speech. co-referent noun phrases in newswire text [19, 44].
Reference: [67] <author> J. Morris and G. Hirst. </author> <title> Lexical cohesion computed by thesaural relations as an indicator of the structure of text. </title> <journal> Computational Linguistics, </journal> <volume> 17(1) </volume> <pages> 21-48, </pages> <year> 1991. </year>
Reference-contexts: Segments can be defined as sections of the dialogue about the same topic or subtopic, independently of the speaker's intentions <ref> [13, 67, 41] </ref>. This alternative definition of segment is useful for information retrieval and indexing of text and speech, where it is desirable to extract from long documents paragraph-like sections that are about a particular topic, and it is not necessary to infer the speaker's intentions. <p> Algorithms for subtopic segmentation rely on co-occurrence of lexical items that are related to each other by co-reference relations <ref> [67] </ref>, or more simply by co-occurrence relations [41]. These algorithms assume that within a segment there are many lexical terms (e.g., nouns and proper nouns) that are related to each other with co-reference relations. The density of these related terms should be minimal across segment boundaries.
Reference: [68] <author> M. G. Moser, J. D. Moore, and E. Glendening. </author> <title> Instructions for coding explanations: Identifying segments, relations and minimal units. </title> <type> Technical Report 96-17, </type> <institution> University of Pittsburgh, Department of Computer Science, </institution> <year> 1996. </year>
Reference-contexts: In general, a discourse segment should consist of a rhetorical parse tree, and a subsegment should consist of a rhetorical subtree. In particular, the discourse coding scheme proposed by Moser, Moore, and Glendening <ref> [68] </ref> is an attempt to unify discourse segment structure with rhetorical relations. In their scheme, a segment must be labeled with a purpose and contain a nucleus, or core contribution, and a series of satellite contributions related to the focus by rhetorical relations. <p> Surface Form specified how the communicative act was realized (e.g., Declarative vs. Interrogative vs. Imperative). Finally, Speech Acts were communicative acts common to the other coding schemes, such as Request, Accept, Reject and Confirm. The sixth coding scheme, proposed by Moser, Moore and Glendening <ref> [68] </ref>, was a segmentation scheme that was designed to combine the top-down intentional theory of discourse structure with the bottom-up approach of rhetorical structure theory. In this scheme, segments were labeled with their intentional purposes.
Reference: [69] <author> M.G. Moser and J.D. Moore. </author> <title> Towards a synthesis of two accounts of discourse structure. </title> <journal> Computational Linguistics, </journal> <volume> 22(3) </volume> <pages> 409-420, </pages> <year> 1996. </year>
Reference-contexts: For example, a discourse segment or subsegment may start with specific dialogue acts such as requests for information, requests for clarification and other direct questions. 2.1.4 Rhetorical Relations The fourth type of discourse unit is rhetorical relations that exist between pairs of clauses, or pairs of speech acts <ref> [60, 49, 62, 61, 69] </ref>. Rhetorical relationship theories are motivated by the observation that clauses in text and speech do not occur in isolation. Instead, there is a small set of relationships that can be established between pairs of units (e.g., elaboration, background, motivation). our example dialogue. <p> One important contribution of [63] is the development and empirical evaluation of a full-blown discourse-level parser based on the principles of rhetorical relations. Discourse segments are complementary to rhetorical relations <ref> [69] </ref>. While rhetorical relations build discourse structures from the bottom up from pairs of clauses, the point of view taken in discourse segmentation is to detect segment boundaries top-down. In particular, discourse segment structure algorithms focus on detecting segment initiatives related to switches in purposes. <p> open problem is to determine whether or not communicative acts, rhetorical relations, subtopics and intentions would produce consistent analyses of the same text, i.e., whether or not the implicit or explicit segmentation produced by a theory can be contained in the segmentation produced by another theory without crossing segment boundaries <ref> [69] </ref>. Most linguistic theories postulate the existence of a set of exhaustive categories, whether they are speech acts, rhetorical relations, or another type of unit. Discourse segment purposes tend to be domain dependent and task specific, such as List movies playing at theater. <p> Corpus specific tags can be specified as subclasses of the abstract tags. The DAMSL tag set has been adapted to tag the Switchboard corpus using a set of 42 mutually exclusive speech act tags [51]. The papers by Mann and Thompson [60], by Moser, Moore and Glendening <ref> [69] </ref> and Marcu's doctoral thesis [62, 61] list a set of rhetorical relations that can be used for rhetorical parsing of text. In the area of discourse segmentation, the group led by Grosz at Harvard has published a manual for annotating direction giving monologues according to discourse segment purposes [71].
Reference: [70] <author> T. Nagata and T. Morimoto. </author> <title> First steps towards statistical modeling of dialogue to predict the speech act type of the next utterance. Speech Communication, </title> <address> 15(3-4):193-203, </address> <year> 1994. </year>
Reference-contexts: Finite state machines and context-free grammars have been used to model graphical user interfaces [76], typed natural language interfaces [108, 29] and spoken language interfaces <ref> [4, 8, 18, 70] </ref>. They have been used to model natural language interactions in Wizard-of-Oz studies, in which users talked to a system simulated by an engineer, before the system is fully developed [98, 29], and sequences of communicative acts in spontaneous telephone conversations of the Switchboard corpus [51]. <p> This measure is used frequently to evaluate the predictive power of structural dialogue models for human-to-computer spoken language systems (e.g., <ref> [70, 51] </ref>). Perplexity is an empirical measure which estimates the average number of likely communicative acts at a particular point in time, given one or two preceding communicative acts. We distinguish between training set perplexity, test set perplexity and Markov model perplexity.
Reference: [71] <author> C.H. Nakatani, B. Grosz, D. Ahn, and J. Hirschberg. </author> <title> Instructions for annotating discourses. </title> <type> Technical Report 21, </type> <institution> Center for Research in Computing Technology, Harvard University, </institution> <month> October </month> <year> 1995. </year>
Reference-contexts: In the area of discourse segmentation, the group led by Grosz at Harvard has published a manual for annotating direction giving monologues according to discourse segment purposes <ref> [71] </ref>. In their approach, annotators are free to choose label names, and the evaluation is conducted by measuring agreement in placing segment boundaries, ignoring domain-specific and theory-specific segment label names. <p> At Harvard University, Nb has been used to annotate the discourse of direction giving monologues, by examining text transcriptions as well as listening to the corresponding speech signals. This coding scheme was rooted in the intentional theory of discourse structure proposed by Grosz and Sidner <ref> [38, 71, 45] </ref>. <p> At Harvard, Nb has been used for discourse segmentation using text and acoustic cues from written instructions, with very encouraging reliability results <ref> [71, 45] </ref>. When users were able to listen to the corresponding speech signal as well as browse the corresponding text, the kappa coefficient was found to be 0.83.
Reference: [72] <author> C.H. Nakatani, J. Hirschberg, and B. Grosz. </author> <title> Discourse structure in spoken language: Studies on speech corpora. </title> <booktitle> In Working Notes of the AAAI-95 Spring Symposium on Empirical Methods in Discourse Interpretation, </booktitle> <pages> pages 106-112, </pages> <address> Menlo Park, CA, </address> <year> 1995. </year> <journal> American Association for Artificial Intelligence. </journal>
Reference-contexts: Agreed upon units include phonemes and phonetic variants [25], intonation labels [96], and syntactic parse trees [64]. In contrast, reliability studies in discourse analysis have explored more specific contexts <ref> [27, 72, 107, 59, 15] </ref>. <p> tags (e.g., [14, 27]), frequency analysis and models for speech repairs, grounding contributions and other spontaneous speech phenomena such as repairs (e.g., [103, 42]), correlation analysis between prosodic cues and discourse segment boundaries (e.g., [46, 36, 45]), evaluating the agreement among subjects in placing discourse boundaries in transcriptions of monologues <ref> [72] </ref>, and evaluating human and algorithmic performance in annotating 46 Annotation Task Citation % Agree Recall Precision Kappa Discourse Segments Subtopic Segmentation of written science articles Hearst 97 [41] 81.6 71.4 0.67 Discourse Segmentation Hirschberg and of spoken directions from text Nakatani 96 [45] 0.63 Discourse Segmentation Hirschberg and of directions <p> The two monologues were extracted from the Boston Direction Corpus (walking directions to a landmark building in Boston) <ref> [72] </ref> and from the instruction corpus developed at the University of Pittsburgh (directions for assembling some electronic parts). Each text was annotated by three to eleven coders. <p> However, speakers convey changes in their intentional and attentional state using a combination of lexical, acoustic and prosodic cues such as discourse cue words, pause duration, speech signal amplitude and pitch contour <ref> [82, 46, 100, 36, 72, 52] </ref>. Hirshberg and Nakatani report very reliable results in annotating segments by listening to the speech signal as well as reading the text transcription [45].
Reference: [73] <author> C.H. Nakatani and J. Hirshberg. </author> <title> A speech-first model for repair detection and correction. </title> <booktitle> In Proc. of the 31st Annual Meeting of the Association for Computational Linguistics. ACL, </booktitle> <year> 1993. </year>
Reference-contexts: Repairs Repairs can be self-repairs, involving only one speaker and one dialogue turn, or they may involve both participants for a few dialogue turns. They are also local discourse phenomena: as soon as the speaker or hearer detects an error in the speech stream, she tries to repair it <ref> [90, 56, 47, 89, 73, 20] </ref>. The instructions specified that in case of speech repairs, segment boundaries should be placed before complete clauses that could be fully understood as switches in segment purposes. However, some spontaneous repairs could not be handled consistently by this rule.
Reference: [74] <author> N.J. Nilsson. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga Publishing Company, </publisher> <address> Palo Alto, CA, </address> <year> 1980. </year>
Reference-contexts: In this model, intentions and purposes are encoded explicitly a priori by one or more of the atomic conditions. In contrast, inference models such as Artimis's system apply first-order predicate calculus, which is a more complex computational model <ref> [109, 74] </ref>. First- order logic inference allows one to deduct the truth value of predicates such as the speaker's beliefs, intentions and purposes from other related predicates that encode the meaning of a sentence, by way of automated reasoning.
Reference: [75] <author> D. Norman. </author> <title> The Invisible Computer. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1998. </year>
Reference: [76] <author> D.R. Olsen. </author> <title> User Interface Management Systems: Models and Algorithms. </title> <publisher> Morgan Kauffman, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year> <month> 149 </month>
Reference-contexts: Using a grammar-based approach has been motivated by the observation that sequences of communicative acts tend to appear in adjacency pairs such as Statement- Acknowledgment and Question-Answer [91]. Finite state machines and context-free grammars have been used to model graphical user interfaces <ref> [76] </ref>, typed natural language interfaces [108, 29] and spoken language interfaces [4, 8, 18, 70]. <p> Systems such as CSELT DIALOGOS [30], AT&T Amica [81] and MIT Bianca [94] apply the principles of propositional production systems <ref> [76, 77] </ref>. According to Olsen's definition [77], a propositional production system consists of a state space of equivalent classes and a set of rules. The equivalent classes are determined by a set of predicates over a finite set of conditions. At every dialogue turn, the rules are applied in order. <p> Once a communicative act is completed, one or more condition has been changed as a side effect, resulting in a new dialogue state. The predicates may encode knowledge about expected and recognized topics and intentions. Propositional production systems are equivalent to simple propositional logic <ref> [76, 77] </ref>, which does not infer logical consequences beyond the ones expressed by atomic logical conditions. In this model, intentions and purposes are encoded explicitly a priori by one or more of the atomic conditions.
Reference: [77] <author> D.R. Olsen, </author> <title> A.F. Monk, and M.B. Curry. Algorithms for automatic dialogue analysis using propositional production systems. </title> <journal> Human-Computer Interaction, </journal> <volume> 10 </volume> <pages> 39-78, </pages> <year> 1995. </year>
Reference-contexts: Systems such as CSELT DIALOGOS [30], AT&T Amica [81] and MIT Bianca [94] apply the principles of propositional production systems <ref> [76, 77] </ref>. According to Olsen's definition [77], a propositional production system consists of a state space of equivalent classes and a set of rules. The equivalent classes are determined by a set of predicates over a finite set of conditions. At every dialogue turn, the rules are applied in order. <p> Systems such as CSELT DIALOGOS [30], AT&T Amica [81] and MIT Bianca [94] apply the principles of propositional production systems [76, 77]. According to Olsen's definition <ref> [77] </ref>, a propositional production system consists of a state space of equivalent classes and a set of rules. The equivalent classes are determined by a set of predicates over a finite set of conditions. At every dialogue turn, the rules are applied in order. <p> Once a communicative act is completed, one or more condition has been changed as a side effect, resulting in a new dialogue state. The predicates may encode knowledge about expected and recognized topics and intentions. Propositional production systems are equivalent to simple propositional logic <ref> [76, 77] </ref>, which does not infer logical consequences beyond the ones expressed by atomic logical conditions. In this model, intentions and purposes are encoded explicitly a priori by one or more of the atomic conditions.
Reference: [78] <author> B. Orestrom. </author> <title> Turn-taking in English Conversations. </title> <institution> Gleerup, Lund, </institution> <year> 1983. </year>
Reference-contexts: We will discuss in more detail the issues in predicting communicative acts in the next section. Frequent confirmations and short, elliptical dialogue turns are typical of spontaneous dialogue. They appear frequently also in other corpus-based studies (e.g., the London-Lund corpora described in <ref> [78] </ref> and the task-oriented conversations analyzed in [105, 79]). 5.3 Modeling Turn Transitions within Segments In this section we assess the extent to which a probabilistic finite state model is adequate for predicting the internal turn-taking organization of discourse segments. <p> The data reported here are consistent with the analysis by Orestrom of a similar corpus of telephone conversations between British-English operators and customers (the London- Lund corpus) <ref> [78] </ref>. The average agent word count reported by that study is strikingly close to the one reported here (80% of the time the agent speaks 15 words or less, with an average of 12 words). <p> In addition, the statistics reported here are consistent with at least two other empirical studies conducted on a similar corpus of British-English telephone conversations, the London-Lund corpus [99] analyzed by Orestrom <ref> [78] </ref> and by Clark and Schaefer [22]. The movie schedule domain is within reach of state-of-the-art spoken dialogue systems.
Reference: [79] <author> S. Oviatt and P.R. Cohen. </author> <title> Discourse structure and performance efficiency in interactive and non-interactive spoken modalities. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 5(4) </volume> <pages> 297-326, </pages> <year> 1991. </year>
Reference-contexts: We will discuss in more detail the issues in predicting communicative acts in the next section. Frequent confirmations and short, elliptical dialogue turns are typical of spontaneous dialogue. They appear frequently also in other corpus-based studies (e.g., the London-Lund corpora described in [78] and the task-oriented conversations analyzed in <ref> [105, 79] </ref>). 5.3 Modeling Turn Transitions within Segments In this section we assess the extent to which a probabilistic finite state model is adequate for predicting the internal turn-taking organization of discourse segments.
Reference: [80] <author> R. Passonneau and D. Litman. </author> <title> Discourse segmentation by human and automated means. </title> <journal> Computational Linguistics, </journal> <volume> 23(1) </volume> <pages> 103-139, </pages> <year> 1997. </year>
Reference-contexts: We have assessed inter-coder agreement using the metrics of precision, recall and the kappa coefficient. The reliability results are competitive with other published work on discourse segmentation <ref> [107, 41, 45, 80, 16] </ref>, and lend empirical support to the notion that discourse segmentation can be done as reliably as annotating other types of discourse units, such as communicative acts. <p> Some researchers suggest first to evaluate where coders agree in placing segment initiatives, and then to evaluate if they also agree on segment closings for the segments in which they agree on the initiatives <ref> [45, 80] </ref>. One important feature of the kappa coefficient is that it can be extended to experimental conditions with multiple coders, more than two annotated categories and missing annotated data. In such cases it becomes the group-wise kappa coefficient. <p> Kappa Discourse Segments Subtopic Segmentation of written science articles Hearst 97 [41] 81.6 71.4 0.67 Discourse Segmentation Hirschberg and of spoken directions from text Nakatani 96 [45] 0.63 Discourse Segmentation Hirschberg and of directions from text and speech Nakatani 96 0.80 Discourse Segmentation Passonneau and of spoken stories Litman 97 <ref> [80] </ref> 63.3 70.6 Map Task Move Boundaries Carletta et al. 97 [16] 89.0 0.92 Map Task Transaction Segments Carletta at al. 97 0.59 Communicative Acts DAMSL Forward looking Core and Speech Act labels Allen 97 [28] 82 - 93 0.15 - 0.70 DAMSL Backward looking Core and Function labels Allen 97
Reference: [81] <author> R. Pieraccini, E. Levin, and W. Eckert. Amica: </author> <title> the AT&T mixed initiative conversational architecture. </title> <booktitle> In Proceedings Eurospeech-97 5th International Conference on Speech Communication and Technology, </booktitle> <pages> pages 1875-1879, </pages> <address> Rhodes, Greece, </address> <year> 1997. </year> <institution> Univerity of Patras. </institution>
Reference-contexts: In order to circumvent the state space explosion problem faced by finite state models, another alternative has been to represent the state space by equivalence classes that contains several individual states at once. Systems such as CSELT DIALOGOS [30], AT&T Amica <ref> [81] </ref> and MIT Bianca [94] apply the principles of propositional production systems [76, 77]. According to Olsen's definition [77], a propositional production system consists of a state space of equivalent classes and a set of rules.
Reference: [82] <author> J. Pierrehumbert and J. Hirshberg. </author> <title> The meaning of intonational contours in the interpretation of discourse. </title> <editor> In P.R. Cohen, J. Morgan, and M. Pollack, editors, </editor> <booktitle> Intentions in Communication, </booktitle> <pages> pages 271-312, </pages> <address> Cambridge, MA, 1990. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Intention-based segmentation recognizes three related analysis structures [38]. The first one is the linguistic structure which corresponds to acoustic and lexical features of individual sentences and phrases. These features include intonation contours and discourse cue words which are correlated with segment transitions <ref> [82, 46, 45, 100] </ref>. The second one is the attentional structure, or focus of attention, which is a data structure that records the salient semantic entities that the dialogue participants can refer to in the dialogue (e.g., movie titles, theater locations, show times). <p> Finally, discourse segment structure is correlated with specific acoustic and prosodic cues such as changes in pause duration, speech signal amplitude and pitch contour <ref> [82, 36, 46, 52] </ref>. For example, Hirshberg and Nakatani report an increase of the kappa coefficient from 0.67 to 0.80 when trained coders were able to listen to the speech signal as well as read the transcription [45]. <p> However, speakers convey changes in their intentional and attentional state using a combination of lexical, acoustic and prosodic cues such as discourse cue words, pause duration, speech signal amplitude and pitch contour <ref> [82, 46, 100, 36, 72, 52] </ref>. Hirshberg and Nakatani report very reliable results in annotating segments by listening to the speech signal as well as reading the text transcription [45].
Reference: [83] <author> L. Polanyi. </author> <title> The linguistic structure of discourse. </title> <type> Technical Report CSLI-96-200, CSLI, </type> <institution> Center for the Study of Language Understanding at Stanford University, </institution> <address> Palo Alto, CA, </address> <year> 1996. </year>
Reference-contexts: Another example of a linguistic theory which combines discourse segmentation with rhetorical relations is the one proposed by Polanyi <ref> [83] </ref>. In that model, a text is first segmented into elementary 34 communicative act units called discourse coherent units (DCUs). Each DCU has syntactic and semantic features attached to it.
Reference: [84] <author> J.A. Rotondo. </author> <title> Clustering analysis of subject partitions of text. </title> <booktitle> Discourse Processes, </booktitle> <volume> 7 </volume> <pages> 69-88, </pages> <year> 1984. </year>
Reference-contexts: Our goal was to determine by cluster analysis techniques what types of discourse patterns were agreed upon by a majority of coders without extensive instructions. This data-driven approach was proposed by Rotondo in 1984 to assess inter-coder agreement in segmenting text <ref> [84] </ref>. In addition, we wanted to determine empirically where coders would disagree and what types of instructions and tutorial examples were needed to achieve more reliable results. We did not expect to obtain substantial agreement among coders without giving them specific directions. <p> The segment purpose accuracy ranged between 62% and 93% for Experiment 2. 4.2.4 Agreement Displays We applied a visual clustering technique to display the patterns of agreement in segmenting the dialogues. The technique is based upon the discourse analysis study by Rotondo <ref> [84] </ref>. Let N be the 80 clauses (i; j) is proportional to the fraction of coders that places clause i and clause j in the same segment.
Reference: [85] <author> H. Sacks, E.A. Schegloff, and G. Jefferson. </author> <title> A simplest systematics for the organization of turn-taking for conversation. </title> <booktitle> Language, </booktitle> <volume> 50 </volume> <pages> 696-735, </pages> <year> 1974. </year>
Reference-contexts: get all the different theaters? 5 A: I can give you that information 6 C: You can? 7 C: Okay, in Snellville, Septum movies The variability in determining the exact location of the start of the task-related conversation can be explained by what some researchers have called preliminaries, or pre-sequences <ref> [91, 85, 21, 48] </ref>. Pre-sequences are discourse transitions that are used by conversation participants to set a general common ground before committing to a more specific task. Transitional pre-closing statements also posed some problems in locating the end of the task-oriented part of the conversation. <p> Psycho-linguists have argued that these opportunities for switches in speaker tend to occur at specific syntactic, semantic and intentional boundaries, (e.g., just after reporting an item in a list) and may be indicated by the agent with acoustic correlates such as pauses and raising intonation contours <ref> [85, 48] </ref>. The examples also illustrate the fact that such turn-switching opportunities exist even while the agent is speaking, whether or not she indicates them to the customer. <p> This taxonomy combines the types considered in the intentional theory of discourse [39, 58] with the ones considered in the theories of discourse contributions [21, 22] and of turn-taking in conversations <ref> [85, 48] </ref>. A preliminary segment (or pre-sequence) has a generic purpose which is the introduction to a more specific, task-oriented purpose. A preliminary purpose is a pre-condition to the purpose that follows it. In the movie schedule domain, a new task corresponds 118 A. <p> OK) tend to be spoken with a falling intonation contour, and do not require that the agent further explain or repeat the information. 6.2.3 Collaborative Timing Spoken dialogue is a real-time collaborative process in which speakers take the initiative at specific instant in time <ref> [20, 21, 85] </ref>.
Reference: [86] <author> D. Sadek. </author> <title> Towards a theory of belief reconstruction: Application to communication. Speech Communication, </title> <address> 15(3-4):243-250, </address> <year> 1994. </year>
Reference-contexts: A finite language model such as a trigram may be useful in predicting the customer's next action from the few preceding actions, but it seems inappropriate in helping to predict the agent's behavior. One alternative to finite state models is the co-operative plan-based approach (see <ref> [39, 37, 57, 58, 24, 86, 87] </ref>, among others). In this approach, the dialogue state and sentence meaning are represented by a set of logical predicates. Communicative acts are operators which have predicate pre-conditions 124 and side effects they may add or delete predicates to the dialogue state. <p> The CNET Artimis system is an example of a deployed co-operative spoken language system that uses a set of rationality principles and a detailed inference model for recognizing the speaker's meaning and intentions and generating the system responses <ref> [86, 87] </ref>. In order to circumvent the state space explosion problem faced by finite state models, another alternative has been to represent the state space by equivalence classes that contains several individual states at once.
Reference: [87] <author> D. Sadek and R. De Mori. </author> <title> Spoken dialogue systems. In Spoken Dialogue With Computers (Chapter 15), </title> <address> NY, 1997. </address> <publisher> Academic Press. </publisher>
Reference-contexts: Critics of the structural model approach have argued that such models may be appropriate only for IVR and question-answer systems in which the sequence of the interactions is essentially defined a priori (e.g., <ref> [24, 87] </ref>). They argue that the number of states and state transitions would become too large if one wished to model co-operative dialogues with clarifications, confirmations, switches in intentions initiated by either speaker, and purposes that can be completed out of order. <p> A finite language model such as a trigram may be useful in predicting the customer's next action from the few preceding actions, but it seems inappropriate in helping to predict the agent's behavior. One alternative to finite state models is the co-operative plan-based approach (see <ref> [39, 37, 57, 58, 24, 86, 87] </ref>, among others). In this approach, the dialogue state and sentence meaning are represented by a set of logical predicates. Communicative acts are operators which have predicate pre-conditions 124 and side effects they may add or delete predicates to the dialogue state. <p> The CNET Artimis system is an example of a deployed co-operative spoken language system that uses a set of rationality principles and a detailed inference model for recognizing the speaker's meaning and intentions and generating the system responses <ref> [86, 87] </ref>. In order to circumvent the state space explosion problem faced by finite state models, another alternative has been to represent the state space by equivalence classes that contains several individual states at once.
Reference: [88] <author> E.A. Schegloff. </author> <title> Discourse as an interactional achievement: Some uses of uh-huh and other things that come between sentences. In Text and Talk, </title> <address> Washington, DC, </address> <year> 1981. </year> <note> Georgetown University Roundtable on Languages and Linguistics, Georgetown University Press. </note>
Reference-contexts: For example, the most common responses to the agent's acknowledgments and confirmations are also acknowledgments and confirmations. This indicates that sequences of confirmations are joint activities that often require both speakers' participation for more than one dialogue turn <ref> [88] </ref>. We will discuss in more detail the issues in predicting communicative acts in the next section. Frequent confirmations and short, elliptical dialogue turns are typical of spontaneous dialogue.
Reference: [89] <author> E.A. Schegloff. </author> <title> Repair after next turn: The last structurally provided defense of intersubjectivity in conversations. </title> <journal> American Journal of Sociology, </journal> <volume> 97(5) </volume> <pages> 1295-1345, </pages> <year> 1992. </year>
Reference-contexts: Repairs Repairs can be self-repairs, involving only one speaker and one dialogue turn, or they may involve both participants for a few dialogue turns. They are also local discourse phenomena: as soon as the speaker or hearer detects an error in the speech stream, she tries to repair it <ref> [90, 56, 47, 89, 73, 20] </ref>. The instructions specified that in case of speech repairs, segment boundaries should be placed before complete clauses that could be fully understood as switches in segment purposes. However, some spontaneous repairs could not be handled consistently by this rule. <p> This constraint is motivated by previous empirical studies in speech repairs which indicated that repairs occur sooner rather than later <ref> [90, 56, 89, 20] </ref>. In particular, this constraint is consistent with Clark's principle of repair [21]: 130 When agents detect a problem serious enough to warrant a repair, they try to initiate and repair the problem at the first opportunity after detecting it.
Reference: [90] <author> E.A. Schegloff, G. Jefferson, and H. Sacks. </author> <title> The preference for self-correction in the organization of repair in conversation. </title> <booktitle> Language, </booktitle> <volume> 53 </volume> <pages> 361-382, </pages> <year> 1977. </year> <month> 150 </month>
Reference-contexts: Repairs Repairs can be self-repairs, involving only one speaker and one dialogue turn, or they may involve both participants for a few dialogue turns. They are also local discourse phenomena: as soon as the speaker or hearer detects an error in the speech stream, she tries to repair it <ref> [90, 56, 47, 89, 73, 20] </ref>. The instructions specified that in case of speech repairs, segment boundaries should be placed before complete clauses that could be fully understood as switches in segment purposes. However, some spontaneous repairs could not be handled consistently by this rule. <p> This constraint is motivated by previous empirical studies in speech repairs which indicated that repairs occur sooner rather than later <ref> [90, 56, 89, 20] </ref>. In particular, this constraint is consistent with Clark's principle of repair [21]: 130 When agents detect a problem serious enough to warrant a repair, they try to initiate and repair the problem at the first opportunity after detecting it.
Reference: [91] <author> E.A. Schegloff and H. Sacks. </author> <title> Opening up closings. </title> <journal> Semiotica, </journal> <volume> 7 </volume> <pages> 289-327, </pages> <year> 1973. </year>
Reference-contexts: get all the different theaters? 5 A: I can give you that information 6 C: You can? 7 C: Okay, in Snellville, Septum movies The variability in determining the exact location of the start of the task-related conversation can be explained by what some researchers have called preliminaries, or pre-sequences <ref> [91, 85, 21, 48] </ref>. Pre-sequences are discourse transitions that are used by conversation participants to set a general common ground before committing to a more specific task. Transitional pre-closing statements also posed some problems in locating the end of the task-oriented part of the conversation. <p> Using a grammar-based approach has been motivated by the observation that sequences of communicative acts tend to appear in adjacency pairs such as Statement- Acknowledgment and Question-Answer <ref> [91] </ref>. Finite state machines and context-free grammars have been used to model graphical user interfaces [76], typed natural language interfaces [108, 29] and spoken language interfaces [4, 8, 18, 70].
Reference: [92] <author> J.R. Searle. </author> <title> Speech Acts: An essay in the philosophy of language. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1969. </year>
Reference-contexts: For example, at the syntactic level, pronouns might be annotated along with the definite noun phrases they refer to [19, 44] and at the intentional level, sentences might be annotated with the speaker intentions (e.g. whether the sentence is a request for information, an acknowledgment) <ref> [92, 93, 1] </ref>. Annotation of some linguistic phenomena such as phonetic variants and disfluencies are relatively straightforward, since agreement on the choices of units and conventions can often be reached [55, 96]. <p> In this thesis, we focus on task-oriented spoken dialogue because it is a genre applicable to building spoken language systems. In this case, discourse analysis is mostly focused on determining relations between sentences spoken by different speakers across dialogue turns. In particular, we focus on intentional relations (e.g., <ref> [1, 38, 39, 92, 93] </ref>). For example, in this framework the first sentence of the above dialogue exchange 27 (I'm trying to find out where the Lion King is located) is not interpreted solely as a declarative, but rather as a communicative act: a request for some specific information. <p> Larger segment units driven by task-related purposes, such as List Movies Playing At Theater, typically contain one or more nested discourse contributions. 2.1.3 Communicative Acts The third type of discourse unit is called a speech act, communicative act, or act for short <ref> [92, 93, 1] </ref>. An act is an abstract label that is attached to one or more clauses in a dialogue turn. It attempts to summarize the intention that the speaker wants to communicate to the listener. <p> The list of communicative acts is displayed in Table 5.2. The list is a subset of acts which are frequently used in discourse analysis <ref> [92, 93, 1] </ref>. On average, a dialogue turn is composed of one to three clauses. Each clause has been annotated with a separate communicative act. In our annotated data, 74.5% of the dialogue turns are a single clause.
Reference: [93] <author> J.R. Searle. </author> <title> A taxonomy of illocutionary acts. </title> <booktitle> In Expression and Meaning, </booktitle> <pages> pages 1-29, </pages> <publisher> Cambridge University Press, </publisher> <year> 1979. </year>
Reference-contexts: For example, at the syntactic level, pronouns might be annotated along with the definite noun phrases they refer to [19, 44] and at the intentional level, sentences might be annotated with the speaker intentions (e.g. whether the sentence is a request for information, an acknowledgment) <ref> [92, 93, 1] </ref>. Annotation of some linguistic phenomena such as phonetic variants and disfluencies are relatively straightforward, since agreement on the choices of units and conventions can often be reached [55, 96]. <p> In this thesis, we focus on task-oriented spoken dialogue because it is a genre applicable to building spoken language systems. In this case, discourse analysis is mostly focused on determining relations between sentences spoken by different speakers across dialogue turns. In particular, we focus on intentional relations (e.g., <ref> [1, 38, 39, 92, 93] </ref>). For example, in this framework the first sentence of the above dialogue exchange 27 (I'm trying to find out where the Lion King is located) is not interpreted solely as a declarative, but rather as a communicative act: a request for some specific information. <p> Larger segment units driven by task-related purposes, such as List Movies Playing At Theater, typically contain one or more nested discourse contributions. 2.1.3 Communicative Acts The third type of discourse unit is called a speech act, communicative act, or act for short <ref> [92, 93, 1] </ref>. An act is an abstract label that is attached to one or more clauses in a dialogue turn. It attempts to summarize the intention that the speaker wants to communicate to the listener. <p> The list of communicative acts is displayed in Table 5.2. The list is a subset of acts which are frequently used in discourse analysis <ref> [92, 93, 1] </ref>. On average, a dialogue turn is composed of one to three clauses. Each clause has been annotated with a separate communicative act. In our annotated data, 74.5% of the dialogue turns are a single clause.
Reference: [94] <author> S. Seneff, P. Schmid, J. Polifroni, J. Glass, T.J. Hazen, C. Pao, and V. Zue. </author> <title> Pegasus: A telephone-access flight status information system. </title> <booktitle> In ICSLP-98: International Conference on Spoken Language Processing, </booktitle> <address> Sidney, Australia, </address> <month> Fall </month> <year> 1998. </year>
Reference-contexts: In order to circumvent the state space explosion problem faced by finite state models, another alternative has been to represent the state space by equivalence classes that contains several individual states at once. Systems such as CSELT DIALOGOS [30], AT&T Amica [81] and MIT Bianca <ref> [94] </ref> apply the principles of propositional production systems [76, 77]. According to Olsen's definition [77], a propositional production system consists of a state space of equivalent classes and a set of rules. The equivalent classes are determined by a set of predicates over a finite set of conditions.
Reference: [95] <author> B. Shneiderman and P. Maes. </author> <title> Direct manipulation vs. interface agents. </title> <journal> ACM Interactions, </journal> <volume> 4(6) </volume> <pages> 42-61, </pages> <year> 1997. </year>
Reference: [96] <author> K. Silverman et al. </author> <title> ToBI: A standard for labeling english prosody. </title> <booktitle> In Proc. Int. Conf. on Spoken Language Processing, </booktitle> <pages> pages 867-870, </pages> <address> Banff, Canada, </address> <year> 1992. </year>
Reference-contexts: Annotation of some linguistic phenomena such as phonetic variants and disfluencies are relatively straightforward, since agreement on the choices of units and conventions can often be reached <ref> [55, 96] </ref>. As a result, the task of annotation can often be shared across site, and the aggregate corpora are larger and more useful to a wider community. As we move up the linguistic chain, however, the 19 picture can rapidly deteriorate. <p> One crucial issue of discourse annotation is whether or not it can be performed reliably by trained coders who do not necessarily have extensive prior knowledge of the discourse theories. Whereas the reliability of annotating phonological, syntactic and intonation units in sentences has been extensively studied <ref> [54, 64, 96] </ref>, a discussion of the issues in annotating discourse units in dialogue has only begun to emerge in last three years [107, 16, 28]. <p> Agreed upon units include phonemes and phonetic variants [25], intonation labels <ref> [96] </ref>, and syntactic parse trees [64]. In contrast, reliability studies in discourse analysis have explored more specific contexts [27, 72, 107, 59, 15]. <p> Speech corpora annotated with the ToBI prosodic labels have been crucial in fostering progress in modeling suprasegmental acoustic features <ref> [96] </ref> and in the study of the correlation between prosody and discourse segment structure [46, 100].
Reference: [97] <author> J. Sinclair and M. Coulthard. </author> <title> Towards an analysis of discourse. </title> <editor> In M. Coulthard, editor, </editor> <booktitle> Advances in Spoken Discourse Analysis, </booktitle> <pages> pages 1-34, </pages> <year> 1992. </year>
Reference-contexts: Examples of structural models are finite state machines, transition networks and context-free grammars. They are rooted in syntactic and semantic analysis of sentences. In analogy with syntactic models for individual sentences, structural models have been proposed to model the observed sequence of communicative acts in natural spoken dialogue <ref> [97, 65, 108] </ref>. Using a grammar-based approach has been motivated by the observation that sequences of communicative acts tend to appear in adjacency pairs such as Statement- Acknowledgment and Question-Answer [91].
Reference: [98] <author> R. Smith and S. Gordon. </author> <title> Effects of variable initiative on linguistic behavior in human-computer spoken natural language dialogue. </title> <journal> Computational Linguistics, </journal> <volume> 23(1) </volume> <pages> 141-168, </pages> <year> 1997. </year>
Reference-contexts: They have been used to model natural language interactions in Wizard-of-Oz studies, in which users talked to a system simulated by an engineer, before the system is fully developed <ref> [98, 29] </ref>, and sequences of communicative acts in spontaneous telephone conversations of the Switchboard corpus [51]. They have also been used to provide a predictive dialogue model for human-to-human spoken interaction within a speech translation system [50].
Reference: [99] <author> J. Svartvick and R. Quirk. </author> <title> A Corpus of English Conversations. </title> <institution> Gleerup, Lund, </institution> <year> 1980. </year>
Reference-contexts: In addition, at least one corpus of spoken monologues has been used to conduct discourse segmentation studies (i.e., the Boston Direction Corpus [45]). The London-Lund corpus has been a pioneering effort in collecting and transcribing spontaneous speech, including some task-oriented telephone conversations <ref> [99] </ref>. The corpus contains 500,000 words of spoken British English recorded from 1953 to 1987. It consists of 100 text samples. The 36 text genres include transcriptions of directory assistance conversations between telephone operators and customers as well as monologues, commentaries and public speeches. <p> In addition, the statistics reported here are consistent with at least two other empirical studies conducted on a similar corpus of British-English telephone conversations, the London-Lund corpus <ref> [99] </ref> analyzed by Orestrom [78] and by Clark and Schaefer [22]. The movie schedule domain is within reach of state-of-the-art spoken dialogue systems.
Reference: [100] <author> M. Swerts and M. Ostendorf. </author> <title> Prosodic and lexical indications of discourse structure in humanmachine interactions. </title> <journal> Speech Communication, </journal> <volume> 22(1) </volume> <pages> 25-41, </pages> <year> 1997. </year>
Reference-contexts: Intention-based segmentation recognizes three related analysis structures [38]. The first one is the linguistic structure which corresponds to acoustic and lexical features of individual sentences and phrases. These features include intonation contours and discourse cue words which are correlated with segment transitions <ref> [82, 46, 45, 100] </ref>. The second one is the attentional structure, or focus of attention, which is a data structure that records the salient semantic entities that the dialogue participants can refer to in the dialogue (e.g., movie titles, theater locations, show times). <p> Speech corpora annotated with the ToBI prosodic labels have been crucial in fostering progress in modeling suprasegmental acoustic features [96] and in the study of the correlation between prosody and discourse segment structure <ref> [46, 100] </ref>. In the area of text processing, text corpora annotated with co-referent nouns and noun phrases have been instrumental in monitoring the progress in automatic information extraction algorithms developed for the series of Message Understanding Conferences (MUC) [19, 44]. <p> However, speakers convey changes in their intentional and attentional state using a combination of lexical, acoustic and prosodic cues such as discourse cue words, pause duration, speech signal amplitude and pitch contour <ref> [82, 46, 100, 36, 72, 52] </ref>. Hirshberg and Nakatani report very reliable results in annotating segments by listening to the speech signal as well as reading the text transcription [45].
Reference: [101] <author> H. Thompson and D. McKelvie. </author> <title> A software architecture for simple, efficient sgml applications: The lt nsl software library. </title> <booktitle> In Proceedings SGML-96 European Conference on the Standard Generalized Markup Language, </booktitle> <address> Munich, </address> <year> 1996. </year>
Reference-contexts: Finally, the Human Language Technology group at the University of Edinburgh is developing a generic software toolkit for generating and parsing annotated text using SGML (standard generalized mark-up language) and XML (extensible mark-up language) <ref> [101] </ref>. 2.3 Evaluating the Reliability of Annotations Various metrics have been proposed to measure the agreement among coders for different linguistic annotations. For example, phonetic transcriptions have been compared in terms of a pairwise inter- coder agreement, taking into account insertion/deletion as well as substitution errors.
Reference: [102] <author> D. Traum. </author> <title> Coding schemes for spoken dialogue structure. </title> <type> Unpublished manuscript, </type> <institution> Universite de Geneve, </institution> <month> January </month> <year> 1996. </year>
Reference-contexts: Table 3.2 lists all the possible annotation tags organized by function. The fifth coding scheme was proposed by Traum and involved four different layers of mark-up <ref> [102] </ref>. In his proposed coding scheme, Discourse Units were discourse segment units that tagged sequences of one or more clauses that were related because they accomplished the same purpose, or task. Traum scheme, like Condon's scheme, recognized that a clause may perform multiple intentional functions.
Reference: [103] <author> D.R. Traum and A.B. Hinkelman. </author> <title> Conversation acts in task-oriented spoken dialogue. </title> <journal> Computational Intelligence, </journal> <volume> 8(3), </volume> <year> 1992. </year>
Reference-contexts: Some of the topics studied by empirical work in discourse analysis include defining and evaluating the consistency of coding schemes for speech act tags (e.g., [14, 27]), frequency analysis and models for speech repairs, grounding contributions and other spontaneous speech phenomena such as repairs (e.g., <ref> [103, 42] </ref>), correlation analysis between prosodic cues and discourse segment boundaries (e.g., [46, 36, 45]), evaluating the agreement among subjects in placing discourse boundaries in transcriptions of monologues [72], and evaluating human and algorithmic performance in annotating 46 Annotation Task Citation % Agree Recall Precision Kappa Discourse Segments Subtopic Segmentation of
Reference: [104] <author> J.S. Uebersax. </author> <title> A generalized kappa coefficient. </title> <booktitle> Educational and Psychological Measurement, </booktitle> <volume> 42 </volume> <pages> 181-183, </pages> <year> 1982. </year>
Reference-contexts: In this section, we review how to compute four metrics for measuring inter-coder agreement: precision, recall, percent agreement and the kappa coefficient. A discussion of evaluation metrics can also be found in <ref> [53, 6, 104, 14] </ref>. 2.3.1 Precision and Recall When comparing two different annotations of the same text, we may select one as the reference and the other one as the test. <p> The computations are based on the article by Uebersax <ref> [104] </ref>. The C source code of the computations can be downloaded by anonymous ftp to the site: ftp.sls.lcs.mit.edu/pub/flammia/kappa.c Let N be the number of coders, and i; j be two different coders. Let C be the number of categories, and c; d be two different categories.
Reference: [105] <author> D.E. Walker and B. Grosz. </author> <title> Understanding Spoken Language. </title> <publisher> North-Holland, </publisher> <address> New York, </address> <year> 1978. </year> <month> 151 </month>
Reference-contexts: In Map Task and Trains, the role of each speaker is different: user vs. assistant and route giver vs. route follower. In Verbmobil and Switchboard, the relationship between speakers is peer-to-peer. Some other relationships that have been analyzed in other corpora are: expert vs. apprentice <ref> [105] </ref> and customer vs. agent (this thesis). In a user vs. assistant setting, for example, the types and size of contributions spoken by the assistant are much more limited than in a customer vs. agent setting or in a peer-to-peer setting. <p> We will discuss in more detail the issues in predicting communicative acts in the next section. Frequent confirmations and short, elliptical dialogue turns are typical of spontaneous dialogue. They appear frequently also in other corpus-based studies (e.g., the London-Lund corpora described in [78] and the task-oriented conversations analyzed in <ref> [105, 79] </ref>). 5.3 Modeling Turn Transitions within Segments In this section we assess the extent to which a probabilistic finite state model is adequate for predicting the internal turn-taking organization of discourse segments. <p> In this respect, our results are not conclusive, and more annotation experiments are needed to settle this issue. We believe there are two possible explanations for the disagreement about hierarchical segmentations. Firstly, as mentioned by Grosz in <ref> [105] </ref>, the structure of information-seeking dialogues is sequential rather than hierarchical. For example, in Chapter 5 we accurately modeled the movie schedule dialogues as sequences of request-response contributions, with no immediately clear dependence relationship between different purposes such as List Movies At Theater and List Phone Number For Theater.
Reference: [106] <author> M. Walker. </author> <title> Limited attention and discourse structure. </title> <journal> Computational Linguistics, </journal> <volume> 22(2) </volume> <pages> 255-264, </pages> <year> 1996. </year>
Reference-contexts: One alternative to the stack based approach is linear recency. In a linear recency model, the meaning and intention of a sentence can be interpreted by a backward linear search in the discourse history <ref> [106] </ref>. The rest of the chapter is organized as follows. Firstly, we describe how we annotated a corpus 190 transcriptions with communicative act labels and segment labels. Secondly, we analyze turn transitions within segments using a probabilistic finite state model, and we discuss strengths and weaknesses of the model.
Reference: [107] <author> M. Walker and J.D. Moore. </author> <title> Empirical studies in discourse. </title> <booktitle> Computational Linguistics, </booktitle> <address> 23(1):112, </address> <year> 1997. </year>
Reference-contexts: Because discourse segment structure is such a controversial issue, it is necessary to conduct empirical studies that test linguistic theories against annotated corpora. With the help of properly annotated data, researchers understand may the regular and the variable aspects of the linguistic phenomena under investigation <ref> [107] </ref>. This thesis takes this approach, by annotating and analyzing hundreds of conversation transcriptions with their discourse segment structure. For a corpus to be truly useful, it must be properly annotated. <p> We have assessed inter-coder agreement using the metrics of precision, recall and the kappa coefficient. The reliability results are competitive with other published work on discourse segmentation <ref> [107, 41, 45, 80, 16] </ref>, and lend empirical support to the notion that discourse segmentation can be done as reliably as annotating other types of discourse units, such as communicative acts. <p> Whereas the reliability of annotating phonological, syntactic and intonation units in sentences has been extensively studied [54, 64, 96], a discussion of the issues in annotating discourse units in dialogue has only begun to emerge in last three years <ref> [107, 16, 28] </ref>. In the rest of this chapter, we define the concept of discourse segment structure and we compare it to other proposed units of discourse analysis. <p> Agreed upon units include phonemes and phonetic variants [25], intonation labels [96], and syntactic parse trees [64]. In contrast, reliability studies in discourse analysis have explored more specific contexts <ref> [27, 72, 107, 59, 15] </ref>. <p> In general, the val <p>- 47 ues reported in the table indicate that this is an emerging, rather than established, research field in computational linguistics (e.g., <ref> [107] </ref>).
Reference: [108] <author> T. Winograd and F. Flores. </author> <title> Understanding Computers and Cognition: A New Fundation For Design. </title> <publisher> Ablex Publishing Co, </publisher> <address> Northwood, NJ, </address> <year> 1986. </year>
Reference-contexts: Examples of structural models are finite state machines, transition networks and context-free grammars. They are rooted in syntactic and semantic analysis of sentences. In analogy with syntactic models for individual sentences, structural models have been proposed to model the observed sequence of communicative acts in natural spoken dialogue <ref> [97, 65, 108] </ref>. Using a grammar-based approach has been motivated by the observation that sequences of communicative acts tend to appear in adjacency pairs such as Statement- Acknowledgment and Question-Answer [91]. <p> Using a grammar-based approach has been motivated by the observation that sequences of communicative acts tend to appear in adjacency pairs such as Statement- Acknowledgment and Question-Answer [91]. Finite state machines and context-free grammars have been used to model graphical user interfaces [76], typed natural language interfaces <ref> [108, 29] </ref> and spoken language interfaces [4, 8, 18, 70].
Reference: [109] <author> P.H. Winston. </author> <booktitle> Artificial Intelligence (Third Edition). </booktitle> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1992. </year>
Reference-contexts: In this model, intentions and purposes are encoded explicitly a priori by one or more of the atomic conditions. In contrast, inference models such as Artimis's system apply first-order predicate calculus, which is a more complex computational model <ref> [109, 74] </ref>. First- order logic inference allows one to deduct the truth value of predicates such as the speaker's beliefs, intentions and purposes from other related predicates that encode the meaning of a sentence, by way of automated reasoning.
Reference: [110] <author> N. Yankelovich. </author> <title> How do users know what to say? ACM Interactions, </title> <type> 3(6), </type> <year> 1996. </year>
Reference-contexts: While a machine may apply the same principles of co-operative behavior as a human agent, many dialogue system designers argue that it may more appropriate to employ more explicit prompts and feedback responses <ref> [7, 40, 110, 12, 30] </ref>.
Reference: [111] <author> N. Yankelovich. </author> <title> Using natural dialogs as the basis for speech interface design. In Susan Luperfoy, editor, Automated Spoken Dialog Systems, </title> <address> Cambridge, MA, 1998. </address> <publisher> MIT Press. </publisher>
Reference: [112] <author> V. Zue. </author> <title> Conversational interfaces: </title> <booktitle> advances and challenges. In Proc. </booktitle> <address> Euroospeech-97, pages KN-9-KN-18. Rhodes, Greece, </address> <month> September </month> <year> 1997. </year> <month> 152 </month>
Reference-contexts: In contrast, a conversational system is designed to conduct a dialogue in which moves can be initiated by either the user or the system, using a large vocabulary and syntactic constructs that are more similar to everyday conversation <ref> [112] </ref>. Designing conversational applications is challenging for at least three reasons. Firstly, the design should incorporate gracious and quick recovery from the inevitable speech recognition errors and natural language misunderstandings. Secondly, speech is an ephemeral medium. <p> To overcome these challenges, the design of better spoken applications may be based on analyses of human-to-human dialogues <ref> [112, 7] </ref>. However, designing user interfaces based on human-to-human interaction is a controversial issue. In a debate between direct manipulation vs. interface agents, B. Schneiderman stated ([95], page 56): 16 I am concerned about the confusion of human and machine capa-bilities.
References-found: 112

