URL: http://www.cs.utexas.edu/users/pclark/papers/newcn.ps
Refering-URL: http://www.cs.utexas.edu/users/pclark/papers/newcn.abs.html
Root-URL: 
Title: Rule Induction with CN2: Some Recent Improvements  
Author: Peter Clark and Robin Boswell 
Keyword: learning, rule induction, CN2, Laplace, noise  
Address: 36 N.Hanover St., Glasgow  
Affiliation: The Turing Institute,  
Note: In: Machine Learning Proceedings of the Fifth European Conference (EWSL-91), pp151-163, Ed: Yves Kodratoff, Berlin: Springer-Verlag, (1991)  
Email: email: fpete,robing@turing.ac.uk  
Web: http://www.cs.utexas.edu/users/pclark/papers/newcn.ps  
Abstract: The CN2 algorithm induces an ordered list of classification rules from examples using entropy as its search heuristic. In this short paper, we describe two improvements to this algorithm. Firstly, we present the use of the Laplacian error estimate as an alternative evaluation function and secondly, we show how unordered as well as ordered rules can be generated. We experimentally demonstrate significantly improved performances resulting from these changes, thus enhancing the usefulness of CN2 as an inductive tool. Comparisons with Quinlan's C4.5 are also made. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Buntine, W. and Niblett, T. </author> <title> A further comparison of splitting rules for decision-tree induction. </title> <note> (Submitted to the Machine Learning Journal), </note> <year> 1990. </year>
Reference: <author> Cestnik, B. </author> <title> Estimating probabilities: A crucial task in machine learning. </title> <booktitle> In ECAI-90, </booktitle> <year> 1990. </year>
Reference: <author> Cestnik, B. and Bratko, I. </author> <title> Learning redundant rules in noisy domains. </title> <editor> In Kodratoff, Y., editor, </editor> <booktitle> ECAI-88, </booktitle> <pages> pages 348-350, </pages> <address> London, </address> <publisher> Pitman, </publisher> <year> 1988. </year>
Reference: <author> Cestnik, B. and Bratko, I. </author> <title> On estimating probabilities in tree pruning. </title> <editor> In Kodratoff, Y., editor, </editor> <booktitle> Proc. </booktitle> <address> EWSL-91, </address> <year> 1991. </year>
Reference: <author> Clark, P. and Niblett, T. </author> <title> Induction in noisy domains. </title> <editor> In Bratko, I. and Lavrac, N., editors, </editor> <booktitle> Progress in Machine Learning (proceedings of the 2nd European Working Session on Learning), </booktitle> <address> Sigma, Wilmslow, UK, </address> <year> 1987. </year>
Reference: <author> Clark, P. and Niblett, T. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning Journal, </journal> <volume> 3(4) </volume> <pages> 261-283, </pages> <year> 1989. </year>
Reference: <author> Gams, M. </author> <title> New measurements highlight the importance of redundant knowledge. </title> <editor> In Morik, K., editor, </editor> <booktitle> EWSL-89, </booktitle> <pages> pages 71-79, </pages> <address> London, </address> <publisher> Pitman, </publisher> <year> 1989. </year>
Reference: <author> Gams, M., Bohanec, M., and Cestnik, B. </author> <title> A schema for using multiple knowledge. </title> <note> (submitted to IJCAI-91), </note> <year> 1991. </year>
Reference: <editor> Hayes-Michie, J. E., editor Pragmatica: </editor> <booktitle> Bulletin of the Inductive Programming Special Interest Group, </booktitle> <volume> volume 1. </volume> <publisher> Turing Institute Press, </publisher> <address> Glasgow, UK, </address> <year> 1990. </year>
Reference: <author> Leech, W. J. </author> <title> A rule-based process control method with feedback. </title> <booktitle> Advances in Instrumentation, </booktitle> <volume> 41 </volume> <pages> 169-175, </pages> <year> 1986. </year>
Reference: <author> Michalski, R., Mozetic, I., Hong, J., and Lavrac, N. </author> <title> The multi-purpose incremental learning system AQ15 and its testing application to three medical domains. </title> <booktitle> In AAAI-86, </booktitle> <volume> volume 2, </volume> <pages> pages 1041-1045, </pages> <address> Ca. </address> <publisher> Kaufmann, </publisher> <year> 1986. </year>
Reference: <author> Niblett, T. </author> <title> Constructing decision trees in noisy domains. </title> <editor> In Bratko, I. and Lavrac, N., editors, </editor> <booktitle> Progress in Machine Learning (proceedings of the 2nd European Working Session on Learning), </booktitle> <pages> pages 67-78. </pages> <address> Sigma, Wilmslow, UK, </address> <year> 1987. </year>
Reference: <author> Quinlan, J. R. </author> <title> Simplifying decision trees. </title> <journal> Int. Journal of Man-Machine Studies, </journal> <volume> 27(3) </volume> <pages> 221-234, </pages> <year> 1987. </year>
Reference: <author> Quinlan, J. R., Compton, P. J., Horn, K. A., and Lazarus, L. </author> <title> Inductive knowledge acquisition: a case study. </title> <booktitle> In Applications of Expert Systems, </booktitle> <pages> pages 157-173, </pages> <publisher> Addison-Wesley, </publisher> <address> Wokingham, UK, </address> <year> 1987. </year>
Reference: <author> Rivest, R. L. </author> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2(3) </volume> <pages> 229-246, </pages> <year> 1987. </year>

References-found: 15

