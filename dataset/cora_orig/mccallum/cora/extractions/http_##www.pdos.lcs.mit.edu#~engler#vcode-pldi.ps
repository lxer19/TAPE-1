URL: http://www.pdos.lcs.mit.edu/~engler/vcode-pldi.ps
Refering-URL: http://www.cs.washington.edu/research/projects/unisw/DynComp/www/Related/papers.html
Root-URL: 
Email: engler@lcs.mit.edu  
Title: VCODE: A Retargetable, Extensible, Very Fast Dynamic Code Generation System  
Author: Dawson R. Engler 
Address: Cambridge, MA 02139  
Affiliation: Laboratory for Computer Science Massachusetts Institute of Technology  
Abstract: Unfortunately, previous general-purpose dynamic code generation systems have been either inefficient or non-portable. We present VCODE, a retargetable, extensible, very fast dynamic code generation system. An important feature of VCODE is that it generates machine code in-place without the use of intermediate data structures. Eliminating the need to construct and consume an intermediate representation at runtime makes VCODE both efficient and extensible. VCODE dynamically generates code at an approximate cost of six to ten instructions per generated instruction, making it over an order of magnitude faster than the most efficient general-purpose code generation system in the literature [10]. Dynamic code generation is relatively well known within the compiler community. However, due in large part to the lack of a publicly available dynamic code generation system, it has remained a curiosity rather than a widely used technique. A practical contribution of this work is the free, unrestricted distribution of the VCODE system, which currently runs on the MIPS, SPARC, and Alpha architectures. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. L. Bailey, B. Gopal, M. A. Pagels, L. L. Peterson, and P. Sarkar. PATHFINDER: </author> <title> A pattern-based packet classifier. </title> <booktitle> In Proceedings of the First Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 115-123, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Table 2: Core VCODE instructions. typedef int (fliptr)(int); /fl Called at runtime to create a function which returns its argument + 1. fl/ iptr mkplus1 (struct v code flip) v reg arg <ref> [1] </ref>; /fl Begin code generation. The type string ("%i") indicates that this routine takes a single integer (i) argument; the register to hold this argument is returned in arg [0]. <p> Furthermore, since DPF knows at code-generation time whether keys have collided, it can eliminate collision checks if no collisions have occurred. We measure DPF's time to classify packets destined for one of ten TCP/IP filters, and compare its time to measurements for PATHFINDER <ref> [1] </ref>, the fastest packet filter engine in the literature, and MPF [24], a widely used packet filter engine. To ensure that the comparison is meaningful, we perform the same experiment described in [1]: the average of 100,000 trials is taken as the base cost of message classification. <p> to classify packets destined for one of ten TCP/IP filters, and compare its time to measurements for PATHFINDER <ref> [1] </ref>, the fastest packet filter engine in the literature, and MPF [24], a widely used packet filter engine. To ensure that the comparison is meaningful, we perform the same experiment described in [1]: the average of 100,000 trials is taken as the base cost of message classification. Table 3 presents the time to perform this message classification. This experiment is more fully described in [8]. In this experiment, DPF is 20 times faster than MPF and 10 times faster than PATHFINDER.
Reference: [2] <author> C. Chambers and D. Ungar. </author> <title> Customization: Optimizing com piler technology for SELF, a dynamically-typed object-oriented programming language. </title> <booktitle> In Proceedings of PLDI '89, </booktitle> <pages> pages 146-160, </pages> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Request Permissions from Publications Dept, ACM Inc., Fax +1 (212) 869-0481, or &lt;permissions@acm.org&gt;. well-known applications of dynamic code generation is by interpreters that compile frequently used code to machine code and then execute it directly <ref> [2, 6, 8, 13] </ref>. Hardware simulators and binary emulators can use the same techniques to dynamically translate simulated instructions to the instructions of the underlying machine [4, 22, 23]. <p> Finally, we conclude in Section 7. 2 Related Work Dynamic code generation has a long history. It has been used to increase the performance of operating systems [20], window-ing operations [18], dynamically typed languages <ref> [2, 13, 6] </ref>, simulators [23] and matrix manipulations [10]. In [14], Kep-pel, Eggers and Henry survey many advantageous uses for dynamic code generation. ParcPlace sells an implementation of Smalltalk-80 that uses a dynamic code generator for SPARC, Motorola 68k, PowerPC, Intel x86, and other architectures. <p> For instance, tcc uses the same VCODE generation backend on the two architectures it supports (MIPS and SPARC). 4.2 DPF There have been many interpreters that dynamically compile frequently used code at runtime <ref> [2, 4, 6, 13, 22, 23] </ref>. In a similar vein, we used VCODE as a dynamic compiler for a packet-filter message demultiplexer [8, 9]. Message demultiplexing is the process of determining which application an incoming message should be delivered to.
Reference: [3] <author> D. D. Clark and D. L. Tennenhouse. </author> <title> Architectural considera tions for a new generation of protocols. </title> <booktitle> In ACM Communication Architectures, Protocols, and Applications (SIGCOMM) 1990, </booktitle> <month> September </month> <year> 1990. </year>
Reference-contexts: VCODE has been used as part of the ASH system to provide support for dynamic and efficient modular composition of network protocols. Modular composition of different network protocols has long been a goal in the networking community <ref> [3] </ref>. Unfortunately, modular composition is expensive. The problem it presents is that each protocol layer frequently has data-touching operations associated with it (e.g., to perform checksumming or byte swapping). Each operation typically touches all (or most) bytes in a message. <p> Each operation typically touches all (or most) bytes in a message. Separating these operations into modular pieces has meant that data is manipulated multiple times. As a result, modularity has exacted a high performance penalty <ref> [3] </ref>, both because many excess scalar operations are performed (e.g., looping overhead) and because touching memory multiple times stresses the weak link in modern workstations, the memory subsystem.
Reference: [4] <author> R. F. Cmelik and D. Keppel. Shade: </author> <title> A fast instruction-set simula tor for execution profiling. </title> <booktitle> In Proceedings of the 1994 ACM SIG-METRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 128-137, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Hardware simulators and binary emulators can use the same techniques to dynamically translate simulated instructions to the instructions of the underlying machine <ref> [4, 22, 23] </ref>. Runtime partial evaluation also uses dynamic code generation in order to propagate run-time constants to feed optimizations such as strength reduction, dead-code elimination, and constant folding [7, 20]. Unfortunately, portability and functionality barriers limit the use of dynamic code generation. <p> For instance, tcc uses the same VCODE generation backend on the two architectures it supports (MIPS and SPARC). 4.2 DPF There have been many interpreters that dynamically compile frequently used code at runtime <ref> [2, 4, 6, 13, 22, 23] </ref>. In a similar vein, we used VCODE as a dynamic compiler for a packet-filter message demultiplexer [8, 9]. Message demultiplexing is the process of determining which application an incoming message should be delivered to.
Reference: [5] <author> C. Consel and F. Noel. </author> <title> A general approach for run-time spe cialization and its application to C. </title> <booktitle> In Proceedings of the 23th Annual Symposium on Principles of Programming Languages, </booktitle> <address> St. Petersburg, FL, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: Also, VCODE's low-level nature allows greater control over low-level details (calling conventions, register names, etc.). VCODE is a manual code generation system. An alternative approach is to dynamically generate code automatically <ref> [5, 15, 16] </ref>. While an automatic system can be easier to use, it does require complex compiler support and can be less applicable than a manual system. The reason for reduced applicability is that automatic systems are primarily users of dynamic code generation rather than providers of it. <p> For instance, clients can use VCODE to dynamically generate functions (and function calls) that take an arbitrary number and type of arguments, allowing them to construct efficient argument marshaling and unmarshaling code [7]. It does not seem possible to efficiently perform such operations with current automatic systems <ref> [5, 15, 16] </ref>. Leone and Lee [15] describe an interesting automatic dynamic code generation system that performs compile-time specialization of a primitive functional language. Recently, they have extended their compiler, FABIUS, to accept a functional subset of ML [16]. <p> As a result, VCODE can be used, practically speaking, in more arenas than FABIUS (e.g., in the context of a pointer and side-effect rich language such as C). Another interesting automatic code generation system is Tempo <ref> [5] </ref>, a general-purpose dynamic specializer for C. Tempo can be easier to use than VCODE, but like other automatic systems, it requires complex compiler support and can be less applicable.
Reference: [6] <author> P. Deutsch and A.M. Schiffman. </author> <title> Efficient implementation of the Smalltalk-80 system. </title> <booktitle> In Proceedings of 11th POPL, </booktitle> <pages> pages 297-302, </pages> <address> Salt Lake City, UT, </address> <month> January </month> <year> 1984. </year>
Reference-contexts: Request Permissions from Publications Dept, ACM Inc., Fax +1 (212) 869-0481, or &lt;permissions@acm.org&gt;. well-known applications of dynamic code generation is by interpreters that compile frequently used code to machine code and then execute it directly <ref> [2, 6, 8, 13] </ref>. Hardware simulators and binary emulators can use the same techniques to dynamically translate simulated instructions to the instructions of the underlying machine [4, 22, 23]. <p> Finally, we conclude in Section 7. 2 Related Work Dynamic code generation has a long history. It has been used to increase the performance of operating systems [20], window-ing operations [18], dynamically typed languages <ref> [2, 13, 6] </ref>, simulators [23] and matrix manipulations [10]. In [14], Kep-pel, Eggers and Henry survey many advantageous uses for dynamic code generation. ParcPlace sells an implementation of Smalltalk-80 that uses a dynamic code generator for SPARC, Motorola 68k, PowerPC, Intel x86, and other architectures. <p> For instance, tcc uses the same VCODE generation backend on the two architectures it supports (MIPS and SPARC). 4.2 DPF There have been many interpreters that dynamically compile frequently used code at runtime <ref> [2, 4, 6, 13, 22, 23] </ref>. In a similar vein, we used VCODE as a dynamic compiler for a packet-filter message demultiplexer [8, 9]. Message demultiplexing is the process of determining which application an incoming message should be delivered to.
Reference: [7] <author> D. R. Engler, W. C. Hsieh, and M. F. Kaashoek. </author> <title> `C: A language for high-level, efficient, and machine-independent dynamic code generation. </title> <booktitle> In Proceedings of the 22th Annual Symposium on Principles of Programming Languages, </booktitle> <year> 1995. </year>
Reference-contexts: Runtime partial evaluation also uses dynamic code generation in order to propagate run-time constants to feed optimizations such as strength reduction, dead-code elimination, and constant folding <ref> [7, 20] </ref>. Unfortunately, portability and functionality barriers limit the use of dynamic code generation. Because binary instructions are generated, programs using dynamic code generation must be retargeted for each machine. <p> Engler and Proebsting [10] describe DCG, a general-purpose dynamic code generation system. VCODE grew out of my experiences building DCG and the subsequent use of DCG in building a compiler for the `C language <ref> [7] </ref>. Compared to DCG, VCODE is both substantially simpler and approximately 35 times faster. Both of these benefits come from eschewing an intermediate representation during code generation; in contrast, DCG builds and consumes IR-trees at runtime. VCODE also provides an extensible framework and generates more efficient code than DCG. <p> Both of these benefits come from eschewing an intermediate representation during code generation; in contrast, DCG builds and consumes IR-trees at runtime. VCODE also provides an extensible framework and generates more efficient code than DCG. Engler, Hsieh, and Kaashoek <ref> [7] </ref> describe the language `C (tick C), a superset of ANSI C that is designed for the high-level, efficient, and machine-independent specification of dynamically generated code. Their implementation uses the DCG dynamic code generation system that, as we described above, is both substantially less efficient and more complex than VCODE. <p> In contrast, VCODE clients control code generation and can create arbitrary code at runtime. For instance, clients can use VCODE to dynamically generate functions (and function calls) that take an arbitrary number and type of arguments, allowing them to construct efficient argument marshaling and unmarshaling code <ref> [7] </ref>. It does not seem possible to efficiently perform such operations with current automatic systems [5, 15, 16]. Leone and Lee [15] describe an interesting automatic dynamic code generation system that performs compile-time specialization of a primitive functional language.
Reference: [8] <author> D. R. Engler, M. F. Kaashoek, and J. O'Toole Jr. Exokernel: </author> <title> an operating system architecture for application-specific resource management. </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: Request Permissions from Publications Dept, ACM Inc., Fax +1 (212) 869-0481, or &lt;permissions@acm.org&gt;. well-known applications of dynamic code generation is by interpreters that compile frequently used code to machine code and then execute it directly <ref> [2, 6, 8, 13] </ref>. Hardware simulators and binary emulators can use the same techniques to dynamically translate simulated instructions to the instructions of the underlying machine [4, 22, 23]. <p> Fortunately, stack architectures are relatively rare. 4 Experimental Clients We discuss three experimental clients. The first client is a compiler for the `C language that demonstrates VCODE's viability as a code generation substrate [19]. The last two are network subsystems within the Aegis exokernel operating system <ref> [8] </ref>. <p> In a similar vein, we used VCODE as a dynamic compiler for a packet-filter message demultiplexer <ref> [8, 9] </ref>. Message demultiplexing is the process of determining which application an incoming message should be delivered to. Packet filters are a well-known technique used to implement extensible kernel demultiplexing [17]. <p> As a result, most high-performance networking systems do not use them, despite the flexibility and extensibility they provide. To remedy this situation, we have implemented Dynamic Packet Filters (DPF), a new packet filter system that is over an order of magnitude more efficient than previous systems <ref> [8, 9] </ref>. The key to our approach is dynamic code generation. <p> To ensure that the comparison is meaningful, we perform the same experiment described in [1]: the average of 100,000 trials is taken as the base cost of message classification. Table 3 presents the time to perform this message classification. This experiment is more fully described in <ref> [8] </ref>. In this experiment, DPF is 20 times faster than MPF and 10 times faster than PATHFINDER. <p> The bulk of this performance improvement is due to the use of dynamic code generation, 4.3 ASHs ASHs are user message handlers that are safely downloaded into the operating system kernel in order to direct message processing <ref> [8] </ref>. VCODE has been used as part of the ASH system to provide support for dynamic and efficient modular composition of network protocols. Modular composition of different network protocols has long been a goal in the networking community [3]. Unfortunately, modular composition is expensive. <p> It has proved to be a useful tool and has performed well in demanding situations. For instance, the DPF system we described earlier in the paper is used as the packet filter system for the Aegis exokernel operating system <ref> [8] </ref>. A nice practical feature of VCODE is that its complexity is mostly horizontal rather than vertical: each additional piece of the VCODE system usually does not depend on others. As a result, each extension increases the number of system states roughly additively rather than multiplicatively. <p> VCODE is not a toy system. We have used it extensively in the networking subsystem of our experimental exokernel operating system <ref> [8] </ref> and as a compiler backend for an extension of ANSI C that supports dynamic code generation. VCODE both generates code efficiently and generates efficient code. Its interface and abilities make it useful for a broad class of clients.
Reference: [9] <author> D. R. Engler, D. Wallach, and M. F. Kaashoek. </author> <title> Efficient, safe, application-specific message processing. Technical Memorandum MIT/LCS/TM533, </title> <publisher> MIT, </publisher> <month> March </month> <year> 1995. </year>
Reference-contexts: In a similar vein, we used VCODE as a dynamic compiler for a packet-filter message demultiplexer <ref> [8, 9] </ref>. Message demultiplexing is the process of determining which application an incoming message should be delivered to. Packet filters are a well-known technique used to implement extensible kernel demultiplexing [17]. <p> As a result, most high-performance networking systems do not use them, despite the flexibility and extensibility they provide. To remedy this situation, we have implemented Dynamic Packet Filters (DPF), a new packet filter system that is over an order of magnitude more efficient than previous systems <ref> [8, 9] </ref>. The key to our approach is dynamic code generation. <p> Second, it is used to compose multiple data processing steps dynamically into a single specialized data copying loop generated at runtime. This system is described and measured in <ref> [9] </ref>. Table 4 shows the performance benefit of integrating checksumming and byte swapping routines into the copying loop from a network buffer to an application's memory. Measurements are taken both when the data is in the cache and when it has been flushed.
Reference: [10] <author> D.R. Engler and T.A. Proebsting. </author> <title> DCG: An efficient, retargetable dynamic code generation system. </title> <booktitle> Proceedings of ASPLOS-VI, </booktitle> <pages> pages 263-272, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Finally, we conclude in Section 7. 2 Related Work Dynamic code generation has a long history. It has been used to increase the performance of operating systems [20], window-ing operations [18], dynamically typed languages [2, 13, 6], simulators [23] and matrix manipulations <ref> [10] </ref>. In [14], Kep-pel, Eggers and Henry survey many advantageous uses for dynamic code generation. ParcPlace sells an implementation of Smalltalk-80 that uses a dynamic code generator for SPARC, Motorola 68k, PowerPC, Intel x86, and other architectures. <p> ParcPlace sells an implementation of Smalltalk-80 that uses a dynamic code generator for SPARC, Motorola 68k, PowerPC, Intel x86, and other architectures. Unlike VCODE, their system is designed specifically for the compilation of Smalltalk-80, and not as a stand-alone system for dynamic code generation. Engler and Proebsting <ref> [10] </ref> describe DCG, a general-purpose dynamic code generation system. VCODE grew out of my experiences building DCG and the subsequent use of DCG in building a compiler for the `C language [7]. Compared to DCG, VCODE is both substantially simpler and approximately 35 times faster. <p> It generates machine code at an approximate cost of ten instructions per generated instruction, which is roughly 35 times faster than the fastest equivalent system in the literature <ref> [10] </ref>. It can be retargeted to RISC machines in approximately one to four days. Finally, it allows many levels of the system to be parameterized at runtime. VCODE provides a portable, idealized RISC instruction set to clients.
Reference: [11] <author> C. W. Fraser. </author> <title> A language for writing code generators. </title> <booktitle> In Proceed ings of the SIGPLAN '89 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 238-245, </pages> <year> 1989. </year>
Reference-contexts: Since the VCODE core is small and simple, mapping its instructions to their corresponding binary emitters is straightforward. To aid this process, we have developed a concise preprocessor specification language in the spirit of Fraser <ref> [11] </ref> that handles much of the details of this mapping. Complete mapping specifications for the MIPS, SPARC, and Alpha architectures take approximately 40-100 lines each. Finally, the construction of calling conventions and activation record management can typically be based on existing code.
Reference: [12] <author> C. W. Fraser and D. R. Hanson. </author> <title> A retargetable compiler for ANSI C. </title> <journal> SIGPLAN Notices, </journal> <volume> 26(10), </volume> <month> October </month> <year> 1991. </year>
Reference-contexts: This process has also been influenced by a number of compiler intermediate representations, the strongest influence being the intermediate representation language of the lcc compiler <ref> [12] </ref>. The instruction set is built from a set of base operations (e.g., sub, mul) that are composed with a set of types (e.g., integer, unsigned). Each instruction takes register or immediate operands and, usually, performs a simple operation on them.
Reference: [13] <author> U. H olzle and D. Ungar. </author> <title> Optimizing dynamically-dispatched calls with run-time type feedback. </title> <booktitle> In Proceedings of PLDI '94, </booktitle> <pages> pages 326-335, </pages> <address> Orlando, Florida, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Request Permissions from Publications Dept, ACM Inc., Fax +1 (212) 869-0481, or &lt;permissions@acm.org&gt;. well-known applications of dynamic code generation is by interpreters that compile frequently used code to machine code and then execute it directly <ref> [2, 6, 8, 13] </ref>. Hardware simulators and binary emulators can use the same techniques to dynamically translate simulated instructions to the instructions of the underlying machine [4, 22, 23]. <p> Finally, we conclude in Section 7. 2 Related Work Dynamic code generation has a long history. It has been used to increase the performance of operating systems [20], window-ing operations [18], dynamically typed languages <ref> [2, 13, 6] </ref>, simulators [23] and matrix manipulations [10]. In [14], Kep-pel, Eggers and Henry survey many advantageous uses for dynamic code generation. ParcPlace sells an implementation of Smalltalk-80 that uses a dynamic code generator for SPARC, Motorola 68k, PowerPC, Intel x86, and other architectures. <p> For instance, tcc uses the same VCODE generation backend on the two architectures it supports (MIPS and SPARC). 4.2 DPF There have been many interpreters that dynamically compile frequently used code at runtime <ref> [2, 4, 6, 13, 22, 23] </ref>. In a similar vein, we used VCODE as a dynamic compiler for a packet-filter message demultiplexer [8, 9]. Message demultiplexing is the process of determining which application an incoming message should be delivered to.
Reference: [14] <author> D. Keppel, S.J. Eggers, and R.R. Henry. </author> <title> A case for runtime code generation. </title> <type> TR 91-11-04, </type> <institution> Univ. of Washington, </institution> <year> 1991. </year>
Reference-contexts: Finally, we conclude in Section 7. 2 Related Work Dynamic code generation has a long history. It has been used to increase the performance of operating systems [20], window-ing operations [18], dynamically typed languages [2, 13, 6], simulators [23] and matrix manipulations [10]. In <ref> [14] </ref>, Kep-pel, Eggers and Henry survey many advantageous uses for dynamic code generation. ParcPlace sells an implementation of Smalltalk-80 that uses a dynamic code generator for SPARC, Motorola 68k, PowerPC, Intel x86, and other architectures.
Reference: [15] <author> M. Leone and P. Lee. </author> <title> Lightweight run-time code generation. </title> <booktitle> In Proceedings of the Workshop on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 97-106, </pages> <address> Copen-hagen, Denmark, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Also, VCODE's low-level nature allows greater control over low-level details (calling conventions, register names, etc.). VCODE is a manual code generation system. An alternative approach is to dynamically generate code automatically <ref> [5, 15, 16] </ref>. While an automatic system can be easier to use, it does require complex compiler support and can be less applicable than a manual system. The reason for reduced applicability is that automatic systems are primarily users of dynamic code generation rather than providers of it. <p> For instance, clients can use VCODE to dynamically generate functions (and function calls) that take an arbitrary number and type of arguments, allowing them to construct efficient argument marshaling and unmarshaling code [7]. It does not seem possible to efficiently perform such operations with current automatic systems <ref> [5, 15, 16] </ref>. Leone and Lee [15] describe an interesting automatic dynamic code generation system that performs compile-time specialization of a primitive functional language. Recently, they have extended their compiler, FABIUS, to accept a functional subset of ML [16]. <p> It does not seem possible to efficiently perform such operations with current automatic systems [5, 15, 16]. Leone and Lee <ref> [15] </ref> describe an interesting automatic dynamic code generation system that performs compile-time specialization of a primitive functional language. Recently, they have extended their compiler, FABIUS, to accept a functional subset of ML [16].
Reference: [16] <author> M. Leone and P. Lee. </author> <title> Optimizing ML with run-time code gen eration. </title> <booktitle> In Proceedings of the SIGPLAN '96 Conference on Programming Language Design and Implementation, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Also, VCODE's low-level nature allows greater control over low-level details (calling conventions, register names, etc.). VCODE is a manual code generation system. An alternative approach is to dynamically generate code automatically <ref> [5, 15, 16] </ref>. While an automatic system can be easier to use, it does require complex compiler support and can be less applicable than a manual system. The reason for reduced applicability is that automatic systems are primarily users of dynamic code generation rather than providers of it. <p> For instance, clients can use VCODE to dynamically generate functions (and function calls) that take an arbitrary number and type of arguments, allowing them to construct efficient argument marshaling and unmarshaling code [7]. It does not seem possible to efficiently perform such operations with current automatic systems <ref> [5, 15, 16] </ref>. Leone and Lee [15] describe an interesting automatic dynamic code generation system that performs compile-time specialization of a primitive functional language. Recently, they have extended their compiler, FABIUS, to accept a functional subset of ML [16]. <p> Leone and Lee [15] describe an interesting automatic dynamic code generation system that performs compile-time specialization of a primitive functional language. Recently, they have extended their compiler, FABIUS, to accept a functional subset of ML <ref> [16] </ref>. FABIUS generates code quickly by using techniques developed by programmers to dynamically generate code by hand: dynamic code is emitted by inline expanded macros that create instructions whose operand register names are determined at static compile time.
Reference: [17] <author> J.C. Mogul, R.F. Rashid, and M.J. Accetta. </author> <title> The packet filter: An efficient mechanism for user-level network code. </title> <booktitle> In Proceedings of the Eleventh ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 39-51, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: In a similar vein, we used VCODE as a dynamic compiler for a packet-filter message demultiplexer [8, 9]. Message demultiplexing is the process of determining which application an incoming message should be delivered to. Packet filters are a well-known technique used to implement extensible kernel demultiplexing <ref> [17] </ref>. A packet filter is a piece of user-level code downloaded into the kernel that is used to Filter Classification Time MPF 35.0 PATHFINDER 19.0 DPF 1.5 Table 3: Average time on a DEC5000/200 to classify TCP/IP headers destined for one of ten TCP/IP filters; times are in microseconds.
Reference: [18] <author> R. Pike, B.N. Locanthi, and J.F. Reiser. </author> <title> Hardware/software trade offs for bitmap graphics on the Blit. </title> <journal> SoftwarePractice and Experience, </journal> <volume> 15(2) </volume> <pages> 131-151, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Section 5 presents some key implementation details and Section 6 reports on our experiences using VCODE. Finally, we conclude in Section 7. 2 Related Work Dynamic code generation has a long history. It has been used to increase the performance of operating systems [20], window-ing operations <ref> [18] </ref>, dynamically typed languages [2, 13, 6], simulators [23] and matrix manipulations [10]. In [14], Kep-pel, Eggers and Henry survey many advantageous uses for dynamic code generation. ParcPlace sells an implementation of Smalltalk-80 that uses a dynamic code generator for SPARC, Motorola 68k, PowerPC, Intel x86, and other architectures.
Reference: [19] <author> M. Poletto, D. R. Engler, and M. F. Kaashoek. tcc: </author> <title> A template based compiler for `C. </title> <booktitle> In Workshop on Compiler Support for Systems Software, </booktitle> <address> Tucson, AZ, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: Their implementation uses the DCG dynamic code generation system that, as we described above, is both substantially less efficient and more complex than VCODE. Poletto, Engler, and Kaashoek <ref> [19] </ref> describe a reimplementation of `C that uses VCODE as its target machine. As a result, `C can automatically generate code for any architecture VCODE has been ported to, and gains the advantages of VCODE: fast code generation and efficient generated code. `C and VCODE are complementary. <p> Fortunately, stack architectures are relatively rare. 4 Experimental Clients We discuss three experimental clients. The first client is a compiler for the `C language that demonstrates VCODE's viability as a code generation substrate <ref> [19] </ref>. The last two are network subsystems within the Aegis exokernel operating system [8]. <p> Furthermore, since VCODE is portable, a compiler that compiles to it has the benefit of its generated code working on the machines that VCODE supports. We have implemented a `C compiler, tcc, that uses VCODE as an abstract machine to generate code dynamically <ref> [19] </ref>. As discussed in Section 2, `C is a superset of ANSI C that provides language constructs programmers can use to generate code at runtime.
Reference: [20] <author> C. Pu, H. Massalin, and J. Ioannidis. </author> <title> The Synthesis kernel. </title> <journal> Computing Systems, </journal> <volume> 1(1) </volume> <pages> 11-32, </pages> <year> 1988. </year>
Reference-contexts: Runtime partial evaluation also uses dynamic code generation in order to propagate run-time constants to feed optimizations such as strength reduction, dead-code elimination, and constant folding <ref> [7, 20] </ref>. Unfortunately, portability and functionality barriers limit the use of dynamic code generation. Because binary instructions are generated, programs using dynamic code generation must be retargeted for each machine. <p> Section 5 presents some key implementation details and Section 6 reports on our experiences using VCODE. Finally, we conclude in Section 7. 2 Related Work Dynamic code generation has a long history. It has been used to increase the performance of operating systems <ref> [20] </ref>, window-ing operations [18], dynamically typed languages [2, 13, 6], simulators [23] and matrix manipulations [10]. In [14], Kep-pel, Eggers and Henry survey many advantageous uses for dynamic code generation.
Reference: [21] <author> N. Ramsey and M. F. Fernandez. </author> <title> The New Jersey Machine-Code Toolkit. </title> <type> Technical Report 95-082, </type> <institution> Purdue University, Dept of Computer Sciences, </institution> <month> December </month> <year> 1995. </year> <note> Submitted to ACM Transactions on Programming Languages and Systems </note> . 
Reference-contexts: Because binary instructions are generated, programs using dynamic code generation must be retargeted for each machine. Generating binary instructions is non-portable, tedious, error-prone, and frequently the source of latent bugs due to boundary conditions (e.g., constants that don't fit in immediate fields) <ref> [21] </ref>. Many of the amenities of symbolic assemblers are not present, such as detection of scheduling hazards and linking of jumps to target addresses. <p> This low-level interface allows VCODE to generate machine code from client specifications at an approximate cost of six to ten instructions per generated instruction. This overhead is roughly equivalent to that of a highly tuned, non-portable dynamic code generator (or faster; compare <ref> [21] </ref>). Furthermore, the low-level instruc tion set can be used by clients to write portable VCODE that translates to high-quality code. <p> For example, the scope of Tempo's optimizations is limited by the usual challenges C presents to optimizing compilers (e.g., unrestricted aliasing). Ramsey and Fernandez have developed a tool kit for the concise specification of functions to emit and disassemble machine code <ref> [21] </ref>. Like VCODE, their system can be used to dynamically generate code quickly, is extensible, and is freely distributed. <p> Generating the code to emit binary instructions can be done using either VCODE's preprocessor or programs such as the New Jersey Toolkit <ref> [21] </ref>. Since the VCODE core is small and simple, mapping its instructions to their corresponding binary emitters is straightforward. To aid this process, we have developed a concise preprocessor specification language in the spirit of Fraser [11] that handles much of the details of this mapping.
Reference: [22] <author> M. Rosenblum, S. A. Herrod, E. Witchel, and A. Gupta. </author> <title> Complete computer simulation: The SimOS approach. </title> <booktitle> IEEE Parallel and Distributed Technology, </booktitle> <month> Fall </month> <year> 1995. </year>
Reference-contexts: Hardware simulators and binary emulators can use the same techniques to dynamically translate simulated instructions to the instructions of the underlying machine <ref> [4, 22, 23] </ref>. Runtime partial evaluation also uses dynamic code generation in order to propagate run-time constants to feed optimizations such as strength reduction, dead-code elimination, and constant folding [7, 20]. Unfortunately, portability and functionality barriers limit the use of dynamic code generation. <p> For instance, tcc uses the same VCODE generation backend on the two architectures it supports (MIPS and SPARC). 4.2 DPF There have been many interpreters that dynamically compile frequently used code at runtime <ref> [2, 4, 6, 13, 22, 23] </ref>. In a similar vein, we used VCODE as a dynamic compiler for a packet-filter message demultiplexer [8, 9]. Message demultiplexing is the process of determining which application an incoming message should be delivered to.
Reference: [23] <author> J.E. Veenstra and R.J. Fowler. MINT: </author> <title> a front end for efficient sim ulation of shared-memory multiprocessors. </title> <booktitle> In Modeling and Simulation of Computers and Telecommunications Systems, </booktitle> <year> 1994. </year>
Reference-contexts: Hardware simulators and binary emulators can use the same techniques to dynamically translate simulated instructions to the instructions of the underlying machine <ref> [4, 22, 23] </ref>. Runtime partial evaluation also uses dynamic code generation in order to propagate run-time constants to feed optimizations such as strength reduction, dead-code elimination, and constant folding [7, 20]. Unfortunately, portability and functionality barriers limit the use of dynamic code generation. <p> Finally, we conclude in Section 7. 2 Related Work Dynamic code generation has a long history. It has been used to increase the performance of operating systems [20], window-ing operations [18], dynamically typed languages [2, 13, 6], simulators <ref> [23] </ref> and matrix manipulations [10]. In [14], Kep-pel, Eggers and Henry survey many advantageous uses for dynamic code generation. ParcPlace sells an implementation of Smalltalk-80 that uses a dynamic code generator for SPARC, Motorola 68k, PowerPC, Intel x86, and other architectures. <p> For instance, tcc uses the same VCODE generation backend on the two architectures it supports (MIPS and SPARC). 4.2 DPF There have been many interpreters that dynamically compile frequently used code at runtime <ref> [2, 4, 6, 13, 22, 23] </ref>. In a similar vein, we used VCODE as a dynamic compiler for a packet-filter message demultiplexer [8, 9]. Message demultiplexing is the process of determining which application an incoming message should be delivered to.
Reference: [24] <author> M. Yahara, B. Bershad, C. Maeda, and E. Moss. </author> <title> Efficient packet demultiplexing for multiple endpoints and large messages. </title> <booktitle> In Proceedings of the Winter 1994 USENIX Conference, </booktitle> <year> 1994. </year>
Reference-contexts: We measure DPF's time to classify packets destined for one of ten TCP/IP filters, and compare its time to measurements for PATHFINDER [1], the fastest packet filter engine in the literature, and MPF <ref> [24] </ref>, a widely used packet filter engine. To ensure that the comparison is meaningful, we perform the same experiment described in [1]: the average of 100,000 trials is taken as the base cost of message classification. Table 3 presents the time to perform this message classification.
References-found: 24

