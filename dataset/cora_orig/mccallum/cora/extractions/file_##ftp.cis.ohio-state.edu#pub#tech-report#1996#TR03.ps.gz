URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1996/TR03.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Email: Email: ajayk@vnet.ibm.com  Email: singhal@cis.ohio-state.edu  
Phone: Phone: (919) 254-4370  Phone: (614)-292-5839  
Title: An Optimal Algorithm for Generalized Causal Message Ordering  
Author: Ajay D. Kshemkalyani P. O. Mukesh Singhal 
Keyword: Key Words: Causal message ordering, distributed systems, optimal, synchronization, concur rency.  
Address: C95A Bldg. 664  Box 12195  Triangle Park NC 27709  2015 Neil Avenue Columbus, OH 43210  
Affiliation: IBM Corporation Dept.  Research  Dept of Computer and Information Science The Ohio State University  
Abstract: This paper presents an optimal algorithm for enforcing causal message ordering. The algorithm works with non-FIFO channels and allows a process to multicast to arbitrary and dynamically changing process groups. The algorithm achieves optimality by transmitting the bare minimum causal dependency information and using an encoding scheme to represent and transmit this information. The algorithm is shown to be optimal both in space complexity of message overheads and in space complexity of message logs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ahamad, P. Hutto, R. John, </author> <title> Implementing and Programming Causal Distributed Memory, </title> <booktitle> Proc. of the 11th Intl. Conf. on Distrib. Comput. Sys., </booktitle> <pages> 274-281, </pages> <year> 1991. </year>
Reference-contexts: Note that the CO property is strictly stronger than the FIFO property. The concept of causal ordering is of considerable interest to the design of distributed systems and finds applications in several domains such as updates of replicated data [4], global state collection, distributed shared memory <ref> [1] </ref>, teleconferencing, multimedia systems, and fair resource allocation [6]. In an asynchronous distributed system, if there is no synchronous communication at the transport or lower layers, causal message ordering requires appending some control information with each message to enforce the causal order.
Reference: [2] <author> K. Birman, T. Joseph, </author> <title> Reliable Communication in Presence of Failures, </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 5(1), </volume> <pages> 47-76, </pages> <month> Feb. </month> <year> 1987. </year>
Reference-contexts: Asynchronous execution of processes and unpredictable communication delays create non-determinism in distributed systems that complicates the design, verification, and analysis of distributed programs. To simplify the design and development of distributed applications, the idea of "causal message ordering" was introduced by Birman and Joseph <ref> [2] </ref>. Definition 1 (Causal ordering (CO)): If for any two messages M and M 0 , Send (M ) ! Send (M 0 ) and M and M 0 have the same destination, then causal ordering ensures that Delivery (M ) ! Delivery (M 0 ). <p> The recipient process of a message uses this information to determine if there are undelivered messages that causally precede this message and delays the delivery of this message until all such messages have been delivered. Previous Work In the first ISIS system implementation of CO <ref> [2] </ref>, a message carries a history of all the messages that causally precede it. Due to redundant information, this scheme is resilient to processor crashes; however, a complex mechanism is required to prevent unbounded growth of the control information. In any case, the volume of control information can be huge. <p> Due to redundant information, this scheme is resilient to processor crashes; however, a complex mechanism is required to prevent unbounded growth of the control information. In any case, the volume of control information can be huge. The CO algorithm in [8] is similar to <ref> [2] </ref> but carries message-ids rather than entire messages in the control information. Furthermore, unnecessary control information is not sent if the sending host had sent it before.
Reference: [3] <author> K. Birman, A. Schiper, P. Stephenson, </author> <title> Lightweight Causal and Atomic Group Multicast, </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 9(3), </volume> <year> 1991, </year> <pages> 272-314. </pages>
Reference-contexts: Clearly, the message overhead of both algorithms [9, 10] is O (n 2 ). In the causal multicast in overlapping groups implementation of ISIS <ref> [3] </ref>, every process maintains a vector for every group whether it belongs to that group or not. A vector for a group informs the process of the number of messages multicast by the various members of the group.
Reference: [4] <author> T. Joseph, K. Birman, </author> <title> Low Cost Management of Replicated Data in Fault-Tolerant Distributed Systems, </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 4(1), </volume> <pages> 54-70, </pages> <year> 1986. </year>
Reference-contexts: Note that the CO property is strictly stronger than the FIFO property. The concept of causal ordering is of considerable interest to the design of distributed systems and finds applications in several domains such as updates of replicated data <ref> [4] </ref>, global state collection, distributed shared memory [1], teleconferencing, multimedia systems, and fair resource allocation [6]. In an asynchronous distributed system, if there is no synchronous communication at the transport or lower layers, causal message ordering requires appending some control information with each message to enforce the causal order.
Reference: [5] <author> A. Kshemkalyani, M. Singhal, </author> <title> Necessary and Sufficient Conditions on Information on Causal Message Ordering and Their Optimal Implementation, </title> <type> TR 29.2040, </type> <institution> IBM, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: M j;b sent to d can then be delivered to d before M i;a is, despite the Delivery Constraint, because M j;b does not carry "d 2 M i;a :Dests" with it. Thus, the Propagation Constraints and Delivery Conditions are required for CO. See <ref> [5] </ref> for a formal proof that any information must not exist in the causal future of its fixed points to achieve optimality. the propagation of information "6 2 M 5;1 :Dests" is curtailed. The flow of this information is depicted by thick arrows/lines. <p> The proofs of these properties are given in <ref> [5] </ref>. Lemma 1 states that for every sender node i, a destination node d belongs to l i;fl :Dests for at most one entry l i;fl in the log at any node. <p> The proof can be shown from the algorithm steps SND (2), SND (3), RCV (3), RCV (4), RCV (5). See <ref> [5] </ref> for the proof. Theorem 1 (Safety): d 2 M i;a :Dests V d 2 M j;b :Dests V Send (M i;a ) ! Send (M j;b ) V Delivered d (M j;b ) =) Delivered d (M i;a ). <p> Thus, the information is transmitted and stored only upto the fixed points ! This is the bare minimum that must be transmitted and stored for correctness as shown in Section 3. Thus, the algorithm is optimal. See <ref> [5] </ref> for a detailed proof. 2 9 6.1 Performance We compute the size of the control information sent as O M on a message M .
Reference: [6] <author> L. Lamport, </author> <title> Time, Clocks, and the Ordering of Events in a Distributed System, </title> <journal> Comm. of the ACM, </journal> <volume> 558-565, 21(7), </volume> <month> July </month> <year> 1978. </year>
Reference-contexts: An event at local time a on process i is denoted by (i; a). The cause and effect relationship is captured by Lamport's "happened before" relation (!) <ref> [6] </ref>, which defines a partial order on the events of a distributed execution. Asynchronous execution of processes and unpredictable communication delays create non-determinism in distributed systems that complicates the design, verification, and analysis of distributed programs. <p> The concept of causal ordering is of considerable interest to the design of distributed systems and finds applications in several domains such as updates of replicated data [4], global state collection, distributed shared memory [1], teleconferencing, multimedia systems, and fair resource allocation <ref> [6] </ref>. In an asynchronous distributed system, if there is no synchronous communication at the transport or lower layers, causal message ordering requires appending some control information with each message to enforce the causal order.
Reference: [7] <author> F. Mattern, </author> <title> Virtual Time and Global States of Distributed Systems, Parallel and Distrib. Algorithms, </title> <publisher> North-Holland, </publisher> <pages> 215-226, </pages> <year> 1989. </year>
Reference-contexts: This information represents messages sent in the causal past that are not known to be delivered. The receiving site uses vector time <ref> [7] </ref> to determine whether messages represented in the control vectors need to be delivered before the current message is delivered. The causal ordering algorithm of Raynal-Schiper-Toueg [9] attaches a matrix SEN T of size n fi n with every message.
Reference: [8] <author> L. L. Peterson, N. C. Buchholz, R. D. Schlichting, </author> <title> Preserving and Using Context Information in Interprocess Communication, </title> <journal> ACM Trans. on Comput. Sys.,7,217-246,1989. </journal>
Reference-contexts: Due to redundant information, this scheme is resilient to processor crashes; however, a complex mechanism is required to prevent unbounded growth of the control information. In any case, the volume of control information can be huge. The CO algorithm in <ref> [8] </ref> is similar to [2] but carries message-ids rather than entire messages in the control information. Furthermore, unnecessary control information is not sent if the sending host had sent it before.
Reference: [9] <author> M. Raynal, A. Schiper, S. Toueg, </author> <title> The Causal Ordering Abstraction and a Simple Way to Implement It, </title> <journal> Inf. Proc. Letters, </journal> <volume> 39(6), </volume> <pages> 343-350, </pages> <year> 1991. </year>
Reference-contexts: This information represents messages sent in the causal past that are not known to be delivered. The receiving site uses vector time [7] to determine whether messages represented in the control vectors need to be delivered before the current message is delivered. The causal ordering algorithm of Raynal-Schiper-Toueg <ref> [9] </ref> attaches a matrix SEN T of size n fi n with every message. SEN T [i; j] indicates the number of messages that are known to be sent by i to j. <p> The algorithm also uses an array DELIV of size n, where DELIV [i] is the number of messages from node i that have been delivered to the sender. Clearly, the message overhead of both algorithms <ref> [9, 10] </ref> is O (n 2 ). In the causal multicast in overlapping groups implementation of ISIS [3], every process maintains a vector for every group whether it belongs to that group or not.
Reference: [10] <author> A. Schiper, J. Eggli, A. Sandoz, </author> <title> A New Algorithm to Implement Causal Ordering, </title> <booktitle> Proc. 3rd Int. Workshop on Distrib. Algorithms, </booktitle> <year> 1989, </year> <pages> 219-232, </pages> <note> in LNCS 392, Springer-Verlag. 10 </note>
Reference-contexts: The CO algorithm in [8] is similar to [2] but carries message-ids rather than entire messages in the control information. Furthermore, unnecessary control information is not sent if the sending host had sent it before. The control information in the Schiper-Eggli-Sandoz CO algorithm <ref> [10] </ref> consists of n vectors of 1 The arrival of a message signifies that the communication network has placed the message in the buffer of the receiving process; Its delivery means that the process has taken up the message for processing 1 length upto n each. <p> The algorithm also uses an array DELIV of size n, where DELIV [i] is the number of messages from node i that have been delivered to the sender. Clearly, the message overhead of both algorithms <ref> [9, 10] </ref> is O (n 2 ). In the causal multicast in overlapping groups implementation of ISIS [3], every process maintains a vector for every group whether it belongs to that group or not.
References-found: 10

