URL: http://www.cs.pitt.edu/~gupta/research/Comp/loplas.ps
Refering-URL: http://www.cs.pitt.edu/~gupta/research/optimization.html
Root-URL: 
Title: Optimizing Array Bound Checks Using Flow Analysis  
Author: Rajiv Gupta 
Keyword: Categories and Subject Descriptors: D.2.5 [Software Engineering]: Testing and Debugging-error handling and recovery; D.3.4 [Programming Languages]: Processors-optimization, compilers. General Terms: Languages, Reliability Additional Key Words and Phrases: Data flow analysis, available checks, very busy checks, check hoisting  
Address: Pittsburgh  
Affiliation: University of  
Abstract: Bound checks are introduced in programs for the run-time detection of array bound violations. Compile-time optimizations are employed to reduce the execution time overhead due to bound checks. The optimizations reduce the program execution time through elimination of checks and propagation of checks out of loops. An execution of the optimized program terminates with an array bound violation if and only if the same outcome would have resulted during the execution of the program containing all array bound checks. However, the point at which the array bound violation occurs may not be the same. Experimental results indicate that the number of bound checks performed during the execution of a program is greatly reduced using these techniques. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Aho, A.V., Sethi, R., and Ullman, J.D. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1986. </year>
Reference-contexts: The elimination and propagation algorithms developed by Markstein et al [8] were developed in conjunction with a traditional code optimizer. In some situations their algorithms are able to benefit from the application of other code optimizations <ref> [1, 3, 10] </ref>. The algorithms described in this work do not rely on other code optimizations. However, their effectiveness can be enhanced by performing traditional optimizations. The analysis algorithms presented in this paper exploit semantic information that is not exploited by Markstein's algorithms.
Reference: 2. <author> Banerjee, U. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, Mas-sachusetts, </address> <year> 1988. </year>
Reference-contexts: In a compiler that parallelizes scientific programs we can take advantage of Banerjee's techniques for computing min and max for subscript expressions in nested loops <ref> [2] </ref>. Using this information bound checks may be moved out of a loop nest. In our approach checks can only be moved out of a loop nest one loop at a time.
Reference: 3. <author> Callahan, D., Cooper. K.D., Kennedy, K., and Torczon, L. </author> <title> Interprocedural constant propagation. </title> <booktitle> Proceedings 14th ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1986, </year> <pages> 152-161. </pages>
Reference-contexts: The elimination and propagation algorithms developed by Markstein et al [8] were developed in conjunction with a traditional code optimizer. In some situations their algorithms are able to benefit from the application of other code optimizations <ref> [1, 3, 10] </ref>. The algorithms described in this work do not rely on other code optimizations. However, their effectiveness can be enhanced by performing traditional optimizations. The analysis algorithms presented in this paper exploit semantic information that is not exploited by Markstein's algorithms.
Reference: 4. <author> Chow, F. </author> <title> A portable machine-independent global optimizer design and measurements. </title> <type> Technical Report 83-254, Ph.D. Thesis, </type> <institution> Computer Sytems Lab, Stanford University, </institution> <year> 1983. </year>
Reference-contexts: The overhead of these checks is quite high resulting in inefficient code with high execution times. Earlier investigations indicate that execution times for programs can double if run-time checks are performed <ref> [4] </ref>. This is true for both optimized and unoptimized code because traditional optimizations are ineffective in reducing the overhead due to array bound checks [4]. Most compilers allow the programmer to control the generation of run-time checks through a switch which is specified at compile-time. <p> Earlier investigations indicate that execution times for programs can double if run-time checks are performed <ref> [4] </ref>. This is true for both optimized and unoptimized code because traditional optimizations are ineffective in reducing the overhead due to array bound checks [4]. Most compilers allow the programmer to control the generation of run-time checks through a switch which is specified at compile-time. The programs are compiled with run-time checks only during the debugging phase. When the software is being used in a production environment it does not include run-time checks. <p> The results indicate that substantial reduction in the number of run-time checks results by applying bound check optimizations. As mentioned earlier, previous research has shown that similar results cannot be obtained through traditional optimizations <ref> [4] </ref>. Acknowledgement: The comments from the reviewers have been helpful in improving the algorithms and the presentation of the paper. In particular, observations of one reviewer resulted in the generalization of the algorithms. - 10 -
Reference: 5. <author> Gupta, R. </author> <title> A fresh look at optimizing array bound checking. </title> <booktitle> Proceedings ACM SIGPLAN'90 Conference on Programming Language Design and Implementation, </booktitle> <year> 1990, </year> <pages> 272-282. </pages>
Reference-contexts: Markstein's algorithm would not have eliminated the check i MAX (a ) before S 4 because it does not take advantage of modified checks. The elimination process described above is much more general than the algorithms described in previous work <ref> [5] </ref>. In the earlier version of this work modification of checks, which creates additional redundant checks, was not carried out. Thus, the propagation algorithms forward and backward developed in this paper are more general. <p> However, if the loop iterates more than once we are guaranteed that the number of checks executed after propagation will be lower. Since typically loops iterate more than once it is beneficial to perform propagation of such checks. In previous version of this work only identical checks were propagated <ref> [5] </ref>. Thus, the bound checks on variable i would not have been propagated out of the loop. Algorithm for Propagation: This algorithm first identifies the bound checks that are potential candidates for propagation.
Reference: 6. <author> Gupta, R. and Spezialetti, M. </author> <title> Loop monotonic computations: an approach for the efficient run-time detection of races. </title> <booktitle> Proceedings of the SIGSOFT Symposium on Testing, Analysis, and Verification, </booktitle> <year> 1991, </year> <pages> 98-111. </pages>
Reference-contexts: It is beneficial to take advantage of monotonic definitions because the definitions of variables used in subscript expressions are very often monotonic. In this work we use a simple approach for detecting monotonic definitions. A more general algorithm for detecting monotonic computations can be found in <ref> [6] </ref>. The affect of B on variable v is summarized by AFFECT (B ,v ) as shown below. Here v bef ore and v af ter denote the values of variable v before and after a block and c is a positive compile-time constant.
Reference: 7. <author> Harrison, W. </author> <title> Compiler analysis of the value ranges for variables. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 3, 3 (1977), </volume> <pages> 243-250. </pages>
Reference-contexts: Thus, certain bound checks optimized by our algorithms cannot be handled using Markstein's algorithms. Some important differences will be discussed in subsequent sections which describe our algorithms in detail. Harrison also used compile-time analysis to reduce the overhead due to bound checks in his work <ref> [7] </ref>. Compile-time techniques of range propagation and range analysis are employed yielding bounds on the values of variables at various points in a program. The range information is used to eliminate redundant bound checks on array subscripts.
Reference: 8. <author> Markstein, V., Cocke, J., and Markstein, P. </author> <title> Optimization of range checking. </title> <booktitle> Proceedings of SIGPLAN'82 Symposium on Compiler Construction, </booktitle> <year> 1982, </year> <pages> 114-119. </pages>
Reference-contexts: Next the bound check optimizations are described and algorithms to perform these optimizations are discussed in detail. Finally some experimental results demonstrating the effectiveness of the bound check optimizations are presented. - 2 - 2. Background Markstein et al <ref> [8] </ref> also treat the elimination and propagation of bound checks as an optimization problem. Their work provided the inspiration for this work and we use the same approach in this work. The elimination and propagation algorithms developed by Markstein et al [8] were developed in conjunction with a traditional code optimizer. <p> Background Markstein et al <ref> [8] </ref> also treat the elimination and propagation of bound checks as an optimization problem. Their work provided the inspiration for this work and we use the same approach in this work. The elimination and propagation algorithms developed by Markstein et al [8] were developed in conjunction with a traditional code optimizer. In some situations their algorithms are able to benefit from the application of other code optimizations [1, 3, 10]. The algorithms described in this work do not rely on other code optimizations. <p> MIN 1 f and MIN 2 f maximum (MIN 1 ,MIN 2 ) f f MAX 1 and f MAX 2 f minimum (MAX 1 ,MAX 2 ) The techniques developed by Markstein et al <ref> [8] </ref> use common subexpression elimination which can only eliminate identical checks. Their techniques cannot eliminate subsumed checks in the manner discussed above. It should be noted that the application of subsumption optimizations may cause an error to be reported at an earlier program point. <p> In the example of Fig. 10 the bound check on variable i is first hoisted to the beginning of the loop. Next the bound check is propagated out of the loop. The propagation algorithm proposed by Markstein et al <ref> [8] </ref> does not perform code hoisting. 4. Experimental Results and Conclusion The bound check optimizations were applied to a small set of programs. The programs were first profiled to determine the number of bound checks that would be performed at run-time if no optimization was carried out.
Reference: 9. <author> Suzuki, N. and Ishihata, K. </author> <title> Implementation of array bound checker. </title> <booktitle> Proceedings 4th ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1977, </year> <pages> 132-143. </pages>
Reference-contexts: Harrison's techniques will not be effective in the presence of dynamic arrays since value range analysis will not be effective. Suzuki and Ishihata discuss the implementation of a system that performs array bound checks on a program in <ref> [9] </ref>. The system creates logical assertions immediately before array element accesses that must be true for the program to be valid. These assertions are then proven, by a theorem prover, using techniques similar to inductive assertion methods.

Reference: 1. <author> A.V. Aho, R. Sethi, and J.D. Ullman, </author> <booktitle> Compilers: Principles, Techniques, and Tools, </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: The elimination and propagation algorithms developed by Markstein et al [8] were developed in conjunction with a traditional code optimizer. In some situations their algorithms are able to benefit from the application of other code optimizations <ref> [1, 3, 10] </ref>. The algorithms described in this work do not rely on other code optimizations. However, their effectiveness can be enhanced by performing traditional optimizations. The analysis algorithms presented in this paper exploit semantic information that is not exploited by Markstein's algorithms.
Reference: 2. <author> U. Banerjee, </author> <title> ``Dependence Analysis for Supercomputing,'' </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: In a compiler that parallelizes scientific programs we can take advantage of Banerjee's techniques for computing min and max for subscript expressions in nested loops <ref> [2] </ref>. Using this information bound checks may be moved out of a loop nest. In our approach checks can only be moved out of a loop nest one loop at a time.
Reference: 3. <author> D. Callahan, K.D. Cooper, K. Kennedy, and L. Torczon, </author> <title> ``Interprocedural Constant Propagation,'' </title> <booktitle> Proceedings 14th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 152-161, </pages> <year> 1986. </year>
Reference-contexts: The elimination and propagation algorithms developed by Markstein et al [8] were developed in conjunction with a traditional code optimizer. In some situations their algorithms are able to benefit from the application of other code optimizations <ref> [1, 3, 10] </ref>. The algorithms described in this work do not rely on other code optimizations. However, their effectiveness can be enhanced by performing traditional optimizations. The analysis algorithms presented in this paper exploit semantic information that is not exploited by Markstein's algorithms.
Reference: 4. <author> F. Chow, </author> <title> ``A Portable Machine-independent Global Optimizer Design and Measurements,'' </title> <type> Ph.D. Thesis, Technical Report 83-254, </type> <institution> Computer Sytems Lab, Stanford University, </institution> <month> Dec., </month> <year> 1983. </year>
Reference-contexts: The overhead of these checks is quite high resulting in inefficient code with high execution times. Earlier investigations indicate that execution times for programs can double if run-time checks are performed <ref> [4] </ref>. This is true for both optimized and unoptimized code because traditional optimizations are ineffective in reducing the overhead due to array bound checks [4]. Most compilers allow the programmer to control the generation of run-time checks through a switch which is specified at compile-time. <p> Earlier investigations indicate that execution times for programs can double if run-time checks are performed <ref> [4] </ref>. This is true for both optimized and unoptimized code because traditional optimizations are ineffective in reducing the overhead due to array bound checks [4]. Most compilers allow the programmer to control the generation of run-time checks through a switch which is specified at compile-time. The programs are compiled with run-time checks only during the debugging phase. When the software is being used in a production environment it does not include run-time checks. <p> The results indicate that substantial reduction in the number of run-time checks results by applying bound check optimizations. As mentioned earlier, previous research has shown that similar results cannot be obtained through traditional optimizations <ref> [4] </ref>. Acknowledgement: The comments from the reviewers have been helpful in improving the algorithms and the presentation of the paper. In particular, observations of one reviewer resulted in the generalization of the algorithms. - 10 -
Reference: 5. <author> R. Gupta, </author> <title> ``A Fresh Look at Optimizing Array Bound Checking,'' </title> <booktitle> ACM SIGPLAN'90 Conference on Programming Language Design and Implementation, </booktitle> <address> White Plains, New York, </address> <pages> pp. 272-282, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Markstein's algorithm would not have eliminated the check i MAX (a ) before S 4 because it does not take advantage of modified checks. The elimination process described above is much more general than the algorithms described in previous work <ref> [5] </ref>. In the earlier version of this work modification of checks, which creates additional redundant checks, was not carried out. Thus, the propagation algorithms forward and backward developed in this paper are more general. <p> However, if the loop iterates more than once we are guaranteed that the number of checks executed after propagation will be lower. Since typically loops iterate more than once it is beneficial to perform propagation of such checks. In previous version of this work only identical checks were propagated <ref> [5] </ref>. Thus, the bound checks on variable i would not have been propagated out of the loop. Algorithm for Propagation: This algorithm first identifies the bound checks that are potential candidates for propagation.
Reference: 6. <author> R. Gupta and M. Spezialetti, </author> <title> ``Loop Monotonic Computations: An Approach for the Efficient Run-time Detection of Races,'' </title> <booktitle> Proc. of the SIGSOFT Symposium on Testing, Analysis, and Verification, </booktitle> <address> Victoria, Canada, </address> <pages> pp. 98-111, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: It is beneficial to take advantage of monotonic definitions because the definitions of variables used in subscript expressions are very often monotonic. In this work we use a simple approach for detecting monotonic definitions. A more general algorithm for detecting monotonic computations can be found in <ref> [6] </ref>. The affect of B on variable v is summarized by AFFECT (B ,v ) as shown below. Here v bef ore and v af ter denote the values of variable v before and after a block and c is a positive compile-time constant.
Reference: 7. <author> W. Harrison, </author> <title> ``Compiler Analysis of the Value Ranges for Variables,'' </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 3, no. 3, </volume> <pages> pp. 243-250, </pages> <year> 1977. </year>
Reference-contexts: Thus, certain bound checks optimized by our algorithms cannot be handled using Markstein's algorithms. Some important differences will be discussed in subsequent sections which describe our algorithms in detail. Harrison also used compile-time analysis to reduce the overhead due to bound checks in his work <ref> [7] </ref>. Compile-time techniques of range propagation and range analysis are employed yielding bounds on the values of variables at various points in a program. The range information is used to eliminate redundant bound checks on array subscripts.
Reference: 8. <author> V. Markstein, J. Cocke, and P. Markstein, </author> <title> ``Optimization of Range Checking,'' </title> <booktitle> Proceedings of SIGPLAN'82 Symposium on Compiler Construction, </booktitle> <year> 1982. </year>
Reference-contexts: Next the bound check optimizations are described and algorithms to perform these optimizations are discussed in detail. Finally some experimental results demonstrating the effectiveness of the bound check optimizations are presented. - 2 - 2. Background Markstein et al <ref> [8] </ref> also treat the elimination and propagation of bound checks as an optimization problem. Their work provided the inspiration for this work and we use the same approach in this work. The elimination and propagation algorithms developed by Markstein et al [8] were developed in conjunction with a traditional code optimizer. <p> Background Markstein et al <ref> [8] </ref> also treat the elimination and propagation of bound checks as an optimization problem. Their work provided the inspiration for this work and we use the same approach in this work. The elimination and propagation algorithms developed by Markstein et al [8] were developed in conjunction with a traditional code optimizer. In some situations their algorithms are able to benefit from the application of other code optimizations [1, 3, 10]. The algorithms described in this work do not rely on other code optimizations. <p> MIN 1 f and MIN 2 f maximum (MIN 1 ,MIN 2 ) f f MAX 1 and f MAX 2 f minimum (MAX 1 ,MAX 2 ) The techniques developed by Markstein et al <ref> [8] </ref> use common subexpression elimination which can only eliminate identical checks. Their techniques cannot eliminate subsumed checks in the manner discussed above. It should be noted that the application of subsumption optimizations may cause an error to be reported at an earlier program point. <p> In the example of Fig. 10 the bound check on variable i is first hoisted to the beginning of the loop. Next the bound check is propagated out of the loop. The propagation algorithm proposed by Markstein et al <ref> [8] </ref> does not perform code hoisting. 4. Experimental Results and Conclusion The bound check optimizations were applied to a small set of programs. The programs were first profiled to determine the number of bound checks that would be performed at run-time if no optimization was carried out.
Reference: 9. <author> N. Suzuki and K. Ishihata, </author> <title> ``Implementation of Array Bound Checker,'' </title> <booktitle> Proceedings 4th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 132-143, </pages> <year> 1977. </year>
Reference-contexts: Harrison's techniques will not be effective in the presence of dynamic arrays since value range analysis will not be effective. Suzuki and Ishihata discuss the implementation of a system that performs array bound checks on a program in <ref> [9] </ref>. The system creates logical assertions immediately before array element accesses that must be true for the program to be valid. These assertions are then proven, by a theorem prover, using techniques similar to inductive assertion methods.
Reference: 10. <author> M.N. Wegman and F.K. Zadeck, </author> <title> ``Constant Propagation with Conditional Branches,'' </title> <booktitle> Proceedings 12th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 152-161, </pages> <year> 1984. </year>
Reference-contexts: The elimination and propagation algorithms developed by Markstein et al [8] were developed in conjunction with a traditional code optimizer. In some situations their algorithms are able to benefit from the application of other code optimizations <ref> [1, 3, 10] </ref>. The algorithms described in this work do not rely on other code optimizations. However, their effectiveness can be enhanced by performing traditional optimizations. The analysis algorithms presented in this paper exploit semantic information that is not exploited by Markstein's algorithms.
References-found: 19

