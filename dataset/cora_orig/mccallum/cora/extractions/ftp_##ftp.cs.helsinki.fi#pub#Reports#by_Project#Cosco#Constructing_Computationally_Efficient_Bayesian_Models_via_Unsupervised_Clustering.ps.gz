URL: ftp://ftp.cs.helsinki.fi/pub/Reports/by_Project/Cosco/Constructing_Computationally_Efficient_Bayesian_Models_via_Unsupervised_Clustering.ps.gz
Refering-URL: http://www.cs.helsinki.fi/~tirri/publications.html
Root-URL: 
Email: Petri.Myllymaki@cs.Helsinki.FI, Henry.Tirri@cs.Helsinki.FI  
Title: Constructing Computationally Efficient Bayesian Models via Unsupervised Clustering  Probabilistic Reasoning and Bayesian Belief Networks,  
Author: Petri Myllymaki and Henry Tirri 
Date: 1995.  
Note: Pp. 237-248 in  edited by A.Gammerman. Alfred Waller Publishers, Suffolk  
Address: P.O.Box 26, FIN-00014 University of Helsinki, FINLAND  
Affiliation: University of Helsinki, Department of Computer Science  
Abstract: Given a set of samples of an unknown probability distribution, we study the problem of constructing a good approximative Bayesian network model of the probability distribution in question. This task can be viewed as a search problem, where the goal is to find a maximal probability network model, given the data. In this work, we do not make an attempt to learn arbitrarily complex multi-connected Bayesian network structures, since such resulting models can be unsuitable for practical purposes due to the exponential amount of time required for the reasoning task. Instead, we restrict ourselves to a special class of simple tree-structured Bayesian networks called Bayesian prototype trees, for which a polynomial time algorithm for Bayesian reasoning exists. We show how the probability of a given Bayesian prototype tree model can be evaluated, given the data, and how this evaluation criterion can be used in a stochastic simulated annealing algorithm for searching the model space. The simulated annealing algorithm provably finds the maximal probability model, provided that a sufficient amount of time is used.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aarts, E., and Korst, J., </author> <title> Simulated Annealing and Boltzmann Machines: A Stochastic Approach to Combinatorial Optimization and Neural Computing. </title> <publisher> John Wiley & Sons, </publisher> <address> Chichester 1989. </address>
Reference-contexts: After being introduced to the optimization theory community in [14], simulated annealing has been applied to many different (NP-hard) optimization problems, such as TSP, graph partitioning, graph coloring, number set partitioning and clustering (for an extensive survey of applications, see <ref> [1, pp.89-90] </ref>). Unfortunately, the number of iterations for the theoretically guaranteed convergence is too high for practical purposes, but in many cases good results has been obtained even with a relatively small number of iterations [1]. <p> Unfortunately, the number of iterations for the theoretically guaranteed convergence is too high for practical purposes, but in many cases good results has been obtained even with a relatively small number of iterations <ref> [1] </ref>. Simulated annealing has also been used for implementing the reasoning computation in Bayesian networks [26]. However, as suggested in [5], in this work we use the simulated annealing algorithm for learning, i.e., finding a globally maximal probability Bayesian network model for our problem domain. <p> If the computational temperature T (t) is decreased slowly enough, the simulated annealing algorithm given will converge to the maximum probability clustering resulting in maximum probability model M fl <ref> [1] </ref>.
Reference: [2] <author> Barker, A.A., </author> <title> Monte Carlo calculations of the radial distribution functions for a proton-electron plasma. Aust. </title> <journal> J. Phys. </journal> <volume> 18 (1965), </volume> <pages> 119-133. </pages>
Reference-contexts: The value of the function T is usually called the (computational) temperature of the process. Without the temperature parameter, the probability p t is identical to the acceptance probability proposed by Barker in <ref> [2] </ref>.
Reference: [3] <author> Brown, D.E., and Huntley, C.L., </author> <title> A practical application of simulated annealing to clustering. </title> <booktitle> Pattern Recognition 25 (1992), </booktitle> <pages> 401-412. </pages>
Reference-contexts: In the following, we show how the simulated annealing algorithm can be used for performing a more elaborate stochastic local search in the model space. Our approach is supported by the results of applying simulated annealing for finding globally optimal clusterings <ref> [3, 35, 16] </ref>. An alternative approach to our clustering problem can be obtained by using a family of algorithms based on alternating between finding the maximum probability model for a given clustering, and computing a new clustering based on the assumption that the current model is correct [9, 8].
Reference: [4] <author> Cheeseman, P., Kelly, J., Self, M., Stutz, J., Taylor, W., and Freeman, D., </author> <title> AutoClass: a Bayesian classification system. Pp. </title> <booktitle> 54-64 in Proc. of the Fifth International Conference on Machine Learning, </booktitle> <address> Ann Arbor, </address> <publisher> June 1988 (Morgan Kaufmann). </publisher>
Reference-contexts: The prototype vectors are regarded as values of a latent hidden random clustering variable, which forms the root of the prototype tree model, and the actual problem domain random variables are the leaves of the tree. The approach resembles the discrete version of the AutoClass model <ref> [4] </ref>, the simple Bayesian classifier model in [18] and [19], and the finite mixture model of multivariate Bernoulli distributions in [12], but unlike these models, our network can be used also for general regression tasks, not only for classification. <p> problem domain distribution well, an optimal prototype tree is obtained by finding a model which maximizes the probability P (M j D) = P (D) 1 Incomplete data vectors can be transformed to complete vectors by adding an `unknown' category to the value sets of the attributes with missing values <ref> [4] </ref>. 4 As the probability P (D) is constant for a given training set, we can compare the likelihood of different prototype sets by using as the criterion the formula P (M j D) = cP (M)P (D j M); (3) where c can be any positive constant.
Reference: [5] <author> Cheeseman, P., </author> <title> On finding the most probable model. </title> <note> Pp. 73-95 in J. </note> <editor> Shrager and P. Lan-gley (eds.), </editor> <title> Computational Models of Scientific Discovery and Theory Formation. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year> <month> 8 </month>
Reference-contexts: Simulated annealing has also been used for implementing the reasoning computation in Bayesian networks [26]. However, as suggested in <ref> [5] </ref>, in this work we use the simulated annealing algorithm for learning, i.e., finding a globally maximal probability Bayesian network model for our problem domain. In contrast to most existing learning algorithms for Bayesian networks, we do not try to learn arbitrarily complex multi-connected Bayesian network structures.
Reference: [6] <author> Cooper, </author> <title> G.F., The computational complexity of probabilistic inference using Bayesian belief networks. </title> <booktitle> Artificial Intelligence 42 (1990), </booktitle> <pages> 393-405. </pages>
Reference-contexts: In this restriction we are motivated by the fact that in the general case the resulting model can be unsuitable for practical purposes as the Bayesian reasoning task with multi-connected networks may take an exponential amount of time <ref> [6] </ref>. Instead, we restrict ourselves to a special class of simple tree-structured Bayesian networks, Bayesian prototype trees [28, 29], for which a polynomial time algorithm for Bayesian reasoning exists [31].
Reference: [7] <author> Cooper, G.F., and Herskovits, E., </author> <title> A Bayesian method for induction of probabilistic networks from data. </title> <booktitle> Machine Learning 9 (1992), </booktitle> <pages> 309-347. </pages>
Reference-contexts: The learning process has two important components: an evaluation criterion for a candidate network, and a search algorithm for selecting new candidate networks. Under certain assumptions, a probabilistic evaluation criterion for comparing different Bayesian network models can be constructed by computing directly the probability of a given Bayesian network <ref> [7] </ref>, or indirectly [20] by using the Minimum Description Length approach [32]. This type of criteria are totally independent of the search algorithm used, and hence each search algorithm can be combined with several different criteria. <p> Maximum likelihood estimates of the class prototype vectors corresponding to a given partitioning of the training data into l classes can be either derived by simply using the relative frequencies of value occurrences, or as noted in <ref> [7, 18] </ref>, approximated more accurately with the formula P k (a ij ) = jC k j + n i where F k (a ij ) is the number of vectors in cluster C k with the property A i = a ij , and jC k j is the total <p> The third term containing a sum of these prior probabilities is constant for a given data set, and can hence be ignored. An alternative criterion, which computes the probability P (D j M) directly, is given in <ref> [7] </ref>. To approximate the model size S (M), let us first code all the different Bayesian trees using the information theoretically optimal coding scheme in [32].
Reference: [8] <author> Csiszar, I. and Tusnady, G., </author> <title> Information geometry and alternating minimization procedure. Statistics & Decisions, </title> <booktitle> Supplement Issue 1 (1984), </booktitle> <pages> 205-237. </pages>
Reference-contexts: An alternative approach to our clustering problem can be obtained by using a family of algorithms based on alternating between finding the maximum probability model for a given clustering, and computing a new clustering based on the assumption that the current model is correct <ref> [9, 8] </ref>. Perhaps the most famous variant of this procedure is the computationally simple K-means clustering algorithm [22]. <p> With this kind of approach, there would be no need for an evaluation criterion at all, as clustering is based on comparing data vectors against prototype vectors, not comparing models against each other. However, although the method converges provably under certain conditions to a locally optimal clustering <ref> [8, 36] </ref>, the outcome depends on the number of the prototype vectors used, and the choice of the initial prototype vectors, and hence finding a globally optimal clustering with this approach is difficult.
Reference: [9] <author> Dempster, A.P. Laird, N.M. and Rubin, </author> <title> D.B. Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society, Ser. </journal> <volume> B 39 (1977) 1, </volume> <pages> 1-38. </pages>
Reference-contexts: An alternative approach to our clustering problem can be obtained by using a family of algorithms based on alternating between finding the maximum probability model for a given clustering, and computing a new clustering based on the assumption that the current model is correct <ref> [9, 8] </ref>. Perhaps the most famous variant of this procedure is the computationally simple K-means clustering algorithm [22].
Reference: [10] <author> Forsstrom, J. </author> <title> Machine learning in clinical medicine by knowledge acquisition from patient databases. </title> <type> Ph.D. Thesis, </type> <institution> Departments of Medicine and Clinical Chemistry, University of Turku. Annales Universitatis Turkuensis, Ser. D, </institution> <type> Report 92. </type> <institution> University of Turku, </institution> <year> 1992. </year>
Reference-contexts: for decreasing the temperature may be difficult in practice [26]. 6 Experiments To test the proposed framework in practice, we ran a series of experiments by using a set of medical data dealing with diagnosis of Nephropathia epidemica (NE), which is the mildest form of hemorrhagic fevers with renal syndrome <ref> [10] </ref>. In these experiments, each data vector consisted of values of 33 attributes, the last of which gives the diagnosis of the patient (NE or non-NE).
Reference: [11] <author> Geman, S. and Geman, D., </author> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence 6 (1984), </journal> <pages> 721-741. </pages>
Reference-contexts: Simulated annealing [24] is an iterative stochastic sampling method which has been shown to be able to find a maximum probability state of the sampling space almost surely, provided that a sufficient number of iterations is used <ref> [11] </ref>. After being introduced to the optimization theory community in [14], simulated annealing has been applied to many different (NP-hard) optimization problems, such as TSP, graph partitioning, graph coloring, number set partitioning and clustering (for an extensive survey of applications, see [1, pp.89-90]).
Reference: [12] <author> Gyllenberg, M., Gyllenberg, H.G., Koski, T., and Schindler, J., </author> <title> Non-uniqueness of numerical taxonomic structures. </title> <booktitle> Binary 5 (1993), </booktitle> <pages> 138-144. </pages>
Reference-contexts: The approach resembles the discrete version of the AutoClass model [4], the simple Bayesian classifier model in [18] and [19], and the finite mixture model of multivariate Bernoulli distributions in <ref> [12] </ref>, but unlike these models, our network can be used also for general regression tasks, not only for classification. The Bayesian prototype tree model is described in more detail in Section 2.
Reference: [13] <author> Hsu, W., Hsu, </author> <title> L.S., and Tenorio, M.F., The Clusnet algorithm and time series prediction. </title> <booktitle> International Journal of Neural Systems 4 (1993), </booktitle> <pages> 247-255. </pages>
Reference-contexts: Such models are becoming increasingly popular in the neural network community, since the models can often be implemented very efficiently on massively parallel neural network architectures <ref> [25, 37, 21, 13] </ref>. In our approach we restrict ourselves to discrete problem domains, which allows us to drop all assumptions about the form of the underlying probability distribution.
Reference: [14] <author> Kirkpatrick, S., Gelatt, D. and Vecchi, </author> <title> M.P., Optimization by simulated annealing. </title> <booktitle> Science 220 (1983), </booktitle> <pages> 671-680. </pages>
Reference-contexts: Simulated annealing [24] is an iterative stochastic sampling method which has been shown to be able to find a maximum probability state of the sampling space almost surely, provided that a sufficient number of iterations is used [11]. After being introduced to the optimization theory community in <ref> [14] </ref>, simulated annealing has been applied to many different (NP-hard) optimization problems, such as TSP, graph partitioning, graph coloring, number set partitioning and clustering (for an extensive survey of applications, see [1, pp.89-90]).
Reference: [15] <author> Kitano, H., </author> <title> Challenges of massive parallelism. Pp. </title> <booktitle> 813-834 in Proc. of IJCAI-93, the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Chambery, France, </address> <publisher> August 1993 (Morgan Kaufmann). </publisher>
Reference-contexts: The model also conforms interestingly to the intuitively appealing memory-based reasoning paradigm (see e.g. <ref> [15] </ref>), and it can be seen as a Bayesian solution to the case matching and case adaptation problems (see [29]) in such domains.
Reference: [16] <author> Klein, R.W. and Dubes, </author> <title> R.C. Experiments in projection and clustering by simulated annealing. </title> <booktitle> Pattern Recognition 22 (1989), </booktitle> <pages> 213-220. </pages>
Reference-contexts: In the following, we show how the simulated annealing algorithm can be used for performing a more elaborate stochastic local search in the model space. Our approach is supported by the results of applying simulated annealing for finding globally optimal clusterings <ref> [3, 35, 16] </ref>. An alternative approach to our clustering problem can be obtained by using a family of algorithms based on alternating between finding the maximum probability model for a given clustering, and computing a new clustering based on the assumption that the current model is correct [9, 8].
Reference: [17] <author> Kohonen, T. </author> <title> Self-Organization and Associative Memory. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin 1988. </address>
Reference-contexts: Some attempts towards more robust variations of the approach are reported in <ref> [17, 23] </ref>, but the global convergence properties of the resulting algorithms are hard to analyze theoretically. <p> The resulting success rates ranged from 76.2% to 91.5%. The two clear winners with the success rates of 91.5% used Backpropagation (BP) (see e.g. [34]) and Learning Vector Quantization (LVQ) <ref> [17] </ref>, respectively. The best BP result was obtained by a 32-5-3-2 network, and by adding 20% noise to the training data. However, finding this setup required a lot of experiments, and constant manual tuning of the parameters of the algorithm during the training.
Reference: [18] <author> Kononenko, I., </author> <title> Successive naive Bayesian classifier. </title> <note> Informatica 17 (1993) , 167-174. </note>
Reference-contexts: The approach resembles the discrete version of the AutoClass model [4], the simple Bayesian classifier model in <ref> [18] </ref> and [19], and the finite mixture model of multivariate Bernoulli distributions in [12], but unlike these models, our network can be used also for general regression tasks, not only for classification. The Bayesian prototype tree model is described in more detail in Section 2. <p> Maximum likelihood estimates of the class prototype vectors corresponding to a given partitioning of the training data into l classes can be either derived by simply using the relative frequencies of value occurrences, or as noted in <ref> [7, 18] </ref>, approximated more accurately with the formula P k (a ij ) = jC k j + n i where F k (a ij ) is the number of vectors in cluster C k with the property A i = a ij , and jC k j is the total
Reference: [19] <author> Langley, P., </author> <title> Induction of recursive Bayesian classifiers. </title> <note> Pp. 153-164 in P.B. </note> <editor> Brazdil (ed.), </editor> <booktitle> Proc. of ECML-93, European Conference on Machine Learning, </booktitle> <address> Vienna, Austria, </address> <month> April </month> <year> 1993 </year> <month> (Springer-Verlag). </month>
Reference-contexts: The approach resembles the discrete version of the AutoClass model [4], the simple Bayesian classifier model in [18] and <ref> [19] </ref>, and the finite mixture model of multivariate Bernoulli distributions in [12], but unlike these models, our network can be used also for general regression tasks, not only for classification. The Bayesian prototype tree model is described in more detail in Section 2.
Reference: [20] <author> Lam W., and Bacchus, F., </author> <title> Using causal information and local measures to learn Bayesian networks. Pp. </title> <editor> 243-250 in D. Heckerman and A. Mamdani (eds.), </editor> <booktitle> Proc. of the Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Washington, D.C., </address> <publisher> July 1993 (Morgan Kaufmann). </publisher>
Reference-contexts: Under certain assumptions, a probabilistic evaluation criterion for comparing different Bayesian network models can be constructed by computing directly the probability of a given Bayesian network [7], or indirectly <ref> [20] </ref> by using the Minimum Description Length approach [32]. This type of criteria are totally independent of the search algorithm used, and hence each search algorithm can be combined with several different criteria. <p> This type of criteria are totally independent of the search algorithm used, and hence each search algorithm can be combined with several different criteria. In this paper, we use a combination of the techniques adopted from <ref> [20, 32] </ref> for constructing an example of suitable evaluation criteria. In principle, the best model for the problem domain probability distribution can be found by going through all the possible networks, and choosing the model with the highest probability. <p> There are many different approaches to approximating the terms S (M) and S (D j M). For example, we can apply Theorem 2.2 in <ref> [20] </ref> to derive an approximation for S (D j M) as S (D j M) = N k=1 i=1 j=1 P k (a ij ) N k=1 N i=1 j=1 where m is the number of attributes, n i is the number of values of attribute A i , l is
Reference: [21] <author> Lee S., and Shimoji, S., BAYESNET: </author> <title> Bayesian classification network based on biased random competition using Gaussian kernels. Pp. </title> <booktitle> 1354-1359 in Proc. of the IEEE International Conf. on Neural Networks, </booktitle> <address> San Francisco, </address> <publisher> March 1993 (IEEE Press). </publisher>
Reference-contexts: Such models are becoming increasingly popular in the neural network community, since the models can often be implemented very efficiently on massively parallel neural network architectures <ref> [25, 37, 21, 13] </ref>. In our approach we restrict ourselves to discrete problem domains, which allows us to drop all assumptions about the form of the underlying probability distribution.
Reference: [22] <author> MacQueen, J. </author> <title> Some methods of classification and analysis of multivariate observation. Pp. </title> <editor> 281-297 in L.M.LeCam and J.Neyman (eds.), </editor> <booktitle> Proc. 5th Berkeley Symposium on Math. Stat., and Prob., </booktitle> <year> 1967. </year>
Reference-contexts: Perhaps the most famous variant of this procedure is the computationally simple K-means clustering algorithm <ref> [22] </ref>. With this kind of approach, there would be no need for an evaluation criterion at all, as clustering is based on comparing data vectors against prototype vectors, not comparing models against each other.
Reference: [23] <author> Marroquin, J.L. and Girosi, F. </author> <title> Some extensions of the k-means algorithm for image segmentation and pattern classification. </title> <institution> Massachusetts Institute of Technology, Artificial Intelligence Laboratory, A.I. </institution> <note> Memo 1390, C.B.C.L. Paper No. 079, MIT January 1993. 9 </note>
Reference-contexts: Some attempts towards more robust variations of the approach are reported in <ref> [17, 23] </ref>, but the global convergence properties of the resulting algorithms are hard to analyze theoretically.
Reference: [24] <author> Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, M.N. and Teller, E., </author> <title> Equations of state calculations by fast computing machines. </title> <journal> Journal of Chem. Phys. </journal> <volume> 21 (1953), </volume> <pages> 1087-1092. </pages>
Reference-contexts: This is an important aspect, as in the large model space in question the probability of having a large number of local maxima is very high, in which case the quality of the solution found with such optimization methods may be poor. Simulated annealing <ref> [24] </ref> is an iterative stochastic sampling method which has been shown to be able to find a maximum probability state of the sampling space almost surely, provided that a sufficient number of iterations is used [11]. <p> The value of the function T is usually called the (computational) temperature of the process. Without the temperature parameter, the probability p t is identical to the acceptance probability proposed by Barker in [2]. An alternative form for the acceptance probability, proposed originally by Metropolis et al. in <ref> [24] </ref>, is given by p t (M t+1 ) = 1 ; if P (M t jD) 1, P (M t+1 jD) 1 P (M t+1 jD) (9) It has been argued that in practice the Metropolis form should be preferred since in the case of equally probable states, Barker's method
Reference: [25] <author> Moody, J., and Darken, C., </author> <title> Fast learning in networks of locally-tuned processing units. </title> <booktitle> Neural Computation 1 (1989), </booktitle> <pages> 281-294. </pages>
Reference-contexts: Such models are becoming increasingly popular in the neural network community, since the models can often be implemented very efficiently on massively parallel neural network architectures <ref> [25, 37, 21, 13] </ref>. In our approach we restrict ourselves to discrete problem domains, which allows us to drop all assumptions about the form of the underlying probability distribution.
Reference: [26] <author> Myllymaki, P., </author> <title> Bayesian reasoning by stochastic neural networks. Ph. Lic. </title> <type> Thesis, Report C-1993-67, </type> <institution> Department of Computer Science, University of Helsinki, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: Unfortunately, the number of iterations for the theoretically guaranteed convergence is too high for practical purposes, but in many cases good results has been obtained even with a relatively small number of iterations [1]. Simulated annealing has also been used for implementing the reasoning computation in Bayesian networks <ref> [26] </ref>. However, as suggested in [5], in this work we use the simulated annealing algorithm for learning, i.e., finding a globally maximal probability Bayesian network model for our problem domain. <p> However, it should be noted that the stochastic process generated by using the Barker's formula can be implemented extremely efficiently by using a massively parallel architecture <ref> [26, 27] </ref>. Theoretically there is no preference for either of these models, since using the candidate generation scheme described above both methods lead to a stochastic process fulfilling the condition (7) (see [26]). <p> Theoretically there is no preference for either of these models, since using the candidate generation scheme described above both methods lead to a stochastic process fulfilling the condition (7) (see <ref> [26] </ref>). Algorithm 1 (Searching models by simulated annealing) 1. /* start with a random clustering: */ for h = 1 to N do (a) c 0 (h) = RANDINT (1,N ); 2. <p> If the computational temperature T (t) is decreased slowly enough, the simulated annealing algorithm given will converge to the maximum probability clustering resulting in maximum probability model M fl [1]. Unfortunately, finding a proper cooling schedule for decreasing the temperature may be difficult in practice <ref> [26] </ref>. 6 Experiments To test the proposed framework in practice, we ran a series of experiments by using a set of medical data dealing with diagnosis of Nephropathia epidemica (NE), which is the mildest form of hemorrhagic fevers with renal syndrome [10].
Reference: [27] <author> Myllymaki, P., </author> <title> Using Bayesian networks for incorporating probabilistic a priori knowledge into Boltzmann machines. </title> <note> Pp. 97-102 in Proc. of SOUTHCON'94, Orlando, March 1994 (IEEE Press). </note>
Reference-contexts: However, it should be noted that the stochastic process generated by using the Barker's formula can be implemented extremely efficiently by using a massively parallel architecture <ref> [26, 27] </ref>. Theoretically there is no preference for either of these models, since using the candidate generation scheme described above both methods lead to a stochastic process fulfilling the condition (7) (see [26]).
Reference: [28] <author> Myllymaki, P., and Tirri, H., </author> <title> Bayesian case-based reasoning with neural networks. Pp. </title> <booktitle> 422-427 in Proc. of the IEEE International Conf. on Neural Networks, </booktitle> <address> San Francisco, </address> <publisher> March 1993 (IEEE Press). </publisher>
Reference-contexts: Instead, we restrict ourselves to a special class of simple tree-structured Bayesian networks, Bayesian prototype trees <ref> [28, 29] </ref>, for which a polynomial time algorithm for Bayesian reasoning exists [31]. In addition, the Bayesian prototype tree model can also be implemented extremely efficiently on massively parallel hardware, as there is a direct mapping from a Bayesian tree structure to a multi-layer feedforward neural network structure [28]. <p> In addition, the Bayesian prototype tree model can also be implemented extremely efficiently on massively parallel hardware, as there is a direct mapping from a Bayesian tree structure to a multi-layer feedforward neural network structure <ref> [28] </ref>. The model also conforms interestingly to the intuitively appealing memory-based reasoning paradigm (see e.g. [15]), and it can be seen as a Bayesian solution to the case matching and case adaptation problems (see [29]) in such domains. <p> The Bayesian prototype tree model is described in more detail in Section 2. Naturally the accuracy of the model depends on how well the chosen Bayesian prototypes reflect the actual probability distribution. In <ref> [28, 29] </ref> the prototypes were assumed to be provided by a domain expert. However, although using experts is viable in some domains, in many cases such prototypes need to be inferred from raw data.
Reference: [29] <author> Myllymaki, P., and Tirri, H., </author> <title> Massively parallel case-based reasoning with probabilistic similarity metrics. </title> <note> Pp. 48-53 in M.M. </note> <editor> Richter, S. Wess, K.-D. Althoff and F. Maurer (eds.), </editor> <booktitle> Proc. of the First European Workshop on Case-Based Reasoning, </booktitle> <institution> University of Kaiserslautern, </institution> <month> November </month> <year> 1993. </year> <type> SEKI Report SR-93-12 (SFB 314), </type> <institution> University of Kaiserslautern. </institution>
Reference-contexts: Instead, we restrict ourselves to a special class of simple tree-structured Bayesian networks, Bayesian prototype trees <ref> [28, 29] </ref>, for which a polynomial time algorithm for Bayesian reasoning exists [31]. In addition, the Bayesian prototype tree model can also be implemented extremely efficiently on massively parallel hardware, as there is a direct mapping from a Bayesian tree structure to a multi-layer feedforward neural network structure [28]. <p> The model also conforms interestingly to the intuitively appealing memory-based reasoning paradigm (see e.g. [15]), and it can be seen as a Bayesian solution to the case matching and case adaptation problems (see <ref> [29] </ref>) in such domains. The Bayesian prototype tree model is based on the assumption that the problem domain probability distribution can be approximated by a set of prototype vectors, where each prototype represents a set of (in some sense) similar problem domain instances. <p> The Bayesian prototype tree model is described in more detail in Section 2. Naturally the accuracy of the model depends on how well the chosen Bayesian prototypes reflect the actual probability distribution. In <ref> [28, 29] </ref> the prototypes were assumed to be provided by a domain expert. However, although using experts is viable in some domains, in many cases such prototypes need to be inferred from raw data.
Reference: [30] <author> Myllymaki, P., and Tirri, H., </author> <title> Learning in neural networks with Bayesian prototypes. </title> <note> Pp. 60-64 in Proc. of SOUTHCON'94, Orlando, March 1994 (IEEE Press). </note>
Reference-contexts: In <ref> [30] </ref> we presented a greedy heuristic for the search process. This heuristic was a "bottom-up" approach which starts by partitioning all the data vectors in separate clusters, and continues by combining the two prototypes which produce the greatest increase in the probability P (M j D).
Reference: [31] <author> Pearl, J., </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: Instead, we restrict ourselves to a special class of simple tree-structured Bayesian networks, Bayesian prototype trees [28, 29], for which a polynomial time algorithm for Bayesian reasoning exists <ref> [31] </ref>. In addition, the Bayesian prototype tree model can also be implemented extremely efficiently on massively parallel hardware, as there is a direct mapping from a Bayesian tree structure to a multi-layer feedforward neural network structure [28].
Reference: [32] <author> Rissanen, J., </author> <title> Stochastic Complexity in Statistical Inquiry. </title> <publisher> World Scientific, </publisher> <year> 1989. </year>
Reference-contexts: Under certain assumptions, a probabilistic evaluation criterion for comparing different Bayesian network models can be constructed by computing directly the probability of a given Bayesian network [7], or indirectly [20] by using the Minimum Description Length approach <ref> [32] </ref>. This type of criteria are totally independent of the search algorithm used, and hence each search algorithm can be combined with several different criteria. In this paper, we use a combination of the techniques adopted from [20, 32] for constructing an example of suitable evaluation criteria. <p> This type of criteria are totally independent of the search algorithm used, and hence each search algorithm can be combined with several different criteria. In this paper, we use a combination of the techniques adopted from <ref> [20, 32] </ref> for constructing an example of suitable evaluation criteria. In principle, the best model for the problem domain probability distribution can be found by going through all the possible networks, and choosing the model with the highest probability. <p> This criterion can also be approximated using the Minimum Description Length (MDL) <ref> [32] </ref> approach, where the goal is to minimize the size S of the model M, given the data: S (M j D) = S (M) + S (D j M) = log P (M) log P (D j M): The first term S (M) is the size of the prototype tree <p> An alternative criterion, which computes the probability P (D j M) directly, is given in [7]. To approximate the model size S (M), let us first code all the different Bayesian trees using the information theoretically optimal coding scheme in <ref> [32] </ref>. As our model contains l prototype vectors and l prior probabilities (one for each class C k ), we now need S (M) = l i=1 bits to code all the parameters in the model, where r is the number of bits needed to store a truncated real value.
Reference: [33] <author> Robinson, W.R., </author> <title> Counting unlabeled acyclic digraphs. In C.H.C. Little (ed.), </title> <booktitle> Lecture notes in mathematics 622: Combinatorial mathematics. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1977. </year>
Reference-contexts: Unfortunately, in the Bayesian network framework the number of possible models is too large for such an exhaustive search approach to be used in practice (see the combinatorial analysis in <ref> [33] </ref>). For this reason most existing learning methods for Bayesian networks typically use simple greedy heuristics for searching the model space.
Reference: [34] <author> Rumelhart, D.E., Hinton G.E. and Williams R.J., </author> <title> Learning internal representations by error propagation. Pp. </title> <editor> 318-362 in D.E.Rumelhart and J.L.McClelland (eds.), </editor> <booktitle> Parallel Distributed Processing. </booktitle> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: The resulting success rates ranged from 76.2% to 91.5%. The two clear winners with the success rates of 91.5% used Backpropagation (BP) (see e.g. <ref> [34] </ref>) and Learning Vector Quantization (LVQ) [17], respectively. The best BP result was obtained by a 32-5-3-2 network, and by adding 20% noise to the training data. However, finding this setup required a lot of experiments, and constant manual tuning of the parameters of the algorithm during the training.
Reference: [35] <author> Selim, S.Z., and Alsultan, K., </author> <title> A simulated annealing algorithm for the clustering problem. </title> <booktitle> Pattern Recognition 24 (1991) 10, </booktitle> <pages> 1003-1008. </pages>
Reference-contexts: In the following, we show how the simulated annealing algorithm can be used for performing a more elaborate stochastic local search in the model space. Our approach is supported by the results of applying simulated annealing for finding globally optimal clusterings <ref> [3, 35, 16] </ref>. An alternative approach to our clustering problem can be obtained by using a family of algorithms based on alternating between finding the maximum probability model for a given clustering, and computing a new clustering based on the assumption that the current model is correct [9, 8].
Reference: [36] <author> Selim, S.Z., and Ismail, M.A. </author> <title> K-Means-type algorithms: a generalized convergence theorem and characterization of local optimality. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence 6 (1984) 1, </journal> <pages> 81-87. </pages>
Reference-contexts: With this kind of approach, there would be no need for an evaluation criterion at all, as clustering is based on comparing data vectors against prototype vectors, not comparing models against each other. However, although the method converges provably under certain conditions to a locally optimal clustering <ref> [8, 36] </ref>, the outcome depends on the number of the prototype vectors used, and the choice of the initial prototype vectors, and hence finding a globally optimal clustering with this approach is difficult.
Reference: [37] <author> Specht, D.F., </author> <title> Probabilistic neural networks. </title> <booktitle> Neural Networks 3, </booktitle> <pages> 109-118, </pages> <year> 1990. </year> <month> 10 </month>
Reference-contexts: Such models are becoming increasingly popular in the neural network community, since the models can often be implemented very efficiently on massively parallel neural network architectures <ref> [25, 37, 21, 13] </ref>. In our approach we restrict ourselves to discrete problem domains, which allows us to drop all assumptions about the form of the underlying probability distribution.
References-found: 37

