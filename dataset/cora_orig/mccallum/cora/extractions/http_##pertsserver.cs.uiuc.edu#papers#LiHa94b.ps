URL: http://pertsserver.cs.uiuc.edu/papers/LiHa94b.ps
Refering-URL: http://pertsserver.cs.uiuc.edu/papers/
Root-URL: http://www.cs.uiuc.edu
Title: Chapter 9 Efficient Methods of Validating Timing Constraints  
Author: Jane W. S. Liu Rhan Ha 
Note: 9.1 Introduction 196  
Abstract: Analytical and efficient validation methods to determine whether all jobs always complete by their deadlines are not yet available for systems using modern dynamic scheduling strategies. Exhaustive methods are often infeasible or unreliable since the execution time and release time of each job may vary. This chapter presents several worst-case bounds and efficient algorithms for determining how late the completion times of independent jobs with arbitrary release times can be in a dynamic multiprocessor or distributed system when their release times and execution times may vary from one instance to another. The special cases considered here are when the jobs are (1) preemptable and migratable, or (2) preemptable and nonmigratable, or (3) nonpreemptable. In a real-time system, many jobs are time-critical. Here, by job, we mean a unit of work to be scheduled and executed. A job may be the computation of a control law, the transmission of an operator command, the retrieval of a file, etc. To execute, it requires a computer, a data link, a console, a disk, respectively; we refer to them all as processors. The processors are identical if they can be used interchangeably. Otherwise they are functionally dedicated, as exemplified by the processors listed above. The length of time a job requires to complete if it were to execute alone is called its execution time. The execution of a time-critical job cannot begin until its release time and must complete by its deadline. To validate a real-time system, its builder must demonstrate convincingly that all time-critical jobs will always complete by their deadlines, after making sure that the scheduler works correctly, that is, it never schedules any job before its release time. Hereafter, we assume 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. L. Liu and J. W. Layland. </author> <title> Scheduling algorithms for multiprogramming in a hard-real-time environment. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 20(1) </volume> <pages> 46-61, </pages> <month> January </month> <year> 1973. </year>
Reference-contexts: For example, if the jobs are scheduled on the rate-monotonic basis (that is, the shorter the period, the higher the priority) and synchronized according to the priority-ceiling protocol <ref> [1, 3] </ref>, all jobs in T i always complete by their deadlines if i X u k + b i =p i i (2 1=i 1) (9:1) when ffi i = p i .
Reference: [2] <author> J. Leung and J. Whitehead. </author> <title> On the complexity of fixed-priority scheduling of periodic, real-time tasks. Performance Evaluation, </title> <booktitle> 2 </booktitle> <pages> 237-250, </pages> <year> 1982. </year>
Reference: [3] <author> L. Sha, R. Rajkumar, and J. P. Lehoczky. </author> <title> Priority inheritance protocols: An approach to real-time synchronization. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(9) </volume> <pages> 1175-1185, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: In this way, we can ignore precedence constraints and treat all jobs as if they are independent. In our notation, most of the jobs are P/N/J jobs; they are scheduled preemptively (and are not migratable). Their resource accesses are controlled by a protocol (such as the ones in <ref> [3, 4] </ref>) that ensures the blocking time of every job in T i due to resource conflicts with all jobs in the system is never more than b i . <p> For example, if the jobs are scheduled on the rate-monotonic basis (that is, the shorter the period, the higher the priority) and synchronized according to the priority-ceiling protocol <ref> [1, 3] </ref>, all jobs in T i always complete by their deadlines if i X u k + b i =p i i (2 1=i 1) (9:1) when ffi i = p i .
Reference: [4] <author> T. P. Baker. </author> <title> A stack-based allocation policy for realtime processes. </title> <booktitle> In Proceedings of IEEE 11th Real-Time Systems Symposium, </booktitle> <pages> pages 191-200, </pages> <month> December </month> <year> 1990. </year> <note> References 217 </note>
Reference-contexts: In this way, we can ignore precedence constraints and treat all jobs as if they are independent. In our notation, most of the jobs are P/N/J jobs; they are scheduled preemptively (and are not migratable). Their resource accesses are controlled by a protocol (such as the ones in <ref> [3, 4] </ref>) that ensures the blocking time of every job in T i due to resource conflicts with all jobs in the system is never more than b i .
Reference: [5] <author> B. Sprunt, L. Sha, and J. P. Lehoczky. </author> <title> Aperiodic task scheduling for hard-real-time systems. </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 1 </volume> <pages> 27-60, </pages> <year> 1989. </year>
Reference-contexts: Jobs on each processor are scheduled according to a uniprocessor scheduling algorithm and synchronized according to a resource access-control protocol that leads of bounded durations of priority inversion (for example, the ones in <ref> [5, 6] </ref>). (A priority inversion is said to occur when a lower-priority job executes or a processor is left idle while some higher-priority job is waiting for execution. <p> With a slight abuse of the notation, we use e + i to denote the maximum execution time of each job in T i . u i = e + i =p i is called the utilization of the task T i . Some tasks are (periodic) servers <ref> [5] </ref>. A periodic server is created to handle the execution of a stream of jobs whose release times and execution times are random variables. Each server T s is characterized by its period p s , execution time e + s , and relative deadline ffi s .
Reference: [6] <author> J. P. Lehoczky, L. Sha, and Y. Ding. </author> <title> The rate monotone scheduling algorithm: Exact characterization and average case behavior. </title> <booktitle> In Proceedings of IEEE 10th Real-Time Systems Symposium, </booktitle> <pages> pages 166-171, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Jobs on each processor are scheduled according to a uniprocessor scheduling algorithm and synchronized according to a resource access-control protocol that leads of bounded durations of priority inversion (for example, the ones in <ref> [5, 6] </ref>). (A priority inversion is said to occur when a lower-priority job executes or a processor is left idle while some higher-priority job is waiting for execution.
Reference: [7] <author> R. L. Graham. </author> <title> Bounds on multiprocessing timing anomalies. </title> <journal> SIAM Journal of Applied Mathematics, </journal> <volume> 17(2) </volume> <pages> 416-429, </pages> <month> March </month> <year> 1969. </year>
Reference-contexts: Graham has shown that the completion time of a set of nonpreemptive jobs with identical release times can be later when more processors are used to execute them and when they have shorter execution times and fewer dependencies <ref> [7] </ref>. When jobs have arbitrary release times and share nonpreemptable resources, scheduling anomalies can occur even when there is only one processor and the jobs are preempt-able.
Reference: [8] <author> J. Blazewicz. </author> <title> Selected topics in scheduling theory. </title> <journal> Annals of Discrete Mathematics, </journal> <volume> 31 </volume> <pages> 1-60, </pages> <year> 1987. </year>
Reference: [9] <author> C. Shen, K. Ramamritham, and J. A. Stankovic. </author> <title> Resource reclaiming in real-time. </title> <booktitle> In Proceedings of IEEE 11th Real-Time Systems Symposium, </booktitle> <pages> pages 41-50, </pages> <month> December </month> <year> 1990. </year>
Reference: [10] <author> D. W. Gillies and J. W. S. Liu. </author> <title> Greed in resource scheduling. </title> <journal> Acta Informatica, </journal> <volume> 28 </volume> <pages> 755-775, </pages> <year> 1991. </year>
Reference: [11] <author> M. H. Klein, T. Ralya, B. Pollak, R. Obenza, and M. G. Harbour. </author> <title> A Practitioner's Handbook for Real-Time Analysis: Guide to Rate Monotonic Analysis for Real-Time Systems. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: Similar conditions are known for many fixed-priority algorithms and for arbitrary values of ffi i less than or equal to p i . It is straightforward to generalize the conditions to account for the effects of nonpreemption if some jobs are not preemptable <ref> [11, 12] </ref>.
Reference: [12] <author> L. Sha and S. S. Sathaye. </author> <title> A systematic approach to designing distributed real-time systems. </title> <journal> IEEE Computer, </journal> <volume> 26(9) </volume> <pages> 68-78, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Similar conditions are known for many fixed-priority algorithms and for arbitrary values of ffi i less than or equal to p i . It is straightforward to generalize the conditions to account for the effects of nonpreemption if some jobs are not preemptable <ref> [11, 12] </ref>. <p> It is also straightforward to use these conditions to bound the worst-case completion times of jobs in periodic job-shops and flow-shops where each job consists of subjobs 204 Efficient Methods of Validating Timing Constraints Chap. 9 which execute in turn on two or more processors and have end-to-end deadlines <ref> [12, 13] </ref>. The known sufficient conditions, such as (9.1), are particularly robust. For example, the values of the periods and worst-case execution times of jobs in tasks T 1 ; T 2 ; ; T i do not appear in the left-handed side of (9.1), only their utilizations.
Reference: [13] <author> R. Bettati. </author> <title> End-to-End Scheduling to Meet Deadlines. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1994. </year>
Reference-contexts: It is also straightforward to use these conditions to bound the worst-case completion times of jobs in periodic job-shops and flow-shops where each job consists of subjobs 204 Efficient Methods of Validating Timing Constraints Chap. 9 which execute in turn on two or more processors and have end-to-end deadlines <ref> [12, 13] </ref>. The known sufficient conditions, such as (9.1), are particularly robust. For example, the values of the periods and worst-case execution times of jobs in tasks T 1 ; T 2 ; ; T i do not appear in the left-handed side of (9.1), only their utilizations.
Reference: [14] <author> J. W. S. Liu, J. Redondo, Z. Deng, T. Tia, R. Bettati, A. Silberman, M. Storch, R. Ha, and W. Shih. PERTS: </author> <title> A prototyping environment for real-time systems. </title> <type> Technical Report UIUCDCS-R-93-1802, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1993. </year>
Reference-contexts: An algorithm that makes use of the known parameters p i and e + i can give a more accurate prediction of the worst-case response times. Such algorithms are used in PERTS <ref> [14] </ref>. To determine whether any job in a task T i can meet its deadline, the algorithm takes the release time of the job as the time origin 0 and computes the maximum time demand w + i (t) between 0 and its deadline at ffi i .
Reference: [15] <author> E. L. Lawler and J. M. Moore. </author> <title> A functional equation and its application to resource allocation and scheduling problem. </title> <journal> Management Science, </journal> <volume> 16 </volume> <pages> 77-84, </pages> <year> 1969. </year>
Reference-contexts: Similarly, its effective release time is the latest time among its release time and the release times of its successors. Working with effective release times and deadlines allows the scheduler to ignore temporarily the precedence constraints between jobs and make scheduling decisions as if the jobs are independent <ref> [15] </ref>. Similarly, to vali date whether every job completes before its deadline, we can use the algorithms for validating independent jobs. Unfortunately, this method does not work when the system is dynamic.
Reference: [16] <author> R. Ha and J. W. S. Liu. </author> <title> Validating timing constraints in multiprocessor and distributed real-time systems. </title> <type> Technical Report UIUCDCS-R-93-1833, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1993. </year>
Reference-contexts: Sometimes in the actual schedule, a job may be preempted by a different job from the one in the maximal schedule, even though all the starting sequences are same. Examples illustrating these facts can be found in <ref> [16] </ref>. We note from these examples that the completion times of the jobs are in fact accurately predicted by the upper bounds given by Theorem 9.5.3. <p> The proof of the theorem can be found in <ref> [16] </ref>. Theorem 9.6.1 The completion time F (J i ) of J i is no later than the completion time of the transformed job H i in the schedule of G i , L i1 and H i generated by IN N F algorithm. <p> Similarly, the schedule of J n constructed by assuming all the jobs are preemptable and nonmigratable gives us no information on which lower-priority jobs can actually start before J i . Examples illustrating these facts can be found in <ref> [16] </ref>. Algorithm IN N F N can be used to bound the completion times in this case. It consists of two steps. Step 1 considers the delays in the start time of each job J i by nonpreemptable lower-priority jobs. <p> An algorithm for determining the worst-case completion times for the case where each job can execute on several types of processors can be found in <ref> [16] </ref>. The results presented here constitute a small part of the theoretical basis needed for a comprehensive validation strategy that is capable of dealing with dynamic distributed real-time systems. Much of the work on schedulability analysis remains to be done.
References-found: 16

