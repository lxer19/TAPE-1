URL: http://www.cs.ucsd.edu/groups/csl/users/norival/Papers/TR-CS95-426.ps.gz
Refering-URL: http://www.cs.ucsd.edu/groups/csl/users/norival/ref.html
Root-URL: http://www.cs.ucsd.edu
Email: norival, pasquale-@cs.ucsd.edu  
Title: Leave-in-Time: A Service Discipline for Real-Time Communications in a PacketSwitching Network  
Author: Norival R. Figueira and Joseph Pasquale 
Keyword: delay shifting  
Date: Abstract  
Address: San Diego, CA 92093-0114  
Affiliation: Computer Systems Laboratory Department of Computer Science and Engineering University of California, San Diego  
Abstract: Leave-in-Time is a new rate-based service discipline for packetswitching nodes in a connection-oriented data network. Leave-in-T ime provides sessions with upper bounds on end-to-end delay , delay jitter, buffer space requirements, and an upper bound on the probability distribution of end-toend delay s. A Leave-in-Time session s guarantees are completely determined by the dynamic traffic behavior of that session, without in uence from other sessions. This results in the desirable property that these guarantees are expressed as functions derivable simply from a single fi xed-rate server (with rate equal to the sessions reserved rate) serving only that session. Leave-in-Time has a nonwork-conserving mode of operation for sessions desiring low end-to-end delay jitter . Finally, Leave-in-Time supports the notion of , whereby the delay bounds of some sessions may be decreased at the expense of increasing those of other sessions. We present a set of admis sion control algorithms which support the ability to do delay shifting in a systematic way. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Clark, S. Shenker, and L. Zhang, </author> <title> Supporting Real-Time Applications in an Integrated Services Packet Network: Architecture and Mechanism, </title> <booktitle> In Proceedings of ACM SIGCOMM 92 , pp. </booktitle> <pages> 14-26, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Providing an upper bound on delay has been a major point of concern for previously proposed service disci plines; however, even this is not enough. The delay distribution of packets is likely to be very useful for tolerant applications <ref> [ 1] </ref>. Tolerant applications permit some brief interruptions in service; the level of tolerance might be defined as a maximum percentage of missing packets over some period of time. <p> New tokens are continuously filling up the bucket at rate . All tokens exceeding the maximum bucket capacity are discarded. A sessions traffic conforms to a token bucket filter ( ) (here we adopt a notation similar to the one used in <ref> [1] </ref>, adding an identifier for the session with the subscript ) if, for every generated packet, tokens are removed from the bucket, where is the length of the packet, and the bucket size is never negative (i.e. there are always enough tokens to be removed when a packet is generated). <p> Leave-in-T imes performance bounds depend only on the dynamic traf fic behavior of that session, and are not af fected by the behavior of other sessions being transported over the same links and servers. The bound on delay distribution is especially useful in supporting tolerant applications as defined in <ref> [1] </ref>. A special case of Leave-in-T imes operation reduces to that of VirtualClock. Since the performance bounds we have presented apply to the general case of Leave-in-Times operation, they also apply to VirtualClock.
Reference: [2] <author> R. L. Cruz, </author> <title> A Calculus for Network Delay, Part I: Network Elements in Isolation, </title> <journal> In IEEE Transactions on Information Theory , Vol. </journal> <volume> 37, No. 1, </volume> <pages> pp. 114-131, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Thus, from (14), , which is competitive with the result of Stop-and-Go. The reader is referred to [ 24] which compares the delay distribution seen by sessions under FCFS multiplexing with the delay bound computed with Cruzs method <ref> [ 2, 3] </ref>, the delay bound using Stop-and-Go, and the delay bound using PGPS (presented later in this section). Hierarchical Round Robin (HRR) [ 12] also uses a framing strategy and is a nonwork-conserving service discipline. <p> The reader is referred to [11] for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a net work setting <ref> [2, 3, 14, 23] </ref>. In [2, 3], Cruz uses a non-probabilistic approach to characterize each session entering the network the burstiness constraint , which is in principle very similar to a token bucket filter. <p> The reader is referred to [11] for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a net work setting [2, 3, 14, 23]. In <ref> [2, 3] </ref>, Cruz uses a non-probabilistic approach to characterize each session entering the network the burstiness constraint , which is in principle very similar to a token bucket filter. Under this assumption, a methodology is proposed to calculate per-session upper bounds on delay and buffer requirements. <p> Kurose in [ 14], and Yaron and Sidi in [ 23] describe methods to calculate bounds on the distribution of delay and buffer occupancy when all sessions entering the network are stochastically bounded. The work in <ref> [2, 3, 14, 23] </ref> differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session, while the methodology in [ 2, 3, 14, 23] provides the upper bound on the delay distribution directly. <p> The work in [2, 3, 14, 23] differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session, while the methodology in <ref> [ 2, 3, 14, 23] </ref> provides the upper bound on the delay distribution directly. <p> to provide this function for sessions with any kind of dynamic traffic behavior, and this function depends only on the session in question, i.e. the dynamic traf fic behavior of other sessions does not enter into consideration (i.e. the Leave-in-Time service discipline provides isolation between sessions), while the methodology in <ref> [2, 3, 14, 23] </ref> is based on the traffic characterization of all sessions sharing network servers with the session in question, and the dynamic traffic behavior of all sessions enters in the calculation of the delay distribution. 4 Conclusions We have presented the Leave-in-T ime service discipline which provides sessions with
Reference: [3] <author> R. L. Cruz, </author> <title> A Calculus for Network Delay, Part II: Network Analysis, </title> <journal> In IEEE Transactions on Information Theory , Vol. </journal> <volume> 37, No. 1, </volume> <pages> pp. 132-141, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Thus, from (14), , which is competitive with the result of Stop-and-Go. The reader is referred to [ 24] which compares the delay distribution seen by sessions under FCFS multiplexing with the delay bound computed with Cruzs method <ref> [ 2, 3] </ref>, the delay bound using Stop-and-Go, and the delay bound using PGPS (presented later in this section). Hierarchical Round Robin (HRR) [ 12] also uses a framing strategy and is a nonwork-conserving service discipline. <p> The reader is referred to [11] for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a net work setting <ref> [2, 3, 14, 23] </ref>. In [2, 3], Cruz uses a non-probabilistic approach to characterize each session entering the network the burstiness constraint , which is in principle very similar to a token bucket filter. <p> The reader is referred to [11] for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a net work setting [2, 3, 14, 23]. In <ref> [2, 3] </ref>, Cruz uses a non-probabilistic approach to characterize each session entering the network the burstiness constraint , which is in principle very similar to a token bucket filter. Under this assumption, a methodology is proposed to calculate per-session upper bounds on delay and buffer requirements. <p> Kurose in [ 14], and Yaron and Sidi in [ 23] describe methods to calculate bounds on the distribution of delay and buffer occupancy when all sessions entering the network are stochastically bounded. The work in <ref> [2, 3, 14, 23] </ref> differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session, while the methodology in [ 2, 3, 14, 23] provides the upper bound on the delay distribution directly. <p> The work in [2, 3, 14, 23] differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session, while the methodology in <ref> [ 2, 3, 14, 23] </ref> provides the upper bound on the delay distribution directly. <p> to provide this function for sessions with any kind of dynamic traffic behavior, and this function depends only on the session in question, i.e. the dynamic traf fic behavior of other sessions does not enter into consideration (i.e. the Leave-in-Time service discipline provides isolation between sessions), while the methodology in <ref> [2, 3, 14, 23] </ref> is based on the traffic characterization of all sessions sharing network servers with the session in question, and the dynamic traffic behavior of all sessions enters in the calculation of the delay distribution. 4 Conclusions We have presented the Leave-in-T ime service discipline which provides sessions with
Reference: [4] <author> A. Demers, S. Keshav, and S. Shenker, </author> <title> Analysis and Simulation of a Fair Queueing Algorithm, </title> <booktitle> In Proceedings of ACM SIGCOMM 89 , pp. </booktitle> <pages> 1-12, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: PGPS is Parekh and Gallagers method for computing delay bounds under Weighted Fair Queueing <ref> [4] </ref>. An important problem we address is that, in general, an upper bound on delay will grow linearly with the connection length. <p> Leave-in-T ime uses an approximate sorted priority queue algorithm which runs in O (1) time with a small cost in emulation error [6]. Weighted Fair Queueing (WFQ) is proposed in <ref> [4] </ref> and is a service discipline that tries to emulate the service pro vided by a bit-by-bit round robin server.
Reference: [5] <author> D. Ferrari and D. Verma, </author> <title> A Scheme for Real-Time Channel Establishment in Wide-Area Networks, </title> <journal> In IEEE JSAC , Vol. </journal> <volume> 8, No. 4, </volume> <pages> pp. 368-379, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the fi nite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD <ref> [5] </ref>, JitterEDD [21], RCSP [25], Virtual Clock [28], PGPS [ 16, 17, 18, 19], Stop-and-Go [ 8, 9, 10], and Hierarchical Round Robin [ 12]. <p> In exactly the same manner, upper bounds on the end-to-end delay distribution, end-to-end delay jitter, and buffer space requirements are obtained. Except for the upper bound on end-to-end delay (presented in [ 7]), these results are new for the VirtualClock service discipline. In DelayEDD <ref> [ 5] </ref>, and its extension Jitter -EDD [21] (EDD stands for earliest-due-date), packets are assigned deadlines and transmitted in order of increasing deadline. The deadline of a packet is not directly coupled to the reserved bandwidth of its session as in the Leave-in-T ime scheme (see equation (11)). <p> The deadline of a packet is not directly coupled to the reserved bandwidth of its session as in the Leave-in-T ime scheme (see equation (11)). This leads to a schedulability test at connection establishment time <ref> [ 5] </ref> to avoid scheduling saturation, which can occur even if bandwidth is not overbooked [ 5, 27]. The schedulability test is then a compromise on the looser coupling between reserved rate and delay bound. The Leave-in-Time scheme needs an admission control procedure for the same reason. <p> This leads to a schedulability test at connection establishment time [ 5] to avoid scheduling saturation, which can occur even if bandwidth is not overbooked <ref> [ 5, 27] </ref>. The schedulability test is then a compromise on the looser coupling between reserved rate and delay bound. The Leave-in-Time scheme needs an admission control procedure for the same reason.
Reference: [6] <author> N. R. Figueira, </author> <title> A New Approach to the Control of Real-Time Traffic in Packet Switching Data Networks, </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science and Engineering, University of California, </institution> <address> San Diego, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Leave-in-T ime uses an approximate sorted priority queue algorithm which runs in O (1) time with a small cost in emulation error <ref> [6] </ref>. Weighted Fair Queueing (WFQ) is proposed in [4] and is a service discipline that tries to emulate the service pro vided by a bit-by-bit round robin server.
Reference: [7] <author> N. R. Figueira and Joseph Pasquale, </author> <title> An Upper Bound on Delay for the VirtualClock Service Discipline, </title> <journal> IEEE/ ACM Transactions on Networking , Vol. </journal> <volume> 3, No. 4, </volume> <month> August </month> <year> 1995, </year> <note> (in press). </note>
Reference-contexts: Technical Report CS95-426, University of California, San Diego, May 1995. toend delay was unknown until recently proven in <ref> [ 7] </ref>). JitterEDD, RCSP, and Stop-and-Go also provide an upper bound on delay jitter. Providing an upper bound on delay has been a major point of concern for previously proposed service disci plines; however, even this is not enough. <p> Queue Received Packets . is related to and by the following equation (proof in <ref> [7] </ref>): , i 1, (1) where . 2.2 The Leave-in-Time Service Discipline We present the Leave-in-T ime service discipline as a construction in three steps: a base server algorithm based on the reference server, and two generalizations that result in the final version. <p> As discussed before, the term is part of the upper bound on delay of VirtualClock and PGPS. In VirtualClock, this term originates from the term of equation (2) (the upper bound on delay for VirtualClock is given in <ref> [7] </ref>). The second generalization replaces by which allows some reduction of the upper bound on delay, i.e. by allowing a smaller value than to be assigned to . Thus, this generalization allows control over the upper bounds on the end-to-end delays that sessions experience. <p> In exactly the same manner, upper bounds on the end-to-end delay distribution, end-to-end delay jitter, and buffer space requirements are obtained. Except for the upper bound on end-to-end delay (presented in <ref> [ 7] </ref>), these results are new for the VirtualClock service discipline. In DelayEDD [ 5], and its extension Jitter -EDD [21] (EDD stands for earliest-due-date), packets are assigned deadlines and transmitted in order of increasing deadline.
Reference: [8] <author> S. J. Golestani, </author> <title> A Stop-and-Go Queueing Framework for Congestion Management, </title> <booktitle> In Proceedings of ACM SIGCOMM 90 , pp. </booktitle> <pages> 8-18, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the fi nite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [5], JitterEDD [21], RCSP [25], Virtual Clock [28], PGPS [ 16, 17, 18, 19], Stop-and-Go <ref> [ 8, 9, 10] </ref>, and Hierarchical Round Robin [ 12]. <p> The admission control of Stop-and-Go requires that during any time frame of size , the arrived packets collec tively have no more than bits, where is the bandwidth given to session . In <ref> [ 8] </ref>, a session is called ( smooth if it follows this traf fic constraint. This is more restrictive than a token bucket f ilter.
Reference: [9] <author> S. J. Golestani, </author> <title> Congestion-Free Transmission of Real-Time Traffic in Packet Networks, </title> <booktitle> In Proceedings of IEEE INFOCOM 90 , pp. </booktitle> <pages> 527-536, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the fi nite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [5], JitterEDD [21], RCSP [25], Virtual Clock [28], PGPS [ 16, 17, 18, 19], Stop-and-Go <ref> [ 8, 9, 10] </ref>, and Hierarchical Round Robin [ 12].
Reference: [10] <author> S. J. Golestani, </author> <title> Duration-Limited Statistical Multiplexing of DelaySensitive Traffic in Packet Networks, </title> <booktitle> I Proceedings of IEEE INFOCOM 91 , pp. </booktitle> <pages> 323-332, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the fi nite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [5], JitterEDD [21], RCSP [25], Virtual Clock [28], PGPS [ 16, 17, 18, 19], Stop-and-Go <ref> [ 8, 9, 10] </ref>, and Hierarchical Round Robin [ 12].
Reference: [11] <author> S. J. Golestani, </author> <title> A Self-Clocked Fair Queueing Scheme for Broadband Applications, </title> <booktitle> In Proceedings of IEEE INFOCOM 94 , pp. </booktitle> <pages> 636-646, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: However , the Leave-in-T ime service discipline does not conform to the notion of fairness attributed to PGPS. PGPS is called a fair queueing scheme because it closely emulates the service provided by a bit-by-bit round robin server. The reader is referred to <ref> [11] </ref> for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a net work setting [2, 3, 14, 23].
Reference: [12] <author> C. Kalmanek, H. Kanakia, and S. Keshav, </author> <title> Rate Controlled Servers for Very HighSpeed Networks, </title> <booktitle> In Proceedings of IEEE GlobeCom 90 , pp. </booktitle> <address> 300.3.1-300.3.9, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: Several rate-based service disciplines have been proposed: DelayEDD [5], JitterEDD [21], RCSP [25], Virtual Clock [28], PGPS [ 16, 17, 18, 19], Stop-and-Go [ 8, 9, 10], and Hierarchical Round Robin <ref> [ 12] </ref>. All of these service disciplines provide an upper bound on end-to-end delay (this includes VirtualClock for which an upper bound on end This work was supported in part by a scholarship from CAPES and UFRJ (Brazil), and by grants from NASA and NSF. <p> The reader is referred to [ 24] which compares the delay distribution seen by sessions under FCFS multiplexing with the delay bound computed with Cruzs method [ 2, 3], the delay bound using Stop-and-Go, and the delay bound using PGPS (presented later in this section). Hierarchical Round Robin (HRR) <ref> [ 12] </ref> also uses a framing strategy and is a nonwork-conserving service discipline. It of fers the same upper bound on delay as Stop-and-Go, but does not guarantee a lower bound on delay . The same arguments in the discussion of Stop-and-Go also apply.
Reference: [13] <author> L. </author> <title> Kleinrock, </title> <journal> Queueing Systems, </journal> <volume> Vol. </volume> <pages> 1. </pages> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1975. </year>
Reference-contexts: This inequality is a function of the probability distribution of delays of packets of the session in its reference server , i.e. a fi xed-rate server, which is wellstudied <ref> [ 13, 22] </ref>. This inequality says that an upper bound on the probability distribution of delays is A token bucket filter is characterized by two parameters, a rate and the maximum number of tokens ( ) the bucket can store. Initially, the bucket has tokens (a full bucket).
Reference: [14] <author> J. Kurose, </author> <title> On Computing Per-session Performance Bounds in HighSpeed Multi-hop Computer Networks, </title> <booktitle> ACM Sigmetrics 92 , pp. </booktitle> <pages> 128-139, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The reader is referred to [11] for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a net work setting <ref> [2, 3, 14, 23] </ref>. In [2, 3], Cruz uses a non-probabilistic approach to characterize each session entering the network the burstiness constraint , which is in principle very similar to a token bucket filter. <p> In [2, 3], Cruz uses a non-probabilistic approach to characterize each session entering the network the burstiness constraint , which is in principle very similar to a token bucket filter. Under this assumption, a methodology is proposed to calculate per-session upper bounds on delay and buffer requirements. Kurose in <ref> [ 14] </ref>, and Yaron and Sidi in [ 23] describe methods to calculate bounds on the distribution of delay and buffer occupancy when all sessions entering the network are stochastically bounded. <p> Kurose in [ 14], and Yaron and Sidi in [ 23] describe methods to calculate bounds on the distribution of delay and buffer occupancy when all sessions entering the network are stochastically bounded. The work in <ref> [2, 3, 14, 23] </ref> differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session, while the methodology in [ 2, 3, 14, 23] provides the upper bound on the delay distribution directly. <p> The work in [2, 3, 14, 23] differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session, while the methodology in <ref> [ 2, 3, 14, 23] </ref> provides the upper bound on the delay distribution directly. <p> to provide this function for sessions with any kind of dynamic traffic behavior, and this function depends only on the session in question, i.e. the dynamic traf fic behavior of other sessions does not enter into consideration (i.e. the Leave-in-Time service discipline provides isolation between sessions), while the methodology in <ref> [2, 3, 14, 23] </ref> is based on the traffic characterization of all sessions sharing network servers with the session in question, and the dynamic traffic behavior of all sessions enters in the calculation of the delay distribution. 4 Conclusions We have presented the Leave-in-T ime service discipline which provides sessions with
Reference: [15] <author> A. M. Lee, </author> <title> Applied Queueing Theory . London: </title> <publisher> Macmillan, </publisher> <address> New York: St. </address> <publisher> Martins Press, </publisher> <year> 1966. </year>
Reference: [16] <author> A. K. Parekh, </author> <title> A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks, </title> <type> Ph.D. Dissertation, </type> <institution> Massachusetts Institute of Technology, LIDS-TH-2089, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the fi nite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [5], JitterEDD [21], RCSP [25], Virtual Clock [28], PGPS <ref> [ 16, 17, 18, 19] </ref>, Stop-and-Go [ 8, 9, 10], and Hierarchical Round Robin [ 12]. <p> For the special case where Leave-in-T ime operates like VirtualClock, we will show that the upper bound on delay for sessions conforming to a token bucket fi lter (also called leaky bucket constrained sessions) is the same as the upper bound on delay given by PGPS <ref> [ 16, 17, 18, 19] </ref>. PGPS is Parekh and Gallagers method for computing delay bounds under Weighted Fair Queueing [4]. An important problem we address is that, in general, an upper bound on delay will grow linearly with the connection length. <p> For a session conforming to a token bucket filter ( Thus, , N 1, (15) for a session conforming to a token bucket fi lter ( ). This result is the same as that found using PGPS <ref> [ 16, 17, 18, 19] </ref> (see equation (4.36) in [16], or equation (23) in [18]) and for Leave-in-Time with admission control procedure 1 (which we define later) with one class and , since in this case is zero and . 2.3.2 Upper Bound on the End-to-End Delay Distribution where denotes the <p> For a session conforming to a token bucket filter ( Thus, , N 1, (15) for a session conforming to a token bucket fi lter ( ). This result is the same as that found using PGPS [ 16, 17, 18, 19] (see equation (4.36) in <ref> [16] </ref>, or equation (23) in [18]) and for Leave-in-Time with admission control procedure 1 (which we define later) with one class and , since in this case is zero and . 2.3.2 Upper Bound on the End-to-End Delay Distribution where denotes the probability that delay is larger than , is the <p> Weighted Fair Queueing (WFQ) is proposed in [4] and is a service discipline that tries to emulate the service pro vided by a bit-by-bit round robin server. Each packet is stamped with the finishing round number (or virtual time fin ishing time , as called by Parekh in <ref> [ 16] </ref>) at which the packet would have fi nished transmission, had the server been doing a bit-by-bit round robin. Packets are served in increasing order of fi nishing round number. <p> Packets are served in increasing order of fi nishing round number. Packet-by-Packet Generalized Processor Sharing (PGPS) is the name given in <ref> [16, 17, 18, 19] </ref> to a method for computing delay bounds under WFQ when sessions conform to a token bucket filter.
Reference: [17] <author> A. K. Parekh, and G. Gallager, </author> <title> A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks - The Single Node Case, </title> <booktitle> In Proceedings of IEEE INFOCOM 92 , Vol. </booktitle> <volume> 2, </volume> <pages> pp. 915-924, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the fi nite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [5], JitterEDD [21], RCSP [25], Virtual Clock [28], PGPS <ref> [ 16, 17, 18, 19] </ref>, Stop-and-Go [ 8, 9, 10], and Hierarchical Round Robin [ 12]. <p> For the special case where Leave-in-T ime operates like VirtualClock, we will show that the upper bound on delay for sessions conforming to a token bucket fi lter (also called leaky bucket constrained sessions) is the same as the upper bound on delay given by PGPS <ref> [ 16, 17, 18, 19] </ref>. PGPS is Parekh and Gallagers method for computing delay bounds under Weighted Fair Queueing [4]. An important problem we address is that, in general, an upper bound on delay will grow linearly with the connection length. <p> For a session conforming to a token bucket filter ( Thus, , N 1, (15) for a session conforming to a token bucket fi lter ( ). This result is the same as that found using PGPS <ref> [ 16, 17, 18, 19] </ref> (see equation (4.36) in [16], or equation (23) in [18]) and for Leave-in-Time with admission control procedure 1 (which we define later) with one class and , since in this case is zero and . 2.3.2 Upper Bound on the End-to-End Delay Distribution where denotes the <p> Packets are served in increasing order of fi nishing round number. Packet-by-Packet Generalized Processor Sharing (PGPS) is the name given in <ref> [16, 17, 18, 19] </ref> to a method for computing delay bounds under WFQ when sessions conform to a token bucket filter.
Reference: [18] <author> A. K. Parekh, and G. Gallager, </author> <title> A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks - The Multiple Node Case, </title> <booktitle> In Proceedings of IEEE INFOCOM 93 , Vol. </booktitle> <volume> 2, </volume> <pages> pp. 521-530, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the fi nite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [5], JitterEDD [21], RCSP [25], Virtual Clock [28], PGPS <ref> [ 16, 17, 18, 19] </ref>, Stop-and-Go [ 8, 9, 10], and Hierarchical Round Robin [ 12]. <p> For the special case where Leave-in-T ime operates like VirtualClock, we will show that the upper bound on delay for sessions conforming to a token bucket fi lter (also called leaky bucket constrained sessions) is the same as the upper bound on delay given by PGPS <ref> [ 16, 17, 18, 19] </ref>. PGPS is Parekh and Gallagers method for computing delay bounds under Weighted Fair Queueing [4]. An important problem we address is that, in general, an upper bound on delay will grow linearly with the connection length. <p> For a session conforming to a token bucket filter ( Thus, , N 1, (15) for a session conforming to a token bucket fi lter ( ). This result is the same as that found using PGPS <ref> [ 16, 17, 18, 19] </ref> (see equation (4.36) in [16], or equation (23) in [18]) and for Leave-in-Time with admission control procedure 1 (which we define later) with one class and , since in this case is zero and . 2.3.2 Upper Bound on the End-to-End Delay Distribution where denotes the <p> This result is the same as that found using PGPS [ 16, 17, 18, 19] (see equation (4.36) in [16], or equation (23) in <ref> [18] </ref>) and for Leave-in-Time with admission control procedure 1 (which we define later) with one class and , since in this case is zero and . 2.3.2 Upper Bound on the End-to-End Delay Distribution where denotes the probability that delay is larger than , is the end-to-end delay packet session experiences <p> Packets are served in increasing order of fi nishing round number. Packet-by-Packet Generalized Processor Sharing (PGPS) is the name given in <ref> [16, 17, 18, 19] </ref> to a method for computing delay bounds under WFQ when sessions conform to a token bucket filter.
Reference: [19] <author> A. K. Parekh, and G. Gallager, </author> <title> A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks: The Single-Node Case, </title> <journal> In IEEE/ACM Transactions on Networking , Vol. </journal> <volume> 1, No. 3, </volume> <pages> pp. 344-357, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the fi nite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [5], JitterEDD [21], RCSP [25], Virtual Clock [28], PGPS <ref> [ 16, 17, 18, 19] </ref>, Stop-and-Go [ 8, 9, 10], and Hierarchical Round Robin [ 12]. <p> For the special case where Leave-in-T ime operates like VirtualClock, we will show that the upper bound on delay for sessions conforming to a token bucket fi lter (also called leaky bucket constrained sessions) is the same as the upper bound on delay given by PGPS <ref> [ 16, 17, 18, 19] </ref>. PGPS is Parekh and Gallagers method for computing delay bounds under Weighted Fair Queueing [4]. An important problem we address is that, in general, an upper bound on delay will grow linearly with the connection length. <p> For a session conforming to a token bucket filter ( Thus, , N 1, (15) for a session conforming to a token bucket fi lter ( ). This result is the same as that found using PGPS <ref> [ 16, 17, 18, 19] </ref> (see equation (4.36) in [16], or equation (23) in [18]) and for Leave-in-Time with admission control procedure 1 (which we define later) with one class and , since in this case is zero and . 2.3.2 Upper Bound on the End-to-End Delay Distribution where denotes the <p> Packets are served in increasing order of fi nishing round number. Packet-by-Packet Generalized Processor Sharing (PGPS) is the name given in <ref> [16, 17, 18, 19] </ref> to a method for computing delay bounds under WFQ when sessions conform to a token bucket filter.
Reference: [20] <author> J. R. Shelton, </author> <title> Solution Methods for Waiting Line Problems, </title> <journal> Journal of Industrial Engineering July-August 1960. </journal>
Reference: [21] <author> D. Verma, H. Zhang, and D. Ferrari, </author> <title> Delay Jitter Control for Real-Time Communication in a Packet Switching Network, </title> <booktitle> In Proceedings of IEEE TriCom 91 , pp. </booktitle> <pages> 35-43, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the fi nite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [5], JitterEDD <ref> [21] </ref>, RCSP [25], Virtual Clock [28], PGPS [ 16, 17, 18, 19], Stop-and-Go [ 8, 9, 10], and Hierarchical Round Robin [ 12]. <p> Thus, a session can know what its performance bounds will be based on how it and it alone behaves. Leave-in-Time builds on ideas found in VirtualClock [28] and JitterEDD <ref> [21] </ref>. The reader will see that Leave-in-Time exploits the good properties of VirtualClock and Jitter -EDD while maintaining ef ficiency and exibility, and providing desirable performance bounds. <p> The nonwork-conserving service discipline has two components (see Figure 2): a set of delay regulators that hold packets until their eligibility times, and a server transmission queue. The use of delay regulators to shape the traffic pattern to reduce delay jitter is based on JitterEDD <ref> [21] </ref>. A session desiring delay jitter control (i.e. delay jitter reduction) is assigned a delay regulator. A session not desiring delay jitter control has all of its packets sent directly to the server queue upon arrival, i.e. the eligibility time equals the arrival time. <p> As in JitterEDD <ref> [21] </ref>, the holding time calculated at server node - 1 is trans mitted in the packet s header to node . Note that is always positive, and that (both proven in the Appendix). <p> server to the right by a constant. 2.3.3 Upper Bound on End-to-End Delay Jitter Define the end-to-end delay jitter of session traversing servers 1 to as the maximum difference between the delays experienced by any two packets from session (this is the same defi nition as the one used in <ref> [ 21] </ref>). This definition implies that must be finite (i.e. the session has an upper bound on end-to-end delay). <p> exploitation of the bandwidth of the server , since the values assigned to are implicitly pre-allocated, while admission control procedure 3 may lead to incomplete usage of bandwidth, since may be assigned arbitrary small values. 3 Comparing Leave-in-Time to Other Schemes Leave-in-Time is most related to VirtualClock [28] and JitterEDD <ref> [21] </ref>. In VirtualClock, each packet is assigned a transmission deadline and packets are served in increasing order of deadline. The transmission deadlines are calculated by an equation equivalent to equation (2). The Leave-in-Time service discipline builds on equation (2) through two generalizations. <p> Except for the upper bound on end-to-end delay (presented in [ 7]), these results are new for the VirtualClock service discipline. In DelayEDD [ 5], and its extension Jitter -EDD <ref> [21] </ref> (EDD stands for earliest-due-date), packets are assigned deadlines and transmitted in order of increasing deadline. The deadline of a packet is not directly coupled to the reserved bandwidth of its session as in the Leave-in-T ime scheme (see equation (11)).
Reference: [22] <author> R. W. Wolff, </author> <title> Stochastic Modelling and the Theory of Queues. </title> , <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: This inequality is a function of the probability distribution of delays of packets of the session in its reference server , i.e. a fi xed-rate server, which is wellstudied <ref> [ 13, 22] </ref>. This inequality says that an upper bound on the probability distribution of delays is A token bucket filter is characterized by two parameters, a rate and the maximum number of tokens ( ) the bucket can store. Initially, the bucket has tokens (a full bucket).
Reference: [23] <author> O. Yaron and M. Sidi, </author> <title> Calculating Performance Bounds in Communication Networks, </title> <booktitle> In Proceedings of IEEE INFOCOM 93 , Vol. </booktitle> <volume> 2, </volume> <pages> pp. 539-545, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: The reader is referred to [11] for a relevant work on fair queueing systems. Others have addressed the possibility of providing per session bounds on delay and delay distribution in a net work setting <ref> [2, 3, 14, 23] </ref>. In [2, 3], Cruz uses a non-probabilistic approach to characterize each session entering the network the burstiness constraint , which is in principle very similar to a token bucket filter. <p> Under this assumption, a methodology is proposed to calculate per-session upper bounds on delay and buffer requirements. Kurose in [ 14], and Yaron and Sidi in <ref> [ 23] </ref> describe methods to calculate bounds on the distribution of delay and buffer occupancy when all sessions entering the network are stochastically bounded. <p> Kurose in [ 14], and Yaron and Sidi in [ 23] describe methods to calculate bounds on the distribution of delay and buffer occupancy when all sessions entering the network are stochastically bounded. The work in <ref> [2, 3, 14, 23] </ref> differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session, while the methodology in [ 2, 3, 14, 23] provides the upper bound on the delay distribution directly. <p> The work in [2, 3, 14, 23] differs from our work in that the Leave-in-Time scheme provides a function to calculate an upper bound on the delay distribution for a session, while the methodology in <ref> [ 2, 3, 14, 23] </ref> provides the upper bound on the delay distribution directly. <p> to provide this function for sessions with any kind of dynamic traffic behavior, and this function depends only on the session in question, i.e. the dynamic traf fic behavior of other sessions does not enter into consideration (i.e. the Leave-in-Time service discipline provides isolation between sessions), while the methodology in <ref> [2, 3, 14, 23] </ref> is based on the traffic characterization of all sessions sharing network servers with the session in question, and the dynamic traffic behavior of all sessions enters in the calculation of the delay distribution. 4 Conclusions We have presented the Leave-in-T ime service discipline which provides sessions with
Reference: [24] <author> D. Yates, J. Kurose, D. Towsley, and M. G. Hluchyj, </author> <title> On Per-session End-to-End Delay Distributions and The Call Admission Problem for Real-Time Applications with QOS Requirements, </title> <journal> In Proceedings of ACM SIG COMM 93 , pp. </journal> <pages> 2-12, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: The delay jitter bound provided by the Leave-in-Time scheme is (inequality (17)), while in Stop-and-Go it is 2 )-smooth session conforms to a token bucket filter ( ). Thus, from (14), , which is competitive with the result of Stop-and-Go. The reader is referred to <ref> [ 24] </ref> which compares the delay distribution seen by sessions under FCFS multiplexing with the delay bound computed with Cruzs method [ 2, 3], the delay bound using Stop-and-Go, and the delay bound using PGPS (presented later in this section).
Reference: [25] <author> H. Zhang and D. Ferrari, </author> <title> Rate-Controlled Static-Priority Queueing, </title> <booktitle> In Proceedings of IEEE INFOCOM 93 pp. </booktitle> <pages> 227-236, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the fi nite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [5], JitterEDD [21], RCSP <ref> [25] </ref>, Virtual Clock [28], PGPS [ 16, 17, 18, 19], Stop-and-Go [ 8, 9, 10], and Hierarchical Round Robin [ 12]. <p> The traffic characterization speci fies a minimum packet interarrival time , a minimum average packet interarrival time over an averaging interval of time , and a maximum packet length . In <ref> [ 25] </ref>, bandwidth is reserved at the peak rate implied by This admission control is refined in [26], where both are taken into consideration. <p> It of fers the same upper bound on delay as Stop-and-Go, but does not guarantee a lower bound on delay . The same arguments in the discussion of Stop-and-Go also apply. Rate-Controlled Static-Priority Queueing (RCSP) <ref> [25] </ref> is a service discipline that avoids both framing strategies (as in Stop-and-Go and HRR) and sorted priority queues (that are used in all the other service disciplines studied here), by the separation of rate-control and delay-control in the design of the server , which allows it to provide throughput, delay,
Reference: [26] <author> H. Zhang and D. Ferrari, </author> <title> Improving Utilization for Deterministic Service in Multimedia Communication, </title> <booktitle> Proceedings of the International Conference on Multimedia Computing and Systems , pp. </booktitle> <pages> 295-304, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The traffic characterization speci fies a minimum packet interarrival time , a minimum average packet interarrival time over an averaging interval of time , and a maximum packet length . In [ 25], bandwidth is reserved at the peak rate implied by This admission control is refined in <ref> [26] </ref>, where both are taken into consideration. In the Leave-in-Time scheme, bandwidth may be reserved at the average rate, although a session may need to reserve more bandwidth than its average rate in order to reduce the end-to-end delay, due to the coupling between delay bound and bandwidth allo cation.
Reference: [27] <author> H. Zhang and S. Keshav, </author> <title> Comparison of Rate-Based Service Disciplines, </title> <booktitle> In Proceedings of ACM SIGCOMM 91 , pp. </booktitle> <pages> 113-121, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: First Generalization : The base algorithm is generalized by allowing it to work in a nonwork-conserving mode. Nonwork-conserving service disciplines can generally provide lower variance in delay (or delay jitter) than with work-conserving ones <ref> [ 27] </ref>. Thus, packets are not necessarily immediately available for transmission upon arrival, and thus arrived packets may be delayed before being queued for transmission. The time a packet joins the server transmission queue is called the eligibility time of the packet. <p> This leads to a schedulability test at connection establishment time [ 5] to avoid scheduling saturation, which can occur even if bandwidth is not overbooked <ref> [ 5, 27] </ref>. The schedulability test is then a compromise on the looser coupling between reserved rate and delay bound. The Leave-in-Time scheme needs an admission control procedure for the same reason.
Reference: [28] <author> L. Zhang, VirtualClock: </author> <title> A New Traffic Control Algorithm for Packet Switching Networks, </title> <journal> In ACM Transactions on Computer Systems , Vol. </journal> <volume> 9, No. 2, </volume> <pages> pp. 101-124, </pages> <month> May </month> <year> 1991. </year> <note> Also in Proceedings of ACM SIGCOMM 90 pp. 19-29, </note> <month> September </month> <year> 1990. </year>
Reference-contexts: This guaranteed data rate generally requires some admission control mechanism to allocate the fi nite link capacity of the servers. Several rate-based service disciplines have been proposed: DelayEDD [5], JitterEDD [21], RCSP [25], Virtual Clock <ref> [28] </ref>, PGPS [ 16, 17, 18, 19], Stop-and-Go [ 8, 9, 10], and Hierarchical Round Robin [ 12]. <p> Thus, a session can know what its performance bounds will be based on how it and it alone behaves. Leave-in-Time builds on ideas found in VirtualClock <ref> [28] </ref> and JitterEDD [21]. The reader will see that Leave-in-Time exploits the good properties of VirtualClock and Jitter -EDD while maintaining ef ficiency and exibility, and providing desirable performance bounds. <p> 2 allow complete exploitation of the bandwidth of the server , since the values assigned to are implicitly pre-allocated, while admission control procedure 3 may lead to incomplete usage of bandwidth, since may be assigned arbitrary small values. 3 Comparing Leave-in-Time to Other Schemes Leave-in-Time is most related to VirtualClock <ref> [28] </ref> and JitterEDD [21]. In VirtualClock, each packet is assigned a transmission deadline and packets are served in increasing order of deadline. The transmission deadlines are calculated by an equation equivalent to equation (2). The Leave-in-Time service discipline builds on equation (2) through two generalizations.
References-found: 28

