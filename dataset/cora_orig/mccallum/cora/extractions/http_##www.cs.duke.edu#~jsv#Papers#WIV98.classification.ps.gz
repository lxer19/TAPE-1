URL: http://www.cs.duke.edu/~jsv/Papers/WIV98.classification.ps.gz
Refering-URL: http://www.cs.duke.edu/~jsv/Papers/catalog/node58.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Scalable Mining for Classification Rules in Relational Databases  
Author: Min Wang Bala Iyer Jeffrey Scott Vitter 
Address: Durham, NC 27708 San Jose, CA 95161 Durham, NC 27708  
Affiliation: Dept. of Computer Science Database Technology Institute Dept. of Computer Science Duke University IBM Santa Teresa Lab Duke University  
Abstract: Classification is a key function of many "business intelligence" toolkits and a fundamental building block in data mining. Immense data may be needed to train a classifier for good accuracy. The state-of-art classifiers [21, 25] need an in-memory data structure of size O(N ), where N is the size of the training data, to achieve efficiency. For large data sets, such a data structure will not fit in the internal memory. The best previously known classifier does a quadratic number of I/Os for large N . In this paper, we propose a novel classification algorithm (classifier) called MIND (MINing in Databases). MIND can be phrased in such a way that its implementation is very easy using the extended relational calculus SQL, and this in turn allows the classifier to be built into a relational database system directly. MIND is truly scalable with respect to I/O efficiency, which is important since scalability is a key requirement for any data mining algorithm. We built a prototype of MIND in the relational database manager DB2 and benchmarked its performance. We describe the working prototype and report the measured performance with respect to the previous method of choice. MIND scales not only with the size of the datasets but also with the number of processors on an IBM SP2 computer system. Even on uniproces-sors, MIND scales well beyond the dataset sizes previously published for classifiers. We also give some insights that may have an impact on the evolution of the extended relational calculus SQL. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Adrians and D. Zantinge. </author> <title> Data Mining. </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year>
Reference-contexts: MIND leverages the extended relational calculus SQL, an industry standard, by reducing the solution to novel manipulations of SQL 1 statements embedded in a small program written in C. MIND scales, as long as the database primitives it uses scale. We can follow the recommendations in <ref> [1, 20] </ref> that numerical data be discretized so that each attribute has a reasonable number of distinct values. <p> By including leaf num in the attribute list for grouping, MIND collects summaries for every leaf in one query. In the case that the number of distinct values of attr i is very large, preprocessing is often done in practice to further discretize it <ref> [1, 20] </ref>. Dis-cretization of variable values into a smaller number of classes is sometimes referred to as "encoding" in data mining practice [1]. Roughly speaking, this is done to obtain a measure of aggregate behavior that may be detectable [22]. <p> In the case that the number of distinct values of attr i is very large, preprocessing is often done in practice to further discretize it [1, 20]. Dis-cretization of variable values into a smaller number of classes is sometimes referred to as "encoding" in data mining practice <ref> [1] </ref>. Roughly speaking, this is done to obtain a measure of aggregate behavior that may be detectable [22].
Reference: [2] <author> R. Agrawal, S. Ghosh, T. Imielinski, B. Iyer, and A. Swami. </author> <title> An interval classifier for database mining applications. </title> <booktitle> In Proceedings of the 1992 International Conference on Very Large Databases, </booktitle> <pages> pages 560-573, </pages> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: In our current working prototype, this is done by using user-defined function as we described in Section 3.1. Owing to the lack of a classification benchmark, we used the synthetic database proposed in <ref> [2] </ref>. <p> Ten classifier functions are proposed in <ref> [2] </ref> to produce databases with different complexities. We run our prototype using function 2. It generates a database with two classes: Group A and Group B. The description of the class predicate for Group A is shown below.
Reference: [3] <author> R. Agrawal and K. Shim. </author> <title> Developing tightly-coupled data mining applications on a relational database system. </title> <booktitle> In Proceedings of the 2nd International Conference on Knowledge Discovery in Databases and Data Mining, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: Since such an operator is not supported, we make use of the object extensions in DB2, the user-defined function (udf) [27, 8, 15], which is another reason why MIND is efficient. User-defined functions are used for association in <ref> [3] </ref>. An external udf is a function that is written by a user in a host programming language. The CREATE FUNCTION statement for an external function tells the system where to find the code that implements the function.
Reference: [4] <author> R. D. Barve, E. F. Grove, and J. S. Vitter. </author> <title> Simple randomized mergesort on parallel disks. </title> <journal> Parallel Computing, </journal> <volume> 23(4), </volume> <year> 1997. </year> <title> Special issue on parallel I/O. An earlier version appears in Proc. </title> <booktitle> of the 8th Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA '96), </booktitle> <address> Padua, Italy, </address> <month> June </month> <year> 1996, </year> <pages> 109-118. </pages>
Reference-contexts: tables cannot fit in memory, they can be formed by sorting in linear time, if we make the weak assumption that (M=B) c D=B for some small positive constant c, where D, M , and B are respectively the dimension table size, the internal memory size, and the block size <ref> [4, 29] </ref>.
Reference: [5] <author> G. Bhargava, P. Goel, and B. Iyer. </author> <title> Hypergraph based reordering of outer join queries with complex predicates. </title> <booktitle> In Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data, </booktitle> <year> 1995. </year>
Reference-contexts: The table formation query has a nested subquery in it. The performance and optimization of such queries are studied in <ref> [5, 23, 13] </ref>. We repeat the above procedure for all other attributes.
Reference: [6] <author> L. Breiman et al. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont, </address> <year> 1984. </year>
Reference-contexts: The objective of classification is to process the DETAIL table and produce a classifier, which contains a description (model) for each class. The models will be used to classify future data for which the class labels are unknown (see <ref> [6, 24, 23, 7] </ref>). A simple illustration of training data is shown in Table 1. The examples reflect the past experience of an organization extending credit. From those examples, we can generate the classifier shown in Figure 1. <p> Several splitting indices have recently been proposed. We use the gini index, originally proposed in <ref> [6] </ref> and used in [21, 25], because it gives acceptable accuracy. The accuracy of our classifier is therefore the same as those in [21, 25]. <p> the gini index of the divided data gini split (S) is given by gini split (S) = N 1 gini (S 1 ) + N 2 gini (S 2 ) (2) The attribute containing the split point achieving the smallest gini index value is then chosen to split the node <ref> [6] </ref>. Computing the gini index is the most expensive part of the algorithm since finding the best split for a node requires evaluating the gini index value for each attribute at each possible split point.
Reference: [7] <author> J. Catlett. </author> <title> Megainduction: Machine Learning on Very Large Databases. </title> <type> PhD thesis, </type> <institution> University of Sydney, </institution> <year> 1991. </year>
Reference-contexts: The objective of classification is to process the DETAIL table and produce a classifier, which contains a description (model) for each class. The models will be used to classify future data for which the class labels are unknown (see <ref> [6, 24, 23, 7] </ref>). A simple illustration of training data is shown in Table 1. The examples reflect the past experience of an organization extending credit. From those examples, we can generate the classifier shown in Figure 1.
Reference: [8] <author> D. Chamberlin. </author> <title> Using the New DB2: IBM's Object-Relational Database System. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year>
Reference-contexts: Since such an operator is not supported, we make use of the object extensions in DB2, the user-defined function (udf) <ref> [27, 8, 15] </ref>, which is another reason why MIND is efficient. User-defined functions are used for association in [3]. An external udf is a function that is written by a user in a host programming language.
Reference: [9] <author> D. Chamberlin. </author> <type> Personal communication, </type> <year> 1997. </year>
Reference-contexts: In the case of a file, DETAIL resolves to an execution of a user-defined function (e.g. fread in UNIX) <ref> [9] </ref>). hundreds [22]. By including leaf num in the attribute list for grouping, MIND collects summaries for every leaf in one query. In the case that the number of distinct values of attr i is very large, preprocessing is often done in practice to further discretize it [1, 20].
Reference: [10] <author> D. Chamberlin et al. Seqel: </author> <title> A structured english query language. </title> <booktitle> In Proc. of ACM SIGMOD Workshop on Data Description, Access, and Control, </booktitle> <month> May </month> <year> 1974. </year>
Reference-contexts: A theoretical performance analysis is given in Section 4. In Section 5, we present our experimental results. We make concluding remarks in Section 6. 1 SQL is simply an implementation of the relational calculus proposed in [11]. A few extensions have been done since then <ref> [28, 10] </ref>. 2 The Algorithm 2.1 Overview A decision tree classifier is built in two phases: a growth phase and a pruning phase.
Reference: [11] <author> E. F. Codd. </author> <title> A relational model of data for large shared data banks. </title> <journal> CACM, </journal> <volume> 13(6), </volume> <month> June </month> <year> 1970. </year>
Reference-contexts: The database implementation of our algorithm is described in Section 3. A theoretical performance analysis is given in Section 4. In Section 5, we present our experimental results. We make concluding remarks in Section 6. 1 SQL is simply an implementation of the relational calculus proposed in <ref> [11] </ref>. A few extensions have been done since then [28, 10]. 2 The Algorithm 2.1 Overview A decision tree classifier is built in two phases: a growth phase and a pruning phase.
Reference: [12] <author> T. Dietterich, M. Kearns, and Y. Mansour. </author> <title> Applying the weak learning framework to understand and improve C4.5. </title> <booktitle> In Proceedings of the 13th International Conference on Machine Learning, </booktitle> <pages> pages 96-104, </pages> <year> 1996. </year>
Reference-contexts: It's very difficult to estimate how fast the algo rithm will give a satisfactory solution. * The complexity of the model. The best known theoretical upper bounds on sample size suggest that the training set size may need to be immense to assure good accuracy <ref> [12, 19] </ref>. 2. In many real applications, customers insist that all data, not just a sample of the data, must be processed. Since the data are usually obtained from valuable resources at considerable expense, they should be used as a whole throughout the analysis.
Reference: [13] <author> R. A. Ganski and H. K. T. Wong. </author> <title> Optimization of nested sql queried revisited. </title> <booktitle> In Proceeding of the 1987 ACM SIGMOD International Conference on Management of Data, </booktitle> <year> 1987. </year>
Reference-contexts: The table formation query has a nested subquery in it. The performance and optimization of such queries are studied in <ref> [5, 23, 13] </ref>. We repeat the above procedure for all other attributes.
Reference: [14] <author> S. Hasty. </author> <title> Mining databases. </title> <journal> Apparel Industry Magazine, </journal> <volume> 57(5), </volume> <year> 1996. </year>
Reference-contexts: 1 Introduction Information technology has developed rapidly over the last three decades. To make decisions faster, many companies have combined data from various sources in relational databases <ref> [14] </ref>. The data contain patterns previously undeciphered that are valuable for business purposes. Data mining is the process of extracting valid, previously unknown, and ultimately comprehensible information from large databases and using it to make crucial business decisions.
Reference: [15] <author> IBM. </author> <title> IBM DATABASE 2 Application Programming Guide-for common servers, </title> <note> version 2 edition. </note>
Reference-contexts: Since such an operator is not supported, we make use of the object extensions in DB2, the user-defined function (udf) <ref> [27, 8, 15] </ref>, which is another reason why MIND is efficient. User-defined functions are used for association in [3]. An external udf is a function that is written by a user in a host programming language.
Reference: [16] <institution> IBM Germany. </institution> <note> IBM Intelligence Miner User's Guide, version 1 edition, </note> <month> July </month> <year> 1996. </year>
Reference-contexts: Since the data are usually obtained from valuable resources at considerable expense, they should be used as a whole throughout the analysis. Therefore, designing a scalable classifier may be neces sary or preferable, although we can always use random sampling in places where it is appropriate. In <ref> [21, 25, 16] </ref>, data access for classification follows "a record at a time" access paradigm. Scalability is addressed individually for each operating system, hardware platform, and architecture. In this paper, we introduce the MIND (MINing in Databases) classifier.
Reference: [17] <author> T. Imielinsk and H. Mannila. </author> <title> A database perspective on knowledge discovery. </title> <journal> Communication of the ACM, </journal> <volume> 39(11), </volume> <month> November </month> <year> 1996. </year>
Reference-contexts: The extracted information can be used to form a prediction or classification model, or to identify relations between database records. Since extracting data to files before running data mining functions would require extra I/O costs, users as well as previous investigators <ref> [18, 17] </ref> have pointed to the need for the relational database managers to have these functions built in. The classification problem can be described informally as follows: We are given a training set (or DETAIL table) consisting of many training examples.
Reference: [18] <author> T. Imielinski. </author> <title> From file mining to database mining. </title> <booktitle> In Proceedings of the 1996 SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: The extracted information can be used to form a prediction or classification model, or to identify relations between database records. Since extracting data to files before running data mining functions would require extra I/O costs, users as well as previous investigators <ref> [18, 17] </ref> have pointed to the need for the relational database managers to have these functions built in. The classification problem can be described informally as follows: We are given a training set (or DETAIL table) consisting of many training examples.
Reference: [19] <author> M. Kearns and Y. Mansour. </author> <title> On the boosting ability of top-down decision tree learning algorithms. </title> <booktitle> In Proceedings of the 28th ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 459-468, </pages> <year> 1996. </year>
Reference-contexts: It's very difficult to estimate how fast the algo rithm will give a satisfactory solution. * The complexity of the model. The best known theoretical upper bounds on sample size suggest that the training set size may need to be immense to assure good accuracy <ref> [12, 19] </ref>. 2. In many real applications, customers insist that all data, not just a sample of the data, must be processed. Since the data are usually obtained from valuable resources at considerable expense, they should be used as a whole throughout the analysis.
Reference: [20] <author> H. Lu et al. </author> <title> On preprocessing data for efficient classification. </title> <booktitle> In Proceedings of SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: MIND leverages the extended relational calculus SQL, an industry standard, by reducing the solution to novel manipulations of SQL 1 statements embedded in a small program written in C. MIND scales, as long as the database primitives it uses scale. We can follow the recommendations in <ref> [1, 20] </ref> that numerical data be discretized so that each attribute has a reasonable number of distinct values. <p> By including leaf num in the attribute list for grouping, MIND collects summaries for every leaf in one query. In the case that the number of distinct values of attr i is very large, preprocessing is often done in practice to further discretize it <ref> [1, 20] </ref>. Dis-cretization of variable values into a smaller number of classes is sometimes referred to as "encoding" in data mining practice [1]. Roughly speaking, this is done to obtain a measure of aggregate behavior that may be detectable [22].
Reference: [21] <author> M. Mehta, R. Agrawal, and J. Rissanen. SLIQ: </author> <title> A fast scalable classifier for data mining. </title> <booktitle> In Proceedings of the 5th International Conference on Extending Database Technology, </booktitle> <address> Avignon, France, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: In salary age credit rating 65K 30 Safe 15K 23 Risky 75K 40 Safe 15K 28 Risky 100K 55 Safe 60K 45 Safe 62K 30 Risky Table 1: Training set data mining applications, it is common to have training sets with several million examples. It is observed in <ref> [21] </ref> that previously known classification algorithms do not scale. Random sampling is often an effective technique in dealing with large data sets. For simple applications whose inherent structures are not very complex, this approach is efficient and gives good results. <p> Since the data are usually obtained from valuable resources at considerable expense, they should be used as a whole throughout the analysis. Therefore, designing a scalable classifier may be neces sary or preferable, although we can always use random sampling in places where it is appropriate. In <ref> [21, 25, 16] </ref>, data access for classification follows "a record at a time" access paradigm. Scalability is addressed individually for each operating system, hardware platform, and architecture. In this paper, we introduce the MIND (MINing in Databases) classifier. <p> Splits for a categorical attribute A are of the form value (A) 2 S, where S is a subset of domain (A). We consider only binary splits as in <ref> [21, 25] </ref> for purpose of comparisons. After the tree has been fully grown, it is pruned to remove noise in order to obtain the final tree classifier. The tree growth phase is computationally much more expensive than the subsequent pruning phase. <p> do get the overall best split for it; partition the records and grow the tree for one more level according to the best splits; mark all small or pure leaves as STOP nodes; return T ; 2.2 Leaf node list data structure A powerful method called SLIQ was proposed in <ref> [21] </ref> as a semi-scalable classification algorithm. The key data structure used in SLIQ is a class list whose size is linear in the number of examples in the training set. <p> Several splitting indices have recently been proposed. We use the gini index, originally proposed in [6] and used in <ref> [21, 25] </ref>, because it gives acceptable accuracy. The accuracy of our classifier is therefore the same as those in [21, 25]. <p> Several splitting indices have recently been proposed. We use the gini index, originally proposed in [6] and used in <ref> [21, 25] </ref>, because it gives acceptable accuracy. The accuracy of our classifier is therefore the same as those in [21, 25]. For a data set S containing N examples from C classes, gini (S) is defined as gini (S) = 1 C X p 2 where p i is the relative frequency of class i in S. <p> For large N , SPRINT does a quadratic number of I/Os, whereas MIND scales well. 5 Experimental Results There are two important metrics to evaluate the quality of a classifier: classification accuracy and classification time. We compare our results with those of SLIQ <ref> [21] </ref> and SPRINT [25]. (For brevity, we include only SPRINT in this paper; comparisons showing the improvement of SPRINT over SLIQ are given in [25].) Unlike SLIQ and SPRINT, we use the classical database methodology of summarization. <p> Like SLIQ and SPRINT, we use the same metric (gini index) to choose the best split for each node, we grow our tree in a breadth-first fashion, and we prune it using the same pruning algorithm. Our classifier therefore generates a decision tree identical to the one produced by <ref> [21, 25] </ref> for the same training set, which facilitates meaningful comparisons of run time. The accuracy of SPRINT and SLIQ is discussed in [21, 25], where it is argued that the accuracy is sufficient. For our scaling experiments, we ran our prototype on large data sets. <p> Our classifier therefore generates a decision tree identical to the one produced by <ref> [21, 25] </ref> for the same training set, which facilitates meaningful comparisons of run time. The accuracy of SPRINT and SLIQ is discussed in [21, 25], where it is argued that the accuracy is sufficient. For our scaling experiments, we ran our prototype on large data sets.
Reference: [22] <author> H. Messatfa. </author> <type> Personal communications, </type> <year> 1997. </year>
Reference-contexts: In the case of a file, DETAIL resolves to an execution of a user-defined function (e.g. fread in UNIX) [9]). hundreds <ref> [22] </ref>. By including leaf num in the attribute list for grouping, MIND collects summaries for every leaf in one query. In the case that the number of distinct values of attr i is very large, preprocessing is often done in practice to further discretize it [1, 20]. <p> Dis-cretization of variable values into a smaller number of classes is sometimes referred to as "encoding" in data mining practice [1]. Roughly speaking, this is done to obtain a measure of aggregate behavior that may be detectable <ref> [22] </ref>. Alternatively, efficient external memory techniques can be used to form the dimension tables in a small number (typically one or two) linear passes, at the possible cost of some added complexity in the application program to give the proper hints to the DBMS, as suggested in Section 4.
Reference: [23] <author> S. K. Murthy. </author> <title> On Growing Better Decision Trees from Data. </title> <type> PhD thesis, </type> <institution> Johns Hopkins University, </institution> <year> 1995. </year>
Reference-contexts: The objective of classification is to process the DETAIL table and produce a classifier, which contains a description (model) for each class. The models will be used to classify future data for which the class labels are unknown (see <ref> [6, 24, 23, 7] </ref>). A simple illustration of training data is shown in Table 1. The examples reflect the past experience of an organization extending credit. From those examples, we can generate the classifier shown in Figure 1. <p> The table formation query has a nested subquery in it. The performance and optimization of such queries are studied in <ref> [5, 23, 13] </ref>. We repeat the above procedure for all other attributes.
Reference: [24] <author> J. Ross Quilan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufman, </publisher> <year> 1993. </year>
Reference-contexts: The objective of classification is to process the DETAIL table and produce a classifier, which contains a description (model) for each class. The models will be used to classify future data for which the class labels are unknown (see <ref> [6, 24, 23, 7] </ref>). A simple illustration of training data is shown in Table 1. The examples reflect the past experience of an organization extending credit. From those examples, we can generate the classifier shown in Figure 1.
Reference: [25] <author> J. C. Shafer, R. Agrawal, and M. Mehta. SPRINT: </author> <title> A scalable parallel classifier for data mining. </title> <booktitle> In Proceedings of the 1996 International Conference on Very Large Databases, </booktitle> <address> Mumbai (Bombay), India, </address> <month> Septem-ber </month> <year> 1996. </year>
Reference-contexts: Since the data are usually obtained from valuable resources at considerable expense, they should be used as a whole throughout the analysis. Therefore, designing a scalable classifier may be neces sary or preferable, although we can always use random sampling in places where it is appropriate. In <ref> [21, 25, 16] </ref>, data access for classification follows "a record at a time" access paradigm. Scalability is addressed individually for each operating system, hardware platform, and architecture. In this paper, we introduce the MIND (MINing in Databases) classifier. <p> A salient feature of MIND and one reason for its efficiency is its ability to do classification without any update to the DETAIL table. We analyze and compare the I/O complexities of MIND and the previous method of choice, the interesting method called SPRINT <ref> [25] </ref>. Our theoretical analysis and experimental results show that MIND scales well whereas SPRINT can exhibit quadratic I/O times. We describe our MIND algorithm in the next section. The database implementation of our algorithm is described in Section 3. A theoretical performance analysis is given in Section 4. <p> Splits for a categorical attribute A are of the form value (A) 2 S, where S is a subset of domain (A). We consider only binary splits as in <ref> [21, 25] </ref> for purpose of comparisons. After the tree has been fully grown, it is pruned to remove noise in order to obtain the final tree classifier. The tree growth phase is computationally much more expensive than the subsequent pruning phase. <p> The fact that the class list must be memory-resident puts a hard limitation on the size of the training set that SLIQ can handle. In the improved SPRINT classification algorithm <ref> [25] </ref>, new data structures attribute list and histogram are proposed. Although it is not necessary for the attribute list data structure to be memory resident, the histogram data structure must be in memory to insure good performance. To perform the split in [25], a hash table whose size is linear in <p> In the improved SPRINT classification algorithm <ref> [25] </ref>, new data structures attribute list and histogram are proposed. Although it is not necessary for the attribute list data structure to be memory resident, the histogram data structure must be in memory to insure good performance. To perform the split in [25], a hash table whose size is linear in the number of examples of the training set is used. When the hash table is too large to fit in memory, splitting is done in multiple steps, and SPRINT does not scale well. <p> Several splitting indices have recently been proposed. We use the gini index, originally proposed in [6] and used in <ref> [21, 25] </ref>, because it gives acceptable accuracy. The accuracy of our classifier is therefore the same as those in [21, 25]. <p> Several splitting indices have recently been proposed. We use the gini index, originally proposed in [6] and used in <ref> [21, 25] </ref>, because it gives acceptable accuracy. The accuracy of our classifier is therefore the same as those in [21, 25]. For a data set S containing N examples from C classes, gini (S) is defined as gini (S) = 1 C X p 2 where p i is the relative frequency of class i in S. <p> DIM i contains all the information we need to compute the gini index for any subset splitting. In fact, it is an analog of the count matrix in <ref> [25] </ref>, but formed with SQL operators. 1 i is a host variable, the value applies on invocation of the statement. 2 Again, note the transformation for the table name DIM i to column value i and column name attr i . <p> In this section we analyze the I/O complexity of both MIND and SPRINT and compare their performances. As we described in Section 2.1, the classification algorithm iteratively does two main operations: computing the splitting index (in our case, the gini index) and performing the partition. SPRINT <ref> [25] </ref> forms an attribute list (projection of the DETAIL table) for each attribute. In order to reduce the cost of computing the gini index, SPRINT presorts each attribute list and maintains the sorted order throughout the course of the algorithm. However, the use of attribute lists complicates the partitioning operation. <p> For large N , SPRINT does a quadratic number of I/Os, whereas MIND scales well. 5 Experimental Results There are two important metrics to evaluate the quality of a classifier: classification accuracy and classification time. We compare our results with those of SLIQ [21] and SPRINT <ref> [25] </ref>. (For brevity, we include only SPRINT in this paper; comparisons showing the improvement of SPRINT over SLIQ are given in [25].) Unlike SLIQ and SPRINT, we use the classical database methodology of summarization. <p> We compare our results with those of SLIQ [21] and SPRINT <ref> [25] </ref>. (For brevity, we include only SPRINT in this paper; comparisons showing the improvement of SPRINT over SLIQ are given in [25].) Unlike SLIQ and SPRINT, we use the classical database methodology of summarization. Like SLIQ and SPRINT, we use the same metric (gini index) to choose the best split for each node, we grow our tree in a breadth-first fashion, and we prune it using the same pruning algorithm. <p> Like SLIQ and SPRINT, we use the same metric (gini index) to choose the best split for each node, we grow our tree in a breadth-first fashion, and we prune it using the same pruning algorithm. Our classifier therefore generates a decision tree identical to the one produced by <ref> [21, 25] </ref> for the same training set, which facilitates meaningful comparisons of run time. The accuracy of SPRINT and SLIQ is discussed in [21, 25], where it is argued that the accuracy is sufficient. For our scaling experiments, we ran our prototype on large data sets. <p> Our classifier therefore generates a decision tree identical to the one produced by <ref> [21, 25] </ref> for the same training set, which facilitates meaningful comparisons of run time. The accuracy of SPRINT and SLIQ is discussed in [21, 25], where it is argued that the accuracy is sufficient. For our scaling experiments, we ran our prototype on large data sets. <p> Figure 2 hints that our algorithm achieves linear scalability with respect to the training set size. Figure 3 shows that the time per example curve stays flat when the training set size increases. The corresponding curve for <ref> [25] </ref> appears to be growing slightly on the largest cases. Figure 4 is the performance comparison between MIND and SPRINT. MIND ran on a processor with a slightly slower clock rate.
Reference: [26] <author> J. B. Sinclair. </author> <type> Personal communication, </type> <year> 1997. </year>
Reference-contexts: Existing buffer management schemes that rely on I/O latency appear to synchronize access to DETAIL for the different attributes. The idea is that one query piggy-backs onto another query's I/O data stream. Results from early experiments are encouraging <ref> [26] </ref>. It is also possible for SQL to be extended to insure that, in addition to optimizing I/O, CPU processing is also optimized.
Reference: [27] <author> M. Stonebraker and L. A. Rowe. </author> <booktitle> The design of post-gres. In Proceedings of the 1986 ACM SIGMOD International Conference on Management of Data, </booktitle> <year> 1986. </year>
Reference-contexts: Since such an operator is not supported, we make use of the object extensions in DB2, the user-defined function (udf) <ref> [27, 8, 15] </ref>, which is another reason why MIND is efficient. User-defined functions are used for association in [3]. An external udf is a function that is written by a user in a host programming language.
Reference: [28] <author> J. Ullman. </author> <title> Principles of Database Systems. </title> <note> Computer Science Press, second edition, </note> <year> 1982. </year>
Reference-contexts: A theoretical performance analysis is given in Section 4. In Section 5, we present our experimental results. We make concluding remarks in Section 6. 1 SQL is simply an implementation of the relational calculus proposed in [11]. A few extensions have been done since then <ref> [28, 10] </ref>. 2 The Algorithm 2.1 Overview A decision tree classifier is built in two phases: a growth phase and a pruning phase.
Reference: [29] <author> D. E. Vengroff and J. S. Vitter. </author> <title> I/O-efficient scientific computation using TPIE. </title> <booktitle> In Proceedings of the God-dard Conference on Mass Storage Systems and Technologies, NASA Conference Publication 3340, </booktitle> <volume> Volume II, </volume> <pages> pages 553-570, </pages> <address> College Park, MD, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: If so, operations like histogram formation, which have a significant impact on performance, can be done in a linear number of I/Os, usually requiring one, but never more than two passes over the DETAIL table <ref> [29] </ref>. Without the discretization, the I/O performance bound has an extra factor that is logarithmic but fortunately with a very large base M=B, which is the number of disk blocks that can fit in the internal memory. One advantage of our approach is that its implementation is easy. <p> tables cannot fit in memory, they can be formed by sorting in linear time, if we make the weak assumption that (M=B) c D=B for some small positive constant c, where D, M , and B are respectively the dimension table size, the internal memory size, and the block size <ref> [4, 29] </ref>.
References-found: 29

