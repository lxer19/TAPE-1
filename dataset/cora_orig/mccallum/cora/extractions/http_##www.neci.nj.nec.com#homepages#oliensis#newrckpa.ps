URL: http://www.neci.nj.nec.com/homepages/oliensis/newrckpa.ps
Refering-URL: http://www.neci.nj.nec.com/homepages/vision/motion.html
Root-URL: 
Email: (oliensis@research.nj.nec.com)  
Title: Provably Correct Algorithms for Multiframe Structure from Motion: the Case of Constant Translation Direction  
Author: John Oliensis 
Keyword: Multiframe structure from motion, nonlinear estimation, autonomous naviga tion, low level vision.  
Address: 4 Independence Way Princeton, N.J. 08540  
Affiliation: NEC Research Institute  
Abstract: We have recently demonstrated a new approach to multiframe structure from motion from point features which, in the appropriate domain, provably reconstructs structure and motion correctly. The domain is one well suited to outdoor robot navigation scenarios where perspective effects are large. In this paper, we describe a version of our approach adapted to an important special case of motion: translational motion approximately in a constant direction (but not necessarily of constant magnitude) with arbitrary rotations. Experimental results are presented for real and synthetic image sequences. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Dutta, R. Manmatha, </author> <title> L.R. Williams, and E.M. Riseman, "A data set for quantitative motion analysis," </title> <booktitle> CVPR, </booktitle> <pages> 159-164, </pages> <year> 1989. </year>
Reference-contexts: We emphasize that we place no contraint on the rotations and do not require the magnitudes of the translations to be constant; only the translation direction is assumed approximately constant. In our experimental section, we report results for a real image sequence|the Martin-Marietta Rocket Field sequence <ref> [1, 16] </ref>|for which actually both the translation direction and translation magnitudes vary. <p> Though the use of this approximate procedure is heuristic compared to the rigorously justifiable multiplicative iteration, its use may actually give better results. 3 Experiments: Rocket Sequence Our experiments were carried out on the Rocket sequence <ref> [1, 16] </ref>, using 22 feature point correspondences provided to us by J. Thomas. Ground truth was available for only 11 of these; depth reconstructions are reported only for these points.
Reference: [2] <author> G. Golub and C. F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> John Hopkins Press, </publisher> <address> Baltimore, Maryland,1983. </address>
Reference-contexts: Heeger and Jepson used this technique [5, 3, 7] in the context of recovering motion from optical flow, but their technique did not extend to annihilating general vectors or to sparse flows as ours does [6]. Our extension is based on Householder matrices. The Householder matrix <ref> [2] </ref> H ab is an orthogonal matrix that takes a to b by a reflection. With ^ n (0; 0 : : : 1) t , the matrix defined by the first n 1 rows of H a^n is a rank n 1 matrix annihilating ^ n. <p> The estimates rely on theorems which bound the perturbations in the leading singular vectors of a matrix M when M is perturbed. Similar theorems can be found in <ref> [2, 14] </ref>; however, our bounds, since they deal with the leading singular vectors, improve on the ones contained in these references. Given the above estimates, the rotations with respect to the base image can be recomputed.
Reference: [3] <author> D.J. Heeger and A.D. Jepson, </author> <title> "Subspace methods for recovering rigid motion I: Algorithm and implementation," </title> <booktitle> IJCV 7, </booktitle> <pages> 95-117, </pages> <year> 1992. </year>
Reference-contexts: Our approach for the constant translation direction case has some connection with previous work on optical flow by Heeger and Jepson <ref> [3, 5, 7, 4] </ref>. The new features of our work include a generalization of their technique for canceling first order rotation and the analysis of the finite rotation case [11]. <p> residual rotational image displacement has the famil iar optical flow form: f (R h ; p h y ; ! h z b i (! h y x i ): (8) The second stage of our algorithm determines the translation direction using a generalization of an earlier optical flow technique <ref> [3, 5, 7] </ref> to cancel the first order residual rotation (8). Note that though [3, 5, 7] specifically deal with infinitesimal motion, we can recover the direction of translation direction here for finite motion with no further approximation. <p> ; p h y ; ! h z b i (! h y x i ): (8) The second stage of our algorithm determines the translation direction using a generalization of an earlier optical flow technique <ref> [3, 5, 7] </ref> to cancel the first order residual rotation (8). Note that though [3, 5, 7] specifically deal with infinitesimal motion, we can recover the direction of translation direction here for finite motion with no further approximation. <p> We now design a (M 6) fi M matrix H T annihilating the six vectors f1g, fxg, fyg, fx 2 g, fxyg, fy 2 g, where, for example, fxyg is a M fi 1 vector with elements x i y i . Heeger and Jepson used this technique <ref> [5, 3, 7] </ref> in the context of recovering motion from optical flow, but their technique did not extend to annihilating general vectors or to sparse flows as ours does [6]. Our extension is based on Householder matrices.
Reference: [4] <author> R. Hummel and V. Sundareswaran, </author> <title> "Motion parameter estimation from global flow field data," </title> <type> PAMI 15, </type> <pages> 459-476, </pages> <year> 1993. </year>
Reference-contexts: Our approach for the constant translation direction case has some connection with previous work on optical flow by Heeger and Jepson <ref> [3, 5, 7, 4] </ref>. The new features of our work include a generalization of their technique for canceling first order rotation and the analysis of the finite rotation case [11].
Reference: [5] <author> A.D. </author> <title> Jepson and D.J. Heeger, "Linear subspace methods for recovering translational direction," </title> <institution> University of Toronto Technical Report RBCV-TR-92-40,1992. </institution>
Reference-contexts: Our approach for the constant translation direction case has some connection with previous work on optical flow by Heeger and Jepson <ref> [3, 5, 7, 4] </ref>. The new features of our work include a generalization of their technique for canceling first order rotation and the analysis of the finite rotation case [11]. <p> residual rotational image displacement has the famil iar optical flow form: f (R h ; p h y ; ! h z b i (! h y x i ): (8) The second stage of our algorithm determines the translation direction using a generalization of an earlier optical flow technique <ref> [3, 5, 7] </ref> to cancel the first order residual rotation (8). Note that though [3, 5, 7] specifically deal with infinitesimal motion, we can recover the direction of translation direction here for finite motion with no further approximation. <p> ; p h y ; ! h z b i (! h y x i ): (8) The second stage of our algorithm determines the translation direction using a generalization of an earlier optical flow technique <ref> [3, 5, 7] </ref> to cancel the first order residual rotation (8). Note that though [3, 5, 7] specifically deal with infinitesimal motion, we can recover the direction of translation direction here for finite motion with no further approximation. <p> We now design a (M 6) fi M matrix H T annihilating the six vectors f1g, fxg, fyg, fx 2 g, fxyg, fy 2 g, where, for example, fxyg is a M fi 1 vector with elements x i y i . Heeger and Jepson used this technique <ref> [5, 3, 7] </ref> in the context of recovering motion from optical flow, but their technique did not extend to annihilating general vectors or to sparse flows as ours does [6]. Our extension is based on Householder matrices. <p> Multiplying the matrix [d ] h i by H t T produces X [d ] h T ] i (10) is a linear equation for the translation 0 i i [H t which can be solved by least squares <ref> [5] </ref>. (11) is exact up to the neglected second order terms in the rotation error (o (! 2 )) and also up to terms of order j!j times the translational image displacement. <p> Apart from these approximations, (11) incorporates almost all of the information available for determining the translation direction. As discussed in <ref> [5] </ref>, only three nonlinear constraints on the translation direction per image frame are not taken advantage of in (11). 6 2.1 Improved Estimate of the Translation Direction Assuming constant direction of translation, accurate structure recovery depends critically on determining this direction accurately.
Reference: [6] <institution> See page 19 in [5]. </institution>
Reference-contexts: Heeger and Jepson used this technique [5, 3, 7] in the context of recovering motion from optical flow, but their technique did not extend to annihilating general vectors or to sparse flows as ours does <ref> [6] </ref>. Our extension is based on Householder matrices. The Householder matrix [2] H ab is an orthogonal matrix that takes a to b by a reflection.
Reference: [7] <author> A.D. </author> <title> Jepson and D.J. Heeger, "A fast subspace algorithm for recovering rigid motion," </title> <booktitle> Motion Workshop , Princeton, N.J., </booktitle> <pages> 124-131, </pages> <year> 1991. </year>
Reference-contexts: Our approach for the constant translation direction case has some connection with previous work on optical flow by Heeger and Jepson <ref> [3, 5, 7, 4] </ref>. The new features of our work include a generalization of their technique for canceling first order rotation and the analysis of the finite rotation case [11]. <p> residual rotational image displacement has the famil iar optical flow form: f (R h ; p h y ; ! h z b i (! h y x i ): (8) The second stage of our algorithm determines the translation direction using a generalization of an earlier optical flow technique <ref> [3, 5, 7] </ref> to cancel the first order residual rotation (8). Note that though [3, 5, 7] specifically deal with infinitesimal motion, we can recover the direction of translation direction here for finite motion with no further approximation. <p> ; p h y ; ! h z b i (! h y x i ): (8) The second stage of our algorithm determines the translation direction using a generalization of an earlier optical flow technique <ref> [3, 5, 7] </ref> to cancel the first order residual rotation (8). Note that though [3, 5, 7] specifically deal with infinitesimal motion, we can recover the direction of translation direction here for finite motion with no further approximation. <p> We now design a (M 6) fi M matrix H T annihilating the six vectors f1g, fxg, fyg, fx 2 g, fxyg, fy 2 g, where, for example, fxyg is a M fi 1 vector with elements x i y i . Heeger and Jepson used this technique <ref> [5, 3, 7] </ref> in the context of recovering motion from optical flow, but their technique did not extend to annihilating general vectors or to sparse flows as ours does [6]. Our extension is based on Householder matrices.
Reference: [8] <author> H. C. Longuet-Higgins, </author> <title> "A computer algorithm for reconstructing a scene from two projections," </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: Experimentally, our approach is essentially always valid if the translation magnitude is less than 1=2 of the 3D depths|a relatively large translation. Moreover, for translations of this large size, standard two-frame algorithms, including the notoriously unreliable "8-point" algorithm <ref> [8] </ref>, produce excellent estimates of structure and motion, assuming only that the 3D feature points have significant depth variation. We have verified this claim in extensive experiments in [11].
Reference: [9] <author> J. Oliensis, </author> <title> "Multiframe Structure from Motion in Perspective," </title> <booktitle> to appear in the proceedings of the IEEE Workshop on the Representations of Visual Scenes, </booktitle> <address> Boston, </address> <month> June, </month> <year> 1995. </year> <note> Also http://www.neci.nj.nec.com/homepages/oliensis.html. </note>
Reference-contexts: 1 Introduction We have recently demonstrated in <ref> [9, 10] </ref> a new approach to multiframe structure from motion (MFSFM) from point features which, in the appropriate domain, provably reconstructs structure and motion correctly. In particular, it has no local minimum problem. <p> In our experimental section, we report results for a real image sequence|the Martin-Marietta Rocket Field sequence [1, 16]|for which actually both the translation direction and translation magnitudes vary. We have argued previously <ref> [9, 10] </ref> that there probably is no one SFM algorithm producing 1 Our approach can be implemented in recursive or batch mode; this is a separate issue from the use of noise-sensitive partial estimates based on limited data. 1 good results in arbitrary situations, and that the best approach to estimating <p> It provably gives a good approximation to the ground truth within the appropriate domain. In addition to the translation direction restriction, our approach also requires that the translation not be too large compared to the depths of the feature points 3 . We have argued in <ref> [11, 9, 10] </ref> that this is not an important restriction. Experimentally, our approach is essentially always valid if the translation magnitude is less than 1=2 of the 3D depths|a relatively large translation. <p> As previously quoted in <ref> [9] </ref>, we have also conducted a general study [12] comparing Euclidean to projective reconstruction. <p> However the bias introduced should not be significant because the denominator factor never deviates significantly from 1 and because of the overredundancy of information in the image. We have achieved good with this multiplicative iteration for the case of general motion <ref> [9, 10] </ref>. An apparently more serious problem is that postmultiplying by H t V no longer eliminates the first order rotational terms exactly. However, the surviving terms, though they are first order in the rotation, are insignificant since they are also scaled by the size of the translational image displacements.
Reference: [10] <author> J. Oliensis, </author> <title> "A Linear Solution for Multiframe Structure from Motion," </title> <booktitle> in Proc. Arpa Image Understanding Workshop, </booktitle> <address> Monterey, California, </address> <month> November </month> <year> 1994, </year> <pages> pp. 1225-1231. </pages>
Reference-contexts: 1 Introduction We have recently demonstrated in <ref> [9, 10] </ref> a new approach to multiframe structure from motion (MFSFM) from point features which, in the appropriate domain, provably reconstructs structure and motion correctly. In particular, it has no local minimum problem. <p> In our experimental section, we report results for a real image sequence|the Martin-Marietta Rocket Field sequence [1, 16]|for which actually both the translation direction and translation magnitudes vary. We have argued previously <ref> [9, 10] </ref> that there probably is no one SFM algorithm producing 1 Our approach can be implemented in recursive or batch mode; this is a separate issue from the use of noise-sensitive partial estimates based on limited data. 1 good results in arbitrary situations, and that the best approach to estimating <p> It provably gives a good approximation to the ground truth within the appropriate domain. In addition to the translation direction restriction, our approach also requires that the translation not be too large compared to the depths of the feature points 3 . We have argued in <ref> [11, 9, 10] </ref> that this is not an important restriction. Experimentally, our approach is essentially always valid if the translation magnitude is less than 1=2 of the 3D depths|a relatively large translation. <p> However the bias introduced should not be significant because the denominator factor never deviates significantly from 1 and because of the overredundancy of information in the image. We have achieved good with this multiplicative iteration for the case of general motion <ref> [9, 10] </ref>. An apparently more serious problem is that postmultiplying by H t V no longer eliminates the first order rotational terms exactly. However, the surviving terms, though they are first order in the rotation, are insignificant since they are also scaled by the size of the translational image displacements.
Reference: [11] <author> J. Oliensis, </author> <title> "Rigorous Bounds for Two-Frame Structure from Motion," </title> <note> submitted to ECCV 1996. Also http://www.neci.nj.nec.com/homepages/oliensis.html. </note>
Reference-contexts: It provably gives a good approximation to the ground truth within the appropriate domain. In addition to the translation direction restriction, our approach also requires that the translation not be too large compared to the depths of the feature points 3 . We have argued in <ref> [11, 9, 10] </ref> that this is not an important restriction. Experimentally, our approach is essentially always valid if the translation magnitude is less than 1=2 of the 3D depths|a relatively large translation. <p> Moreover, for translations of this large size, standard two-frame algorithms, including the notoriously unreliable "8-point" algorithm [8], produce excellent estimates of structure and motion, assuming only that the 3D feature points have significant depth variation. We have verified this claim in extensive experiments in <ref> [11] </ref>. If the 3D points do not have significant depth variation, then Tomasi and Kanade's approach [18, 17] works essentially regardless of the translation size. Thus algorithms already exist which can deal with motion sequences where the translations are large. <p> The new features of our work include a generalization of their technique for canceling first order rotation and the analysis of the finite rotation case <ref> [11] </ref>. <p> Though this may seem a strong assumption, we have derived a rigorous bound on the resulting rotation errors and proven that they are small when the translations are not too large <ref> [11] </ref>. Contrary to traditional belief, the errors in recovering rotation are typically small. We have proven this for the case of small/moderate translation; we have demonstrated it experimentally not only for small translations but also for large translations [11]. <p> proven that they are small when the translations are not too large <ref> [11] </ref>. Contrary to traditional belief, the errors in recovering rotation are typically small. We have proven this for the case of small/moderate translation; we have demonstrated it experimentally not only for small translations but also for large translations [11]. In the large translation case, we of course do not assume the translations to be zero; any standard algorithm, including the "8-point" algorithm, will be reliable in this case 4 . <p> The basic strategy of our approach is to proceed in a sequence of stages, beginning with quantities that are easy to estimate reliably, and using these to bootstrap toward more difficult estimations. At every stage the estimation is designed to have minimal noise sensitivity. The results derived in <ref> [11] </ref> show that rotations are the unknowns that can be estimated most robustly initially. To state the bound on the rotation error for moderate translation explicitly, we assume that the h-th frame has been rotated to the first frame using the exact relative rotation. <p> Define j E j to be the magnitude of the rotation error. Then j E j jM 1 V R j: (7) In <ref> [11] </ref> (7) is shown explicitly to be small for small translation and noise. Assuming that the rotations have been approximately compensated, the residual rotations can henceforth be assumed small. <p> However, if we do compensate for the rotations the residual rotations are small, averaging 2.2 degrees with a maximum of 4.3 degrees. The error in recovering the rotations increases almost linearly with the size of the translation <ref> [11] </ref>. The reconstruction results for the Rocket sequence obtained with our various algorithms are displayed in Tables 1, 2, and 3.
Reference: [12] <author> J. Oliensis and Venu Govindu, </author> <note> in preparation. </note>
Reference-contexts: As previously quoted in [9], we have also conducted a general study <ref> [12] </ref> comparing Euclidean to projective reconstruction. Our experimental results indicate that the projective approach is unstable, often giving worse results for the projective structure itself than does a Euclidean estimate (i.e., an estimate based on an assumed calibration) derived for the incorrect calibration parameters.
Reference: [13] <author> J. Oliensis and J. I. Thomas, </author> <title> "Incorporating Motion Error in Multi-frame Structure from Motion," </title> <booktitle> in IEEE Workshop on Visual Motion, </booktitle> <address> Princeton, New Jersey, </address> <month> October </month> <year> 1991, </year> <pages> pp. 8-13. </pages>
Reference-contexts: Our results are also better than in previous work <ref> [16, 13] </ref>. However, the superiority of the brute force algorithm is shown in the accuracy with which it recovers the depths of the difficult 7-th and 10-th points|for these two points, precise determination of the FOE is crucial.
Reference: [14] <author> G.W. Stewart and J. G. Sun, </author> <title> "Matrix Perturbation Theory," </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: The estimates rely on theorems which bound the perturbations in the leading singular vectors of a matrix M when M is perturbed. Similar theorems can be found in <ref> [2, 14] </ref>; however, our bounds, since they deal with the leading singular vectors, improve on the ones contained in these references. Given the above estimates, the rotations with respect to the base image can be recomputed.
Reference: [15] <author> V. Sundareswaran, </author> <title> "Egomotion from global flow field data," </title> <booktitle> Motion Workshop, Prince-ton, </booktitle> <pages> 140-145, </pages> <year> 1991. </year>
Reference: [16] <author> J. Inigo Thomas, A. Hanson, and J. Oliensis, </author> <title> "Refining 3D reconstructions: A theoretical and experimental study of the effect of cross-correlations", </title> <journal> CVGIP:IU, </journal> <volume> Vol. 60, </volume> <year> 1994, </year> <pages> pp. 359-370. </pages>
Reference-contexts: We emphasize that we place no contraint on the rotations and do not require the magnitudes of the translations to be constant; only the translation direction is assumed approximately constant. In our experimental section, we report results for a real image sequence|the Martin-Marietta Rocket Field sequence <ref> [1, 16] </ref>|for which actually both the translation direction and translation magnitudes vary. <p> Though the use of this approximate procedure is heuristic compared to the rigorously justifiable multiplicative iteration, its use may actually give better results. 3 Experiments: Rocket Sequence Our experiments were carried out on the Rocket sequence <ref> [1, 16] </ref>, using 22 feature point correspondences provided to us by J. Thomas. Ground truth was available for only 11 of these; depth reconstructions are reported only for these points. <p> Our results are also better than in previous work <ref> [16, 13] </ref>. However, the superiority of the brute force algorithm is shown in the accuracy with which it recovers the depths of the difficult 7-th and 10-th points|for these two points, precise determination of the FOE is crucial.
Reference: [17] <author> C. Tomasi and T. Kanade, </author> <title> "Shape and motion from image streams under orthography: A factorization method," </title> <booktitle> IJCV 9, </booktitle> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: In particular, it has no local minimum problem. The algorithm is valid for general motion in situations such as are typically encountered in outdoor robot navigation, where perspective effects are large. Like the algorithm of Tomasi and Kanade <ref> [18, 17] </ref>, it is a true multiframe technique. <p> Our algorithm is also fast, comparable to <ref> [18, 17] </ref>: for 32 features and 16 images, our current nonoptimal MATLAB implementation takes about a second on an SGI. <p> We have verified this claim in extensive experiments in [11]. If the 3D points do not have significant depth variation, then Tomasi and Kanade's approach <ref> [18, 17] </ref> works essentially regardless of the translation size. Thus algorithms already exist which can deal with motion sequences where the translations are large. Our approach deals with the complementary domain which is actually more difficult: large perspective effects and small baselines. <p> Similarly, the column vector best characterizing the columns of this matrix will be approximately proportional to the vector C 1=2 H fg which contains the translation magnitudes only. When there is no occlusion, this can be done using the SVD as in <ref> [18, 17] </ref>. It is well known that the SVD gives the best rank 1 approximation to D CH under the Frobenius norm. When there is occlusion, other techniques can be used, for instance the best row or column vectors can be determined initially simply by clustering and averaging. <p> The corresponding translation magnitudes are fg = v 1 C H where v 1 is the leading singular value. The two stage method, like the one in Tomasi's approach <ref> [17] </ref>, does not correspond to a MLE of the structure and translations directly. As noted above, however, the first stage does give a MLE for the leading singular subspaces of D CH .
Reference: [18] <author> C. Tomasi and T. Kanade, </author> <title> "Factoring Image Sequences into Shape and Motion," Motion Workshop, </title> <publisher> Princeton, </publisher> <pages> 21-28, </pages> <year> 1991. </year> <month> 29 </month>
Reference-contexts: In particular, it has no local minimum problem. The algorithm is valid for general motion in situations such as are typically encountered in outdoor robot navigation, where perspective effects are large. Like the algorithm of Tomasi and Kanade <ref> [18, 17] </ref>, it is a true multiframe technique. <p> Our algorithm is also fast, comparable to <ref> [18, 17] </ref>: for 32 features and 16 images, our current nonoptimal MATLAB implementation takes about a second on an SGI. <p> We have verified this claim in extensive experiments in [11]. If the 3D points do not have significant depth variation, then Tomasi and Kanade's approach <ref> [18, 17] </ref> works essentially regardless of the translation size. Thus algorithms already exist which can deal with motion sequences where the translations are large. Our approach deals with the complementary domain which is actually more difficult: large perspective effects and small baselines. <p> Similarly, the column vector best characterizing the columns of this matrix will be approximately proportional to the vector C 1=2 H fg which contains the translation magnitudes only. When there is no occlusion, this can be done using the SVD as in <ref> [18, 17] </ref>. It is well known that the SVD gives the best rank 1 approximation to D CH under the Frobenius norm. When there is occlusion, other techniques can be used, for instance the best row or column vectors can be determined initially simply by clustering and averaging.
References-found: 18

