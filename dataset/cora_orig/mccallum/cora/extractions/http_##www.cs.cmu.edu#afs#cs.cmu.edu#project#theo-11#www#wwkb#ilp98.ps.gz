URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-11/www/wwkb/ilp98.ps.gz
Refering-URL: http://www.cs.cmu.edu/~craven/text-learning.html
Root-URL: 
Email: e-mail: hfirstnamei.hlastnamei@cs.cmu.edu  
Title: Combining Statistical and Relational Methods for Learning in Hypertext Domains  
Author: Sean Slattery and Mark Craven 
Address: Pittsburgh, PA 15213-3891, USA  
Affiliation: School of Computer Science, Carnegie Mellon University  
Note: Appears in Proceedings of the 8th International Conference on Inductive Logic Programming, Springer-Verlag, 1998.  
Abstract: We present a new approach to learning hypertext classifiers that combines a statistical text-learning method with a relational rule learner. This approach is well suited to learning in hypertext domains because its statistical component allows it to characterize text in terms of word frequencies, whereas its relational component is able to describe how neighboring documents are related to each other by hyperlinks that connect them. We evaluate our approach by applying it to tasks that involve learning definitions for (i) classes of pages, (ii) particular relations that exist between pairs of pages, and (iii) locating a particular class of information in the internal structure of pages. Our experiments demonstrate that this new approach is able to learn more accurate classifiers than either of its constituent methods alone.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> W. W. Cohen. </author> <title> Fast effective rule induction. </title> <booktitle> In Proc. of the 12th International Conference on Machine Learning. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1995. </year>
Reference-contexts: Even after employing such feature-selection methods, it is common to use feature sets consisting of hundreds or thousands of words. 2.2 Relational Text Learning Both propositional and relational symbolic rule learners have also been used for text learning tasks <ref> [1, 2, 13] </ref>. We argue that relational learners are especially appealing for learning in hypertext domains because they enable learned classifiers to represent the relationships among documents as well as information about the occurrence of words in documents.
Reference: 2. <author> W. W. Cohen. </author> <title> Learning to classify English text with ILP methods. </title> <editor> In L. De Raedt, editor, </editor> <booktitle> Advances in Inductive Logic Programming. </booktitle> <publisher> IOS Press, </publisher> <year> 1995. </year>
Reference-contexts: Even after employing such feature-selection methods, it is common to use feature sets consisting of hundreds or thousands of words. 2.2 Relational Text Learning Both propositional and relational symbolic rule learners have also been used for text learning tasks <ref> [1, 2, 13] </ref>. We argue that relational learners are especially appealing for learning in hypertext domains because they enable learned classifiers to represent the relationships among documents as well as information about the occurrence of words in documents.
Reference: 3. <author> M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam, and S. Slattery. </author> <title> Learning to extract symbolic knowledge from the World Wide Web. </title> <booktitle> In Proc. of the 15th National Conference on Artificial Intelligence, </booktitle> <address> Madison, WI, 1998. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: three types of tasks learning definitions of page classes, learning definitions of relations between pages, and learning to locate a particular type of information within pages that we have investigated as part of an effort aimed at developing methods for automatically constructing knowledge bases by extracting information from the Web <ref> [3] </ref>. Finally, Section 5 provides conclusions and discusses future work. 2 Two Approaches to Hypertext Learning In this section we describe two approaches to learning in text domains. <p> Specifically, we compare our Foil-Pilfs method to ordinary Foil on several hypertext learning tasks. 4.1 The University Data Set Our primary data set for these experiments is one assembled for a research project aimed at extracting knowledge bases from the Web <ref> [3] </ref>. This project encompasses many learning problems and we study two of those here. The first is to recognize instances of knowledge base classes (e.g. students, faculty, courses etc.) on the Web. In some cases, this can be framed as a page-classification task.
Reference: 4. <author> M. Craven, S. Slattery, and K. Nigam. </author> <title> First-order learning for Web mining. </title> <booktitle> In Proc. of the 10th European Conference on Machine Learning, </booktitle> <pages> pages 250-255, </pages> <address> Chemnitz, Germany, 1998. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: An interesting aspect of the Web is that it can be thought of as a graph in which pages are the nodes of the graph and hyperlinks are the edges. The graph structure of the Web makes it an interesting domain for relational learning. In previous work <ref> [4] </ref>, we demonstrated that for several Web-based learning tasks, a relational learning algorithm can learn more accurate classifiers than competing propositional approaches. In this paper, we present a new approach to learning hypertext classifiers that combines a statistical text-learning method with a relational rule learner. <p> We argue that relational learners are especially appealing for learning in hypertext domains because they enable learned classifiers to represent the relationships among documents as well as information about the occurrence of words in documents. In previous work <ref> [4] </ref>, we demonstrated that this ability enables relational methods to learn more accurate classifiers than propositional methods in some cases. In Section 4, we present experiments in which we apply Foil to several hypertext learning tasks.
Reference: 5. <author> D. DiPasquo. </author> <title> Using HTML formatting to aid in natural language processing on the World Wide Web, 1998. </title> <type> Senior thesis, </type> <institution> Computer Science Department, Carnegie Mellon University. </institution>
Reference-contexts: and F 1 results for the node classification task. method R P F 1 R wins P wins Foil 55.5 64.0 59.5 1 1 Foil-Pilfs 64.4 66.6 65.5 4 4 Our approach makes use of an algorithm that parses Web pages into tree structures representing the layout of the pages <ref> [5] </ref>. For example, one node of the tree might represent an HTML table where its ancestors are the HTML headings that come above it in the page. In general any node in the tree can have some text associated with it.
Reference: 6. <author> P. Domingos and M. Pazzani. </author> <title> On the optimality of the simple Bayesian classifier under zero-one loss. </title> <journal> Machine Learning, </journal> <volume> 29 </volume> <pages> 103-130, </pages> <year> 1997. </year>
Reference-contexts: Naive Bayes' probability estimates are usually poor when its independence assumption is violated, although its predictive accuracy is often quite good in such situations <ref> [6] </ref>. 4 Experimental Evaluation At the beginning of Section 3, we stated that our Foil-Pilfs algorithm has two desirable properties: Because it characterizes pages and hyperlinks using a statistical method such as Naive Bayes, its learned rules will not be dependent on the presence or absence of specific key words.
Reference: 7. <author> S. Dzeroski and I. Bratko. </author> <title> Handling noise in inductive logic programming. </title> <booktitle> In Proc. of the 2nd International Workshop on Inductive Logic Programming, </booktitle> <pages> pages 109-125, </pages> <address> Tokyo, Japan, </address> <year> 1992. </year>
Reference-contexts: Once such a path is found, an initial clause is formed from the relations that constitute the path, and the clause is further refined by a hill-climbing search. Also, like Dzeroski and Bratko's m-Foil <ref> [7] </ref>, both algorithms considered here use m-estimates of a clause's error to guide its construction. We have found that this evaluation function results in fewer, more general clauses for these tasks than Foil's information gain measure.
Reference: 8. <author> A. Ehrenfeucht, D. Haussler, M. Kearns, and L. Valiant. </author> <title> A general lower bound on the number of examples needed for learning. </title> <journal> Information and Computation, </journal> <volume> 82(3) </volume> <pages> 247-251, </pages> <year> 1989. </year>
Reference-contexts: task small enough such that if we find a predicate that fits its training set well, we can be reasonably confident that it will generalize to new instances of the "target class." A lower bound on the number of examples required to PAC-learn some target function f 2 F is <ref> [8] </ref>: VC-dimension (F ) * (4) where * is the usual PAC error parameter.
Reference: 9. <author> B. Kijsirikul, M. Numao, and M. Shimura. </author> <title> Discrimination-based constructive induction of logic programs. </title> <booktitle> In Proc. of the 10th National Conference on Artificial Intelligence, </booktitle> <pages> pages 44-49, </pages> <address> San Jose, CA, 1992. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Here we present an algorithm, which we refer to as Foil-Pilfs (for Foil with Predicate Invention for Large Feature Spaces), that represents one particular instantiation of our approach. This algorithm is basically Foil, augmented with a predicate-invention method in the spirit of Champ <ref> [9] </ref>. Figure 1 shows the inner loop of Foil-Pilfs (which learns a single clause) and its relation to its predicate invention method, which is shown in Figure 2 The predicates that Foil-Pilfs invents are statistical classifiers applied to some textual description of pages, hyperlinks, or components thereof.
Reference: 10. <author> D. D. Lewis and M. Ringuette. </author> <title> A comparison of two learning algorithms for text categorization. </title> <booktitle> In Proc. of the 3rd Annual Symposium on Document Analysis and Information Retrieval, </booktitle> <pages> pages 81-93, </pages> <year> 1994. </year>
Reference-contexts: Clearly, this assumption does not hold in real text documents. However, in practice Naive Bayes classifiers often perform quite well <ref> [10] </ref>. Since document corpora typically have vocabularies of thousands of words, it is common in text learning to use some type of feature selection method.
Reference: 11. <author> D. D. Lewis, R. E. Schapire, J. P. Callan, and R. Papka. </author> <title> Training algorithms for linear classifiers. </title> <booktitle> In Proc. of the 19th Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 298-306. </pages> <publisher> Hartung-Gorre Verlag, </publisher> <year> 1996. </year>
Reference-contexts: Recall and precision are defined as follows: R = # correct positive examples # of positive examples , P = # correct positive examples # of positive predictions : Also shown is the F 1 score <ref> [11, 16] </ref> for each algorithm on each task. This is a score commonly used in the information-retrieval community which weights precision and recall equally and has nice measurement properties.
Reference: 12. <author> T. Mitchell. </author> <title> Machine Learning. </title> <publisher> McGraw Hill, </publisher> <year> 1997. </year>
Reference-contexts: One common approach to text classification is to use a Naive Bayes classifier with a bag-of-words representation <ref> [12] </ref>.
Reference: 13. <author> I. Moulinier, G. Raskinis, and J.-G. Ganascia. </author> <title> Text categorization: a symbolic approach. </title> <booktitle> In Proc. of the 6th Annual Symposium on Document Analysis and Information Retrieval, </booktitle> <year> 1996. </year>
Reference-contexts: Even after employing such feature-selection methods, it is common to use feature sets consisting of hundreds or thousands of words. 2.2 Relational Text Learning Both propositional and relational symbolic rule learners have also been used for text learning tasks <ref> [1, 2, 13] </ref>. We argue that relational learners are especially appealing for learning in hypertext domains because they enable learned classifiers to represent the relationships among documents as well as information about the occurrence of words in documents.
Reference: 14. <author> J. R. Quinlan and R. M. Cameron-Jones. </author> <title> FOIL: A midterm report. </title> <booktitle> In Proc. of the 5th European Conference on Machine Learning, </booktitle> <pages> pages 3-20, </pages> <address> Vienna, Austria, 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In this paper, we present a new approach to learning hypertext classifiers that combines a statistical text-learning method with a relational rule learner. We present experiments that evaluate one particular instantiation of this general approach: a Foil-based <ref> [14] </ref> learner augmented with the ability to invent predicates using a Naive Bayes text classifier. Our experiments indicate that this approach is able to learn classifiers that are often more accurate than either purely statistical or purely relational alternatives.
Reference: 15. <author> B. Richards and R. Mooney. </author> <title> Learning relations by pathfinding. </title> <booktitle> In Proc. of the 10th National Conference on Artificial Intelligence, </booktitle> <pages> pages 50-55, </pages> <address> San Jose, CA, 1992. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: Thus, for the experiments in this section, we augment both algorithms with a deterministic variant of Richards and Mooney's relational pathfinding method <ref> [15] </ref>. The basic idea underlying this method is that a relational problem domain can be thought of as a graph in which the nodes are the domain's constants and the edges correspond to relations which hold among constants.
Reference: 16. <author> C. J. van Rijsbergen. </author> <note> Information Retrieval, chapter 7. Butterworths, </note> <year> 1979. </year>
Reference-contexts: Recall and precision are defined as follows: R = # correct positive examples # of positive examples , P = # correct positive examples # of positive predictions : Also shown is the F 1 score <ref> [11, 16] </ref> for each algorithm on each task. This is a score commonly used in the information-retrieval community which weights precision and recall equally and has nice measurement properties.
Reference: 17. <author> Y. Yang and J. Pedersen. </author> <title> A comparative study on feature set selection in text categorization. </title> <booktitle> In Proc. of the 14th International Conference on Machine Learning, </booktitle> <pages> pages 412-420, </pages> <address> Nashville, TN, 1997. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Frequently used methods include (i) dropping putatively un-informative words that occur on a stop-list, (ii) dropping words that occur fewer than a specified number of times in the training set, (iii) ranking words by a measure such as their mutual information with the class variable, and then dropping low-ranked words <ref> [17] </ref>, and (iv) stemming. Stemming refers to the process of heuristically reducing words to their root form. For example the words compute, computers and computing would be stemmed to the root comput.
References-found: 17

