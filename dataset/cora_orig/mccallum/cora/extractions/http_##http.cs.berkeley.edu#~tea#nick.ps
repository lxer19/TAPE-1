URL: http://http.cs.berkeley.edu/~tea/nick.ps
Refering-URL: http://http.cs.berkeley.edu/~tea/atm.html
Root-URL: 
Title: A Quantitative Comparison of Scheduling Algorithms for Input-Queued Switches  
Author: Nick McKeown Thomas E. Anderson 
Abstract: This paper quantitatively evaluates several alternative approaches to the scheduling of cells in a high-bandwidth input-queued ATM switch. In particular, we compare the performance of three algorithms described previously: FIFO queueing, parallel iterative matching (PIM), maximum matching and two new algorithms: iterative round-robin matching with slip (SLIP) and least-recently used (LRU). For the synthetic workloads we consider, including uniform and bursty traffic, SLIP performs almost identically to the other algorithms. Cases for which PIM and SLIP perform poorly are presented, indicating that care should be taken when using these algorithms. But, we show that the implementation complexity of SLIP is an order of magnitude less than for PIM, making it feasible to implement a 32x32 switch scheduler for SLIP on a single chip.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ali, M., Nguyen, H. </author> <title> "A neural network implementation of an input access scheme in a high-speed packet switch," </title> <booktitle> Proc. of GLOBECOM 1989, pp.1192-1196. </booktitle> <pages> 14 </pages>
Reference-contexts: Our work is motivated by a different approach. HOL blocking can also be eliminated by using a separate queue for each output <ref> [1, 2, 14, 23] </ref>, where any cell queued at an input is eligible for forwarding across the switch. <p> algorithm must now consider the cells at the head of all N 2 input FIFOs and determine a pattern of conflict-free connections that will provide a high throughput. (The algorithm is an example of bipartite graph matching [24] and is also an example of the "rooks on a chessboard problem" <ref> [1] </ref>). 2.2 Maximum Matching Ideally, we would like an algorithm that finds the maximum number of matches between inputs and outputs.
Reference: [2] <author> Anderson, T., Owicki, S., Saxe, J., and Thacker, C. </author> <title> "High speed switch scheduling for local area networks," </title> <journal> ACM Trans. on Computer Systems. </journal> <month> Nov </month> <year> 1993, </year> <pages> pp. 319-352. </pages>
Reference-contexts: One reason for the popularity of arbitrary topology networks is that they offer a number of potential advantages relative to other approaches <ref> [2] </ref>: (i) aggregate throughput that can be much larger than that of a single link, (ii) the ability to add throughput incrementally as the workload changes by simply adding extra links and switches, (iii) improved fault tolerance by allowing redundant paths between hosts, (iv) and reduced latency because control over the <p> A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 6, 8, 12, 15, 21, 22] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance. <p> Our work is motivated by a different approach. HOL blocking can also be eliminated by using a separate queue for each output <ref> [1, 2, 14, 23] </ref>, where any cell queued at an input is eligible for forwarding across the switch. <p> The central problem with random-access input queues is the need for fast scheduling quickly finding a conflict-free set of cells to be forwarded across the switch, such that each input is connected to at most one output, and vice versa. As observed in <ref> [2] </ref>, this is equivalent to matching inputs to outputs [24]. This paper examines a number of scheduling algorithms for scheduling cells across an input-queued switch, including several proposed in the literature and two novel algorithms we have devised. <p> This is illustrated in figure 1. If cells for one output are blocked because the output is busy, the scheduling algorithm may select a cell for some other output. This method was implemented in <ref> [2] </ref>, where they showed that the scheme is not only straightforward to build, but yields large performance gains. <p> Furthermore, by introducing randomness or time-varying priorities, we shall see that starvation can be avoided. 2.3 Parallel Iterative Matching (PIM) The first iterative algorithm that we shall describe is called Parallel Iterative Matching <ref> [2] </ref>. It uses randomness to (i) reduce the number of iterations needed, and (ii) avoid starvation. PIM attempts to quickly converge on a conflict-free match in multiple iterations where each iteration consists of three steps. <p> By considering only unmatched inputs and outputs, each iteration only considers connections not made by earlier iterations. Note that in step (2) above the independent output schedulers randomly select a request among contending requests. This has three effects: first, in <ref> [2] </ref>, the authors show that each iteration will match or eliminate at least 3=4 of the remaining possible connections and thus the algorithm will converge to a maximal match in O (log N ) iterations. Second, it ensures that all requests will eventually be granted. <p> Consider an example in which two inputs are both requesting the same two outputs. Initially, both outputs may grant to the same input; in that case only one connection will be made in the first iteration. 5 Input Choice Output Choice Random Rotating LRU Random PIM <ref> [2] </ref> Rotating SLIP LRU LRU Table 1: Alternative Selection methods for Input and Output Schedulers. <p> For this reason, we compare the algorithms for a single iteration. In other applications, there may be time for more than one iteration, particularly if the scheduler can be integrated on a single chip. In <ref> [2] </ref>, the authors were able to achieve four iterations of the PIM algorithm within a single 53-byte ATM cell time (420ns) at link speeds of 1Gbits/sec. <p> When the scheduler completes its matching decision, it informs each input which output, if any, it can send a cell to. A PIM scheduler is difficult to implement|random selection is an expensive operation, particularly for a variable number of input requests. In the implementation described in <ref> [2] </ref>, the scheduler filled approximately 1.5 Xilinx 3190 [27] devices for each port [25]. For a 16x16 switch, this is approximately 64,000 complex gates. If we assume that each gate is approximately eight 2-input gate equivalents this totals 512,000 simple gates. <p> We chose four iterations as this was the number of iterations performed in a single slot in the implementation of PIM <ref> [2] </ref>. There is a large improvement for PIM, SLIP and LRU for multiple iterations and their performance is now almost indistinguishable. All three algorithms are now significantly better than FIFO due to the elimination of HOL blocking and all approach the performance to maximum matching.
Reference: [3] <author> Anick, D., Mitra, D., Sondhi, </author> <title> M.M., "Stochastic theory of a data-handling system with multiple sources," </title> <journal> Bell System Technical Journal 61, </journal> <year> 1982, </year> <month> pp.1871-1894. </month>
Reference-contexts: Many ways of modeling bursts in network traffic have been described <ref> [9, 13, 3, 17] </ref>. Recently, Leland et al. have demonstrated that measured network traffic is bursty at every level and that, contrary to popular belief, burstiness in Ethernet networks typically intensifies as the number of active traffic sources increases [17].
Reference: [4] <author> ANSI. </author> <title> "Fiber distributed data interface (FDDI). Token ring media access control(MAC)," ANSI Standard X3.139, </title> <publisher> American National Standards Institute, Inc., </publisher> <address> New York. </address>
Reference-contexts: In these networks, hosts are connected together by an arbitrary graph of communication links and switches, instead of via a bus, as in Ethernet [20], or a ring, as in FDDI <ref> [4] </ref>.
Reference: [5] <author> The ATM Forum. </author> <title> "The ATM Forum user-network interface specification, version 3.0, </title> " <publisher> Prentice Hall Intl., </publisher> <address> New Jersey, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction The past few years has seen increasing interest in arbitrary topology cell-based local area networks, such as ATM <ref> [5] </ref>. In these networks, hosts are connected together by an arbitrary graph of communication links and switches, instead of via a bus, as in Ethernet [20], or a ring, as in FDDI [4].
Reference: [6] <author> Eng, K., Hluchyj, M., and Yeh, Y. </author> <title> "Multicast and broadcast services in a knockout packet switch," </title> <booktitle> INFOCOM '88, </booktitle> <address> 35(12) pp.29-34. </address>
Reference-contexts: A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 6, 8, 12, 15, 21, 22] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance.
Reference: [7] <author> Even, S., Tarjan, R.E. </author> <title> "Network flow and testing graph connectivity" SIAM J. </title> <institution> Comput., </institution> <month> 4 </month> <year> (1975), </year> <month> pp.507-518. </month>
Reference-contexts: But as we are only considering the scheduling of input-output connections in this paper, we shall assume that each input maintains only N output FIFOs. 3 There are several algorithms for achieving a maximum match <ref> [7, 10, 16, 24] </ref>, but these are not suitable for this application for two reasons. First, a maximum match can take a long time to converge and, second, they can lead to starvation of an input-output connection under certain traffic patterns.
Reference: [8] <author> Giacopelli, J., Hickey, J., Marcus, W., Sincoskie, D., Littlewood, M. "Sunshine: </author> <title> A high-performance self-routing broadband packet switch architecture," </title> <journal> IEEE J. Selected Areas Commun., </journal> <volume> 9, 8, </volume> <month> Oct </month> <year> 1991, </year> <month> pp.1289-1298. </month>
Reference-contexts: A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 6, 8, 12, 15, 21, 22] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance.
Reference: [9] <author> Heffes, H., Lucantoni, D. M., </author> <title> "A Markov modulated characterization of packetized voice and data traffic and related statistical multiplexer performance," </title> <journal> IEEE J. Selected Areas in Commun., </journal> <volume> 4, </volume> <year> 1986, </year> <month> pp.856-868. </month>
Reference-contexts: Many ways of modeling bursts in network traffic have been described <ref> [9, 13, 3, 17] </ref>. Recently, Leland et al. have demonstrated that measured network traffic is bursty at every level and that, contrary to popular belief, burstiness in Ethernet networks typically intensifies as the number of active traffic sources increases [17].
Reference: [10] <author> Hopcroft, J.E., Karp, </author> <title> R.M. "An O(n 5=2 ) algorithm for maximum matching in bipartite graphs," </title> <institution> Society for Industrial and Applied Mathematics J. Comput., </institution> <month> 2 </month> <year> (1973), </year> <month> pp.225-231. </month>
Reference-contexts: But as we are only considering the scheduling of input-output connections in this paper, we shall assume that each input maintains only N output FIFOs. 3 There are several algorithms for achieving a maximum match <ref> [7, 10, 16, 24] </ref>, but these are not suitable for this application for two reasons. First, a maximum match can take a long time to converge and, second, they can lead to starvation of an input-output connection under certain traffic patterns.
Reference: [11] <author> Huang, A., Knauer, S. "Starlite: </author> <title> A wideband digital switch," </title> <booktitle> Proc. GLOBECOM '84 (1984), </booktitle> <address> pp.121-125. </address>
Reference-contexts: With less benign traffic patterns, the situation can be much worse [18]. Several methods have been proposed for reducing HOL blocking <ref> [11, 14, 15, 21, 23] </ref>, but a simple way described in [14, 15], to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output 1 . This is illustrated in figure 1.
Reference: [12] <author> Hui, J., Arthurs, E. </author> <title> "A broadband packet switch for integrated transport," </title> <journal> IEEE J. Selected Areas Commun., </journal> <volume> 5, 8, </volume> <month> Oct </month> <year> 1987, </year> <pages> pp 1264-1273. </pages>
Reference-contexts: A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 6, 8, 12, 15, 21, 22] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance.
Reference: [13] <author> Jain, R., Routhier, S. A., </author> <title> "Packet Trains: measurements and a new model for computer network traffic," </title> <journal> IEEE J. Selected Areas in Commun., </journal> <volume> 4, </volume> <year> 1986, </year> <month> pp.986-995. </month>
Reference-contexts: Many ways of modeling bursts in network traffic have been described <ref> [9, 13, 3, 17] </ref>. Recently, Leland et al. have demonstrated that measured network traffic is bursty at every level and that, contrary to popular belief, burstiness in Ethernet networks typically intensifies as the number of active traffic sources increases [17]. <p> We illustrate the effect of burstiness on PIM, SLIP and LRU using a simple packet train model similar to the introduced in <ref> [13] </ref>. The source alternately produces a burst (train) of full cells (all with the same destination) followed by one or more empty cells. The bursts contain a geometrically distributed number of cells.
Reference: [14] <author> Karol, M., Hluchyj, M., and Morgan, S. </author> <title> "Input versus output queueing on a space division switch," </title> <journal> IEEE Trans. Comm, </journal> <note> 35(12) (1987) pp.1347-1356. </note>
Reference-contexts: The authors are both with the Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, Berkeley, CA 94720. By email nickm@eecs.berkeley.edu 1 As a result, FIFO input queues suffer from head of line (HOL) blocking <ref> [14] </ref> if the cell at the front of the queue is blocked, other cells in the queue cannot be forwarded to other unused inputs. <p> Our work is motivated by a different approach. HOL blocking can also be eliminated by using a separate queue for each output <ref> [1, 2, 14, 23] </ref>, where any cell queued at an input is eligible for forwarding across the switch. <p> This choice between random and varying priorities is found in all of the approaches we consider. Before considering other scheduling approaches, we need to examine a serious performance problem caused by maintaining FIFO queues at the inputs: head of line (HOL) blocking <ref> [14] </ref>. <p> HOL blocking has been shown to limit the aggregate throughput of the switch to just 58% of its maximum for independent Bernoulli arrivals and destinations uniformly distributed over outputs <ref> [14] </ref>. With less benign traffic patterns, the situation can be much worse [18]. <p> With less benign traffic patterns, the situation can be much worse [18]. Several methods have been proposed for reducing HOL blocking <ref> [11, 14, 15, 21, 23] </ref>, but a simple way described in [14, 15], to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output 1 . This is illustrated in figure 1. <p> With less benign traffic patterns, the situation can be much worse [18]. Several methods have been proposed for reducing HOL blocking [11, 14, 15, 21, 23], but a simple way described in <ref> [14, 15] </ref>, to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output 1 . This is illustrated in figure 1. If cells for one output are blocked because the output is busy, the scheduling algorithm may select a cell for some other output.
Reference: [15] <author> Karol, M., Eng, K., Obara, H. </author> <title> "Improving the performance of input-queued ATM packet switches," </title> <address> INFO-COM '92, pp.110-115. </address>
Reference-contexts: A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 6, 8, 12, 15, 21, 22] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance. <p> With less benign traffic patterns, the situation can be much worse [18]. Several methods have been proposed for reducing HOL blocking <ref> [11, 14, 15, 21, 23] </ref>, but a simple way described in [14, 15], to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output 1 . This is illustrated in figure 1. <p> With less benign traffic patterns, the situation can be much worse [18]. Several methods have been proposed for reducing HOL blocking [11, 14, 15, 21, 23], but a simple way described in <ref> [14, 15] </ref>, to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output 1 . This is illustrated in figure 1. If cells for one output are blocked because the output is busy, the scheduling algorithm may select a cell for some other output.
Reference: [16] <author> Karp, R., Vazirani, U., and Vazirani, V. </author> <title> "An optimal algorithm for on-line bipartite matching," </title> <booktitle> Proc. 22nd ACM Symp. on Theory of Computing, </booktitle> <address> pp.352-358, Maryland, </address> <year> 1990. </year>
Reference-contexts: But as we are only considering the scheduling of input-output connections in this paper, we shall assume that each input maintains only N output FIFOs. 3 There are several algorithms for achieving a maximum match <ref> [7, 10, 16, 24] </ref>, but these are not suitable for this application for two reasons. First, a maximum match can take a long time to converge and, second, they can lead to starvation of an input-output connection under certain traffic patterns.
Reference: [17] <author> Leland, W.E., Willinger, W., Taqqu, M., Wilson, D., </author> <title> "On the self-similar nature of Ethernet traffic" Proc. </title> <booktitle> of Sigcomm, </booktitle> <address> San Francisco, </address> <year> 1993, </year> <month> pp.183-193. </month>
Reference-contexts: Second, the algorithm should provide high throughput and avoid starvation for any connection pattern. This is because real network traffic is rarely uniformly distributed over inputs and outputs. Fourth, the algorithm should provide high throughput for bursty traffic. Real network traffic is highly correlated from cell to cell <ref> [17] </ref> and the scheduling algorithm should not be unduly affected by the burstiness. However, we can expect all algorithms to perform worse under more bursty traffic. <p> Many ways of modeling bursts in network traffic have been described <ref> [9, 13, 3, 17] </ref>. Recently, Leland et al. have demonstrated that measured network traffic is bursty at every level and that, contrary to popular belief, burstiness in Ethernet networks typically intensifies as the number of active traffic sources increases [17]. <p> Recently, Leland et al. have demonstrated that measured network traffic is bursty at every level and that, contrary to popular belief, burstiness in Ethernet networks typically intensifies as the number of active traffic sources increases <ref> [17] </ref>. So it is very important to understand the performance of switches in the presence of bursty traffic, whether it is a small private switch with a small number of active users, or a large public switch with many thousands of aggregated flows.
Reference: [18] <author> Li, S.-Y., </author> <title> "Theory of periodic contention and its application to packet switching" Proc. </title> <booktitle> of INFOCOM 1988, </booktitle> <address> pp.320-325. </address>
Reference-contexts: Because HOL blocking has very poor performance in the worst case <ref> [18] </ref>, the standard approach has been to abandon input queueing and instead use output queueing by increasing the bandwidth of the internal interconnect, multiple cells can be forwarded at the same time to the same output, and queued there for transmission on the output link. <p> HOL blocking has been shown to limit the aggregate throughput of the switch to just 58% of its maximum for independent Bernoulli arrivals and destinations uniformly distributed over outputs [14]. With less benign traffic patterns, the situation can be much worse <ref> [18] </ref>. Several methods have been proposed for reducing HOL blocking [11, 14, 15, 21, 23], but a simple way described in [14, 15], to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output 1 . This is illustrated in figure 1.
Reference: [19] <author> McKeown, N., Varaiya, P., Walrand, J., </author> <title> "Scheduling Cells in an Input-Queued Switch," </title> <journal> Electronics Letters, </journal> <volume> Vol. </volume> <pages> 29, </pages> <address> No.25 pp.2174-2175. </address>
Reference: [20] <author> Metcalfe, R., Boggs, D. </author> <title> "Ethernet: Distributed packet switching for local computer networks," </title> <journal> Communic. ACM, </journal> <volume> 19, 7, </volume> <month> July </month> <year> 1976, </year> <month> pp.395-404. </month>
Reference-contexts: 1 Introduction The past few years has seen increasing interest in arbitrary topology cell-based local area networks, such as ATM [5]. In these networks, hosts are connected together by an arbitrary graph of communication links and switches, instead of via a bus, as in Ethernet <ref> [20] </ref>, or a ring, as in FDDI [4].
Reference: [21] <author> Obara, H. </author> <title> "Optimum architecture for input queueing ATM switches," Elect. Letters, 28th March 1991, </title> <publisher> pp.555-557. </publisher>
Reference-contexts: A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 6, 8, 12, 15, 21, 22] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance. <p> With less benign traffic patterns, the situation can be much worse [18]. Several methods have been proposed for reducing HOL blocking <ref> [11, 14, 15, 21, 23] </ref>, but a simple way described in [14, 15], to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output 1 . This is illustrated in figure 1.
Reference: [22] <author> Obara, H., Okamoto, S., and Hamazumi, Y. </author> <title> "Input and output queueing ATM switch architecture with spatial and temporal slot reservation control" Elect. Letters, </title> <booktitle> 2nd Jan 1992, </booktitle> <address> pp.22-24. </address>
Reference-contexts: A large number of alternative switch designs have been proposed with varying approaches to these three functions <ref> [2, 6, 8, 12, 15, 21, 22] </ref>, each with their own set of advantages and disadvantages. The goal of this paper is to make a quantitative comparison of scheduling policies for input-queued switches, considering both hardware complexity and switch performance.
Reference: [23] <author> Tamir, Y., Frazier, G. </author> <title> "High performance multi-queue buffers for VLSI communication switches," </title> <booktitle> Proc. of 15th Ann. Symp. on Comp. Arch., </booktitle> <month> June </month> <year> 1988, </year> <month> pp.343-354. </month>
Reference-contexts: Our work is motivated by a different approach. HOL blocking can also be eliminated by using a separate queue for each output <ref> [1, 2, 14, 23] </ref>, where any cell queued at an input is eligible for forwarding across the switch. <p> With less benign traffic patterns, the situation can be much worse [18]. Several methods have been proposed for reducing HOL blocking <ref> [11, 14, 15, 21, 23] </ref>, but a simple way described in [14, 15], to eliminate HOL blocking is to maintain a separate FIFO queue at each input for each output 1 . This is illustrated in figure 1.
Reference: [24] <author> Tarjan, R.E. </author> <title> "Data structures and network algorithms," </title> <institution> Society for Industrial and Applied Mathematics, Pennsylvania, </institution> <month> Nov </month> <year> 1983. </year> <month> 15 </month>
Reference-contexts: As observed in [2], this is equivalent to matching inputs to outputs <ref> [24] </ref>. This paper examines a number of scheduling algorithms for scheduling cells across an input-queued switch, including several proposed in the literature and two novel algorithms we have devised. We simulate the behavior of these algorithms on a variety of synthetic workloads, comparing them on queueing delay, fairness and burst-reduction. <p> buffering to eliminate HOL blocking, we must change the connection scheduling algorithm: the algorithm must now consider the cells at the head of all N 2 input FIFOs and determine a pattern of conflict-free connections that will provide a high throughput. (The algorithm is an example of bipartite graph matching <ref> [24] </ref> and is also an example of the "rooks on a chessboard problem" [1]). 2.2 Maximum Matching Ideally, we would like an algorithm that finds the maximum number of matches between inputs and outputs. <p> But as we are only considering the scheduling of input-output connections in this paper, we shall assume that each input maintains only N output FIFOs. 3 There are several algorithms for achieving a maximum match <ref> [7, 10, 16, 24] </ref>, but these are not suitable for this application for two reasons. First, a maximum match can take a long time to converge and, second, they can lead to starvation of an input-output connection under certain traffic patterns.
Reference: [25] <author> Thacker, C., </author> <title> Private communication. </title>
Reference-contexts: A PIM scheduler is difficult to implement|random selection is an expensive operation, particularly for a variable number of input requests. In the implementation described in [2], the scheduler filled approximately 1.5 Xilinx 3190 [27] devices for each port <ref> [25] </ref>. For a 16x16 switch, this is approximately 64,000 complex gates. If we assume that each gate is approximately eight 2-input gate equivalents this totals 512,000 simple gates. A SLIP scheduling chip contains 2N schedulers, each one is an N input priority encoder with a programmable priority level.
Reference: [26] <author> Wolff, R.W. </author> <title> "Stochastic modeling and the theory of queues," </title> <publisher> Prentice Hall Intl., </publisher> <address> New Jersey, </address> <year> 1989. </year>
Reference-contexts: As a result, the performance is limited by output contention. 5.3.1 Burst Reduction It should come as no surprise that burstiness increases queueing delay: this is generally the case for queueing systems <ref> [26] </ref>. Comparing Figure 8 with Figure 5 (a) we indeed see the serious effect of burstiness on switch performance. In addition to the performance of a single switch for bursty traffic, it is important to consider the effect that the switch has on other switches downstream.
Reference: [27] <author> Xilinx, Inc. "Xilinx: </author> <title> The programmable gate array data book" Xilinx, </title> <publisher> Inc., </publisher> <year> 1991. </year> <month> 16 </month>
Reference-contexts: A PIM scheduler is difficult to implement|random selection is an expensive operation, particularly for a variable number of input requests. In the implementation described in [2], the scheduler filled approximately 1.5 Xilinx 3190 <ref> [27] </ref> devices for each port [25]. For a 16x16 switch, this is approximately 64,000 complex gates. If we assume that each gate is approximately eight 2-input gate equivalents this totals 512,000 simple gates.
References-found: 27

