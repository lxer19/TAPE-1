URL: http://polaris.cs.uiuc.edu/reports/969.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: EFFICIENT SOLUTION OF PARABOLIC EQUATIONS BY KRYLOV APPROXIMATION METHODS  
Author: E. GALLOPOULOS AND Y. SAAD 
Keyword: Key words. parabolic problems, method of lines, explicit methods, Krylov subspace, parallelism, matrix exponential, polynomial approximation, exponential propagation, rational approximation, partial fractions, stability  
Note: AMS(MOS) subject classifications. 65M20, 65F10, 65W05  
Abstract: In this paper we take a new look at numerical techniques for solving parabolic equations by the method of lines. The main motivation for the proposed approach is the possibility of exploiting a high degree of parallelism in a simple manner. The basic idea of the method is to approximate the action of the evolution operator on a given state vector by means of a projection process onto a Krylov subspace. Thus, the resulting approximation consists of applying an evolution operator of very small dimension to a known vector which is, in turn, computed accurately by exploiting high-order rational Chebyshev and Pade approximations to the exponential. Because the rational approximation is only applied to a small matrix, the only operations required with the original large matrix are matrix-by-vector multiplications, and as a result the algorithm can easily be parallelized and vectorized. Further parallelism is introduced by expanding the rational approximations into partial fractions. Some relevant approximation and stability issues are discussed. We present some numerical experiments with the method and compare its performance with a few explicit and implicit algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. N. Brown and A. C. Hindmarsh, </author> <title> Matrix-free methods for stiff systems of ODEs, </title> <journal> SIAM J. Numer.Anal., </journal> <volume> 23 (1986), </volume> <pages> pp. 610-638. 27 </pages>
Reference-contexts: More recently, Friesner et al. [9] have demonstrated that these techniques can be extended to solving nonlinear stiff differential equations. The approach developed in this paper is related to that of Gear and Saad [14], Brown and Hindmarsh <ref> [1] </ref> on matrix-free methods in the Newton iteration of implicit mul-tistep schemes; Our scheme uses a similar reduction of the underlying matrix but goes further in combining it with high-order approximation schemes for the reduced (exponential) operator.
Reference: [2] <author> A. J. Carpenter, A. Ruttan, and R. S. Varga, </author> <title> Extended numerical computations on the 1/9 conjecture in rational approximation theory, in Rational Approximation and Interpolation, </title> <editor> P. R. Graves-Morris, E. B. Saff, and R. S. Varga, eds., </editor> <volume> vol. </volume> <booktitle> 1105 of Lecture Notes in Mathematics, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1984, </year> <pages> pp. 383-411. </pages>
Reference-contexts: For typical parabolic problems that involve a second order partial differential operator L that is self-adjoint elliptic, the eigen-values of L are located in the interval [0; +1). It is therefore natural to follow the idea introduced by Varga in [52] (see also <ref> [2, 3] </ref>) and seek the Chebyshev (uniform) rational approximation to the function e z which minimizes the maximum error on the interval [0; +1). <p> We mentioned earlier that the Pade approximations provide good approximation only near the origin. Using the Chebyshev rational approximation to the function e z over the interval [0; +1) <ref> [2, 52] </ref>, it becomes possible to utilize time steps as large as our Krylov-based method allows. For example in the diagonal Chebyshev rational approximation, the infinity norm of the error over the interval [0; +1) is of the order of 10 10 as soon as reaches 10. <p> For example in the diagonal Chebyshev rational approximation, the infinity norm of the error over the interval [0; +1) is of the order of 10 10 as soon as reaches 10. For each additional degree the improvement is of the order of 9.289025... <ref> [2] </ref>. What this means is that for all practical purposes e z can be replaced by a rational function of relatively small degree. When H is nonsymmetric and its eigenvalues are complex, then the rational function is no longer guaranteed to be an accurate approximation to the exponential.
Reference: [3] <author> J. C. Cavendish, W. E. Culham, and R. S. Varga, </author> <title> A comparison of Crank-Nicolson and Chebyshev rational methods for numerically solving linear parabolic equations, </title> <journal> J. Comput. Phys., </journal> <volume> 10 (1972), </volume> <pages> pp. 354-368. </pages>
Reference-contexts: This brings to mind an analogous situation for linear systems in which it is preferable to solve Ax = b than to compute A 1 and then multiply the solution by b. We point out that we follow an approach common in the literature <ref> [3, 42] </ref>, putting the emphasis on the semi-discrete problem (1.2). As a result, our discussion of stability is purely from an Ordinary Differential Equation point of view and is not concerned with the effect of space discretization errors and convergence. <p> Since Pade approximations are local, they are very accurate near the origin but may be inaccurate far away from it. Other schemes have been developed <ref> [3, 18, 52] </ref> to overcome this difficulty. For typical parabolic problems that involve a second order partial differential operator L that is self-adjoint elliptic, the eigen-values of L are located in the interval [0; +1). <p> For typical parabolic problems that involve a second order partial differential operator L that is self-adjoint elliptic, the eigen-values of L are located in the interval [0; +1). It is therefore natural to follow the idea introduced by Varga in [52] (see also <ref> [2, 3] </ref>) and seek the Chebyshev (uniform) rational approximation to the function e z which minimizes the maximum error on the interval [0; +1).
Reference: [4] <author> A. R. Curtis, </author> <title> Jacobian matrix properties and their impact on the choice of software for stiff ODE systems, </title> <journal> IMA J. Numer. Anal., </journal> <volume> 3 (1983), </volume> <pages> pp. 397-415. </pages>
Reference-contexts: Although our method works from a subspace, it does not suffer from some of the aspects of partitioning methods (see, for example, [55]). Partitioning methods rely on explicitly separating and treating differently the stiff and nonstiff parts. However, it is usually impractical to confine stiffness to a subsystem <ref> [4] </ref>. The Krylov method, on the other hand, relies on the nice convergence property of Krylov approximations to essentially reach a similar goal in an implicit manner [38].
Reference: [5] <author> K. Dekker and J. G. Verwer, </author> <title> Stability of Runge-Kutta methods for stiff nonlinear differential equations, </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1984. </year>
Reference-contexts: We establish conditions under which our methods, applied to the stiff system of ODEs (1.2), satisfy certain criteria of stability which, in turn, is an important step toward any investigations of convergence. (See also <ref> [5, 40] </ref>.) The Krylov subspace method presented here was introduced in [13] for general nonsymmetric matrices. However, similar ideas have been used previously in various ways in different applications for symmetric or skew-symmetric matrices. <p> Then the logarithmic norm (B) is equal to the maximum eigenvalue of the symmetric part of B, that is, (B) = max ( 2 The function satisfies many norm-like properties, but it can also take negative values. We refer to <ref> [5, 6] </ref> for a description of its properties. It can be shown in particular that ke Bt k e (B)t :(2.4) We assume throughout that A is a real matrix. We now state the main theorem of this section. Theorem 2.1. <p> In general, the advantage of using the logarithmic norm follows from the inequality kAk (A) which is among the properties of (:) (cf. [6]). One can construct examples however, for which the bounds from using (A) are as loose as those obtained from using kAk (cf. <ref> [5] </ref>). Also, asymptotically the rates of convergence as estimated by the bounds (2.6) and (2.5) are both of the form =(m!) 1=m . The following corollary follows trivially from Theorem 2.1. Corollary 2.2.
Reference: [6] <author> C. Desoer and H. Haneda, </author> <title> The measure of a matrix as a tool to analyze computer algorithms for circuit analysis, </title> <journal> IEEE Trans. Circuit Theory, </journal> <volume> 19 (1972), </volume> <pages> pp. 480-486. </pages>
Reference-contexts: Then the logarithmic norm (B) is equal to the maximum eigenvalue of the symmetric part of B, that is, (B) = max ( 2 The function satisfies many norm-like properties, but it can also take negative values. We refer to <ref> [5, 6] </ref> for a description of its properties. It can be shown in particular that ke Bt k e (B)t :(2.4) We assume throughout that A is a real matrix. We now state the main theorem of this section. Theorem 2.1. <p> When m = 7, the error in the approximation from (2.6) is bounded by 0:1004fi, whereas Theorem 2.1 provides the sharper estimate 0:018fi. In general, the advantage of using the logarithmic norm follows from the inequality kAk (A) which is among the properties of (:) (cf. <ref> [6] </ref>). One can construct examples however, for which the bounds from using (A) are as loose as those obtained from using kAk (cf. [5]). Also, asymptotically the rates of convergence as estimated by the bounds (2.6) and (2.5) are both of the form =(m!) 1=m .
Reference: [7] <author> B. L. Ehle, </author> <title> A-stable methods and Pade approximations to the exponential, </title> <journal> SIAM. J. Numer. Anal., </journal> <volume> 4 (Nov. </volume> <year> 1973), </year> <pages> pp. 671-680. </pages>
Reference-contexts: We note however that alterna-tive strategies (e.g., (- 1; -)) will frequently work better for Pade approximations, without altering the principle of the method. Note that the stability properties of the aforementioned rational approximations are discussed extensively in the literature <ref> [7, 20, 54] </ref>. A comparison between the Pade approximation and the Chebyshev rational approximation reveals the vast superiority of the latter in the context of the Krylov-based methods presented in this paper, at least for symmetric positive matrices H, and relatively large values of m.
Reference: [8] <author> S. W. Ellacott, </author> <title> On the Faber transformation and efficient numerical rational approximation, </title> <journal> SIAM J. Numer. Anal., </journal> <month> 20 (Oct. </month> <year> 1983), </year> <pages> pp. 989-1000. </pages>
Reference-contexts: Although little is known concerning rational uniform approximation in general regions of the complex plane, a promising alternative is to use asymptotically optimal methods based on Faber transformations in the complex plane <ref> [8] </ref>. We also point out that there exist other techniques for approximating matrix exponentials by rational functions of A; see, for example, [18, 31]. <p> Roland Freund for many helpful discussions, and Dr. Randall Bramley for his comments on an early version of the paper. We also thank the referees for their recommendations and for bringing to our attention reference <ref> [8] </ref>.
Reference: [9] <author> R. A. Friesner, L. S. Tuckerman, B. C. Dornblaser, and T. V. Russo, </author> <title> A method for exponential propagation of large systems of stiff nonlinear differential equations, </title> <journal> J. Sci. Com-put., </journal> <volume> 4 (1989), </volume> <pages> pp. 327-354. </pages>
Reference-contexts: The idea of exploiting the Lanczos algorithm to evaluate terms of the exponential of Hamiltonian operators seems to have been first used in chemical physics by Nauts and Wyatt in the context of the Recursive-Residue-Generation method [29]. More recently, Friesner et al. <ref> [9] </ref> have demonstrated that these techniques can be extended to solving nonlinear stiff differential equations.

Reference: [14] <author> C. W. Gear and Y. Saad, </author> <title> Iterative solution of linear equations in ODE codes, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 4 (1983), </volume> <pages> pp. 583-601. </pages>
Reference-contexts: More recently, Friesner et al. [9] have demonstrated that these techniques can be extended to solving nonlinear stiff differential equations. The approach developed in this paper is related to that of Gear and Saad <ref> [14] </ref>, Brown and Hindmarsh [1] on matrix-free methods in the Newton iteration of implicit mul-tistep schemes; Our scheme uses a similar reduction of the underlying matrix but goes further in combining it with high-order approximation schemes for the reduced (exponential) operator.
Reference: [15] <author> E. Hairer, G. Bader, and C. Lubich, </author> <title> On the stability of semi-implicit methods for ordinary differential equations, </title> <journal> BIT, </journal> <volume> 22 (1982), </volume> <pages> pp. 211-232. </pages>
Reference-contexts: from a result of von Neumann which states that, when the field of values of a matrix B is contained in H, the nonnegative half of the complex plane, and if a rational function f maps H into the unit disk, then kf (B)k 2 1; see also [47] and <ref> [15, Theorem 4] </ref>. A similar conclusion holds for the subdiagonal (- 1; -) approximation. When a diagonal Chebyshev approximation is used then this no longer holds as these approximations may amplify small eigenvalues of H m near zero.
Reference: [16] <author> A. C. Hindmarsh, ODEPACK, </author> <title> A systematized collection of ODE solvers, in Scientific Computing, </title> <editor> R. S. Stepleman, et al., ed., </editor> <publisher> North Holland, </publisher> <address> Amsterdam, </address> <year> 1983, </year> <pages> pp. 55-64. </pages>
Reference-contexts: From this viewpoint, this "inexact Crank-Nicolson" method shares many of the benefits of the Krylov method, as was already mentioned in the introduction. Finally, a well known stiff ODE package such as LSODE <ref> [16] </ref> is also considered. For this comparison we took the same problem as before, but we needed to take fl = 0:0 in order to make the matrix A symmetric.
Reference: [17] <author> E. Isaacson and H. B. Keller, </author> <title> Analysis of Numerical Methods, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: It is verified whenever the quadrature weights are nonnegative. In particular Lemma 5.1. The positivity condition is satisfied for any Gaussian quadrature formula. Proof. The fact that the weights are positive for Gaussian quadrature is well known; see, e.g. <ref> [17, p. 328] </ref>. For the undervaluation condition, we can prove the following lemma. Lemma 5.2. 1. Any composite or simple open Newton-Cotes formula satisfies the undervalu ation condition (5.10). 2. Any k-point Gaussian quadrature rule satisfies the undervaluation condition (5.10). Proof. <p> Lemma 5.2. 1. Any composite or simple open Newton-Cotes formula satisfies the undervalu ation condition (5.10). 2. Any k-point Gaussian quadrature rule satisfies the undervaluation condition (5.10). Proof. This is a consequence of the well-known error formulas for open Newton-Cotes rules <ref> [17, p. 313-314] </ref>, and for Gaussian quadrature rules [17, p. 330], and the fact that all the derivatives of the function e s are positive in the interval [0; ffi]. Going back to the condition (5.8), we first observe under the positivity condition (5.9) the left-hand inequality is trivially satisfied. <p> Lemma 5.2. 1. Any composite or simple open Newton-Cotes formula satisfies the undervalu ation condition (5.10). 2. Any k-point Gaussian quadrature rule satisfies the undervaluation condition (5.10). Proof. This is a consequence of the well-known error formulas for open Newton-Cotes rules [17, p. 313-314], and for Gaussian quadrature rules <ref> [17, p. 330] </ref>, and the fact that all the derivatives of the function e s are positive in the interval [0; ffi]. Going back to the condition (5.8), we first observe under the positivity condition (5.9) the left-hand inequality is trivially satisfied.
Reference: [18] <author> A. Iserles, </author> <title> Rational interpolation to exp(x) with application to certain stiff systems, </title> <journal> SIAM J. Numer. Anal., </journal> <month> 18 (Feb. </month> <year> 1981), </year> <pages> pp. 1-12. </pages>
Reference-contexts: Since Pade approximations are local, they are very accurate near the origin but may be inaccurate far away from it. Other schemes have been developed <ref> [3, 18, 52] </ref> to overcome this difficulty. For typical parabolic problems that involve a second order partial differential operator L that is self-adjoint elliptic, the eigen-values of L are located in the interval [0; +1). <p> We also point out that there exist other techniques for approximating matrix exponentials by rational functions of A; see, for example, <ref> [18, 31] </ref>. The restricted Pade approximations of [31] avoid complex arithmetic at the price of a reduced order of approximation, and reduced levels of parallelism caused by the occurrence of multiple poles.
Reference: [19] <author> A. Iserles and S. P. Ntrsett, </author> <title> On the theory of parallel Runge-Kutta methods, </title> <journal> IMA J. Numer. Anal., </journal> <volume> 10 (1990), </volume> <pages> pp. 463-488. </pages>
Reference-contexts: Note that there have been several recent efforts to design algorithms for the solution of time-dependent problems, some of which may be particularly suited to parallel processing; see <ref> [19, 21, 22, 43, 48] </ref> and [49] for a review.
Reference: [20] <author> A. Iserles and M. J. D. Powell, </author> <title> On the A-acceptability of rational approximations that interpolate the exponential function, </title> <journal> IMA J. Numer. Anal., </journal> <volume> 1 (1981), </volume> <pages> pp. 241-251. </pages>
Reference-contexts: We note however that alterna-tive strategies (e.g., (- 1; -)) will frequently work better for Pade approximations, without altering the principle of the method. Note that the stability properties of the aforementioned rational approximations are discussed extensively in the literature <ref> [7, 20, 54] </ref>. A comparison between the Pade approximation and the Chebyshev rational approximation reveals the vast superiority of the latter in the context of the Krylov-based methods presented in this paper, at least for symmetric positive matrices H, and relatively large values of m.
Reference: [21] <author> O. A. Karakashian and W. Rust, </author> <title> On the parallel implementation of implicit Runge-Kutta methods, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 9 (Nov. </volume> <year> 1988), </year> <pages> pp. 1085-1090. </pages>
Reference-contexts: Note that there have been several recent efforts to design algorithms for the solution of time-dependent problems, some of which may be particularly suited to parallel processing; see <ref> [19, 21, 22, 43, 48] </ref> and [49] for a review.
Reference: [22] <author> S. Keeling, </author> <title> Galerkin Runge-Kutta discretizations for parabolic equations with time-dependent coefficients, </title> <journal> Math. Comp., </journal> <month> 52 (April </month> <year> 1989), </year> <pages> pp. 561-586. </pages>
Reference-contexts: Note that there have been several recent efforts to design algorithms for the solution of time-dependent problems, some of which may be particularly suited to parallel processing; see <ref> [19, 21, 22, 43, 48] </ref> and [49] for a review.
Reference: [23] <author> H. T. Kung, </author> <title> New algorithms and lower bounds for the parallel evaluation of certain rational expressions and recurrences, </title> <journal> J. Assoc. Comput. Mach., </journal> <month> 23 (April </month> <year> 1976), </year> <pages> pp. 252-261. </pages>
Reference-contexts: need to evaluate the vector ~y, where ~y = p -(H)q -(H) 1 e 1 = q - (H) 1 p - (H)e 1 :(3.2) It has been proposed in several contexts that an efficient method for computing some rational matrix functions is to resort to their partial fraction expansions <ref> [10, 11, 13, 23, 25, 33, 44, 56] </ref>. The approach is possible since it can be proved analytically that the diagonal Pade approximation to e z has distinct poles [57]. Explicit calculations indicate that this seems to be also true for the uniform approximation.
Reference: [24] <author> E. Landau, </author> <title> Uber einen Mellinshen Satz, </title> <journal> Arch. Math. Phys. Ser. </journal> <volume> 3, 24 (1915), </volume> <pages> pp. 97-107. </pages>
Reference-contexts: Then kr m (A)k 2 = k k=m k! 1 X 1 (fl) k k 2 : From the assumption on A, &lt;e [fl] 0. Applying component-wise a result of E. Landau <ref> [24] </ref>, (cf. [36, p. 35, problem 151]), the remainder can be bounded by its first term: kr m (A)k 2 m! kA m k 2 : The bound of Corollary 2.2 follows after using a similar treatment for H m and combining the results as shown in Lemma A.1 of Appendix
Reference: [25] <author> J. D. Lawson and D. A. Swayne, </author> <title> High-order near best uniform approximations to the solution of heat conduction problems, </title> <booktitle> in Proc. IFIP Congress 80 Information Processing 80, </booktitle> <address> New York, 1980, </address> <publisher> North Holland, </publisher> <pages> pp. 741-746. </pages>
Reference-contexts: need to evaluate the vector ~y, where ~y = p -(H)q -(H) 1 e 1 = q - (H) 1 p - (H)e 1 :(3.2) It has been proposed in several contexts that an efficient method for computing some rational matrix functions is to resort to their partial fraction expansions <ref> [10, 11, 13, 23, 25, 33, 44, 56] </ref>. The approach is possible since it can be proved analytically that the diagonal Pade approximation to e z has distinct poles [57]. Explicit calculations indicate that this seems to be also true for the uniform approximation.
Reference: [26] <author> D. Lee, </author> <title> Nonlinear Multistep Methods for Solving Initial Value Problems in Ordinary Differential Equations, </title> <type> PhD thesis, </type> <institution> Polytechnic Institute of New York, </institution> <year> 1974. </year>
Reference-contexts: The basic operation in the above formula is the computation of the exponential of a given matrix times a vector. If we were able to perform this basic operation with high accuracy, we would have what is sometimes called a nonlinear one-step method <ref> [26] </ref>, because it involves a nonlinear operation with the matrix A. We should stress that there is no need to actually evaluate the matrix exponential exp (ffiA), but only its product with a given vector. <p> The above scheme is a one-step technique where ffi is the time step. If we assume that the exponential term is exactly evaluated, then the above methods are referred to as the nonlinear multistep methods by Lee <ref> [26] </ref>. It was remarked in [27] that these methods are stable.
Reference: [27] <author> D. Lee and J. S. Papadakis, </author> <title> Numerical solutions of underwater acoustic wave propagation problems, </title> <type> Tech. Report NUSC TR. 5929, </type> <institution> Naval Underwater Systems Center, </institution> <address> New London, CT, </address> <year> 1979. </year>
Reference-contexts: The above scheme is a one-step technique where ffi is the time step. If we assume that the exponential term is exactly evaluated, then the above methods are referred to as the nonlinear multistep methods by Lee [26]. It was remarked in <ref> [27] </ref> that these methods are stable. More generally, let us assume that the error incurred in the evaluation of the term e Affi w N in (5.1) is e 1;N , while the error in the evaluation of the integral term s N is e 2;N .
Reference: [28] <author> C. Moler and C. V. Loan, </author> <title> Nineteen dubious ways to compute the exponential of a matrix, </title> <journal> SIAM Rev., </journal> <month> 20 (October </month> <year> 1978), </year> <pages> pp. 801-836. </pages>
Reference-contexts: We drop the subscript m for convenience. Although H is a small matrix, the cost of computing y can easily become non-negligible. See <ref> [28] </ref> for a review of methods for computing the matrix exponential. For example, when H is tridiagonal symmetric, the simplest technique for computing y is based on the QR algorithm. However, this is rather expensive.
Reference: [29] <author> A. Nauts and R. E. Wyatt, </author> <title> New approach to many-state quantum dynamics: The recursive-residue-generation method, </title> <journal> Phys. Rev. Lett., </journal> <volume> 51 (1983), </volume> <pages> pp. </pages> <month> 2238-2241. </month> <title> [30] , Theory of laser-module interaction: The recursive-residue-generation method, </title> <journal> Physical Rev., </journal> <volume> 30 (1984), </volume> <pages> pp. 872-883. </pages>
Reference-contexts: The idea of exploiting the Lanczos algorithm to evaluate terms of the exponential of Hamiltonian operators seems to have been first used in chemical physics by Nauts and Wyatt in the context of the Recursive-Residue-Generation method <ref> [29] </ref>. More recently, Friesner et al. [9] have demonstrated that these techniques can be extended to solving nonlinear stiff differential equations.
Reference: [31] <author> S. P. Ntrsett, </author> <title> Restricted Pade approximations to the exponential function, </title> <journal> SIAM J. Numer. Anal., </journal> <month> 15 (Oct. </month> <year> 1978), </year> <pages> pp. 1008-1029. </pages>
Reference-contexts: We also point out that there exist other techniques for approximating matrix exponentials by rational functions of A; see, for example, <ref> [18, 31] </ref>. The restricted Pade approximations of [31] avoid complex arithmetic at the price of a reduced order of approximation, and reduced levels of parallelism caused by the occurrence of multiple poles. <p> We also point out that there exist other techniques for approximating matrix exponentials by rational functions of A; see, for example, [18, 31]. The restricted Pade approximations of <ref> [31] </ref> avoid complex arithmetic at the price of a reduced order of approximation, and reduced levels of parallelism caused by the occurrence of multiple poles.
Reference: [32] <author> B. Nour-Omid, </author> <title> Applications of the Lanczos algorithm, </title> <journal> Comput. Phys. Comm., </journal> <volume> 53 (1989), </volume> <pages> pp. 153-168. </pages>
Reference-contexts: It is also related to the work of Nour-Omid <ref> [32] </ref>, in which systems of ODEs are solved by first projecting into Krylov subspaces with an unsym-metric two-sided Lanczos process and then solving tridiagonal systems of ODEs; the approach of Tal-Ezer and Kosloff [46]; and also the work of Tal-Ezer [45] and Schaefer 3 [41] on polynomial methods based on Chebyshev
Reference: [33] <author> P. Pandey, C. Kenney, and A. J. Laub, </author> <title> A parallel algorithm for the matrix sign function, </title> <journal> Int'l. J. High Speed Comput., </journal> <month> 2 (June </month> <year> 1990), </year> <pages> pp. 181-191. </pages>
Reference-contexts: need to evaluate the vector ~y, where ~y = p -(H)q -(H) 1 e 1 = q - (H) 1 p - (H)e 1 :(3.2) It has been proposed in several contexts that an efficient method for computing some rational matrix functions is to resort to their partial fraction expansions <ref> [10, 11, 13, 23, 25, 33, 44, 56] </ref>. The approach is possible since it can be proved analytically that the diagonal Pade approximation to e z has distinct poles [57]. Explicit calculations indicate that this seems to be also true for the uniform approximation.
Reference: [34] <author> T. J. Park and J. C. </author> <title> Light, Unitary quantum time evolution by iterative Lanczos reduction, </title> <journal> J. Chem. Phys., </journal> <volume> 85 (1986), </volume> <pages> pp. 5870-5876. </pages>
Reference-contexts: However, similar ideas have been used previously in various ways in different applications for symmetric or skew-symmetric matrices. For example, we would like to mention the use of this basic idea in Park and Light <ref> [34] </ref> following the work by Nauts and Wyatt [30]. The idea of exploiting the Lanczos algorithm to evaluate terms of the exponential of Hamiltonian operators seems to have been first used in chemical physics by Nauts and Wyatt in the context of the Recursive-Residue-Generation method [29].
Reference: [35] <author> B. N. Parlett, </author> <title> The Symmetric Eigenvalue Problem, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, </address> <year> 1980. </year>
Reference-contexts: If A is positive real, 1 i.e., if its symmetric part S = 1 2 (A + A T ) is positive definite, then, so is the matrix H m <ref> [35] </ref>.
Reference: [36] <author> G. P olya and G. </author> <title> Szeg o, Problems and Theorems in Analysis I, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: Then kr m (A)k 2 = k k=m k! 1 X 1 (fl) k k 2 : From the assumption on A, &lt;e [fl] 0. Applying component-wise a result of E. Landau [24], (cf. <ref> [36, p. 35, problem 151] </ref>), the remainder can be bounded by its first term: kr m (A)k 2 m! kA m k 2 : The bound of Corollary 2.2 follows after using a similar treatment for H m and combining the results as shown in Lemma A.1 of Appendix A.
Reference: [37] <author> G. Rodrigue and D. Wolitzer, </author> <title> Preconditioned time-differencing for the parallel solution of the heat equation, </title> <booktitle> in Proc. Fourth SIAM Conf. Parallel Processing for Scientific Computing, </booktitle> <editor> J. Dongarra, P. Messina, D. C. Sorensen, and R. G. Voigt, eds., </editor> <publisher> SIAM, </publisher> <year> 1990, </year> <pages> pp. 268-272. </pages> <address> Chicago, </address> <month> Dec. </month> <year> 1989. </year>
Reference-contexts: The use of preconditioning for extending the stability interval of explicit methods, thus bringing them closer to fully implicit methods, has been discussed in <ref> [37, 50] </ref>. Although our method works from a subspace, it does not suffer from some of the aspects of partitioning methods (see, for example, [55]). Partitioning methods rely on explicitly separating and treating differently the stiff and nonstiff parts.
Reference: [38] <author> Y. Saad, </author> <title> On the rates of convergence of the Lanczos and the block-Lanczos methods, </title> <journal> SIAM J. Numer. Anal., </journal> <month> 17 (Oct. </month> <year> 1980), </year> <pages> pp. </pages> <month> 687-706. </month> <title> [39] , Analysis of some Krylov subspace approximations to the matrix exponential operator, </title> <note> SIAM J. Numer. Anal., (To appear). </note>
Reference-contexts: However, it is usually impractical to confine stiffness to a subsystem [4]. The Krylov method, on the other hand, relies on the nice convergence property of Krylov approximations to essentially reach a similar goal in an implicit manner <ref> [38] </ref>. The outermost eigenvalues, including the largest ones, will be well approximated by the Krylov subspace, so that the Krylov approximation to the matrix exponential will be accurate in those eigenvalues, thus accommodating stiffness.
Reference: [40] <author> J. M. Sanz-Serna and J. G. Verwer, </author> <title> Stability and convergence at the PDE/stiff ODE interface, </title> <journal> Appl. Numer. Math., </journal> <volume> 5 (1989), </volume> <pages> pp. 117-132. </pages>
Reference-contexts: We establish conditions under which our methods, applied to the stiff system of ODEs (1.2), satisfy certain criteria of stability which, in turn, is an important step toward any investigations of convergence. (See also <ref> [5, 40] </ref>.) The Krylov subspace method presented here was introduced in [13] for general nonsymmetric matrices. However, similar ideas have been used previously in various ways in different applications for symmetric or skew-symmetric matrices.
Reference: [41] <author> M. J. Schaefer, </author> <title> A polynomial based iterative method for linear parabolic equations, </title> <type> Tech. Report 661, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> May </month> <year> 1987. </year>
Reference-contexts: related to the work of Nour-Omid [32], in which systems of ODEs are solved by first projecting into Krylov subspaces with an unsym-metric two-sided Lanczos process and then solving tridiagonal systems of ODEs; the approach of Tal-Ezer and Kosloff [46]; and also the work of Tal-Ezer [45] and Schaefer 3 <ref> [41] </ref> on polynomial methods based on Chebyshev expansions. The idea of evaluating arbitrary functions of a Hermitian matrix with the use of the Lanczos algorithm has also been mentioned by van der Vorst [51].
Reference: [42] <author> W. L. Seward, G. Fairweather, and R. L. Johnston, </author> <title> A survey of high-order methods for the numerical integration of semidiscrete parabolic problems, </title> <journal> IMA J. Numer. Anal., </journal> <volume> 4 (1984), </volume> <pages> pp. 375-425. </pages>
Reference-contexts: This brings to mind an analogous situation for linear systems in which it is preferable to solve Ax = b than to compute A 1 and then multiply the solution by b. We point out that we follow an approach common in the literature <ref> [3, 42] </ref>, putting the emphasis on the semi-discrete problem (1.2). As a result, our discussion of stability is purely from an Ordinary Differential Equation point of view and is not concerned with the effect of space discretization errors and convergence. <p> In particular, let exp (H m ffi) be evaluated using a diagonal (-; -) Pade approximation R -. Diagonal Pade approximations are A-acceptable, that is jR -(z)j &lt; 1 for all z in the positive half plane <ref> [42] </ref>. From above, &lt;x H H m x 0 for any x and (H m ) 0. <p> Then the region of stability of this scheme contains the positive real line. Note that schemes with such properties are said to be A 0 -stable in the literature <ref> [42] </ref>. In many of our numerical experiments, we have observed this difference in stability behavior between schemes that satisfy the conditions of the theorem and those that don't. In many instances the composite closed-type Newton-Cotes formulas tended to diverge for a small number of subintervals.
Reference: [43] <author> Q. Sheng, </author> <title> Solving linear partial differential equations by exponential splitting, </title> <journal> IMA J. Numer. Anal., </journal> <volume> 9 (1989), </volume> <pages> pp. 199-212. </pages>
Reference-contexts: Note that there have been several recent efforts to design algorithms for the solution of time-dependent problems, some of which may be particularly suited to parallel processing; see <ref> [19, 21, 22, 43, 48] </ref> and [49] for a review.
Reference: [44] <author> R. A. Sweet, </author> <title> A parallel and vector cyclic reduction algorithm, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <month> 9 (July </month> <year> 1988), </year> <pages> pp. 761-765. </pages>
Reference-contexts: need to evaluate the vector ~y, where ~y = p -(H)q -(H) 1 e 1 = q - (H) 1 p - (H)e 1 :(3.2) It has been proposed in several contexts that an efficient method for computing some rational matrix functions is to resort to their partial fraction expansions <ref> [10, 11, 13, 23, 25, 33, 44, 56] </ref>. The approach is possible since it can be proved analytically that the diagonal Pade approximation to e z has distinct poles [57]. Explicit calculations indicate that this seems to be also true for the uniform approximation.
Reference: [45] <author> H. Tal-Ezer, </author> <title> Spectral methods in time for parabolic problems, </title> <journal> SIAM J. Numer. Anal., </journal> <month> 26 (Feb. </month> <year> 1989), </year> <pages> pp. 1-11. </pages>
Reference-contexts: It is also related to the work of Nour-Omid [32], in which systems of ODEs are solved by first projecting into Krylov subspaces with an unsym-metric two-sided Lanczos process and then solving tridiagonal systems of ODEs; the approach of Tal-Ezer and Kosloff [46]; and also the work of Tal-Ezer <ref> [45] </ref> and Schaefer 3 [41] on polynomial methods based on Chebyshev expansions. The idea of evaluating arbitrary functions of a Hermitian matrix with the use of the Lanczos algorithm has also been mentioned by van der Vorst [51].
Reference: [46] <author> H. Tal-Ezer and R. Kosloff, </author> <title> An accurate and efficient scheme for propagating the time dependent Schrodinger equation, </title> <journal> J. Chem. Phys., </journal> <volume> 81 (1984), </volume> <pages> pp. 3967-3971. </pages>
Reference-contexts: It is also related to the work of Nour-Omid [32], in which systems of ODEs are solved by first projecting into Krylov subspaces with an unsym-metric two-sided Lanczos process and then solving tridiagonal systems of ODEs; the approach of Tal-Ezer and Kosloff <ref> [46] </ref>; and also the work of Tal-Ezer [45] and Schaefer 3 [41] on polynomial methods based on Chebyshev expansions. The idea of evaluating arbitrary functions of a Hermitian matrix with the use of the Lanczos algorithm has also been mentioned by van der Vorst [51].
Reference: [47] <author> J. v. Neumann, </author> <title> Eine Spektraletheorie fur allgemeine Operatoren eines unitaren Raumes, </title> <journal> Math. Nachr., </journal> <volume> 4 (1950-51), </volume> <pages> pp. 258-281. </pages>
Reference-contexts: ffi)V T from a result of von Neumann which states that, when the field of values of a matrix B is contained in H, the nonnegative half of the complex plane, and if a rational function f maps H into the unit disk, then kf (B)k 2 1; see also <ref> [47] </ref> and [15, Theorem 4]. A similar conclusion holds for the subdiagonal (- 1; -) approximation. When a diagonal Chebyshev approximation is used then this no longer holds as these approximations may amplify small eigenvalues of H m near zero.
Reference: [48] <author> P. J. van der Houwen and B. P. Sommeijer, </author> <title> Parallel iteration of high-order Runge-Kutta methods with stepsize control, </title> <journal> J. Comput. Appl. Math., </journal> <volume> 29 (1990), </volume> <pages> pp. </pages> <month> 111-127. </month> <title> [49] , Parallel ODE solvers, </title> <booktitle> in Proc. 1990 ACM Int'l. Conference on Supercomputing, </booktitle> <address> Amster-dam, </address> <month> June </month> <year> 1990, </year> <booktitle> ACM, </booktitle> <pages> pp. 71-81. </pages>
Reference-contexts: Note that there have been several recent efforts to design algorithms for the solution of time-dependent problems, some of which may be particularly suited to parallel processing; see <ref> [19, 21, 22, 43, 48] </ref> and [49] for a review.
Reference: [50] <author> P. J. van der Houwen, B. P. Sommeijer, and F. W. Wubs, </author> <title> Analysis of smoothing operators in the solution of partial differential equations by explicit difference schemes, </title> <journal> Appl. Numer. Math., </journal> <volume> 6 (1989/90), </volume> <pages> pp. 501-521. </pages>
Reference-contexts: The use of preconditioning for extending the stability interval of explicit methods, thus bringing them closer to fully implicit methods, has been discussed in <ref> [37, 50] </ref>. Although our method works from a subspace, it does not suffer from some of the aspects of partitioning methods (see, for example, [55]). Partitioning methods rely on explicitly separating and treating differently the stiff and nonstiff parts.
Reference: [51] <author> H. van der Vorst, </author> <title> An iterative solution method for solving f(A)x = b using Krylov subspace information obtained for the symmetric positive definite matrix A, </title> <journal> J. Comput. Appl. Math., </journal> <volume> 18 (1987), </volume> <pages> pp. 249-263. </pages>
Reference-contexts: The idea of evaluating arbitrary functions of a Hermitian matrix with the use of the Lanczos algorithm has also been mentioned by van der Vorst <ref> [51] </ref>. The use of preconditioning for extending the stability interval of explicit methods, thus bringing them closer to fully implicit methods, has been discussed in [37, 50]. Although our method works from a subspace, it does not suffer from some of the aspects of partitioning methods (see, for example, [55]).
Reference: [52] <author> R. S. Varga, </author> <title> On higher order stable implicit methods for solving parabolic partial differential equations, </title> <journal> J. Math. Phys., </journal> <volume> 40 (1961), </volume> <pages> pp. 220-231. </pages>
Reference-contexts: Going back to the comparison sketched above, we note that the process involved in one single step of an implicit method is often simply an attempt to generate some approximation to the operation exp (ffit A)v via a rational approximation to the evolution operator <ref> [52] </ref>. If a CG-like method is used to solve the linear systems arising in the implicit procedure, the result will be a polynomial scheme. <p> It should also be mentioned that the approach we are using to aproximate and evaluate the exponential of the reduced operator has its roots in the work of Varga <ref> [52] </ref> and in previous work by the authors and others; see Section 3 for details. The structure of our paper is as follows. In Section 2 we formulate the Krylov subspace approximation algorithm and prove some a priori error bounds. <p> Since Pade approximations are local, they are very accurate near the origin but may be inaccurate far away from it. Other schemes have been developed <ref> [3, 18, 52] </ref> to overcome this difficulty. For typical parabolic problems that involve a second order partial differential operator L that is self-adjoint elliptic, the eigen-values of L are located in the interval [0; +1). <p> For typical parabolic problems that involve a second order partial differential operator L that is self-adjoint elliptic, the eigen-values of L are located in the interval [0; +1). It is therefore natural to follow the idea introduced by Varga in <ref> [52] </ref> (see also [2, 3]) and seek the Chebyshev (uniform) rational approximation to the function e z which minimizes the maximum error on the interval [0; +1). <p> We mentioned earlier that the Pade approximations provide good approximation only near the origin. Using the Chebyshev rational approximation to the function e z over the interval <ref> [0; +1) [2, 52] </ref>, it becomes possible to utilize time steps as large as our Krylov-based method allows. For example in the diagonal Chebyshev rational approximation, the infinity norm of the error over the interval [0; +1) is of the order of 10 10 as soon as reaches 10. <p> We mentioned earlier that the Pade approximations provide good approximation only near the origin. Using the Chebyshev rational approximation to the function e z over the interval [0; +1) <ref> [2, 52] </ref>, it becomes possible to utilize time steps as large as our Krylov-based method allows. For example in the diagonal Chebyshev rational approximation, the infinity norm of the error over the interval [0; +1) is of the order of 10 10 as soon as reaches 10.
Reference: [53] <author> E. L. </author> <title> Wachspress, Iterative solution of elliptic systems, </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1966. </year>
Reference-contexts: Since V m has orthonormal columns, the approximate evolution operator satisfies kV m e H m ffi V T 1 A matrix B is positive real if x T Bx &gt; 0 for any real vector x 6= 0 <ref> [53] </ref>. 12 As a result, we can state that in the case where exp (H m ffi) is evaluated exactly then kV m e H m ffi V T e (H m ffi) e (Affi) 1: If, on the other hand, exp (H m ffi) is not computed exactly, then stability
Reference: [54] <author> G. Wanner, </author> <title> Order stars and stability, in The State of the Art in Numerical Analysis, </title> <editor> A. Iserles and M. J. D. Powell, eds., </editor> <publisher> Clarendon Press, Oxford, </publisher> <year> 1987, </year> <pages> pp. 451-472. 29 </pages>
Reference-contexts: We note however that alterna-tive strategies (e.g., (- 1; -)) will frequently work better for Pade approximations, without altering the principle of the method. Note that the stability properties of the aforementioned rational approximations are discussed extensively in the literature <ref> [7, 20, 54] </ref>. A comparison between the Pade approximation and the Chebyshev rational approximation reveals the vast superiority of the latter in the context of the Krylov-based methods presented in this paper, at least for symmetric positive matrices H, and relatively large values of m.
Reference: [55] <author> D. S. Watkins and R. W. Hansonsmith, </author> <title> The numerical solution of separably stiff systems by precise partitioning, </title> <journal> ACM Trans. Math. Softw., </journal> <month> 9 (Sept. </month> <year> 1983), </year> <pages> pp. 293-301. </pages>
Reference-contexts: The use of preconditioning for extending the stability interval of explicit methods, thus bringing them closer to fully implicit methods, has been discussed in [37, 50]. Although our method works from a subspace, it does not suffer from some of the aspects of partitioning methods (see, for example, <ref> [55] </ref>). Partitioning methods rely on explicitly separating and treating differently the stiff and nonstiff parts. However, it is usually impractical to confine stiffness to a subsystem [4].
Reference: [56] <author> D. M. Young, </author> <title> The search for "high-order" parallelism for iterative sparse linear system solvers, in Parallel Supercomputing: Methods, Algorithms and Applications, </title> <editor> G. F. Carey, ed., </editor> <publisher> John Wiley & Sons, </publisher> <address> Chichester, </address> <year> 1989, </year> <pages> pp. 89-106. </pages>
Reference-contexts: need to evaluate the vector ~y, where ~y = p -(H)q -(H) 1 e 1 = q - (H) 1 p - (H)e 1 :(3.2) It has been proposed in several contexts that an efficient method for computing some rational matrix functions is to resort to their partial fraction expansions <ref> [10, 11, 13, 23, 25, 33, 44, 56] </ref>. The approach is possible since it can be proved analytically that the diagonal Pade approximation to e z has distinct poles [57]. Explicit calculations indicate that this seems to be also true for the uniform approximation.
Reference: [57] <author> V. Zakian, </author> <title> Properties of I MN and J MN approximants and applications to numerical inversion of Laplace transforms and initial value problems, </title> <journal> J. Math. Anal. Applic., </journal> <volume> 50 (1975), </volume> <pages> pp. 191-222. </pages>
Reference-contexts: The approach is possible since it can be proved analytically that the diagonal Pade approximation to e z has distinct poles <ref> [57] </ref>. Explicit calculations indicate that this seems to be also true for the uniform approximation.
References-found: 50

