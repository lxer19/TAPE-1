URL: http://www.merl.com/reports/TR96-27/TR96-27.ps.gz
Refering-URL: http://www.merl.com/reports/TR96-27/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: ACTIVE: Abstract Creative Tools for Interactive Video Environments  
Author: Chloe M. Chao Alex Pentland Joe Marks MERL 
Address: 1996 201 Broadway, Cambridge, Massachusetts 02139  
Date: October 1996  
Affiliation: Harvard Flavia Sparacino MIT Media Lab  MIT Media Lab  Mitsubishi Electric Information Technology Center America,  
Web: http://www.merl.com  
Note: MERL A MITSUBISHI ELECTRIC RESEARCH LABORATORY  Copyright c  
Pubnum: TR-96-27  
Abstract: Full-body, unencumbered, gestural interfaces offer new possibilities for computer painting tools. However, traditional painting metaphors and current gestural input technology are not well suited to one another; the user cannot be tracked with sufficient accuracy to support brush-like or pen-like painting. Our approach to this problem has been to interpose different layers of abstraction between input gestures and painting actions. We illustrate this approach with two sample applications implemented in the context of the MIT Media Lab's Interactive Video Environment. Keywords Painting tools, full-body unencumbered interfaces, art, virtual en This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Information Technology Center America; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Information Technology Center America. All rights reserved. vironments.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Myron Krueger. </author> <booktitle> Artificial reality II, </booktitle> <year> 1991. </year>
Reference-contexts: Our approach is to use a novel gestural interface in conjunction with layers of abstraction to produce 3D graphics that correspond to the user's movement in a performance space. In this summary we describe two of several applications that explore this concept. 2 Related Work Krueger's VIDEOPLACE project <ref> [1] </ref> was the first to use an unencumbered video-based interface with a large-screen display. Krueger demonstrated some artistic capabilities with interactions like finger-painting, and leaving 2D color silhouettes.
Reference: [2] <editor> Pattie Maes. </editor> <title> Artificial life meets entertainment: lifelike autonomous agents. </title> <journal> Communications of the ACM, </journal> <volume> 38(11) </volume> <pages> 108-14, </pages> <year> 1995. </year>
Reference-contexts: ACTIVE uses these coordinates as an artistic language that translates into colors and 3D shape. The vision routines and the Interactive Video Environment (IVE) used in ACTIVE have their origins in the ALIVE (Artificial Life Interactive Video Environment) project. Maes et al. <ref> [2] </ref> proposed an unencumbered full-body interaction between the user and a graphical world inhabited by autonomous agents.
Reference: [3] <author> Christa Sommerer and Laurent Mignonneau. Trans-plant, </author> <year> 1995. </year> <note> URL: http://www.mic.atr.co.jp/~christa. </note>
Reference-contexts: Krueger demonstrated some artistic capabilities with interactions like finger-painting, and leaving 2D color silhouettes. ACTIVE goes beyond this by being able to take 3D coordinates from the user and in turn interpret the user's gestures into 3D graphics. More recently the "Trans-Plant" project by Sommerer and Mignonneau <ref> [3] </ref> uses a 3D key system similar in concept to ACTIVE to allow the user to create a graphical world of plants through body movement.
Reference: [4] <author> Chris Wren, Ali Azarbayejani, Trevor Darrell, and Alex Pentland. Pfinder: </author> <title> Real-time tracking of the human body. </title> <booktitle> SPIE Photonics East 1995, </booktitle> <volume> 2615 </volume> <pages> 89-98, </pages> <year> 1995. </year>
Reference-contexts: MERL-TR-96-27 October 1996 3 Krasnodar. MERL-TR-96-27 October 1996 4 MERL-TR-96-27 October 1996 5 4 Implementation Details When executing the applications, we run two programs simultaneously: the Pfinder, a vision system for tracking and interpreting people in real-time <ref> [4] </ref>, and ACTIVE's program. The two programs communicate via a series of updates and callbacks. The Pfinder (short for Person Finder) takes care of the vision side of the application, and ACTIVE's programs continuously obtain body coordinates from the Pfinder as input.
Reference: [5] <author> Chris Wren, Flavia Sparacino, Ali J. Azarbayejani, Trevor J. Darrell, Thad E. Starner, Akira Kotani, Chloe M. Chao, Michal Hlavac, Kenneth B. Russell, and Alex P. Pentland. </author> <title> Perceptive spaces for performance and entertainment: Untethered interaction using computer vision and audition. </title> <type> Technical Report 372, </type> <institution> MIT Media Lab Vision and Modeling Group, </institution> <month> March </month> <year> 1996. </year> <month> MERL-TR-96-27 October </month> <year> 1996 </year> <month> 6 MERL-TR-96-27 October </month> <year> 1996 </year>
Reference-contexts: ACTIVE's graphics code has been integrated with music code to produce an application called "DanceSpace" <ref> [5] </ref>, with which dancers can generate music and graphics through their body movements. It employs ACTIVE's "BezierBuddy" trail-type graphics to shadow the dancer's movement throughout the performance. Possibilities for future research include augmenting ACTIVE to allow dynamic mapping of input gestures to painting actions.
References-found: 5

