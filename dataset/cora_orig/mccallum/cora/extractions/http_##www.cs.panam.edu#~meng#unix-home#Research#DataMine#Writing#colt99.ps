URL: http://www.cs.panam.edu/~meng/unix-home/Research/DataMine/Writing/colt99.ps
Refering-URL: http://www.cs.panam.edu/~meng/unix-home/Research/DataMine/Writing/
Root-URL: http://www.cs.panam.edu
Title: On Building an Intelligent WWW Search Engine with On-Line Learning Algorithms  
Author: Zhixiang Chen Xiannong Meng Binhai Zhu Richard Fowler 
Keyword: S  
Abstract: In this paper, we continue our on-line learning approach [5] towards building an intelligent WWW search engine. We establish a connection between on-line learning theory and search engine construction based on our Membership Query, Target Concept, and Ranking Assumptions. With applications of Winnow [13] and virtual-variable [15] methods we show that when d discretized attributes with a total of S different values are used to index web documents, any collection of documents represented by a disjunction of k relevant attributes can be exactly identified with at most k log 2 S membership queries, or at most 1:885k log 2 k k equivalence queries. We also show that it is possible to slightly improve the membership query bounds with randomization. In our COLT SEARCH project, we have been building an experimental search engine. So far, we have collected more than 3.9 millions urls, indexed 843,398 documents with 343 keywords, and implemented the membership query algorithms. Further implementation is undergoing. Our experimental results support the theoretical bounds on the number of queries, though it also reveals a number of problems for further study. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Angluin, </author> <title> Queries and concept learning, </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <pages> pages 319-342, </pages> <year> 1987. </year> <month> 10 </month>
Reference-contexts: A list of urls returned by the engine can be interpreted as an approximation to the collection of the desired documents. This type of scenario is essentially the same as the process of on-line learning with queries <ref> [1, 13] </ref>, where the user acts as a teacher and the engine as a learner. In the on-line learning with queries [1, 13], the goal of the learner is to find an unknown target concept chosen by the teacher. The learner can present hypotheses to the teacher. <p> This type of scenario is essentially the same as the process of on-line learning with queries <ref> [1, 13] </ref>, where the user acts as a teacher and the engine as a learner. In the on-line learning with queries [1, 13], the goal of the learner is to find an unknown target concept chosen by the teacher. The learner can present hypotheses to the teacher. <p> There are successful applications of machine learning techniques in some aspects of web mining [7] (for example, [2, 17]). But little is known in literature about the "practically tolerable query complexity" for search engines in spite of their growing popularity. Based on the on-line learning model with queries <ref> [1, 13] </ref>, we have shown in [5] that any collection of web documents represented by a disjunction (or a conjunction) of k relevant boolean-valued attributes can be exactly identified with at most k log 2 d membership queries, or with at most 1:885k log 2 d k k equivalence queries, where <p> In section 5, we describe our COLT SEARCH project that implements the obtained theoretical results on index data base we have built. We list several problems for further study. 3 2 An On-Line Learning Approach towards Web Search In the on-line learning model <ref> [1, 13] </ref> with equivalence and membership queries, the goal of a learner for a concept class C over the domain Z is to learn any unknown target concept c t 2 C that has been fixed by a teacher.
Reference: [2] <author> R. Armstrong, D. Freitag, T. Joachims, T. Mitchell, webwatcher: </author> <title> A learning apprentice for the world wide web, </title> <booktitle> Working Notes of the AAAI Spring Symposium: Information Gathering from Heterogeneous, Distributed Environments, </booktitle> <pages> pages 6-12, </pages> <year> 1995. </year>
Reference-contexts: The learning model assumes that the teacher knows the domain, the target concept, and knows how to answer membership and equivalence queries. But this may not true for a user. There are successful applications of machine learning techniques in some aspects of web mining [7] (for example, <ref> [2, 17] </ref>). But little is known in literature about the "practically tolerable query complexity" for search engines in spite of their growing popularity.
Reference: [3] <author> C.M. Bowman, P.B. Danzig, D.R. Hardy, U. Manber, and M.F. Schwartz, </author> <title> The harvest information discovery and access system, </title> <booktitle> Proceedings of the Second International World Wide web Conference, </booktitle> <pages> pages 763-771, </pages> <year> 1994. </year>
Reference: [4] <author> S. Brin, L. </author> <title> Page, The anatomy of a large-scale hypertextual web search engine, </title> <booktitle> Proceedings of the 1998 WWW Conference, </booktitle> <year> 1998. </year>
Reference: [5] <author> Z. Chen, X. Meng, R. Fowler, </author> <title> Searching the web with Queries, </title> <note> accepted for publication by Knowledge and Information Systems, </note> <year> 1999. </year>
Reference-contexts: Usually the engine returns tremendously many urls that are irrelevant, forcing the user to manually sift through the long list to locate the desired documents. In this paper, we continue our work in <ref> [5] </ref> to study the problem of building an intelligent search engine within an index database with on-line learning algorithms. <p> But little is known in literature about the "practically tolerable query complexity" for search engines in spite of their growing popularity. Based on the on-line learning model with queries [1, 13], we have shown in <ref> [5] </ref> that any collection of web documents represented by a disjunction (or a conjunction) of k relevant boolean-valued attributes can be exactly identified with at most k log 2 d membership queries, or with at most 1:885k log 2 d k k equivalence queries, where d is the total number of <p> In this paper, our major contribution are the following: (1) On the theoretical part, we extend the work in <ref> [5] </ref> to discretized attributes with application of the virtual-variable method in [15]. Assume that an index system uses d discretized attributes to index documents, and let S denote the total number of different values of those d attributes. <p> For example, more realistic membership assumption and more accurate ranking mechanism are needed. This paper is organized as follows: In section 2 we describe how to model web search with on-line learning approach. In section 3, we summary results obtained in <ref> [5] </ref> also give a new randomized membership learning algorithm. In section 4, we show several learning algorithms for discretized attributes. In section 5, we describe our COLT SEARCH project that implements the obtained theoretical results on index data base we have built. <p> Using machine learning techniques, efficient algorithms have been constructed in <ref> [5] </ref> for searching any collection of documents represented by a disjunction (or a conjunction) of k relevant boolean-valued variables. We summary two main results in [5]. Theorem 3.1 [5]. <p> Using machine learning techniques, efficient algorithms have been constructed in <ref> [5] </ref> for searching any collection of documents represented by a disjunction (or a conjunction) of k relevant boolean-valued variables. We summary two main results in [5]. Theorem 3.1 [5]. There is an algorithm that identifies any collection of documents M D [x i 1 ; : : : ; x i k ] 2 M D (k) with at most k log 2 d membership queries. <p> Using machine learning techniques, efficient algorithms have been constructed in <ref> [5] </ref> for searching any collection of documents represented by a disjunction (or a conjunction) of k relevant boolean-valued variables. We summary two main results in [5]. Theorem 3.1 [5]. There is an algorithm that identifies any collection of documents M D [x i 1 ; : : : ; x i k ] 2 M D (k) with at most k log 2 d membership queries. <p> The algorithm uses O (d) time for constructing its new query vector after a membership query. Theorem 3.2 <ref> [5] </ref>. There is an algorithm which identifies any collection M D [x 1 ; : : : ; x k ] 2 M D (k) of documents with at most k1:885 log 2 d k k equivalence queries.
Reference: [6] <author> K. Cios, W. Pedrycz, R. Swiniarski, </author> <title> Data Mining Methods for Knowledge Discovery, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1998. </year>
Reference-contexts: Unfortunately, it is not easy to find those 39 boolean attributes to build the vector space. More efforts should be made along this direction in the future. One direction we are planning to study is to use rough set theory <ref> [6] </ref> to remove redundant attributes. Another promising direction is to use a user's personal profile to project the whole vector space to a relatively smaller subspace and then restrict the search of that user within the subspace.
Reference: [7] <author> O. Etzioni, </author> <title> The World-Wide web: </title> <journal> Quagmire or gold mine? Communication of ACM, </journal> <volume> Vol. 39, </volume> <pages> pages 65-68, </pages> <year> 1997. </year>
Reference-contexts: The learning model assumes that the teacher knows the domain, the target concept, and knows how to answer membership and equivalence queries. But this may not true for a user. There are successful applications of machine learning techniques in some aspects of web mining <ref> [7] </ref> (for example, [2, 17]). But little is known in literature about the "practically tolerable query complexity" for search engines in spite of their growing popularity.
Reference: [8] <author> M. Flickner, H. Sawhney, W. Niblack, J. Ashley, Q. Huang, D. Dom, M. Gorkani, J. Hafner, D. Lee, D. Petkvic, D. Steele, and P. Yanker, </author> <title> Query by image and video content: </title> <booktitle> The qbic system, IEEE Computer, </booktitle> <pages> pages 23-30, </pages> <year> 1995. </year>
Reference-contexts: Vector space model can be used to represent not only hypertext web documents but also image web documents. In <ref> [8] </ref> a query by example model was established to search image documents. In [18, 20], an image document search engine was designed and implemented using vector presentation and relevance feedback.
Reference: [9] <author> L. Frelechoux, T. Kamba, </author> <title> An architecture for support personalized web applications, </title> <booktitle> Proceedings of the Sixth World Wide web Conference, </booktitle> <address> &lt;www.uio.no/usit/prosjekter/www/www6/ proceedings/Posters/726/POSTER726.html&gt;. </address>
Reference: [10] <author> E. Gabber, F. Gibbon, Y. Matias, and A. Mayer, </author> <title> How to make personalized web browsing simple, secure, </title> <editor> and anonymous, </editor> <publisher> &lt;lpwa.com:800/papers.html&gt; </publisher>
Reference: [11] <author> J. Kleinberg, </author> <title> Authoritive sources in a hyperlinked environment, </title> <booktitle> Proc. ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1998. </year>
Reference: [12] <author> S. Lawrence, C. L. Giles, </author> <title> Search the World Wide web, </title> <journal> Science, </journal> <volume> Vol. 280, </volume> <pages> pages 98-100, </pages> <year> 1998. </year>
Reference-contexts: One possibility is to design a search engine that can learn the ranking function and the target collection at the same time. Note again that a ranking function is just a partial order over the class of documents. It is determined by the user's preference. According to <ref> [12] </ref> there are at least 320 million indexable web documents over the Internet which is bounded by 2 29 = 536; 870; 912. The growth of the size of the Internet is rapid.
Reference: [13] <author> N. Littlestone, </author> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm, </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <pages> pages 285-318, </pages> <year> 1988. </year>
Reference-contexts: A list of urls returned by the engine can be interpreted as an approximation to the collection of the desired documents. This type of scenario is essentially the same as the process of on-line learning with queries <ref> [1, 13] </ref>, where the user acts as a teacher and the engine as a learner. In the on-line learning with queries [1, 13], the goal of the learner is to find an unknown target concept chosen by the teacher. The learner can present hypotheses to the teacher. <p> This type of scenario is essentially the same as the process of on-line learning with queries <ref> [1, 13] </ref>, where the user acts as a teacher and the engine as a learner. In the on-line learning with queries [1, 13], the goal of the learner is to find an unknown target concept chosen by the teacher. The learner can present hypotheses to the teacher. <p> There are successful applications of machine learning techniques in some aspects of web mining [7] (for example, [2, 17]). But little is known in literature about the "practically tolerable query complexity" for search engines in spite of their growing popularity. Based on the on-line learning model with queries <ref> [1, 13] </ref>, we have shown in [5] that any collection of web documents represented by a disjunction (or a conjunction) of k relevant boolean-valued attributes can be exactly identified with at most k log 2 d membership queries, or with at most 1:885k log 2 d k k equivalence queries, where <p> In section 5, we describe our COLT SEARCH project that implements the obtained theoretical results on index data base we have built. We list several problems for further study. 3 2 An On-Line Learning Approach towards Web Search In the on-line learning model <ref> [1, 13] </ref> with equivalence and membership queries, the goal of a learner for a concept class C over the domain Z is to learn any unknown target concept c t 2 C that has been fixed by a teacher. <p> The algorithms uses O (d) time for updating its data structure after a mistake. This first algorithm is obtained by binary search. The second is obtained by a careful analysis of Winnow <ref> [13] </ref>. We now show a new randomized membership learning algorithm as follows.
Reference: [14] <author> X. Meng, Z. Chen, </author> <title> Personalize web search using information on client's side, </title> <note> submitted for publication, </note> <year> 1999. </year>
Reference-contexts: Although finding a good ranking function may be as difficult as finding a good search algorithm, we believe that a combination of certain objective ranking (for 2 example, PageRank [16]) and subjective ranking (for example, personalized ranking <ref> [14] </ref>) should provide a very satisfactory ranking mechanism. In this paper, we use machine learning techniques to design intelligent search algorithms. <p> So far, we have collected more than 3.9 millions urls and, using 343 keywords we have built an index database to index 843,398 documents among the urls we collected. We also implemented a personalized ranking mechanism based on the user profile on the client side <ref> [14] </ref>. Our experimental result supports the theoretical bounds on the number of queries. It also reveals a number problems for further study. For example, more realistic membership assumption and more accurate ranking mechanism are needed. <p> We implemented a web crawler to collect web documents. So far we have collected more than 3.9 million urls. Using the list of 343 keyword in appendix B we built an index database of 843,398 documents. We also implemented a personalized ranking mechanism developed in <ref> [14] </ref>. The idea here is to implement an agent that automatically builds a users profile based on the "digital trace" left on the user's dedicated computer. The search engine then uses the profile to rank and filter document for the user.
Reference: [15] <author> W. Maass, M. Warmuth, </author> <title> Efficient Learning with virtual threshold gates, </title> <booktitle> Proceedings of the 12th International Machine Learning Conference, </booktitle> <pages> pages 378-386, </pages> <year> 1995. </year>
Reference-contexts: In this paper, our major contribution are the following: (1) On the theoretical part, we extend the work in [5] to discretized attributes with application of the virtual-variable method in <ref> [15] </ref>. Assume that an index system uses d discretized attributes to index documents, and let S denote the total number of different values of those d attributes. <p> : : ; c i k ]j1 k dg; N CDoc (k) = fN CDoc [c i 1 ; : : : ; c i l ; c j 1 ; : : : ; c j m ]jl + m = k and 1 k 2dg; As enlightened by <ref> [15] </ref>, we study how to use algorithms designed in the previous section to design our document search algorithms. We first introduce virtual boolean variables. <p> Moreover, the time complexity of the algorithm for updating its data structure after a membership query is O (d). We now follow Maass and Warmuth's virtual boolean variable method <ref> [15] </ref> to design algorithm to search documents over the d-dimensional discretized domain V . Theorem 4.8. <p> Moreover, the time complexity of the algorithm for updating its data structure after an equivalence query is O (1:885dk log 2 vdim (V ) k ). Proof. By Theorem 3.3 and the virtual-variable method in <ref> [15] </ref>. 2 The following corollaries are derived from Theorem 3.10. Corollary 4.9.
Reference: [16] <author> L. Page, S. Brin, R. Motwani, T. Winograd, </author> <title> The PageRank Citation Ranking: Bring order to the web, </title> <type> Manuscript, </type> <year> 1998. </year>
Reference-contexts: Although finding a good ranking function may be as difficult as finding a good search algorithm, we believe that a combination of certain objective ranking (for 2 example, PageRank <ref> [16] </ref>) and subjective ranking (for example, personalized ranking [14]) should provide a very satisfactory ranking mechanism. In this paper, we use machine learning techniques to design intelligent search algorithms.
Reference: [17] <author> M. Perkowitz, R. Doorenbos, O. Etzioni, D. Weld, </author> <title> Learning to understand information on the Internet: An example-based approach, </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> 8, </volume> <pages> pages 1-24, </pages> <year> 1997. </year>
Reference-contexts: The learning model assumes that the teacher knows the domain, the target concept, and knows how to answer membership and equivalence queries. But this may not true for a user. There are successful applications of machine learning techniques in some aspects of web mining [7] (for example, <ref> [2, 17] </ref>). But little is known in literature about the "practically tolerable query complexity" for search engines in spite of their growing popularity.
Reference: [18] <author> S. Sclaroff, L. Taycher, and M. La Cascia, ImageRover: </author> <title> A content-based image browser for the world wide web, </title> <booktitle> Proceedings of IEEE Workshop on Content-based Access of Image and Video Libraries, </booktitle> <year> 1997. </year> <month> 11 </month>
Reference-contexts: Vector space model can be used to represent not only hypertext web documents but also image web documents. In [8] a query by example model was established to search image documents. In <ref> [18, 20] </ref>, an image document search engine was designed and implemented using vector presentation and relevance feedback.
Reference: [19] <author> G. Salton, </author> <title> Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer, </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: We now consider how to use the on-line learning model to approach the problem of intelligent web document search. We use the vector space model <ref> [19] </ref> to represent documents. The vector space may consist of boolean vectors. It may also consist of discretized vectors, especially when image documents are considered. A target concept is a subset of the vector space. The learner is the search engine. The teacher is the user. <p> Otherwise he informs the engine one url in the top list that are not relevant, one url in the bottom list that are relevant, and thus provides counterexamples to the search engine. Remark 2.1. One must distinguish our on-line learning approach from relevance feedback in information retrieval <ref> [19] </ref>. In relevance feedback the search target is represented by a vector, while in our approach the target may be any collection of documents.
Reference: [20] <author> L. Taycher, M. La Cascia, S. Sclaroff, </author> <title> Image digestion and relevance feedback in the ImageRover WWW search engines, </title> <booktitle> Proceedings of Visual, </booktitle> <address> San Diego, </address> <year> 1997. </year>
Reference-contexts: Vector space model can be used to represent not only hypertext web documents but also image web documents. In [8] a query by example model was established to search image documents. In <ref> [18, 20] </ref>, an image document search engine was designed and implemented using vector presentation and relevance feedback.
References-found: 20

