URL: http://www.eecs.umich.edu/techreports/cse/1997/CSE-TR-334-97.ps.gz
Refering-URL: http://www.eecs.umich.edu/home/techreports/cse97.html
Root-URL: http://www.eecs.umich.edu
Title: Symbolic Performance Learning In Continuous-valued Environments  
Author: by Seth Olds Rogers Paul Nielsen, Co-Chair 
Degree: A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Science and Engineering) in The  Doctoral Committee: Associate Professor John Laird, Co-Chair Assistant  Professor Daniel Koditschek Assistant Professor Thad Polk  
Note: Research Scientist  
Date: 1997  
Affiliation: University of Michigan  
Abstract-found: 0
Intro-found: 1
Reference: <institution> 129 BIBLIOGRAPHY </institution>
Reference: [1] <author> David W. Aha, Dennis Kibler, and Marc K. Albert. </author> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6(1) </volume> <pages> 37-66, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: A disadvantage is that the algorithm is expensive in space because it has to store every point, and expensive in time for control because it has to search every point for the nearest neighbors. Kibler and Aha independently derived a similar algorithm called Instance-Based Learning <ref> [1] </ref> for symbolic classification and introduce some heuristics to improve efficiency. Their most efficient version only adds instances to memory if the classification is incorrect, so the algorithm only learns when it makes a mistake.
Reference: [2] <author> Hiroshi Akima. </author> <title> On estimating partial derivatives for bivariate interpolation of scattered data. </title> <journal> Rocky Mountain Journal of Mathematics, </journal> <volume> 14(1), </volume> <month> Winter </month> <year> 1984. </year>
Reference-contexts: There is one final non task-oriented evaluation metric. It is a comparison of the derived response surface with the "true" response surface; in effect measuring the error on all possible problems at once. It is popular in traditional adaptive control literature <ref> [2] </ref>, probably because such systems develop easily analyzable response surfaces. Although the focus of this research is on task-oriented performance, it is possible to define a methodology to generate an accurate response surface. <p> Splines are continuous because the individual functions are continuous, and the merging function between polynomials maintains continuity. By defining a spline surface from a set of data points, the resulting surface will pass through the data points and smoothly interpolate between them. Bivar <ref> [2] </ref> is a popular algorithm for fitting a spline surface to data. This algorithm is part of the NCAR mathematical algorithms library.
Reference: [3] <author> L. E. Baum and T. Petrie. </author> <title> Statistical inference for probabilistic functions of finite state Markov chains. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 41, </volume> <year> 1966. </year>
Reference-contexts: In highly nondeterministic environments, this can cause serious problems as false monotonic violations bog down the learning process. A better approach is to define a new variable n corresponding to the hidden state, and attempt to deduce its value from observations <ref> [3] </ref>. For example, when n = 1; the environment responds in one particular consistent way. If the environment begins responding inconsistently, n transitions to 2, and the agent continues learning.
Reference: [4] <author> Richard Ernest Bellman. </author> <title> Dynamic Programming. </title> <publisher> Princeton University Press, </publisher> <address> Prince-ton, NJ, </address> <year> 1957. </year>
Reference-contexts: If the agent moves the elevators too little, the agent will notice the plane dropping and try to correct, but it may try to move the ailerons less, which would reduce descent but also reduce turning. The major obstacle to success for these enhancements is "the curse of dimensionality," <ref> [4] </ref> where each additional input or output dimension causes an exponential increase in the number of possible states.
Reference: [5] <author> Scott Benson and Nils Nilsson. </author> <title> Machine Intelligence, volume 14, chapter Reacting, Planning and Learning in an Autonomous Agent. </title> <publisher> The Clarendon Press, Oxford, </publisher> <year> 1995. </year>
Reference-contexts: Since this procedure is comparatively simple for a human to observe and encode, it is most logical for the implementor to include this as domain knowledge for the agent. However, autonomous discovery of such high-level regularities, such as Benson and Nilsson's work on learning teleo-reactive trees <ref> [5] </ref>, are interesting research problems. Another possible approach is to integrate observation of human performance [52] to provide basic capabilities and a generalizing module to learn new tasks. At the lowest level, learning algorithms in continuous-valued environments need to be able to deal with unique characteristics of the environment.
Reference: [6] <author> L. Breiman, J. Friedman, R. Olshen, and C. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Monterey, CA, </address> <year> 1984. </year>
Reference-contexts: Even research with continuous sensor readings frequently selects actions from a small set, such as bang-bang control in pole balancing [35, 16, 33]. AI systems with continuous actions include regression trees <ref> [6] </ref> and ALVINN [23]. 3. The environment is dynamic. Although not all continuous-valued environments change over time independently of the agent, many realistic ones do, and these present particular problems to agents. One of the most significant problems is the need to consider time when computing a response. <p> The most direct analogues to numerical adaptive control are regression trees <ref> [6] </ref>, which are standard decision trees [46] with linear models in the leaves, and variable inequality tests in the internal nodes. For control, the decision tree classifies the current and desired states (x; y fl ) to find the correct linear model, and then computes the control from the model.
Reference: [7] <author> Rodney A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-2(1):14-23, </volume> <month> March </month> <year> 1986. </year>
Reference-contexts: Most AI systems use some representation of a goal to guide behavior, with the notable exception of subsumption architectures <ref> [7] </ref>, for example. Goals focus processing to achieve some desired situation. Explicit goal representations allow the agent to dynamically generate behavior intended to achieve the goals, giving the agent more flexibility than an agent with implicit goals in its behavior.
Reference: [8] <author> Y. Le Cun, L. D. Jackel, B. Boser, and J. S. Denker. </author> <title> Handwritten digit recognition: Applications of neural network chips and automatic learning. </title> <journal> IEEE Communications Magazine, </journal> <volume> 27(11) </volume> <pages> 41-46, </pages> <year> 1989. </year>
Reference-contexts: This work focuses on environments where variables measure different quantities and do not need to be combined to form patterns. Although numerical approaches such as neural networks have been applied to image processing <ref> [8] </ref>, the fundamental independence of the input nodes implies that the network does not explicitly generalize patterns, but instead tends to memorize specific training examples. 1.3 Representation Styles Most computational systems utilize some representation of the external environment.
Reference: [9] <author> Carl DeBoor. </author> <title> A Practical Guide to Splines. </title> <publisher> Applied mathematical sciences. Springer-Verlag, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: Statistics provides a number of models for function approximation, such as linear and polynomial functions and spline curves <ref> [9] </ref>. Generally, the approximation algorithm attempts to specify parameters for the model in order to minimize the error between each observed data point and the model m at that point. For example, a linear model in one 11 dimension is m linear (x) = ff x + fi. <p> In fact, since the PID control strategy is unable to adapt to its environment, it is a strawman measuring minimal performance competency. 6.1.2 Spline Fitting Spline curves and surfaces are smooth functions with an extremely flexible representation <ref> [9] </ref>. These are representative of the parametric function approximation approaches. The spline fit algorithm fits a spline surface to the data to explicitly represent the response surface. Spline surfaces are good at representing curved surfaces because their definition is both local and continuous.
Reference: [10] <author> Gerald F. DeJong. </author> <title> Learning to plan in continuous domains. </title> <journal> Artificial Intelligence, </journal> <volume> 65(1) </volume> <pages> 71-141, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: A particularly interesting aspect of this work is that the flight simulation domain is the same as the one used in the experiments in complex environments in Chapter 7 of this thesis. DeJong develops a hybrid system for adaptive control in complex environments <ref> [10] </ref>. The system first attempts to predict what variables will be useful in solving a problem using a symbolic qualitative physics model of the environment. Since the qualitative model is ambiguous and can generate many possible solutions, the system by default chooses the simplest explanation of the qualitative relationships.
Reference: [11] <author> Gerald F. DeJong and Raymond J. Mooney. </author> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2) </volume> <pages> 145-176, </pages> <year> 1986. </year>
Reference-contexts: The standard approach to generalization in symbolic machine learning has been to ignore irrelevant variables, either through deductive <ref> [11] </ref> or inductive [46] reasoning. SPLICE adapts this approach to continuous variables by inductively (through differential reasoning) selecting the most specific relevant resolution for the state and desired variables for a particular case, and ignoring details finer than this threshold.
Reference: [12] <author> Robert B. Doorenbos. </author> <title> Matching 100,000 learned rules. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 290-296, </pages> <year> 1993. </year>
Reference-contexts: The underlying symbolic architecture supporting this approach is Soar [29], the automatic subgoaling [27] and chunking [28] rule-based system. Many researchers have used Soar with success for symbolic capabilities such as natural language [34] and planning [49]. Soar provides practical strength with its state-of-the-art matching technology <ref> [12] </ref> and theoretical strength as a candidate Unified Theory of Cognition [38]. <p> The only possible source of slowdown in performance is the growing number of cases, represented as Soar chunks. The state-of-the-art Soar matching facility has empirically found that match cost does not suffer when learning up to 100,000 chunks <ref> [12] </ref>. Since no SPLICE agent has ever learned more than 1000 chunks in its lifetime, the number of rules is not a significant factor in execution time.
Reference: [13] <author> Richard C. Dorf. </author> <title> Modern Control Systems. </title> <publisher> Addison-Wesley, </publisher> <address> 5th edition edition, </address> <month> Jan-uary </month> <year> 1989. </year>
Reference-contexts: The following sections introduce and summarize work in numerical static control and adaptive control, and symbolic variants of these. 2.1 Control: Performance in a Continuous-valued Environ ment The most straightforward approach to control in the domains of interest in this thesis is the concern of traditional control theory <ref> [13] </ref>. In control theory, researchers first model the environment laws using equations, then study the model for stability and other properties. When the model is well understood, researchers derive control policies that guide the system to desired or stable states. <p> This state at the deadline becomes the initial state for the next iteration of the PE. Goals can remain constant (a setpoint) or vary over time (a goal trajectory) <ref> [13] </ref>. Some definitions are necessary to completely describe the Performance Element. Definition 1 The basic unit of information is the State, a set of values for variables, S = (x variable 1 ; : : : ; x variable N ), for i = 1 : : : N . <p> This sequence is similar to the Newton-Raphson root-finding algorithm (e.g., <ref> [13] </ref>, p. 193), with a slight difference in calculating the derivative. 4.5.3 Proof Given the environmental function f and the behavior of SPLICE, we will prove that SPLICE converges to a final result y such that jy y fl j *. <p> SPLICE's initial knowledge requirements are information about the sensory variables and effectors, and a qualitative model. The characteristics of the competing algorithms are discussed below. 6.1.1 PID Control PID control is a very simple non-adaptive algorithm for control <ref> [13] </ref>. PID is representative of the traditional control theory paradigm.
Reference: [14] <author> Usama M. Fayyad. </author> <title> On the Induction of Decision Trees for Multiple Concept Learning. </title> <type> PhD thesis, </type> <institution> The University of Michigan, </institution> <year> 1991. </year> <month> 130 </month>
Reference-contexts: The criteria attempt to be general enough to include many environments, but specific enough to allow a single basic performance and learning mechanism to apply to all of them. 1. Some or all environmental variables available to the agent are continuous-valued. According to standard practice in machine learning <ref> [14, 46] </ref>, "continuous-valued" does not necessary imply real numbers. Continuous-valued variables can take on any element of a many-valued, totally-ordered set, such as the integers or natural numbers. Nominal variables take values from an unordered set, and there are many symbolic approaches for environments for these variables. <p> A straightforward approach would be to assign a set of "threshold values" to each variable, and classify current state variable values and current desired values according to the intervals in which they fall (e.g., <ref> [14] </ref>). The problem with this approach is that the threshold values themselves are very hard to extract from the environment through interaction. The most successful results [14] come from batch analysis of data, which is not tractable for incremental, integrated learning and performance systems. <p> "threshold values" to each variable, and classify current state variable values and current desired values according to the intervals in which they fall (e.g., <ref> [14] </ref>). The problem with this approach is that the threshold values themselves are very hard to extract from the environment through interaction. The most successful results [14] come from batch analysis of data, which is not tractable for incremental, integrated learning and performance systems. An additional problem is a lack of structure in the threshold set. An incremental algorithm must expect to only provide general answers at first, and gradually become more specific and accurate.
Reference: [15] <author> Kenneth D. Forbus, Paul E. Nielsen, and Boi Faltings. </author> <title> Qualitative spatial reasoning: The CLOCK project. </title> <journal> Artificial Intelligence, </journal> <volume> 51(1-3):417-471, </volume> <month> October </month> <year> 1991. </year>
Reference-contexts: Soar provides practical strength with its state-of-the-art matching technology [12] and theoretical strength as a candidate Unified Theory of Cognition [38]. The following sections 1 Thanks to Barney the Dinosaur for chapter quotes. 2 The Poverty Conjecture <ref> [15] </ref> is a theoretical refutation of the PSSH in continuous environments, claiming that spatial reasoning requires some quantitative component. 1 Agent State Action Control Sensing ENVIRONMENT Learning define more clearly the relationship between an agent and its environment, the nature of the environments covered in this thesis, and properties of the
Reference: [16] <author> K. Furuta, T. Ochiai, and N. Ono. </author> <title> Attitude control of a triple inverted pendulum. </title> <journal> International Journal of Control, </journal> <volume> 39(6) </volume> <pages> 1351-1365, </pages> <year> 1984. </year>
Reference-contexts: Continuous-valued effectors are very common in real-world environments, such as pressures on control pedals or chemical concentrations, but less common for AI research. Even research with continuous sensor readings frequently selects actions from a small set, such as bang-bang control in pole balancing <ref> [35, 16, 33] </ref>. AI systems with continuous actions include regression trees [6] and ALVINN [23]. 3. The environment is dynamic. Although not all continuous-valued environments change over time independently of the agent, many realistic ones do, and these present particular problems to agents.
Reference: [17] <author> Robert Gray. </author> <title> Source Coding Theory. </title> <booktitle> The Kluwer international series in engineering and computer science. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: SPLICE begins with the maximally general partition and subdivides based on feedback from the environment. Since SPLICE creates new cases local to where the model from the current case database is incorrect, it bears some resemblance to compression in coding theory <ref> [17] </ref>. This correspondence may merit further investigation. 5. The learning algorithm is guaranteed to converge. Given certain environment restrictions, SPLICE operates much like an iterative Newton-Raphson method. It is guaranteed to converge to within * of a desired value y fl after some number of iterations on the same problem.
Reference: [18] <author> Peter E. Hart. </author> <title> The condensed nearest neighbor rule. </title> <journal> Transactions on Information Theory, </journal> <volume> IT-14:515-516, </volume> <year> 1967. </year>
Reference-contexts: These algorithms are considered more flexible because they can have a higher degree of self-organization. Hart described an early example of a non-parametric method with the Nearest-Neighbor algorithm <ref> [18] </ref>. This algorithm simply recorded data as experienced. When the algorithm was required to issue a control, it found the k nearest points to the query (x; y fl ) and performed a weighted average to find the correct control. <p> This includes remembering the problems it has "accidentally" solved in case they are useful in the future. This is the purpose of the "False Sense of Accomplishment" case described in Chapter 4. For simple algorithms such as Nearest Neighbor <ref> [18] </ref>, this is implicit because all data points reside in the same memory, and new problems search the entire memory for the nearest points. For agents living in environments where long life is necessary, this algorithm becomes inefficient.
Reference: [19] <author> Peter M. Hastings. </author> <title> The Soar coloring book: A tutorial for soar. </title> <note> http://ai.eecs.umich.edu/soar/tutorial, 1996. </note>
Reference-contexts: Further information about data-chunking is in Unified Theories of Cognition [38], for example. The on-line Soar Tutorial <ref> [19] </ref> contains additional practical information, including a version of this Appendix and code. B.1 Data-chunking in General A persistent challenge to Soar agents is the need to remember specific symbols for later use.
Reference: [20] <author> Michael Hucka. </author> <title> The Soar development environment. </title> <type> Unpublished manuscript, </type> <month> April </month> <year> 1994. </year>
Reference-contexts: It greatly reduced development time for tasks appropriate for its representation language, but proved to require too much editing of raw production rules for much time reduction for general Soar programming. SDE A general effort for Soar editing and debugging, SDE <ref> [20] </ref> (Soar Development Environment) included a flexible function for interactive creation of Soar rules from templates. The user would define a template of one or more partially-instantiated Soar productions.
Reference: [21] <author> Scott B. Huffman. </author> <title> Instructable autonomous agents. </title> <type> PhD thesis, </type> <institution> University of Michigan, Dept. of Electrical Engineering and Computer Science, </institution> <year> 1993. </year> <month> Forthcoming. </month>
Reference-contexts: However, for complex domains, it may require many observations to develop a complex and correct qualitative model. Since a qualitative model is conceptually simple and understandable, it may be more effective for an instructor to directly teach the model using natural language. Instructo-Soar <ref> [21] </ref> is a Soar agent with this capability. If the agent is able to determine that the domain model is incorrect, it will need to revise itself. IMPROV [44] is a Soar agent with the capability to detect knowledge errors and correct them through experiments.
Reference: [22] <author> Ramesh Jain, Rangachar Kasturi, and Brian Schunck. </author> <title> Machine Vision. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1995. </year>
Reference-contexts: Partitioning the space of possible problems into cases of widely varying generality is a novel and compact representation for control and function approximation. Although representations like quad-trees and oct-trees <ref> [22] </ref> are common for spatial occupation, most function approximation algorithms that subdivide the domain space use similar-sized partitions, which is inefficient for some functions. SPLICE begins with the maximally general partition and subdivides based on feedback from the environment.
Reference: [23] <author> Todd Jochem and Dean Pomerleau. </author> <title> Life in the fast lane: the evolution of an adaptive vehicle control system. </title> <journal> AI Magazine, </journal> <volume> 17(2) </volume> <pages> 11-50, </pages> <month> Summer </month> <year> 1996. </year>
Reference-contexts: Although aspects of static, nominal environments still provide challenges today, there has been a shift in focus toward investigating dynamic, continuous environments, such as driving <ref> [23] </ref>, flying [52], robot navigation [25], or juggling [53]. In the process, many of the new paradigms developed for continuous environments, such as neural networks, reinforcement learning, and Bayesian nets, lost touch with their symbolic relatives. <p> Even research with continuous sensor readings frequently selects actions from a small set, such as bang-bang control in pole balancing [35, 16, 33]. AI systems with continuous actions include regression trees [6] and ALVINN <ref> [23] </ref>. 3. The environment is dynamic. Although not all continuous-valued environments change over time independently of the agent, many realistic ones do, and these present particular problems to agents. One of the most significant problems is the need to consider time when computing a response. <p> Although artificial neural networks are popular for a wide range of machine learning tasks, their continuous nature makes them particularly appropriate for control in a continuous environment. One successful example of using neural networks to control a vehicle is ALVINN <ref> [23] </ref>. However, this work and others show that it still takes considerable effort to successfully train neural networks in very complex environments. The above function approximation algorithms are considered parametric methods because a fixed number of parameters for the model are adapted to fit the data. <p> In these cases, the agent must acquire a domain model by some method. Although there is much previous work on generating a control strategy without using a domain model <ref> [55, 23] </ref>, there is little addressing the problem of finding a qualitative model for a domain. For simple domains like the artificial ones presented here, two observations are all that is necessary to define whether the relationship between the single control and single desired variable is positive or negative.
Reference: [24] <author> Leslie Pack Kaelbling, Michael L. Littman, and Andrew W. Moore. </author> <title> Reinforcement learning: A survey. </title> <journal> Jounal of Artificial Intelligence Research, </journal> <volume> 4 </volume> <pages> 237-285, </pages> <year> 1996. </year> <note> http://www.cs.washington.edu/research/jair/abstracts/kaelbling96a.html. </note>
Reference-contexts: RFWR only modifies a receptive field if the field's model is inconsistent with a data point. This algorithm is covered in more detail in Chapter 6. Schaal and Atkeson use yet another non-parametric method to estimate the value function for reinforcement learning <ref> [24] </ref>, where 12 they train a robot to perform devil-sticking [53]. 2.4 Symbolic Adaptive Control Finally, there are symbolic and hybrid systems which perform adaptive control.
Reference: [25] <author> David Kortenkamp, Marcus Huber, Frank Koss, William Belding, Jaeho Lee, Annie Wu, Clint Bidlack, and Seth Rogers. </author> <title> Mobile robot exploration and navigation of indoor spaces using sonar and vision. </title> <booktitle> In Proceedings of the AIAA/NASA Conference on Intelligent Robots in Field, Factory, Service, and Space (CIRFFSS 94), </booktitle> <pages> pages 509-519, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Although aspects of static, nominal environments still provide challenges today, there has been a shift in focus toward investigating dynamic, continuous environments, such as driving [23], flying [52], robot navigation <ref> [25] </ref>, or juggling [53]. In the process, many of the new paradigms developed for continuous environments, such as neural networks, reinforcement learning, and Bayesian nets, lost touch with their symbolic relatives.
Reference: [26] <author> C. M. Krishna. </author> <title> On the design and analysis of real-time computers. </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <address> Ann Arbor, MI, </address> <year> 1984. </year>
Reference-contexts: However, there are two intuitive procedures for changing goals. The first is to only allow one cycle for each goal. This corresponds to a hard real-time system <ref> [26] </ref> which must go on to the next goal by the deadline, whether the current goal is achieved or not. The logical evaluation metric for this procedure is to measure the difference between the final state and the desired state.
Reference: [27] <author> John E. Laird. </author> <title> Universal Subgoaling. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Carnegie-Mellon University, </institution> <year> 1983. </year>
Reference-contexts: Besides merely performing in continuous environments, a secondary research goal is to show that symbolic adaptive control is comparable to traditional numerical approaches along a number of evaluation dimensions. The underlying symbolic architecture supporting this approach is Soar [29], the automatic subgoaling <ref> [27] </ref> and chunking [28] rule-based system. Many researchers have used Soar with success for symbolic capabilities such as natural language [34] and planning [49]. Soar provides practical strength with its state-of-the-art matching technology [12] and theoretical strength as a candidate Unified Theory of Cognition [38].
Reference: [28] <author> John E. Laird, Allen Newell, and Paul S. Rosenbloom. </author> <title> Chunking in Soar: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 11-46, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: Besides merely performing in continuous environments, a secondary research goal is to show that symbolic adaptive control is comparable to traditional numerical approaches along a number of evaluation dimensions. The underlying symbolic architecture supporting this approach is Soar [29], the automatic subgoaling [27] and chunking <ref> [28] </ref> rule-based system. Many researchers have used Soar with success for symbolic capabilities such as natural language [34] and planning [49]. Soar provides practical strength with its state-of-the-art matching technology [12] and theoretical strength as a candidate Unified Theory of Cognition [38].
Reference: [29] <author> John E. Laird, Allen Newell, and Paul S. Rosenbloom. </author> <title> Soar: An architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33(1) </volume> <pages> 1-64, </pages> <year> 1987. </year>
Reference-contexts: Moreover, it brings the PSSH back into relevance for continuous environments. Besides merely performing in continuous environments, a secondary research goal is to show that symbolic adaptive control is comparable to traditional numerical approaches along a number of evaluation dimensions. The underlying symbolic architecture supporting this approach is Soar <ref> [29] </ref>, the automatic subgoaling [27] and chunking [28] rule-based system. Many researchers have used Soar with success for symbolic capabilities such as natural language [34] and planning [49]. Soar provides practical strength with its state-of-the-art matching technology [12] and theoretical strength as a candidate Unified Theory of Cognition [38]. <p> In many systems that perform tests of differing generality, such as decision trees [46], more specific cases match slower because the algorithm requires more tests. However, the SPLICE implementation is based on SCA [36] in Soar <ref> [29] </ref>. In SCA, more specific matches are actually faster because less abstraction is necessary. The only possible source of slowdown in performance is the growing number of cases, represented as Soar chunks.
Reference: [30] <author> P. Langley, G. L. Bradshaw, and H. A. Simon. BACON.5: </author> <title> The discovery of conservation laws. </title> <booktitle> In Proceedings IJCAI-81, </booktitle> <year> 1981. </year>
Reference-contexts: A related problem to continuous control is scientific discovery of natural laws [31]. These systems gather data from experiments and attempt discover regularities. BACON <ref> [30] </ref> is a well-known example. BACON replicates the discoveries of early chemists by systematically varying conditions in experiments. There are two major differences between scientific discovery and adaptive control.
Reference: [31] <author> P. Langley, H. A. Simon, G. L. Bradshaw, and J. M. Zytkow. </author> <title> Scientific Discovery. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year> <month> 131 </month>
Reference-contexts: However, using numerical processing for performance and learning after computing the qualitative model prevents the system from fully taking advantage of the symbolic capabilities discussed in Chapter 1. A related problem to continuous control is scientific discovery of natural laws <ref> [31] </ref>. These systems gather data from experiments and attempt discover regularities. BACON [30] is a well-known example. BACON replicates the discoveries of early chemists by systematically varying conditions in experiments. There are two major differences between scientific discovery and adaptive control.
Reference: [32] <author> Pat Langley. </author> <title> Relevance and insight in experimental studies. </title> <journal> IEEE Expert, </journal> <pages> pages 11-12, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: A common way <ref> [32] </ref> to demonstrate the effect of some capability is to remove the capability and compare performance of this lesion again the intact system.
Reference: [33] <author> Pat Langley. </author> <title> Learning to sense selectively in physical domains. </title> <booktitle> In Proceedings of the First International Conference on Autonomous Agents, </booktitle> <year> 1997. </year> <month> ftp://robotics.stanford.edu/pub/langley/sense.aa97.ps.gz. </month>
Reference-contexts: Continuous-valued effectors are very common in real-world environments, such as pressures on control pedals or chemical concentrations, but less common for AI research. Even research with continuous sensor readings frequently selects actions from a small set, such as bang-bang control in pole balancing <ref> [35, 16, 33] </ref>. AI systems with continuous actions include regression trees [6] and ALVINN [23]. 3. The environment is dynamic. Although not all continuous-valued environments change over time independently of the agent, many realistic ones do, and these present particular problems to agents.
Reference: [34] <author> Jill Fain Lehman, Richard L. Lewis, and Allen Newell. </author> <title> Natural language comprehension in Soar: Spring 1991. </title> <type> Technical Report CMU-CS-91-117, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: The underlying symbolic architecture supporting this approach is Soar [29], the automatic subgoaling [27] and chunking [28] rule-based system. Many researchers have used Soar with success for symbolic capabilities such as natural language <ref> [34] </ref> and planning [49]. Soar provides practical strength with its state-of-the-art matching technology [12] and theoretical strength as a candidate Unified Theory of Cognition [38].
Reference: [35] <author> Donald Michie and R. A. Chambers. </author> <booktitle> Machine Intelligence 2, chapter BOXES: An Experiment in Adaptive Control, </booktitle> <pages> pages 125-133. </pages> <address> Elsevier/North-Holland, Amsterdam, London, New York, </address> <year> 1968. </year>
Reference-contexts: Continuous-valued effectors are very common in real-world environments, such as pressures on control pedals or chemical concentrations, but less common for AI research. Even research with continuous sensor readings frequently selects actions from a small set, such as bang-bang control in pole balancing <ref> [35, 16, 33] </ref>. AI systems with continuous actions include regression trees [6] and ALVINN [23]. 3. The environment is dynamic. Although not all continuous-valued environments change over time independently of the agent, many realistic ones do, and these present particular problems to agents.
Reference: [36] <author> Craig M. Miller. </author> <title> A model of concept acquisition in the context of a unified theory of cognition. </title> <type> PhD thesis, </type> <institution> The University of Michigan, Dept. of Computer Science and Electrical Engineering, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: All three cases match the initial state, but A and B are more specific than C, so M I = fA; Bg. However, since the desired generalization for B is more specific than A, the best match M = B. SPLICE uses the SCA inductive learning technique <ref> [36] </ref> to implement case retrieval. SCA matches cases in parallel by first checking if any maximally specific initial state matches the current initial state. Next SCA generalizes the current initial state one step and again checks for matches. <p> In many systems that perform tests of differing generality, such as decision trees [46], more specific cases match slower because the algorithm requires more tests. However, the SPLICE implementation is based on SCA <ref> [36] </ref> in Soar [29]. In SCA, more specific matches are actually faster because less abstraction is necessary. The only possible source of slowdown in performance is the growing number of cases, represented as Soar chunks.
Reference: [37] <author> Allen Newell. </author> <title> Physical symbol systems. </title> <journal> Cognitive Science, </journal> <volume> 4 </volume> <pages> 135-183, </pages> <year> 1980. </year>
Reference-contexts: Researchers found symbol processing systems effective in solving problems in these environments (e.g., [39]), and went so far as to formulate the Physical Symbol System Hypothesis (PSSH) <ref> [37] </ref>, which states that all intelligent behavior can originate from a symbol system. Although aspects of static, nominal environments still provide challenges today, there has been a shift in focus toward investigating dynamic, continuous environments, such as driving [23], flying [52], robot navigation [25], or juggling [53].
Reference: [38] <author> Allen Newell. </author> <title> Unified Theories of Cognition. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: Many researchers have used Soar with success for symbolic capabilities such as natural language [34] and planning [49]. Soar provides practical strength with its state-of-the-art matching technology [12] and theoretical strength as a candidate Unified Theory of Cognition <ref> [38] </ref>. <p> Further information about data-chunking is in Unified Theories of Cognition <ref> [38] </ref>, for example. The on-line Soar Tutorial [19] contains additional practical information, including a version of this Appendix and code. B.1 Data-chunking in General A persistent challenge to Soar agents is the need to remember specific symbols for later use. <p> This leads to large repetitive parts of rules. Even worse, when a data structure changes, every rule referencing the data structure must be changed. Also, the limited number of knowledge types defined by the Problem Space Computational Model <ref> [38] </ref> implies that productions of the same type share some structure. Creating a more compact knowledge representation that can easily adjust to new data structures has been a common factor in improving Soar's usability.
Reference: [39] <author> Allen Newell and Herbert A. Simon. </author> <title> GPS: A program that simulates human thought. </title> <editor> In E. A. Feigenbaum and J. Feldman, editors, </editor> <booktitle> Computers and Thought, </booktitle> <pages> pages 279-293. </pages> <editor> R. Oldenbourg KG., </editor> <year> 1963. </year>
Reference-contexts: Introduction Barney is a dinosaur from our imagination . . . 1 The field of artificial intelligence has made great advances since its inception, but until recently progress has been limited to largely static, nominal environments. Researchers found symbol processing systems effective in solving problems in these environments (e.g., <ref> [39] </ref>), and went so far as to formulate the Physical Symbol System Hypothesis (PSSH) [37], which states that all intelligent behavior can originate from a symbol system.
Reference: [40] <author> John K. Ousterhout. </author> <title> Tcl and the Tk toolkit. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1994. </year>
Reference-contexts: The SPLICE agent was written in Soar, and the environment was simulated in Tcl <ref> [40] </ref>. The Soar agent included special output productions to change Tcl variables acting as controls, and the Tcl environment updated itself after every Soar primitive sequential control decision. Part of the updating included inserting the current values of sensed variables into Soar's working memory. <p> Creating a more compact knowledge representation that can easily adjust to new data structures has been a common factor in improving Soar's usability. The integration of Soar with the Tcl <ref> [40] </ref> macro language gives some additional flexibility in defining knowledge. This appendix will present some past approaches to adding another layer of knowledge representation and introduce the approach used in this thesis. C.1 Off-line Approaches One set of approaches defines a separate knowledge representation and "compiles" it into Soar productions.
Reference: [41] <author> Douglas J. Pearson. </author> <title> Tcl variable ideas. soar-group@cs.cmu.edu mailing list, </title> <month> June </month> <year> 1995. </year>
Reference-contexts: Defining a Soar production is now a Tcl procedure that accepts variable substitution, so it can now be automated through Tcl control. The approach advocated by Doug Pearson <ref> [41] </ref> is to create partially-instantiated productions in files. The Tcl procedure loading productions would set Tcl variables and load a template file, so the template is instantiated with the current variable values. This is "load-time" template expansion because the instantiated productions are created as they are being loaded.
Reference: [42] <author> Douglas J. Pearson. </author> <title> [new] data-chunking example. </title> <address> http://ai.eecs.umich.edu/- people/douglasp/soar/data-chunk-read-me.html, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: Since exploiting search control is not a theoretically satisfying solution, and since chunks may include search control in future versions of Soar, Rick Lewis and others have developed a new approach, as documented Doug Pearson's web site <ref> [42] </ref>. Although this thesis used the normal data-chunking approach, the problems and solutions in the next section are equally valid for data chunking without search control. B.2 Data-chunking Numbers SPLICE needs to recall numbers for a variety of purposes.
Reference: [43] <author> Douglas J. Pearson, Scott B. Huffman, Mark B. Willis, John E. Laird, and Randolph M. Jones. </author> <title> A symbolic solution to intelligent real-time control. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 11 </volume> <pages> 279-291, </pages> <year> 1993. </year> <note> http://ai.eecs.umich.edu/people/douglasp/pubs/ robojournal.html. </note>
Reference-contexts: the algorithm developed in this research and other control algorithms. 9 Goal State Subgoal State Subgoal State Goal Regions State Regions Goal Regions State Regions Goal Regions State Regions ENVIRONMENT Compare Goal and State Compare Goal and State Compare Goal and State Automatic Subgoal 2.2 Symbolic Control The Air-Soar system <ref> [43] </ref> is an example of a symbolic system for control. Air-Soar acts as a pilot in a simulated airplane. The environment fits the definition of continuous because its sensed variables and effectors are continuous-valued, and the domain is dynamic. <p> Possible actions are moving the mouse to control the elevators and ailerons, and using the keyboard to control the throttle and flaps. There are additional high-level commands 86 developed for other airplane control research such as the Air-Soar system <ref> [43] </ref> presented in Chapter 2, but these were not used for this research. The visual interface for the flight simulator consists of a cockpit and rendered exterior view. The simulator regularly accepts commands from its communication channel or the user and updates the state in quasi real-time.
Reference: [44] <author> Douglas J. Pearson and John E. Laird. </author> <title> Toward incremental knowledge correction for agents in complex environments. </title> <booktitle> In Machine Intelligence, </booktitle> <volume> volume 15. </volume> <publisher> Oxford University Press, </publisher> <year> 1996. </year> <note> http://ai.eecs.umich.edu/people/douglasp/pubs/machine-int.html. </note>
Reference-contexts: There may also be an additional goal relating to fuel expenditure which may require learning at the planning level. The IMPROV system <ref> [44] </ref> is a recent attempt to autonomously revise planning knowledge in Soar. The agent can also utilize this framework to experimentally optimize its behavior. For example, it can search for the fastest possible time to move a certain distance without a net speed change. <p> Instructo-Soar [21] is a Soar agent with this capability. If the agent is able to determine that the domain model is incorrect, it will need to revise itself. IMPROV <ref> [44] </ref> is a Soar agent with the capability to detect knowledge errors and correct them through experiments. <p> Unlike the original SCA implementation, generalization does not necessarily follow a prescribed ordering, but matches any collection of regions at the given level of generality. This is an enhancement to SCA most useful for classifying multiple objects presented in 105 IMPROV <ref> [44] </ref>, another inductive learning system in Soar. The qualitative reasoner needs to explicitly copy numbers to avoid the data-chunking problem, as described in Appendix B. Chunks 1 and 2 identify speed and pedal variables as relevant for future learning.
Reference: [45] <editor> Garret Pelton. </editor> <title> Generating constants. </title> <publisher> ftp://centro.soar.cs.cmu.edu/afs/cs/- project/soar/member/gap/doc/generating-constants.Z. </publisher>
Reference-contexts: This could work by generating an impasse whenever a variable cannot be classified to its most specific region. The subgoal would determine the correct region for the most general unclassified level, and the result would create a chunk identical to the automatically-generated region classification rules now used <ref> [45] </ref>. This enhancement is not included in SPLICE at this time because we judged action learning to be a more interesting research problem than region learning.
Reference: [46] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: Since incremental architectures such as neural networks [50] and Soar do not slow down as they incorporate experiences, they are the only systems practical for agents with a long life expectancy in time-sensitive environments. In contrast, batch-style (non-O (1)) learning algorithms such as ID3 <ref> [46] </ref> perform best with either a upper bound on the number of experiences expected or unlimited computation time. <p> The criteria attempt to be general enough to include many environments, but specific enough to allow a single basic performance and learning mechanism to apply to all of them. 1. Some or all environmental variables available to the agent are continuous-valued. According to standard practice in machine learning <ref> [14, 46] </ref>, "continuous-valued" does not necessary imply real numbers. Continuous-valued variables can take on any element of a many-valued, totally-ordered set, such as the integers or natural numbers. Nominal variables take values from an unordered set, and there are many symbolic approaches for environments for these variables. <p> The most direct analogues to numerical adaptive control are regression trees [6], which are standard decision trees <ref> [46] </ref> with linear models in the leaves, and variable inequality tests in the internal nodes. For control, the decision tree classifies the current and desired states (x; y fl ) to find the correct linear model, and then computes the control from the model. <p> Learning finally halts when SPLICE stops seeing new data points, but performance can continue as long as the user presents goals to the PE. In many systems that perform tests of differing generality, such as decision trees <ref> [46] </ref>, more specific cases match slower because the algorithm requires more tests. However, the SPLICE implementation is based on SCA [36] in Soar [29]. In SCA, more specific matches are actually faster because less abstraction is necessary. <p> The standard approach to generalization in symbolic machine learning has been to ignore irrelevant variables, either through deductive [11] or inductive <ref> [46] </ref> reasoning. SPLICE adapts this approach to continuous variables by inductively (through differential reasoning) selecting the most specific relevant resolution for the state and desired variables for a particular case, and ignoring details finer than this threshold.
Reference: [47] <author> Alfred A. Rizzi. </author> <title> Dexterous Robot Manipulation. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <year> 1994. </year>
Reference-contexts: The difficulty with this solution is that the inverse does not always exist for all values of (x; y fl ), or it may be difficult to compute. An impressive example of a traditional control system is the Bueggler <ref> [47] </ref>. This is a robotic actuated paddle combined with video cameras for sensing. It can simultaneously bounce two table tennis balls in the air at a specified height. The control laws are robust to small disturbances and provably correct.
Reference: [48] <author> Seth O. Rogers. Air-Soar documentation. </author> <note> http://ai.eecs.umich.edu/air-soar, 1993. </note>
Reference-contexts: The visual interface for the flight simulator consists of a cockpit and rendered exterior view. The simulator regularly accepts commands from its communication channel or the user and updates the state in quasi real-time. Figure 7.1 displays the flight simulator screen. The World Wide Web site <ref> [48] </ref> contains more complete information concerning the SGI flight simulator. 7.2 Controlling Speed The simplest goals to achieve in this domain are the same as the artificial driving domains: speed. The first experiments with the flight simulator were designed to demonstrate that SPLICE can learn realistic, complex response functions.
Reference: [49] <author> Paul S. Rosenbloom, SooWoon Lee, and Amy Unruh. </author> <title> Responding to impasses in memory-driven behavior: A framework for planning. In Proceedings of the Workshop on Innovative Approaches to Planning, Scheduling, </title> <journal> and Control, </journal> <year> 1990. </year>
Reference-contexts: The underlying symbolic architecture supporting this approach is Soar [29], the automatic subgoaling [27] and chunking [28] rule-based system. Many researchers have used Soar with success for symbolic capabilities such as natural language [34] and planning <ref> [49] </ref>. Soar provides practical strength with its state-of-the-art matching technology [12] and theoretical strength as a candidate Unified Theory of Cognition [38].
Reference: [50] <editor> D. E. Rumelhart and J. L. McClelland, editors. </editor> <booktitle> Parallel Distributed Processing. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year> <title> In two volumes. </title>
Reference-contexts: A learning and retrieval system which is O (1) is defined to be incremental. Since incremental architectures such as neural networks <ref> [50] </ref> and Soar do not slow down as they incorporate experiences, they are the only systems practical for agents with a long life expectancy in time-sensitive environments. <p> Numerical representation of nominal values has some advantages over symbolic representation, because continuous quantities allow infinite shades of meaning and the potential to combine elements to create new atomic elements, instead of just additional structure. Numerical methods such as Neural Networks <ref> [50] </ref> commonly process nominal data. Symbolic representations naturally represent nominal environmental variables, but they can also represent continuous variables. The necessary encoding function is to convert quantities to symbols using inequalities or some other qualitative measure. The decoding function re-quantizes symbols by reversing the encoding function.
Reference: [51] <author> Stuart Russell and Peter Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1995. </year>
Reference-contexts: This section also provides a road map to the remainder of this dissertation. 1.1 Agent-based Interaction A common definition of artificial intelligence is "the study of rational action <ref> [51] </ref>." Action implies that there is some entity, called an agent, capable of affecting some external system, called an environment. Rational implies that this agent's actions are directed toward achieving its goals given its current knowledge.
Reference: [52] <author> Claude Sammut, Scott Hurst, Dana Kedzier, and Donald Michie. </author> <title> Learning to fly. </title> <booktitle> In Proceedings of the Ninth International Conference on Machine Learning, </booktitle> <pages> pages 385-393, </pages> <year> 1992. </year>
Reference-contexts: Although aspects of static, nominal environments still provide challenges today, there has been a shift in focus toward investigating dynamic, continuous environments, such as driving [23], flying <ref> [52] </ref>, robot navigation [25], or juggling [53]. In the process, many of the new paradigms developed for continuous environments, such as neural networks, reinforcement learning, and Bayesian nets, lost touch with their symbolic relatives. <p> For control, the decision tree classifies the current and desired states (x; y fl ) to find the correct linear model, and then computes the control from the model. Sammut et al. describe a specific application which uses decision trees for control <ref> [52] </ref>. This system collects a large amount of human data from flying a plane in a flight simulator, and uses the data to generate a decision tree. <p> However, autonomous discovery of such high-level regularities, such as Benson and Nilsson's work on learning teleo-reactive trees [5], are interesting research problems. Another possible approach is to integrate observation of human performance <ref> [52] </ref> to provide basic capabilities and a generalizing module to learn new tasks. At the lowest level, learning algorithms in continuous-valued environments need to be able to deal with unique characteristics of the environment. For example, SPLICE needs a more sophisticated mechanism of handling nondeterminism.
Reference: [53] <author> Stefan Schaal and Christopher G. Atkeson. </author> <title> Robot juggling: Implementation of memory-based learning. </title> <journal> IEEE Control Systems Magazine, </journal> <volume> 14(1) </volume> <pages> 57-71, </pages> <month> February </month> <year> 1994. </year> <month> ftp://ftp.cc.gatech.edu/pub/people/sschaal/schaal-CMS94.html. </month>
Reference-contexts: Although aspects of static, nominal environments still provide challenges today, there has been a shift in focus toward investigating dynamic, continuous environments, such as driving [23], flying [52], robot navigation [25], or juggling <ref> [53] </ref>. In the process, many of the new paradigms developed for continuous environments, such as neural networks, reinforcement learning, and Bayesian nets, lost touch with their symbolic relatives. <p> This algorithm is covered in more detail in Chapter 6. Schaal and Atkeson use yet another non-parametric method to estimate the value function for reinforcement learning [24], where 12 they train a robot to perform devil-sticking <ref> [53] </ref>. 2.4 Symbolic Adaptive Control Finally, there are symbolic and hybrid systems which perform adaptive control. The most direct analogues to numerical adaptive control are regression trees [6], which are standard decision trees [46] with linear models in the leaves, and variable inequality tests in the internal nodes.
Reference: [54] <author> Stefan Schaal and Christopher G. Atkeson. </author> <title> Robot learning by nonparametric regression. </title> <booktitle> In Proceedings of the IEEE/RSJ/GI International Conference on Intelligent Robots and Systems, </booktitle> <volume> volume 1, </volume> <pages> pages 478-485, </pages> <year> 1994. </year> <note> ftp://ftp.cc.gatech.edu/ pub/people/sschaal/schaal-IROS94.html. </note>
Reference-contexts: The above function approximation algorithms are considered parametric methods because a fixed number of parameters for the model are adapted to fit the data. Since the model itself is fixed, the possible domains for a particular model is limited. A second class of function approximation algorithms are non-parametric algorithms <ref> [54] </ref>, where the data defining the model are not fixed in advanced. These algorithms are considered more flexible because they can have a higher degree of self-organization. Hart described an early example of a non-parametric method with the Nearest-Neighbor algorithm [18]. This algorithm simply recorded data as experienced. <p> The difference is that the total response function is distributed among an arbitrary number of cases, instead of defined by a fixed set of parameters. SPLICE is closer to nonparametric techniques <ref> [54] </ref> that build a number of local models instead of a single monolithic global model.
Reference: [55] <author> Stefan Schaal and Christopher G. Atkeson. </author> <title> From isolation to cooperation: An alternative view of a system of experts. </title> <editor> In D. S. Touretzky, M. C. Moser, and M. E. Hanselmo, editors, </editor> <booktitle> Advanced in Neural Information Processing Systems 8, </booktitle> <pages> pages 605-611, </pages> <address> Cam-bridge, MA, 1996. </address> <publisher> MIT Press. ftp://ftp.cc.gatech.edu/pub/people/sschaal/ schaal-NIPS95.html. </publisher>
Reference-contexts: Their most efficient version only adds instances to memory if the classification is incorrect, so the algorithm only learns when it makes a mistake. Schaal and Atkeson extend this concept to continuous domains with Receptive Field Weighted Regression (RFWR) <ref> [55] </ref>. They collect data in receptive fields, and each receptive field contains a linear model of its data. RFWR only modifies a receptive field if the field's model is inconsistent with a data point. This algorithm is covered in more detail in Chapter 6. <p> Overall splines, like many parametric functions, are good and efficient at fitting data that matches their assumptions, but can fail dramatically if their assumptions are violated. 6.1.3 Receptive Field Weighted Regression Receptive Field Weighted Regression is a new local function approximation technique <ref> [55] </ref>. It derives from research on non-parametric modeling methods. The basic data structure of RFWR is the receptive field. A model consists of a set of receptive fields, each of which has an extent and a linear partial model. RFWR makes predictions with the following algorithm: 1. <p> In these cases, the agent must acquire a domain model by some method. Although there is much previous work on generating a control strategy without using a domain model <ref> [55, 23] </ref>, there is little addressing the problem of finding a qualitative model for a domain. For simple domains like the artificial ones presented here, two observations are all that is necessary to define whether the relationship between the single control and single desired variable is positive or negative.
Reference: [56] <editor> On-line shortcuts. </editor> <booktitle> Sixteenth Soar Workshop, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: C.2 On-line Approaches A different solution is to actively interpret high-level representations during execution. The simplest way to do this is define data structure abbreviations <ref> [56] </ref> similar to regular Soar attributes. Instead of directly matching the abbreviation, the interpreter matches against the abbreviation expansion. Changing the data structure only requires changing the definition of the abbreviations. This can be either implemented in the architecture or knowledge.
Reference: [57] <author> Paul E. Utgoff. ID5: </author> <title> An incremental ID3. </title> <editor> In John E. Laird, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pages 107-120, </pages> <address> San Mateo, CA, June 1988. </address> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: Batch-style algorithms such as decision trees are too inefficient to perform on-line learning. Even incremental decision trees like ID5 <ref> [57] </ref> perform worse as the training set grows, because the increasing tree depth slows classification. Similarly, raw nearest-neighbor algorithms slow down as their memory grows, and so are not incremental. Finally, it is desirable to select established and well-understood representatives of different approaches to control.
Reference: [58] <author> B. Widrow and M. E. Hoff. </author> <title> Adaptive switching circuits. </title> <booktitle> In 1960 IRE WESCON Convention Record, </booktitle> <pages> pages 435-461, </pages> <address> New York, </address> <year> 1960. </year>
Reference-contexts: For example, a linear model in one 11 dimension is m linear (x) = ff x + fi. A popular approach to finding these parameters is called the LMS (least mean squares) error <ref> [58] </ref>.
Reference: [59] <author> Michael D. Williams, James D. Hollan, and Albert L. Stevens. </author> <title> Mental Models, chapter Human Reasoning About a Simple Physical System, pages 131-154. </title> <editor> L. </editor> <publisher> Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1983. </year>
Reference-contexts: To accomplish this, SPLICE sequentially adjusts all the controls it can access, and qualitatively simulates the results using a model such as that in Figure 3.3. This model of a heat exchanger, based on an example <ref> [59] </ref> in the work of Williams et al., describes the effect of input temperatures (T 1;3 ) and flow rates (f 1;2 ) on output temperatures (T 2;4 ).
Reference: [60] <author> Gregg R. Yost. </author> <title> Acquiring knowledge in Soar. </title> <journal> IEEE Expert, </journal> <volume> 8(3) </volume> <pages> 26-34, </pages> <year> 1993. </year> <month> 133 </month>
Reference-contexts: These techniques are frequently used in conjunction with standard Soar programming for highly repetitive and common sets of rules. TAQL The most ambitious and comprehensive approach is TAQL <ref> [60] </ref> (Task AcQuisition Language). TAQL was intended to be a knowledge-level design tool with a compiler for reduction to the problem-space level. Changing data structures only requires changing the high-level representation and re-compiling for a new Soar system.
References-found: 61

