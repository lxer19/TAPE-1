URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/user/alavie/www/papers/ecai-96-discourse.ps
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs.cmu.edu/user/alavie/www/publications.html
Root-URL: http://www.cs.cmu.edu
Title: Minimizing Cumulative Error in Discourse Context  
Author: Yan Qu Barbara Di Eugenio Alon Lavie Lori Levin and Carolyn P. Rose 
Abstract: Cumulative error limits the usefulness of context in applications utilizing contextual information. It is especially a problem in spontaneous speech systems where unexpected input, out-of-domain utterances and missing information are hard to fit into the standard structure of the contextual model. In this paper we discuss how our approaches to recognizing speech acts address the problem of cumulative error. We demonstrate the advantage of the proposed approaches over those that do not address the problem of cumulative error. The experiments are conducted in the context of Enthusiast, a large Spanish-to-English speech-to-speech translation system in the appointment scheduling domain [13, 12, 11, 5]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. F. Allen and L. K. Schubert. </author> <title> The Trains Project. </title> <type> PhD thesis, </type> <institution> University of Rochester, School of Computer Science, </institution> <year> 1991. </year> <type> Technical Report 382. </type>
Reference-contexts: Cumulative error is introduced when an incorrect hypothesis is chosen and incorporated into the context, thus providing an inaccurate context from which subsequent context based predictions are made. For example, in Enthusiast, we model the discourse context using speech acts to represent the functions of dialogue utterances <ref> [1, 3, 6, 7] </ref>. Speech act selection is strongly related to the task of determining how the current input utterance relates to the discourse context. <p> Lastly, we evaluate the effects of the proposed approaches on reducing cumulative error. 2 Related Work There has been much recent work on building a representation of the discourse context with a plan-based or finite state automaton based discourse processor <ref> [1, 10, 3, 6, 8, 5] </ref>. Of these, the Verbmobil discourse processor [6] and our Enthusiast discourse processor are designed to be used in a wide coverage, large scale, spontaneous speech system.
Reference: [2] <author> K. W. Church and W. A. Gale. </author> <title> Probability scoring for spelling correction. </title> <journal> Statistics and Computing, </journal> <volume> 1:93103, </volume> <year> 1991. </year>
Reference-contexts: The adverse effects of cumulative error in context has been noted in NLP in general. For example, Church and Gale <ref> [2] </ref> state that it is important to estimate the context carefully; we have found that poor measures of context are worse than none. However, we are not aware of this issue having been raised in the discourse processing literature.
Reference: [3] <author> L. Lambert. </author> <title> Recognizing Complex Discourse Acts: A Tripartite Plan-Based Model of Dialogue. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Delaware, </institution> <year> 1993. </year>
Reference-contexts: Cumulative error is introduced when an incorrect hypothesis is chosen and incorporated into the context, thus providing an inaccurate context from which subsequent context based predictions are made. For example, in Enthusiast, we model the discourse context using speech acts to represent the functions of dialogue utterances <ref> [1, 3, 6, 7] </ref>. Speech act selection is strongly related to the task of determining how the current input utterance relates to the discourse context. <p> Focusing heuristics are used to rank the different inference chains and choose the one which attaches most coherently to the discourse context <ref> [3, 8, 5] </ref>. However, since heuristics can make wrong predictions, the speech act may be misrecognized, thus making the context inaccurate for future context based predictions. Unexpected input, disfluencies, out of domain utterances, and missing information add to the frequency of misrecognition in spontaneous speech systems. <p> Lastly, we evaluate the effects of the proposed approaches on reducing cumulative error. 2 Related Work There has been much recent work on building a representation of the discourse context with a plan-based or finite state automaton based discourse processor <ref> [1, 10, 3, 6, 8, 5] </ref>. Of these, the Verbmobil discourse processor [6] and our Enthusiast discourse processor are designed to be used in a wide coverage, large scale, spontaneous speech system.
Reference: [4] <author> A. Lavie. </author> <title> A Grammar Based Robust Parser For Spontaneous Speech. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1995. </year>
Reference-contexts: For example, we applied context based predictions from our plan-based discourse processor [7] to the problem of parse disambiguation. Specifically, we combined context based predictions from the discourse processor with non-context based predictions produced by the parser module <ref> [4] </ref> to disambiguate possibly multiple parses provided by the parser for an input utterance. We evaluated two different methods for combining context based predictions with non-context based predictions, namely a genetic programming approach and a neural network approach. <p> Each module is domain-independent and language-independent but makes use of domain specific and language specific knowledge sources for customization. After the speech recognizer produces a hypothesis of what the speaker has said, it is passed to the parser. The GLR* parser <ref> [4] </ref> produces a set of one or more meaning representation structures which are then processed by the discourse processor. The output of the parser is a representation of the meaning of the speaker's sentence. Our meaning representation, called an interlingua (ILT), is a frame-based language independent meaning representation.
Reference: [5] <author> L. Levin, O. Glickman, Y. Qu, D. Gates, A. Lavie, C. P. Rose, C Van Ess-Dykema, and A. Waibel. </author> <title> Using context in machine translation of spoken language. </title> <booktitle> In Theoretical and Methodological Issues in Machine Translation, </booktitle> <year> 1995. </year>
Reference-contexts: Focusing heuristics are used to rank the different inference chains and choose the one which attaches most coherently to the discourse context <ref> [3, 8, 5] </ref>. However, since heuristics can make wrong predictions, the speech act may be misrecognized, thus making the context inaccurate for future context based predictions. Unexpected input, disfluencies, out of domain utterances, and missing information add to the frequency of misrecognition in spontaneous speech systems. <p> Lastly, we evaluate the effects of the proposed approaches on reducing cumulative error. 2 Related Work There has been much recent work on building a representation of the discourse context with a plan-based or finite state automaton based discourse processor <ref> [1, 10, 3, 6, 8, 5] </ref>. Of these, the Verbmobil discourse processor [6] and our Enthusiast discourse processor are designed to be used in a wide coverage, large scale, spontaneous speech system.
Reference: [6] <author> N. Reithinger and E. Maier. </author> <title> Utilizing statistical dialogue act processing in Verbmobil. </title> <booktitle> In Proceedings of the ACL, </booktitle> <year> 1995. </year>
Reference-contexts: Cumulative error is introduced when an incorrect hypothesis is chosen and incorporated into the context, thus providing an inaccurate context from which subsequent context based predictions are made. For example, in Enthusiast, we model the discourse context using speech acts to represent the functions of dialogue utterances <ref> [1, 3, 6, 7] </ref>. Speech act selection is strongly related to the task of determining how the current input utterance relates to the discourse context. <p> Lastly, we evaluate the effects of the proposed approaches on reducing cumulative error. 2 Related Work There has been much recent work on building a representation of the discourse context with a plan-based or finite state automaton based discourse processor <ref> [1, 10, 3, 6, 8, 5] </ref>. Of these, the Verbmobil discourse processor [6] and our Enthusiast discourse processor are designed to be used in a wide coverage, large scale, spontaneous speech system. <p> Of these, the Verbmobil discourse processor <ref> [6] </ref> and our Enthusiast discourse processor are designed to be used in a wide coverage, large scale, spontaneous speech system. In these systems, the design of the dialogue model, whether plan-based or a finite state machine, is grounded in a corpus study that records the standard dialogue act sequences. <p> When the recognized dialogue act is inconsistent with the dialogue model, the systems can rely on a repair procedure to resolve the inconsistency as described in <ref> [6] </ref>. The Verbmobil repair model [6], however, does not address cumulative error in discourse context. Such a repair model is motivated by the fact that the semantic component in Verbmobil only gives the most plausible dialogue act for a given utterance. <p> When the recognized dialogue act is inconsistent with the dialogue model, the systems can rely on a repair procedure to resolve the inconsistency as described in <ref> [6] </ref>. The Verbmobil repair model [6], however, does not address cumulative error in discourse context. Such a repair model is motivated by the fact that the semantic component in Verbmobil only gives the most plausible dialogue act for a given utterance.
Reference: [7] <author> C. P. Rose. </author> <title> Plan-based discourse processor for negotiation dialogues, 1995b. </title> <type> unpublished manuscript. </type>
Reference-contexts: Cumulative error is introduced when an incorrect hypothesis is chosen and incorporated into the context, thus providing an inaccurate context from which subsequent context based predictions are made. For example, in Enthusiast, we model the discourse context using speech acts to represent the functions of dialogue utterances <ref> [1, 3, 6, 7] </ref>. Speech act selection is strongly related to the task of determining how the current input utterance relates to the discourse context. <p> Our previous experiments conducted in the context of the Enthusiast spontaneous speech translation system show that cumulative error can significantly reduce the usefulness of contextual information [9]. For example, we applied context based predictions from our plan-based discourse processor <ref> [7] </ref> to the problem of parse disambiguation. Specifically, we combined context based predictions from the discourse processor with non-context based predictions produced by the parser module [4] to disambiguate possibly multiple parses provided by the parser for an input utterance. <p> We identify a total of fourteen possible speech acts in the appointment scheduling domain <ref> [7] </ref> (Figure 2). The discourse processing module disambiguates the speech act of each utterance, updates a dynamic memory of schedules, and incorporates the utterance into discourse context. Speech Act Example Accept Thursday I'm free the whole day. Acknowledge OK, I see. Address Wait, Alex. Closing See you then. <p> The plan-based discourse processor handles knowledge-intensive tasks exploiting various knowledge sources, including the grammar component predictions and linguistic information. Details about the plan-based discourse processor can be found in <ref> [7, 8] </ref>. The finite state machine and the statistical component have recently been implemented as a fast and efficient alternative to the more time-consuming plan-based discourse processor. In our future design of the discourse processing module, we may adopt a layered architecture similar to the one proposed in Verbmobil.
Reference: [8] <author> C. P. Rose, B. Di Eugenio, L. S. Levin, and C. Van Ess-Dykema. </author> <title> Discourse processing of dialogues with multiple threads. </title> <booktitle> In Proceedings of the ACL, </booktitle> <year> 1995. </year>
Reference-contexts: Focusing heuristics are used to rank the different inference chains and choose the one which attaches most coherently to the discourse context <ref> [3, 8, 5] </ref>. However, since heuristics can make wrong predictions, the speech act may be misrecognized, thus making the context inaccurate for future context based predictions. Unexpected input, disfluencies, out of domain utterances, and missing information add to the frequency of misrecognition in spontaneous speech systems. <p> Lastly, we evaluate the effects of the proposed approaches on reducing cumulative error. 2 Related Work There has been much recent work on building a representation of the discourse context with a plan-based or finite state automaton based discourse processor <ref> [1, 10, 3, 6, 8, 5] </ref>. Of these, the Verbmobil discourse processor [6] and our Enthusiast discourse processor are designed to be used in a wide coverage, large scale, spontaneous speech system. <p> The plan-based discourse processor handles knowledge-intensive tasks exploiting various knowledge sources, including the grammar component predictions and linguistic information. Details about the plan-based discourse processor can be found in <ref> [7, 8] </ref>. The finite state machine and the statistical component have recently been implemented as a fast and efficient alternative to the more time-consuming plan-based discourse processor. In our future design of the discourse processing module, we may adopt a layered architecture similar to the one proposed in Verbmobil.
Reference: [9] <author> C. P. Rose and Y. Qu. </author> <title> Automatically learning to use discourse information for disambiguation, </title> <booktitle> 1995. in submission. </booktitle>
Reference-contexts: Our previous experiments conducted in the context of the Enthusiast spontaneous speech translation system show that cumulative error can significantly reduce the usefulness of contextual information <ref> [9] </ref>. For example, we applied context based predictions from our plan-based discourse processor [7] to the problem of parse disambiguation.
Reference: [10] <author> R. W. Smith, D. R. Hipp, and A. W. Biermann. </author> <title> An architecture for voice dialogue systems based on prolog-style theorem proving. </title> <booktitle> Computational Linguistics, </booktitle> <address> 21(3):218320, </address> <year> 1995. </year>
Reference-contexts: Lastly, we evaluate the effects of the proposed approaches on reducing cumulative error. 2 Related Work There has been much recent work on building a representation of the discourse context with a plan-based or finite state automaton based discourse processor <ref> [1, 10, 3, 6, 8, 5] </ref>. Of these, the Verbmobil discourse processor [6] and our Enthusiast discourse processor are designed to be used in a wide coverage, large scale, spontaneous speech system.
Reference: [11] <author> B. Suhm, L. Levin, N. Coccaro, J. Carbonell, K. Horiguchi, R. Isotani, A. Lavie, L. Mayfield, C. P. Rose, C. Van-Ess Dykema, and A. Waibel. </author> <title> Speech-language integration in a multi-lingual speech translation system. </title> <booktitle> In Proceedings of the AAAI Workshop on Integration of Natural Language and Speech Processing, </booktitle> <year> 1994. </year>
Reference: [12] <author> M. Woszcyna, N. Aoki-Waibel, F. D. Buo, N. Coccaro, K. Horiguchi, T. Kemp, A. Lavie, A. McNair, T. Polzin, I. Rogina, C. P. Rose, T. Schultz, B. Suhm, M. Tomita, and A. Waibel. </author> <title> JANUS 93: Towards spontaneous speech translation. </title> <booktitle> In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <year> 1994. </year>
Reference: [13] <author> M. Woszcyna, N. Coccaro, A. Eisele, A. Lavie, A. McNair, T. Polzin, I. Rogina, C. P. Rose, T. Sloboda, M. Tomita, J. Tsutsumi, N. Waibel, A. Waibel, and W. Ward. </author> <title> Recent advances in JANUS: a speech translation system. </title> <booktitle> In Proceedings of the ARPA Human LanguagesTechnology Workshop, </booktitle> <year> 1993. </year>
Reference: [14] <author> S. M. Katz. </author> <title> Estimation of Probabilities from Sparse Data for the Language Model Component of a Speech Recognizer. </title> <booktitle> In IEEE Transactions on Acoustics, Speech and Signal Processing, </booktitle> <year> 1987. </year>
Reference-contexts: The statistical component is able to provide ranked predictions in a fast and efficient way. To cater to the sparse data problem, bigram speech act probabilities are smoothed based on backoff models <ref> [14] </ref>. The finite state machine (FSM) describes representative sequences of speech acts in the scheduling domain. It is used to record the standard dialogue flow and to check whether the predicted speech act follows idealized dialogue act sequences. The FSM consists of states and transition arcs.
References-found: 14

