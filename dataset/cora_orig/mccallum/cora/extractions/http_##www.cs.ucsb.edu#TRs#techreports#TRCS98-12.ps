URL: http://www.cs.ucsb.edu/TRs/techreports/TRCS98-12.ps
Refering-URL: http://www.cs.ucsb.edu/TRs/
Root-URL: http://www.cs.ucsb.edu
Email: fveho, besmith, tyangg@cs.ucsb.edu  
Title: Cooperative Caching of Dynamic Content on a Distributed Web Server  
Author: Vegard Holmedahl, Ben Smith, Tao Yang 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: In this technical report we propose a new method for improving the average response time of Web servers by cooperatively caching the results of requests for dynamic content. The work is motivated by our recent study of access logs from the Alexandria Digital Library server at UCSB, which demonstrates that approximately a 30 percent decrease in average response time could be achieved by caching dynamically generated content. We have developed a distributed Web server called Swala, in which the nodes cooperatively cache the results of CGI requests. We use a two-level cache table consistency protocol and a replicated global cache directory to maximize the system performance and minimize overhead in responding to dynamic Web requests. Our experiments show that the single-node performance of Swala without caching is comparable to the Netscape Enterprise server, that considerable speedups are obtained using caching, and that the cache hit rate is substantially higher with cooperative cache than with standalone cache.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.Andresen, L.Carver, R.Dolin, C.Fischer, J.Frew, M.Goodchild, O.Ibarra, R.Kothuri, M.Larsgaard, B.Manjunath, D.Nebert, J.Simpson, T.Smith, T.Yang, Q.Zheng, </author> <title> "The WWW Prototype of the Alexandria Digital Library", </title> <booktitle> Proceedings of ISDL'95: International Symposium on Digital Libraries, </booktitle> <address> Japan August 22 - 25, </address> <year> 1995. </year>
Reference-contexts: Our solution is a distributed Web server, called Swala, which cooperatively caches the results of CGI requests. Our work is motivated, in part, by our experience with the Alexandria Digital Library (ADL) system <ref> [1] </ref> developed at UCSB. The current ADL system provides on-line browsing and processing 1 of digitized maps and other geo-spatially mapped data through the Web. <p> However, these papers do not study caching. 3 Access log analysis In this section we illustrate the benefits of dynamic request results caching by analyzing an access log from the Alexandria Digital Library (ADL) at UCSB <ref> [1] </ref>. We have studied its log for September and October 1997, which contains a total of 69,990 requests. After filtering out HEAD and POST requests [5], we have re-sent the requests to the server and timed them.
Reference: [2] <author> D.Andresen, T.Yang, V.Holmedahl, O.Ibarra, "SWEB: </author> <title> Towards a Scalable World Wide Web Server on Multicomputers", </title> <booktitle> Proc. of 10th IEEE International Symp. on Parallel Processing (IPPS'96), </booktitle> <pages> pp. 850-856. </pages> <month> April, </month> <year> 1996. </year>
Reference-contexts: In order to accommodate the growth, advances in server server technology are needed to improve the response time to the client under heavy load conditions. Typical methods for improving performance are file caching with proxies [6, 16, 7], and load balancing multi-node Web servers <ref> [2, 9, 14] </ref>. Research shows that for file fetches on the Web, the network is responsible for a significant portion of the response time. Web proxy caching is effective because it reduces the network bottleneck by keeping copies of files closer to clients. <p> For call mechanisms such as CGI, the operating system overhead for this call is significant, as we demonstrate in one of our experiments in Section 4. Our work overcomes both limitations, since 2 our cache is built into the Web server. Several papers <ref> [2, 9, 14] </ref> address load balancing within a group of Web servers to improve scalability. <p> However, the next time a client wants to access information at the Web site, it will reuse the address from the previous request, bypassing the round-robin distribution of the DNS. This imbalance can be further adjusted by using redirection, as addressed in the SWEB project <ref> [2] </ref>. Our goal is to measure the benefit of distributed caching without any help from load balancing. of server nodes varies from one to eight. The results show that Swala with cooperative caching enabled yields a much lower average response time than Swala with caching disabled.
Reference: [3] <author> D.Andresen, T.Yang, O.Egecioglu, O.H.Ibarra, T.R.Smith, </author> <title> "Scalability Issues for High Performance Digital Libraries on the World Wide Web", </title> <booktitle> Proc. of the 3rd IEEE Forum on Research and Tech. Advances in Digital Libraries (ADL96), </booktitle> <pages> pp. 139-148, </pages> <month> May, </month> <year> 1996. </year>
Reference: [4] <author> G.Bang, P.Druschel, </author> <title> "Measuring the Capacity of a Web Server", </title> <booktitle> Proc. of the USENIX Symposium on Internet Technologies and Systems, </booktitle> <month> December, </month> <year> 1997. </year>
Reference: [5] <author> T. Berners-Lee, R. Fielding, and H. Frystyk, </author> <title> Hypertext Transfer Protocol - HTTP/1.0, RFC 1945, </title> <institution> HTTP Working Group, </institution> <month> May, </month> <year> 1996. </year>
Reference-contexts: We have studied its log for September and October 1997, which contains a total of 69,990 requests. After filtering out HEAD and POST requests <ref> [5] </ref>, we have re-sent the requests to the server and timed them. Illegal requests have been removed from the result file before analyzing the statistics, so the total number of requests studied is 69,337, of which 28,663 (41.3%) require execution of a CGI program.
Reference: [6] <author> P.Cao, S.Irani, </author> <title> "Cost-Aware WWW Proxy Caching Algorithms", </title> <booktitle> Proc. of the USENIX Symposium on Internet Technologies and Systems, </booktitle> <month> December, </month> <year> 1997. </year>
Reference-contexts: 1 Introduction World Wide Web usage has experienced explosive growth in the last few years. In order to accommodate the growth, advances in server server technology are needed to improve the response time to the client under heavy load conditions. Typical methods for improving performance are file caching with proxies <ref> [6, 16, 7] </ref>, and load balancing multi-node Web servers [2, 9, 14]. Research shows that for file fetches on the Web, the network is responsible for a significant portion of the response time. <p> Section 2 describes related work. Section 3 discusses our analysis of a recent access log from the ADL server. Section 4 presents the design of our system and consistency protocol. Section 5 presents the experimental results. Section 6 concludes the paper. 2 Related work Numerous papers <ref> [6, 16, 7] </ref> discuss caching of Web content; however, they focus on caching static data and intentionally avoid caching dynamic data. Furthermore, they concentrate on proxy caching rather than server-side caching. <p> There are two reasons for this. First, our access log analysis in Section 3 shows that execution of dynamic requests generally takes orders of magnitude more time than file fetches. Secondly, previous work on Web file caching <ref> [6, 16] </ref> has determined that for file requests, the network is the bottleneck, so file caching should occur as close to the client as possible, i.e. at a proxy server rather than at the base Web server.
Reference: [7] <author> A.Chankhunthod, P.Danzig, C.Neerdaels, M.Schwartz and K.Worrell, </author> <title> "A Hierarchical Internet Object Cache", </title> <type> Technical Report 95-611, </type> <institution> Computer Science Department, University of Southern California, </institution> <address> Los Angeles, California, </address> <month> March </month> <year> 1995. </year> <title> [8] "The Common Gateway Interface", </title> <address> http://hoohoo.ncsa.uiuc.edu/cgi/. </address>
Reference-contexts: 1 Introduction World Wide Web usage has experienced explosive growth in the last few years. In order to accommodate the growth, advances in server server technology are needed to improve the response time to the client under heavy load conditions. Typical methods for improving performance are file caching with proxies <ref> [6, 16, 7] </ref>, and load balancing multi-node Web servers [2, 9, 14]. Research shows that for file fetches on the Web, the network is responsible for a significant portion of the response time. <p> Section 2 describes related work. Section 3 discusses our analysis of a recent access log from the ADL server. Section 4 presents the design of our system and consistency protocol. Section 5 presents the experimental results. Section 6 concludes the paper. 2 Related work Numerous papers <ref> [6, 16, 7] </ref> discuss caching of Web content; however, they focus on caching static data and intentionally avoid caching dynamic data. Furthermore, they concentrate on proxy caching rather than server-side caching.
Reference: [9] <author> D.Dias, W.Kish, R.Mukherjee, R.Tewari, </author> <title> "A Scalable and Highly Available Web Server", </title> <booktitle> Proc. of COMPCON 1996, Forty-First IEEE Computer Society International Conference: Technologies for the Information Superhighway, </booktitle> <address> Santa Clara, California, </address> <month> February, </month> <year> 1996. </year>
Reference-contexts: In order to accommodate the growth, advances in server server technology are needed to improve the response time to the client under heavy load conditions. Typical methods for improving performance are file caching with proxies [6, 16, 7], and load balancing multi-node Web servers <ref> [2, 9, 14] </ref>. Research shows that for file fetches on the Web, the network is responsible for a significant portion of the response time. Web proxy caching is effective because it reduces the network bottleneck by keeping copies of files closer to clients. <p> For call mechanisms such as CGI, the operating system overhead for this call is significant, as we demonstrate in one of our experiments in Section 4. Our work overcomes both limitations, since 2 our cache is built into the Web server. Several papers <ref> [2, 9, 14] </ref> address load balancing within a group of Web servers to improve scalability.
Reference: [10] <author> S.Gadde, M.Rabinovich, J.Chase, </author> <title> "Reduce, Reuse, Recycle: An Approach to Building Large Internet Caches", </title> <booktitle> Workshop on Hot Topics in Operating Systems (HotOS), </booktitle> <month> May </month> <year> 1997. </year> <month> 16 </month>
Reference: [11] <author> James Gwertzman, Margo Seltzer, </author> <title> "World Wide Web Cache Consistency," </title> <booktitle> Proceedings of the 1996 USENIX Technical Conference, </booktitle> <address> San Diego, CA, </address> <month> Jan </month> <year> 1996. </year>
Reference-contexts: Furthermore, they concentrate on proxy caching rather than server-side caching. Proxy caching of dynamic content may not be feasible because it does not permit caching of authenticated content and it hinders cache replacement algorithms based on job execution time. Gwertzman and Seltzer <ref> [11] </ref> provide motivation for our research, by noting a tenfold increase in dynamically generated pages in six months, and suggesting that this increase in dynamic requests must be met by caching the scripts that generate the dynamic results.
Reference: [12] <author> J.Hu, S.Mungee, D.Schmidt, </author> <title> "Techniques for Developing and Measuring High-performance Web Servers over ATM Networks," </title> <institution> Washington University technical report #WUCS-97-09. </institution>
Reference-contexts: All execution is multi-threaded, to maximize throughput. Multi-threading raises consistency issues, which we discuss in section 4.2. We use memory-mapped I/O whenever possible to minimize the number of system calls and eliminate double-buffering. Multi-threading and memory-mapped I/O are important components of efficient Web servers <ref> [12] </ref>. 4.1 Module design As illustrated in Figure 1, every Swala node contains two primary runtime modules: HTTP Module The control module starts and shuts down all other threads. <p> We use NCSA HTTPd because it is a widely used research package, and we use Netscape Enterprise because it is one of the most efficient commercial Web servers available <ref> [12] </ref>.
Reference: [13] <author> A.Iyengar, J.Challenger, </author> <title> "Improving Web Server Performance by Caching Dynamic Data", </title> <booktitle> Proc. of the USENIX Symposium on Internet Technologies and Systems, </booktitle> <month> December, </month> <year> 1997. </year>
Reference-contexts: Finally, the proxy must be trusted by the original server to receive the scripts and source files. Most proxies operate as normal HTTP clients toward servers; this is not possible with Gwertzman and Seltzer's approach. Caching the results of dynamic requests has been studied recently by IBM <ref> [13] </ref>. They have written a cache server and rewritten their server applications to insert and delete items in this cache. There are two main drawbacks to this approach. First, they require that the server application be rewritten to take advantage of the cache, and this can be a nontrivial task. <p> We discuss cache replacement algorithms in greater detail in section 4.3. While our log analysis has been limited to a digital library, we expect that other Web sites that make extensive use of dynamic requests also can benefit from dynamic content caching. This is verified by recent work <ref> [13] </ref>. 4 Design of the Swala distributed Web server Swala is a multi-threaded, distributed Web server that runs on a cluster of workstations and shares cache information and cache data between nodes. <p> This is true in digital library applications, where the material available through the Web server normally is read-only. We plan to investigate cache entry invalidation methods in future versions of Swala. This can be implemented by receiving invalidation messages from applications after the model of Iyengar et al. <ref> [13] </ref>, and / or by monitoring the input of the CGI programs whose output is being cached, to detect invalidation, as suggested by Vahdat and Anderson [19]. We address cache table 6 consistency with a two-level consistency protocol: intra-server and inter-server consistency.
Reference: [14] <author> E.D. Katz, M. Butler, R. McGrath, </author> <title> A Scalable HTTP Server: the NCSA Prototype, </title> <journal> Computer Networks and ISDN Systems. </journal> <volume> vol. 27, </volume> <year> 1994, </year> <pages> pp. 155-164. </pages>
Reference-contexts: In order to accommodate the growth, advances in server server technology are needed to improve the response time to the client under heavy load conditions. Typical methods for improving performance are file caching with proxies [6, 16, 7], and load balancing multi-node Web servers <ref> [2, 9, 14] </ref>. Research shows that for file fetches on the Web, the network is responsible for a significant portion of the response time. Web proxy caching is effective because it reduces the network bottleneck by keeping copies of files closer to clients. <p> For call mechanisms such as CGI, the operating system overhead for this call is significant, as we demonstrate in one of our experiments in Section 4. Our work overcomes both limitations, since 2 our cache is built into the Web server. Several papers <ref> [2, 9, 14] </ref> address load balancing within a group of Web servers to improve scalability. <p> The DNS answers with different addresses in round-robin fashion, so that the clients initially are distributed evenly among the available Web servers in the group <ref> [14] </ref>. However, the next time a client wants to access information at the Web site, it will reuse the address from the previous request, bypassing the round-robin distribution of the DNS. This imbalance can be further adjusted by using redirection, as addressed in the SWEB project [2].
Reference: [15] <author> Paolo Lorenzetti, Luigi Rizzo, Lorenzo Vicisano, </author> <title> "Replacement policies for a proxy cache," </title> <type> draft, </type> <note> http://www.iet.unipi.it/ luigi/caching.ps.gz. </note>
Reference: [16] <author> R.McGrath, </author> <title> "Caching for Large Scale Systems", </title> <journal> D-Lib Magazine, </journal> <month> January </month> <year> 1996. </year> <title> [17] "Netscape Server Central Index Page", </title> <note> http://home.netscape.com/comprod/server central/. [18] "The NCSA HTTPd Home Page", http://hoohoo.ncsa.uiuc.edu/. </note>
Reference-contexts: 1 Introduction World Wide Web usage has experienced explosive growth in the last few years. In order to accommodate the growth, advances in server server technology are needed to improve the response time to the client under heavy load conditions. Typical methods for improving performance are file caching with proxies <ref> [6, 16, 7] </ref>, and load balancing multi-node Web servers [2, 9, 14]. Research shows that for file fetches on the Web, the network is responsible for a significant portion of the response time. <p> Section 2 describes related work. Section 3 discusses our analysis of a recent access log from the ADL server. Section 4 presents the design of our system and consistency protocol. Section 5 presents the experimental results. Section 6 concludes the paper. 2 Related work Numerous papers <ref> [6, 16, 7] </ref> discuss caching of Web content; however, they focus on caching static data and intentionally avoid caching dynamic data. Furthermore, they concentrate on proxy caching rather than server-side caching. <p> There are two reasons for this. First, our access log analysis in Section 3 shows that execution of dynamic requests generally takes orders of magnitude more time than file fetches. Secondly, previous work on Web file caching <ref> [6, 16] </ref> has determined that for file requests, the network is the bottleneck, so file caching should occur as close to the client as possible, i.e. at a proxy server rather than at the base Web server.
Reference: [19] <author> A. Vahdat, T. Anderson, </author> <title> "Transparent Result Caching," </title> <note> unpublished. [20] "WebStone", http://www.sgi.com/Products/WebFORCE/WebStone/index.html. 17 </note>
Reference-contexts: This can be implemented by receiving invalidation messages from applications after the model of Iyengar et al. [13], and / or by monitoring the input of the CGI programs whose output is being cached, to detect invalidation, as suggested by Vahdat and Anderson <ref> [19] </ref>. We address cache table 6 consistency with a two-level consistency protocol: intra-server and inter-server consistency. In the following section we describe our cache table consistency protocol. Our intra-node consistency protocol protects the internal cache directory against simultaneous updates, avoiding potential data corruption.
References-found: 16

