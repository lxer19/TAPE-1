URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-314.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: trevor@media.mit.edu fleet@qucis.queensu.ca  
Title: Second-order method for occlusion relationships in motion layers  
Author: Trevor Darrell and David Fleety 
Abstract: M.I.T. Media Laboratory Vision and Modeling Group Technical Report No. 314 ABSTRACT A new method is presented to recover the depth ordering of motion layers in a scene. We derive a measure for determining the occlusion relationship between two layers, by testing whether the support of one motion layer is moving with the predicted local velocity of another motion layer. This is used to construct a graph which represents the depth ordering of all layers. By cascading two first-order motion models, a second-order model is defined which is sensitive to the motion of motion-defined support regions, which is sometimes called kinetic occlusion. Our algorithm makes few assumptions about the motion and layer models, and can use any motion layer model which provides global hypotheses in the form of velocity fields, and any local motion mechanism which provides the conditional probabilty of a velocity given a local image region. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adelson E. H., and Anandan, P., </author> <title> "Ordinal characteristics of transparency", </title> <booktitle> in Proc. AAAI Workshop on Qualitative Vision, </booktitle> <pages> pp. 77-81, </pages> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: More recently, the concept of layers was introduced to provide a more general representation for scene yDavid Fleet is with the Robotics and Perception Lab, Department of Computing Science, Queen's University segmentations, and to facilitate a richer description of images in terms of their intrinsic properties <ref> [1] </ref>. Several authors have implemented methods that compute motion layers. Darrell and Pentland [8] applied a model of cooperative robust estimation to the motion domain, decomposing an image sequence into a set of support layers that represent homogeneous motions (parameterized by a global model). <p> No static segmentation cues are present; segmentation into layers and determination of occlusion/ordering is based purely on motion cues. (b) First-order support layers s 0 (x; y),s 1 (x; y) for this sequence (v 0 (x; y) = <ref> [1; 0] </ref> T , v 1 (x; y) = [1; 0] T ). (c) Second-order support layers ss 0 (x; y),ss 1 (x; y) for this sequence. <p> No static segmentation cues are present; segmentation into layers and determination of occlusion/ordering is based purely on motion cues. (b) First-order support layers s 0 (x; y),s 1 (x; y) for this sequence (v 0 (x; y) = <ref> [1; 0] </ref> T , v 1 (x; y) = [1; 0] T ). (c) Second-order support layers ss 0 (x; y),ss 1 (x; y) for this sequence.
Reference: [2] <author> Adelson, E. H., </author> <type> personal communiction. </type>
Reference-contexts: However, the published methods for recovering layers based on motion information have not extracted cues for depth ordering. It may be possible to find T-junctions in space-time which would imply occlusion boundaries <ref> [2] </ref>, but their detection in space-time remains a formidable problem. In this paper we present a new approach for recovering occlusion relationships between layers, using a motion-based analysis that does not rely on static scene cues.
Reference: [3] <author> Black, M. J., and Anandan, P., </author> <title> "The Robust Estimation of Multiple Motions: Affine and Piecewise-Smooth Flow Fields", </title> <note> Xerox PARC Technical Report SPL-93-092, </note> <month> December, </month> <year> 1993. </year>
Reference-contexts: Several authors have implemented methods that compute motion layers. Darrell and Pentland [8] applied a model of cooperative robust estimation to the motion domain, decomposing an image sequence into a set of support layers that represent homogeneous motions (parameterized by a global model). Irani and Peleg [17] and Black <ref> [3] </ref> used higher-order motion models, such as the affine model, to segment moving objects and find regions of support. <p> Methods for recovering layers typically combine a local mechanism for extracting local constraints on optical flow, with a gobal mechanism for constraint selection or clustering. The global constraint is often a parametric model of flow <ref> [17, 20, 3, 8] </ref>, but could be defined by a smoothness constraint, such as regularized optic flow. The constraint for a particular layer can be expressed as a global velocity field, depicting how points in the image would move if such motion were present in that region of the scene. <p> A method for recovering a layered description typically combines this type of test with a mechanism for determining the set of velocity fields v k (x; y) that is an optimal representation of the image. This has been accomplished using clustering methods, based either on the k-means algorithm <ref> [20, 3] </ref>, or on a Minimum Description Length principle to select from a set of hypotheses [7, 11, 15]. These detailed methods are beyond the scope of this paper.
Reference: [4] <author> Black, M. J., and Anandan, P., </author> <title> "A framework for the robust estimation of optical flow", </title> <booktitle> In Proc. Intl. Conf. Computer Vision, ICCV-93, </booktitle> <pages> pages 231-236, </pages> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: It can be viewed as an inverse-outlier measure when used in robust estimation methods <ref> [7, 4] </ref>. Thus s k (x; y) = C x;y;0 (I; v k (x; y)); (2) where C x;y;t (I; v) is a constraint function which effectively supports whether velocity v is present in the image sequence I at time t and location (x; y).
Reference: [5] <author> Blake, A. and Zisserman, A. </author> <title> Visual Reconstruction. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <year> 1987. </year>
Reference-contexts: This has been formalized as a line-process within the framework of Markov Random Fields [16], or with the notion of controlled dis-coninuities within a regularization framework <ref> [5, 18] </ref>. More recently, the concept of layers was introduced to provide a more general representation for scene yDavid Fleet is with the Robotics and Perception Lab, Department of Computing Science, Queen's University segmentations, and to facilitate a richer description of images in terms of their intrinsic properties [1].
Reference: [6] <author> Cavanagh, P. and Mather, G. </author> <title> "Motion: The long and Short of it", Spatial Vision Vol. 4, </title> <journal> Nos. </journal> <volume> 2/3, </volume> <pages> pp. </pages> <month> 103-129, </month> <title> 1989 9 (o ij ) j=0 j=1 j=2 i=1 (a) 0 1 2 1 0.001 0.001 0.000 l i is occluding l j . (d) Occlusion matrix showing amount of occlusion between pairs of layers. (e) Occlusion graph constructed from occlusion matrix, reflecting the depth ordering of of objects in the scene. A tree is recovered, since the relative depth of layers l 0 ,l 2 is ambiguous. </title> <type> 10 </type>
Reference-contexts: are no static cues available, such as the display of random dot motion on a computer screen, the agreement of motion of aperature and pattern is interpreted by human observers as being due to the motion of a single, unoccluded, moving object. 4 Boundary ownership from second-order motion Following Cavanagh <ref> [6] </ref>, first-order motion refers to the motion of image structure, extracted using constraints applied to the original image or a band-pass filtered version of it. Second-order motion, by comparison, refers to the motion of first-order properties such as regions of uniform texture, or regions of consistent motion.
Reference: [7] <author> Darrell, T., and Pentland, P. </author> <title> "Cooperative Ro--bust Estimation of Multiple Layers of Support", to appear, </title> <journal> IEEE Trans. Pattern Anal. and Mach. Intell. </journal>
Reference-contexts: These authors have found that layers are an effective representation for problems which are not well suited for edge-based models, such as those involving transparency or disjoint occluded features. Layered representations draw from an establisted tradition of robust estimation methods <ref> [7] </ref>, which are of increasing interest in the computer vision community [12, 13]. Ideally, a layered representation might also produce, or facilitate the inference of, a partial ordering of the layers that corresponds to a depth ordering of the surfaces of the scene. <p> It can be viewed as an inverse-outlier measure when used in robust estimation methods <ref> [7, 4] </ref>. Thus s k (x; y) = C x;y;0 (I; v k (x; y)); (2) where C x;y;t (I; v) is a constraint function which effectively supports whether velocity v is present in the image sequence I at time t and location (x; y). <p> This has been accomplished using clustering methods, based either on the k-means algorithm [20, 3], or on a Minimum Description Length principle to select from a set of hypotheses <ref> [7, 11, 15] </ref>. These detailed methods are beyond the scope of this paper.
Reference: [8] <author> Darrell, T., and Pentland, A. P., </author> <title> "Robust Estimation of a Multi-Layer Motion Representation", </title> <booktitle> in Proceedings IEEE Workshop on Visual Motion, </booktitle> <pages> pp. 173-177, </pages> <year> 1991. </year>
Reference-contexts: Several authors have implemented methods that compute motion layers. Darrell and Pentland <ref> [8] </ref> applied a model of cooperative robust estimation to the motion domain, decomposing an image sequence into a set of support layers that represent homogeneous motions (parameterized by a global model). <p> Methods for recovering layers typically combine a local mechanism for extracting local constraints on optical flow, with a gobal mechanism for constraint selection or clustering. The global constraint is often a parametric model of flow <ref> [17, 20, 3, 8] </ref>, but could be defined by a smoothness constraint, such as regularized optic flow. The constraint for a particular layer can be expressed as a global velocity field, depicting how points in the image would move if such motion were present in that region of the scene. <p> Indeed, the method presented here can be applied with any model of layer recovery that returns a set of layers L as defined above. (The examples shown in this paper were obtained using an implementation of the layer recovery method given in <ref> [8] </ref>.) 3 Scene ambiguity and boundary ownership Given a layered representation of an image sequence, we want to determine a depth ordering of objects in the scene that correspond to the layers. <p> Mechanisms for second-order motion can be simply expressed as the cascade of two first-order velocity selective mechanisms, separated by a pointwise non-linearity [10]. We combine this model with the layers approach to motion segmentation <ref> [20, 8] </ref>, and observe that second-order motion in layers is an important cue to occlusion relationships and depth ordering. One advantage of the layers model is that global constraints on the velocity field allow the local measurement mechanism to use velocity hypothesis testing rather than velocity estimation.
Reference: [9] <author> Darrell, T., and Simoncelli, E. P., </author> <title> "Separation of Transparent Motion into Layers using Velocity-Tuned Mechanisms", </title> <note> presented at Proceedings Assn. Research in Vision and Opth. annual conference (ARVO93), available as MIT Media Lab Perceptual Computing Technical Report TR-244. </note>
Reference-contexts: Regions of support need not be connected within any given layer, and if there is transparency in the scene, then more than one motion layer may be supported at a single image location <ref> [9] </ref>. <p> When additive transparency occurs, higher-order filters must be applied to test motion support <ref> [9] </ref>. C t (I; v) provides a method to test the support for a local velocity that is implied by a particular layer.
Reference: [10] <author> Fleet, D.J. and Langley, K., </author> <title> "Computational analysis of non-Fourier motion", </title> <journal> Vision Research Vol. </journal> <volume> 34, No. 22, </volume> <pages> pp. 3057-3079, </pages> <year> 1994 </year>
Reference-contexts: Second-order motion has also been refered to as non-Fourier motion in the psychophysics literature, and related to a number of distinct phenomena, including the motion of contrast envelopes, subsampled time-varying signals, and of course the motion of occlusion boundaries <ref> [10] </ref>. In the current context, we are interested in the motion of regions of coherent motion, that is, the motion of the aperture (or occlusion) boundaries. <p> Mechanisms for second-order motion can be simply expressed as the cascade of two first-order velocity selective mechanisms, separated by a pointwise non-linearity <ref> [10] </ref>. We combine this model with the layers approach to motion segmentation [20, 8], and observe that second-order motion in layers is an important cue to occlusion relationships and depth ordering.
Reference: [11] <author> Leonardis, A., </author> <title> "Recover and Select Paradigm-A Robust Approach to Estimation of Parametric Models", </title> <booktitle> in Proceedings NSF/ARPA Wk-shp. on Performance vs. Methodology in Computer Vision, </booktitle> <address> Seattle, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: This has been accomplished using clustering methods, based either on the k-means algorithm [20, 3], or on a Minimum Description Length principle to select from a set of hypotheses <ref> [7, 11, 15] </ref>. These detailed methods are beyond the scope of this paper.
Reference: [12] <author> Meer, P., Mintz, D., and Rosenfeld, A., </author> <title> "Robust regression methods for computer vision: A review", </title> <journal> Intl. J. Computer Vision, </journal> <volume> vol 6, </volume> <pages> pp. 60-70, </pages> <year> 1991. </year>
Reference-contexts: Layered representations draw from an establisted tradition of robust estimation methods [7], which are of increasing interest in the computer vision community <ref> [12, 13] </ref>. Ideally, a layered representation might also produce, or facilitate the inference of, a partial ordering of the layers that corresponds to a depth ordering of the surfaces of the scene.
Reference: [13] <editor> Meer, P., and Haralick, R., eds, </editor> <booktitle> Proceedings Workshop on Performance vs. Methodology in Computer Vision, </booktitle> <address> CVPR-94, Seattle, </address> <year> 1994. </year>
Reference-contexts: Layered representations draw from an establisted tradition of robust estimation methods [7], which are of increasing interest in the computer vision community <ref> [12, 13] </ref>. Ideally, a layered representation might also produce, or facilitate the inference of, a partial ordering of the layers that corresponds to a depth ordering of the surfaces of the scene.
Reference: [14] <author> Nitzberg, M., and Mumford, D., </author> <title> "The 2.1-D Sketch", </title> <booktitle> Proc. 3rd Intl. Conf. on Computer Vision, </booktitle> <pages> pp. 138-144, </pages> <year> 1990. </year>
Reference-contexts: Inference of depth ordering has been achieved in layered representations of static images based on edges, with the assumption that T-junctions indicate occlusions <ref> [14] </ref>. However, the published methods for recovering layers based on motion information have not extracted cues for depth ordering. It may be possible to find T-junctions in space-time which would imply occlusion boundaries [2], but their detection in space-time remains a formidable problem.
Reference: [15] <author> Pentland, A., </author> <title> "Automatic recovery of de-formable part models", </title> <journal> Intl. J. Computer Vision, </journal> <volume> vol 4, </volume> <pages> pp. 107-126, </pages> <year> 1990. </year>
Reference-contexts: This has been accomplished using clustering methods, based either on the k-means algorithm [20, 3], or on a Minimum Description Length principle to select from a set of hypotheses <ref> [7, 11, 15] </ref>. These detailed methods are beyond the scope of this paper.
Reference: [16] <author> Poggio, T., Torre, V., and Koch, C. </author> <title> "Computational vision and regularization theory", </title> <journal> Nature, </journal> <volume> vol. 317(26), </volume> <year> 1985. </year>
Reference-contexts: Early approaches to this problem attempted to find the boundaries of homogeneous motions in the scene and estimate parameters within regions defined by these edges. This has been formalized as a line-process within the framework of Markov Random Fields <ref> [16] </ref>, or with the notion of controlled dis-coninuities within a regularization framework [5, 18].
Reference: [17] <author> Irani, M., Rousso, B., and Peleg, S., </author> <title> Computing Occluding and Transparent Motions Intl. </title> <journal> J. Computer Vision, </journal> <volume> vol. 12(1), </volume> <pages> pp. 5-16, </pages> <year> 1994. </year>
Reference-contexts: Several authors have implemented methods that compute motion layers. Darrell and Pentland [8] applied a model of cooperative robust estimation to the motion domain, decomposing an image sequence into a set of support layers that represent homogeneous motions (parameterized by a global model). Irani and Peleg <ref> [17] </ref> and Black [3] used higher-order motion models, such as the affine model, to segment moving objects and find regions of support. <p> Methods for recovering layers typically combine a local mechanism for extracting local constraints on optical flow, with a gobal mechanism for constraint selection or clustering. The global constraint is often a parametric model of flow <ref> [17, 20, 3, 8] </ref>, but could be defined by a smoothness constraint, such as regularized optic flow. The constraint for a particular layer can be expressed as a global velocity field, depicting how points in the image would move if such motion were present in that region of the scene.
Reference: [18] <author> Terzopoulos, D. </author> <title> "The computation of visible surface representations", </title> <journal> IEEE Trans. Pattern Anal. and Machine Intell., </journal> <volume> vol. 10:4, </volume> <year> 1988 </year>
Reference-contexts: This has been formalized as a line-process within the framework of Markov Random Fields [16], or with the notion of controlled dis-coninuities within a regularization framework <ref> [5, 18] </ref>. More recently, the concept of layers was introduced to provide a more general representation for scene yDavid Fleet is with the Robotics and Perception Lab, Department of Computing Science, Queen's University segmentations, and to facilitate a richer description of images in terms of their intrinsic properties [1].
Reference: [19] <author> Simoncelli, E., Adelson, E. H., and Heeger, D. J., </author> <title> "Probability Distributions of Optical Flow", </title> <booktitle> Proc. IEEE Conf. Computer Vision and Pattern Recognition, </booktitle> <year> 1991. </year>
Reference-contexts: If we have a probabalistic motion model than a natural expression for the contraint function is the conditional probability of v given the observed intensities I. If we consider sequences without additive transparency we can use the model developed by Simon celli <ref> [19] </ref> which has a particularly simple form: P (vjI x;y;t ) exp (D (v)I x;y;t ) 2 jjrI x;y;t jj 2 (4) where D (v) = v x 1 r = (v x @x @ + @t and I x;y;t is the input sequence offset by (x; y; t). <p> To compute the support maps for each layer we are interested in testing the support for a hypothesized velocity, rather than estimating a velocity in general. For example, as shown in <ref> [19] </ref>, the first-order stage can return a velocity-selective measure, which could be implemented, for example, using spatiotemporal linear filters to compute a gradient constraint, followed by a squaring and a normalization stage.
Reference: [20] <author> Wang, J., and Adelson, E. H., </author> <title> "Layered Representations for Image Sequence Coding", </title> <booktitle> Proc. IEEE Conf. Computer Vision and Pattern Recognition, </booktitle> <year> 1993. </year> <month> 11 </month>
Reference-contexts: Irani and Peleg [17] and Black [3] used higher-order motion models, such as the affine model, to segment moving objects and find regions of support. Wang and Adelson <ref> [20] </ref> used an affine model and a k-means clustering method to find motion layers, from which extended representations were constructed by compositing layers from several consecutive frames of an image sequence into a larger image. <p> Methods for recovering layers typically combine a local mechanism for extracting local constraints on optical flow, with a gobal mechanism for constraint selection or clustering. The global constraint is often a parametric model of flow <ref> [17, 20, 3, 8] </ref>, but could be defined by a smoothness constraint, such as regularized optic flow. The constraint for a particular layer can be expressed as a global velocity field, depicting how points in the image would move if such motion were present in that region of the scene. <p> We restrict our attention to instantaneous layers that describe the image information at a single moment in time. Methods which composite information from multiple frames into an extended layer have been developed <ref> [20] </ref>, and our framework here can be generalized naturally to cover that case. <p> A method for recovering a layered description typically combines this type of test with a mechanism for determining the set of velocity fields v k (x; y) that is an optimal representation of the image. This has been accomplished using clustering methods, based either on the k-means algorithm <ref> [20, 3] </ref>, or on a Minimum Description Length principle to select from a set of hypotheses [7, 11, 15]. These detailed methods are beyond the scope of this paper. <p> Mechanisms for second-order motion can be simply expressed as the cascade of two first-order velocity selective mechanisms, separated by a pointwise non-linearity [10]. We combine this model with the layers approach to motion segmentation <ref> [20, 8] </ref>, and observe that second-order motion in layers is an important cue to occlusion relationships and depth ordering. One advantage of the layers model is that global constraints on the velocity field allow the local measurement mechanism to use velocity hypothesis testing rather than velocity estimation.
References-found: 20

