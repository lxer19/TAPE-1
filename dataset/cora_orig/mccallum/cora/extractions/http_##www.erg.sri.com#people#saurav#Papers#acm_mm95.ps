URL: http://www.erg.sri.com/people/saurav/Papers/acm_mm95.ps
Refering-URL: http://www.erg.sri.com/people/saurav/paper.html
Root-URL: 
Title: A Generalized Admissions Control Strategy for Heterogeneous, Distributed Multimedia Systems  
Author: Saurav Chatterjee and Jay Strosnider 
Keyword: admissions control, heterogeneous resources, timing analysis  
Affiliation: Department of Electrical Computer Engineering Carnegie Mellon University  
Address: San Francisco, Ca,  Pittsburgh, PA 15213  
Note: In Proceedings of ACM Multimedia 95,  
Email: -saurav, jks-@ece.cmu.edu  
Date: November 1995.  
Abstract: This paper presents a generalized admissions control strategy for providing timing guarantees to multimedia applications executing over a set of distributed, heterogeneous system resources. This paper illustrates complications that arise in moving from resource-specific to generalized admissions control and introduces a strategy that can be used to solve some of these problems. Key elements of this Distributed Pipeline Admissions Control Strategy include (i) a resource-independent model for representing multimedia applications requiring access to an heterogeneous set of system resources, (ii) an uniform model for representing a set of heterogeneous system resources, (iii) a real-time heterogeneous resource allocation and routing algorithm, (iv) distributed pipeline scheduling policies that result in efficient and predictable resource usage by clients, and (v) a divide-and-conquer timing analysis technique for ascertaining whether client timing requirements are met. An audio/video example is provided to illustrate the application of this approach. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> D. Anderson, R. Herrtwich, and C. Schaefer, SRP: </author> <title> A Resource Reservation Protocol for Guaranteed Performance Communication in the Internet, </title> <type> ICSI Technical Report TR-90-006, </type> <institution> International Computer Science Institute, </institution> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: Specifically, previous work on the Integrated Service Packet Network by Clark, Shenker and Zhang [7], the Flow Protocol by Zhang [24], the Tenet scheme by Ferrari and Verma [12], the HeiRAT scheme by Vogt, Herrtwich, and Nagarajan [21], and the Session Reservation Protocol by Anderson, Herrtwich and Schaefer <ref> [1] </ref> have each provided solutions to the challenges listed in the left-hand column of Table 1. Because multimedia applications generally execute over heterogeneous resources, guaranteeing all application-specific timing requirements require similar admissions control for processors, buses and disks [1]. <p> Nagarajan [21], and the Session Reservation Protocol by Anderson, Herrtwich and Schaefer <ref> [1] </ref> have each provided solutions to the challenges listed in the left-hand column of Table 1. Because multimedia applications generally execute over heterogeneous resources, guaranteeing all application-specific timing requirements require similar admissions control for processors, buses and disks [1]. As a result, Klara and Steinmetz [16] and Mercer, Zelenka and Rajkumar [18] have recently addressed admissions control on processors. Unfortunately, this practice of designing resource-specific admissions control protocols creates a set of disjoint admissions control approaches that do not necessarily work together in a coherent manner. <p> resource in the centralized version Once the decision to accept or reject a client request is made, the updated state information is propagated to all other host resources. - 3 - The decentralized version of DPACS attempts an end-to-end connection establishment using a protocol similar to the Session Reservation Protocol <ref> [1] </ref>. The mapping algorithm determines the neighboring system resource that may be potentially involved in the clients connection setup. This resource in turn finds a neighbor resource that could be allocated to the client. This continues until the sink resource is reached. <p> MODELING MULTIMEDIA CLIENTS AND SERVERS Various techniques have been used to model a clients timing requirements. Ferrari [10] provided a parameter set for representing periodic applications timing requirements. The DASH resource model by Anderson, et. al. <ref> [1] </ref> used in the Session Reservation Protocol scheme consists of a set of messages with distinct arrival and completion times. Timed Petri Nets [8] have been used for representing aperiodic multimedia applications such as video browsing. However, these models do not specify the heterogeneous resource requirements of a client.
Reference: 2. <author> J. Beck and D. Siewiorek, </author> <title> Automated Task Allocation and Processor Specification Strategies for Multi-computer Systems, </title> <type> CMU-EDRC 18-50-94 Technical Report, </type> <institution> 1994. t 1 t 1 t 0 ,&gt;, </institution>
Reference-contexts: The mapping algorithm may output other TSAS streams corresponding to previously admitted applications if (i) the mapping policy permits re-mapping and (ii) remapping is necessary for the system to accommodate the new client [6]. Previous work has explored allocation among CPUs connected via a common bus <ref> [2] </ref> and network routing between fixed source and sink nodes [19]. However, the DPACS mapping algorithm requires not only source to sink routing but must consider intermediate processing step allocation requirements.
Reference: 3. <author> U. Chandra and M. Harmon, </author> <title> Predictability of Program Execution Times on Superscalar Pipelined Architectures, </title> <booktitle> Third Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <year> 1995. </year>
Reference-contexts: For processing steps executing on processor-type resources, i.e., threads, the instructions per byte, PIPB = , is a client-specified function that is used by the mapping algorithm to compute the resource-specific execution time. More sophisticated estimator algorithms <ref> [3, 17] </ref> can also be incorporated into the DPACS. The computation type can be used to specify thread-specific information such as semaphore usage, etc. [5]. The Optional Parameters (OP) data structure specifies target platform-specific attributes for each LASM. <p> k k TSPS i k k PC i intermediate= PIDS i k r k network= PODS i 1 k k = k network= PRT i CPU= PIIDS i k PODS i k PIDS i k r PRN i = RPS PIDS i k PIDS i 1+ k sophisticated estimator algorithm <ref> [3, 17] </ref> can also be incorporated into the DPACS. The execution rate is calculated based on the relative input and output bytes of adjacent logical processing steps. See [5] for equations for both execution time and rate.
Reference: 4. <author> S. Chatterjee and J. Strosnider, </author> <title> Distributed Pipeline Scheduling: End-to-End Analysis of Heterogeneous, </title> <booktitle> Multi-Resource Real-Time Systems, Proceedings of the 15th IEEE International Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: For and set equal to jitter-earliest-due-date ow control mechanism [22], [11], where can be calculated using the clock_skew ( , ) algorithm given in Figure 8. for the stop-and-go ow control mechanism can be found in <ref> [4] </ref>. The following theorem checks if all end-to-end latency timing requirements are met. Theorem 1: All latency requirements are met if, for every , . Proofs for Lemma 1 and Theorem 1 can be found in [6].
Reference: 5. <author> S. Chatterjee and J. Strosnider, </author> <title> Distributed Pipeline Scheduling: </title>
Reference-contexts: More sophisticated estimator algorithms [3, 17] can also be incorporated into the DPACS. The computation type can be used to specify thread-specific information such as semaphore usage, etc. <ref> [5] </ref>. The Optional Parameters (OP) data structure specifies target platform-specific attributes for each LASM. The OP is generally used to identify the exact resources on which the source and sink processing steps execute. <p> The OP is generally used to identify the exact resources on which the source and sink processing steps execute. Furthermore, the OP execution time attribute can be used to override the estimator algorithm result with a client specified result. Refer to <ref> [5] </ref> for more detail. , set of Input Data Structures , set of Output Data Structures Table 6: Additional Synchronization Attributes PIDS i k pids ij k LEij k PODS i k pods ij k LEij k r k i,( ) s k i,( ) , min. and max. <p> The execution rate is calculated based on the relative input and output bytes of adjacent logical processing steps. See <ref> [5] </ref> for equations for both execution time and rate. <p> DISTRIBUTED PIPELINE SCHEDULING Distributed pipeline scheduling transforms a TSAS into a pipelined application stream by partitioning groups of target-specific processing steps into distributed pipeline stages and assigning both intra- and inter-pipeline stage attributes (Figure 6). This section briey summarizes the key ideas in distributed pipeline scheduling. Refer to <ref> [5] </ref> for a more thorough explanation and example. Distributed pipelining is similar to processor pipelining but distributed pipeline stages are generally asynchronously clocked, i.e., unlike a processor pipeline, a single global clock may not be present to clock every one of the distributed pipeline stages. <p> Finally, distributed pipeline stage execution pipeline stage partitioning intra- & inter-pipeline stage attributes assign. TSAS PAS - 9 - rates are a function of intrinsic resource attributes and adjacent pipeline stages do not necessarily execute at the same rate. A partitioning algorithm <ref> [5] </ref> transforms each TSAS into an efficient distributed pipeline by grouping target-specific processing steps into distributed pipeline stages. One key rule is that adjacent processing steps executing on the same resource and at the same rate are grouped into a single pipeline stage. <p> These assignment rules result in low application latency, small resource buffers, and high resource utilization <ref> [5] </ref>. The maximum packet size is a configuration parameter for each I/O resource. The normalized packet period rule minimizes required buffering and eliminates unnecessary latency. This approach is necessary for the transfer of large data structures across multi-hop networks. <p> Pipeline Stage Coupling Attributes DPS i PRN i RP h k RP DPSE ij k ij DPSE ij k F ij DPSE ij k DPS i DPS j single resource timing problems <ref> [5] </ref>: stream timing check: determines if all end-to-end application timing requirements are met, assuming that all pipeline stages completed execution by their allotted local deadlines, resource schedulability check: determines if all local pipeline stage deadlines met. <p> By plugging in resource and scheduling policy-specific resource timing models, this hierarchical approach allows analysis of arbitrarily large real-time systems composed of non-ideal, heterogeneous resources, each with its own local scheduling policy. Section 5.1 augments the end-to-end latency equations in <ref> [5] </ref> for synchronization constructs and Section 5.2 examines the trade-off between algorithm complexity and accuracy for resource schedulability equations. Section 5.3 analyzes the example audio/video system. 5.1 End-to-End Latency Analysis Latency can be calculated using the following lemma. <p> Therefore, resource schedulability analysis next checks to see if this is indeed true. Chatterjee and Strosnider <ref> [5] </ref> illustrates how distributed pipeline scheduling allows a multi-resource scheduling check using single resource scheduling equations.
References-found: 5

