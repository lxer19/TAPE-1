URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/thrun/papers/thrun.SOAVE97.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/thrun/papers/full.html
Root-URL: http://www.cs.cmu.edu
Title: Probabilistic Methods for State Estimation in Robotics  
Author: Sebastian Thrun Dieter Fox Wolfram Burgard 
Web: http://www.cs.cmu.edu/~thrun  http://www.cs.uni-bonn.de/~ffox,wolframg  
Address: Pittsburgh, USA  Bonn, Bonn, Germany  
Affiliation: Computer Science Department and Robotics Institute Carnegie Mellon University,  Institut fur Informatik Universitat  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. Buhmann, W. Burgard, A. B. Cremers, D. Fox, T. Hofmann, F. Schneider, J. Strikos, and S. Thrun. </author> <title> The mobile robot RHINO. </title> <journal> AI Magazine, </journal> <volume> 16(1), </volume> <year> 1995. </year>
Reference-contexts: In our own work, we have employed probabilistic representations combined with neural network learning for various state estimation problems that predominately arose in the context of mobile robotics. For example, probabilistic state estimation played a major role in our entry at the 1994 AAAI mobile robot competition <ref> [1, 18] </ref>, where our robot "RHINO", shown in Figure 1, explored and mapped an unknown arena of approximate size 20 by 30 meter at a maximum speed of 90 cm per second.
Reference: [2] <author> W. Burgard, D. Fox, D. Hennig, and T. Schmidt. </author> <title> Estimating the absolute position of a mobile robot using position probability grids. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <address> Menlo Park, </address> <month> August </month> <year> 1996. </year> <booktitle> AAAI, </booktitle> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: in Bonn. 1 RHINO navigated safely for more than 50 hours in a frequently crowded environment at a speed of up to 80 cm per second, traversing a total distance of over 18 km while reliably avoiding collisions with various obstacles, some of which were "invisible." RHINO's probabilistic localization methods <ref> [2, 3] </ref> provided it with reliable position estimates, which was essential for the robustness of the entire approach. <p> For each action command a do: P (~) P (~j ~ ~; a) P ( ~ ~) d ~ ~ (8) Most existing probabilistic state estimation methods are variants of this basic algorithmic scheme (see e.g., <ref> [2, 5, 6, 7, 8, 9, 11, 13, 15, 14] </ref>), some of which date back to the early sixties. As apparent from this incremental rule, three probabilities must be known for probabilistic state estimation: 1. The initial probability P (~), also called a prior. 2. <p> Hierarchical representations, which possess different resolutions at different levels of abstraction, are other, often elegant ways of selectively updating the internal belief. In RHINO's approach to localization <ref> [2, 3] </ref>, large subspaces are quickly eliminated once the robot roughly knows its heading direction relative to the environment. For state spaces of size 3 10 6 or larger, this quickly reduces the update time by an order of magnitude or more.
Reference: [3] <author> W. Burgard, D. Fox, and S. Thrun. </author> <title> Active mobile robot localization. </title> <booktitle> In Proceedings of IJCAI-97. IJCAI, </booktitle> <publisher> Inc., </publisher> <year> 1997. </year> <note> (to appear). </note>
Reference-contexts: in Bonn. 1 RHINO navigated safely for more than 50 hours in a frequently crowded environment at a speed of up to 80 cm per second, traversing a total distance of over 18 km while reliably avoiding collisions with various obstacles, some of which were "invisible." RHINO's probabilistic localization methods <ref> [2, 3] </ref> provided it with reliable position estimates, which was essential for the robustness of the entire approach. <p> Hierarchical representations, which possess different resolutions at different levels of abstraction, are other, often elegant ways of selectively updating the internal belief. In RHINO's approach to localization <ref> [2, 3] </ref>, large subspaces are quickly eliminated once the robot roughly knows its heading direction relative to the environment. For state spaces of size 3 10 6 or larger, this quickly reduces the update time by an order of magnitude or more.
Reference: [4] <author> A. Elfes. </author> <title> Sonar-based real-world mapping and navigation. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> PA-3(3):249-265, </volume> <month> June </month> <year> 1987. </year>
Reference-contexts: A second way to stipulate such assumptions is to factorize the state space, which amounts to partitioning the state space into multiple, smaller components, which are then estimated independently. For example, in RHINO's map learning approach, maps are represented by discrete occupancy grids <ref> [4, 10] </ref>. Maps of size 50 by 50 meter represented with a spatial resolution of 15 cm contain approximately 100; 000 values. The corresponding state space consists of 2 100;000 states, which means that more values are needed to specify P (~) than there are atoms in the universe.
Reference: [5] <author> L.P. Kaelbling, A.R. Cassandra, and J.A. Kurien. </author> <title> Acting under uncertainty: Discrete bayesian models for mobile-robot navigation. </title> <booktitle> In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, </booktitle> <year> 1996. </year>
Reference-contexts: For each action command a do: P (~) P (~j ~ ~; a) P ( ~ ~) d ~ ~ (8) Most existing probabilistic state estimation methods are variants of this basic algorithmic scheme (see e.g., <ref> [2, 5, 6, 7, 8, 9, 11, 13, 15, 14] </ref>), some of which date back to the early sixties. As apparent from this incremental rule, three probabilities must be known for probabilistic state estimation: 1. The initial probability P (~), also called a prior. 2.
Reference: [6] <author> R. E. </author> <title> Kalman. A new approach to linear filtering and prediction problems. </title> <journal> Trans. ASME, Journal of Basic Engineering, </journal> <volume> 82 </volume> <pages> 35-45, </pages> <year> 1960. </year>
Reference-contexts: For each action command a do: P (~) P (~j ~ ~; a) P ( ~ ~) d ~ ~ (8) Most existing probabilistic state estimation methods are variants of this basic algorithmic scheme (see e.g., <ref> [2, 5, 6, 7, 8, 9, 11, 13, 15, 14] </ref>), some of which date back to the early sixties. As apparent from this incremental rule, three probabilities must be known for probabilistic state estimation: 1. The initial probability P (~), also called a prior. 2.
Reference: [7] <author> S. Koenig and R. Simmons. </author> <title> Passive distance learning for robot navigation. </title> <editor> In L. Saitta, editor, </editor> <booktitle> Proceedings of the Thirteenth International Conference on Machine Learning, </booktitle> <year> 1996. </year>
Reference-contexts: For each action command a do: P (~) P (~j ~ ~; a) P ( ~ ~) d ~ ~ (8) Most existing probabilistic state estimation methods are variants of this basic algorithmic scheme (see e.g., <ref> [2, 5, 6, 7, 8, 9, 11, 13, 15, 14] </ref>), some of which date back to the early sixties. As apparent from this incremental rule, three probabilities must be known for probabilistic state estimation: 1. The initial probability P (~), also called a prior. 2.
Reference: [8] <author> D. Kortenkamp and T. Weymouth. </author> <title> Topological mapping for mobile robots using a combination of sonar and vision sensing. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 979-984, </pages> <address> Menlo Park, July 1994. </address> <publisher> AAAI, AAAI Press/MIT Press. </publisher>
Reference-contexts: For each action command a do: P (~) P (~j ~ ~; a) P ( ~ ~) d ~ ~ (8) Most existing probabilistic state estimation methods are variants of this basic algorithmic scheme (see e.g., <ref> [2, 5, 6, 7, 8, 9, 11, 13, 15, 14] </ref>), some of which date back to the early sixties. As apparent from this incremental rule, three probabilities must be known for probabilistic state estimation: 1. The initial probability P (~), also called a prior. 2.
Reference: [9] <author> J.J. Leonard, H.F. Durrant-Whyte, and I.J. Cox. </author> <title> Dynamic map building for an autonomous mobile robot. </title> <journal> International Journal of Robotics Research, </journal> <volume> 11(4) </volume> <pages> 89-96, </pages> <year> 1992. </year>
Reference-contexts: For each action command a do: P (~) P (~j ~ ~; a) P ( ~ ~) d ~ ~ (8) Most existing probabilistic state estimation methods are variants of this basic algorithmic scheme (see e.g., <ref> [2, 5, 6, 7, 8, 9, 11, 13, 15, 14] </ref>), some of which date back to the early sixties. As apparent from this incremental rule, three probabilities must be known for probabilistic state estimation: 1. The initial probability P (~), also called a prior. 2.
Reference: [10] <author> H. P. Moravec. </author> <title> Sensor fusion in certainty grids for mobile robots. </title> <journal> AI Magazine, </journal> <pages> pages 61-74, </pages> <month> Summer </month> <year> 1988. </year>
Reference-contexts: A second way to stipulate such assumptions is to factorize the state space, which amounts to partitioning the state space into multiple, smaller components, which are then estimated independently. For example, in RHINO's map learning approach, maps are represented by discrete occupancy grids <ref> [4, 10] </ref>. Maps of size 50 by 50 meter represented with a spatial resolution of 15 cm contain approximately 100; 000 values. The corresponding state space consists of 2 100;000 states, which means that more values are needed to specify P (~) than there are atoms in the universe.
Reference: [11] <author> I. Nourbakhsh, R. Powers, and S. Birchfield. </author> <title> DERVISH an office-navigating robot. </title> <journal> AI Magazine, </journal> <volume> 16(2) </volume> <pages> 53-60, </pages> <month> Summer </month> <year> 1995. </year>
Reference-contexts: For each action command a do: P (~) P (~j ~ ~; a) P ( ~ ~) d ~ ~ (8) Most existing probabilistic state estimation methods are variants of this basic algorithmic scheme (see e.g., <ref> [2, 5, 6, 7, 8, 9, 11, 13, 15, 14] </ref>), some of which date back to the early sixties. As apparent from this incremental rule, three probabilities must be known for probabilistic state estimation: 1. The initial probability P (~), also called a prior. 2.
Reference: [12] <author> J. Pearl. </author> <title> Probabilistic reasoning in intelligent systems: networks of plausible inference. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: The reader interested in the technical details of the abovementioned work is referred to the various articles references in this paper. 2 A Brief Tutorial On Probabilistic State Estimation How does probabilistic state estimation work? The basic scheme is simple and easily implemented (see, e.g., <ref> [12] </ref>). Suppose we are interested in estimating a certain state variable, denoted by ~. Let us assume that ~ is not directly observable; Instead, the system is equipped with sensors whose measurements (denoted by s) merely depend on ~. <p> way to reduce complexity is to stip ulate assumptions that multiple aspects of the state are independent of each other, or can be seen, most of the interior has been mapped with high certainty, while some of the outer walls require more sensor evidence. conditionally independent given certain other information <ref> [12] </ref>. An example of such an assumption can readily be found above: the Markov assumption, which specifies temporal conditional independence of sensor measurements given the state.
Reference: [13] <author> L. R. Rabiner. </author> <title> A tutorial on hidden markov models and selected applications in speech recognition. </title> <booktitle> In Proceedings of the IEEE. IEEE, 1989. IEEE Log Number 8825949. </booktitle>
Reference-contexts: For each action command a do: P (~) P (~j ~ ~; a) P ( ~ ~) d ~ ~ (8) Most existing probabilistic state estimation methods are variants of this basic algorithmic scheme (see e.g., <ref> [2, 5, 6, 7, 8, 9, 11, 13, 15, 14] </ref>), some of which date back to the early sixties. As apparent from this incremental rule, three probabilities must be known for probabilistic state estimation: 1. The initial probability P (~), also called a prior. 2.
Reference: [14] <author> R. Simmons and S. Koenig. </author> <title> Probabilistic robot navigation in partially observable environments. </title> <booktitle> In Proceedings of IJCAI-95, </booktitle> <pages> pages 1080-1087, </pages> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year> <title> IJCAI, </title> <publisher> Inc. </publisher>
Reference-contexts: For each action command a do: P (~) P (~j ~ ~; a) P ( ~ ~) d ~ ~ (8) Most existing probabilistic state estimation methods are variants of this basic algorithmic scheme (see e.g., <ref> [2, 5, 6, 7, 8, 9, 11, 13, 15, 14] </ref>), some of which date back to the early sixties. As apparent from this incremental rule, three probabilities must be known for probabilistic state estimation: 1. The initial probability P (~), also called a prior. 2.
Reference: [15] <author> R. C. Smith and P. Cheeseman. </author> <title> On the representation and estimation of spatial uncertainty. </title> <type> Technical Report TR 4760 & 7239, </type> <institution> SRI, </institution> <year> 1985. </year>
Reference-contexts: For each action command a do: P (~) P (~j ~ ~; a) P ( ~ ~) d ~ ~ (8) Most existing probabilistic state estimation methods are variants of this basic algorithmic scheme (see e.g., <ref> [2, 5, 6, 7, 8, 9, 11, 13, 15, 14] </ref>), some of which date back to the early sixties. As apparent from this incremental rule, three probabilities must be known for probabilistic state estimation: 1. The initial probability P (~), also called a prior. 2.
Reference: [16] <author> S. Thrun. </author> <title> Exploration and model building in mobile robot domains. </title> <editor> In E. Ruspini, editor, </editor> <booktitle> Proceedings of the ICNN-93, </booktitle> <pages> pages 175-180, </pages> <address> San Francisco, CA, </address> <month> March </month> <year> 1993. </year> <institution> IEEE Neural Network Council. </institution>
Reference-contexts: In our work, we have applied neural network learning to the problem of filtering sensor data. For example, RHINO's approach to map learning <ref> [16, 18] </ref> employs artificial neural networks for modeling P (~js) | a quantity that is closely related to P (sj~). P (~js) specifies the probability that a certain grid cell is occupied given a sonar sensor scan.
Reference: [17] <author> S. Thrun. </author> <title> A bayesian approach to landmark discovery and active perception for mobile robot navigation. </title> <type> Technical Report CMU-CS-96-122, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <address> Pittsburgh, PA 15213, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: Probabilistic representations also played a key role in BaLL <ref> [17] </ref>, an algorithm 1 This work was carried out jointly with Dirk Hahnel, Dirk Schulz, and Wolli Steiner from the Institut fur In-formatik of the Universitat Bonn. See http://www.cs.uni-bonn.de/~RHINO/tourguide/ for further information. that enables a robot to discover optimal landmarks for navigation, and to learn neural networks for their recognition. <p> Figure 4 provides examples of probabilities generated by the networks after training. The darker a value in the circular region around the robot, the higher the probability that the corresponding grid cell is occupied. In a second approach, BaLL <ref> [17] </ref>, neural network learning was employed to map high-dimensional data into low-dimensional spaces, so that this low-dimensional data can be used to model P (sj~).
Reference: [18] <author> S. Thrun, A. Bucken, W. Burgard, D. Fox, T. Frohlinghaus, D. Hennig, T. Hofmann, M. Krell, and T. Schimdt. </author> <title> Map learning and high-speed navigation in RHINO. </title> <editor> In D. Ko-rtenkamp, R.P. Bonasso, and R. Murphy, editors, </editor> <title> AI-based Mobile Robots: Case studies of successful robot systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <note> to appear. </note>
Reference-contexts: In our own work, we have employed probabilistic representations combined with neural network learning for various state estimation problems that predominately arose in the context of mobile robotics. For example, probabilistic state estimation played a major role in our entry at the 1994 AAAI mobile robot competition <ref> [1, 18] </ref>, where our robot "RHINO", shown in Figure 1, explored and mapped an unknown arena of approximate size 20 by 30 meter at a maximum speed of 90 cm per second. <p> In our work, we have applied neural network learning to the problem of filtering sensor data. For example, RHINO's approach to map learning <ref> [16, 18] </ref> employs artificial neural networks for modeling P (~js) | a quantity that is closely related to P (sj~). P (~js) specifies the probability that a certain grid cell is occupied given a sonar sensor scan.
References-found: 18

