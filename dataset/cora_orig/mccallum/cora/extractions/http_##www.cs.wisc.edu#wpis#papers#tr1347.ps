URL: http://www.cs.wisc.edu/wpis/papers/tr1347.ps
Refering-URL: http://www.cs.wisc.edu/wpis/papers/
Root-URL: http://www.cs.wisc.edu
Title: Maximal-Munch Tokenization in Linear Time  
Author: THOMAS REPS 
Keyword: General Terms: Algorithms, Theory Additional Key Words and Phrases: memoization, tabulation, tokenization  
Affiliation: University of Wisconsin  
Abstract: The lexical-analysis (or scanning) phase of a compiler attempts to partition the input stream into a sequence of tokens. The convention in most languages is that the input is scanned left to right, and each token identified is a maximal munch of the remaining inputthe longest prefix of the remaining input that is a token of the language. Most textbooks on compiling have extensive discussions of lexical analysis in terms of finite-state automata and regular expressions: Token classes are defined by a set of regular expressions R i , 1 i k, and the lexical analyzer is based on some form of finite-state automaton for recognizing the language L (R 1 + R 2 + . . . + R k ). However, the treatment is unsatisfactory in one respect: The theory of finite-state automata assumes that the end of the input stringi.e., the right-hand-side boundary of the candidate for recognitionis known a priori, whereas a scanner must identify the next token without knowing a definite bound on the extent of the token. Although most of the standard compiler textbooks discuss this issue, the solution they sketch out is one thatfor certain sets of token definitionscan cause the scanner to exhibit quadratic behavior in the worst case. This property is not only dissatisfying, it blemishes an otherwise elegant treatment of lexical analysis. In this paper, we rectify this defect: We show that, given a deterministic finite-state automaton that recognizes the tokens of a language, maximal-munch tokenization can always be performed in time linear in the size of the input. CR Categories and Subject Descriptors: D.3.1 [Programming Languages]: Formal Definitions and Theory syntax; D.3.4 [Programming Languages]: Processors compilers; F.1.1 [Computation by Abstract Devices]: Models of Computation automata; F.2.2 [Analysis of Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problems pattern matching; I.2.8 [Artificial Intelligence]: Problem Solving, Control Methods, and Search backtracking, dynamic programming; I.5.4 [Pattern Recognition]: Applications text processing 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Aho, A.V., Hopcroft, J.E., and Ullman, J.D., </author> <title> The Design and Analysis of Computer Algorithms, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA (1974). </address>
Reference-contexts: mark on a WORM tape), or else as a variant of the standard (quadratic-time) backtracking algorithm [2,15,3,8,16] that uses a stackand explicit pushes, pops, and a test for whether the popped state is a final stateto implement an explicit search for the most recent final state. - 7 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh <ref> [1] </ref> procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i <p> F do [20] [22] i := i - 1 [23] if q = Bottom then [24] return Failure: tokenization not possible [25] fi [27] print (i - 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] reset the stack to empty [32] pool [33] end <ref> [1] </ref> procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom) /*
Reference: 2. <author> Aho, A.V. and Ullman, J.D., </author> <title> Principles of Compiler Design, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA (1977). </address>
Reference-contexts: If the last DFA state to include a final NFA state in fact includes more than one final state, then the final state for the pattern listed first has priority <ref> [2, pp. 109-110] </ref>. <p> Bottom-, where Bottom is a special bottom-of-stack symbol.) Thus, the stack records a trace of the progress of M. g The trace of M recorded on the stack is used to implement the phase of review [ing] the states of the DFA which we have entered while processing the input <ref> [2] </ref>, which is also carried out by the standard backtracking algorithm for tokenization. (Note, however, that the standard algorithm need not use a stack to carry out this review: As the input is scanned, it merely has to maintain a pair of variables, say last_final_state_position and last_final_state, to record the position <p> variant of the standard (quadratic-time) backtracking algorithm [2,15,3,8,16] that uses a stackand explicit pushes, pops, and a test for whether the popped state is a final stateto implement an explicit search for the most recent final state. - 7 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) <ref> [2] </ref> let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] [15] push (q) [16] q <p> [23] if q = Bottom then [24] return Failure: tokenization not possible [25] fi [27] print (i - 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] reset the stack to empty [32] pool [33] end [1] procedure Tokenize (M : DFA, input : string) <ref> [2] </ref> let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) <p> However, lexical-analysis tools such as Lex are often used for tasks outside the domain of compilation. For example, Aho and Ullman mention the use of Lex to recognize imperfections in printed circuits <ref> [2] </ref>. Some of these nonstandard applications may represent situations in which the algorithms presented in this paper could be of importance. The lexical analysis of spoken natural language might be another such application.
Reference: 3. <author> Aho, A.V., Sethi, R., and Ullman, J.D., </author> <booktitle> Compilers: Principles, Techniques, and Tools, </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA (1986). </address>
Reference-contexts: Second, we continue making transitions until we reach termination. Upon termination, we retract the forward pointer to the position at which the last match occurred. The pattern making this match identifies the token found, and the lexeme matched is the string between the lexeme-beginning and forward pointers <ref> [3, pp. 104] </ref>. The discussions of the problem given in Waite and Goos [15], Fischer and LeBlanc [8], and Wilhelm and - 3 - Maurer [16] are similar. <p> Compiler efficiency is improved . . . [and] compiler portability is enhanced <ref> [3, pp. 84-85] </ref>. - 4 - know that using Mogensen's construction, this can be converted into a linear-time RAM program for tokenization. (ii) In Section 2, we do not actually give the details of the program that results from Mogensen's construction. <p> explicit pushes, pops, and a test for whether the popped state is a final stateto implement an explicit search for the most recent final state. - 7 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in <ref> [3] </ref> begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 <p> [25] fi [27] print (i - 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] reset the stack to empty [32] pool [33] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in <ref> [3] </ref> begin [4] for each q Q and i [1..length (input)] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] and failed_previously
Reference: 4. <author> Aho, </author> <title> A.V., Algorithms for finding patterns in strings, pp. 255-300 in Handbook of Theoretical Computer Science, Volume A: Algorithms and Complexity, </title> <editor> ed. J. </editor> <publisher> van Leeuwen,The M.I.T. Press, </publisher> <address> Cambridge, MA (1990). </address>
Reference-contexts: pops, and a test for whether the popped state is a final stateto implement an explicit search for the most recent final state. - 7 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin <ref> [4] </ref> [6] [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack <p> [27] print (i - 1) [28] if i &gt; length (input) then [29] return Success [30] fi [31] reset the stack to empty [32] pool [33] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin <ref> [4] </ref> for each q Q and i [1..length (input)] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] and failed_previously [q,i] [14]
Reference: 5. <author> Andersen, N. and Jones, </author> <title> N.D, Generalizing Cook's transformation to imperative stack programs, pp. </title> <booktitle> 1-18 in Results and Trends in Theoretical Computer Science, Lecture Notes in Computer Science, </booktitle> <volume> Vol. 812, </volume> <editor> ed. J. Karhuma .. ki, H. Maurer, and G. Rozenberg,Springer-Verlag, </editor> <address> New York, NY (1994). </address>
Reference-contexts: In contrast, Jones's technique only considers (and tabulates) transitions for stack configurations that the 2DPDA being simulated would also reach. Jones's approach was further extended to a language of stack-manipulation programs by Andersen and Jones <ref> [5] </ref>. In their work, they showed how each program in the language could be compiled to a program that runs in linear-time (where the program contains code to tabulate transition information for the configurations that it encounters). <p> (input) then [29] return Success [30] fi [31] reset the stack to empty [32] pool [33] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)] do <ref> [5] </ref> failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] and failed_previously [q,i] [14] do [15] push (q) [16] q := d (q, input
Reference: 6. <author> Cook, S.A., </author> <title> Linear time simulation of deterministic two-way pushdown automata, pp. </title> <booktitle> 172-179 in Information Processing 71: Proceedings of the IFIP Congress 71, </booktitle> <publisher> ed. C.V. </publisher> <address> Freiman,North-Holland, Amsterdam (1972). </address> - <month> 12 </month> - 
Reference-contexts: We make use of a result due to Mogensen [14], extending an earlier result by Cook <ref> [6] </ref>, that a certain variant of a two-way deterministic pushdown automaton (a so-called WORM-2DPDA) can be simulated in linear time on a RAM computer (even though the WORM-2DPDA itself may perform many more than a linear number of steps). <p> An Indirect Solution Based on Simulation of WORM-2DPDAs This section presents a somewhat indirect method for obtaining a linear-time solution to the maximal-munch tokenization problem. It makes use of a result due to Mogensen [14], extending an earlier result by Cook <ref> [6] </ref>, that a certain variant of a two-way deterministic pushdown automaton (2DPDA) can be simulated in linear time on a RAM computer (even though the 2DPDA itself may perform many more than a linear number of steps). <p> and a test for whether the popped state is a final stateto implement an explicit search for the most recent final state. - 7 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] <ref> [6] </ref> [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to <p> [30] fi [31] reset the stack to empty [32] pool [33] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)] do [5] failed_previously [q,i] := false <ref> [6] </ref> od [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] and failed_previously [q,i] [14] do [15] push (q) [16] q := d (q, input [i ]) [17] i :=
Reference: 7. <author> DeRemer, F.L., </author> <title> Lexical analysis, pp. 109-120 in Compiler Construction: An Advanced Course, </title> <editor> ed. F.L. Bauer and J. Eickel,Springer-Verlag, </editor> <address> New York, NY (1974). </address>
Reference: 8. <author> Fischer, C.N. and LeBlanc, </author> <title> R.J., Crafting a Compiler, </title> <publisher> Benjamin/Cummings Publishing Company, Inc., </publisher> <address> Menlo Park, CA (1988). </address>
Reference-contexts: The pattern making this match identifies the token found, and the lexeme matched is the string between the lexeme-beginning and forward pointers [3, pp. 104]. The discussions of the problem given in Waite and Goos [15], Fischer and LeBlanc <ref> [8] </ref>, and Wilhelm and - 3 - Maurer [16] are similar. <p> a test for whether the popped state is a final stateto implement an explicit search for the most recent final state. - 7 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] <ref> [8] </ref> loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the <p> [31] reset the stack to empty [32] pool [33] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)] do [5] failed_previously [q,i] := false [6] od <ref> [8] </ref> loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] and failed_previously [q,i] [14] do [15] push (q) [16] q := d (q, input [i ]) [17] i := i +
Reference: 9. <author> Hopcroft, J.E. and Ullman, J.D., </author> <title> Introduction to Automata Theory, Languages, and Computation, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA (1979). </address>
Reference-contexts: We assume that we are given a deterministic finite-state automaton (DFA) M such that L (M) = L (R 1 + R 2 + . . . + R k ). We make use of standard notation for DFAs (e.g., see <ref> [9] </ref>). That is, a DFA M is a five-tuple Q, S, d, q 0 , F, where - Q is a finite nonempty set of states. <p> for whether the popped state is a final stateto implement an explicit search for the most recent final state. - 7 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop <ref> [9] </ref> q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent <p> the stack to empty [32] pool [33] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)] do [5] failed_previously [q,i] := false [6] od [8] loop <ref> [9] </ref> q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] and failed_previously [q,i] [14] do [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /*
Reference: 10. <author> Jones, </author> <title> N.D., A note on linear time simulation of deterministic two-way pushdown automata, </title> <note> Information Processing Letters 6(4) pp. </note> <month> 110-112 (August </month> <year> 1977). </year>
Reference-contexts: to take shortcuts that, in essence, allow it to skip the second and successive repetitions of these computation sequences and proceed directly to a configuration further along in the computation.) Cook's result was extended by Jones, who gave an alternative 2DPDA simulation method that tabulates configuration transitions on-line, at run-time <ref> [10, 13] </ref>. This technique is similar to the technique of memoization of function calls in functional programs. Because the Cook construction tabulates configuration transitions off-line, it considers transitions for stack configurations that are not reachable from the initial configuration (and thus are ones that the 2DPDA would never enter). <p> is a final stateto implement an explicit search for the most recent final state. - 7 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 <ref> [10] </ref> push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent final state */ [19] while <p> pool [33] end [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 <ref> [10] </ref> push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] and failed_previously [q,i] [14] do [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent
Reference: 11. <author> Knuth, D.E., Morris, J.H., and Pratt, </author> <title> V.R., Fast pattern matching in strings, </title> <note> SIAM J. Computing 6(2) pp. </note> <month> 323-350 </month> <year> (1977). </year>
Reference-contexts: for the most recent final state. - 7 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ <ref> [11] </ref> while i length (input) [12] and d (q, input [i ]) is defined [13] [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent final state */ [19] while q / F do [20] [22] i := <p> DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ <ref> [11] </ref> while i length (input) [12] and d (q, input [i ]) is defined [13] and failed_previously [q,i] [14] do [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent final state */ [19] while q / F
Reference: 12. <author> Lesk, </author> <title> M.E., Lex A lexical analyzer generator, </title> <institution> Comp. Sci. </institution> <type> Tech. Rep. 39, </type> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, NJ (October 1975). </address>
Reference-contexts: The 1986 book by Aho, Sethi, and Ullman discusses the issue in the context of the design of the lexical analyzer generator Lex <ref> [12] </ref>, under the assumption that the lexical analyzer generated will simulate an NFA, rather than first convert the NFA to a DFA: To simulate this NFA we can use [an algorithm that] ensures that the combined NFA recognizes the longest prefix of the input that is matched by a pattern. <p> state. - 7 - hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh [1] procedure Tokenize (M : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) <ref> [12] </ref> and d (q, input [i ]) is defined [13] [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent final state */ [19] while q / F do [20] [22] i := i - 1 [23] if <p> let Q, S, d, q 0 , F = M in [3] begin [4] for each q Q and i [1..length (input)] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) <ref> [12] </ref> and d (q, input [i ]) is defined [13] and failed_previously [q,i] [14] do [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent final state */ [19] while q / F do [20] failed_previously [q,i] :=
Reference: 13. <author> Mehlhorn, K., </author> <title> Data Structures and Algorithms 1: Sorting and Searching, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin (1984). </address>
Reference-contexts: to take shortcuts that, in essence, allow it to skip the second and successive repetitions of these computation sequences and proceed directly to a configuration further along in the computation.) Cook's result was extended by Jones, who gave an alternative 2DPDA simulation method that tabulates configuration transitions on-line, at run-time <ref> [10, 13] </ref>. This technique is similar to the technique of memoization of function calls in functional programs. Because the Cook construction tabulates configuration transitions off-line, it considers transitions for stack configurations that are not reachable from the initial configuration (and thus are ones that the 2DPDA would never enter). <p> : DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined <ref> [13] </ref> [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent final state */ [19] while q / F do [20] [22] i := i - 1 [23] if q = Bottom then [24] return Failure: tokenization not <p> M in [3] begin [4] for each q Q and i [1..length (input)] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined <ref> [13] </ref> and failed_previously [q,i] [14] do [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent final state */ [19] while q / F do [20] failed_previously [q,i] := true [21] q := pop () [23] if q <p> The added code (lines [4]-[6], <ref> [13] </ref>, and [20], which are indicated in Helvetica-Bold typeface in Figure 1 (b)) tabulates which pairs of states and index positions that were previously encountered failed to lead to the identification of a longer token. <p> This information is gathered at the time states are popped off the stack (line [20]), and used during the scanning loop to determine whether the current configuration is known to be unproductive (line <ref> [13] </ref>). More precisely, the algorithm shown in Figure 1 (b) carries out the same process as Figure 1 (a), except that it uses a two-dimensional table, failed_previously [q,i ], to tabulate previously encountered pairs of states and index positions that failed to lead to the identification of a longer token. <p> By consulting this table on line <ref> [13] </ref> of the scanning loop (lines [11]-[18]) the algorithm keeps track ofand avoids repeating fruitless searches of the input text. <p> Because the algorithm repeatedly identifies the last character of the longest prefix of the remaining input that is a token, a pair q,i for which failed_previously [q,i ] is true on line <ref> [13] </ref> must represent a failed previous search that started from position i in state q. Hence, it would be unproductive to make another search from position i in state q. For this reason, the algorithm exits the scanning loop and switches to backtrack mode. <p> The test on line <ref> [13] </ref> of Figure 1 (b) represents a new condition under which the machine shifts from forward mode to backtrack mode.
Reference: 14. <author> Mogensen, T., WORM-2DPDAs: </author> <title> An extension to 2DPDAs that can be simulated in linear time, </title> <note> Information Processing Letters 52 pp. </note> <month> 15-22 </month> <year> (1994). </year>
Reference-contexts: Both techniques rely on tabulation (or memoization) to avoid repeating work that is known not to lead to the identification of a new token: (i) In Section 2, we obtain a linear-time algorithm by a somewhat indirect method. We make use of a result due to Mogensen <ref> [14] </ref>, extending an earlier result by Cook [6], that a certain variant of a two-way deterministic pushdown automaton (a so-called WORM-2DPDA) can be simulated in linear time on a RAM computer (even though the WORM-2DPDA itself may perform many more than a linear number of steps). <p> An Indirect Solution Based on Simulation of WORM-2DPDAs This section presents a somewhat indirect method for obtaining a linear-time solution to the maximal-munch tokenization problem. It makes use of a result due to Mogensen <ref> [14] </ref>, extending an earlier result by Cook [6], that a certain variant of a two-way deterministic pushdown automaton (2DPDA) can be simulated in linear time on a RAM computer (even though the 2DPDA itself may perform many more than a linear number of steps). <p> Using the compilation approach, Mogensen showed how to obtain linear-time programs for a variant of 2DPDAs that are equipped with one or more auxiliary write-once, read-many tapes, whence the name WORM-2DPDAs <ref> [14] </ref>. The WORM tapes provide WORM-2DPDAs with a limited form of auxiliary storage. They represent a limited form of auxiliary storage because the following restrictions apply: (i) The WORM tapes can be thought of as being a kind of writable store that is parallel to the input tape. <p> [4] for each q Q and i [1..length (input)] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] and failed_previously [q,i] <ref> [14] </ref> do [15] push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent final state */ [19] while q / F do [20] failed_previously [q,i] := true [21] q := pop () [23] if q = Bottom then [24]
Reference: 15. <author> Waite, W.M. and Goos, G., </author> <title> Compiler Construction, </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY (1983). </address>
Reference-contexts: The pattern making this match identifies the token found, and the lexeme matched is the string between the lexeme-beginning and forward pointers [3, pp. 104]. The discussions of the problem given in Waite and Goos <ref> [15] </ref>, Fischer and LeBlanc [8], and Wilhelm and - 3 - Maurer [16] are similar. <p> DFA, input : string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] <ref> [15] </ref> push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent final state */ [19] while q / F do [20] [22] i := i - 1 [23] if q = Bottom then [24] return Failure: tokenization not possible <p> each q Q and i [1..length (input)] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] and failed_previously [q,i] [14] do <ref> [15] </ref> push (q) [16] q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent final state */ [19] while q / F do [20] failed_previously [q,i] := true [21] q := pop () [23] if q = Bottom then [24] return Failure: <p> Whether this technique solves all prob lems is still an open question <ref> [15, pp. 138-139] </ref>. The solutions given in the present paper are based on a different principle; rather than permitting the state to be retained from the last invocation, they rely on tabulation to avoid repeating work.
Reference: 16. <author> Wilhelm, R. and Maurer, D., </author> <title> Compiler Design (English Edition), </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA (1995). </address>
Reference-contexts: The pattern making this match identifies the token found, and the lexeme matched is the string between the lexeme-beginning and forward pointers [3, pp. 104]. The discussions of the problem given in Waite and Goos [15], Fischer and LeBlanc [8], and Wilhelm and - 3 - Maurer <ref> [16] </ref> are similar. <p> string) [2] let Q, S, d, q 0 , F = M in [3] begin [4] [6] [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] [15] push (q) <ref> [16] </ref> q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent final state */ [19] while q / F do [20] [22] i := i - 1 [23] if q = Bottom then [24] return Failure: tokenization not possible [25] fi [27] <p> and i [1..length (input)] do [5] failed_previously [q,i] := false [6] od [8] loop [9] q := q 0 [10] push (Bottom) /* Scan for tokens */ [11] while i length (input) [12] and d (q, input [i ]) is defined [13] and failed_previously [q,i] [14] do [15] push (q) <ref> [16] </ref> q := d (q, input [i ]) [17] i := i + 1 /* Backtrack to the most recent final state */ [19] while q / F do [20] failed_previously [q,i] := true [21] q := pop () [23] if q = Bottom then [24] return Failure: tokenization not possible
References-found: 16

