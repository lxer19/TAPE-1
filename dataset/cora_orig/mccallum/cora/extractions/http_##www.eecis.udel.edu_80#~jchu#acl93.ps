URL: http://www.eecis.udel.edu:80/~jchu/acl93.ps
Refering-URL: http://www.eecis.udel.edu:80/~jchu/
Root-URL: http://www.cis.udel.edu
Email: Internet: jchu@cis.udel.edu  
Title: RESPONDING TO USER QUERIES IN A COLLABORATIVE ENVIRONMENT  
Author: Jennifer Chu 
Address: 19716, USA  
Affiliation: Department of Computer and Information Sciences University of Delaware Newark, DE  
Abstract: We propose a plan-based approach for responding to user queries in a collaborative environment. We argue that in such an environment, the system should not accept the user's query automatically, but should consider it a proposal open for negotiation. In this paper we concentrate on cases in which the system and user disagree, and discuss how this disagreement can be detected, negotiated, and how final modifications should be made to the existing plan.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> James Allen. </author> <title> Discourse structure in the TRAINS project. </title> <booktitle> In Darpa Speech and Natural Language Workshop, </booktitle> <year> 1991. </year>
Reference-contexts: Note that our model accounts for why the user's original question about the instructor of CS689 is never answered a conflict was detected that made the question superfluous. 5 Related Work Several researchers have studied collaboration <ref> [1, 3, 10] </ref> and Allen proposed different plan modalities depending on whether a plan fragment is shared, proposed and acknowledged, or merely private [1]. <p> original question about the instructor of CS689 is never answered a conflict was detected that made the question superfluous. 5 Related Work Several researchers have studied collaboration [1, 3, 10] and Allen proposed different plan modalities depending on whether a plan fragment is shared, proposed and acknowledged, or merely private <ref> [1] </ref>. However, they have emphasized discourse analysis and none has provided a plan-based framework for proposal negotiation, specified appropriate system response during collaboration, or accounted for why a question might never be answered. Litman and Allen used discourse meta-plans to handle a class of correction subdialogues [7].
Reference: [2] <author> Rhonda Eller and Sandra Carberry. </author> <title> A meta-rule approach to flexible plan recognition in dialogue. User Modeling and User-Adapted Interaction, </title> <address> 2:27--53, </address> <year> 1992. </year>
Reference-contexts: Figure 1 illustrates the dialogue model that would be built after the following utterances by Lam-bert's plan recognition algorithm modified to accommodate the separation of the existing and proposed dialogue models, and augmented with a relaxation algorithm to recognize ill-formed plans <ref> [2] </ref>. U: I want to satisfy my seminar course requirement. Who's teaching CS689? 3 The Evaluator A collaborative system should only incorporate proposed actions into an existing plan if they are considered appropriate. This decision is made by the evaluator, which will be discussed in this section.
Reference: [3] <author> Barbara Grosz and Candace Sidner. </author> <title> Plans for discourse. </title> <editor> In Cohen et al., editor, </editor> <booktitle> Intentions in Communication, </booktitle> <pages> pages 417--444. </pages> <year> 1990. </year>
Reference-contexts: Note that our model accounts for why the user's original question about the instructor of CS689 is never answered a conflict was detected that made the question superfluous. 5 Related Work Several researchers have studied collaboration <ref> [1, 3, 10] </ref> and Allen proposed different plan modalities depending on whether a plan fragment is shared, proposed and acknowledged, or merely private [1].
Reference: [4] <author> Peter Heeman. </author> <title> A computational model of collaboration on referring expressions. </title> <type> Master's thesis, </type> <institution> University of Toronto, </institution> <year> 1991. </year>
Reference-contexts: Furthermore, they were only concerned with understanding utterances, not with generating appropriate responses. The work in [5, 11, 9] addressed generating cooperative responses and responding to plan-based misconceptions, but did not capture these within an overall collaborative system that must negotiate proposals with the user. Hee-man <ref> [4] </ref> used meta-plans to account for collaboration on referring expressions.
Reference: [5] <author> Aravind Joshi, Bonnie Webber, and Ralph Weischedel. </author> <title> Living up to expectations: Computing expert responses. </title> <booktitle> In Proc. AAAI, </booktitle> <pages> pages 169--175, </pages> <year> 1984. </year>
Reference-contexts: Thus their meta-plans do not handle correction of proposed additions to the dialogue model (since this generally does not involve adding a step to the proposal). Furthermore, they were only concerned with understanding utterances, not with generating appropriate responses. The work in <ref> [5, 11, 9] </ref> addressed generating cooperative responses and responding to plan-based misconceptions, but did not capture these within an overall collaborative system that must negotiate proposals with the user. Hee-man [4] used meta-plans to account for collaboration on referring expressions.
Reference: [6] <author> Lynn Lambert and Sandra Carberry. </author> <title> A tripartite plan-based model of dialogue. </title> <booktitle> In Proc. ACL, </booktitle> <pages> pages 47--54, </pages> <year> 1991. </year>
Reference-contexts: This suggests that the participants communicate their disagreements when they arise lest the agents work on developing different plans. We are extending the dialogue understanding system in <ref> [6] </ref> to include a system that responds to the user's utterances in a collaborative manner. Each utterance by a participant constitutes a proposal intended to affect the agents' shared plan. One component of our architecture, the evaluator, examines the user's proposal and decides whether to accept or reject it. <p> We show how the system determines that the user's proposed additions are erroneous and, instead of directly responding to the user's utterances, conveys the disagreement. Thus, our work contributes to an overall dialogue system by 1) extending the model in <ref> [6] </ref> to eliminate the assumption that the system will automatically answer the user's questions or follow the user's proposals, and 2) capturing the notion fl This material is based upon work supported by the National Science Foundation under Grant No. <p> IRI-9122026. of cooperative responses within an overall collaborative framework that allows for negotiation. 2 The Tripartite Model Lambert and Carberry proposed a plan-based tripartite model of expert/novice consultation dialogue which includes a domain level, a problem-solving level, and a discourse level <ref> [6] </ref>. The domain level represents the system's beliefs about the user's plan for achieving some goal in the application domain. The problem-solving level encodes the system's beliefs about how both agents are going about constructing the domain plan. The discourse level represents the system's beliefs about both agents' communicative actions. <p> The discourse level represents the system's beliefs about both agents' communicative actions. Lambert developed a plan recognition algorithm that uses contextual knowledge, world knowledge, linguistic clues, and a library of generic recipes for actions to analyze utterances and construct a dialogue model <ref> [6] </ref>. Lambert's system automatically adds to the dialogue model all actions inferred from an utterance. However, we argue that in a collaborative environment, the system should only accept the proposed additions if the system believes that they are appropriate.
Reference: [7] <author> Diane Litman and James Allen. </author> <title> A plan recognition model for subdialogues in conversation. </title> <booktitle> Cognitive Science, </booktitle> <address> 11:163--200, </address> <year> 1987. </year>
Reference-contexts: However, they have emphasized discourse analysis and none has provided a plan-based framework for proposal negotiation, specified appropriate system response during collaboration, or accounted for why a question might never be answered. Litman and Allen used discourse meta-plans to handle a class of correction subdialogues <ref> [7] </ref>. However, their Correct-Plan only addressed cases in which an agent adds a repair step to a pre-existing plan that does not execute as expected.
Reference: [8] <author> Johanna Moore and Cecile Paris. </author> <title> Planning text for advisory dialogues. </title> <booktitle> In Proc. ACL, </booktitle> <pages> pages 203--211, </pages> <year> 1989. </year>
Reference-contexts: The evaluator then decides that this pair of proposed actions would make the domain plan ill-formed. 4 When the Proposal is Erroneous The goal selector's task is to determine, based on the current dialogue model, an intentional goal <ref> [8] </ref> that is most appropriate for the system to pursue. An intentional goal could be to directly respond to the user's utterance, 1 Both applicability conditions and preconditions are prerequisites for executing a recipe.
Reference: [9] <author> Martha Pollack. </author> <title> A model of plan inference that distinguishes between the beliefs of actors and observers. </title> <booktitle> In Proc. ACL, </booktitle> <pages> pages 207--214, </pages> <year> 1986. </year>
Reference-contexts: Thus their meta-plans do not handle correction of proposed additions to the dialogue model (since this generally does not involve adding a step to the proposal). Furthermore, they were only concerned with understanding utterances, not with generating appropriate responses. The work in <ref> [5, 11, 9] </ref> addressed generating cooperative responses and responding to plan-based misconceptions, but did not capture these within an overall collaborative system that must negotiate proposals with the user. Hee-man [4] used meta-plans to account for collaboration on referring expressions.
Reference: [10] <author> Candace Sidner. </author> <title> Using discourse to negotiate in collaborative activity: </title> <booktitle> An artificial language. In Workshop Notes: AAAI-92 Cooperation Among Heterogeneous Intelligent Systems, </booktitle> <pages> pages 121--128, </pages> <year> 1992. </year>
Reference-contexts: Note that our model accounts for why the user's original question about the instructor of CS689 is never answered a conflict was detected that made the question superfluous. 5 Related Work Several researchers have studied collaboration <ref> [1, 3, 10] </ref> and Allen proposed different plan modalities depending on whether a plan fragment is shared, proposed and acknowledged, or merely private [1].
Reference: [11] <author> Peter van Beek. </author> <title> A model for generating better explanations. </title> <booktitle> In Proc. ACL, </booktitle> <pages> pages 215--220, </pages> <year> 1987. </year>
Reference-contexts: Thus their meta-plans do not handle correction of proposed additions to the dialogue model (since this generally does not involve adding a step to the proposal). Furthermore, they were only concerned with understanding utterances, not with generating appropriate responses. The work in <ref> [5, 11, 9] </ref> addressed generating cooperative responses and responding to plan-based misconceptions, but did not capture these within an overall collaborative system that must negotiate proposals with the user. Hee-man [4] used meta-plans to account for collaboration on referring expressions.
References-found: 11

