URL: http://www.isi.edu/~apoorv/thesis.ps
Refering-URL: http://www.isi.edu/~apoorv/
Root-URL: http://www.isi.edu
Title: QUANTITATIVE PIPELINE OPTIMIZATIONS FOR VLSI MICROPROCESSORS  
Author: by Apoorv Srivastava 
Degree: A Dissertation Presented to the FACULTY OF THE GRADUATE SCHOOL  In Partial Fulfillment of the Requirements for the Degree DOCTOR OF PHILOSOPHY  
Note: Copyright 1998 Apoorv Srivastava  
Date: May 1998  
Affiliation: UNIVERSITY OF SOUTHERN CALIFORNIA  (Electrical Engineering Systems)  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Abnous and N. Bagherzadeh. </author> <title> Pipelining and Bypassing in a VLIW Processor. </title> <journal> In IEEE Transactions on Parallel and Distributed Computing. </journal> <volume> 5(6), </volume> <month> June </month> <year> 1994, </year> <pages> pages 658-664. </pages>
Reference: [2] <author> Morteza Afghahi and Christer Svensson. </author> <title> Performance of Synchronous and Asynchronous Schemes for VLSI Systems. </title> <journal> In IEEE Transactions on Computer, pp. </journal> <volume> 858-872, Vol. 41, No. 7, </volume> <month> July </month> <year> 1992. </year>
Reference-contexts: Ho wever, even in perfectly balanced networks, clock skew exists. This skew is due primarily to variations in the fabrication process. Of the man y fabrication process variations, clock skew in balanced networks is due primarily to the variations in the width of the metal lines <ref> [2] </ref>. Yet another strategy is to have the skew tolerant clocking where the clock ows in the opposite or the same direction of the data [2]. (For a discussion of clock skew see Appendix E.) 2.3.3 Overcoming Control Path Limitations Control path limitations can be o vercome by adopting a simple <p> Of the man y fabrication process variations, clock skew in balanced networks is due primarily to the variations in the width of the metal lines <ref> [2] </ref>. Yet another strategy is to have the skew tolerant clocking where the clock ows in the opposite or the same direction of the data [2]. (For a discussion of clock skew see Appendix E.) 2.3.3 Overcoming Control Path Limitations Control path limitations can be o vercome by adopting a simple scheduling and interlock strategy in a microprocessor.
Reference: [3] <author> Pritpal S. Ahuja, Douglas W. Clark, and Anne Rogers. </author> <title> The Performance Impact of Incomplete Bypassing in Processor Pipelines. </title> <booktitle> In Proceedings of the 28 Annual International Symposium on Microarchitecture, </booktitle> <address> Nov. 29-Dec. 1, 1995, Ann Arbor, Michigan. </address>
Reference-contexts: 4-stage adder increase by roughly 70%, 51%, and 48%, for a single, dual, and quad-issue pipeline pro cessor. 5.5 Bypass Pipeline Depth In both single and multiple issue superpipelined processors the comple xity of the bypass network can be a critical path in determining the cycle time of the processor <ref> [3] </ref>. In this section, I study the ef fect of bypass pipeline depth on the performance. <p> In a superpipelined processors with s stages between the output of the f irst functional unit and the retiring of the instruction, there are 2 W 2 s bypass busses, where W is the issue-width and the f actor two is for 2-input functional units <ref> [3] </ref>. The output dri ver, in this model, dri ves only the capacitance of the wire. The distributed multiplexor bypass (DMB) model on the other hand scales well in area with growing number of pipeline stages and gro wing issue-width. <p> limited by the complexity of the bypass network, the design of architectures with clustered datapaths and incomplete or multi-cycle bypassing is a promising alternative to full bypassing [1]<ref> [3] </ref>. A key observation in pipelined processors is that utilization of bypass busses decreases as a function of distance from the bypass stage [3]. Reduced bypassing can therefore be implemented with marginal penalty in the number of c ycles required to execute a benchmark, and significant cycle time reduction in deeply pipelined wide-issue processors [3]. <p> in pipelined processors is that utilization of bypass busses decreases as a function of distance from the bypass stage <ref> [3] </ref>. Reduced bypassing can therefore be implemented with marginal penalty in the number of c ycles required to execute a benchmark, and significant cycle time reduction in deeply pipelined wide-issue processors [3]. Another approach is clustered datapaths, which allo w fast access to operands within the same cluster and slow access to operands across clusters.
Reference: [4] <author> Jonas Alowersson. </author> <title> A CMOS Circuit Technique for High-Speed RAMS. </title> <booktitle> In Sixth Annual IEEE International ASIC Conference and Exhibit, Sep-tember 1993, </booktitle> <pages> pages 243-246. </pages>
Reference-contexts: The timing estimates are based on Srivastavas [101], Sanos [89], and Irissous [51] study. The wordline decoder is a nor-decoder. Alowersson <ref> [4] </ref> has reported f aster decoders and senseamplifier circuits for re gister files, however, these timings are for a dual-rail read register file. The register file presented here assumes a single-ended read port.
Reference: [5] <author> D. Alpert and D. Avnon. </author> <title> Architecture of the Pentium microprocessor. </title> <booktitle> In IEEE Micro, </booktitle> <month> June </month> <year> 1993, </year> <pages> 11-21. </pages>
Reference-contexts: MIPS led the adv ent of the more streamlined microprocessors. The MIPS R3000 [55] (commercial v ersion of the MIPS-X [18]) is a streamlined 5-stage RISC processor. One of the more recent 5-stage integer pipelines is the Intel Pentium <ref> [5] </ref>. The pipeline stages are: 1. PF - Fetch and Align instruction 2. D1 - Decode Instruction, Generate Control Word 3. D2 - Decode Control Word, Generate memory address 4. E - Access data cache or Calculate ALU Result 5.
Reference: [6] <author> D.W. Anderson, F.J. Sparacio, </author> <title> and F.M. Tomasulo. The IBM System/360 Model 91: </title> <journal> Machine Philosophy and Instruction-Handling IBM Journal, </journal> <volume> vol 11, </volume> <month> January </month> <year> 1967, </year> <pages> pages 8-24. </pages>
Reference-contexts: Control path limitations. The latency of the logic needed to generate the control signals for each pipeline stage limits the minimum clock cycle time. Concerned about control path limitations, the designers of the IBM 360/91 wrote <ref> [6] </ref>: The 5 amount of control hardware and control complexity required to handle architectural and machine organization interlocks increases enormously as the number of assembly line stations is increased. <p> The IBM 360/91 employed a hierarchy of pipelines and used pipelining e xtensively. The goal was to gain an order or tw o performance improvement over the IBM 7090. The IBM 360/91 was one of the first processors to have a 13 stage pipeline <ref> [6] </ref>. The pipeline in the IBM 360/91 does not flow in lockstep, and some stages ha ve a variable latency. The cycle time objective was 60 ns. With a gate delay of 5-6 ns, the designers opted for 11 or 12 circuit levels per stage.
Reference: [7] <author> Creighton Asato. </author> <title> A 14-Port 3.8-ns 116-Word 64-b Read-Renaming Register File. </title> <journal> In IEEE Journal of Solid-State Circuits, </journal> <volume> Vol. 30, No. 11, </volume> <month> No-vember </month> <year> 1995. </year>
Reference-contexts: The wordline decoder is a nor-decoder. Alowersson [4] has reported f aster decoders and senseamplifier circuits for re gister files, however, these timings are for a dual-rail read register file. The register file presented here assumes a single-ended read port. A study by Asato reports <ref> [7] </ref> that a single-ended read reduces the area of the overall design by 20% for register files with a large number of read and write ports (10 read ports and 4 write ports). 92 Table 6.3 gives the cell timing breakdown for the register file. <p> However, they will incur a cycle time increase due to the increased complexity of the hardware. The register rename file and reorder buffer are some of the modules that add to the complexity of an out-of-order issue processor <ref> [7] </ref>. Furthermore the comple xity of the bypass network will remain unchanged for out-of-order e xecution processors.
Reference: [8] <author> T. Asprey, G.S. Averill, E. Delano, B Weiner, and J. Yetter. </author> <title> Performance Features of the PA7100 Microprocessor. </title> <booktitle> In IEEE Micro, </booktitle> <month> June </month> <year> 1993, </year> <pages> pages 22-35. </pages>
Reference-contexts: The pipeline depth for the inte ger and the load/store unit in the MIPS R10000 [39][106] is, respectively, five and six. The HP 8000 [62] has a 7-stage inte ger and a 9 stage load/store pipeline up from a 5-stage pipeline in the HP 7100 <ref> [8] </ref>. i 2 6 10 MIPS R4400 (8/10) [92] [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) <p> Examples of a 4-stage pipeline are Sparc processors and the PowerPC [40][78]. The second type performs multiple cascaded micro-operations (see Figure 3.1). A common optimization, found in man y processors (MIPS R2000 [55], MIPS R4000 [66], 24 HP PA 7100 <ref> [8] </ref>), is performing the address calculation for a memory operation and the actual load/store from memory as one instruction (Figure 3.1 (b)). A possible extension is shown in Figure 3.1 (c) where multiple micro-operations can be pipelined and packed within one instruction. <p> The 5-stage pipeline combines the 1-stage cache, a 2-stage register file, a s=2 bypass logic combined with the ALU, and a single-cycle adder. Many commercial RISC microprocessors fit this pipeline model very well; e.g. MIPS R2000/3000 pipeline [55], HP P A7100 <ref> [8] </ref>, and PowerPC 603 (load/store pipe) [78]. The 5-stages are: 1. F: Instruction Fetch Stage. The F-stage fetches the instructions from the instruction cache. 2. D: Instruction Decode Stage. The D-stage decodes and issues the fetched instruction. The stage also reads the reg ister file. 3. E: Execute Stage.
Reference: [9] <author> E. </author> <booktitle> Block.The Engineering Design of the STRETCH Computer. Proc. EJCC, </booktitle> <pages> pp 48-59. </pages> <year> 1959. </year> <month> 150 </month>
Reference: [10] <author> William J. Bowhill et. al. </author> <title> Circuit Implementation of a 300-MHz 64-bit Second-generation CMOS Alpha CPU. </title> <journal> Digital Technical Journal. </journal> <volume> Vol. 7 No. 1, </volume> <year> 1995. </year>
Reference-contexts: The Dec Alpha also implements the first level caches (8 Kbyte instruction and 8 Kbyte data) on chip. The processor has been fabricated in a specialized 0.75 mm CMOS process and operates at a clock frequenc y of 150 MHz. The Dec Alpha 21164 <ref> [10] </ref> is quad-issue second-generation Alpha fabricated in 0.5 mm CMOS, and the Dec Alpha 21264 [35][42] [57] is fabricated in 0.35 mm. They operate at a clock rate of, respecti vely, 300 MHz and 600 14 MHz. <p> driver and a pre-driver 1 account for roughly 40% of the total switching capacitance [21]<ref> [10] </ref>. The design of balanced clock netw orks is an attempt to minimize 1. The pre-driver is a buffer driving the clock driver. 18 both the wiring capacitance and the skew [52][105]. The Dec Alpha 21164 [10] uses a balanced clock network for routing the clock o ver the chip. The processor is designed in 0.5 mm CMOS and the sk ew over the chip is less than 90 ps [10]. Ho wever, even in perfectly balanced networks, clock skew exists. <p> The Dec Alpha 21164 <ref> [10] </ref> uses a balanced clock network for routing the clock o ver the chip. The processor is designed in 0.5 mm CMOS and the sk ew over the chip is less than 90 ps [10]. Ho wever, even in perfectly balanced networks, clock skew exists. This skew is due primarily to variations in the fabrication process. Of the man y fabrication process variations, clock skew in balanced networks is due primarily to the variations in the width of the metal lines [2]. <p> A two-phase clocking strategy requires the implementation of non-overlapped clocks. Intentional clock skew between the two clocks is introduced to pre vent race-through conditions. The Dec Alpha 21064 [21] and the 21164 <ref> [10] </ref> use a single phase clock logic. The addition of dynamic latches in pipelining modules (shown in Figure 6.1 (b)) adds to the propagation delay of the circuitry. As such it is part of the pipeline o verhead. <p> The multiplexors bypass the results of the functional units to respectively the A and B inputs of the function units. The second implementation (Figure 6.27 (b)) used in the Dec Alpha 21164 <ref> [10] </ref>, has a bypass bus for each input of a functional unit with the multiplexor operation physically distributed over the datapath by means of tri-stated drivers. monds are Hspice simulation results. 3.50 stages - 0.80+ 2 4 6 8 Tcycle (ns) Pipeline stages Hspice 102 The bypass busses and the bypass <p> Another approach is clustered datapaths, which allo w fast access to operands within the same cluster and slow access to operands across clusters. A similar approach has been adopted in the Dec Alpha 21264 <ref> [10] </ref> processor. 9.2.3 VLSI Technology and Clocking Another key observation has been that a tw ofold improvement in speed can be obtained by changes in the circuit design style within the same technology .
Reference: [11] <author> Allan G. Bromley. </author> <title> The Evolution of Babbages Calculating Engines. </title> <journal> Annals of the History of Computing, </journal> <volume> Volume 9, Number 2, </volume> <year> 1987, </year> <pages> pages 113-136. </pages>
Reference-contexts: Tien Chi Chen, Introduction to Computer Architecture (1980), chapter Overlap and Pipeline Processing, Stone et al. [103] 2.1 A Brief History of Pipelined Processor Design Pipelining in terms of segmenting the instruction execution was first used in Babbages Analytical Engine <ref> [11] </ref> b uilt in 1840 (see Figure 2.1). The Analytical Engine had a four - stage pipeline: fetch an operand, add or subtract an operand, con vert partial result to the sign and magnitude notation, and finally transfer result to the store.
Reference: [12] <author> Dale M. Brown, Mario Ghezzo, and Joseph M. Pimbley. </author> <title> Trends in Advanced Process Technology - Submicrometer CMOS Device Design and Process Requirements. </title> <booktitle> Proceedings of the IEEE, </booktitle> <month> December </month> <year> 1986. </year>
Reference: [13] <author> W. Bucholz, </author> <title> Planning a Computer System: Project STRETCH, </title> <publisher> McGraw-Hill, </publisher> <address> New York. </address> <year> 1962. </year>
Reference: [14] <author> M. Butler, et al. </author> <title> Single Instruction Stream Parallelism Is Greater Than Two. </title> <booktitle> Proceedings of the 18th Annual Int. Symposium on Computer Architecture, </booktitle> <month> May </month> <year> S1991. </year>
Reference: [15] <author> S.G. Campbell, P.S. Herwitz, J.H. Pomerone. </author> <title> A Nonarithmetical System Extension. In Planning a computer system: Project STRETCH, edited by W. Buchholz. </title> <publisher> McGraw-Hill, </publisher> <address> New York 1962, </address> <pages> pages 254-271. </pages>
Reference-contexts: over a broader range of parameters, and include suggestions for future work. 11 Chapter 2 Related Work The word pipeline and a sister term str eaming probably originated within the IBM STRETCH project (1954-62), whic h developed both the highly o verlapped STRETCH and the radically different 7950 Stream Processor <ref> [15] </ref>. Tien Chi Chen, Introduction to Computer Architecture (1980), chapter Overlap and Pipeline Processing, Stone et al. [103] 2.1 A Brief History of Pipelined Processor Design Pipelining in terms of segmenting the instruction execution was first used in Babbages Analytical Engine [11] b uilt in 1840 (see Figure 2.1).
Reference: [16] <author> Po-Yung Chang, Eric Hao, Yale N. Patt. </author> <title> Alternative Implementations of Hybrid Branch Predictors. </title> <booktitle> Proc. of the 28th Annual International Symposium on Microarchitecture. </booktitle> <address> Nov. 29 - Dec. 1, 1995, Ann Arbor, </address> <publisher> Michigan, </publisher> <pages> pages 252-257. </pages>
Reference-contexts: Of the various proposed prediction mechanisms, the pipeline simulator implements a h ybrid two-level hardware branch prediction mechanism 32 (see Figure 4.3). The h ybrid branch predictor is based on Chang et al. s <ref> [16] </ref>, Yeh and Patts [113][114], and McFarlings [71] studies. The hybrid branch predictor combines McF arlings gshare predictor with Yeh and Patts per-address (PAs) variation of the two-level adaptive branch predictor [71][114].
Reference: [17] <author> Alessandra Costa, Alessandro De Gloria, Paolo Faraboschi, and Mauro Olivieri. </author> <title> An Analysis of Dynamic Scheduling Techniques for Symbolic Applications. </title> <booktitle> Proceedings of the 26th Annual International Symposium on Microarchitecture, </booktitle> <month> December </month> <year> 1993, </year> <pages> pages 185-191. </pages>
Reference: [18] <author> Paul Chow and Mark Horowitz. </author> <booktitle> Architectural Tradeoffs in the Design of the MIPS-X. Communication of the ACM, </booktitle> <year> 1987. </year>
Reference-contexts: The Intel 8086 [50] is a single chip processor with a 2 and a 3-stage pipeline. MIPS led the adv ent of the more streamlined microprocessors. The MIPS R3000 [55] (commercial v ersion of the MIPS-X <ref> [18] </ref>) is a streamlined 5-stage RISC processor. One of the more recent 5-stage integer pipelines is the Intel Pentium [5]. The pipeline stages are: 1. PF - Fetch and Align instruction 2. D1 - Decode Instruction, Generate Control Word 3. D2 - Decode Control Word, Generate memory address 4. <p> Using the four abstract stages, the in-order and out-of-order behavior results in 16 possible permutations. The eight possible permutations of in-order fetch processors are: IIII, IIIO, IIOO, IIOI, IOII, IOIO, IOOO, IOOI. An example of the IIII processor is the MIPS-X <ref> [18] </ref>, and MIPS R3000 [55]. The superscalar processors belong to one of two camps. Gwennap has coined the word Brainiacs and Speed Demons to describe these camps [38]. <p> In this section, I develop a reference pipeline architecture which is based on the 4-stage abstract pipeline model (see Figure 4.4). The 5-stage pipeline model is one of the most widely used pipeline architectures. This architecture model originated from some of the early RISC processors such as the MIPS-X <ref> [18] </ref>, MIPS R2000/R3000 [70] and the DLX [46]. The five pipeline stages are: Instruction Fetch Stage (F): In the fetch stage the processor fetches instructions from the instruction memory (or instruction cache in the case of most single-chip microprocessors). In W-issue (multiple-issue) processors W instructions are fetched.
Reference: [19] <institution> Cray Research Inc. CRAY-1 Computer System, </institution> <note> No. 2240004, Blooming-ton, Minnessota 1976. </note>
Reference-contexts: The cycle time objective was 60 ns. With a gate delay of 5-6 ns, the designers opted for 11 or 12 circuit levels per stage. Attached array processor (IBM 3033 and vector processors are also examples of pipelined processor. In the class of v ector processors, the CRAY-1S <ref> [19] </ref> has a floating point pipeline depth of six stages. By the end of 1970, VLSI technology allo wed enough integration to enable the f abri-cation of f airly complex microprocessors. Of these microprocessors, the Intel 8086 13 became one of the most widely used microprocessors.
Reference: [20] <author> Alvin M. Despain. </author> <booktitle> Notes on Computer Architecture for High Performance. </booktitle> <year> 1983. </year>
Reference-contexts: This makes the constant fan-out adder well suited for implementation in CMOS. & Fishers notation [63], the adder circuit is designated by P, a subscript, k, to indicate the order of the circuit, and a superscript j to indicate the maximum permissible f anin. Despain <ref> [20] </ref> describes the order of a circuit as being related to the circuit delay , with zero order being the minimum possible in this series of circuits. A parallel prefix circuit represents a 32-bit adder with permissible fan-in of four and k 1.
Reference: [21] <author> Daniel W. Dobberpuhl et. al. </author> <title> A 200MHz 64-b Dual-Issue CMOS Microprocessor. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> Vol. 27, No. 11, </volume> <month> Novem-ber </month> <year> 1992. </year> <month> 151 </month>
Reference-contexts: A two-phase clocking strategy requires the implementation of non-overlapped clocks. Intentional clock skew between the two clocks is introduced to pre vent race-through conditions. The Dec Alpha 21064 <ref> [21] </ref> and the 21164 [10] use a single phase clock logic. The addition of dynamic latches in pipelining modules (shown in Figure 6.1 (b)) adds to the propagation delay of the circuitry. As such it is part of the pipeline o verhead. <p> The bypass logic is responsible for bypassing the functional unit results that have not been written back into the re gister file to subsequent instructions. The bypass logic consists of three components: the bypass datapath, the bypass multiple xors, and the control logic [81]. 101 6.6.1 Structure <ref> [21] </ref> has a separate bus for each source pipestage and a wide multiplexor near the input to the function units [81] (in an y one stage there can be multiple function units in multiple issue processors). <p> Timing Breakdown of the 5-Stage Pipeline Latency Type Latency (cycles) Adder-Use Latency 1 Shifter-Use Latency 1 Logical-Use Latency 1 Load-Use Latency 2 Branch Miss Latency 4 Table 7.2: Latencies for the 5-Stage Pipeline 115 Several commercial microprocessors fit this pipeline configuration; e.g MIPS LR 4000 [66] and Dec Alpha 21064 <ref> [21] </ref>. Figure 7.2 shows the 7-stage pipeline model. In terms of combinational logic this model is based on each phase (half a stage) having a maximum of five levels.
Reference: [22] <author> Daniel W. Dobberpuhl et. al. </author> <title> A 200MHz 64b Dual-Issue CMOS Microprocessor, </title> <booktitle> 1992 IEEE International Solid State Circuits Conference. Session 6/Microprocessors/Paper TA6.2 </booktitle>
Reference: [23] <author> Pradeep K. Dubey and Michael J. Flynn. </author> <title> Optimal Pipelining. </title> <journal> Journal of Parallel and Distributed Computing 8, </journal> <month> 10-19 </month> <year> (1990). </year>
Reference-contexts: This can lead to a situation for which the control paths determining the gating between stations contain more circuit levels than the datapaths being controlled. The performance limiting factors, mentioned above, fall into two categories <ref> [23] </ref>: (a) factors that limit the full utilization of the pipeline, and (b) factors that limit the minimum clock cycle time, T cycle . As the number of stages in a pipeline increase, the average degree of pipelining increases with it. <p> The optimal speedup is achie ved for a pipeline depth of about eight stages. 6 After this the utilization of the pipeline de grades (effective IPC decreases) voiding any performance increases due to the reduction of the clock cycle time. Analytical models presented by Dubey and Flynn <ref> [23] </ref> suggest that performance for any pipelined processor follows a similar upward convex curve. <p> Kunkel and Smith [61] studied the performance of numeric benchmarks (first 14 of the Li vermore Loops) for various pipeline depths of a floating point unit of a Cray-1 processor. Dubey and Flynn <ref> [23] </ref> de veloped analytical models for describing the performance of pipelined machines and used K unkel and Smiths [61] results to v alidate the analytical models. More recently Franklin and P an [32] have proposed analytical models for the performance of pipelined machines.
Reference: [24] <author> J. Earle. </author> <title> Latched Carry-Save Adder. </title> <journal> IBM Technical Disclosure Bulletin, </journal> <volume> vol. 7 no. 10, </volume> <month> March, </month> <pages> pages 909-910, </pages> <year> 1965 </year>
Reference-contexts: The general design of pipelined circuits using a single phase clock is shown in Figure 6.1 (b). 68 Similar to the design of Earle latches <ref> [24] </ref>, the use of single-phase dynamic logic also allows combinational logic to be mer ged with the latches (see Figure 6.1 (b)). An important advantage of single-phase clock strate gy is the absence of an y intentional clock skew in comparison to a tw o-phase clocking strategy.
Reference: [25] <author> J.P. Eckert, J.C. Chu, A.B. Tonik, and W.F. Schmitt. </author> <title> Design of UNIVAC-LARC System: I. </title> <booktitle> Proc. EJCC, </booktitle> <pages> pages 59-65. </pages>
Reference-contexts: However, fully overlapped I/O involv 12 ing timesharing of memory and asynchronous channels be gan with the IBM 705 (1958) [103]. The IBM 7094, and the IBM 7094 II took the overlapping concept further by overlapping the instruction fetch with the data execution [103]. The STRETCH and the LARC <ref> [25] </ref> were the first electronic computers to use pipelin-ing by segmenting instructions. The performance goal of the STRETCH w as a 100-fold improvement over the older 704. The STRETCH achie ved this goal only for lar ger programs that strained the 704.
Reference: [26] <author> John H. Edmondson et al. </author> <title> Internal Organization of the Alpha 21164, a 300-MHz 64-bit Quad-Issue CMOS RISC Microprocessor. </title> <journal> Digital Tehc-nical Journal, </journal> <volume> Vol. 7, No. 1, </volume> <year> 1995, </year> <pages> pages 119-132. </pages>
Reference-contexts: If there are no dependencies the issue logic lets the instruction proceed for execution. In the case of dependencies, instructions are 42 stalled till all the operands become available. This dissertation models only in-order issue machines. The Dec Alpha 21064 [21][22] and 21164 <ref> [26] </ref>. for example, fit the in-order issue model. This stage also reads the operands from the register file or from the bypass network and sends the data to the function units for execution. Execute Stage (E): The execute stage consists of both parallel and pipelined function units. <p> Pipeline Architectures: F D E R Fetch Decode Execute Retire speculative execution Execute Reg File 43 and not the translation lookaside buffer (TLB), since the TLB is much simpler than the design of the cache and can be accessed in parallel <ref> [26] </ref>. Retire Stage (R): The retire stage is the last stage where the result of the computation is committed. The 5-stage pipeline is laid out for the execution of both register-register and memory operations that require the ALU to perform an address calculation [93]. <p> I consider only the implementation of the cache and not the translation-lookaside buffer (TLB) [92], since the TLB is much simpler than the design of the cache and can be accessed in parallel <ref> [26] </ref>. The retire stage involves writing the final result back into the register file. In the case of microprocessors that support out-of-order completion the result is written back to a reorder-buffer [91] or a shadow register file [106]. <p> Processors 49 that support register renaming write the results back to the re gister file [81] [106] [57]. However, processors that only support in-order e xecution and in-order completion <ref> [26] </ref> can avoid the cost of register renaming and reorder-buffers. The critical component of the retire stage is the register file.
Reference: [27] <author> John R. Ellis. Bulldog: </author> <title> A Compiler for VLIW Architectures. </title> <publisher> The MIT Press, </publisher> <year> 1985. </year>
Reference: [28] <author> Marius Evers, Po-Yung Chang, and Yale N. Patt. </author> <title> Using Hybrid Branch Predictors to Improve Branch Prediction Accuracy in the Presence of Context Switches. </title> <booktitle> Proceedings of the 23rd Annual Int. Symposium on Computer Architecture </booktitle>
Reference: [29] <author> David M. Fenwick et al. </author> <title> The AlphaServer 8000 Series: High-end Server Platform Development. </title> <journal> Digital Technical Journal. </journal> <volume> Vol. 7 No. </volume> <month> 1 </month> <year> 1995. </year>
Reference-contexts: The cache miss latency is another parameter that af fects the performance. As the processor cycle time decreases the memory latenc y increases, given an unchanging memory system. The memory latency of the AlphaServer 8000 <ref> [29] </ref> is 176 ns (8 memory bank configuration). In the chapters below I develop a timing model for estimating the cycle time of pipelined processors. The c ycle time of the 5-stage pipeline is estimated at 8.85 ns.
Reference: [30] <author> Joseph Fisher. </author> <title> Trace Scheduling: A Technique for Global Microcode Compaction. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30(7):478-490, </volume> <month> July </month> <year> 1981. </year>
Reference: [31] <author> Michael J. Flynn. </author> <title> Computer Architecture: Pipelined and Parallel Processor Design, </title> <publisher> Jones and Bartlett Publishers, </publisher> <address> Boston, London </address>
Reference-contexts: CPU performance refers to the inverse of the user execution CPU time [46]. In this dissertation execution time refers to the user CPU execution time and performance refers to the inverse of the user CPU execution time. Flynn <ref> [31] </ref> defines the following four base issues that determine the o verall program execution time, T CPU : 1. The cycle time (T cycle ). <p> Flynn <ref> [31] </ref> notes that There are probably fe w areas within the computer systems field that create as much controversy as the relative merits of one particular instruction set selection versus another. The pipeline simulator implements a subset of the MIPS [55] instruction set.
Reference: [32] <author> M.A. Franklin and T. Pan. </author> <title> Clocked and Asynchronous Instruction Pipelines. </title> <booktitle> Proceedings of the 26th Annual International Symposium on Mi-croarchitecture, </booktitle> <month> December </month> <year> 1993, </year> <pages> pages 177-184. </pages>
Reference-contexts: Dubey and Flynn [23] de veloped analytical models for describing the performance of pipelined machines and used K unkel and Smiths [61] results to v alidate the analytical models. More recently Franklin and P an <ref> [32] </ref> have proposed analytical models for the performance of pipelined machines. The y compare the performance of clock ed and asynchronous pipelines. For both clock ed and asynchronous pipelines the y conclude that the highest throughput is achieved for a pipeline depth of eight stages.
Reference: [33] <author> Linda Geppert. </author> <title> Not your fathers CPU. </title> <journal> IEEE Spectrum, </journal> <volume> Vol. 30, No. 12, </volume> <month> December </month> <year> 1993. </year>
Reference: [34] <author> Phillip B. Gibbons and Steven S. Muchnick. </author> <title> Efficient Instruction Scheduling for a Pipelined Architecture. </title> <booktitle> In Proceedings of the SIGPLAN 1986 Symposium on Compiler Construction, </booktitle> <pages> pp 11=16, </pages> <month> June </month> <year> 1986. </year> <month> 152 </month>
Reference: [35] <author> Bruce A. Gieseke, et. al. </author> <title> A 600 MHz Superscalar RISC Microprocessor with Out-Of-Order Execution. </title> <booktitle> 1997 IEEE Int. Solid-State Circuits Conference, Paper FA 10.7, </booktitle> <year> 1997. </year>
Reference: [36] <author> Lance A. Glasser and Daniel W. Dobberpuhl. </author> <title> The Design and Analysis of VLSI Circuits. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1985. </year>
Reference-contexts: Hspice measurements sho w one g ate delay to be 0.3 ns. This is the approximation I have used for the multiplexor delay. The RC delay of a long interconnect line can be reduced by inserting intermediate buffers called repeaters [85] (see Figure 6.28) <ref> [36] </ref>. Each RC line segment is modeled with a p model and each repeater is S times larger than the previous one. I approximate the delay of the unperturbed line (without the repeaters) using the Elmore delay model [85]. <p> If b t = b n /b p , then the optimum delay of the RC line with repeaters can be approximated by <ref> [36] </ref>: (6.10) For an inverter with equal rise and fall times b t = 1. Using Equations 6.9 and 6.10, and the length of a bypass b us (L), I estimate the wire delay of a bypass bus. <p> It is interesting to note that as the feature size shrinks, t generally improves, but t L does not improve at the same rate; i.e wires do not scale as well <ref> [36] </ref>. 6.6.3 Bypass Delay Since a datapath is arranged in a linear pattern, the length of the longest bypass bus can be calculated by summing the lengths of the modules.
Reference: [37] <editor> David Greenhill, et. al. </editor> <title> A 330 MHz 4-Way Superscalar Microprocessor. </title> <booktitle> In the 1997 IEEE International Solid-State Circuits Conference. FA 10.2, </booktitle> <pages> pages 166-167. </pages>
Reference: [38] <author> Linley Gwennap. </author> <title> Speed Kills? Not for RISC Processors. In Microprocessor Report, </title> <journal> Vol. </journal> <volume> 7, Number 3, </volume> <month> March 8, </month> <year> 1993. </year>
Reference-contexts: An example of the IIII processor is the MIPS-X [18], and MIPS R3000 [55]. The superscalar processors belong to one of two camps. Gwennap has coined the word Brainiacs and Speed Demons to describe these camps <ref> [38] </ref>. The brainiacs rely primarily on increasing the IPC (superscalar technique), while the speed-demons rely on increasing the clock frequency (superpipe technique) for achieving high-performance. The 23 brainiacs frequently use out-of-order issuing and increase primarily the IPC, while the speed-demons primarily adhere to in-order-issue of multiple instruction.
Reference: [39] <author> Linley Gwennap. </author> <title> MIPS R10000 Uses Decoupled Architecture. </title> <type> Microprocessor Report, 8(14), </type> <year> 1994, </year> <pages> pages 13-22. </pages>
Reference: [40] <author> Linley Gwennap. </author> <title> PowerPC Becomes Best-Selling Desktop RISC. </title> <journal> Microprocessor Report. </journal> <volume> Vol 8, No. 17, </volume> <month> December 26, </month> <year> 1994. </year>
Reference: [41] <author> Linley Gwennap. </author> <title> Intels P6 uses Decoupled Superscalar Design. In Microprocessor Report, </title> <booktitle> 9(2), </booktitle> <pages> 9-15, </pages> <year> 1995. </year>
Reference-contexts: Within the Intel family of proces sors, however, we see a trend to wards deeper pipelining. For example the pipeline depth has changed from a 3-stage pipeline in the 8086 [50] to an 8 and a 14-stage (decoupled) pipeline on the Pentium Pro <ref> [41] </ref>. MIPS reversed its trend toward pipelining with the MIPS R10000 s [106] decoupled pipeline. The pipeline depth for the inte ger and the load/store unit in the MIPS R10000 [39][106] is, respectively, five and six.
Reference: [42] <author> Linley Gwennap. </author> <title> Digital 21264 Sets new Standard. </title> <note> In Microprocessor Report, Vol. 10, Issue 14, </note> <month> Oct. 28, </month> <year> 1996. </year>
Reference-contexts: The pipelined machine models are v alidated from components constructed and fabricated in a 0.8 mm CMOS technology. In the quest for performance most single-chip microprocessors, lik e the MIPS R10000 [106] and the Dec Alpha 21264 <ref> [42] </ref>, use both superscalar and superpipelining techniques. The scope of this dissertation is restricted to the in-order single and multiple-issue processors.
Reference: [43] <author> Thomas G. Hallin and Michael J. Flynn. </author> <title> Pipelining of Arithmetic Functions. </title> <journal> In IEEE Transactions on Computers, </journal> <month> August </month> <year> 1972, </year> <pages> pages 880-885. </pages>
Reference-contexts: For both clock ed and asynchronous pipelines the y conclude that the highest throughput is achieved for a pipeline depth of eight stages. Ho wever, they do not provide any validation for their model. Some of the earlier work by Hallin and Flynn <ref> [43] </ref> looked at the efficiency of pipelin-ing primarily in the conte xt of arithmetic functions only and did not directly look for the pipeline depth that results in the highest performance arithmetic unit.
Reference: [44] <author> W. </author> <title> Handler. The Impact of Classification Schemes on Computer Architecture. </title> <booktitle> Proc. 1977 International Conference on Parallel Processing, </booktitle> <pages> pp 7-15. </pages>
Reference: [45] <author> Ralph Haygood. </author> <title> A Prolog Benchmark Suite for Aquarius. </title> <type> Report. </type> <institution> No. UCB/UCSD 89/509, University of California at Berkeley, </institution> <month> April </month> <year> 1989. </year>
Reference-contexts: The memory contention latency is set to zero for all simulations because I am only modeling the execution of a single processor. 4.2 Benchmarks The performance of various processor pipeline architectures are compared by running benchmarks taken from the SPECInt95 [99], Dhrystone, and Aquarius Benchmark Suite <ref> [45] </ref>.
Reference: [46] <author> John L. Hennessy and David A. Patterson, </author> <title> Computer Architecture: A Quantitative Approach, </title> <publisher> Morgan Kaufmann Publishers, Inc. </publisher> <year> 1990. </year>
Reference-contexts: Superscalar processors improve performance by exploiting spatial microparallelism, while superpipelined 3 processors improve performance primarily by exploiting temporal microparallelism. The goal of superpipelined processors is to achieve an effective IPC as close as possible to one. The effective IPC of superscalar processors is occasionally two, but rarely higher <ref> [46] </ref>. Most current processors tend to be both pipelined and superscalar (e.g. MIPS R10000 [106], Dec Alpha 21264 [42][57]). 2. Clock frequency = . Both the terms frequency and cycle time are used throughout this dissertation. 3. <p> The execution time of a benchmark is used as a primary measure of performance. System performance is the elapsed time for a benchmark and includes the time spent w aiting on I/O or running other programs <ref> [46] </ref>. CPU e xecution time consists of both time spent e xecuting a benchmark, called user CPU execution time, and time spent in the operating system, called system execution CPU time. CPU performance refers to the inverse of the user execution CPU time [46]. <p> aiting on I/O or running other programs <ref> [46] </ref>. CPU e xecution time consists of both time spent e xecuting a benchmark, called user CPU execution time, and time spent in the operating system, called system execution CPU time. CPU performance refers to the inverse of the user execution CPU time [46]. In this dissertation execution time refers to the user CPU execution time and performance refers to the inverse of the user CPU execution time. Flynn [31] defines the following four base issues that determine the o verall program execution time, T CPU : 1. <p> The 5-stage pipeline model is one of the most widely used pipeline architectures. This architecture model originated from some of the early RISC processors such as the MIPS-X [18], MIPS R2000/R3000 [70] and the DLX <ref> [46] </ref>. The five pipeline stages are: Instruction Fetch Stage (F): In the fetch stage the processor fetches instructions from the instruction memory (or instruction cache in the case of most single-chip microprocessors). In W-issue (multiple-issue) processors W instructions are fetched.
Reference: [47] <author> Bruce K. Holmer. </author> <title> Automatic Design of Computer Instruction Sets. </title> <type> PhD Dissertation, </type> <institution> Computer Science Division, U.C. Berkeley, </institution> <year> 1993. </year>
Reference-contexts: Data-stationary control can reduce the control path limitations because the control logic is also pipelined in parallel with the data that it operates on <ref> [47] </ref>. (Holmer [47] discusses the pipeline control model in more detail.) 2.4 Pipeline Taxonomies Several taxonomies have been proposed for the classification of pipelined processors. Ramamoorthy and Li [87] ha ve proposed a taxonomy of pipelines based on three parameters: 19 1. <p> Data-stationary control can reduce the control path limitations because the control logic is also pipelined in parallel with the data that it operates on <ref> [47] </ref>. (Holmer [47] discusses the pipeline control model in more detail.) 2.4 Pipeline Taxonomies Several taxonomies have been proposed for the classification of pipelined processors. Ramamoorthy and Li [87] ha ve proposed a taxonomy of pipelines based on three parameters: 19 1.
Reference: [48] <author> Peter Y.T. Hsu and Edward S. Davidson. </author> <title> Highly Concurrent Scalar Processing. </title> <booktitle> Proceedings of the 13th Annual Int. Symp. on Computer Architecture, </booktitle> <pages> pages 386-395, </pages> <month> May 86. 153 </month>
Reference-contexts: Hardware branch prediction is an ef fective mechanism for reducing control 17 dependencies [18][100][64][28][114][71]. Several more general mechanisms for speculative execution, such as guarded execution <ref> [48] </ref>, boosting [96][97][98], and value prediction [65][90] have also been proposed. 2.3.2 Reducing Pipelining Overhead Reducing pipelining overhead concerns reducing propag ation delay, data skew, and clock skew. Propagation overhead can be reduced by merging the latch with the logic. An example of this is the Earle latch [24][43].
Reference: [49] <author> Inseok S. Hwang and Aaron L. Fisher. </author> <title> Ultrafast Compact 32-bit CMOS Adders in Multiple-Output Domino Logic. </title> <journal> IEEE Journal of Solid State Circuits, </journal> <volume> Vol. 24, No. 2, </volume> <month> April </month> <year> 1989, </year> <pages> pages 358-369. </pages>
Reference-contexts: The implementation uses the Multiple Output Domino Logic (MODL) <ref> [49] </ref> style. Bitline Dr. Wordline F Reg. <p> Catenation nodes represent a parallel prefix circuit performing the addition operation on its inputs. P 4 P 4 95 produce one output. In MODL the dynamic circuits are conf igured to produce multiple outputs. Figure 6.22 shows the concept of MODL <ref> [49] </ref> and an e xample circuit. In Figure 6.22 (a) the circuit for e xample produces the output f 1 and f 2 .
Reference: [50] <institution> Intel Corp. </institution> <note> MCS-86 Preliminary Users Manual, </note> <institution> INTEL Corp. </institution> <month> June </month> <year> 1978. </year>
Reference-contexts: By the end of 1970, VLSI technology allo wed enough integration to enable the f abri-cation of f airly complex microprocessors. Of these microprocessors, the Intel 8086 13 became one of the most widely used microprocessors. The Intel 8086 <ref> [50] </ref> is a single chip processor with a 2 and a 3-stage pipeline. MIPS led the adv ent of the more streamlined microprocessors. The MIPS R3000 [55] (commercial v ersion of the MIPS-X [18]) is a streamlined 5-stage RISC processor. <p> Within the Intel family of proces sors, however, we see a trend to wards deeper pipelining. For example the pipeline depth has changed from a 3-stage pipeline in the 8086 <ref> [50] </ref> to an 8 and a 14-stage (decoupled) pipeline on the Pentium Pro [41]. MIPS reversed its trend toward pipelining with the MIPS R10000 s [106] decoupled pipeline. The pipeline depth for the inte ger and the load/store unit in the MIPS R10000 [39][106] is, respectively, five and six.
Reference: [51] <author> Bertrand S. Irissou. </author> <title> Design Techniques for High-Speed Datapaths. </title> <type> UCB Technical Report, </type> <institution> EECS-CSD, </institution> <month> November </month> <year> 1992 </year>
Reference-contexts: The timing estimates are based on Srivastavas [101], Sanos [89], and Irissous <ref> [51] </ref> study. The wordline decoder is a nor-decoder. Alowersson [4] has reported f aster decoders and senseamplifier circuits for re gister files, however, these timings are for a dual-rail read register file. The register file presented here assumes a single-ended read port.
Reference: [52] <author> Michael A.B. Jackson, Arvind Srinivasan, </author> <title> E.S. Kuh. Clock Routing for High-Performance ICs. </title> <booktitle> 27th ACM/IEEE Design Automation Conference, </booktitle> <year> 1990. </year>
Reference: [53] <author> Mike Johnson, </author> <title> Superscalar Microprocessor Design. </title> <publisher> Prentice Hall, </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1990. </year>
Reference-contexts: The execution driven simulator executes the compiled instruction stream using architecture parameters to estimate the pipeline architecture performance. In contrast, trace-driven 28 simulation uses a predetermined instruction sequence, an instruction trace. to estimate the performance metrics <ref> [53] </ref>. The pipeline execution-driven simulator executes compiled MIPS [55] binaries in ELF format [80] and uses the architecture parameters that describe the pipeline, the branch prediction mechanism, and the memory hierarch y to model the beha vior of various pipeline architecture configurations.
Reference: [54] <author> Norman P. Jouppi and David W. Wall. </author> <title> Available Instruction-Level Parallelism for Superscalar and Superpipelined Machines. </title> <booktitle> Third Int. Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> April </month> <year> 1989, </year> <pages> pages 272-282. </pages>
Reference-contexts: The term superpipelined is used to describe any processor with a pipeline depth deeper than that of current processors (most processors have a pipeline that ranges from five to seven stages). Generally the term is used for single-issue microprocessors <ref> [54] </ref>, however, superpipelining in this dissertation is used to describe any deeply pipelined processor. T CPU T cycle Dynamic Instruction Count i IPCeffective i - = T cycle - 4 1.3 Limitations to Speedup Ideally we would like performance to increase linearly with increasing pipeline depth. <p> As the number of stages in a pipeline increase, the average degree of pipelining increases with it. Jouppi and W all <ref> [54] </ref> define the average degree of pipelining of a machine as the latenc y of each instruction multiplied by the relati ve frequency of its occurrence. <p> The number of stages in a pipeline and the de gree of pipelining are related, since deeper pipelined machines have a higher degree of pipelining. A higher degree of pipelining implies that more independent instructions must be found to fully utilize the pipeline <ref> [54] </ref>; i.e the effective IPC for a deeper pipe decreases, unless sufficient independent instructions can be found. The clock cycle time decreases (or the frequency, 1/T cycle , increases) with increasing de gree of pipelining until it reaches a limit imposed by the overhead of pipelining.
Reference: [55] <author> Gerry Kane and Joe Heinrich, </author> <title> MIPS Risc Architecture, </title> <publisher> PTR Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey 07632. ISBN 0-13-590472-2. </address> <year> 1992. </year>
Reference-contexts: Of these microprocessors, the Intel 8086 13 became one of the most widely used microprocessors. The Intel 8086 [50] is a single chip processor with a 2 and a 3-stage pipeline. MIPS led the adv ent of the more streamlined microprocessors. The MIPS R3000 <ref> [55] </ref> (commercial v ersion of the MIPS-X [18]) is a streamlined 5-stage RISC processor. One of the more recent 5-stage integer pipelines is the Intel Pentium [5]. The pipeline stages are: 1. PF - Fetch and Align instruction 2. D1 - Decode Instruction, Generate Control Word 3. <p> Using the four abstract stages, the in-order and out-of-order behavior results in 16 possible permutations. The eight possible permutations of in-order fetch processors are: IIII, IIIO, IIOO, IIOI, IOII, IOIO, IOOO, IOOI. An example of the IIII processor is the MIPS-X [18], and MIPS R3000 <ref> [55] </ref>. The superscalar processors belong to one of two camps. Gwennap has coined the word Brainiacs and Speed Demons to describe these camps [38]. The brainiacs rely primarily on increasing the IPC (superscalar technique), while the speed-demons rely on increasing the clock frequency (superpipe technique) for achieving high-performance. <p> The 4-stage pipeline is laid out for register-register instructions [93]. Examples of a 4-stage pipeline are Sparc processors and the PowerPC [40][78]. The second type performs multiple cascaded micro-operations (see Figure 3.1). A common optimization, found in man y processors (MIPS R2000 <ref> [55] </ref>, MIPS R4000 [66], 24 HP PA 7100 [8]), is performing the address calculation for a memory operation and the actual load/store from memory as one instruction (Figure 3.1 (b)). A possible extension is shown in Figure 3.1 (c) where multiple micro-operations can be pipelined and packed within one instruction. <p> The execution driven simulator executes the compiled instruction stream using architecture parameters to estimate the pipeline architecture performance. In contrast, trace-driven 28 simulation uses a predetermined instruction sequence, an instruction trace. to estimate the performance metrics [53]. The pipeline execution-driven simulator executes compiled MIPS <ref> [55] </ref> binaries in ELF format [80] and uses the architecture parameters that describe the pipeline, the branch prediction mechanism, and the memory hierarch y to model the beha vior of various pipeline architecture configurations. <p> Flynn [31] notes that There are probably fe w areas within the computer systems field that create as much controversy as the relative merits of one particular instruction set selection versus another. The pipeline simulator implements a subset of the MIPS <ref> [55] </ref> instruction set. <p> MIPS R10000 [76][106], Dec Alpha [42][57], HP PA-8000 [62]). The MIPS ISA implements three 32-bit instruction formats <ref> [55] </ref>. Figure 4.2 shows the three integer formats. <p> The SPEC integer benchmarks [99] also execute some oating-point instructions, primarily for some of the built-in C functions (e.g. printf). The simulator implements a subset of the MIPS floating point instructions (for a detailed description see MIPS architecture manual <ref> [55] </ref>). Table 4.2 shows the latencies of the various oating point operations used in the pipeline simulator. The latencies are tak en from the MIPS IV instruction set manual [76][84]. <p> With the advent of synthesis tools, the trend is to use basic logic gates for control path design. Detecting hardw are interlocks and generating control for the data bypass logic is the most critical part of the control path design. 5.2 4-Stage Versus 5-Stage Pipeline The MIPS ISA <ref> [55] </ref> can be implemented both with a 4 or a 5-stage pipeline. A memory load or store operation is e xpanded into a two stage operation in a 4-stage pipeline, where the two stages are the virtual address calculation and the data cache access. <p> The 5-stage pipeline combines the 1-stage cache, a 2-stage register file, a s=2 bypass logic combined with the ALU, and a single-cycle adder. Many commercial RISC microprocessors fit this pipeline model very well; e.g. MIPS R2000/3000 pipeline <ref> [55] </ref>, HP P A7100 [8], and PowerPC 603 (load/store pipe) [78]. The 5-stages are: 1. F: Instruction Fetch Stage. The F-stage fetches the instructions from the instruction cache. 2. D: Instruction Decode Stage. The D-stage decodes and issues the fetched instruction. The stage also reads the reg ister file. 3.
Reference: [56] <author> Manolis G.H. Katevenis. </author> <title> Reduced Instruction Set Computer Architectures for VLSI. </title> <type> Report No. </type> <institution> UCB/CSD 83/141, Computer Science Division (EECS), University of California, Berkeley, </institution> <address> California 94720, </address> <month> October </month> <year> 1983. </year>
Reference: [57] <author> Jim Keller. </author> <title> The 21264: A Superscalar Alpha Processor with Out-of-Order Execution. </title> <booktitle> Slide presentation at the 9th Annual Microprocessor Forum, </booktitle> <address> San Jose, California, </address> <month> October 22-23, </month> <year> 1996. </year> <note> (URL - http://ssd.sscc.ru/library/cpu/a264up1). </note>
Reference-contexts: The processor has been fabricated in a specialized 0.75 mm CMOS process and operates at a clock frequenc y of 150 MHz. The Dec Alpha 21164 [10] is quad-issue second-generation Alpha fabricated in 0.5 mm CMOS, and the Dec Alpha 21264 [35][42] <ref> [57] </ref> is fabricated in 0.35 mm. They operate at a clock rate of, respecti vely, 300 MHz and 600 14 MHz. Both processors have a 7-stage integer and a load/store pipeline and a 9-stage oat ing point pipeline. <p> The input size affects the performance of the data cache since small data sets tend to fit in the cache, while large data sets cause more cache misses. Many of the current microprocessors are now implemented in 0.35 or 0.25 mm CMOS (e.g. the Dec Alpha 21264 <ref> [57] </ref>) and have 64K byte instruction and data caches. <p> In the case of microprocessors that support out-of-order completion the result is written back to a reorder-buffer [91] or a shadow register file [106]. Processors 49 that support register renaming write the results back to the re gister file [81] [106] <ref> [57] </ref>. However, processors that only support in-order e xecution and in-order completion [26] can avoid the cost of register renaming and reorder-buffers. The critical component of the retire stage is the register file.
Reference: [58] <author> Peter M. Kogge. </author> <title> The Microprogramming of Pipelined Processors. </title> <booktitle> Proc. 4th Annual Conf. Parallel Processing, IEEE No 77 CH1253-4C, </booktitle> <month> August, </month> <note> p. 217. </note>
Reference-contexts: Kogge <ref> [58] </ref> introduced the terms timestationary and data-stationary control; timestationary generates control for the processor for one c ycle, while in data-stationary, the opcode follows the flow of data and produces control signals for the corresponding pipestage.
Reference: [59] <author> Peter M. Kogge. </author> <title> The Architecture of Pipelined Computers. </title> <publisher> Hemisphere Publishing Corporation. </publisher> <year> 1981. </year>
Reference-contexts: The memory technology in the STRETCH w as six times faster (2 ms versus 12 ms) and logic technology w as ten times f aster [103]. The memory and logic technology together pro vided a 10-fold improvement in performance. Kogge <ref> [59] </ref> writes that the rest of the performance increase came primarily from pipelining the STRETCH in two stages: an instruction fetch/decode and a data e xecution stage. The LARC went a step f arther and implemented a four stage pipeline: instruction fetch, address index operations, data fetch, and execution [59]. <p> Kogge <ref> [59] </ref> writes that the rest of the performance increase came primarily from pipelining the STRETCH in two stages: an instruction fetch/decode and a data e xecution stage. The LARC went a step f arther and implemented a four stage pipeline: instruction fetch, address index operations, data fetch, and execution [59]. The IBM 360/91 employed a hierarchy of pipelines and used pipelining e xtensively. The goal was to gain an order or tw o performance improvement over the IBM 7090. The IBM 360/91 was one of the first processors to have a 13 stage pipeline [6]. <p> pipeline up from a 5-stage pipeline in the HP 7100 [8]. i 2 6 10 MIPS R4400 (8/10) [92] [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) <ref> [59] </ref> [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium (5/8) [96] Dec Alpha 21164a (7/7/9) [96] HP 8000 (7/9/9) # <p> The use of data-stationary control can eliminate the critical paths due the comple xity of the control logic <ref> [59] </ref>. In the follo wing sections I will discuss the latency as a function of the number of pipeline stages for implementing the four key modules. This study pro vides a basis for determining the c ycle time of various pipeline architecture models presented in the following chapters.
Reference: [60] <author> R. Krambeck et al. </author> <title> High-Speed Compact Circuits with CMOS. </title> <journal> IEEE Journal of Solid State Circuits, </journal> <volume> vol. SC-17, no. 3, </volume> <pages> pages 614-619, </pages> <month> June </month> <year> 1982. </year> <month> 154 </month>
Reference: [61] <author> Steven R. Kunkel and James E. Smith. </author> <title> Optimal Pipelining in Supercomputers. </title> <booktitle> The 13th Annual Int. Symposium on Computer Architecture, </booktitle> <address> To-kyo, Japan, </address> <year> 1986. </year>
Reference-contexts: Control hazards occur when an instructions execution depends on control information from a previous instruction. All three hazards result in unutilized cycles in the pipelined execution. These cycles are also known as bubbles in the pipeline. 2. Pipelining overhead. Pipeline overhead consists of three main components <ref> [61] </ref>: (a) Propagation delay is increased by the addition of latches. <p> Further pipelining decreases the utilization of the pipeline without a proportional decrease in the cycle time. The performance of a pipelined microprocessor, therefore, reaches a maximum for some de gree of pipelining and then drops. Kunkel and Smith <ref> [61] </ref> performed a study of performance as a function of the pipeline depth of a Cray-1 floating point unit of the pipeline (see Figure 1.1). The performance is derived for the first fourteen of the Livermore Loops [72]. <p> The performance is derived for the first fourteen of the Livermore Loops [72]. The relative performance grows until a depth of four stages, grows marginally until eight stages, and then drops for sixteen stages <ref> [61] </ref>. The optimal speedup is achie ved for a pipeline depth of about eight stages. 6 After this the utilization of the pipeline de grades (effective IPC decreases) voiding any performance increases due to the reduction of the clock cycle time. <p> up from a 5-stage pipeline in the HP 7100 [8]. i 2 6 10 MIPS R4400 (8/10) [92] [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] <ref> [61] </ref> STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium (5/8) [96] Dec Alpha 21164a (7/7/9) [96] HP 8000 (7/9/9) # - <p> Kunkel and Smith <ref> [61] </ref> studied the performance of numeric benchmarks (first 14 of the Li vermore Loops) for various pipeline depths of a floating point unit of a Cray-1 processor. Dubey and Flynn [23] de veloped analytical models for describing the performance of pipelined machines and used K unkel and Smiths [61] results to <p> and Smith <ref> [61] </ref> studied the performance of numeric benchmarks (first 14 of the Li vermore Loops) for various pipeline depths of a floating point unit of a Cray-1 processor. Dubey and Flynn [23] de veloped analytical models for describing the performance of pipelined machines and used K unkel and Smiths [61] results to v alidate the analytical models. More recently Franklin and P an [32] have proposed analytical models for the performance of pipelined machines. The y compare the performance of clock ed and asynchronous pipelines.
Reference: [62] <author> Ashok Kumar, </author> <title> The HP PA-8000 RISC CPU, </title> <journal> IEEE Micro, </journal> <volume> Vol. 17, No. 2, </volume> <month> March/April </month> <year> 1997. </year>
Reference-contexts: MIPS reversed its trend toward pipelining with the MIPS R10000 s [106] decoupled pipeline. The pipeline depth for the inte ger and the load/store unit in the MIPS R10000 [39][106] is, respectively, five and six. The HP 8000 <ref> [62] </ref> has a 7-stage inte ger and a 9 stage load/store pipeline up from a 5-stage pipeline in the HP 7100 [8]. i 2 6 10 MIPS R4400 (8/10) [92] [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 [93] <p> MIPS R10000 [76][106], Dec Alpha [42][57], HP PA-8000 <ref> [62] </ref>). The MIPS ISA implements three 32-bit instruction formats [55]. Figure 4.2 shows the three integer formats.
Reference: [63] <author> Richard E. Ladner and Michael J. Fisher. </author> <title> Parallel Prefix Computation. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> Vol 27, No. 4, </volume> <month> Oc-tober </month> <year> 1980, </year> <pages> pages 831-838. </pages>
Reference-contexts: The implementation is based on parallel prefix calculation <ref> [63] </ref>. CMOS circuits have a limited fan-in and a limited fanout. This makes the constant fan-out adder well suited for implementation in CMOS. & Fishers notation [63], the adder circuit is designated by P, a subscript, k, to indicate the order of the circuit, and a superscript j to indicate the <p> The implementation is based on parallel prefix calculation <ref> [63] </ref>. CMOS circuits have a limited fan-in and a limited fanout. This makes the constant fan-out adder well suited for implementation in CMOS. & Fishers notation [63], the adder circuit is designated by P, a subscript, k, to indicate the order of the circuit, and a superscript j to indicate the maximum permissible f anin.
Reference: [64] <author> J.K.F. Lee and A.J. Smith. </author> <title> Branch prediction strategies and branch target buffer design. </title> <journal> IEEE Computer Magazine, </journal> <pages> pages 6-22, </pages> <month> January </month> <year> 1984. </year>
Reference: [65] <author> Mikko H. Lipasti and John Paul Shen. </author> <title> Exceeding the Dataflow Limit via Value Predction. </title> <booktitle> Proceedings of the 29 th IEEE/ACM International Symposium on Microarchitecture (MICRO-29). </booktitle> <month> December 2-4, </month> <year> 1996. </year>
Reference: [66] <institution> LR4000 MIPS RISC Microprocessor Users Manual, MM72-000108-99A, LSI Logic Corporation. </institution>
Reference-contexts: The 4-stage pipeline is laid out for register-register instructions [93]. Examples of a 4-stage pipeline are Sparc processors and the PowerPC [40][78]. The second type performs multiple cascaded micro-operations (see Figure 3.1). A common optimization, found in man y processors (MIPS R2000 [55], MIPS R4000 <ref> [66] </ref>, 24 HP PA 7100 [8]), is performing the address calculation for a memory operation and the actual load/store from memory as one instruction (Figure 3.1 (b)). A possible extension is shown in Figure 3.1 (c) where multiple micro-operations can be pipelined and packed within one instruction. <p> ns (210 MHz) Table 7.1: Timing Breakdown of the 5-Stage Pipeline Latency Type Latency (cycles) Adder-Use Latency 1 Shifter-Use Latency 1 Logical-Use Latency 1 Load-Use Latency 2 Branch Miss Latency 4 Table 7.2: Latencies for the 5-Stage Pipeline 115 Several commercial microprocessors fit this pipeline configuration; e.g MIPS LR 4000 <ref> [66] </ref> and Dec Alpha 21064 [21]. Figure 7.2 shows the 7-stage pipeline model. In terms of combinational logic this model is based on each phase (half a stage) having a maximum of five levels.
Reference: [67] <author> Fang Lu, Henry Samueli, Jiren Yuan, and Christer Svensson. </author> <title> A 700-MHz 24-b Pipelined Acculmulator in 1.2 -mm CMOS for Application as a Numerically Controlled Oscillator. </title> <journal> IEEE Journal of Solid State Circuits, </journal> <volume> Vol. 28, No. 8, </volume> <month> August </month> <year> 1993. </year>
Reference-contexts: Yuan and Svensson [117] have showed that circuits in e xcess of 200 MHz can be fabricated in 3.0 mm CMOS technology. Lu et al. <ref> [67] </ref> ha ve used single phase dynamic logic successfully to b uild a 700 MHz 24 bit pipelined accumulator in 1.2 mm CMOS.
Reference: [68] <author> Monica Lam. </author> <title> Software Pipelining: An Effective Scheduling Technique for VLIW Machines. </title> <booktitle> Proceedings of the SIGPLAN 88 Conference on Programming Language Design and Implementation, </booktitle> <address> Atlanta, Georgia, </address> <month> June </month> <year> 1988, </year> <pages> pages 318-328. </pages>
Reference-contexts: Hardware support for scheduling be yond basic blocks is pro vided by speculative execution. Software analysis techniques are then required to exploit the speculative execution mechanisms. Trace scheduling [30][27], percolation scheduling [79], loop unrolling [110], and software pipelining <ref> [68] </ref> are some of the compiler techniques that have been explored in the past. Hardware branch prediction is an ef fective mechanism for reducing control 17 dependencies [18][100][64][28][114][71].
Reference: [69] <author> Monica S. Lam and Robert P. Wilson. </author> <title> Limits of Control Flow Parallelism. </title> <booktitle> Proceedings of the 19th Annual International Symposium on Computer Architecture. </booktitle> <pages> pages 46-57, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: The hazards that cause instruction dependencies are: structural, data, and control. The utilization of the pipeline can be increased by reducing the effect of the three hazards. Both Wall [108], and Lam and Wilson <ref> [69] </ref> found that the instruction level parallelism (ILP) in non-numeric benchmarks without going across basic block boundaries w as limited to two. <p> Much work has been done to study the limits of available instruction level parallelism in integer benchmarks [108][14][74]<ref> [69] </ref>[17]. Lam and W ilson [69] showed that multiple control-flow analysis could potentially e xpose an ILP of 39 for the SPEC benchmarks. These studies suggest that with a syner gistic combination of compiler techniques and hardware mechanisms sufficient ILP can be found in integer benchmarks.
Reference: [70] <editor> LSI Logic, </editor> <title> LR3300 MIPS Embedded Processor, Users Manual, </title> <year> 1990. </year>
Reference-contexts: The 5-stage pipeline model is one of the most widely used pipeline architectures. This architecture model originated from some of the early RISC processors such as the MIPS-X [18], MIPS R2000/R3000 <ref> [70] </ref> and the DLX [46]. The five pipeline stages are: Instruction Fetch Stage (F): In the fetch stage the processor fetches instructions from the instruction memory (or instruction cache in the case of most single-chip microprocessors). In W-issue (multiple-issue) processors W instructions are fetched.
Reference: [71] <author> Scott McFarling. </author> <title> Combining Branch Predictors. </title> <note> WRL Technical Note TN-36, </note> <institution> Digital, Western Research Laboratory, 250 University Ave., </institution> <address> Palo Alto, CA 94301, U.S.A., </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Of the various proposed prediction mechanisms, the pipeline simulator implements a h ybrid two-level hardware branch prediction mechanism 32 (see Figure 4.3). The h ybrid branch predictor is based on Chang et al. s [16], Yeh and Patts [113][114], and McFarlings <ref> [71] </ref> studies. The hybrid branch predictor combines McF arlings gshare predictor with Yeh and Patts per-address (PAs) variation of the two-level adaptive branch predictor [71][114]. In terms of Chang et al.s terminology I use a gsh (8)/PAs (16,1) hybrid branch predictor where gsh is McFarlings gshare predictor [71] and PAs is <p> [113][114], and McFarlings <ref> [71] </ref> studies. The hybrid branch predictor combines McF arlings gshare predictor with Yeh and Patts per-address (PAs) variation of the two-level adaptive branch predictor [71][114]. In terms of Chang et al.s terminology I use a gsh (8)/PAs (16,1) hybrid branch predictor where gsh is McFarlings gshare predictor [71] and PAs is Yeh and Patts per-address 2 Global Register PC Pattern Taken Predict Taken m = 8 PC Taken Predict Taken Branch gsh (8) PAs (16,1) P1c P2c P1c-P2c operation 0 0 0 (no change) 0 1 -1 (decrement cnt) 1 0 1 (increment cnt) 1 1 0 (no
Reference: [72] <author> F.M. McMahon, </author> <title> The Livermore FORTRAN kernels: A computer test of numerical performance range. </title> <type> Tech. Rep. </type> <institution> UCRL-55745, Lawrence Liver-more National Laboratory, University of California, Livermore, Califor-nia, </institution> <month> December </month> <year> 1986. </year> <month> 155 </month>
Reference-contexts: Kunkel and Smith [61] performed a study of performance as a function of the pipeline depth of a Cray-1 floating point unit of the pipeline (see Figure 1.1). The performance is derived for the first fourteen of the Livermore Loops <ref> [72] </ref>. The relative performance grows until a depth of four stages, grows marginally until eight stages, and then drops for sixteen stages [61].
Reference: [73] <author> Carver Mead and Lynn Conway. </author> <title> Introduction to VLSI Systems. </title> <publisher> Addison-Wesley Publishing Company. </publisher>
Reference-contexts: The decoder is implemented in tw o stages. The first stage consists of a 3-to-8 NAND-decoder and the second stage consists of a NOR-decoder. 78 For CMOS a fanout of four is considered near optimal <ref> [73] </ref> and therefore the N AND-decoder should not be more than a 4-input N AND. Wilton and Jouppi and chosen a 3-input NAND to implement the NAND-decoder [112].
Reference: [74] <author> S. Melvin and Y. Patt. </author> <title> Exploiting Fine-Grain Parallelism Through a Combination of Hardware and Software Techniques. </title> <booktitle> Proceedings of the 18th Annual Int. Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1991. </year>
Reference: [75] <author> Meta-Software Inc. </author> <title> Hspice Users Manual, </title> <address> Meta-Software, Campbell, CA 95008, </address> <year> 1992. </year>
Reference-contexts: This, methodology, however, is too complex to allow a search of a lar ge design space of pipelined architectures. The methodology introduced in this chapter focuses on the modules that are the sources of complexity in a processor, and uses a mixture of detailed analytical models and Hspice <ref> [75] </ref> simulations on netlists extracted from layout to estimate the cycle time of each module. The module with the highest cycle time determines the cycle time of the processor. <p> The length of a bypass bus grows linearly with the issue-width of the processors. 67 4. I have not taken clock skew explicitly into account in the determination of the cycle time of the modules, because the mismatch in the clock routing is taken into account in Hspice simulations <ref> [75] </ref> on netlists extracted from layout. 6.2 Logic Styles for High-Speed Processor Design A promising approach to high-speed circuit design is the use of single phase dynamic logic [117][2]. <p> The timing breakdown is based on Hspice <ref> [75] </ref> simulations of the register file circuits extracted from layout. 6.4.3 Timing of Pipelined Configurations This section presents the register file pipeline configurations based on the micro-operation latencies of Table 6.3.
Reference: [76] <institution> MIPS Technologies, Inc. </institution> <note> MIPS R10000 Microprocessor Users Manual. Version 1.0, </note> <institution> 2011 North Shoreline, Mountain View, </institution> <address> California 94039-7311. </address>
Reference-contexts: 9 stage load/store pipeline up from a 5-stage pipeline in the HP 7100 [8]. i 2 6 10 MIPS R4400 (8/10) [92] [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) <ref> [76] </ref> LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium (5/8) [96] Dec Alpha 21164a (7/7/9) [96] HP
Reference: [77] <author> S. Mirapuri, M. Woodacre, N. Vasseghi. </author> <title> The MIPS R4000 processor. </title> <booktitle> IEEE Micro, </booktitle> <month> April </month> <year> 1992, </year> <pages> pages 10-22. </pages>
Reference-contexts: D1 - Decode Instruction, Generate Control Word 3. D2 - Decode Control Word, Generate memory address 4. E - Access data cache or Calculate ALU Result 5. WB - Write Result The more notable of the superpipelined single-chip processors are the MIPS R4000 <ref> [77] </ref> and the MIPS R4400 [33][94], and the Dec Alpha 21064 [21][22].
Reference: [78] <author> Motorola Inc. </author> <title> Technical Summary PowerPC 603 RISC Microprocessor, </title> <institution> MPC603, Motorola Inc. </institution> <year> 1993. </year>
Reference-contexts: 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] <ref> [78] </ref> 8086 (1) [93] Pentium (5/8) [96] Dec Alpha 21164a (7/7/9) [96] HP 8000 (7/9/9) # - # (decoupled pipe) 5 Dec Alpha n HP PA-RISC s Intel i Motorola m PowerPC u SGI t Sparc t 15 2.2 The Search for the Highest Performance Pipeline Depth Two studies pertain directly <p> The 5-stage pipeline combines the 1-stage cache, a 2-stage register file, a s=2 bypass logic combined with the ALU, and a single-cycle adder. Many commercial RISC microprocessors fit this pipeline model very well; e.g. MIPS R2000/3000 pipeline [55], HP P A7100 [8], and PowerPC 603 (load/store pipe) <ref> [78] </ref>. The 5-stages are: 1. F: Instruction Fetch Stage. The F-stage fetches the instructions from the instruction cache. 2. D: Instruction Decode Stage. The D-stage decodes and issues the fetched instruction. The stage also reads the reg ister file. 3. E: Execute Stage.
Reference: [79] <author> Alexandru Nicolau, </author> <title> Percolation Scheduling: A Parallel Compilation Technique, </title> <type> TR 85-678, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, New York. </address> <month> May </month> <year> 1985. </year>
Reference-contexts: Hardware support for scheduling be yond basic blocks is pro vided by speculative execution. Software analysis techniques are then required to exploit the speculative execution mechanisms. Trace scheduling [30][27], percolation scheduling <ref> [79] </ref>, loop unrolling [110], and software pipelining [68] are some of the compiler techniques that have been explored in the past. Hardware branch prediction is an ef fective mechanism for reducing control 17 dependencies [18][100][64][28][114][71].
Reference: [80] <author> M.L. Nohr. </author> <title> Unix System V: Understanding ELF Object Files and Debugging Tools, </title> <publisher> PTR Prentice Hall, </publisher> <year> 1994. </year>
Reference-contexts: The execution driven simulator executes the compiled instruction stream using architecture parameters to estimate the pipeline architecture performance. In contrast, trace-driven 28 simulation uses a predetermined instruction sequence, an instruction trace. to estimate the performance metrics [53]. The pipeline execution-driven simulator executes compiled MIPS [55] binaries in ELF format <ref> [80] </ref> and uses the architecture parameters that describe the pipeline, the branch prediction mechanism, and the memory hierarch y to model the beha vior of various pipeline architecture configurations. The simulator models the system calls as C functions and is designed to be portable across several UNIX platforms.
Reference: [81] <author> Subbarao Palacharla, Norman P. Jouppi, James E. Smith. </author> <title> Quantifying the Complexity of Superscalar Processors. </title> <type> Technical Report CS-TR-96-1328, </type> <institution> University of Wisconsin-Madison, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: In the case of microprocessors that support out-of-order completion the result is written back to a reorder-buffer [91] or a shadow register file [106]. Processors 49 that support register renaming write the results back to the re gister file <ref> [81] </ref> [106] [57]. However, processors that only support in-order e xecution and in-order completion [26] can avoid the cost of register renaming and reorder-buffers. The critical component of the retire stage is the register file. <p> The bypass logic is responsible for bypassing the functional unit results that have not been written back into the re gister file to subsequent instructions. The bypass logic consists of three components: the bypass datapath, the bypass multiple xors, and the control logic <ref> [81] </ref>. 101 6.6.1 Structure [21] has a separate bus for each source pipestage and a wide multiplexor near the input to the function units [81] (in an y one stage there can be multiple function units in multiple issue processors). <p> The bypass logic consists of three components: the bypass datapath, the bypass multiple xors, and the control logic <ref> [81] </ref>. 101 6.6.1 Structure [21] has a separate bus for each source pipestage and a wide multiplexor near the input to the function units [81] (in an y one stage there can be multiple function units in multiple issue processors). The multiplexors bypass the results of the functional units to respectively the A and B inputs of the function units. <p> The k ey factor in the latency of the bypass logic is the delay due to the length of the bypass b usses (wire length). The control adds only a small fraction to this delay and is ignored in this study <ref> [81] </ref>. (b) Distributed Bypass Multiplexor and Control (b) . . . Bypass Stage FU Stage 2 . . . FU Stage n-1 FU Stage n Retire Stage A-input mux B-input mux . . . FU Stage 2 . . .
Reference: [82] <author> David Patterson, et. al., </author> <title> A Case for Intelligent RAM, </title> <journal> IEEE Micro, </journal> <volume> Vol. 17, No. 2, </volume> <month> March/April </month> <year> 1997. </year>
Reference-contexts: I will therefore discuss the structure and operation of only SRAM cache memories. 4. Researchers have recently proposed building a processor together with DRAM memory using a DRAM fabrication process <ref> [82] </ref>. At present, however, these DRAM processors are not widely used. 73 Dynamic TSPC n-latch. Solid lines are (0.1431 + 0.0337 fanout) for T pLH and (0.1431 + 0.0337 fanout) for T pHL. Diamonds and crosses represent simulated (Hspice) data, (b) Dynamic TSPC p-latch.
Reference: [83] <author> David A. Patterson and John L. Hennessy, </author> <title> Computer Organization & Design: The Hardware/Software Interface, </title> <publisher> Morgan Kaufmann Publishers, Inc. </publisher> <year> 1994. </year>
Reference-contexts: Performance is inversely proportional to the CPU execution time, T cpu . CPU performance can thus be stated as: Performance CPU 1/T CPU (1.1) T CPU is defined as the cycle time 1 , T cycle , times the CPU cycle count, Cycle Count CPU , for a program <ref> [83] </ref>. Equation 1.2 shows this relationship: T cpu = T cycle Cycle Count CPU (1.2) The Cycle Count CPU can in turn be defined as: Cycle Count CPU = (1.3) where I is the set of all instructions in the instruction set architecture, Dynamic Instruction 1.
Reference: [84] <author> Charles Price, </author> <title> MIPS IV Instruction Set, Revision 3.2, MIPS Technologies, </title> <publisher> Inc., </publisher> <month> September </month> <year> 1995. </year>
Reference: [85] <author> Jan M. Rabaey, </author> <title> Digital Integrated Circuits, A design Perspective, </title> <publisher> Pren-tice Hall, </publisher> <address> ISBN 0-13-178609-1, </address> <year> 1996. </year> <month> 156 </month>
Reference-contexts: 7-stage inte ger and a 9 stage load/store pipeline up from a 5-stage pipeline in the HP 7100 [8]. i 2 6 10 MIPS R4400 (8/10) [92] [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) <ref> [85] </ref> 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium (5/8) [96] Dec <p> The critical components of the decode stage are the issue logic, the re gister file, and the bypass logic. The execute stage consists of both parallel and pipelined function units. The ALU is the most critical function unit and the adder constitutes the most critical function of the ALU <ref> [85] </ref>. The critical component of the data fetch stage for processors with on-chip caches is the data cache. <p> This study pro vides a basis for determining the c ycle time of various pipeline architecture models presented in the following chapters. The control path produces the control signals for the datapath. The control path can be viewed as a finite state machine (FSM) <ref> [85] </ref>. The control path is designed using programmable logic arrays (PLAs) and instruction memory , or using basic logic g ates called random logic [85]. With the advent of synthesis tools, the trend is to use basic logic gates for control path design. <p> The control path produces the control signals for the datapath. The control path can be viewed as a finite state machine (FSM) <ref> [85] </ref>. The control path is designed using programmable logic arrays (PLAs) and instruction memory , or using basic logic g ates called random logic [85]. With the advent of synthesis tools, the trend is to use basic logic gates for control path design. <p> For a processor without hardw are branch prediction, the c ycle count increases by roughly 203%, 83%, and 77%, for, respectively, a single, dual, and quad-issue processor. 5.4 Adder Pipeline Depth The adder is the critical component in the design of the ALU <ref> [85] </ref>. In this section, I measure the effect of the adder pipeline depth on the performance. <p> Figure 6.2 shows an example of both logic styles. P-logic netw orks must have large transistors to compensate for the lower mobility of the p-mos transistor. P-logic networks therefore have a higher capacitance than an equi valent n-logic network <ref> [85] </ref>. In terms of the capacitance domino logic has to dri ve less capacitance than np-CMOS logic because n-networks have smaller transistors and hence lo wer capacitances. Np-CMOS (also called modified domino or zipper logic) is 20% f aster than domino because of the absence of the static inverter [85]. <p> network <ref> [85] </ref>. In terms of the capacitance domino logic has to dri ve less capacitance than np-CMOS logic because n-networks have smaller transistors and hence lo wer capacitances. Np-CMOS (also called modified domino or zipper logic) is 20% f aster than domino because of the absence of the static inverter [85]. Np-CMOS logic, however, suffers from very low noise margins [85]. This logic style has therefore not been found to be v ery practical. <p> Np-CMOS (also called modified domino or zipper logic) is 20% f aster than domino because of the absence of the static inverter <ref> [85] </ref>. Np-CMOS logic, however, suffers from very low noise margins [85]. This logic style has therefore not been found to be v ery practical. <p> diagram of a 1stage re gister file. implementation assumes that the re gister-file provides an internal bypass operation for a read and a write operation to the same register in the same cycle. 6.5 The Adder One of the speed-limiting elements in the design of the ALU is the adder <ref> [85] </ref>. <p> Hspice measurements sho w one g ate delay to be 0.3 ns. This is the approximation I have used for the multiplexor delay. The RC delay of a long interconnect line can be reduced by inserting intermediate buffers called repeaters <ref> [85] </ref> (see Figure 6.28) [36]. Each RC line segment is modeled with a p model and each repeater is S times larger than the previous one. I approximate the delay of the unperturbed line (without the repeaters) using the Elmore delay model [85]. <p> be reduced by inserting intermediate buffers called repeaters <ref> [85] </ref> (see Figure 6.28) [36]. Each RC line segment is modeled with a p model and each repeater is S times larger than the previous one. I approximate the delay of the unperturbed line (without the repeaters) using the Elmore delay model [85]. The Elmore delay approximates the time constant, t L (N), of a distributed RC delay of an unperturbed wire as: (6.8) where N = L/DL represents the number of sections in the wire, r is the resistance and c is the capacitance of each wire section of length DL. <p> For N fi , the equation reduces to <ref> [85] </ref>: where R metal is the resistance of the wire per unit length and C metal is the capacitance of p-model 1 (unit size) S S 2 Wire Delay intrinsic t L N ( ) r c LD ( ) 2 N N 1+( ) - = = R metal C
Reference: [86] <author> George Radin. </author> <title> The 801 Minicomputer. </title> <booktitle> Proceeding of the ASPLOS, </booktitle> <address> Palo Alto, California, </address> <month> March </month> <year> 1982, </year> <pages> pages 39-47. </pages>
Reference: [87] <author> C.V. Ramamoorthy and H.F. Li. </author> <title> Pipeline Architecture. </title> <journal> ACM Computing Surveys, </journal> <volume> vol. 9, no. 1, </volume> <month> March </month> <year> 1977, </year> <pages> pages 61-102. </pages>
Reference-contexts: Ramamoorthy and Li <ref> [87] </ref> ha ve proposed a taxonomy of pipelines based on three parameters: 19 1. Unifunction versus multifunction: A unifunction pipeline performs only one fixed function, such as only a floating point addition. A multifunction pipeline can perform different functions. 2. Static versus dynamic.
Reference: [88] <author> Barton J. Sano and Alvin M. Despain. </author> <title> The 16-Fold Way: A Microparallel Taxonomy. </title> <booktitle> In the 26th International Symposium on Microarchitecture. </booktitle> <month> December </month> <year> 1993. </year>
Reference-contexts: HP PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) <ref> [88] </ref> [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium (5/8) [96] Dec Alpha 21164a (7/7/9) [96] HP 8000 (7/9/9) # - # (decoupled pipe) 5 Dec Alpha n HP PA-RISC s Intel i Motorola m PowerPC u SGI t Sparc t 15 2.2 The Search for the <p> Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) <ref> [88] </ref> [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium (5/8) [96] Dec Alpha 21164a (7/7/9) [96] HP 8000 (7/9/9) # - # (decoupled pipe) 5 Dec Alpha n HP PA-RISC s Intel i Motorola m PowerPC u SGI t Sparc t 15 2.2 The Search for the Highest Performance Pipeline Depth Two studies pertain
Reference: [89] <author> Barton J. Sano. </author> <title> Microparallel Processors. </title> <type> Ph.D. Thesis, </type> <institution> University of Southern California, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: [92] [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) <ref> [89] </ref> Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium (5/8) [96] Dec Alpha 21164a (7/7/9) [96] HP 8000 (7/9/9) # - # (decoupled pipe) 5 Dec Alpha n HP PA-RISC s Intel i Motorola m PowerPC u SGI <p> A stage is called dynamic if it alters the order of instructions in the instruction stream. In contrast, a static stage leaves the order of the processed instruction stream unchanged. 22 In this dissertation, I describe a slight v ariant of Sano and Despains <ref> [89] </ref> taxonomy. The taxonomy proposed here uses the four abstract stages of a pipeline and classifies them according to in-order (I) or out-of-order (O) behavior. Examples of out-of-order beha vior are: 1. Out-of-order fetch. Decoupled fetch is an example of an out-of-order fetch stage. <p> Write Circuitry: To implement fast writes, the write circuitry also uses differential dual-rail busses to perform a write operation. 6.4.2 Register File Circuit Timing This section presents the circuits an timing estimates for the 4 register file components. The timing estimates are based on Srivastavas [101], Sanos <ref> [89] </ref>, and Irissous [51] study. The wordline decoder is a nor-decoder. Alowersson [4] has reported f aster decoders and senseamplifier circuits for re gister files, however, these timings are for a dual-rail read register file. The register file presented here assumes a single-ended read port. <p> ALU 2,900 ALU consisting of an adder, barrel shiftier and logic unit Adder 1,300 32-bit adder Barrel Shifter 1,300 32-bit full barrel shifter Logic Unit 300 Logical AND, OR, XOR operations Staging Latch 120 Simple non-inverting latch Driver 250 Four stage dynamic buffer driver Table 6.4: Widths of VLSI Modules <ref> [89] </ref> 107 Now let us put some real numbers (using the values from Table 6.5) into this equation. <p> This section studies the impact of multi-ported SRAM memory cells on the cache cycle time. The effect of multiple-issue processors on the cache cycle time is based on actual layouts of memory cells <ref> [89] </ref> and cache latencies obtained from a modif ied version of Cacti [112]. The latencies of the cache micro-operations are obtained by running Cacti with the memory cell dimensions of Table 8.1. <p> 0.96 0.96 Wordline Drive Delay (ns) 0.93 0.96 1.09 Bitline Drive and Senseamplifier Read Delay (ns) 1.05 1.23 1.54 Write Data Delay (ns) &lt; read delay &lt; read delay &lt; read delay Data Output Driver Delay (ns) 0.71 0.71 0.71 Table 8.4: Register File Cell Latencies for Multi-Ported Register Files <ref> [89] </ref> Register File Pipeline Configuration Single-Issue (W = 1) Ports = 3 Dual-Issue (W = 2) Ports = 6 Quad-Issue (W = 4) Ports = 12 1-Stage Register File (ns) 4.06 ns (246 MHz) 4.18 ns (239 MHz) 4.80 ns (208 MHz) 2-Stage Register File (ns) 2.44 ns (410 MHz) 2.80
Reference: [90] <author> Yiannakis Sazeides and Stamatis Vassiliadis. </author> <title> The Performance Potential of Data Dependence Speculation & Collapsing. </title> <booktitle> Proceedings of the 29 th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO-29), </booktitle> <address> Paris, France, </address> <month> December 2-4, </month> <year> 1996, </year> <pages> pages 238-247. </pages>
Reference: [91] <author> Anne P. Scott, Kevin P. Burkhart, Ashok Kumar, Richard M. Blumbert, and Gregory L. Ranson. </author> <title> Four-Way Superscalar PA-RISC Processors. </title> <journal> Hewlett-Packard Journal, </journal> <month> August </month> <year> 1997. </year>
Reference-contexts: The retire stage involves writing the final result back into the register file. In the case of microprocessors that support out-of-order completion the result is written back to a reorder-buffer <ref> [91] </ref> or a shadow register file [106]. Processors 49 that support register renaming write the results back to the re gister file [81] [106] [57]. However, processors that only support in-order e xecution and in-order completion [26] can avoid the cost of register renaming and reorder-buffers.
Reference: [92] <author> Daniel P. Siewiorek, C. Gordon Bell, Allen Newell. </author> <title> Computer Structures: Principles and Examples. </title> <publisher> McGraw-Hill Inc., </publisher> <year> 1982. </year>
Reference-contexts: The HP 8000 [62] has a 7-stage inte ger and a 9 stage load/store pipeline up from a 5-stage pipeline in the HP 7100 [8]. i 2 6 10 MIPS R4400 (8/10) <ref> [92] </ref> [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] <p> The HP 8000 [62] has a 7-stage inte ger and a 9 stage load/store pipeline up from a 5-stage pipeline in the HP 7100 [8]. i 2 6 10 MIPS R4400 (8/10) <ref> [92] </ref> [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical <p> The HP 8000 [62] has a 7-stage inte ger and a 9 stage load/store pipeline up from a 5-stage pipeline in the HP 7100 [8]. i 2 6 10 MIPS R4400 (8/10) <ref> [92] </ref> [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) <p> The critical component of the data fetch stage for processors with on-chip caches is the data cache. I consider only the implementation of the cache and not the translation-lookaside buffer (TLB) <ref> [92] </ref>, since the TLB is much simpler than the design of the cache and can be accessed in parallel [26]. The retire stage involves writing the final result back into the register file.
Reference: [93] <author> Dezso Sima, Terence Fountain, Peter Kacsuk. </author> <title> Advanced Computer Architectures: A Design Space Approach. </title> <publisher> Addison-Wesley Longman 1997. </publisher>
Reference-contexts: [62] has a 7-stage inte ger and a 9 stage load/store pipeline up from a 5-stage pipeline in the HP 7100 [8]. i 2 6 10 MIPS R4400 (8/10) [92] [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 <ref> [93] </ref> PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium <p> 1990 <ref> [93] </ref> PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium (5/8) [96] Dec Alpha 21164a (7/7/9) [96] HP 8000 (7/9/9) # - # (decoupled pipe) 5 Dec Alpha n HP PA-RISC s Intel i Motorola m PowerPC u SGI t Sparc t 15 2.2 The Search for the Highest Performance Pipeline Depth Two studies pertain directly to the search <p> The first layout type performs only one micro-operation at a time. Figure 3.1 sho ws an example of a 4-stage pipeline architecture. The 4-stage pipeline is laid out for register-register instructions <ref> [93] </ref>. Examples of a 4-stage pipeline are Sparc processors and the PowerPC [40][78]. The second type performs multiple cascaded micro-operations (see Figure 3.1). <p> Retire Stage (R): The retire stage is the last stage where the result of the computation is committed. The 5-stage pipeline is laid out for the execution of both register-register and memory operations that require the ALU to perform an address calculation <ref> [93] </ref>. I ha ve therefore chosen the 5-stage pipeline with complete bypassing as a reference pipeline architecture in this dissertation. Complete bypassing implies that a result of a functional unit is forwarded as soon as it is available. <p> Two parameters determine the issue logic: issue order and alignment of issue <ref> [93] </ref>.
Reference: [94] <author> Satya Simha, </author> <title> R4400 Microprocessor Product Information, MIPS Technologies, </title> <publisher> Inc., </publisher> <address> 2011 N. Shoreine Blvd. P.O. Box 7311, Mountain View, CA 94039-7311. </address>
Reference-contexts: PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] <ref> [94] </ref> PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium (5/8) [96] Dec Alpha 21164a (7/7/9) [96] HP 8000 (7/9/9) # - # (decoupled pipe) 5 Dec Alpha n HP PA-RISC s Intel i Motorola m PowerPC u SGI t Sparc t 15 2.2 The Search for the Highest
Reference: [95] <author> Michael D. Smith, Mike Johnson, and Mark A. Horowitz. </author> <title> Limits on Multiple Instruction Issue. </title> <booktitle> Third International Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 290-302, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: The HP 8000 [62] has a 7-stage inte ger and a 9 stage load/store pipeline up from a 5-stage pipeline in the HP 7100 [8]. i 2 6 10 MIPS R4400 (8/10) [92] [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] <ref> [95] </ref> Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) MIPS <p> the HP 7100 [8]. i 2 6 10 MIPS R4400 (8/10) [92] [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] <ref> [95] </ref> Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 [96] MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium (5/8) [96] Dec Alpha 21164a (7/7/9) [96] HP 8000 (7/9/9) # - # (decoupled pipe) 5 Dec Alpha
Reference: [96] <author> Michael Smith, Monica Lam, and Mark Horowitz. </author> <title> Boosting Beyond Static Scheduling in a Superscalar Processor. </title> <booktitle> Proceedings of the 17th Annual Int. Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: 2 6 10 MIPS R4400 (8/10) [92] [92] Dec Alpha 21064 (7/7/10) 12 Pipeline Depth HP PA7100 (5/6) [92] [95] Sparc64 (4/5) Year 1960 1970 1980 1990 [93] PowerPC601 (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 <ref> [96] </ref> MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium (5/8) [96] Dec Alpha 21164a (7/7/9) [96] HP 8000 (7/9/9) # - # (decoupled pipe) 5 Dec Alpha n HP PA-RISC s Intel <p> (4/5/6) [85] 68020 (3) CRAY1-S (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 <ref> [96] </ref> MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium (5/8) [96] Dec Alpha 21164a (7/7/9) [96] HP 8000 (7/9/9) # - # (decoupled pipe) 5 Dec Alpha n HP PA-RISC s Intel i Motorola m PowerPC u SGI t Sparc t 15 2.2 The Search for the Highest Performance Pipeline Depth Two studies pertain directly to the search for the pipeline <p> (/6) [76] LARC (2) [59] [61] STRETCH (4) [1834] Babbages 1834 [95] Pentium Pro (8-14/14/16) 2000 <ref> [96] </ref> MIPS R10000 (5/6/7) 68040 (6/6) [89] Analytical Engine mProcessors Mainframes integer/ld-st/oating-point integer/oating-point 80386 (7-4-3) [88] [94] PowerPC604 (4/5/6) MIPS R3000 (5) [88] [78] 8086 (1) [93] Pentium (5/8) [96] Dec Alpha 21164a (7/7/9) [96] HP 8000 (7/9/9) # - # (decoupled pipe) 5 Dec Alpha n HP PA-RISC s Intel i Motorola m PowerPC u SGI t Sparc t 15 2.2 The Search for the Highest Performance Pipeline Depth Two studies pertain directly to the search for the pipeline depth that achieves the highest
Reference: [97] <author> Michael D. Smith, </author> <title> Support for Speculative Execution in High-Performance Processors. </title> <type> Ph.D. Thesis, </type> <institution> Stanford, </institution> <month> November </month> <year> 1992. </year> <month> 157 </month>
Reference: [98] <author> Michael D. Smith, Mark Horowitz and Monica S. Lam. </author> <title> Efficient Superscalar Perforamnce Through Boosting. I ASPLOS-V, </title>
Reference: [99] <institution> SPEC (Standard Performance Evaluation Corporation) 95 Benchmark Suite. </institution> <address> 10754 Ambassador Drive, Suite 201, Manassas, VA 20109, </address> <year> 1995. </year>
Reference-contexts: In deeper pipelines, de veloped in Chapter 7, the latencies are scaled linearly. The SPEC integer benchmarks <ref> [99] </ref> also execute some oating-point instructions, primarily for some of the built-in C functions (e.g. printf). The simulator implements a subset of the MIPS floating point instructions (for a detailed description see MIPS architecture manual [55]). <p> The memory contention latency is set to zero for all simulations because I am only modeling the execution of a single processor. 4.2 Benchmarks The performance of various processor pipeline architectures are compared by running benchmarks taken from the SPECInt95 <ref> [99] </ref>, Dhrystone, and Aquarius Benchmark Suite [45]. <p> A major step in determining this is the question posed and answered in this dissertation: What pipeline depth pro vides the highest performance for single-chip integer processors. The inte ger benchmarks studied in this dissertation are taken primarily from the SPECInt95 benchmark suite <ref> [99] </ref>. The scope of this dissertation was the design space of single and multiple in-order issue processors. The thesis of this dissertation w as that the highest-performance pipelined processor would be pipelined beyond a depth of ten and w ould support speculative execution.
Reference: [100] <author> Apoorv Srivastava and Alvin M. Despain. </author> <title> Prophetic Branches: A Branch Architecture for Code Compaction and Efficient Execution. </title> <booktitle> Proceedings of the 26th Annual Int. Symp. on Microarchitecture, </booktitle> <month> December </month> <year> 1993. </year>
Reference: [101] <author> Apoorv Srivastava, Amar Chadha, Alvin M. Despain. </author> <title> A Pseudo 5-Ported 200 MHz Register File. </title> <institution> ACAL-TR-95-08, Advanced Computer Architecture Lab, University of Southern California, </institution> <address> Los Angeles, CA 90089. </address>
Reference-contexts: Write Circuitry: To implement fast writes, the write circuitry also uses differential dual-rail busses to perform a write operation. 6.4.2 Register File Circuit Timing This section presents the circuits an timing estimates for the 4 register file components. The timing estimates are based on Srivastavas <ref> [101] </ref>, Sanos [89], and Irissous [51] study. The wordline decoder is a nor-decoder. Alowersson [4] has reported f aster decoders and senseamplifier circuits for re gister files, however, these timings are for a dual-rail read register file. The register file presented here assumes a single-ended read port.
Reference: [102] <author> Apoorv Srivastava, Yong-Seon Koh, Alvin M. Despain. </author> <title> 190-MHz CMOS 4-Kbyte Pipelined Caches. </title> <booktitle> In Int. Symposium on Circuits and Systems. </booktitle> <address> Seattle, Washington, USA. April 30-May 3, </address> <year> 1995 </year>
Reference-contexts: This allows the pull-down transistors (nmos), which have a higher mobility than pull-up transistors (pmos), to pull-down one of the bitlines. For saving power, the bitlines in my cache implementation are charged only to a voltage of Vdd - V t <ref> [102] </ref>, where V t is the threshold voltage. 3. The Bitline Select Multiplexer and Read Sense Amplifier: The bitline select multiplexer is used in some cache organizations to reduce the number of read sense amplifiers [112]. The bitline select multiplexer selects one bitline from N spd bitlines.
Reference: [103] <author> Harold S. Stone, Tien Chi Chen, Samual H. Fuller, William G. Lane, Her-schel H. Loomis Jr., William M. McKeeman, Kay B. Magleby, Richard E. Matick, Richard Sites, and Thomas M. Whitney. </author> <title> Introduction to Computer Architecture. </title> <publisher> Science Research Associates, Inc., </publisher> <year> 1980. </year>
Reference-contexts: Tien Chi Chen, Introduction to Computer Architecture (1980), chapter Overlap and Pipeline Processing, Stone et al. <ref> [103] </ref> 2.1 A Brief History of Pipelined Processor Design Pipelining in terms of segmenting the instruction execution was first used in Babbages Analytical Engine [11] b uilt in 1840 (see Figure 2.1). <p> The Analytical Engine had a four - stage pipeline: fetch an operand, add or subtract an operand, con vert partial result to the sign and magnitude notation, and finally transfer result to the store. Some of the early machines lik e the UNIVAC I started with overlap. Chen <ref> [103] </ref> describes overlap as the phenomenon of concurrent processing, often to wards some well-defined common goal. (Pipelining is merely taking the concept of o verlapping to an extreme.) The UNIVAC I (1951) had special I/O buffers which allowed program execution to overlap with certain limited I/O acti vities [103]. <p> Chen <ref> [103] </ref> describes overlap as the phenomenon of concurrent processing, often to wards some well-defined common goal. (Pipelining is merely taking the concept of o verlapping to an extreme.) The UNIVAC I (1951) had special I/O buffers which allowed program execution to overlap with certain limited I/O acti vities [103]. However, fully overlapped I/O involv 12 ing timesharing of memory and asynchronous channels be gan with the IBM 705 (1958) [103]. The IBM 7094, and the IBM 7094 II took the overlapping concept further by overlapping the instruction fetch with the data execution [103]. <p> taking the concept of o verlapping to an extreme.) The UNIVAC I (1951) had special I/O buffers which allowed program execution to overlap with certain limited I/O acti vities <ref> [103] </ref>. However, fully overlapped I/O involv 12 ing timesharing of memory and asynchronous channels be gan with the IBM 705 (1958) [103]. The IBM 7094, and the IBM 7094 II took the overlapping concept further by overlapping the instruction fetch with the data execution [103]. The STRETCH and the LARC [25] were the first electronic computers to use pipelin-ing by segmenting instructions. <p> with certain limited I/O acti vities <ref> [103] </ref>. However, fully overlapped I/O involv 12 ing timesharing of memory and asynchronous channels be gan with the IBM 705 (1958) [103]. The IBM 7094, and the IBM 7094 II took the overlapping concept further by overlapping the instruction fetch with the data execution [103]. The STRETCH and the LARC [25] were the first electronic computers to use pipelin-ing by segmenting instructions. The performance goal of the STRETCH w as a 100-fold improvement over the older 704. The STRETCH achie ved this goal only for lar ger programs that strained the 704. <p> The STRETCH achie ved this goal only for lar ger programs that strained the 704. The memory technology in the STRETCH w as six times faster (2 ms versus 12 ms) and logic technology w as ten times f aster <ref> [103] </ref>. The memory and logic technology together pro vided a 10-fold improvement in performance. Kogge [59] writes that the rest of the performance increase came primarily from pipelining the STRETCH in two stages: an instruction fetch/decode and a data e xecution stage.
Reference: [104] <author> G.S. Tjaden and Michael J. Flynn. </author> <title> Detection and parallel execution of independent instructions. </title> <journal> IEEE Trans. on Computers, </journal> <volume> vol. C-19, no. 10, </volume> <pages> pp. 889-895, </pages> <month> October </month> <year> 1970. </year>
Reference: [105] <author> Ren-Song Tsay. </author> <title> Exact Zero Skew. </title> <publisher> IEEE, </publisher> <year> 1991. </year>
Reference: [106] <author> Nader Vasseghi, Kenneth Yeager, Egino Sarto, and Mahdi Seddigh-nezhad, </author> <title> 200-MHz Superscalar RISC Microprocessor, </title> <journal> IEEE Journal of Solid-Stage Circuits, </journal> <volume> Vol. 31, No. 11, </volume> <month> November </month> <year> 1996. </year>
Reference-contexts: The goal of superpipelined processors is to achieve an effective IPC as close as possible to one. The effective IPC of superscalar processors is occasionally two, but rarely higher [46]. Most current processors tend to be both pipelined and superscalar (e.g. MIPS R10000 <ref> [106] </ref>, Dec Alpha 21264 [42][57]). 2. Clock frequency = . Both the terms frequency and cycle time are used throughout this dissertation. 3. <p> This study seeks to prove the thesis for integer benchmarks taken primarily from the Spec 95 benchmark suite. The pipelined machine models are v alidated from components constructed and fabricated in a 0.8 mm CMOS technology. In the quest for performance most single-chip microprocessors, lik e the MIPS R10000 <ref> [106] </ref> and the Dec Alpha 21264 [42], use both superscalar and superpipelining techniques. The scope of this dissertation is restricted to the in-order single and multiple-issue processors. <p> For example the pipeline depth has changed from a 3-stage pipeline in the 8086 [50] to an 8 and a 14-stage (decoupled) pipeline on the Pentium Pro [41]. MIPS reversed its trend toward pipelining with the MIPS R10000 s <ref> [106] </ref> decoupled pipeline. The pipeline depth for the inte ger and the load/store unit in the MIPS R10000 [39][106] is, respectively, five and six. <p> The retire stage involves writing the final result back into the register file. In the case of microprocessors that support out-of-order completion the result is written back to a reorder-buffer [91] or a shadow register file <ref> [106] </ref>. Processors 49 that support register renaming write the results back to the re gister file [81] [106] [57]. However, processors that only support in-order e xecution and in-order completion [26] can avoid the cost of register renaming and reorder-buffers. <p> In the case of microprocessors that support out-of-order completion the result is written back to a reorder-buffer [91] or a shadow register file <ref> [106] </ref>. Processors 49 that support register renaming write the results back to the re gister file [81] [106] [57]. However, processors that only support in-order e xecution and in-order completion [26] can avoid the cost of register renaming and reorder-buffers. The critical component of the retire stage is the register file.
Reference: [107] <author> Tomohisa Wada, Suresh Rajan, and Steven A. Przybylski. </author> <title> An analytical Access Time Model for On-Chip Cache Memories. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> Vol. 27, No. 8 </volume> <pages> 1147-1156, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: 2 4 6 8 10 Delay (ns) T pLH Hspice T pHL Hspice Fanout (number of unit size inverters) (a) n-latch (b) p-latch 0.1 0.2 0.3 0.4 0 2 4 6 8 10 Delay (ns) Fanout (number of unit size inverters) T pLH Hspice T pHL Hspice 74 6.3.1 Structure <ref> [107] </ref> have presented the following three architecture parameters (see Figure 6.6) for a cache memory: block size in bytes ( B), associativity (A), and the number of sets ( S). The cache size in bytes is C = S B A [107]. Wada et. al. [107] and Wilton and Jouppi [112] <p> T pLH Hspice T pHL Hspice 74 6.3.1 Structure <ref> [107] </ref> have presented the following three architecture parameters (see Figure 6.6) for a cache memory: block size in bytes ( B), associativity (A), and the number of sets ( S). The cache size in bytes is C = S B A [107]. Wada et. al. [107] and Wilton and Jouppi [112] also introduce 3 VLSI-layout parameters: There are: the number of w ordline segments (N dwl ), the number of bitline segments (N dbl ), and the number of sets per wordline (N spd ). <p> pHL Hspice 74 6.3.1 Structure <ref> [107] </ref> have presented the following three architecture parameters (see Figure 6.6) for a cache memory: block size in bytes ( B), associativity (A), and the number of sets ( S). The cache size in bytes is C = S B A [107]. Wada et. al. [107] and Wilton and Jouppi [112] also introduce 3 VLSI-layout parameters: There are: the number of w ordline segments (N dwl ), the number of bitline segments (N dbl ), and the number of sets per wordline (N spd ). <p> Figure 6.7 shows various abstract cache layouts based on the above mentioned parameters. Typical cache organizations are shown in Figure 6.7 <ref> [107] </ref>. The design of a large array needs to be split into smaller array se gments, because accessing large arrays requires a longer cycle time. N dwl N bwl is the number of sub-arrays that form the cache. The cache consists of six main sub-modules.
Reference: [108] <author> David W. Wall. </author> <title> Limits of Instruction-Level Parallelim. </title> <booktitle> Proceedings of the Fourth Int. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 176-188, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: The hazards that cause instruction dependencies are: structural, data, and control. The utilization of the pipeline can be increased by reducing the effect of the three hazards. Both Wall <ref> [108] </ref>, and Lam and Wilson [69] found that the instruction level parallelism (ILP) in non-numeric benchmarks without going across basic block boundaries w as limited to two.
Reference: [109] <author> Shlomo Weiss and James E. Smith. </author> <title> Instruction Issue Logic in Pipelined Supercomputers. </title> <journal> IEEE Trans. on Computers, </journal> <volume> vol. c-33, no. 11, </volume> <month> Nov. </month> <year> 1984. </year> <month> 158 </month>
Reference: [110] <author> Shlomo Weiss and James E. Smith. </author> <title> A Study of Scalar Compilation Techniques for Pipelined Supercomputers. </title> <booktitle> Proceedings of the Second Int. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1987, </year> <pages> pages 105-109. </pages>
Reference-contexts: Hardware support for scheduling be yond basic blocks is pro vided by speculative execution. Software analysis techniques are then required to exploit the speculative execution mechanisms. Trace scheduling [30][27], percolation scheduling [79], loop unrolling <ref> [110] </ref>, and software pipelining [68] are some of the compiler techniques that have been explored in the past. Hardware branch prediction is an ef fective mechanism for reducing control 17 dependencies [18][100][64][28][114][71].
Reference: [111] <author> Neil H.E. Weste and Kamran Eshraghian. </author> <title> Principlesof CMOS VLSI Design: A Systems Perspective. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1985 </year>
Reference: [112] <author> Steven J.E. Wilton and Norman P. Jouppi. </author> <title> An Enhanced Access and Cycle Time Model for On-Chip Caches. </title> <note> WRL Research Report 93/5, </note> <institution> Western Research Laboratory, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: I begin by presenting a typical CMOS implementation of the module. Following this I give an analysis of the delay of each sub-circuit of the module and present the Hspice results. I have used data from some of the related w ork <ref> [112] </ref> for estimating the pipeline performance of the cache. The analysis of the latches, the adder, and the register file is based on Hspice simulations on netlists e xtracted from layout. The e xtractor includes the parasitic capacitances. <p> The cache size in bytes is C = S B A [107]. Wada et. al. [107] and Wilton and Jouppi <ref> [112] </ref> also introduce 3 VLSI-layout parameters: There are: the number of w ordline segments (N dwl ), the number of bitline segments (N dbl ), and the number of sets per wordline (N spd ). <p> N dwl and N dbl determine how many sub-arrays constitute the cache. These two parameters imply the duplication of the row decoders, row drivers, and the sense amplifier read circuitry. The total number of sub-arrays is N dwl N dbl . Wilton and Jouppi <ref> [112] </ref> have introduced the parameter N spd that affects the aspect ratio of the data and tag arrays. <p> The Bitline Select Multiplexer and Read Sense Amplifier: The bitline select multiplexer is used in some cache organizations to reduce the number of read sense amplifiers <ref> [112] </ref>. The bitline select multiplexer selects one bitline from N spd bitlines. The read sense amplifier is used to sense quickly voltage differences on the bitlines and read the value of the storage cell. Most current implementations use dual rail bitlines: bit-line and bit-line-bar. 4. <p> The timing estimates are based on a modified version of a cache timing estimation program, Cacti, written by Wilton and Jouppi <ref> [112] </ref>. The timing information is derived for a 0.8 mm CMOS technology. The six components once again are: 1. Row Decoder and Wordline Drivers 2. Data and Tag Array 3. Bitline Select Multiplexors and Read Sense Amplifiers 4. Tag Comparator 5. Block Multiplexor Driver Circuit 6. <p> Wilton and Jouppi and chosen a 3-input NAND to implement the NAND-decoder <ref> [112] </ref>. In high-speed design its preferable to use domino logic, since the output inverter of an AND or and OR-gate can be ratioed to switch fast (move the v thdecdrive to switch closer to Vdd). <p> The cache results in this dissertation are, ho wever, based on Wilton and Jouppis cache model <ref> [112] </ref>. 6.3.2.2 The Data and Tag Arrays The data and tag array consists of a memory storage cell replicated se veral times. Access to the memory cell is through pass transistors whose gate is connected to the word-line select. The wordlines are enabled by the w ordline drivers. <p> The important parameter here is the bitline delay. The bitline delay is the delay from the time that the pass transistors of the memory cell are enabled to the time the bitline voltage has dropped V bitsense below its maximum value <ref> [112] </ref>. 6.3.2.3 Bitline Select Multiplexor and Read Sense Amplifier precharge precharge 3 Memory Cell 2/3 wordline select Diff. Sense Amplifier read data Read Sense Amplifier & Precharge bitline bitline Equilibrium Transistor. precharge 80 6.3.2.4 The Tag Comparator The tag comparator circuitry is an OR of XORed bits. <p> Therefore, there are tri-stated buffers of each b o bits. The A comparators produce the match signals for the block multiplexor driver cir cuits. The address bits for selecting the appropriate block form the other inputs to the Multiplexor Driver and Block Select Output Driver <ref> [112] </ref> (b) Logic Diagram for the Block Multiplexor Driver Circuit (c) Circuit Dia gram of the Block Multiplexor Driver Circuit (Static CMOS) [112] Block mux driver circuit . . . <p> The address bits for selecting the appropriate block form the other inputs to the Multiplexor Driver and Block Select Output Driver <ref> [112] </ref> (b) Logic Diagram for the Block Multiplexor Driver Circuit (c) Circuit Dia gram of the Block Multiplexor Driver Circuit (Static CMOS) [112] Block mux driver circuit . . . <p> The node EVAL is kept high until roughly three inverter chain delays after the generation of b n signals. This is achieved by adding a dummy row to the tag array and using a timing chain driven by a sense amplifier reading a value from the dummy row <ref> [112] </ref>. 6.3.3 Pipelined Structure The key to the design of a highspeed cache is pipelined e xecution. This section discusses how to pipeline the various cache components presented in the previous sections. This section estimates the cycle time of various cache pipelined configurations. <p> This section estimates the cycle time of various cache pipelined configurations. Using the cache structure presented in Figure 6.6, I deri ve a model for pipelined e xecution. I modified the Cacti cache timing simulator <ref> [112] </ref> to derive estimates for each sub-module. sel sel senseout out 83 The timing estimates from Cacti are based on the static CMOS design style. The use of dynamic CMOS gates results in shorter latencies in man y cases. <p> This section studies the impact of multi-ported SRAM memory cells on the cache cycle time. The effect of multiple-issue processors on the cache cycle time is based on actual layouts of memory cells [89] and cache latencies obtained from a modif ied version of Cacti <ref> [112] </ref>. The latencies of the cache micro-operations are obtained by running Cacti with the memory cell dimensions of Table 8.1. The cycle time is affected by primarily the layout of the SRAM memory cell.Table 8.1 shows the sizes of a 1-port, 2-port, and 4-port SRAM cells.
Reference: [113] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> Alternative Implementations of Two-Level Adaptive Branch Prediction. </title> <booktitle> The 19th Annual International Symposium on Computer Architecture. </booktitle> <month> May 19-21, </month> <year> 1992, </year> <pages> pages 124-134. </pages>
Reference-contexts: Branch gsh (8) PAs (16,1) P1c P2c P1c-P2c operation 0 0 0 (no change) 0 1 -1 (decrement cnt) 1 0 1 (increment cnt) 1 1 0 (no change) P1c-P2c useP1 Branch Prediction b=10 PC History Table Pattern History Table History Table Selection Table (BPST) 33 level adaptive branch predictor <ref> [113] </ref>. The h ybrid branch predictor is a good choice because McFarling and Chang et al. have shown that its performance is better than any of the two predictors alone [16][71][114]. The gsh (m) predictor is a modified variation of the two-level branch predictor [113] where the branch history is stored <p> (BPST) 33 level adaptive branch predictor <ref> [113] </ref>. The h ybrid branch predictor is a good choice because McFarling and Chang et al. have shown that its performance is better than any of the two predictors alone [16][71][114]. The gsh (m) predictor is a modified variation of the two-level branch predictor [113] where the branch history is stored in a global re gister of m-bits. In the gshare variant the bits of the global register are XORed with the bits of the program counter to form an index into the pattern history table.
Reference: [114] <author> T. Yeh and Y. Patt. </author> <title> A Comparison of Dynamic Branch Predictors that use Two Levels of Branch History. </title> <booktitle> Proc. 20th Ann. Int. Symp. on Computer Architecture, </booktitle> <month> May </month> <year> 1993. </year>
Reference: [115] <author> Kenneth Yip, </author> <title> Clock Tree Distribution. </title> <journal> IEEE Potentials, </journal> <month> April/May </month> <year> 1997. </year>
Reference: [116] <author> Honesty C. Young, </author> <title> Evaluation of a Decoupled Architecture and the Design of a Vector Extension, </title> <note> Computer Sciences Technical Report #603, </note>
Reference-contexts: Out-of-order fetch. Decoupled fetch is an example of an out-of-order fetch stage. Decoupled fetch implies having two independent instruction streams with no synchronization across the streams, which in turn implies having independent program counters. Decoupled architectures have been the subject of various studies <ref> [116] </ref> and are outside the scope of this dissertation. 2. Out-of-order issue. Once instructions are fetched they can be issued in-order or out-of-order. Out-of-order issue requires a buffer such as a reservation station where instructions wait before they are issued. 3. Out-of-order execute.
Reference: [117] <author> Jiren Yuan and Christer Svensson. </author> <title> High-Speed CMOS Circuit Technique. </title> <journal> In IEEE Journal of Solid-State Circuits, </journal> <volume> Vol. 24, No. 1, </volume> <month> Februrary </month> <year> 1989. </year> <month> 159 </month>
Reference-contexts: Propagation overhead can be reduced by merging the latch with the logic. An example of this is the Earle latch [24][43]. Similar merging of the latch and logic has also been proposed for dynamic CMOS logic <ref> [117] </ref>. Others ha ve proposed low overhead dynamic latches consisting of only a transmission gate and an inverter [10][106]. Data skew can be reduced by careful design where the delay of all stages are made roughly equal. This involves detailed circuit-level simulations on netlists annotated with parasitic capacitances and resistances. <p> time of the modules, because the mismatch in the clock routing is taken into account in Hspice simulations [75] on netlists extracted from layout. 6.2 Logic Styles for High-Speed Processor Design A promising approach to high-speed circuit design is the use of single phase dynamic logic <ref> [117] </ref>[2]. Yuan and Svensson [117] have showed that circuits in e xcess of 200 MHz can be fabricated in 3.0 mm CMOS technology. Lu et al. [67] ha ve used single phase dynamic logic successfully to b uild a 700 MHz 24 bit pipelined accumulator in 1.2 mm CMOS. <p> higher clock speeds can be achieved in 0.8 mm and smaller feature sizes; e.g. the Dec Alpha 21264 [35][42] is fabricated in 0.35 mm, uses dynamic logic, and runs at 600 MHz. 6.2.1 Dynamic Latches and Pipelining The basic building block of this logic is the truesingle-phase-clock (TSPC) dynamic latch <ref> [117] </ref> shown in Figure 6.1 (a).
References-found: 117

