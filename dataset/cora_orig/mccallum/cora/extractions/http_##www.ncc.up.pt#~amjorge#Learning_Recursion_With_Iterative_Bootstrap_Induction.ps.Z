URL: http://www.ncc.up.pt/~amjorge/Learning_Recursion_With_Iterative_Bootstrap_Induction.ps.Z
Refering-URL: http://www.ncc.up.pt/~amjorge/publications.html
Root-URL: 
Email: Email: -amjorge,pbrazdil-@ncc.up.pt  
Phone: Tel. +351 2600 1672. Fax. +351 2600 3654.  
Title: Learning Recursion with Iterative Bootstrap Induction (Extended Abstract)  
Author: Alpio Jorge and Pavel Brazdil 
Address: 823, 4150 PORTO, Portugal  
Affiliation: LIACC, University of Porto, Rua do Campo Alegre,  
Abstract: In this paper we are concerned with the problem of inducing recursive Horn clauses from small sets of training examples. The method of iterative bootstrap induction is presented. In the first step, the system generates simple clauses, which can be regarded as properties of the required definition. Properties represent generalizations of the positive examples, simulating the effect of having larger number of examples. Properties are used subsequently to induce the required recursive definitions. This paper describes the method together with a series of experiments. The results support the thesis that iterative bootstrap induction is indeed an effective technique that could be of general use in ILP.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aha D W, Lapointe S, Ling C X, </author> <title> Matwin S (1994): "Inverting Implication with Small Training Sets", </title> <booktitle> in Proceedings of the European Conference on Machine Learning, </booktitle> <editor> ECML-94 , ed. F. Bergadano and L. de Raedt, </editor> <publisher> Springer Verlag. </publisher>
Reference-contexts: 1. Introduction One potential usage of ILP systems is in algorithm synthesis. However most ILP systems still require relatively large example sets which is rather impractical. Several people have proposed a solution (e.g. <ref> [1] </ref>, [4], [6]). The solution described in [1] and incorporated in CRUSTACEAN exploits common substructures in the examples. Although encouraging results have been achieved, the method seems to be difficult to extend and integrate into a general purpose inductive system. <p> 1. Introduction One potential usage of ILP systems is in algorithm synthesis. However most ILP systems still require relatively large example sets which is rather impractical. Several people have proposed a solution (e.g. <ref> [1] </ref>, [4], [6]). The solution described in [1] and incorporated in CRUSTACEAN exploits common substructures in the examples. Although encouraging results have been achieved, the method seems to be difficult to extend and integrate into a general purpose inductive system. <p> Experiments We have set out to run SKILit on a set of benchmark problems. These are simple definitions with one recursive clause and one base clause. The positive examples given need not necessarily be on the same resolution chain. Manually selected input Following a similar demonstration in <ref> [1] </ref>, we provided SKILit with manually chosen small sets of positive and negative examples of 10 predicates, namely append/3, member/2, delete/3, noneiszero/1, plus/3, extractNth/3, factorial/2, rv/2, last_of/2, split/3, and in addition also insertion_sort/2 and quick_sort/2. In all of these experiments the recursive definition was successfully generated. <p> Despite this, our simple strategy permits to obtain results which are comparable to this system. Randomly selected inputs We also examined the ability of SKILit to synthesise theories from random sets of examples without assuming a priori knowledge of the solution. We followed the evaluation methodology described in <ref> [1] </ref>. For each predicate we sampled positive examples from a universe of facts involving lists and peano integers. The depth of those terms varies from 0 to 4 with uniform distribution. List elements were drawn from a universe of 10 digits (0 to 9) with uniform distribution. <p> The method presented finds regularities within the positive and expresses them in terms of the available background knowledge. Background knowledge may contain definitions of structure handling predicates, test predicates and other more complicated predicates. This fact allows SKILit to express the regularities in a richer language than in <ref> [1] </ref>, enabling it to handle larger classes of problems.
Reference: [2] <author> Brazdil P, Jorge A. </author> <year> (1994): </year> <title> "Learning by Refining Algorithm Sketches", </title> <booktitle> in Proceedings of ECAI-94 , T. </booktitle> <editor> Cohn (ed.), </editor> <address> Amsterdam, The Netherlands. </address>
Reference-contexts: The system of Zelle et al. [7], CHILLIN , also employs the idea of closed loop learning to overcome incomplete example sets. However, CHILLIN uses a FOIL like heuristic to guide the search and still needs relatively large example sets. System SKIL We adapted the system SKIL <ref> [2] </ref>, which performs induction by refining algorithm sketches, to incorporate the iterative bootstrap induction method. SKIL takes as input positive and negative examples and optionally algorithm sketches. Background predicates are defined either extensionally or intensionally.
Reference: [3] <author> Cohen W W (1993): </author> <title> "Rapid prototyping of ILP systems using explicit bias" in Proceedings of 1993 IJCAI Workshop on ILP. </title>
Reference-contexts: SKIL takes as input positive and negative examples and optionally algorithm sketches. Background predicates are defined either extensionally or intensionally. The concept language is described by means of a definite clause grammar (DCG) similar to <ref> [3] </ref>. SKIL is a top-down covering system. For each positive example, SKIL looks for a sequence of ground facts that obtain the output arguments from the inputs. Each of those facts needs to either be proved from the background knowledge, or represent a positive example.
Reference: [4] <institution> Idestam-Almquist P (1993) "Generalization under implication by recursive anti-unification", in Proceedings of ILP-93 , Jozef Stefan Institute, </institution> <type> technical report. </type>
Reference-contexts: 1. Introduction One potential usage of ILP systems is in algorithm synthesis. However most ILP systems still require relatively large example sets which is rather impractical. Several people have proposed a solution (e.g. [1], <ref> [4] </ref>, [6]). The solution described in [1] and incorporated in CRUSTACEAN exploits common substructures in the examples. Although encouraging results have been achieved, the method seems to be difficult to extend and integrate into a general purpose inductive system.
Reference: [5] <author> Michalski R S, </author> <year> (1994): </year> <title> "Inferential Theory of Learning: Developing Foundations for Multistrategy Learning", in Machine Learning, A Multistrategy Approach, </title> <editor> Volume IV , ed.by Ryszard Michalski and Gheorghe Tecuci, </editor> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In this paper we investigate another method called iterative bootstrap induction, which represents an alternative approach to this problem. This method can be seen as a special case of the closed-loop learning strategy <ref> [5] </ref>. An implementation of this method proved experimentally to be able to induce recursive definitions from small sets of positive examples even if these were generated at random. The system of Zelle et al. [7], CHILLIN , also employs the idea of closed loop learning to overcome incomplete example sets.
Reference: [6] <author> Muggleton S. </author> <year> (1993): </year> <title> "Inductive Logic Programming: derivations, </title> <booktitle> successes and shortcomings" in Proceedings of ECML-93 , P.Brazdil (ed.), </booktitle> <publisher> Springer-Verlag. </publisher>
Reference-contexts: 1. Introduction One potential usage of ILP systems is in algorithm synthesis. However most ILP systems still require relatively large example sets which is rather impractical. Several people have proposed a solution (e.g. [1], [4], <ref> [6] </ref>). The solution described in [1] and incorporated in CRUSTACEAN exploits common substructures in the examples. Although encouraging results have been achieved, the method seems to be difficult to extend and integrate into a general purpose inductive system.
Reference: [7] <editor> Zelle J M, Mooney R J, Konvisser J B, </editor> <booktitle> (1994):"Combining Top-down and Bottom-up Techniques in Inductive Logic Programming" in Proceedings of the Eleventh International Conference on Machine Learning ML-94 , Morgan-Kaufmann. </booktitle>
Reference-contexts: This method can be seen as a special case of the closed-loop learning strategy [5]. An implementation of this method proved experimentally to be able to induce recursive definitions from small sets of positive examples even if these were generated at random. The system of Zelle et al. <ref> [7] </ref>, CHILLIN , also employs the idea of closed loop learning to overcome incomplete example sets. However, CHILLIN uses a FOIL like heuristic to guide the search and still needs relatively large example sets.
Reference: [8] <author> Richards B, </author> <title> Mooney R (1992): </title> <booktitle> Learning relations by pathfinding in Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <address> Cambridge, MA, </address> <month> MIT Press. </month> <title> Accuracy (SKILit) % of defs with recursion CRUSTACEAN predicate 2 ex.+ </title> <type> 3 ex.+ 5 ex.+ 2 ex.+ 3 ex.+ 5 ex.+ 2 ex.+ 3 ex.+ </type> <note> append/3 0.760 0.802 0.888 0 20 40 0.630 0.738 delete/3 0.754 0.880 1.000 0 100 100 0.617 0.713 rv/2 0.664 0.848 0.868 40 40 40 0.805 0.855 member/2 0.700 0.886 0.952 60 100 100 0.652 0.762 last_of/2 0.714 0.722 0.944 40 40 100 0.744 0.884 </note>
Reference-contexts: Each of those facts needs to either be proved from the background knowledge, or represent a positive example. Each sequence can give rise to a different candidate clause which is accepted as long as it does not cover negative examples. This process is similar to relational pathfinding described in <ref> [8] </ref>. 2. Iterative Bootstrap Induction The method presented constructs theories in a stepwise manner. In each step a tentative theory is produced which can be reused in the next cycle of the induction process. If certain stopping criteria are satisfied, the process terminates. Let us see an example.
References-found: 8

