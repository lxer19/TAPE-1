URL: http://robotics.eecs.berkeley.edu/~emiris/papers/issac94.ps.gz
Refering-URL: http://robotics.eecs.berkeley.edu/~emiris/
Root-URL: 
Title: Monomial Bases and Polynomial System Solving (Extended Abstract)  
Author: Ioannis Z. Emiris Ashutosh Rege 
Abstract: This paper addresses the problem of efficient construction of monomial bases for the coordinate rings of zero-dimensional varieties. Existing approaches rely on Grob-ner bases methods in contrast, we make use of recent developments in sparse elimination techniques which allow us to strongly exploit the structural sparseness of the problem at hand. This is done by establishing certain properties of a matrix formula for the sparse resultant of the given polynomial system. We use this matrix construction to give a simpler proof of the result of Pedersen and Sturmfels [22] for constructing monomial bases. The monomial bases so obtained enable the efficient generation of multiplication maps in coordinate rings and provide a method for computing the common roots of a generic system of polynomial equations with complexity singly exponential in the number of variables and polynomial in the number of roots. We describe the implementations based on our algorithms and provide empirical results on the well-known problem of cyclic n-roots; our implementation gives the first known upper bounds in the case of n = 10 and n = 11. We also present some preliminary results on root finding for the Stewart platform and motion from point matches problems in robotics and vision respectively. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Anderson, Z. Bai, C. Bischof, J. Dem-mel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen. </author> <title> LAPCK Users' Guide. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: It takes currently 1 second to produce M 0 from M , reduce to an eigenvector problem, solve the latter numerically by the appropriate LAPACK library routines <ref> [1] </ref> and recover the actual solution vectors.
Reference: [2] <author> W. Auzinger and H.J. Stetter. </author> <title> An Elimination Algorithm for the Computation of all Zeros of a System of Multivariate Polynomial Equations. </title> <booktitle> In Proc. Intern. Conf. on Numerical Math., Intern. Series of Numerical Math., </booktitle> <volume> 86, </volume> <pages> pages 12-30. </pages> <publisher> Birkhauser Verlag, </publisher> <address> Basel, </address> <year> 1988. </year>
Reference-contexts: The classical resultant provides a means for root-finding by the use of U -resultants [26, 16, 23, 7]. Related to this approach, the reduction of this problem to an eigenvalue problem was formalized in <ref> [2] </ref> and, independently, in [18, 17]. The latter methods led to impressive results on certain problems from graphics and kinematics, thus motivating our work on resultants. <p> Their proof relies on reducing the general problem to binomial systems via Puiseux series. Here, we obtain the result in a more straightforward fashion by using the above construction and certain well-known matrix techniques <ref> [2] </ref>. <p> This is used to outline an algorithm for finding all roots of the given system of polynomials. 6.1 Polynomial System Solving Root finding reduces to computing eigenvectors by an approach introduced in <ref> [2] </ref> and further discussed, in the context of Grobner bases, in [19]. This section proves that the same approach is possible in the context of sparse elimination.
Reference: [3] <author> J. Backelin and R. Froberg. </author> <title> How we Proved that there are exactly 924 Cyclic 7-Roots. </title> <booktitle> In Proc. ACM Intern. Symp. on Symbolic and Algebr. Computation, </booktitle> <pages> pages 103-111, </pages> <address> Bonn, </address> <year> 1991. </year>
Reference-contexts: For n = 8, Faugere's Gb over a finite characteristic takes more than 3 hours on a Sun Sparc 10 [12], while Backelin's Bergman <ref> [3] </ref> consumes more than 15 hours of a Sun 490 [6], running over zero characteristic. 6 Multiplication Maps This section shows how matrix M 0 , defined in (3), is the matrix of the endomorphism in K [x; x 1 ]=I which expresses multiplication by polynomial f 0 , hence it
Reference: [4] <author> D.N. Bernstein. </author> <title> The Number of Roots of a System of Equations. </title> <journal> Funct. Anal. and Appl., </journal> <volume> 9(2) </volume> <pages> 183-185, </pages> <year> 1975. </year>
Reference-contexts: Assume that V has dimension zero. Then its coordinate ring K [x; x 1 ]=I is an m-dimensional vector space over K, where m = MV (f 1 ; : : : ; f n ) equals the Mixed Volume of the respective Newton polytopes <ref> [4] </ref>. In addition, the ideal I = I (f 1 ; : : : ; f n ) is assumed to be radical which is equivalent to saying that all roots in V are distinct.
Reference: [5] <author> G. Bjorck and R. Froberg. </author> <title> A Faster Way to Count the Solutions of Inhomogeneous Systems of Algebraic Equations, with Applications to Cyclic n-roots. </title> <journal> J. Symbolic Computation, </journal> <volume> 12 </volume> <pages> 329-336, </pages> <year> 1991. </year>
Reference-contexts: This gives us an algorithm that is particularly simple and efficient in practice although its asymptotic worst case complexity is singly exponential in n, the dimension of the problem. We have implemented our algorithm and applied it to the well-known problem of cyclic n-roots <ref> [5] </ref>. In the cases n = 10 and n = 11, our implementation provides the first known upper bounds on the number of isolated roots. For smaller n our bounds usually agree exactly with the known ones. <p> At the last step we add the volumes of all mixed cells to find the Mixed Volume or enumerate the lattice points in the 0-mixed cells to obtain a monomial basis. Table 5.1 reports the running times of our program applied to the benchmark problem of cyclic n-roots <ref> [5, 6] </ref> on an Alpha DECstation. The Bernstein bound is the Mixed Volume of the system, which provides an upper bound on the number of isolated roots as well as the cardinality of the monomial basis. In certain cases, e.g. for n = 8; 9, the variety has positive dimension. <p> Our implementation improves tremendously upon the performance of existing Grobner bases programs, while, of course, it provides less information than a Grobner bases algorithm: For n = 7, Macaulay requires 30 minutes on a Sun 4 <ref> [5] </ref>.
Reference: [6] <author> G. Bjorck and R. Froberg. </author> <title> Methods to "Divide out" certain Solutions from Systems of Algebraic Equations, Applied to Find all Cyclic 8-Roots. </title> <type> Manuscript, </type> <institution> Dept. of Math., Stockholm University, </institution> <year> 1994. </year>
Reference-contexts: At the last step we add the volumes of all mixed cells to find the Mixed Volume or enumerate the lattice points in the 0-mixed cells to obtain a monomial basis. Table 5.1 reports the running times of our program applied to the benchmark problem of cyclic n-roots <ref> [5, 6] </ref> on an Alpha DECstation. The Bernstein bound is the Mixed Volume of the system, which provides an upper bound on the number of isolated roots as well as the cardinality of the monomial basis. In certain cases, e.g. for n = 8; 9, the variety has positive dimension. <p> For n = 8, Faugere's Gb over a finite characteristic takes more than 3 hours on a Sun Sparc 10 [12], while Backelin's Bergman [3] consumes more than 15 hours of a Sun 490 <ref> [6] </ref>, running over zero characteristic. 6 Multiplication Maps This section shows how matrix M 0 , defined in (3), is the matrix of the endomorphism in K [x; x 1 ]=I which expresses multiplication by polynomial f 0 , hence it provides a multiplication map in K [x; x 1 ]=I. <p> This section proves that the same approach is possible in the context of sparse elimination. Note that the two additional methods surveyed in <ref> [19, Sect. 5, 6] </ref> can be combined with our construction, first for finding the roots by means of the minimal polynomial and, second, for counting the number of real roots.
Reference: [7] <author> J. Canny. </author> <title> Generalised Characteristic Polynomials. </title> <journal> J. Symbolic Computation, </journal> <volume> 9 </volume> <pages> 241-250, </pages> <year> 1990. </year>
Reference-contexts: Our approach is based on a matrix formula for the sparse resultant [9] which leads to a simple proof and algorithm for the construction of monomial bases. The classical resultant provides a means for root-finding by the use of U -resultants <ref> [26, 16, 23, 7] </ref>. Related to this approach, the reduction of this problem to an eigenvalue problem was formalized in [2] and, independently, in [18, 17]. The latter methods led to impressive results on certain problems from graphics and kinematics, thus motivating our work on resultants.
Reference: [8] <author> J. Canny, </author> <year> 1993. </year> <type> Personal Communication. </type>
Reference-contexts: Lemma 3.3 Every principal minor of M is generically nonzero. Proof By the previous lemma. 2 An improved version of this algorithm, proposed by J. Canny <ref> [8] </ref>, is presented below; it constructs a matrix N which is at most as large as M and possesses the same properties as M . <p> Canny and the first author, which is the fastest to the best of our knowledge. The main idea is to minimize the number of large edge tuples that must be checked, by performing several tests with small tuples. The basic fact behind this idea of pruning <ref> [8] </ref> is that an edge tuple (e i 1 ; : : : ; e i k ) which does not give rise to any mixed cell in the decomposition of Q i 1 + + Q i k , cannot contribute to any mixed cell of 0 .
Reference: [9] <author> J. Canny and I. Emiris. </author> <title> An Efficient Algorithm for the Sparse Mixed Resultant. </title> <editor> In G. Cohen, T. Mora, and O. Moreno, editors, </editor> <booktitle> Proc. 10th Intern. Symp. on Applied Algebra, Algebraic Algorithms and Error-Correcting Codes, Lect. Notes in Comp. Science 263, </booktitle> <pages> pages 89-104, </pages> <address> Puerto Rico, </address> <month> May </month> <year> 1993. </year> <note> Springer Verlag. Submitted to SIAM J. Computing. </note>
Reference-contexts: In contrast, sparse elimination methods are designed with exactly this goal in mind. In this paper, we reconsider the above questions for regular sequences of polynomials, in light of recent work on sparse resultant theory <ref> [9, 24] </ref>. The notion of sparseness is captured very effectively in terms of the concepts of Newton polytopes and Mixed Volumes and these methods provide us with algorithms whose practical complexity depends on the inherent sparseness of the system as measured by these concepts. <p> Using such techniques, we provide constructive methods for computing monomial bases, linear multiplication maps and the solutions to a system of polynomials; the latter is achieved by reduction to an eigenvalue problem. Our approach is based on the matrix construction for the sparse resultant in <ref> [9] </ref>. This gives us an algorithm that is particularly simple and efficient in practice although its asymptotic worst case complexity is singly exponential in n, the dimension of the problem. We have implemented our algorithm and applied it to the well-known problem of cyclic n-roots [5]. <p> We have also implemented the al-gorithm for solving systems of polynomial equations : some encouraging preliminary results are presented. The paper is organized as follows : In section 2, we give a brief overview of related work. Section 3 summarizes the sparse resultant construction of <ref> [9] </ref> which we use in Section 4 to obtain a monomial basis. Section 5 specifies the algorithm for constructing a monomial K-basis for a given coordinate ring and assesses, on the one hand, its asymptotic complexity and on the other hand its practical performance based on our implementation. <p> Our approach is based on a matrix formula for the sparse resultant <ref> [9] </ref> which leads to a simple proof and algorithm for the construction of monomial bases. The classical resultant provides a means for root-finding by the use of U -resultants [26, 16, 23, 7]. <p> Equivalent formulations of the problem give different Bezout and Bernstein bounds, on the number of projective and affine roots respectively; the lowest bounds we have obtained are, respectively, 256 and 54. 3 Matrix Formulae for the Re sultant This section summarizes the construction of matrix M in <ref> [9] </ref>, whose determinant is a nontrivial multiple of the sparse resultant. A new variant of this algorithm yields a smaller matrix with the same properties. <p> It follows from the construction above that MV (Q 0 ; : : :; Q i1 ; Q i+1 ; : : : ; Q n ) equals the sum of volumes of all i-mixed cells. Canny and Emiris <ref> [9] </ref> construct a matrix M whose rows and columns are indexed by the integer lattice points E = (Q + ffi) " Z n ; where Q + ffi is a polytope obtained by perturbing Q by some arbitrarily small ffi 2 Q n , chosen to be sufficiently generic to <p> Each row of M contains the coefficients of x p f i , for some 0 i n and some p 2 Q 0 + + Q i1 + Q i+1 + + Q n . Theorem 3.1 <ref> [9] </ref> The matrix M , described above, is generically nonsingular and its determinant is divisible by the sparse resultant R (f 0 ; : : : ; f n ). <p> Let matrix ^ M be obtained from M by specializing all coefficients to powers of a new variable t and denote by ^ M pq the entry of ^ M with row index p and column index q, for some p; q 2 E , then Lemma 3.2 <ref> [9, Lemma 16] </ref> For all non-zero elements ^ M pq with p 6= q, deg t ( ^ M pq ) &gt; deg t ( ^ M qq ). Lemma 3.3 Every principal minor of M is generically nonzero. <p> Moreover, the degree of det N in the coefficients of f i lies between the respective degrees of the resultant and of det M in these coefficients. Proof By Lemma 3.3, N is generically nonsingular. The proof of Theorem in <ref> [9] </ref> also works for N to show R j det N . <p> In the rest of this paper we use a matrix obtained by either algorithm and denote it by M . 4 Monomial Bases for Coordinate Rings In this section, we use the matrix construction of <ref> [9] </ref>, outlined in Section 3, to obtain a monomial basis for the coordinate ring generated by the given polynomials. <p> The asymptotic complexity is clearly dominated by that of computing a mixed decomposition of Q 0 . Let bound the number of vertices in every Newton polytope and Then the lifting method in <ref> [9] </ref> has total worst-case bit complexity, if we ignore the polylogarithmic factor, of O fl ((n) 5:5 jE 0 j). Computing the mixed decomposition reduces to linear programming tests, for which any polynomial-time algorithm may be used; the above bound was based on Karmarkar's algorithm [15]. <p> Computing the mixed decomposition reduces to linear programming tests, for which any polynomial-time algorithm may be used; the above bound was based on Karmarkar's algorithm [15]. For the important class of unmixed polynomial systems, i.e. systems of polynomials with identical Newton polytopes, <ref> [9] </ref> proves jE 0 j = O (2 n m), where m is the Mixed Volume of the system. The same bound obviously holds for mixed systems where the Newton poly-topes, though arbitrary, do not differ significantly. <p> Note that the two additional methods surveyed in [19, Sect. 5, 6] can be combined with our construction, first for finding the roots by means of the minimal polynomial and, second, for counting the number of real roots. In computing matrix M by the algorithm in <ref> [9] </ref>, f 0 is linear with generic coefficients, as in the proof of Theorem 4.1. In practice, we pick random coefficients c 0j , for 0 j n, from some range of possible integer values of size r.
Reference: [10] <author> I. Emiris and J. Canny. </author> <title> A Practical Method for the Sparse Resultant. </title> <booktitle> In Proc. ACM Intern. Symp. on Symbolic and Algebr. Computation, </booktitle> <pages> pages 183-192, </pages> <address> Kiev, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: In particular, constructing the Newton polytopes, finding the appropriate lattice points and computing M all belong to a preprocessing step, while computing M 0 and finding eigenvectors v 0 and kernel vectors v are done on-line for the specified coefficients. In practice, the algorithm of <ref> [10] </ref> is preferred, which is expected to construct smaller resultant matrices. For certain classes of systems, including multigraded ones, it produces optimal resultant matrices, called Sylvester-type formulae, by using the results of [25].
Reference: [11] <author> O.D. Faugeras and S. Maybank. </author> <title> Motion from Point Matches: Multiplicity of Solutions. </title> <journal> Intern. J. Comp. Vision, </journal> <volume> 4 </volume> <pages> 225-246, </pages> <year> 1990. </year>
Reference-contexts: For certain classes of systems, including multigraded ones, it produces optimal resultant matrices, called Sylvester-type formulae, by using the results of [25]. In the rest of this section we describe the application of our C implementation of this method for root finding to the motion from point-matches problem <ref> [11] </ref> and the forward kinematics problem of the Stewart platform [20] from vision and robotics respectively. The results presented are preliminary and we expect to improve upon them in the near future. <p> After specializing the coefficients to their given values, Gaussian elimination on M produces a 20 fi 20 matrix M 0 , which is of optimal size since the Mixed Volume of the original 6 fi 6 system is 20; this Mixed Volume is known to be exact <ref> [11] </ref>. It takes currently 1 second to produce M 0 from M , reduce to an eigenvector problem, solve the latter numerically by the appropriate LAPACK library routines [1] and recover the actual solution vectors.
Reference: [12] <author> J.-C. Faugere, </author> <year> 1994. </year> <type> Personal Communication. </type>
Reference-contexts: For n = 8, Faugere's Gb over a finite characteristic takes more than 3 hours on a Sun Sparc 10 <ref> [12] </ref>, while Backelin's Bergman [3] consumes more than 15 hours of a Sun 490 [6], running over zero characteristic. 6 Multiplication Maps This section shows how matrix M 0 , defined in (3), is the matrix of the endomorphism in K [x; x 1 ]=I which expresses multiplication by polynomial f
Reference: [13] <author> B.K.P. Horn. </author> <title> Relative Orientation Revisited. </title> <journal> J. Opt. Soc. Am., </journal> <volume> 8(10) </volume> <pages> 1630-1638, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: For both problems under examination this is possible and, further, most of the lattice points needed lie in B; hence only a few entries of v must be computed. For the motion from point-matches problem, also referred to as relative orientation, we use the quaternion formulation of <ref> [13] </ref>. After hiding one variable in the coefficient field we obtain a bilinear system of 6 equations in 5 unknowns, which has a Sylvester-type formula for its sparse resultant. All preprocessing, including construction of this formula, consumes 23 seconds on a Sun Sparc 10.
Reference: [14] <author> T.W. Hungerford. </author> <title> Algebra. Graduate Texts in Mathematics, 73. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1974. </year>
Reference-contexts: From linear algebra we know that if the eigenvec-tors span the domain and range of square matrix M 0 , then M 0 is similar to a diagonal matrix D whose diagonal entries are the eigenvalues of M 0 ; see e.g. <ref> [14, Thm. VII.5.5] </ref>.
Reference: [15] <author> N. Karmarkar. </author> <title> A New Polynomial-Time Algorithm for Linear Programming. </title> <journal> Combinatorica, </journal> <volume> 4 </volume> <pages> 373-395, </pages> <year> 1984. </year>
Reference-contexts: Computing the mixed decomposition reduces to linear programming tests, for which any polynomial-time algorithm may be used; the above bound was based on Karmarkar's algorithm <ref> [15] </ref>. For the important class of unmixed polynomial systems, i.e. systems of polynomials with identical Newton polytopes, [9] proves jE 0 j = O (2 n m), where m is the Mixed Volume of the system.
Reference: [16] <author> D. Lazard. </author> <title> Resolution des systemes d'equations algebriques. </title> <journal> Theor. Comp. Science, </journal> <volume> 15 </volume> <pages> 77-110, </pages> <year> 1981. </year>
Reference-contexts: Our approach is based on a matrix formula for the sparse resultant [9] which leads to a simple proof and algorithm for the construction of monomial bases. The classical resultant provides a means for root-finding by the use of U -resultants <ref> [26, 16, 23, 7] </ref>. Related to this approach, the reduction of this problem to an eigenvalue problem was formalized in [2] and, independently, in [18, 17]. The latter methods led to impressive results on certain problems from graphics and kinematics, thus motivating our work on resultants.
Reference: [17] <author> D. Manocha and J. Canny. </author> <title> Multipolynomial Resultants and Linear Algebra. </title> <booktitle> In Proc. ACM Intern. Symp. on Symbolic and Algebr. Computation, </booktitle> <pages> pages 96-102, </pages> <address> Berkeley, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: The classical resultant provides a means for root-finding by the use of U -resultants [26, 16, 23, 7]. Related to this approach, the reduction of this problem to an eigenvalue problem was formalized in [2] and, independently, in <ref> [18, 17] </ref>. The latter methods led to impressive results on certain problems from graphics and kinematics, thus motivating our work on resultants. The recent interest in sparse methods is founded on the observation that the number of affine roots is typically significantly less than that predicted by the Be-zout bound.
Reference: [18] <author> D. Manocha and J. Canny. </author> <title> Real Time Inverse Kinematics of General 6R Manipulators. </title> <booktitle> In Proc. IEEE Intern. Conf. Robotics and Automation, </booktitle> <pages> pages 383-389, </pages> <address> Nice, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: The classical resultant provides a means for root-finding by the use of U -resultants [26, 16, 23, 7]. Related to this approach, the reduction of this problem to an eigenvalue problem was formalized in [2] and, independently, in <ref> [18, 17] </ref>. The latter methods led to impressive results on certain problems from graphics and kinematics, thus motivating our work on resultants. The recent interest in sparse methods is founded on the observation that the number of affine roots is typically significantly less than that predicted by the Be-zout bound.
Reference: [19] <author> H. M. Moller. </author> <title> Systems of Algebraic Equations Solved by Means of Endomorphisms. </title> <editor> In G. Co-hen, T. Mora, and O. Moreno, editors, </editor> <booktitle> Proc. 10th Intern. Symp. on Applied Algebra, Algebraic Algorithms and Error-Correcting Codes, Lect. Notes in Comp. Science, </booktitle> <volume> 263, </volume> <pages> pages 43-56, </pages> <address> Puerto Rico, May 1993. </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: Furthermore, this leads to an algorithm for determining the common roots of a system of nonlinear polynomial equations. Previous approaches to computing such bases and multiplication maps have relied on the use of Grobner bases <ref> [19] </ref>. The algorithms obtained from these approaches have complexity exponential in the number of variables n. The main drawback of Grobner bases algorithms is that usually they cannot take advantage of the inherent sparseness of the system of polynomial equations. <p> This is used to outline an algorithm for finding all roots of the given system of polynomials. 6.1 Polynomial System Solving Root finding reduces to computing eigenvectors by an approach introduced in [2] and further discussed, in the context of Grobner bases, in <ref> [19] </ref>. This section proves that the same approach is possible in the context of sparse elimination. <p> This section proves that the same approach is possible in the context of sparse elimination. Note that the two additional methods surveyed in <ref> [19, Sect. 5, 6] </ref> can be combined with our construction, first for finding the roots by means of the minimal polynomial and, second, for counting the number of real roots.
Reference: [20] <author> B. Mourrain. </author> <title> The 40 "Generic" Positions of a Parallel Robot. </title> <booktitle> In Proc. ACM Intern. Symp. on Symbolic and Algebr. Computation, </booktitle> <pages> pages 173-182, </pages> <address> Kiev, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Various problems from robot kinematics and computer vision illustrate this statement, such as the forward kinematics of the Stewart platform. This problem reduces to solving a system of polynomials that has, generically, 40 complex roots; see <ref> [20] </ref> and its references. <p> In the rest of this section we describe the application of our C implementation of this method for root finding to the motion from point-matches problem [11] and the forward kinematics problem of the Stewart platform <ref> [20] </ref> from vision and robotics respectively. The results presented are preliminary and we expect to improve upon them in the near future.
Reference: [21] <author> P. Pedersen and B. Sturmfels. </author> <title> Product Formulas for Resultants and Chow Forms. </title> <journal> Math. Zeitschrift, </journal> <volume> 214 </volume> <pages> 377-396, </pages> <year> 1993. </year>
Reference-contexts: expressed as an 8 fi 8 polynomial system, for which we obtain matrix M 0 of less than twice the optimal size and expect that the last phase of the program will run in real time. 7 A Poisson Formula A Poisson formula for the sparse resultant was given in <ref> [21] </ref>, where the extraneous factor was described. In this section we show how the matrix M 0 can be used to obtain a Poisson formula for the sparse resultant.
Reference: [22] <author> P. Pedersen and B. Sturmfels. </author> <title> Mixed Monomial Bases. </title> <booktitle> In MEGA '94, </booktitle> <month> April </month> <year> 1994. </year> <note> To Appear. </note>
Reference-contexts: Section 7 shows how to obtain a Poisson formula for the sparse resultant. 2 Related Work A method for constructing vector bases of coordinate rings as monomials indexed by the lattice points in the mixed cells of a mixed subdivision was first demonstrated by Pedersen and Sturmfels <ref> [22] </ref>. Our approach is based on a matrix formula for the sparse resultant [9] which leads to a simple proof and algorithm for the construction of monomial bases. The classical resultant provides a means for root-finding by the use of U -resultants [26, 16, 23, 7]. <p> The fact that the coordinate ring has a vector space basis consisting of the monomials indexed by the lattice points in the mixed cells of a mixed subdivision was first demonstrated by Pedersen and Sturmfels <ref> [22] </ref>. Their proof relies on reducing the general problem to binomial systems via Puiseux series. Here, we obtain the result in a more straightforward fashion by using the above construction and certain well-known matrix techniques [2]. <p> It turns out that we can actually compute the basis in a simpler fashion, without going through the resultant matrix construction because the set B is defined independently of f 0 . In that sense our results verify those of <ref> [22] </ref>. Consider a mixed subdivision of the perturbed Min kowski sum Q 0 + ffi = Q 1 + + Q n + ffi where ffi is the same as in the previous section.
Reference: [23] <author> J. Renegar. </author> <title> On the Computational Complexity of the First-Order Theory of the Reals, parts I, II, III. </title> <journal> J. Symbolic Computation, </journal> <volume> 13(3) </volume> <pages> 255-352, </pages> <year> 1992. </year>
Reference-contexts: Our approach is based on a matrix formula for the sparse resultant [9] which leads to a simple proof and algorithm for the construction of monomial bases. The classical resultant provides a means for root-finding by the use of U -resultants <ref> [26, 16, 23, 7] </ref>. Related to this approach, the reduction of this problem to an eigenvalue problem was formalized in [2] and, independently, in [18, 17]. The latter methods led to impressive results on certain problems from graphics and kinematics, thus motivating our work on resultants.
Reference: [24] <author> B. Sturmfels. </author> <title> On the Newton Polytope of the Resultant. </title> <journal> J. of Algebr. Combinatorics, </journal> <volume> 3 </volume> <pages> 207-236, </pages> <year> 1994. </year>
Reference-contexts: In contrast, sparse elimination methods are designed with exactly this goal in mind. In this paper, we reconsider the above questions for regular sequences of polynomials, in light of recent work on sparse resultant theory <ref> [9, 24] </ref>. The notion of sparseness is captured very effectively in terms of the concepts of Newton polytopes and Mixed Volumes and these methods provide us with algorithms whose practical complexity depends on the inherent sparseness of the system as measured by these concepts. <p> Q i is called the Newton polytope of f i . A technical assumption is that [ n i=0 A i spans the affine lattice Z n ; otherwise, a coordinate transformation by means of a Smith normal form can guarantee this <ref> [24] </ref>. The algo rithm selects n + 1 linear lifting functions l i : R n ! R for 0 i n. <p> Cells are either mixed or unmixed, mixed cells being Minkowski sums such that exactly one face is a vertex and all others are edges. This construction is essentially due to Sturmfels <ref> [24] </ref>. Definition 3.1 A mixed maximal cell of the induced mixed subdivision of Q is i-mixed if, in its unique expression as a Minkowski Sum, the summand from Q i is a vertex.
Reference: [25] <author> B. Sturmfels and A. Zelevinsky. </author> <title> Multigraded Resultants of Sylvester Type. </title> <journal> J. of Algebra, </journal> <volume> 163(1) </volume> <pages> 115-127, </pages> <year> 1994. </year>
Reference-contexts: In practice, the algorithm of [10] is preferred, which is expected to construct smaller resultant matrices. For certain classes of systems, including multigraded ones, it produces optimal resultant matrices, called Sylvester-type formulae, by using the results of <ref> [25] </ref>. In the rest of this section we describe the application of our C implementation of this method for root finding to the motion from point-matches problem [11] and the forward kinematics problem of the Stewart platform [20] from vision and robotics respectively.
Reference: [26] <author> B.L. van der Waerden. </author> <title> Modern Algebra. </title> <publisher> Ungar Publishing Co., </publisher> <address> New York, </address> <note> 3rd edition, </note> <year> 1950. </year>
Reference-contexts: Our approach is based on a matrix formula for the sparse resultant [9] which leads to a simple proof and algorithm for the construction of monomial bases. The classical resultant provides a means for root-finding by the use of U -resultants <ref> [26, 16, 23, 7] </ref>. Related to this approach, the reduction of this problem to an eigenvalue problem was formalized in [2] and, independently, in [18, 17]. The latter methods led to impressive results on certain problems from graphics and kinematics, thus motivating our work on resultants.
References-found: 26

