URL: http://www.cs.dartmouth.edu/~jmd/decs/xsong/fliit/paper.ps.gz
Refering-URL: http://www.cs.dartmouth.edu/~jmd/decs/DECSpage.html
Root-URL: http://www.cs.dartmouth.edu
Email: fjmd,gdavis,xsongg@cs.dartmouth.edu  
Phone: +1-603-646-2206  
Title: Fast Lossy Internet Image Transmission  
Author: John M. Danskin Geoffrey M. Davis Xiyong Song 
Keyword: forward error correction, image compression, image transmission, Internet, lossy transmission, World Wide Web.  
Address: 6211 Sudikoff Laboratory Hanover NH, 03755 USA  
Affiliation: Dartmouth College  
Abstract: Images are usually transmitted across the Internet using a lossless protocol such as TCP/IP. Lossless protocols require retransmission of lost packets, which substantially increases transmission time. We introduce a fast lossy Internet image transmission scheme (FLIIT) for compressed images which eliminates retransmission delays by strategically shielding important portions of the image with redundancy bits. We describe a joint source and channel coding algorithm for images which minimizes the expected distortion of transmitted images. The algorithm efficiently allocates quantizer resolution bits and redundancy bits to control quantization errors and expected packet transmission losses. We describe an implementation of this algorithm and compare its performance on the Internet to lossless TCP/IP transmission of the same images. In our experiments, the FLIIT scheme transmitted images five times faster than TCP/IP during the day, with resulting images of equivalent quality. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Albanese, J. Bloemer, J. Edmonds, M. Luby, and M. Sudan, </author> <title> "Priority encoding transmission", </title> <booktitle> Proc. 35th Annual Symposium on Foundations of Computer Sciences, </booktitle> <address> Santa Fe, NM, </address> <pages> pp. 604-612, </pages> <year> 1994. </year>
Reference: [2] <author> T.C. Bell, J.G. Cleary, and I.H. Witten, </author> <title> "Text Compression," </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990 </year>
Reference-contexts: This new symbol is added to histogram H with frequency 1, and histogram F is never again used to code this symbol. This two histogram scheme adapts much more quickly than the single histogram scheme. Similar schemes are used for blending high order contexts in text coding <ref> [2] </ref>, but we are unaware of a prior use of this scheme in image coding. 5. After the compressed blocks are generated, we add redundancy. The blocks are sorted by protection level and size, in order of decreasing protection and size. Blocks requiring replication are simply replicated.
Reference: [3] <author> E.W. Biersack, </author> <title> "Performance evalutaion of forward error correction in ATM networks," </title> <booktitle> Proceedings of the SIGCOMM 92 Symposium, Baltimore, </booktitle> <pages> 248-257, </pages> <year> 1992 </year> . 
Reference-contexts: Furthermore, when efficient compression schemes are used, very little usable redundancy remains for error correction. Better control of transmission errors is obtained by adding redundancy bits to the bitstream rather than relying solely on naturally occurring redundancy. Bier-sack <ref> [3] </ref> evaluates the effect of adding redundancy at a fixed rate to video transmissions over ATM networks. As we discuss below, this fixed rate addition of redundancy is inefficient, and indeed [3] obtains mixed results. <p> Bier-sack <ref> [3] </ref> evaluates the effect of adding redundancy at a fixed rate to video transmissions over ATM networks. As we discuss below, this fixed rate addition of redundancy is inefficient, and indeed [3] obtains mixed results. For heterogeneous traffic scenarios the loss rates were reduced by several orders of magnitude, but for more homogeneous traffic the performance was unchanged or worsened.
Reference: [4] <author> L. S. Brakmo, S. W. O'Malley, and L. L. Peterson. </author> <title> "TCP Vegas: New techniques for congestion detection and avoidance." </title> <booktitle> Proceedings of the SIGCOMM '94 Symposium, </booktitle> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: Whenever the rate of packet reception drops below the rate of packet transmission, the network must be storing or dropping the excess data. This is the strategy implemented in Brakmo et al's TCP Vegas protocol <ref> [4] </ref>. Neither of these rate control schemes is appropriate "as is" for the transmission of compressed images across the Internet. The problem is that compressed images are much smaller than the dataset size required to achieve steady state transmission. In [4] we see a delay of 2.5 seconds before steady state <p> the strategy implemented in Brakmo et al's TCP Vegas protocol <ref> [4] </ref>. Neither of these rate control schemes is appropriate "as is" for the transmission of compressed images across the Internet. The problem is that compressed images are much smaller than the dataset size required to achieve steady state transmission. In [4] we see a delay of 2.5 seconds before steady state and heavy packet for packets sent from Dartmouth College to a Stanford University echo server and back, as a function of time of day. Each curve corresponds to a different transmission rate.
Reference: [5] <author> T.M. Cover and J.A. Thomas, </author> <title> Elements of Information Theory, </title> <publisher> John Wiley & Sons, Inc., </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: In the same way, we can control packet loss errors by se-lectively adding redundancy to our bitstream. Traditionally the costs and distortions associated with quantization and transmission have been treated separately. This separation is motivated by Shannon's joint source channel coding theorem <ref> [5] </ref>, which states that source coding followed by channel coding can be made to be as good as any single-stage source/channel coding procedure.
Reference: [6] <author> M. W. Garrett and M. Vetterli, </author> <title> "Joint source/channel coding of statisticallyl multiplexed real-time services on packet networks," </title> <journal> IEEE Transactions on Networking, </journal> <volume> 1:1, </volume> <pages> 71-80, </pages> <month> Feb </month> <year> 1993. </year>
Reference-contexts: The level of redundancy in PET affects the network packet size, so in some networks PET may have less flexibility than FLIIT in specifying a level of redundancy. The layered transmission schemes in Garret and Vet-terli <ref> [6] </ref> and Posnak et al [11] also make use of joint source/channel coding ideas. Layered schemes require networks which treat packets differently according to their priorities.
Reference: [7] <institution> Georgia Tech Graphics, </institution> <month> Visualization, </month> & <title> Usability Center, "Third degree polynomial curve fitting for bytes transferred per month by service," </title> <institution> NSFNET Backbone Statistics Page, </institution> <month> August </month> <year> 1995, </year> <note> http://www.cc.gatech.edu/gvu/stats/NSF/- merit.html. </note>
Reference-contexts: 1 INTRODUCTION World Wide Web requests are currently estimated to comprise some 25% of all bytes sent over the Internet. This fraction is growing rapidly, and WWW requests are projected to become the single largest consumer of Internet bandwidth in late 1995 <ref> [7] </ref>. Images, most of which are examined for a only a few seconds, undoubt edly constitute the bulk of the 10 terabytes of monthly Web requests.
Reference: [8] <author> G. Karlsson, and M. Vetterli, </author> <title> "Subband coding of video for packet networks," </title> <journal> Optical Engineering, </journal> <volume> 27(7), </volume> <month> 574-586 </month> <year> 1988 </year>
Reference-contexts: Missing pixels are reconstructed by applying a filter to their surviving neighbors. This technique can hide a limited number of missing packets since there is usually a high correlation between neighboring pixels. A network video transmission scheme proposed by Karlsson and Vetterli <ref> [8] </ref> also makes use of naturally occurring image redundancy for error correction. Using intrinsic image redundancy to correct losses is problematic, since the number of losses that can be sustained is highly image dependent. Furthermore, when efficient compression schemes are used, very little usable redundancy remains for error correction.
Reference: [9] <author> C. Leicher, </author> <title> "Hierarchical encoding of MPEG sequences using priority encoding transmission (PET)," </title> <booktitle> TR-94-058, ICSI, </booktitle> <address> Berkeley, CA, </address> <month> Nov. </month> <year> 1994. </year>
Reference: [10] <author> A. S. Lewis and G. Knowles, </author> <title> "Image compression using the 2-D wavelet transform," </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> Vol. 1, No. 2, </volume> <pages> pp. 244-250, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: We use the mean squared error as our measure of distortion to allow comparison to competing algorithms, but the scheme we describe will function equally well with perceptually weighted metrics such as that of <ref> [10] </ref>.
Reference: [11] <author> E.J. Posnak, S.P. Gallindo, A.P. Stephens, and H.M. Vin, </author> <title> "Techniques for resilient transmission of JPEG video streams," </title> <type> preprint. </type>
Reference-contexts: The level of redundancy in PET affects the network packet size, so in some networks PET may have less flexibility than FLIIT in specifying a level of redundancy. The layered transmission schemes in Garret and Vet-terli [6] and Posnak et al <ref> [11] </ref> also make use of joint source/channel coding ideas. Layered schemes require networks which treat packets differently according to their priorities.
Reference: [12] <author> J. Shapiro, </author> <title> "Embedded Image Coding Using Ze-rotrees of Wavelet Coefficients," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> Vol. 41, No. 12, </volume> <pages> pp. 3445-3462. </pages>
Reference-contexts: We have chosen to work with wavelet-based coder because of its simplicity and superior performance. Our low-complexity scheme yields PSNR's for the 512 fi 512 Lena image within 0.3 to 0.9 dB of state of the art coders <ref> [12] </ref>. 2.2 Bit Allocation The discrete wavelet transform partitions an image into a set of subbands ranging from fine scales (high frequency) to coarse (low frequency). Typically the bulk of the visually important information is concentrated in the coarse-scale subbands, with the fine-scale subbands contributing mostly at sharp edges.
Reference: [13] <author> Y. Shoham and A. Gersho, </author> <title> "Efficient bit allocation for an arbitrary set of quantizers," </title> <journal> IEEE Trans. Acoustics, Speech, and Sig. Proc., </journal> <volume> 36:9, </volume> <pages> 1445-1453, </pages> <year> 1988. </year>
Reference-contexts: In addition, the components of q must all be positive integers, and for practical reasons we impose an upper bound on the components of q. Thus we seek a minimization over q 2 Q where Q is some set of valid integer-valued quan-tizer bin allocations. Shoham and Gersho <ref> [13] </ref> describe an algorithm which solves precisely this problem. They show that any unconstrained minimum of C total (q) + D total (q) is also the solution to a constrained problem of the form we require. <p> These unconstrained problems are much easier to solve, but we must determine which value of yields the appropriate constrained problem. The constrained problem is thereby transformed into a search through a family of unconstrained problems. The algorithm in <ref> [13] </ref> gives optimal or near-optimal bit allocations for our problem. In our implementation, we use a uniform quantizer for subband coefficients.
Reference: [14] <author> N. Tanabe and N. Farvardin, </author> <title> "Subband image coding using entropy-coded quantization over noisy channels," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 10:5, </volume> <pages> 926-943, </pages> <year> 1992. </year>
Reference-contexts: Our experiments show that the control of redundancy achieved by FLIIT yields substantial improvements in image quality over non-adaptive schemes. Similar techniques of joint source/channel coding for continuous bitstreams have been developed in Tanabe and Farvardin <ref> [14] </ref>. The error calculations for these continuous streams are extremely difficult, and the algorithms presented rely on computationally expensive simulations during bit allocation. FLIIT's network packet implementation uses a simple and fast allocation scheme.
Reference: [15] <author> A. Tanenbaum, </author> <title> "Computer Networks," </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N. J. </address> <year> 1981. </year>
Reference-contexts: Conversely, if a user sends such large packets that they are fragmented en-route, then they will lose their entire large packet whenever a single fragment is lost, also resulting in reduced throughput. The largest Internet packet which is guaranteed not to be fragmented is 576 bytes <ref> [15] </ref>. We use the largest-first first-fit heuristic to pack blocks into 550 byte UDP packets.
Reference: [16] <author> Turner, Charles J., and Larry L. Peterson, </author> <title> "Im--age transfer: </title> <booktitle> and end-to-end design," SigComm 92, </booktitle> <pages> 258-268. </pages>
Reference-contexts: On the other hand, if we wait too long, we lose responsiveness. We describe a method for incorporating the optimization of the waiting time into our resource allocation algorithm. 1.1 Related Work A number of strategies have been explored for incorporating redundancy into network packets. Turner and Peterson <ref> [16] </ref> propose a scheme in which errors are corrected by making use of naturally occurring redundancy within images. Image pixels are reordered for transmission in such a way that packet losses cause the loss of isolated pixels rather than large contiguous blocks of pixels. <p> Assign quantizer redundancies and levels of parity according to the algorithm described in the previ ous section. 3. For transmission, it makes sense to distribute each band across as many packets as possible using a pixel interleaving scheme like the one described in <ref> [16] </ref> so that a lost packet will not cause a catastrophic band loss.
Reference: [17] <author> J.D. Villasenor, B. Belzer, J. Liao, </author> <title> "Wavelet filter evalution for image compression," </title> <journal> IEEE Trans. Image Processing, </journal> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: We perform a discrete wavelet transform on an image, quantize the coefficients using uniform quantizers, and entropy-code the resulting coefficients using an arithmetic coder. The resolution of the quantizers is determined by a Lagrange multiplier procedure we describe below. We use the 7/9-tap biorthogonal wavelet from <ref> [17] </ref> for our experiments below. The FLIIT scheme can easily be modified to work with DCT-based schemes such as JPEG. We have chosen to work with wavelet-based coder because of its simplicity and superior performance.
Reference: [18] <author> C.L. Williamson and D. R. Cheriton, </author> <title> "Loss-load curves: Support for rate-based congestion control in high-speed datagram networks," </title> <booktitle> Proceedings of SIGCOMM 91, </booktitle> <pages> pp. 17-28, </pages> <year> 1991. </year>
Reference-contexts: For the network experiment in this paper, we used an o*ine process to choose a fair transmission rate for FLIIT packets. This rate was chosen by picking the knee on the load/loss curve <ref> [18] </ref>. Streams of packets containing roughly 550 bytes were sent at various transmission rates, and the loss rate was measured for each rate. As can be seen in Figure 1, the loss rate as a function of transmission rate was roughly constant at rates below about 4ms per packet.
Reference: [19] <author> I. Witten, R. Neal, and J. Cleary, </author> <title> "Arithmetic coding for data compression," </title> <journal> Communications of the ACM, </journal> <volume> 30:6, </volume> <pages> 520-540, </pages> <year> 1987. </year>
References-found: 19

