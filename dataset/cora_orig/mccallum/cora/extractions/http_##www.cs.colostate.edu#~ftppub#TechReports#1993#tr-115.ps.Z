URL: http://www.cs.colostate.edu/~ftppub/TechReports/1993/tr-115.ps.Z
Refering-URL: http://www.cs.colostate.edu/~ftppub/
Root-URL: 
Affiliation: Department of Computer Science Colorado State University  
Abstract: The Effect of Correlated Faults on Software Reliability Kang Wu and Yashwant K. Malaiya Technical Report CS-93-115 September 2, 1993 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.D. Musa, A. Iannino and K. Okumoto, </author> <title> Software Reliability: Measurement, Prediction, Application, </title> <publisher> McGraw-Hill, </publisher> <year> 1987. </year>
Reference-contexts: Now we are ready to explain the configuration. We define G (j) to be G (j) fu j 1 [~n 1 [j]]g; 2 <ref> [1] </ref>; ; u j . . . m [1]; ; u j The configuration for the jth experiment is defined to be G (j). <p> Now we are ready to explain the configuration. We define G (j) to be G (j) fu j 1 [~n 1 [j]]g; 2 <ref> [1] </ref>; ; u j . . . m [1]; ; u j The configuration for the jth experiment is defined to be G (j).
Reference: [2] <author> J.D. Musa, </author> <title> "Rationale for Fault Exposure Ratio,"ACM SIGSOFT Software Engineering News, </title> <journal> pp. </journal> <volume> 79, </volume> <month> July </month> <year> 1991. </year>
Reference: [3] <author> Y. K. Malaiya, A. von Mayrhauser and P. K. Srimani, </author> <title> "The Nature of Fault Exposure Ratio,"Proc. </title> <booktitle> of Symposium on Software Reliability Engineering, </booktitle> <pages> pp. 23-32, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: On the other hand, the value of the fault exposure ratio also gives us an idea about if the faults in a program is easy or difficult to be located. From an extensive data analysis by Malaiya, et.al. <ref> [3] </ref>, the fault exposure ratio indeed varies with the testing time. From the data analysis, Malaiya, et.al. also proposed that there are two distinguishable phases in testing process. They are the early stage of debugging and the later stage of debugging. <p> The probability of locating any fault is the sum of all the P j (t)'s. Doing this using Eq. (18), we obtain K (t) = j=1 r P t j exp (t= t j ) Eq. (19) is different than the result obtained by Y.K.Malaiya, et.al. <ref> [3] </ref>. This is because they are two different models. For large value of t, the terms that contain the largest value of t j 's in the summations, t max , dominates the values of the summations. <p> Thus, for large value of t, we have K (t) t 1 max T L : We can see that for large value of t, the fault exposure ratio for the independent faults model recovers to the fault exposure ratio given by Y.K.Malaiya, et.al. <ref> [3] </ref>. It can be shown that the function K (t) in Eq. (19) is always a decreasing function of time t for any set of t j 's. This tells us that the fault exposure ratio calculated from the independent faults model is a decreasing function of time t. <p> Therefore, we call the correlations among the faults of the second type and the third type are dynamic correlations. As pointed out in reference <ref> [3] </ref>, the dynamic correlations have a major effect on the fault exposure ratio especially in the late stage of testing. Now let us to explain how we model these three types of faults in our theory. <p> Thus, the fault exposure ratio always decreases against time t. In order to see how well the fault exposure ratio for the correlated faults model describes the reality, we use Eq. (29) to fit the experimental data using the least square fit. The experimental data comes from reference <ref> [3] </ref>. In the fitting, we assume that N r faults with the same average time are masked by one fault and there are N i independent faults with the same average time. Both N r and N i are much greater than 1. <p> In this fault model, the fault exposure ratio of the independent faults model approaches to a constant as the time approaches to infinity. This behavior characterizes the testing process in the earlier stage of testing. The same conclusion has been made in reference <ref> [3] </ref> using a different fault model. We analyzed the effect of the nonrandom testing on locating faults. According to our analysis, the nonrandom testing can be considered as the correlations between faults. Based on the analysis, the correlated faults model is proposed. <p> We find that the behaviors of the fault exposure ratios for the independent faults and the correlated faults are significantly different. We find that there are two phases in the testing process. This agrees with the observation from the experimental data <ref> [3] </ref>. We also used the fault exposure ratio for the correlated faults model to fit the experimental data. It fits the experimental data very well. We conclude that the dynamic correlations between faults indeed play an important role in the testing as Malaiya, et.al. pointed out [3]. <p> from the experimental data <ref> [3] </ref>. We also used the fault exposure ratio for the correlated faults model to fit the experimental data. It fits the experimental data very well. We conclude that the dynamic correlations between faults indeed play an important role in the testing as Malaiya, et.al. pointed out [3]. In the early stage of testing process, the independent faults dominate the fault exposure ratio; In the later stage of testing process, the correlated faults dominate the fault exposure ratio. From the theoretical aspect, the correlated faults model has two advantages.
Reference: [4] <author> G. K. Zipf, </author> <title> Human Behavior and the Principle of Least Effort, </title> <publisher> Addison-Wesley, </publisher> <year> 1949. </year>
Reference-contexts: Once we obtain all the correlation functions, all the quantities that we need can be calculated. In the correlated faults model, we will take another approach to calculate the correlation function. We use Zipf's least effort principle <ref> [4; 5] </ref> to solve the problem, which states that people always tend to spend least effort to achieve an object. In order to find out how the faults are found in our model, we need to construct the effort function, E.
Reference: [5] <author> M. Trachtenberg, </author> <title> "Why Failure Rates Observe Zipf's Law in Operational Software,"IEEE Trans. </title> <journal> Reliability, </journal> <volume> Vol. 41, </volume> <pages> pp. 383-389, </pages> <month> September </month> <year> 1981. </year>
Reference-contexts: Once we obtain all the correlation functions, all the quantities that we need can be calculated. In the correlated faults model, we will take another approach to calculate the correlation function. We use Zipf's least effort principle <ref> [4; 5] </ref> to solve the problem, which states that people always tend to spend least effort to achieve an object. In order to find out how the faults are found in our model, we need to construct the effort function, E.
References-found: 5

