URL: ftp://cl-ftp.dfki.uni-sb.de/pub/papers/local/kntsnlp.ps.Z
Refering-URL: http://cl-www.dfki.uni-sb.de/cl/papers/cl-abstracts.html
Root-URL: 
Title: TSNLP Test Suites for Natural Language Processing The TSNLP project addresses a range of issues
Author: Lorna Balkanfl Klaus Netterz Doug Arnoldfl Siety Meijerfl 
Keyword: Motivation  
Address: United Kingdom zDFKI GmbH, Saarbrucken, Germany  
Affiliation: University of Essex,  
Date: 6-7 July 1994,  1994  
Note: In: Proceedings of Language Engineering Convention Paris  pp. 17-22, ELSNET, Edinburgh,  Project Aims  the project are to:  
Abstract: This paper describes the LRE project TSNLP (Test Suites for Natural Language Processing), which is concerned with some central issues in the design and use of test suites. The project combines theoretical research with practical implementations, aiming to provide generally usable tools and test data together with reports discussing the theoretical background. The paper begins by setting out the motivation, aims, and present state of the project, then examines the methodological issues behind it 1 . In a Natural Language Processing context, a test suite is a more or less systematic collection of specially constructed linguistic expressions (test items, e.g. sentences), perhaps with associated annotations and descriptions. Test suites have long been accepted in the NLP community as a useful tool for diagnostic evaluation. However most of the existing test suites have been written for specific systems or simply contain numbers of "interesting examples". This does not meet the demand for large, systematic, well documented and annotated collections of linguistic material, required by a growing number of NLP applications. Collections of this type are not only useful as diagnostic tools, but can also support other kinds of evaluation. Last but not least, large data collections could also serve as repositories of linguistic phenomena for developers. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <editor> Estival, Falkedal et al. </editor> <year> (1994), </year> <title> Analysis of Ex isting Test Suites, </title> <note> Report to LRE 62-089 (D-WP1), </note> <institution> University of Essex. </institution>
Reference-contexts: Research to Date During the first phase of the project a study of existing, publicly available test suites was performed <ref> [1] </ref>. The study revealed that test suites range in evaluation purpose, intended application (parsers, MT systems, etc.), depth and breadth of coverage, etc. Existing test suites display a degree of systematicity, where test items generally only contain one linguistic phenomenon more than those previously tested.
Reference: 2. <author> J. Nerbonne, K. Netter, A Kader Diagne, J. Klein, L. Dickman, </author> <title> A Diagnostic Tool for German Syntax. </title> <note> DFKI D-92-03, Saarbrucken. Also in: </note> <editor> J. Neal / S. Walter. eds. </editor> <booktitle> (1991): Natural Language Processing Systems Evaluation Workshop, </booktitle> <institution> Berkeley. Rome Laboratory, </institution> <address> RL-TR-91-362, New York </address>
Reference-contexts: Develop a database The test items will be stored in a database, where the annotations on the test items allow for ease of access to and manipulation of data. Work done at DFKI Saarbrucken <ref> [2] </ref> will serve as the starting point. 4. Investigate test suite construction tools The project aims to develop methods for automating some of the processes involved in test suite construction. The tools considered here are a test suite generation tool (from grammars and corpora), and an automatic lexicon replacement tool.
Reference: 3. <institution> Draft Interim Report EAGLES Evaluation Group, </institution> <year> 1994. </year>
Reference-contexts: Test Suites and Evaluation Type A number of different factors relating to the type of evaluation to be undertaken are relevant to the design and use of test suites (see e.g. <ref> [4, 3] </ref>). These include the purpose of the evaluation (diagnostic, progress, adequacy evaluation), the type of evaluator (user vs. developer), the evaluation basis (test suites vs. corpora), the type of system (module vs. compound system), the evaluation method (black box vs. glass box evaluation), etc. <p> Purpose of evaluation The purpose of an evaluation has an impact on the utility of test suites. As suggested by (inter alia) the EAGLES subgroup on evaluation <ref> [3] </ref>, the following purposes can be distinguished: * diagnostic evaluation, which aims at localizing deficiencies in the system; * progress evaluation, for a comparison between successive stages of development of a system over a period of time; * adequacy evaluation, which determines whether and to what extent a particular system meets
Reference: 4. <author> J.R. Galliers and K. Sparck Jones, </author> <title> Evaluating Natural Language Processing Systems. </title> <institution> University of Cambridge, England, </institution> <type> Technical Report No. 291, </type> <year> 1993. </year>
Reference-contexts: Test Suites and Evaluation Type A number of different factors relating to the type of evaluation to be undertaken are relevant to the design and use of test suites (see e.g. <ref> [4, 3] </ref>). These include the purpose of the evaluation (diagnostic, progress, adequacy evaluation), the type of evaluator (user vs. developer), the evaluation basis (test suites vs. corpora), the type of system (module vs. compound system), the evaluation method (black box vs. glass box evaluation), etc.
References-found: 4

