URL: http://www.cs.berkeley.edu/~rywang/papers/pipeline/pipeline.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~rywang/papers/pipeline/
Root-URL: 
Title: Modeling Communication Pipeline Latency  
Author: Randolph Y. Wang Arvind Krishnamurthy Richard P. Martin Thomas E. Anderson David E. Culler 
Abstract: In this paper, we study how to minimize the latency of a message through a network that consists of a number of store-and-forward stages. This research is especially relevant for today's low overhead communication systems that employ dedicated processing elements for protocol processing. We develop an abstract pipeline model that reveals a crucial performance tradeoff involving the effects of the overhead of the bottleneck stage and the bandwidth of the remaining stages. We exploit this tradeoff to develop a suite of fragmentation algorithms designed to minimize message latency. We also provide an experimental methodology that enables the construction of customized pipeline algorithms that can adapt to the specific system characteristics and application workloads. By applying this methodology to the Myrinet-GAM system, we have improved its latency by up to 51%. Our theoretical framework is also applicable to pipelined systems beyond the context of high speed networks. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anderson, T., Culler, D., Patterson, D., </author> <title> and the NOW team. A Case for NOW (Networks of Workstations). </title> <journal> IEEE Micro (Feb. </journal> <year> 1995), </year> <pages> 54-64. </pages>
Reference-contexts: As we observed earlier, k must be an integer in <ref> [1; B] </ref>. Due to the shape of the latency function T (k) (as shown in Figure 2 (a)), we only need to apply the floor and ceiling functions to (12) and choose the integer solution that minimizes T . We make several observations about this result. <p> The pipeline algorithms adapt the fragmentation at run time to different packet sizes. We can also monitor changes in the pipeline parameters, due to factors such as contention, to fine-tune the fragmentation at run time. 5.2 Experimental Platform Our main experimental platform is the Berkeley NOW <ref> [1] </ref>, which is a cluster of UltraSPARC Model 170 workstations running Solaris 2.6. Each workstation is equipped with a Myricom M2F network interface card [3] on the SBUS. Figure 6 shows the details of the interface card.
Reference: [2] <author> Anderson, T., Dahlin, M., Neefe, J., Patterson, D., Roselli, D., and Wang, R. </author> <title> Serverless Network File Systems. </title> <journal> ACM Transactions on Computer Systems 14, </journal> <month> 1 (Feb. </month> <year> 1996), </year> <pages> 41-79. </pages>
Reference-contexts: 1 Introduction The goal of this research is to answer a simple question: how do we minimize the latency of a message through a network that consists of a number of store-and-forward stages? This question arose during our effort to improve the performance of a distributed file system <ref> [2] </ref> on a high-speed local area network [3]. Two important characteristics of the communication pattern distinguish the file system workload from the parallel applications which traditionally run on these networks. The first is the synchronous nature of the communication.
Reference: [3] <author> Boden, N., Cohen, D., Felderman, R., Kulawik, A., Seitz, C., Seizovic, J., and Su, W. </author> <title> Myrinet A Gigabit-per-Second Local-Area Network. </title> <journal> IEEE MICRO (Feb. </journal> <year> 1995), </year> <pages> 29-36. </pages>
Reference-contexts: this research is to answer a simple question: how do we minimize the latency of a message through a network that consists of a number of store-and-forward stages? This question arose during our effort to improve the performance of a distributed file system [2] on a high-speed local area network <ref> [3] </ref>. Two important characteristics of the communication pattern distinguish the file system workload from the parallel applications which traditionally run on these networks. The first is the synchronous nature of the communication. <p> Each workstation is equipped with a Myricom M2F network interface card <ref> [3] </ref> on the SBUS. Figure 6 shows the details of the interface card.
Reference: [4] <author> Chun, B., Mainwaring, A., and Culler, D. </author> <title> Virtual Network Transport Protocols for Myrinet. </title> <booktitle> In Proc. of 1997 Hot Interconnects V (August 1997). </booktitle>
Reference-contexts: New communication software [16, 15] has significantly reduced host processing overhead, which in turn has made it possible to use finer-grained fragmentation to increase the parallelism in the communication subsystem. However, these communication subsystems employ rigid policies for fragmentation. For example, the Active Message layer (AM2) <ref> [4] </ref> does not fragment medium messages, while Fast Messages (FM) [10] uses 128 byte fragments. In order to evaluate the soundness of these design choices, one needs a systematic approach.
Reference: [5] <author> Jacobson, V. </author> <title> pathchar ATool to Infer Characteristics of Internet Paths. </title> <address> http://www.msri.org/sched/empennage /jacobson.html, </address> <year> 1997. </year>
Reference-contexts: However, their proposed changes to the internet architecture allow the application of our technique to the IP internet: the use of transparent fragmentation where each hop performs reassembly and the recording of path information in each packet allow high level protocols to intelligently choose fragment sizes. In pathchar <ref> [5] </ref>, Jacobson discusses a technique for measuring the latency and bandwidth of the individual hops on an internet path. By gradually increasing the "time-to-live" field of an IP packet, pathchar isolates the latency contributed by each additional hop.
Reference: [6] <author> Jamrozik, H. A., Feeley, M. J., Voelker, G. M., II, J. E., Kar-lin, A. R., Levy, H. M., and Vernon, M. K. </author> <title> Reducing Network Latency Using Subpages in a Global Memory Environment. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VII) (Oct. </booktitle> <year> 1996), </year> <pages> pp. 258-267. </pages>
Reference-contexts: For example, the Active Message layer (AM2) [4] does not fragment medium messages, while Fast Messages (FM) [10] uses 128 byte fragments. In order to evaluate the soundness of these design choices, one needs a systematic approach. While previous research efforts such as <ref> [6] </ref> have employed simulation and empirical techniques for studying fragmentation, the lack of an analytical model prevents a generalization of their results to other systems. In this paper, we develop a framework that may lead to a complete theory of optimal communication pipelines. We demonstrate several important optimality criteria. <p> GMS relies on simulation to find the optimal fragment size for sending an 8KB message through a pipeline that consists of an AN2 network and DEC Alpha workstations <ref> [6] </ref>. Using the GMS pipeline parameters derived from that work (Table 3), we were able to confirm its optimal fragment size by applying the Fixed-sized Theorem. In Trapeze, the network interface implements pipelining in a manner that is transparent to the host [17].
Reference: [7] <author> Keleher, P., Cox, A. L., Dwarkadas, S., and Zwaenepoel, W. TreadMarks: </author> <title> Distributed Shared Memory on Standard Workstations and Operating Systems. </title> <booktitle> In Proc. of the 1994 Winter Usenix Conference (January 1994), </booktitle> <pages> pp. 115-132. </pages>
Reference-contexts: These communication requirements are not only common to other high performance distributed file systems [14], but are also shared by distributed shared memory systems <ref> [7] </ref> and database applications. While traditional communication layers such as TCP/IP have examined packet fragmentation for managing congestion, buffer overflow, and errors in the wide area context [11, 12], the high initiation overhead in these systems has made fine-grained fragmentation infeasible.
Reference: [8] <author> Kent, C. A., and Mogul, J. C. </author> <title> Fragmentation considered harmful. </title> <booktitle> In Proc. of Frontiers in Computer Communications Technology, ACM SIGCOMM (August 1987). </booktitle>
Reference-contexts: Kent and Mogul discussed this problem in <ref> [8] </ref> and argued that the higher level protocol must use packets whose size matches the minimum of the maximum fragment allowed on the route. This strategy is a compromise to suit legacy systems and is not optimal.
Reference: [9] <author> Martin, R. P., Vahdat, A. M., Culler, D. E., and Anderson, T. E. </author> <title> Effects of Communication Latency, Overhead, and Bandwidth in a Cluster Architecture. </title> <booktitle> In Proceedings of the Twenty-Fourth International Symposium on Computer Architecture (May 1997), </booktitle> <pages> pp. 85-97. </pages>
Reference-contexts: Two important characteristics of the communication pattern distinguish the file system workload from the parallel applications which traditionally run on these networks. The first is the synchronous nature of the communication. While many parallel applications tend to communicate asynchronously to mask communication latency <ref> [9] </ref>, file system operations, such as a read miss in the file system cache, stall the application until the entire operation is performed. The second distinguishing characteristic is message size. <p> We provide a methodology that systematically uncovers the communication pipeline parameters and constructs customized pipeline algorithms. We present empirical studies comparing theory to practice. In one example, we show that the discrepancy between the model prediction and the implementation measurement on Myrinet-GAM <ref> [9] </ref> averages 5.9%. By applying the fixed-sized fragmentation to the system, we achieve a performance improvement of up to 51%. We also study the effectiveness of our algorithms for simulated systems with high overhead components such as disks. The remainder of the paper is organized as follows. <p> The base communication system that we use in the study is Generic Active Messages (GAM) <ref> [9] </ref>, a version of Active Messages [15]. One notable feature of this communication layer is its low overhead, which enables fine-grained fragmentation.
Reference: [10] <author> Pakin, S., Lauria, M., and Chien, A. </author> <title> High Performance Messaging on Workstations: Illinois Fast Messages (FM) for Myrinet. </title> <booktitle> In Proc. of Supercomputing '95 (November 1995). </booktitle>
Reference-contexts: However, these communication subsystems employ rigid policies for fragmentation. For example, the Active Message layer (AM2) [4] does not fragment medium messages, while Fast Messages (FM) <ref> [10] </ref> uses 128 byte fragments. In order to evaluate the soundness of these design choices, one needs a systematic approach. <p> However, as the fragment size decreases, it takes less time for the first fragment to reach the bottleneck stage and for the last fragment to drain from the pipeline. We compare our fixed-sized fragmentation algorithm with the original GAM implementation and FM <ref> [10] </ref>, both of which use a static fragmentation strategy (128B for FM and tion versus static fragmentation. 4KB for the original GAM). Figure 9 shows the comparison. FM suffers from the high overhead incurred by the small fragments for large packets.
Reference: [11] <author> Postel, J. </author> <title> Internet protocol. Request for Comments 791, </title> <journal> Information Sciences Institute, </journal> <month> Sept. </month> <year> 1981. </year>
Reference-contexts: While traditional communication layers such as TCP/IP have examined packet fragmentation for managing congestion, buffer overflow, and errors in the wide area context <ref> [11, 12] </ref>, the high initiation overhead in these systems has made fine-grained fragmentation infeasible. Consequently, they have not systematically addressed the issue of developing an optimal fragmentation strategy for medium messages. Recent developments in high performance local area network technology have necessitated revisiting the message fragmentation issues. <p> From the experiments in this section, we conclude that the optimal algorithms are unlikely to obtain significant improvements over the simple combination of fixed-sized frag mentation and hierarchical fragmentation. 6 Related Work Internet protocols have long used fragmentation to manage packet buffering, congestion control, and packet losses <ref> [11, 12] </ref>. Due to the high overheads of these protocols, it is generally better to use large packets to maximize bandwidth. However, most datagram networks impose a maximum fragment size.
Reference: [12] <author> Postel, J. </author> <title> Transmission control protocol. Request for Comments 793, </title> <journal> Information Sciences Institute, </journal> <month> Sept. </month> <year> 1981. </year>
Reference-contexts: While traditional communication layers such as TCP/IP have examined packet fragmentation for managing congestion, buffer overflow, and errors in the wide area context <ref> [11, 12] </ref>, the high initiation overhead in these systems has made fine-grained fragmentation infeasible. Consequently, they have not systematically addressed the issue of developing an optimal fragmentation strategy for medium messages. Recent developments in high performance local area network technology have necessitated revisiting the message fragmentation issues. <p> From the experiments in this section, we conclude that the optimal algorithms are unlikely to obtain significant improvements over the simple combination of fixed-sized frag mentation and hierarchical fragmentation. 6 Related Work Internet protocols have long used fragmentation to manage packet buffering, congestion control, and packet losses <ref> [11, 12] </ref>. Due to the high overheads of these protocols, it is generally better to use large packets to maximize bandwidth. However, most datagram networks impose a maximum fragment size.
Reference: [13] <author> Prylli, L., and Tourancheau, B. </author> <title> New protocol design for high performance networking. </title> <type> Tech. Rep. 97-22, </type> <institution> LIP-ENS Lyon, 69364 Lyon, France, </institution> <year> 1997. </year>
Reference-contexts: The bottleneck shifts from the "Req-CPU" stage to the "Wire" stage as the fragment size increases. The Myrinet-BIP system <ref> [13] </ref> is the only other system that we are aware of that systematically adapts the fragment size to the user packet size. This system uses fixed-sized fragmentation, but its pipeline model is more complex and requires exhaustive information about the pipeline.

Reference: [17] <author> Yocum, K. G., Chase, J. S., Gallatin, A. J., and Lebeck, A. R. </author> <title> Cut-through delivery in trapeze: An exercise in low-latency messaging. </title> <booktitle> In Proc. of the Sixth IEEE International Symposium on High Performance Distributed Computing (August 1997). </booktitle>
Reference-contexts: Using the GMS pipeline parameters derived from that work (Table 3), we were able to confirm its optimal fragment size by applying the Fixed-sized Theorem. In Trapeze, the network interface implements pipelining in a manner that is transparent to the host <ref> [17] </ref>. Although successful for the specific packet size and configurations studied, these systems do not provide a general solution. stage i g i (s) G i (s/KB) Srv-DMA 2.1 25.6 Wire 4.0 60.1 Req-DMA 2.1 25.6 Table 3: GMS pipeline parameters.
References-found: 14

