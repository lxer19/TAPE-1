URL: http://www.cs.brandeis.edu/~waterman/papers/pacling-final-paper.ps
Refering-URL: http://www.cs.brandeis.edu/~waterman/home.html
Root-URL: http://www.cs.brandeis.edu
Email: Email: jcowie@nmsu.edu  
Title: The Diderot Information Extraction System  
Author: Jim Cowie, Takahiro Wakao, Louise Guthrie, Wang Jin James Pustejovsky, Scott Waterman 
Affiliation: Computing Research Laboratory, New Mexico State University  Computer Science Department, Brandeis University  
Abstract: Diderot is an information extraction system built at CRL and Brandeis University over the past year. It was produced as part of our efforts in the Tipster project. Diderot has already been converted from one subject domain to another and versions of the system have been made for two languages. The same system architecture has been used for English and Japanese and a comparison is made of the processing done at each stage for the two languages. The domain of the texts used is the business area of joint ventures. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> DARPA. </author> <booktitle> Proceedings of the Third Message Understanding Conference (MUC-3), </booktitle> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Within their limited scope information extraction systems now appear to be approaching levels of performance which allow the production of adequately accurate information. This has been evidenced by the steadily improving performance of the text extraction systems which have been evaluated at successive Message Understanding Conferences <ref> [1, 2] </ref>. 2. Tipster Portability and Re-configurability The Tipster research initiative is intended as a first stage in the development of working IE systems. The approach adopted is similar to that of the earlier Message Understanding Conferences [6].
Reference: 2. <author> DARPA. </author> <booktitle> Proceedings of the Fourth Message Understanding Conference (MUC-4), </booktitle> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Within their limited scope information extraction systems now appear to be approaching levels of performance which allow the production of adequately accurate information. This has been evidenced by the steadily improving performance of the text extraction systems which have been evaluated at successive Message Understanding Conferences <ref> [1, 2] </ref>. 2. Tipster Portability and Re-configurability The Tipster research initiative is intended as a first stage in the development of working IE systems. The approach adopted is similar to that of the earlier Message Understanding Conferences [6].
Reference: 3. <author> Ralph Grishman and John Sterling. </author> <title> Acquisition of selec-tional patterns. </title> <booktitle> In Proceedings of the 14th International Conference on Computational Linguistics (COLING92), </booktitle> <address> Nantes, France, </address> <year> 1992. </year>
Reference-contexts: IBM will establish a joint venture with a local company. Using statistical techniques described in Pustejovsky [9] and similar to those in Grishman and Sterling <ref> [3] </ref>, we can automatically identify the contexts and type restrictions for this use of the verb in the corpus.
Reference: 4. <author> Louise Guthrie, Rebecca Bruce, Gees C Stein, and Fu-liang Weng. </author> <title> Development of an application independent lexicon: Lexbase. </title> <type> Technical Report MCCS-92-247, </type> <institution> Computing Research Laboratory, New Mexico State University, </institution> <year> 1992. </year>
Reference-contexts: This was parsed and anal-ysed by the CLR lexical group to give a tractable formatted version of LDOCE called LEXBASE <ref> [4] </ref>. LEXBASE contains syntactic codes, inflectional variants, and box-codes, selectional information for verbs and nouns, indicating generally what kind of arguments are well-formed with that lexical item. A GLS entry is automatically derived from LEXBASE by parsing the LEXBASE format for specific semantic information [10].
Reference: 5. <author> Louise Guthrie and Elbert Walker. </author> <title> Some comments on classification by machine. </title> <type> Technical Report MCCS-92-935, </type> <institution> Computing Research Laboratory, New Mexico State University, </institution> <year> 1992. </year>
Reference-contexts: We have and developed optimal detection algorithms from automatically generated `word' lists. The theoretical results on which the method <ref> [5] </ref> is based assure us that documents can be classified correctly if appropriate sets of words can be chosen for each document type. Intuitively, sets of words are needed which appear much more often in one text type than the other. We refer to these as `distinguishing' words.
Reference: 6. <editor> Wendy Lehnert and Beth Sundheim. </editor> <title> An evaluation of text analysis technologies. </title> <journal> AI Magazine, </journal> <volume> 12(3) </volume> <pages> 81-94, </pages> <year> 1991. </year>
Reference-contexts: Tipster Portability and Re-configurability The Tipster research initiative is intended as a first stage in the development of working IE systems. The approach adopted is similar to that of the earlier Message Understanding Conferences <ref> [6] </ref>. A large number (1,000) of domain specific texts are supplied along with a complex set of rules specifying what information is to be extracted. The texts are accompanied by accurate templates (filled structures) which have been completed by human analysts.
Reference: 7. <author> P Proctor, </author> <title> editor. Longman Dictionary of Contemporary English. </title> <publisher> Longman, </publisher> <address> Harlow, </address> <year> 1978. </year>
Reference-contexts: For this reason, the algorithm and associated dictionary is called a generative lexicon. The lexical structures contain conventional syntactic and morphological information along with detailed typing information about arguments The creation of the GLS lexicon begins with the printer's tape of the Longman Dictionary of Contemporary English (LDOCE), Proctor <ref> [7] </ref>. This was parsed and anal-ysed by the CLR lexical group to give a tractable formatted version of LDOCE called LEXBASE [4]. LEXBASE contains syntactic codes, inflectional variants, and box-codes, selectional information for verbs and nouns, indicating generally what kind of arguments are well-formed with that lexical item.
Reference: 8. <author> James Pustejovsky. </author> <title> The generative lexicon. </title> <journal> Computational Linguistics, </journal> <volume> 17(4), </volume> <year> 1991. </year>
Reference-contexts: Deriving Lexical Entries from Machine-Readable Dictionaries The lexical knowledge base consists of lexical items called generative lexical structures (GLSs), after Pustejovsky <ref> [8] </ref>. This model of semantic knowledge associated with words is based on a system of generative devices which is able to recursively define new word senses for lexical items in the language. For this reason, the algorithm and associated dictionary is called a generative lexicon. <p> The hierarchical structuring of lexical information follows in a fairly principled way the theory of Lexical Conceptual Paradigms as outlined in Pustejovsky <ref> [8] </ref>. 5. Production of the Lexically-Driven Partial Parser The generative lexical structures are "universal" in character in the same way that phrase structural descrip tions provide a general, expressive language for describing the syntactic structures for widely different linguistic behaviors from different languages.
Reference: 9. <author> James Pustejovsky. </author> <title> The acquisition of lexical semantic knowledge from large corpora. </title> <booktitle> In Proceedings of the DARPA Spoken and Written Language Workshop. </booktitle> <publisher> Mor-gan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: IBM will establish a joint venture with a local company. Using statistical techniques described in Pustejovsky <ref> [9] </ref> and similar to those in Grishman and Sterling [3], we can automatically identify the contexts and type restrictions for this use of the verb in the corpus. <p> Here, the verb announce is typed from LDOCE as taking a sentence, but it appears in the corpus with an NP. The acquisition technique presented in Pustejovsky <ref> [9] </ref> shows how coercive contexts can be identified automatically from corpus analysis. Another consideration when tuning lexical forms against a corpus is the proper representation of domain-specific syntactic and semantic typing. We are currently restructuring the lexical database to allow for greater portability across domains.
Reference: 10. <author> James Pustejovsky, Sabine Bergler, and Peter Anick. </author> <title> Lexical semantic techniques for corpus analysis. </title> <booktitle> Computational Linguistics, </booktitle> <year> 1993. </year>
Reference-contexts: LEXBASE contains syntactic codes, inflectional variants, and box-codes, selectional information for verbs and nouns, indicating generally what kind of arguments are well-formed with that lexical item. A GLS entry is automatically derived from LEXBASE by parsing the LEXBASE format for specific semantic information <ref> [10] </ref>. The most novel aspect of this conversion involves parsing the example sentences as well as parenthetical texts in the definition. This gives a much better indication of argument selection for an item than do the the boxcodes alone.
Reference: 11. <author> James Pustejovsky and Bran Boguraev. </author> <title> Lexical knowledge representation and natural language processing. </title> <journal> Artificial Intelligence, </journal> <year> 1993. </year>
Reference-contexts: The two arguments to the verb establish are minimally typed as a result of the conversion from LDOCE, this information being represented as a type-path for each argument, Pustejovsky and Boguraev <ref> [11] </ref>. For example, the subject is typed as a human and the object as a type-path relating solid and the specific type encounted in definition, shop. The syntactic and collocational behavior of a word is represented in the cospec (cospecification) field of the entry.
Reference: 12. <author> Y. Schabes and S. Shieber. </author> <title> An alternative conception of tree-adjoining derivation. </title> <booktitle> In Proceedings of 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <year> 1992. </year>
Reference-contexts: Theoretically, the expressive power of converting the cospecs of a GLS into DCG parse rules is equivalent to the power of a Lexicalized Tree Adjoining Grammar with collocations (Shieber <ref> [12] </ref>). 4.2. Tuning GLS Entries against a Corpus It is very often the case that the lexical structures derived from MRDs do not reflect the behavior of the actual words in a given corpus.
References-found: 12

