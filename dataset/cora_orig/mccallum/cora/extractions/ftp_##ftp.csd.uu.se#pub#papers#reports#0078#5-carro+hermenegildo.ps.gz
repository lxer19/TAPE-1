URL: ftp://ftp.csd.uu.se/pub/papers/reports/0078/5-carro+hermenegildo.ps.gz
Refering-URL: http://www.informatik.uni-trier.de/~ley/db/conf/iclp/iclp94-w6.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fherme,mcarrog@fi.upm.es  
Title: A note on Data-Parallelism and (And-Parallel) Prolog  
Author: Manuel V. Hermenegildo Manuel Carro 
Note: (Extended abstract)  
Address: 28660-Boadilla del Monte, Madrid Spain  
Affiliation: Universidad Politecnica de Madrid (UPM) Facultad de Informatica  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> K.A.M. Ali. </author> <title> Or-parallel Execution of Prolog on the BC-Machine. </title> <booktitle> In Fifth International Conference and Symposium on Logic Programming, </booktitle> <pages> pages 253-268, </pages> <address> Seattle,Washington, 1988. </address> <publisher> MIT Press. </publisher>
Reference: [2] <author> K.A.M. Ali and R. Karlsson. </author> <title> The Muse Or-Parallel Prolog Model and its Performance. </title> <booktitle> In 1990 North American Conference on Logic Programming. </booktitle> <publisher> MIT Press, </publisher> <month> October </month> <year> 1990. </year>
Reference: [3] <author> Henrik Arro, Jonas Barklund, and Johan Bevemyr. </author> <title> Parallel bounded quantification|preliminary results. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 28 </volume> <pages> 117-124, </pages> <year> 1993. </year>
Reference-contexts: Note that, interestingly, such unfoldings can always be performed at compile-time, provided that the depth of the recursion is known. In fact, knowing recursion bounds may actually be frequent in traditional data-parallel applications, (and is often the case when parallelizing bounded quantifications <ref> [3] </ref>).
Reference: [4] <author> Jonas Barklund. </author> <title> Parallel Unification. </title> <type> PhD thesis, </type> <institution> Comp. Sci. Dept., Uppsala Univ., Uppsala, </institution> <year> 1990. </year>
Reference-contexts: Recently, much progress has been reported in the application of concepts from data-parallelism to logic programming, both from the theoretical and practical points of view, including the design of programming constructs and the development of many implementation techniques <ref> [43, 37, 5, 8, 28, 47, 34, 4, 6, 7] </ref>.
Reference: [5] <author> Jonas Barklund and H-akan Millroth. </author> <title> Nova Prolog. </title> <type> UPMAIL Tech. Rep. 52, </type> <institution> Comp. Sci. Dept., Uppsala Univ., Uppsala, </institution> <year> 1988. </year>
Reference-contexts: Recently, much progress has been reported in the application of concepts from data-parallelism to logic programming, both from the theoretical and practical points of view, including the design of programming constructs and the development of many implementation techniques <ref> [43, 37, 5, 8, 28, 47, 34, 4, 6, 7] </ref>.
Reference: [6] <author> J. Bevemyr, T. Lindgren, and H. Millroth. </author> <title> Exploiting recursion-parallelism in Prolog. </title> <booktitle> In Proc. </booktitle> <address> PARLE'93, Berlin, 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Recently, much progress has been reported in the application of concepts from data-parallelism to logic programming, both from the theoretical and practical points of view, including the design of programming constructs and the development of many implementation techniques <ref> [43, 37, 5, 8, 28, 47, 34, 4, 6, 7] </ref>. <p> A number of implementations have been built which are capable of exploiting such special cases in an efficient way (e.g. <ref> [6, 7] </ref>). <p> We believe that this is in general the case, but it is also true that the data-parallel machines also bring some new and interesting techniques. For the sake of discussion, we will concentrate on the abstract machine of Reform Prolog <ref> [6, 7] </ref>. In many aspects, the Reform Prolog abstract machine can in fact be viewed as a "pared-down" version of a general-purpose and-parallel abstract machine such as the RAP-WAM/PWAM [26, 21], the DASWAM [40], or the Andorra-I engine [39].
Reference: [7] <author> J. Bevemyr, T. Lindgren, and H. Millroth. </author> <title> Reform Prolog: the language and its implementation. </title> <booktitle> In Proc. 10th Intl. Conf. Logic Programming, </booktitle> <address> Cambridge, Mass., 1993. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Recently, much progress has been reported in the application of concepts from data-parallelism to logic programming, both from the theoretical and practical points of view, including the design of programming constructs and the development of many implementation techniques <ref> [43, 37, 5, 8, 28, 47, 34, 4, 6, 7] </ref>. <p> A number of implementations have been built which are capable of exploiting such special cases in an efficient way (e.g. <ref> [6, 7] </ref>). <p> We believe that this is in general the case, but it is also true that the data-parallel machines also bring some new and interesting techniques. For the sake of discussion, we will concentrate on the abstract machine of Reform Prolog <ref> [6, 7] </ref>. In many aspects, the Reform Prolog abstract machine can in fact be viewed as a "pared-down" version of a general-purpose and-parallel abstract machine such as the RAP-WAM/PWAM [26, 21], the DASWAM [40], or the Andorra-I engine [39].
Reference: [8] <author> Jens Blanck. </author> <title> Abstrakt maskin for Nova Prolog. </title> <type> Internal report, </type> <institution> Comp. Sci. Dept., Uppsala Univ., Uppsala, </institution> <year> 1992. </year>
Reference-contexts: Recently, much progress has been reported in the application of concepts from data-parallelism to logic programming, both from the theoretical and practical points of view, including the design of programming constructs and the development of many implementation techniques <ref> [43, 37, 5, 8, 28, 47, 34, 4, 6, 7] </ref>.
Reference: [9] <author> M. Carro, L. Gomez, and M. Hermenegildo. </author> <title> Some Paradigms for Visualizing Parallel Execution of Logic Programs. </title> <booktitle> In 1993 International Conference on Logic Programming, </booktitle> <pages> pages 184-201. </pages> <publisher> MIT Press, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: Finally, in order to observe the phenomenon, we run the program in &-Prolog on 8 processors on a Sequent Symmetry and generate a trace file, using the following commands: main (V,VR) :- start_event_trace, vproc (V,VR), stop_event_trace, save_trace ('Eventfile'). The trace is then visualized with VisAndOr <ref> [9] </ref>. The result is depicted in Figure 1 (In VisAndOr graphs, time goes from top to bottom. Vertical solid lines denote actual execution, whereas vertical dashed lines represent waits due to scheduling or dependencies. <p> However, the speedup obtained is in fact quite small for a program such as this with obvious parallelism. This low speedup is in part due to the small granularity of the parallel tasks, and also to the slow generation of the tasks which results from giving out the recursion <ref> [9] </ref>. 2.2 Keeping the Recursion Local One simple transformation can greatly alleviate the problem mentioned above reversing the order of the goals in the parallel conjunction: vproc ([],[]). vproc ([H|T],[HR|TR]) :- vproc (T,TR) & process_element (H,HR).
Reference: [10] <author> M. Carro, E. Pontelli, G. Gupta, and M. Hermenegildo. </author> <title> Improving Execution of And-parallel Prolog Programs by Means of Determinism Analysis. </title> <type> Technical Report TR CLIP 5/94.0, </type> <institution> Computer Science Faculty, Technical University of Madrid, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: However, it should be noted that the same optimizations can also be done in machines such as the RAP-WAM if the particular case is identified, and without losing the general case <ref> [25, 10, 15] </ref>. This is also the case with some other optimizations. On the other hand, a number of optimizations, generally related to the "Reform Compilation" done in Reform Prolog [35] are more fundamental.
Reference: [11] <author> J. S. Conery. </author> <title> The And/Or Process Model for Parallel Interpretation of Logic Programs. </title> <type> PhD thesis, </type> <institution> The University of California At Irvine, </institution> <year> 1983. </year> <type> Technical Report 204. </type>
Reference: [12] <author> M.J.Garca de la Banda, M. Hermenegildo, and K. Marriott. </author> <title> Independence in Constraint Logic Programs. </title> <booktitle> In 1993 International Logic Programming Symposium, </booktitle> <pages> pages 130-146. </pages> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: It is interesting to note that the restrictions that general purpose systems impose on the goals which can be executed in parallel (such as independence and/or determinacy applied at different granularity levels <ref> [23, 36, 38, 12, 24] </ref> are generally the minimal ones needed in order to ensure vital desired properties such as correctness of results or "no-slowdown", i.e. that parallel execution be guaranteed to take no more time than sequential execution.
Reference: [13] <author> D. </author> <title> DeGroot. Restricted AND-Parallelism. </title> <booktitle> In International Conference on Fifth Generation Computer Systems, </booktitle> <pages> pages 471-478. </pages> <address> Tokyo, </address> <month> November </month> <year> 1984. </year> <month> 14 </month>
Reference: [14] <author> D. </author> <title> DeGroot. Restricted AND-Parallelism and Side-Effects. </title> <booktitle> In International Symposium on Logic Programming, </booktitle> <pages> pages 80-89. </pages> <address> San Francisco, </address> <publisher> IEEE Computer Society, </publisher> <month> August </month> <year> 1987. </year>
Reference: [15] <author> T. DongXing, E. Pontelli, G. Gupta, and M. Carro. </author> <title> Last Parallel Call Optimization and Fast Backtracking in And-parallel Logic Programming Systems. </title> <booktitle> 1994. Presented at ICLP'94 Workshop on Parallel and Data Parallel Execution of Logic Programs. </booktitle>
Reference-contexts: However, it should be noted that the same optimizations can also be done in machines such as the RAP-WAM if the particular case is identified, and without losing the general case <ref> [25, 10, 15] </ref>. This is also the case with some other optimizations. On the other hand, a number of optimizations, generally related to the "Reform Compilation" done in Reform Prolog [35] are more fundamental.
Reference: [16] <author> B. S. Fagin. </author> <title> A Parallel Execution Model for Prolog. </title> <type> PhD thesis, </type> <institution> The University of California at Berkeley, </institution> <month> November </month> <year> 1987. </year> <note> Technical Report UCB/CSD 87/380. </note>
Reference: [17] <author> G. Gupta, M. Hermenegildo, Enrico Pontelli, and Vtor Santos Costa. </author> <title> ACE: And/Or-parallel Copying-based Execution of Logic Programs. </title> <booktitle> In International Conference on Logic Programming. </booktitle> <publisher> MIT Press, </publisher> <month> June </month> <year> 1994. </year> <note> to appear. </note>
Reference: [18] <author> G. Gupta and B. Jayaraman. </author> <title> Compiled And-Or Parallelism on Shared Memory Multiprocessors. </title> <booktitle> In 1989 North American Conference on Logic Programming, </booktitle> <pages> pages 332-349. </pages> <publisher> MIT Press, </publisher> <month> October </month> <year> 1989. </year>
Reference: [19] <author> G. Gupta, V. Santos-Costa, R. Yang, and M. Hermenegildo. IDIOM: </author> <title> Integrating Dependent and-, Independent and-, and Or-parallelism. </title> <booktitle> In 1991 International Logic Programming Symposium, </booktitle> <pages> pages 152-166. </pages> <publisher> MIT Press, </publisher> <month> October </month> <year> 1991. </year>
Reference: [20] <author> Philip J. Hatcher and Michael J. Quinn. </author> <title> Data-parallel Programming on MIMD Computers. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1991. </year>
Reference-contexts: In this context a definite iteration as an iteration where the number of repetitions is known before the iteration is initiated. Data parallelism has been exploited in many languages, including Fortran-90 [33], C* [42], Data Parallel C <ref> [20] </ref>, *LISP [41], etc.
Reference: [21] <author> M. Hermenegildo and K. Greene. </author> <title> &-Prolog and its Performance: Exploiting Independent And-Parallelism. </title> <booktitle> In 1990 International Conference on Logic Programming, </booktitle> <pages> pages 253-268. </pages> <publisher> MIT Press, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: For the sake of discussion, we will concentrate on the abstract machine of Reform Prolog [6, 7]. In many aspects, the Reform Prolog abstract machine can in fact be viewed as a "pared-down" version of a general-purpose and-parallel abstract machine such as the RAP-WAM/PWAM <ref> [26, 21] </ref>, the DASWAM [40], or the Andorra-I engine [39]. For example, there are a number of agents or workers which are each essentially a WAM. Also, the dynamic scheduling techniques are very similar to the goal stealing method used in the RAP-WAM. Understandably, there are also some major differences.
Reference: [22] <author> M. Hermenegildo and K. Greene. </author> <title> The &-prolog System: Exploiting Independent And-Parallelism. New Generation Computing, </title> <address> 9(3,4):233-257, </address> <year> 1991. </year>
Reference-contexts: be used in the "forwards" way, i.e. a ground list of values and a free variable will be supplied as arguments (in that order), expecting as a result a ground list. 2.1 The Naive Approach This program can be naively parallelized as follows using "control-parallelism" (we will use throughout &-Prolog <ref> [22] </ref> syntax, where the "&" operator represents a potentially parallel conjunction): vproc ([],[]). vproc ([H|T],[HR|TR]) :- process_element (H,HR) & vproc (T,TR). This will allow the parallel execution of all iterations. Note that the parallelization is safe, since all iterations are independent.
Reference: [23] <author> M. Hermenegildo and F. Rossi. </author> <title> Strict and Non-Strict Independent And-Parallelism in Logic Programs: Correctness, Efficiency, and Compile-Time Conditions. </title> <journal> Journal of Logic Programming, </journal> <note> 1994. To appear. </note>
Reference-contexts: It is interesting to note that the restrictions that general purpose systems impose on the goals which can be executed in parallel (such as independence and/or determinacy applied at different granularity levels <ref> [23, 36, 38, 12, 24] </ref> are generally the minimal ones needed in order to ensure vital desired properties such as correctness of results or "no-slowdown", i.e. that parallel execution be guaranteed to take no more time than sequential execution.
Reference: [24] <author> M. </author> <title> Hermenegildo and the CLIP group. First steps towards a ciao-prolog system. </title> <booktitle> In Proc. of the Compulog Net Area Workshop on Parallelism and Implementation Technologies. </booktitle> <institution> Technical University of Madrid, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: It is interesting to note that the restrictions that general purpose systems impose on the goals which can be executed in parallel (such as independence and/or determinacy applied at different granularity levels <ref> [23, 36, 38, 12, 24] </ref> are generally the minimal ones needed in order to ensure vital desired properties such as correctness of results or "no-slowdown", i.e. that parallel execution be guaranteed to take no more time than sequential execution.
Reference: [25] <author> M. V. Hermenegildo. </author> <title> An Abstract Machine Based Execution Model for Computer Architecture Design and Efficient Implementation of Logic Programs in Parallel. </title> <type> PhD thesis, </type> <institution> Dept. of Electrical and Computer Engineering (Dept. of Computer Science TR-86-20), University of Texas at Austin, Austin, Texas 78712, </institution> <month> August </month> <year> 1986. </year>
Reference-contexts: However, it should be noted that the same optimizations can also be done in machines such as the RAP-WAM if the particular case is identified, and without losing the general case <ref> [25, 10, 15] </ref>. This is also the case with some other optimizations. On the other hand, a number of optimizations, generally related to the "Reform Compilation" done in Reform Prolog [35] are more fundamental.
Reference: [26] <author> M. V. Hermenegildo. </author> <title> An Abstract Machine for Restricted AND-parallel Execution of Logic Programs. </title> <booktitle> In Third International Conference on Logic Programming, number 225 in Lecture Notes in Computer Science, </booktitle> <pages> pages 25-40. </pages> <address> Imperial College, </address> <publisher> Springer-Verlag, </publisher> <month> July </month> <year> 1986. </year>
Reference-contexts: For the sake of discussion, we will concentrate on the abstract machine of Reform Prolog [6, 7]. In many aspects, the Reform Prolog abstract machine can in fact be viewed as a "pared-down" version of a general-purpose and-parallel abstract machine such as the RAP-WAM/PWAM <ref> [26, 21] </ref>, the DASWAM [40], or the Andorra-I engine [39]. For example, there are a number of agents or workers which are each essentially a WAM. Also, the dynamic scheduling techniques are very similar to the goal stealing method used in the RAP-WAM. Understandably, there are also some major differences.
Reference: [27] <author> M. V. Hermenegildo. </author> <title> Independent AND-Parallel Prolog and its Architecture. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA 02061, </address> <year> 1989. </year>
Reference: [28] <author> Peter Kacsuk. </author> <title> Execution Models of Prolog for Parallel Computers. </title> <publisher> Pitman, </publisher> <address> London, </address> <year> 1990. </year>
Reference-contexts: Recently, much progress has been reported in the application of concepts from data-parallelism to logic programming, both from the theoretical and practical points of view, including the design of programming constructs and the development of many implementation techniques <ref> [43, 37, 5, 8, 28, 47, 34, 4, 6, 7] </ref>.
Reference: [29] <author> L. Kale. </author> <title> Parallel Execution of Logic Programs: the REDUCE-OR Process Model. </title> <booktitle> In Fourth International Conference on Logic Programming, </booktitle> <pages> pages 616-632. </pages> <address> Melbourne, Australia, </address> <month> May </month> <year> 1987. </year>
Reference: [30] <editor> V. Kumar and L.N. Kanal. </editor> <title> Parallel branch-and-bound formulations for and/or tree search. </title> <journal> IEEE transactions on pattern analysis and machine intelligence, </journal> <volume> 6 </volume> <pages> 768-778, </pages> <month> November </month> <year> 1984. </year> <month> 15 </month>
Reference: [31] <author> Y. J. Lin and V. Kumar. </author> <title> AND-Parallel Execution of Logic Programs on a Shared Memory Mul--tiprocessor: A Summary of Results. </title> <booktitle> In Fifth International Conference and Symposium on Logic Programming, </booktitle> <pages> pages 1123-1141. </pages> <address> University of Washington, </address> <publisher> MIT Press, </publisher> <month> August </month> <year> 1988. </year>
Reference: [32] <editor> E. Lusk et. al. </editor> <title> The Aurora Or-Parallel Prolog System. New Generation Computing, </title> <address> 7(2,3), </address> <year> 1990. </year>
Reference: [33] <author> Michael Metcalf and John Reid. </author> <title> Fortran 90 Explained. </title> <publisher> Oxford Univ. Press, Oxford, </publisher> <year> 1990. </year>
Reference-contexts: In this context a definite iteration as an iteration where the number of repetitions is known before the iteration is initiated. Data parallelism has been exploited in many languages, including Fortran-90 <ref> [33] </ref>, C* [42], Data Parallel C [20], *LISP [41], etc.
Reference: [34] <author> H-akan Millroth. </author> <title> Reforming Compilation of Logic Programs. </title> <type> PhD thesis, </type> <institution> Comp. Sci. Dept., Uppsala Univ., Uppsala, </institution> <year> 1990. </year>
Reference-contexts: Recently, much progress has been reported in the application of concepts from data-parallelism to logic programming, both from the theoretical and practical points of view, including the design of programming constructs and the development of many implementation techniques <ref> [43, 37, 5, 8, 28, 47, 34, 4, 6, 7] </ref>. <p> The speed is not quite as good as when the 10 tasks are created at the same time, but the results are close. This "flattening" approach, which has been used in &-Prolog compilation informally (see e.g. [46] and some of the standard &-Prolog benchmarks), has been studied formally Millroth <ref> [34] </ref>, which has given 8 sufficient conditions for performing these transformations for particular cases such as linear recursion. There are still two problems with this approach, however.
Reference: [35] <author> H-akan Millroth. </author> <title> Reforming compilation of logic programs. </title> <editor> In Vijay Saraswat and Kazunori Ueda, editors, </editor> <booktitle> Logic Programming, Proceedings of the 1991 International Symposium, </booktitle> <pages> pages 485-502, </pages> <address> San Diego, USA, 1991. </address> <publisher> The MIT Press. </publisher>
Reference-contexts: This is also the case with some other optimizations. On the other hand, a number of optimizations, generally related to the "Reform Compilation" done in Reform Prolog <ref> [35] </ref> are more fundamental. We find these optimizations particularly interesting because they bring attention upon a very interesting issue the performance of and-parallel systems: that of the speed in the creation and joining of tasks.
Reference: [36] <author> L. Naish. </author> <title> Parallelizing NU-Prolog. </title> <booktitle> In Fifth International Conference and Symposium on Logic Programming, </booktitle> <pages> pages 1546-1564. </pages> <address> University of Washington, </address> <publisher> MIT Press, </publisher> <month> August </month> <year> 1988. </year>
Reference-contexts: It is interesting to note that the restrictions that general purpose systems impose on the goals which can be executed in parallel (such as independence and/or determinacy applied at different granularity levels <ref> [23, 36, 38, 12, 24] </ref> are generally the minimal ones needed in order to ensure vital desired properties such as correctness of results or "no-slowdown", i.e. that parallel execution be guaranteed to take no more time than sequential execution.
Reference: [37] <author> Martin Nilsson and Hidehiko Tanaka. </author> <title> A Flat GHC implementation for supercomputers. </title> <editor> In R. A. Kowalski and K. A. Bowen, editors, </editor> <booktitle> Proc. Fifth Intl. Conf. Symp. on Logic Programming, </booktitle> <pages> pages 1337-1350, </pages> <address> Cambridge, Mass., 1988. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Recently, much progress has been reported in the application of concepts from data-parallelism to logic programming, both from the theoretical and practical points of view, including the design of programming constructs and the development of many implementation techniques <ref> [43, 37, 5, 8, 28, 47, 34, 4, 6, 7] </ref>.
Reference: [38] <author> V. Santos-Costa, D.H.D. Warren, and R. Yang. Andorra-I: </author> <title> A Parallel Prolog System that Transparently Exploits both And- and Or-parallelism. </title> <booktitle> In Proceedings of the 3rd. ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming. ACM, </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: It is interesting to note that the restrictions that general purpose systems impose on the goals which can be executed in parallel (such as independence and/or determinacy applied at different granularity levels <ref> [23, 36, 38, 12, 24] </ref> are generally the minimal ones needed in order to ensure vital desired properties such as correctness of results or "no-slowdown", i.e. that parallel execution be guaranteed to take no more time than sequential execution.
Reference: [39] <author> V. Santos-Costa, D.H.D. Warren, and R. Yang. </author> <title> The Andorra-I Engine: A Parallel Implementation of the Basic Andorra Model. </title> <booktitle> In 1991 International Conference on Logic Programming, </booktitle> <pages> pages 825-839. </pages> <publisher> MIT Press, </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: In many aspects, the Reform Prolog abstract machine can in fact be viewed as a "pared-down" version of a general-purpose and-parallel abstract machine such as the RAP-WAM/PWAM [26, 21], the DASWAM [40], or the Andorra-I engine <ref> [39] </ref>. For example, there are a number of agents or workers which are each essentially a WAM. Also, the dynamic scheduling techniques are very similar to the goal stealing method used in the RAP-WAM. Understandably, there are also some major differences.
Reference: [40] <author> K. Shen. </author> <title> Exploiting Dependent And-Parallelism in Prolog: The Dynamic, Dependent And-Parallel Scheme. </title> <booktitle> In Proc. Joint Int'l. Conf. and Symp. on Logic Prog. </booktitle> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: For the sake of discussion, we will concentrate on the abstract machine of Reform Prolog [6, 7]. In many aspects, the Reform Prolog abstract machine can in fact be viewed as a "pared-down" version of a general-purpose and-parallel abstract machine such as the RAP-WAM/PWAM [26, 21], the DASWAM <ref> [40] </ref>, or the Andorra-I engine [39]. For example, there are a number of agents or workers which are each essentially a WAM. Also, the dynamic scheduling techniques are very similar to the goal stealing method used in the RAP-WAM. Understandably, there are also some major differences.
Reference: [41] <institution> Thinking Machines Corp., </institution> <address> Cambridge, Mass. </address> <booktitle> The Essential *LISP Manual, </booktitle> <year> 1986. </year>
Reference-contexts: In this context a definite iteration as an iteration where the number of repetitions is known before the iteration is initiated. Data parallelism has been exploited in many languages, including Fortran-90 [33], C* [42], Data Parallel C [20], *LISP <ref> [41] </ref>, etc. Recently, much progress has been reported in the application of concepts from data-parallelism to logic programming, both from the theoretical and practical points of view, including the design of programming constructs and the development of many implementation techniques [43, 37, 5, 8, 28, 47, 34, 4, 6, 7].
Reference: [42] <institution> Thinking Machines Corp., </institution> <address> Cambridge, Mass. </address> <note> C* Programming Guide, </note> <year> 1990. </year>
Reference-contexts: In this context a definite iteration as an iteration where the number of repetitions is known before the iteration is initiated. Data parallelism has been exploited in many languages, including Fortran-90 [33], C* <ref> [42] </ref>, Data Parallel C [20], *LISP [41], etc.
Reference: [43] <author> Andrei Voronkov. </author> <title> Logic programming with bounded quantifiers. </title> <editor> In Andrei Voronkov, editor, </editor> <booktitle> Logic Programming|Proc. Second Russian Conf. on Logic Programming, LNCS 592, </booktitle> <address> Berlin, 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Recently, much progress has been reported in the application of concepts from data-parallelism to logic programming, both from the theoretical and practical points of view, including the design of programming constructs and the development of many implementation techniques <ref> [43, 37, 5, 8, 28, 47, 34, 4, 6, 7] </ref>.
Reference: [44] <author> D.H.D. Warren. </author> <title> The SRI Model for OR-Parallel Execution of Prolog|Abstract Design and Implementation. </title> <booktitle> In International Symposium on Logic Programming, </booktitle> <pages> pages 92-102. </pages> <address> San Francisco, </address> <publisher> IEEE Computer Society, </publisher> <month> August </month> <year> 1987. </year>
Reference: [45] <author> D.H.D. Warren. </author> <title> The Andorra Model. Presented at Gigalips Project workshop. </title> <type> U. </type> <institution> of Manchester, </institution> <month> March </month> <year> 1988. </year>
Reference: [46] <author> R. Warren and M. Hermenegildo. </author> <title> Experimenting with Prolog: An Overview. </title> <type> Technical Report 43, </type> <institution> MCC, </institution> <month> March </month> <year> 1987. </year>
Reference-contexts: in general and thus some other solution must be explored. 2.4 A More Dynamic Unfolding The following program is an attempt at making the unfolding more dynamic, while still staying within the source-to-source program transformation approach: 2 In fact, a "map" builtin was indeed tried at some point in time <ref> [46] </ref> and showed substantial improvements for some benchmarks. 7 vproc ([H1,H2,H3,H4|T],[HR1,HR2,HR3,HR4|TR]) :- !, vproc (T,TR) & process_element (H1,HR1) & process_element (H2,HR2) & process_element (H3,HR3) & process_element (H4,HR4). vproc ([H1,H2,H3|T],[HR1,HR2,HR3|TR]) :- !, vproc (T,TR) & process_element (H1,HR1) & process_element (H2,HR2) & process_element (H3,HR3). vproc ([H1,H2|T],[HR1,HR2|TR]) :- !, vproc (T,TR) & process_element (H1,HR1) <p> The speed is not quite as good as when the 10 tasks are created at the same time, but the results are close. This "flattening" approach, which has been used in &-Prolog compilation informally (see e.g. <ref> [46] </ref> and some of the standard &-Prolog benchmarks), has been studied formally Millroth [34], which has given 8 sufficient conditions for performing these transformations for particular cases such as linear recursion. There are still two problems with this approach, however.
Reference: [47] <author> M. J. Wise. </author> <title> Experimenting with epilog: Some results and preliminary conclusions. </title> <booktitle> In 13th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 130-139. </pages> <publisher> IEEE Computer Society, </publisher> <month> June </month> <year> 1986. </year>
Reference-contexts: Recently, much progress has been reported in the application of concepts from data-parallelism to logic programming, both from the theoretical and practical points of view, including the design of programming constructs and the development of many implementation techniques <ref> [43, 37, 5, 8, 28, 47, 34, 4, 6, 7] </ref>.
References-found: 47

