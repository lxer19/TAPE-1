URL: http://www.cs.duke.edu/~jsv/Papers/MVN97.dynamic_rv_gen.ps.gz
Refering-URL: http://www.cs.duke.edu/~jsv/Papers/catalog/node70.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email: matias@research.bell-labs.com.  Email: wcn@cs.brown.edu.  
Title: Dynamic Generation of Discrete Random Variates  
Author: Yossi Matias Jeffrey Scott Vitter Wen-Chun Ni 
Note: 2 Support was provided in part by National Science Foundation grants CCR-8906949 and CCR-9111348. Part of the work was done while the author was  4 Support was provided in part by the Office of Naval Research and the Defense Advanced Research Projects Agency under contract N00014-91-J-4052, ARPA order 8225.  
Date: May 1997  
Address: 600 Mountain Avenue Murray Hill, N.J. 07974  Durham, N.C. 27708-0129  Providence, R.I. 02912-1910  University.  
Affiliation: Bell Laboratories  Department of Computer Science Duke University  Department of Computer Science Brown University  at University of Maryland, Institute for Advanced Computer Studies, and at Tel Aviv  
Abstract: 1 This paper is a combination of two independent works [17] and [24] and collaborative work. A summa rized version appears in [19]. 3 Support was provided in part by a National Science Foundation Presidential Young Investigator Award with matching funds from IBM, by NSF research grants CCR-9007851 and CCR-9522047, and by Army Research Office grants DAAL03-91-G-0035 and DAAH04-96-1-0013. Part of the work was done while the author was at Brown University. Part of the revisions were done while the author was visiting Lucent Technologies, Bell Laboratories, Murray Hill, NJ. Email: jsv@cs.duke.edu. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Bratley and B. L. Fox and L. E. </author> <title> Schrage, A Guide to Simulation. </title> <publisher> Springer-Verlag, </publisher> <address> Second Edition, </address> <year> 1987. </year>
Reference-contexts: e.g., [15]), in O (log n= log log n) time when some of the time bounds are allowed to be amortized [8], in O ( p amortized expected time when randomization is allowed [8], and in O (log log u) time when the element values are integers in the universe <ref> [1; u] </ref> [23]. The *-heap we construct supports the more relaxed query *-findmax, in which the element returned must have a value within an * relative factor of the maximum element value. <p> Subsequently, for a given r the appropriate index i = i (r) can be found in constant time. The size of the lookup table, as well as the time it takes to precompute it, are O (W N ). If the weights w i are integers from the range <ref> [1; m] </ref>, then W N mN . To handle updates, we need to precompute a lookup table for each possible set of weights. Since each of the N weights can have m possible values, there are at most m N lookup tables to precompute. <p> The weights of each range R j in interval I t are now normalized to ~w (R j ) = j tblog 1+* N c 2 <ref> [1; : : : ; blog 1+* N c] </ref>. For each interval, we keep a separate priority queue of van Emde Boas et al. [23].
Reference: [2] <author> J. L. Carter and M. N. Wegman. </author> <title> Universal Classes of Hash Functions, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 18: </volume> <pages> 143-154, </pages> <month> April </month> <year> 1979. </year>
Reference-contexts: To reduce the universe, it is sufficient to use a 2-universal hash function <ref> [2] </ref>, which will enable injective universe reduction with high probability. We must find a family of classes of 2-universal hash functions that are easy to compute without a priori knowledge about the universe size.
Reference: [3] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference: [4] <author> M. Dietzfelbinger, J. Gil, Y. Matias, and N. Pippenger. </author> <title> Polynomial Hash Functions are Reliable. </title> <booktitle> Proceedings of the 19th Annual International Colloquium on Automata, Languages, and Programming, </booktitle> <publisher> Springer LNCS 623, </publisher> <pages> 235-246, </pages> <year> 1992. </year>
Reference-contexts: To be more specific, we use a dictionary data structure that supports the operations of insert, delete, and lookup. We use dictionary algorithms that support each of these operations in constant time, with high probability <ref> [6, 4] </ref>. Because of the varying sizes of the weights, we may have to reinitialize dictionaries from time to time when we need to insert a weight that is too large and does not belong to the universe handled by the dictionary.
Reference: [5] <author> M. Dietzfelbinger, T. Hagerup, J. Katajainen, and M. Penttonen. </author> <title> A Reliable Randomized Algorithm for the Closest-Pair Problem. </title> <type> Manuscript, </type> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: We must find a family of classes of 2-universal hash functions that are easy to compute without a priori knowledge about the universe size. Dietzfelbinger et al. <ref> [5] </ref> recently developed such a scheme that allows hash functions to be selected 18 8 *-HEAP in constant time. <p> In our applications for dynamically generating random variates, a simpler version of the dictionary problem arose in Section 6, in which lookup operations are not required by the data structure, and we have an expected constant-time solution, using a new class of hash functions of Dietzfelbinger et al. <ref> [5] </ref>; the main purpose of the dictionary is merely to obtain linear storage space.
Reference: [6] <editor> M. Dietzfelbinger and F. Meyer auf der Heide. </editor> <title> A New Universal Class of Hash Functions and Dynamic Hashing in Real Time, </title> <booktitle> Proceedings of the 17th Annual International Colloquium on Automata, Languages, and Programming, </booktitle> <publisher> Springer LNCS 443: </publisher> <pages> 6-19, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: To be more specific, we use a dictionary data structure that supports the operations of insert, delete, and lookup. We use dictionary algorithms that support each of these operations in constant time, with high probability <ref> [6, 4] </ref>. Because of the varying sizes of the weights, we may have to reinitialize dictionaries from time to time when we need to insert a weight that is too large and does not belong to the universe handled by the dictionary.
Reference: [7] <author> B. L. Fox. </author> <title> Simulated Annealing: Folklore, Facts, and Directions, Monte Carlo and Quasi-Monte Carlo Methods in Scientific Computing (H. </title> <editor> Niederreiter and P.J.-S. Shiue, eds.), </editor> <booktitle> Lecture Notes in Statistics. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference: [8] <author> M. L. Fredman and D. E. Willard. </author> <title> Trans-Dichotomous Algorithms for Minimum Spanning Trees and Shortest Paths. </title> <booktitle> Proceedings of the 31st Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> 719-725, </pages> <year> 1990. </year>
Reference-contexts: The operations can be implemented in O (log n) time on the standard heap (see, e.g., [15]), in O (log n= log log n) time when some of the time bounds are allowed to be amortized <ref> [8] </ref>, in O ( p amortized expected time when randomization is allowed [8], and in O (log log u) time when the element values are integers in the universe [1; u] [23]. <p> The operations can be implemented in O (log n) time on the standard heap (see, e.g., [15]), in O (log n= log log n) time when some of the time bounds are allowed to be amortized <ref> [8] </ref>, in O ( p amortized expected time when randomization is allowed [8], and in O (log log u) time when the element values are integers in the universe [1; u] [23]. The *-heap we construct supports the more relaxed query *-findmax, in which the element returned must have a value within an * relative factor of the maximum element value.
Reference: [9] <author> J. Gil and Y. Matias. </author> <title> Fast and Efficient Simulations among CRCW PRAMs. </title> <journal> J. of Parallel and Distributed Computing, </journal> <volume> 23(2) </volume> <pages> 135-148, </pages> <year> 1994. </year>
Reference-contexts: However, each step of an m-processor Fetch&Add pram can be simulated on standard crcw models (e.g., on Arbitrary, Priority, Collision, or Tolerant) in O (log m= log log m) time, O (m) space, and O (m) operations, with high probability <ref> [9] </ref>. As in the sequential case, the memory is managed through a dictionary algorithm: we use a parallel dictionary algorithm which with linear space supports each instruction in O (log fl m) time and O (m) operations, with high probability [18, 10].
Reference: [10] <author> J. Gil, Y. Matias, and U. Vishkin. </author> <title> Towards a Theory of Nearly Constant Time Parallel Algorithms. </title> <booktitle> Proceedings of the 32nd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> 698-710, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: As in the sequential case, the memory is managed through a dictionary algorithm: we use a parallel dictionary algorithm which with linear space supports each instruction in O (log fl m) time and O (m) operations, with high probability <ref> [18, 10] </ref>. Theorem 7 The expected cost for generating m random variates according to the current weights is O (log fl N ), using m processors on a crcw pram, where N is the number of elements.
Reference: [11] <author> A. Gottlieb, R. Grishman, C. P. Kruskal, K. P. McAulife, L. Rudolph, and M. Snir. </author> <title> The NYU Ultracomputer|Designing an MIMD Shared Memory Parallel Machine. </title> <journal> IEEE Trans. on Comp, </journal> <volume> C-32:175-189, </volume> <year> 1983. </year>
Reference-contexts: For N 65536, we have log fl N 4; for N 2 65536 , we have log fl N 5. 2 2 FIRST ALGORITHM on an m-processor crcw pram with optimal speedup, with respect to the algorithms mentioned above. The parallel update algorithm requires the (non-standard) Fetch&Add pram <ref> [11] </ref>; it can be processed with a slow-down of t = fi (log m= log log m), with high probability, on a (standard) crcw pram with m=t processors, yielding optimal speedup. <p> In such case, we need to update the range by the sum of these updates. This can be done in constant time on a Fetch&Add pram <ref> [11] </ref>. 2 This model is a powerful and non-standard model of crcw pram.
Reference: [12] <author> A. Greenberg and J. S. Vitter. </author> <title> Constant-Time Generation of Dynamic Random Variates, </title> <booktitle> Notes, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: Each generation requires one call to a random number generator that provides a uniform random integer in the range [0; P Recently, Rajasekaran and Ross [21] and Greenberg and Vitter <ref> [12] </ref> developed different algorithms for the dynamic case that do generation and update in constant expected time for various restricted classes of updates.
Reference: [13] <author> T. Hagerup, K. Mehlhorn, and I. Munro. </author> <title> Optimal Algorithms for Generating Time-Varying Discrete Random Variates, </title> <booktitle> Proceedings of the 20th Annual International Colloquium on Automata, Languages, and Programming, </booktitle> <publisher> Springer LNCS 700: </publisher> <pages> 253-264, </pages> <month> July </month> <year> 1993. </year> <month> 23 </month>
Reference-contexts: After the submission of the conference version of this paper [19], the authors learned of an interesting recent algorithm due to Hagerup, Mehlhorn, and Munro <ref> [13] </ref> that does generation and update in constant expected time and linear space when the weights are nonnegative integers and the maximum weight is bounded by a polynomial in N . <p> The ultimate theoretical improvement is constant expected time per dynamic operation, which we show how to achieve in Section 5. We use the lookup table technique of <ref> [13] </ref> to adapt our algorithms and obtain expected constant time for generation and update, without the primary restrictions required in [13]. An application of our method to the problem of constant-time prediction for prefetching appears in [16]. Dictionary issues for efficient space utilization are considered in Section 6. <p> The ultimate theoretical improvement is constant expected time per dynamic operation, which we show how to achieve in Section 5. We use the lookup table technique of <ref> [13] </ref> to adapt our algorithms and obtain expected constant time for generation and update, without the primary restrictions required in [13]. An application of our method to the problem of constant-time prediction for prefetching appears in [16]. Dictionary issues for efficient space utilization are considered in Section 6. In all our algorithms, no assumption is being made about the distributions of the input values and operations. <p> k log fl N , at the cost of O (k + a log fl Nk ) expected generation time, for some constant a &gt; 2. 5 Expected Constant-Time Updates and Generation A simple lookup table technique for dynamic random variate generation was recently developed by Hagerup, Mehlhorn, and Munro <ref> [13] </ref>. Their use of the technique provides a constant-time algorithm for generation and update, but only when the weights are integral and bounded by a polynomial in N . <p> The total space S required for storing all the lookup tables is therefore S = O (N m N+1 ); (4) and it takes O (S) time to construct them. The full details of the construction appear in <ref> [13] </ref>. We apply the table lookup technique as follows. The idea is to use only two levels of recursion of the data structure of Section 3. <p> The expectations in each algorithm are over the randomness in the algorithms; we make no assumptions about the weight updates. We have shown in Section 5 how to improve the running time to expected constant time by using the elegant lookup table technique developed by Hagerup, Mehlhorn, and Munro <ref> [13] </ref>. The table lookup method was used in [13] to get an expected constant-time algorithm for the case when the weights are integers and bounded by a polynomial of N . Our use of table lookup, however, removes all assumptions about the weights. <p> We have shown in Section 5 how to improve the running time to expected constant time by using the elegant lookup table technique developed by Hagerup, Mehlhorn, and Munro <ref> [13] </ref>. The table lookup method was used in [13] to get an expected constant-time algorithm for the case when the weights are integers and bounded by a polynomial of N . Our use of table lookup, however, removes all assumptions about the weights.
Reference: [14] <author> D. E. Knuth. </author> <booktitle> The Art of Computer Programming, Volume 2: Seminumerical Algorithms. </booktitle> <publisher> Ad-dison Wesley, </publisher> <address> Reading, MA, </address> <year> 1981. </year>
Reference-contexts: 1 Introduction The generation of random variates based on arbitrary finite, discrete distributions has long been a key component of many computer simulations [1],[7], <ref> [14] </ref>, [25]. <p> In the static case, when the N weights are fixed, we can utilize the clever optimal algorithm by Walker, commonly called the alias method ; the time to generate a random variate is constant and the preprocessing cost is O (N ) <ref> [14] </ref>, [25]. In this paper we consider the problem in the important and more challenging dynamic case, in which the weights of the elements can be updated dynamically. The relevant measures of efficiency are the generation time and the update time.
Reference: [15] <author> D. E. Knuth. </author> <title> The Art of Computer Programming, Volume 3: Sorting and Searching. </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1973. </year>
Reference-contexts: Priority queues support the operations of insert, delete, and findmax; a findmax query returns an element having the maximum value of all the stored elements. The operations can be implemented in O (log n) time on the standard heap (see, e.g., <ref> [15] </ref>), in O (log n= log log n) time when some of the time bounds are allowed to be amortized [8], in O ( p amortized expected time when randomization is allowed [8], and in O (log log u) time when the element values are integers in the universe [1; u]
Reference: [16] <author> P. Krishnan and J. S. Vitter. </author> <title> Optimal Prediction for Prefetching in the Worst Case, </title> <booktitle> Proceedings of the Fifth Annual SIAM-ACM Symposium on Discrete Algorithms, </booktitle> <pages> 392-401, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: We use the lookup table technique of [13] to adapt our algorithms and obtain expected constant time for generation and update, without the primary restrictions required in [13]. An application of our method to the problem of constant-time prediction for prefetching appears in <ref> [16] </ref>. Dictionary issues for efficient space utilization are considered in Section 6. In all our algorithms, no assumption is being made about the distributions of the input values and operations. The expectations are over the randomness in the algorithm itself. <p> Our use of table lookup, however, removes all assumptions about the weights. The variance of the running times of our algorithms can also be made to be o (1) so as to get good tail bounds. Our constant-time algorithm has been applied in <ref> [16] </ref> to the universal prediction techniques developed in [16]; the resulting prediction algorithm runs in constant expected time. <p> The variance of the running times of our algorithms can also be made to be o (1) so as to get good tail bounds. Our constant-time algorithm has been applied in <ref> [16] </ref> to the universal prediction techniques developed in [16]; the resulting prediction algorithm runs in constant expected time. <p> That test can be done in constant expected time using finite precision by generating an exponentially distributed random variate <ref> [16] </ref>. All our algorithms are implemented in linear space, by using dynamic hashing algorithms.
Reference: [17] <author> Y. Matias. </author> <title> Rolling a Dice with Varying Biases. </title> <type> Manuscript, </type> <month> July </month> <year> 1992. </year>
Reference: [18] <author> Y. Matias and U. Vishkin. </author> <title> Converting High Probability into Nearly-Constant Time|with Applications to Parallel Hashing. </title> <booktitle> Proceedings of the 23rd Annual ACM Symposium on Theory of Computing, </booktitle> <pages> 307-316, </pages> <year> 1991. </year>
Reference-contexts: As in the sequential case, the memory is managed through a dictionary algorithm: we use a parallel dictionary algorithm which with linear space supports each instruction in O (log fl m) time and O (m) operations, with high probability <ref> [18, 10] </ref>. Theorem 7 The expected cost for generating m random variates according to the current weights is O (log fl N ), using m processors on a crcw pram, where N is the number of elements.
Reference: [19] <author> Y. Matias, J. Vitter, and W. C. Ni. </author> <title> Dynamic Generation of Discrete Random Variates, </title> <booktitle> Proceedings of the 4th Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <address> Austin, TX, </address> <month> January </month> <year> 1993, </year> <pages> 361-370. </pages>
Reference-contexts: After the submission of the conference version of this paper <ref> [19] </ref>, the authors learned of an interesting recent algorithm due to Hagerup, Mehlhorn, and Munro [13] that does generation and update in constant expected time and linear space when the weights are nonnegative integers and the maximum weight is bounded by a polynomial in N .
Reference: [20] <author> Y. Matias, J. Vitter, and N. Young. </author> <title> Approximate Data Structures with Applications. </title> <booktitle> Proceedings of the 5th Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <address> Alexandria, VA, </address> <month> January </month> <year> 1994, </year> <pages> 187-194. </pages>
Reference-contexts: In Section 8 we have presented the *-heap data structure|an approximating alternative to the classic heap|that uses O (log log log n) time per operation for * = 1=polylog (n). Recently <ref> [20] </ref> several improvements were obtained, including the presentation of other *-data structures with operations such as *-findmin and *-successor, and an algorithm that maintains an *-heap in O (1) time per operation, for * = 1=polylog (n), and whose use of truncated logarithms is restricted to the reasonable class of binary
Reference: [21] <author> S. Rajasekaran and K. W. Ross. </author> <title> Fast Algorithms for Generating Discrete Random Variates with Changing Distributions, </title> <journal> ACM Transactions on Modeling and Computer Simulation, </journal> <volume> 3(1) </volume> <pages> 1-19, </pages> <year> 1993. </year>
Reference-contexts: Each generation requires one call to a random number generator that provides a uniform random integer in the range [0; P Recently, Rajasekaran and Ross <ref> [21] </ref> and Greenberg and Vitter [12] developed different algorithms for the dynamic case that do generation and update in constant expected time for various restricted classes of updates.
Reference: [22] <author> R. E. Tarjan. </author> <title> Amortized Computational Complexity, </title> <journal> SIAM Journal on Algebraic and Discrete Methods, </journal> <volume> 6(2): </volume> <pages> 306-318, </pages> <year> 1985. </year>
Reference-contexts: All the nodes on the two paths should revise their weights to reflect the changes. To facilitate the amortized analysis, we use an accounting method <ref> [22] </ref>, where we charge C ` units of cost to a level` node w that changes its parent.
Reference: [23] <author> P. van Emde Boas, R. Kaas, and E. Zijlstra. </author> <title> Design and Implementation of an Efficient Priority Queue. </title> <journal> Math. Systems Theory, </journal> <volume> 10 </volume> <pages> 99-127, </pages> <year> 1977. </year>
Reference-contexts: in O (log n= log log n) time when some of the time bounds are allowed to be amortized [8], in O ( p amortized expected time when randomization is allowed [8], and in O (log log u) time when the element values are integers in the universe [1; u] <ref> [23] </ref>. The *-heap we construct supports the more relaxed query *-findmax, in which the element returned must have a value within an * relative factor of the maximum element value. <p> For each interval, we keep a separate priority queue of van Emde Boas et al. <ref> [23] </ref>. In addition to the data structure described above, we keep record of P (1 + *) j , where the summation is over the non-empty ranges R j .
Reference: [24] <author> J. S. Vitter and W.-C. Ni. </author> <title> Dynamic Generation of Discrete Random Variates, </title> <institution> Brown University Technical Report CS-92-36, </institution> <month> August </month> <year> 1992. </year>
Reference: [25] <author> A. J. Walker. </author> <title> New Fast Method for Generating Discrete Random Numbers with Arbitrary Distributions, </title> <journal> Electronic Letters, </journal> <volume> 10(8) </volume> <pages> 127-128, </pages> <year> 1974. </year>
Reference-contexts: 1 Introduction The generation of random variates based on arbitrary finite, discrete distributions has long been a key component of many computer simulations [1],[7], [14], <ref> [25] </ref>. <p> In the static case, when the N weights are fixed, we can utilize the clever optimal algorithm by Walker, commonly called the alias method ; the time to generate a random variate is constant and the preprocessing cost is O (N ) [14], <ref> [25] </ref>. In this paper we consider the problem in the important and more challenging dynamic case, in which the weights of the elements can be updated dynamically. The relevant measures of efficiency are the generation time and the update time.
Reference: [26] <author> C. K. Wong and M. C. Easton. </author> <title> An Efficient Method for Weighted Sampling without Replacement, </title> <journal> SIAM Journal on Computing, </journal> <volume> 9(1) </volume> <pages> 111-114, </pages> <year> 1980. </year> <title> 24 A PREPROCESSING </title>
Reference-contexts: We can rerun Walker's algorithm each time a weight is updated, but the update cost O (N ) is too high. Up until recently, the best known algorithm for the dynamic problem was the binary tree-based scheme developed by Wong and Easton <ref> [26] </ref>, whose generation and update times are both O (log N ). <p> The dynamic scheme of Wong and Easton <ref> [26] </ref> uses O (log N ) time per generation, but it requires only one call to a random number generator that outputs a uniform number in the range [0; 1iN w i ). <p> We choose between the significant intervals and the non-significant intervals with the appropriate probabilities. Step 2. If the non-significant intervals are chosen, then we generate a random variate from the elements in the non-significant intervals by applying any linear time algorithm (e.g., <ref> [26] </ref>), and halt. Step 3. If the significant intervals are chosen, we choose one of them, say, I t , with the appropriate probability, and proceed to the next step. Step 4. <p> We first give a brief description of the lookup table technique and then show how to incorporate it with our algorithms. A simple approach for the basic generation problem, already used in <ref> [26] </ref>, is based on maintaining an array of prefix sums W i of the weights w i ; that is, W i = P 1ji w j , for each 1 i N .
References-found: 26

