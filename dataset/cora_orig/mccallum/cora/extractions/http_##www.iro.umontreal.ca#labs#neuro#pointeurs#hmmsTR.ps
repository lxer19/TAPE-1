URL: http://www.iro.umontreal.ca/labs/neuro/pointeurs/hmmsTR.ps
Refering-URL: http://www.iro.umontreal.ca/labs/neuro/other.html
Root-URL: http://www.iro.umontreal.ca
Title: Markovian Models for Sequential Data  
Author: Yoshua Bengio 
Keyword: hidden Markov models, learning algorithms, artificial neural networks, weighted transducers, state space models, input-output hidden Markov models, Markov switching models.  
Address: Montreal, Montreal, Qc H3C-3J7, Canada  Montreal  
Affiliation: Dept. Informatique et Recherche Operationnelle Universite de  Departement d'Informatique et Recherche Operationnelle, Universite de  
Pubnum: Technical Report #1049,  
Email: bengioy@iro.umontreal.ca  
Date: October 22, 1996  
Abstract: Hidden Markov Models (HMMs) are statistical models of sequential data that have been used successfully in many applications, especially for speech recognition. We first summarize the basics of HMMs, and then review several recent related learning algorithms and extensions of HMMs, including hybrids of HMMs with artificial neural networks, Input-Output HMMs, weighted transducers, variable-length Markov models and Markov switching state-space models. Finally, we discuss some of the challenges of future research in this area. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Bourlard and N. Morgan, </author> <title> Connectionist Speech Recognition. A Hybrid Approach, </title> <booktitle> vol. 247 of The Kluwer international series in engineering and computer science. </booktitle> <address> Boston: </address> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: The focus of this paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks <ref> [1, 2] </ref>, Input-Output HMMs [3, 4, 5, 6], weighted transducers [7, 8, 9], variable-length Markov models [10, 11], Markov switching models [12] and switching state-space models [13, 14]. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. <p> The models proposed by Bourlard et al. rely on a probabilistic interpretation of the ANN outputs <ref> [67, 68, 1, 80] </ref>. The ANN is trained to estimate posterior probabilities of HMM states, given a context of observation vectors, P (q t jy tk ; : : : ; y t1 ; y t ; y t+1 ; y t+k ), centered on the current time step. <p> For each time step, the ANN is supervised with a target value of 1 for the correct state and a target value of 0 for the other states. This procedure has been found to converge and yield speech recognition performance at the level of state-of-the-art systems <ref> [1, 80] </ref>. Bourlard et al. draw links between this procedure and the EM algorithm; however, this procedure does not optimize a well-defined criterion during training: training is based on the local targets provided by the constrained Viterbi alignment algorithm.
Reference: [2] <author> Y. Bengio, </author> <title> Neural Networks for Speech and Sequence Processing. </title> <publisher> International Thomson Computer Press, </publisher> <year> 1996. </year>
Reference-contexts: The focus of this paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks <ref> [1, 2] </ref>, Input-Output HMMs [3, 4, 5, 6], weighted transducers [7, 8, 9], variable-length Markov models [10, 11], Markov switching models [12] and switching state-space models [13, 14]. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. <p> Since ANNs were successful at classifying individual phonemes, initial research focused on using the dynamic programming tools of HMMs in order to go from the recognition of individual phonemes (or other local classification) to the recognition of whole sequences <ref> [66, 67, 68, 69, 70, 71, 72, 73, 74, 2] </ref>. <p> In some cases <ref> [75, 72, 2, 73, 74] </ref>, the ANN outputs are not interpreted as probabilities, but are rather used as scores and generally combined with a dynamic programming algorithm akin to the Viterbi algorithm to perform the alignment and segmentation. <p> Bourlard et al. draw links between this procedure and the EM algorithm; however, this procedure does not optimize a well-defined criterion during training: training is based on the local targets provided by the constrained Viterbi alignment algorithm. Another approach <ref> [2, 81, 30] </ref> uses the ANN to transform the observation sequence into a form that is easier to model for an HMM that has simple (but continuous) emission models (e.g., Gaussian or Gaussian mixture). The ANN is used as a non-linear trainable pre-processor or feature extractor for the HMM. <p> This model was introduced in [81] for phoneme recognition. It is also described in <ref> [2] </ref>, and was extended to character recognition in [30]. The ANN transforms an input sequence u T 1 into an intermediate observation sequence y T 1 , with a parameterized function y T 1 = f (u T 1 ; ). <p> However, it has been shown experimentally with the above ANN/HMM hybrid how training the ANN jointly with the HMM improves performance on a speech recognition problem <ref> [81, 2] </ref>, bringing down the error rate on a plosive recognition task from 19% to 14%. <p> Furthermore, these ANNs can take into account a wide context (not just the observations at time t but also neighboring observations in the sequence), without violating the Markov assumptions, because there are no independence assumptions on the conditioning input variable. The ANN can even be recurrent <ref> [65, 2] </ref> (to take into account arbitrarily distant past contexts). * When the output sequence is discrete (e.g., a sequence of phonemes), the transition probabilities and emission probabilities are generally better matched than in HMMs, thus reducing a problem of imbalance (section 3.6) observed in HMMs for speech recognition.
Reference: [3] <author> L. Chrisman, </author> <title> "Reinforcement learning with perceptual aliasing: The perceptual distinctions approach," </title> <booktitle> in Proceedings of the 12th National Conference on Artificial Intelligence, </booktitle> <pages> pp. 183-188, </pages> <year> 1992. </year>
Reference-contexts: The focus of this paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks [1, 2], Input-Output HMMs <ref> [3, 4, 5, 6] </ref>, weighted transducers [7, 8, 9], variable-length Markov models [10, 11], Markov switching models [12] and switching state-space models [13, 14]. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. <p> In the literature on learning algorithms [4, 5, 6], IOHMMs have been proposed for sequence processing tasks, with complex emission and transition models based on ANNs. In the control and reinforcement learning literature, similar models have been called Partially Observable Markov Decision Processes <ref> [84, 85, 3] </ref>. In this case, the objective is not to model an output sequence given an input sequence, but rather, to find the input sequence (in fact a sequence of actions) which 15 Input-Output Hidden Markov Model.
Reference: [4] <author> T. W. Cacciatore and S. J. Nowlan, </author> <title> "Mixtures of controllers for jump linear and non-linear plants," </title> <booktitle> in Advances in Neural Information Processing Systems 6 (J. </booktitle> <editor> Cowan, G. Tesauro, and J. Alspector, eds.), </editor> <address> (San Mateo, CA), </address> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: The focus of this paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks [1, 2], Input-Output HMMs <ref> [3, 4, 5, 6] </ref>, weighted transducers [7, 8, 9], variable-length Markov models [10, 11], Markov switching models [12] and switching state-space models [13, 14]. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. <p> In the literature on learning algorithms <ref> [4, 5, 6] </ref>, IOHMMs have been proposed for sequence processing tasks, with complex emission and transition models based on ANNs. In the control and reinforcement learning literature, similar models have been called Partially Observable Markov Decision Processes [84, 85, 3].
Reference: [5] <author> Y. Bengio and P. Frasconi, </author> <title> "An input/output HMM architecture," </title> <booktitle> in Advances in Neural Information Processing Systems 7 (G. </booktitle> <editor> Tesauro, D. Touretzky, and T. Leen, </editor> <booktitle> eds.), </booktitle> <pages> pp. 427-434, </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year> <month> 24 </month>
Reference-contexts: The focus of this paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks [1, 2], Input-Output HMMs <ref> [3, 4, 5, 6] </ref>, weighted transducers [7, 8, 9], variable-length Markov models [10, 11], Markov switching models [12] and switching state-space models [13, 14]. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. <p> Another way to integrate ANNs with HMMs in a mathematically clear way is based on the idea of Input-Output HMMs described in the next section. 5 Input-Output HMMs Input-Output Hidden Markov Models (IOHMMs) <ref> [5] </ref> (or Conditional HMMs) are simply HMMs for which the emission and transition distributions are conditional on another sequence, called the input sequence, and noted x L 1 . <p> In the literature on learning algorithms <ref> [4, 5, 6] </ref>, IOHMMs have been proposed for sequence processing tasks, with complex emission and transition models based on ANNs. In the control and reinforcement learning literature, similar models have been called Partially Observable Markov Decision Processes [84, 85, 3].
Reference: [6] <author> M. Meila and M. Jordan, </author> <title> "Learning fine motion by markov mixtures of experts," </title> <booktitle> in Ad--vances in Neural Information Processing Systems 8 (M. </booktitle> <editor> Mozer, D. Touretzky, and M. Per-rone, eds.), </editor> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: The focus of this paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks [1, 2], Input-Output HMMs <ref> [3, 4, 5, 6] </ref>, weighted transducers [7, 8, 9], variable-length Markov models [10, 11], Markov switching models [12] and switching state-space models [13, 14]. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. <p> In the literature on learning algorithms <ref> [4, 5, 6] </ref>, IOHMMs have been proposed for sequence processing tasks, with complex emission and transition models based on ANNs. In the control and reinforcement learning literature, similar models have been called Partially Observable Markov Decision Processes [84, 85, 3].
Reference: [7] <author> M. Riley and F. Pereira, </author> <title> "Weighted-finite-automata tools with applications to speech and language processing," </title> <type> Tech. Rep. Technical Memorandum 11222-931130-28TM, </type> <institution> AT&T Bell Laboratories, </institution> <year> 1994. </year>
Reference-contexts: The focus of this paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks [1, 2], Input-Output HMMs [3, 4, 5, 6], weighted transducers <ref> [7, 8, 9] </ref>, variable-length Markov models [10, 11], Markov switching models [12] and switching state-space models [13, 14]. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. <p> For example, in speech recognition HMMs, different sequences of speech units (corresponding to a subset of the possible state sequences) are associated with different weights (in fact the joint probability of these state sequences and the acoustic sequence). More generally, weighted acceptors and transducers <ref> [7, 8, 9] </ref> can be used to assign a weight to a sequence (or a pair of input/output sequences). <p> Intermediate transducers represent the mapping between sequences of speech units and sequences of words, e.g., P (u N 1 jw L A generic composition operation <ref> [7, 8, 9] </ref> allows to combine a cascade of transducers and acceptors, e.g., the joint distribution over acoustics, phonetic speech units, and words (with 20 conditional independence between the different levels), P (w L 1 ; y T 1 ju N 1 jw L 1 ); integrates different levels of knowledge
Reference: [8] <author> F. Pereira, M. Riley, and R. Sproat, </author> <title> "Weighted rational transductions and their application to human language processing," </title> <booktitle> in ARPA Natural Language Processing Workshop, </booktitle> <year> 1994. </year>
Reference-contexts: The focus of this paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks [1, 2], Input-Output HMMs [3, 4, 5, 6], weighted transducers <ref> [7, 8, 9] </ref>, variable-length Markov models [10, 11], Markov switching models [12] and switching state-space models [13, 14]. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. <p> For example, in speech recognition HMMs, different sequences of speech units (corresponding to a subset of the possible state sequences) are associated with different weights (in fact the joint probability of these state sequences and the acoustic sequence). More generally, weighted acceptors and transducers <ref> [7, 8, 9] </ref> can be used to assign a weight to a sequence (or a pair of input/output sequences). <p> Intermediate transducers represent the mapping between sequences of speech units and sequences of words, e.g., P (u N 1 jw L A generic composition operation <ref> [7, 8, 9] </ref> allows to combine a cascade of transducers and acceptors, e.g., the joint distribution over acoustics, phonetic speech units, and words (with 20 conditional independence between the different levels), P (w L 1 ; y T 1 ju N 1 jw L 1 ); integrates different levels of knowledge
Reference: [9] <author> M. Mohri, </author> <title> "Finite-state transducers in language and speech processing," </title> <journal> Computational Linguistics, </journal> <volume> vol. 20, no. 1, </volume> <pages> pp. 1-33, </pages> <year> 1996. </year>
Reference-contexts: The focus of this paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks [1, 2], Input-Output HMMs [3, 4, 5, 6], weighted transducers <ref> [7, 8, 9] </ref>, variable-length Markov models [10, 11], Markov switching models [12] and switching state-space models [13, 14]. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. <p> For example, in speech recognition HMMs, different sequences of speech units (corresponding to a subset of the possible state sequences) are associated with different weights (in fact the joint probability of these state sequences and the acoustic sequence). More generally, weighted acceptors and transducers <ref> [7, 8, 9] </ref> can be used to assign a weight to a sequence (or a pair of input/output sequences). <p> Intermediate transducers represent the mapping between sequences of speech units and sequences of words, e.g., P (u N 1 jw L A generic composition operation <ref> [7, 8, 9] </ref> allows to combine a cascade of transducers and acceptors, e.g., the joint distribution over acoustics, phonetic speech units, and words (with 20 conditional independence between the different levels), P (w L 1 ; y T 1 ju N 1 jw L 1 ); integrates different levels of knowledge
Reference: [10] <author> D. Ron, Y. Singer, and N. Tishby, </author> <title> "The power of amnesia," </title> <booktitle> in Advances in Neural Information Processing Systems 6 (J. </booktitle> <editor> Cowan, G. Tesauro, and J. Alspector, eds.), </editor> <address> (San Mateo, CA), </address> <pages> pp. 176-183, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: The focus of this paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks [1, 2], Input-Output HMMs [3, 4, 5, 6], weighted transducers [7, 8, 9], variable-length Markov models <ref> [10, 11] </ref>, Markov switching models [12] and switching state-space models [13, 14]. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. <p> A Variable Length Markov Model <ref> [10] </ref> is a probability model over strings in which the state variable is not hidden: its value is a deterministic function of the past observation sequence. However, this function uses more or less of the past sequence for different contexts, hence the name, variable length Markov model. <p> A constructive, on-line (one-pass), learning algorithm was proposed to adaptively grow this tree <ref> [10] </ref>. Each node of the tree at depth d represents a particular value y t1 td of the context of depth d, and may be associated with a distribution over the next symbol y t .
Reference: [11] <author> Y. Singer, </author> <title> "Adaptive mixtures of probabilistic transducers," </title> <booktitle> in Advances in Neural Information Processing Systems 8 (M. </booktitle> <editor> Mozer, D. Touretzky, and M. Perrone, eds.), </editor> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: The focus of this paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks [1, 2], Input-Output HMMs [3, 4, 5, 6], weighted transducers [7, 8, 9], variable-length Markov models <ref> [10, 11] </ref>, Markov switching models [12] and switching state-space models [13, 14]. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. <p> Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition [24, 25, 26, 27, 28, 29, 30], pattern recognition in molecular biology [31, 32], and fault-detection [33]. The variants and extensions of HMMs discussed here also include language models <ref> [34, 35, 11] </ref>, econometrics [12, 13, 36], time series, and signal processing. The learning problem for the type of algorithms discussed here can be framed as follows. <p> The potential branching factor of the tree is equal to the size of the alphabet for y t , but most nodes may have much fewer children. More recently, an extension of this idea to probabilistic but synchronous transducers was proposed <ref> [11] </ref>. <p> Using these posteriors, a mixture over a very large family of such trees can be formed, whose generalization performance tracks that of the best tree in that family <ref> [11] </ref>. <p> Using these posteriors, a mixture over a very large family of such trees can be formed, whose generalization performance tracks that of the best tree in that family [11]. These algorithms were used in language modeling <ref> [34, 11] </ref> and handwritten character recognition [35]. 7 State Space Models In this section we draw a few connections between HMMs (which traditionally are based on a discrete hidden state) and state space models, which can be seen as HMMs with a continuous vector state variable.
Reference: [12] <author> J. Hamilton, </author> <title> "A new approach to the economic analysis of non-stationary time series and the business cycle," </title> <journal> Econometrica, </journal> <volume> vol. 57, </volume> <pages> pp. 357-384, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: The focus of this paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks [1, 2], Input-Output HMMs [3, 4, 5, 6], weighted transducers [7, 8, 9], variable-length Markov models [10, 11], Markov switching models <ref> [12] </ref> and switching state-space models [13, 14]. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. <p> The variants and extensions of HMMs discussed here also include language models [34, 35, 11], econometrics <ref> [12, 13, 36] </ref>, time series, and signal processing. The learning problem for the type of algorithms discussed here can be framed as follows. <p> In the following section, we present the EM algorithm which can be used for training both HMMs and synchronous HMMs. 5.1 Markov Switching Models Markov Switching Models have been introduced in the econometrics literature <ref> [87, 88, 89, 12, 13] </ref> for modeling non-stationarities due to abrupt changes of regime in the economy [90, 91, 92, 93, 94, 36]. <p> t = fi q t x t + e t (10) where y t is the observation (or output) variable at time t, e t is a random variable with a zero-mean Gaussian distribution, and x t is a vector of input variables (e.g., past values of y, as in <ref> [12] </ref>, or present and past values of other observed variables). There are different sets of parameters fi q t for the different (discrete) values of the hidden state variable q t .
Reference: [13] <author> R. Shumway and D. Stoffer, </author> <title> "Dynamic linear models with switching," </title> <journal> J. Amer. Stat. Assoc., </journal> <volume> vol. 86, </volume> <pages> pp. 763-769, </pages> <year> 1991. </year>
Reference-contexts: paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks [1, 2], Input-Output HMMs [3, 4, 5, 6], weighted transducers [7, 8, 9], variable-length Markov models [10, 11], Markov switching models [12] and switching state-space models <ref> [13, 14] </ref>. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. The models and the probability distributions that we talk about in this paper are not assumed to represent necessarily the true relations between the variables of interest. <p> The variants and extensions of HMMs discussed here also include language models [34, 35, 11], econometrics <ref> [12, 13, 36] </ref>, time series, and signal processing. The learning problem for the type of algorithms discussed here can be framed as follows. <p> In the following section, we present the EM algorithm which can be used for training both HMMs and synchronous HMMs. 5.1 Markov Switching Models Markov Switching Models have been introduced in the econometrics literature <ref> [87, 88, 89, 12, 13] </ref> for modeling non-stationarities due to abrupt changes of regime in the economy [90, 91, 92, 93, 94, 36]. <p> See [110] and [14] for a review of such models. Many early models assume that some of the parameters of the distribution are known a-priori, and others <ref> [13] </ref> approximate the EM algorithm with a heuristic, because the E-step would require exponential computations. Others [111, 112] used expensive Monte-Carlo simulations to address this problem. Instead, in [14], a function that is a lower bound on the log likelihood is maximized with a tractable algorithm.
Reference: [14] <author> Z. Ghahramani and G. Hinton, </author> <title> "Switching state-space models," </title> <type> Tech. Rep. Technical Report CRG-TR-91-3, </type> <institution> University of Toronto, </institution> <year> 1996. </year>
Reference-contexts: paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HMMs with artificial neural networks [1, 2], Input-Output HMMs [3, 4, 5, 6], weighted transducers [7, 8, 9], variable-length Markov models [10, 11], Markov switching models [12] and switching state-space models <ref> [13, 14] </ref>. Note that what we call learning here is also called parameter estimation in statistics and system identification in control and engineering. The models and the probability distributions that we talk about in this paper are not assumed to represent necessarily the true relations between the variables of interest. <p> To model both the abrupt and gradual changes in time series, several researchers have in fact proposed hybrids of state space models and discrete-state HMMs (or IOHMMs), also known as state space models with switching, or jump-linear systems. See [110] and <ref> [14] </ref> for a review of such models. Many early models assume that some of the parameters of the distribution are known a-priori, and others [13] approximate the EM algorithm with a heuristic, because the E-step would require exponential computations. Others [111, 112] used expensive Monte-Carlo simulations to address this problem. <p> Many early models assume that some of the parameters of the distribution are known a-priori, and others [13] approximate the EM algorithm with a heuristic, because the E-step would require exponential computations. Others [111, 112] used expensive Monte-Carlo simulations to address this problem. Instead, in <ref> [14] </ref>, a function that is a lower bound on the log likelihood is maximized with a tractable algorithm. This paper uses the idea of variational approximation that has already been proposed in [113] for other intractable models. <p> To address such problems, [113] recently introduced a promising methodology of variational approximation based on tractable substructures in the Bayesian network. This idea was applied to hybrids of continuous and discrete state variables <ref> [14] </ref>. * Transducers offer a generalization of Markovian models that can be applied to a wide range of learning tasks in which complex a priori structural knowledge about the task is to be smoothly integrated with learning from examples.
Reference: [15] <author> L. R. Rabiner, </author> <title> "A tutorial on hidden Markov models and selected applications in speech recognition," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 77, no. 2, </volume> <pages> pp. 257-286, </pages> <year> 1989. </year>
Reference-contexts: The most common of these models are the HMMs, which are best known for their contribution to advances in automatic speech recognition in the last two decades. A good tutorial on HMMs in the context of speech recognition is <ref> [15] </ref>. Algorithms for estimating the parameters of HMMs have been developed in the 60's and 70's [16, 17, 18]. The application of HMMs to speech was independently proposed by [19] and [20], and popularized by [21], [22], and [15]. <p> A good tutorial on HMMs in the context of speech recognition is <ref> [15] </ref>. Algorithms for estimating the parameters of HMMs have been developed in the 60's and 70's [16, 17, 18]. The application of HMMs to speech was independently proposed by [19] and [20], and popularized by [21], [22], and [15]. An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23].
Reference: [16] <author> L. E. Baum and J. Eagon, </author> <title> "An inequality with applications to statistical prediction for functions of Markov processes and to a model of ecology," </title> <journal> Bull. Amer. Math. Soc., </journal> <volume> vol. 73, </volume> <pages> pp. 360-363, </pages> <year> 1967. </year>
Reference-contexts: A good tutorial on HMMs in the context of speech recognition is [15]. Algorithms for estimating the parameters of HMMs have been developed in the 60's and 70's <ref> [16, 17, 18] </ref>. The application of HMMs to speech was independently proposed by [19] and [20], and popularized by [21], [22], and [15]. An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23]. <p> question and restrict the discussion to the general use of prior knowledge in the topology of speech recognition HMMs, and to the numerical free parameters, i.e., those that are chosen numerically with a learning or parameter estimation algorithm. 2.2.4 Parameter Estimation For all the above distributions, the EM (Expectation-Maximization) algorithm <ref> [47, 16, 17, 18] </ref> can be used to estimate the parameters of the HMM in order to maximize the likelihood function l () = P (Dj) = Q T p 1 (p)j) over the set training sequences D (indiced by the letter p). <p> state-space models (in which the hidden state variable is continuous) and hybrids with both discrete and continuous state variables, which have been used in similar time-series modeling applications. 5.2 EM for HMMs and IOHMMs In this section we will sketch the application of the EM (Expectation-Maximization) algorithm [47] to HMMs <ref> [16, 17, 18] </ref> and IOHMMs. The papers by Baum et al. present a special case of the EM algorithm applied to discrete emissions HMMs, but were written before the general version of the EM algorithm was described [47]. <p> i;t ; z j;t1 jx T 1 ; k ]: Let us now see how these posterior probabilities, which we will note P (q t jx T 1 ; y T 1 ; y T to lighten the notation, can be computed with the Baum-Welch forward and backward recur sions <ref> [16, 17, 18] </ref>. 18 We have already introduced the forward recursion (equation 5), which yields P (y t 1 ; q t jx T recursively.
Reference: [17] <author> L. E. Baum, T. Petrie, G. Soules, and N. Weiss, </author> <title> "A maximization technique occuring in the statistical analysis of probabilistic functions of Markov chains," </title> <journal> Ann. Math. Statistic., </journal> <volume> vol. 41, </volume> <pages> pp. 164-171, </pages> <year> 1970. </year>
Reference-contexts: A good tutorial on HMMs in the context of speech recognition is [15]. Algorithms for estimating the parameters of HMMs have been developed in the 60's and 70's <ref> [16, 17, 18] </ref>. The application of HMMs to speech was independently proposed by [19] and [20], and popularized by [21], [22], and [15]. An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23]. <p> question and restrict the discussion to the general use of prior knowledge in the topology of speech recognition HMMs, and to the numerical free parameters, i.e., those that are chosen numerically with a learning or parameter estimation algorithm. 2.2.4 Parameter Estimation For all the above distributions, the EM (Expectation-Maximization) algorithm <ref> [47, 16, 17, 18] </ref> can be used to estimate the parameters of the HMM in order to maximize the likelihood function l () = P (Dj) = Q T p 1 (p)j) over the set training sequences D (indiced by the letter p). <p> state-space models (in which the hidden state variable is continuous) and hybrids with both discrete and continuous state variables, which have been used in similar time-series modeling applications. 5.2 EM for HMMs and IOHMMs In this section we will sketch the application of the EM (Expectation-Maximization) algorithm [47] to HMMs <ref> [16, 17, 18] </ref> and IOHMMs. The papers by Baum et al. present a special case of the EM algorithm applied to discrete emissions HMMs, but were written before the general version of the EM algorithm was described [47]. <p> i;t ; z j;t1 jx T 1 ; k ]: Let us now see how these posterior probabilities, which we will note P (q t jx T 1 ; y T 1 ; y T to lighten the notation, can be computed with the Baum-Welch forward and backward recur sions <ref> [16, 17, 18] </ref>. 18 We have already introduced the forward recursion (equation 5), which yields P (y t 1 ; q t jx T recursively.
Reference: [18] <author> L. E. Baum, </author> <title> "An inequality and associated maximization technique in statistical estimation for probabilistic functions of a Markov process," </title> <journal> Inequalities, </journal> <volume> vol. 3, </volume> <pages> pp. 1-8, </pages> <year> 1972. </year>
Reference-contexts: A good tutorial on HMMs in the context of speech recognition is [15]. Algorithms for estimating the parameters of HMMs have been developed in the 60's and 70's <ref> [16, 17, 18] </ref>. The application of HMMs to speech was independently proposed by [19] and [20], and popularized by [21], [22], and [15]. An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23]. <p> question and restrict the discussion to the general use of prior knowledge in the topology of speech recognition HMMs, and to the numerical free parameters, i.e., those that are chosen numerically with a learning or parameter estimation algorithm. 2.2.4 Parameter Estimation For all the above distributions, the EM (Expectation-Maximization) algorithm <ref> [47, 16, 17, 18] </ref> can be used to estimate the parameters of the HMM in order to maximize the likelihood function l () = P (Dj) = Q T p 1 (p)j) over the set training sequences D (indiced by the letter p). <p> state-space models (in which the hidden state variable is continuous) and hybrids with both discrete and continuous state variables, which have been used in similar time-series modeling applications. 5.2 EM for HMMs and IOHMMs In this section we will sketch the application of the EM (Expectation-Maximization) algorithm [47] to HMMs <ref> [16, 17, 18] </ref> and IOHMMs. The papers by Baum et al. present a special case of the EM algorithm applied to discrete emissions HMMs, but were written before the general version of the EM algorithm was described [47]. <p> i;t ; z j;t1 jx T 1 ; k ]: Let us now see how these posterior probabilities, which we will note P (q t jx T 1 ; y T 1 ; y T to lighten the notation, can be computed with the Baum-Welch forward and backward recur sions <ref> [16, 17, 18] </ref>. 18 We have already introduced the forward recursion (equation 5), which yields P (y t 1 ; q t jx T recursively.
Reference: [19] <author> J. Baker, </author> <title> "Stochastic modeling for automatic speech understanding," in Speech Recognition (D. Reddy, </title> <publisher> ed.), </publisher> <pages> pp. 521-542, </pages> <address> New York: </address> <publisher> Academic Press, </publisher> <year> 1975. </year>
Reference-contexts: A good tutorial on HMMs in the context of speech recognition is [15]. Algorithms for estimating the parameters of HMMs have been developed in the 60's and 70's [16, 17, 18]. The application of HMMs to speech was independently proposed by <ref> [19] </ref> and [20], and popularized by [21], [22], and [15]. An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23].
Reference: [20] <author> F. Jelinek, </author> <title> "Continuous speech recognition by statistical methods," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 64, </volume> <pages> pp. 532-556, </pages> <year> 1976. </year>
Reference-contexts: A good tutorial on HMMs in the context of speech recognition is [15]. Algorithms for estimating the parameters of HMMs have been developed in the 60's and 70's [16, 17, 18]. The application of HMMs to speech was independently proposed by [19] and <ref> [20] </ref>, and popularized by [21], [22], and [15]. An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23].
Reference: [21] <author> S. Levinson, L. Rabiner, and M. Sondhi, </author> <title> "An introduction to the application of the theory of probabilistic functions of a Markov process to automatic speech recognition," </title> <journal> Bell System Technical Journal, </journal> <volume> vol. 64, no. 4, </volume> <pages> pp. 1035-1074, </pages> <year> 1983. </year>
Reference-contexts: A good tutorial on HMMs in the context of speech recognition is [15]. Algorithms for estimating the parameters of HMMs have been developed in the 60's and 70's [16, 17, 18]. The application of HMMs to speech was independently proposed by [19] and [20], and popularized by <ref> [21] </ref>, [22], and [15]. An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23].
Reference: [22] <author> L. Rabiner and B. Juang, </author> <title> "An introduction to hidden Markov models," </title> <journal> IEEE ASSP Magazine, </journal> <pages> pp. 257-285, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: A good tutorial on HMMs in the context of speech recognition is [15]. Algorithms for estimating the parameters of HMMs have been developed in the 60's and 70's [16, 17, 18]. The application of HMMs to speech was independently proposed by [19] and [20], and popularized by [21], <ref> [22] </ref>, and [15]. An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23].
Reference: [23] <author> A. Waibel and K. Lee, </author> <title> Readings in Speech Recognition. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: The application of HMMs to speech was independently proposed by [19] and [20], and popularized by [21], [22], and [15]. An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers <ref> [23] </ref>. Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition [24, 25, 26, 27, 28, 29, 30], pattern recognition in molecular biology [31, 32], and fault-detection [33].
Reference: [24] <author> R. Nag, K. Wong, and F. Fallside, </author> <title> "Script recognition using hidden Markov models," </title> <booktitle> in International Conference on Acoustics, Speech and Signal Processing, (Tokyo), </booktitle> <pages> pp. 2071-2074, </pages> <year> 1986. </year>
Reference-contexts: An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23]. Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition <ref> [24, 25, 26, 27, 28, 29, 30] </ref>, pattern recognition in molecular biology [31, 32], and fault-detection [33]. The variants and extensions of HMMs discussed here also include language models [34, 35, 11], econometrics [12, 13, 36], time series, and signal processing.
Reference: [25] <author> A. Kundu and L. Bahl, </author> <title> "Recognition of handwritten script: a hidden Markov model based approach," </title> <booktitle> in International Conference on Acoustics, Speech and Signal Processing, </booktitle> <address> (New-York, NY), </address> <pages> pp. 928-931, </pages> <year> 1988. </year> <month> 25 </month>
Reference-contexts: An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23]. Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition <ref> [24, 25, 26, 27, 28, 29, 30] </ref>, pattern recognition in molecular biology [31, 32], and fault-detection [33]. The variants and extensions of HMMs discussed here also include language models [34, 35, 11], econometrics [12, 13, 36], time series, and signal processing.
Reference: [26] <author> O. Matan, C. Burges, Y. LeCun, and J. Denker, </author> <title> "Multi-digit recognition using a space displacement neural network," </title> <booktitle> in Advances in Neural Information Processing Systems 4 (J. </booktitle> <editor> Moody, S. Hanson, and R. Lipmann, eds.), </editor> <address> (San Mateo CA), </address> <pages> pp. 488-495, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference-contexts: An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23]. Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition <ref> [24, 25, 26, 27, 28, 29, 30] </ref>, pattern recognition in molecular biology [31, 32], and fault-detection [33]. The variants and extensions of HMMs discussed here also include language models [34, 35, 11], econometrics [12, 13, 36], time series, and signal processing.
Reference: [27] <author> J. Ha, S. Oh, J. Kim, and Y. Kwon, </author> <title> "Unconstrained handwritten word recognition with interconnected hidden Markov models," </title> <booktitle> in Third International Workshop on Frontiers in Handwriting Recognition, (Buffalo), </booktitle> <pages> pp. 455-460, </pages> <address> IAPR, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23]. Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition <ref> [24, 25, 26, 27, 28, 29, 30] </ref>, pattern recognition in molecular biology [31, 32], and fault-detection [33]. The variants and extensions of HMMs discussed here also include language models [34, 35, 11], econometrics [12, 13, 36], time series, and signal processing.
Reference: [28] <author> M. Schenkel, H. Weissman, I. Guyon, C. Nohl, and D. Henderson, </author> <title> "Recognition-based segmentation of on-line hand-printed words," </title> <booktitle> in Advances in Neural Information Processing Systems 5 (S. </booktitle> <editor> J. Hanson, J. D. Cowan, and C. L. Giles, eds.), </editor> <address> (Denver, </address> <publisher> CO), </publisher> <pages> pp. 723-730, </pages> <year> 1993. </year>
Reference-contexts: An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23]. Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition <ref> [24, 25, 26, 27, 28, 29, 30] </ref>, pattern recognition in molecular biology [31, 32], and fault-detection [33]. The variants and extensions of HMMs discussed here also include language models [34, 35, 11], econometrics [12, 13, 36], time series, and signal processing.
Reference: [29] <author> M. Schenkel, I. Guyon, and D. Henderson, </author> <title> "On-line cursive script recognition using time delay neural networks and hidden Markov models," </title> <booktitle> Machine Vision and Applications, </booktitle> <pages> pp. 215-223, </pages> <year> 1995. </year>
Reference-contexts: An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23]. Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition <ref> [24, 25, 26, 27, 28, 29, 30] </ref>, pattern recognition in molecular biology [31, 32], and fault-detection [33]. The variants and extensions of HMMs discussed here also include language models [34, 35, 11], econometrics [12, 13, 36], time series, and signal processing.
Reference: [30] <author> Y. Bengio, Y. LeCun, C. Nohl, and C. Burges, "Lerec: </author> <title> A nn/hmm hybrid for on-line handwriting recognition," </title> <journal> Neural Computation, </journal> <volume> vol. 7, no. 5, </volume> <pages> pp. 1289-1303, </pages> <year> 1995. </year>
Reference-contexts: An early review of alternative methods based on HMMs or related to HMMs, also for speech recognition, can be found in the collection of papers [23]. Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition <ref> [24, 25, 26, 27, 28, 29, 30] </ref>, pattern recognition in molecular biology [31, 32], and fault-detection [33]. The variants and extensions of HMMs discussed here also include language models [34, 35, 11], econometrics [12, 13, 36], time series, and signal processing. <p> In section 5 we discuss the recently proposed asynchronous Input-Output HMMs, which could significantly alleviate this problem. Other solutions are heuristics in which the logarithms of transition probabilities and emission probabilities are linearly weighed differently in order to correct this problem. This was used for example in <ref> [30] </ref>. 4 Integrating Artificial Neural Networks and HMMs Artificial Neural Networks (ANNs) or connectionist models have been successfully used in several pattern recognition and sequential data processing problems. Multi-layered ANNs [65] can 13 represent a non-linear regression or classification model. <p> Bourlard et al. draw links between this procedure and the EM algorithm; however, this procedure does not optimize a well-defined criterion during training: training is based on the local targets provided by the constrained Viterbi alignment algorithm. Another approach <ref> [2, 81, 30] </ref> uses the ANN to transform the observation sequence into a form that is easier to model for an HMM that has simple (but continuous) emission models (e.g., Gaussian or Gaussian mixture). The ANN is used as a non-linear trainable pre-processor or feature extractor for the HMM. <p> This model was introduced in [81] for phoneme recognition. It is also described in [2], and was extended to character recognition in <ref> [30] </ref>. The ANN transforms an input sequence u T 1 into an intermediate observation sequence y T 1 , with a parameterized function y T 1 = f (u T 1 ; ). <p> It has later been shown how using joint training with respect to a discriminant criterion on a handwriting recognition problem <ref> [30] </ref> reduced the character error rate from 12.4% down to 8.2% (no dictionary), or from 2% down to 1.4% (with a 350-word dictionary).
Reference: [31] <author> P. Baldi, Y. Chauvin, T. Hunkapiller, and M. McClure, </author> <title> "Hidden markov models of biological primary sequence information," </title> <journal> Proc. Nat. Acad. Sci. (USA), </journal> <volume> vol. 91, no. 3, </volume> <pages> pp. 1059-1063, </pages> <year> 1995. </year>
Reference-contexts: Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition [24, 25, 26, 27, 28, 29, 30], pattern recognition in molecular biology <ref> [31, 32] </ref>, and fault-detection [33]. The variants and extensions of HMMs discussed here also include language models [34, 35, 11], econometrics [12, 13, 36], time series, and signal processing. The learning problem for the type of algorithms discussed here can be framed as follows.
Reference: [32] <author> Y. Chauvin and P. Baldi, </author> <title> "Hidden markov models of the g-protein-coupled receptor family," </title> <journal> Journal of Computational Biology, </journal> <note> vol. to appear, </note> <year> 1995. </year>
Reference-contexts: Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition [24, 25, 26, 27, 28, 29, 30], pattern recognition in molecular biology <ref> [31, 32] </ref>, and fault-detection [33]. The variants and extensions of HMMs discussed here also include language models [34, 35, 11], econometrics [12, 13, 36], time series, and signal processing. The learning problem for the type of algorithms discussed here can be framed as follows.
Reference: [33] <author> P. Smyth, </author> <title> "Hidden markov models for fault detection in dynamic systems," </title> <journal> Pattern Recognition, </journal> <volume> vol. 27, no. 1, </volume> <pages> pp. 149-164, </pages> <year> 1994. </year>
Reference-contexts: Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition [24, 25, 26, 27, 28, 29, 30], pattern recognition in molecular biology [31, 32], and fault-detection <ref> [33] </ref>. The variants and extensions of HMMs discussed here also include language models [34, 35, 11], econometrics [12, 13, 36], time series, and signal processing. The learning problem for the type of algorithms discussed here can be framed as follows.
Reference: [34] <author> I. Guyon and F. Pereira, </author> <title> "Design of a linguistic postprocessor using variable memory length Markov models," </title> <booktitle> in International Conference on Document Analysis and Recognition, </booktitle> <address> (Montreal, Canada), </address> <pages> pp. 454-457, </pages> <publisher> IEEE Computer Society Press, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition [24, 25, 26, 27, 28, 29, 30], pattern recognition in molecular biology [31, 32], and fault-detection [33]. The variants and extensions of HMMs discussed here also include language models <ref> [34, 35, 11] </ref>, econometrics [12, 13, 36], time series, and signal processing. The learning problem for the type of algorithms discussed here can be framed as follows. <p> Using these posteriors, a mixture over a very large family of such trees can be formed, whose generalization performance tracks that of the best tree in that family [11]. These algorithms were used in language modeling <ref> [34, 11] </ref> and handwritten character recognition [35]. 7 State Space Models In this section we draw a few connections between HMMs (which traditionally are based on a discrete hidden state) and state space models, which can be seen as HMMs with a continuous vector state variable.
Reference: [35] <author> I. Guyon, M. Schenkel, and J. Denker, </author> <title> "Overview and synthesis of on-line cursive handwriting recognition techniques," in Hankbook on Optical Character Recognition and Document Image Analysis (P. </title> <editor> Wang and H. Bunke, eds.), </editor> <publisher> World Scientific, </publisher> <year> 1996. </year>
Reference-contexts: Recently, HMMs have been applied to a variety of applications outside of speech recognition, such as handwriting recognition [24, 25, 26, 27, 28, 29, 30], pattern recognition in molecular biology [31, 32], and fault-detection [33]. The variants and extensions of HMMs discussed here also include language models <ref> [34, 35, 11] </ref>, econometrics [12, 13, 36], time series, and signal processing. The learning problem for the type of algorithms discussed here can be framed as follows. <p> Using these posteriors, a mixture over a very large family of such trees can be formed, whose generalization performance tracks that of the best tree in that family [11]. These algorithms were used in language modeling [34, 11] and handwritten character recognition <ref> [35] </ref>. 7 State Space Models In this section we draw a few connections between HMMs (which traditionally are based on a discrete hidden state) and state space models, which can be seen as HMMs with a continuous vector state variable.
Reference: [36] <author> R. Garcia and P. </author> <title> Perron, "An analysis of the real interest rate under regime shift," </title> <journal> The Review of Economics and Statistics, </journal> <year> 1996. </year>
Reference-contexts: The variants and extensions of HMMs discussed here also include language models [34, 35, 11], econometrics <ref> [12, 13, 36] </ref>, time series, and signal processing. The learning problem for the type of algorithms discussed here can be framed as follows. <p> the following section, we present the EM algorithm which can be used for training both HMMs and synchronous HMMs. 5.1 Markov Switching Models Markov Switching Models have been introduced in the econometrics literature [87, 88, 89, 12, 13] for modeling non-stationarities due to abrupt changes of regime in the economy <ref> [90, 91, 92, 93, 94, 36] </ref>. The point of view taken by most econometricians is to extend time-series regression models by the addition of a discrete hidden state variable, which allows changing the parameters of the regression models when the state variable changes its value.
Reference: [37] <author> V. Vapnik, </author> <title> The Nature of Statistical Learning Theory. </title> <publisher> New-York: Springer, </publisher> <year> 1995. </year>
Reference-contexts: For a general mathematical analysis of the learning theory behind learning algorithms such as those discussed here, see for example <ref> [37] </ref>. In some applications there is only one sequence of observations d = y T 1 = fy 1 ; y 2 ; : : : ; y T g, and the new data is simply a continuation of the training data (e.g., time-series prediction, econometry).
Reference: [38] <author> A. </author> <title> Markov, "An example of statistical investigation in the text of `eugene onyegin' illustrating coupling of `tests' in chains," </title> <booktitle> Proceedings of the Academy of Science, St. Petersburg, </booktitle> <volume> vol. 7, </volume> <pages> pp. 153-162, </pages> <year> 1913. </year>
Reference-contexts: We formalize the assumptions that are made, and describe the basic elements of algorithms for HMMs. The algorithms to estimate the parameters for HMMs will be discussed in section 5.2 after we have generalized HMMs to Input-Output or conditional HMMs. A Markov model <ref> [38] </ref> of order k is a probability distribution over a sequence of variables q t 1 = fq 1 ; q 2 ; : : : ; q t g with the following conditional independence property: P (q t jq t1 tk ): Since q t1 tk summarizes all the relevant
Reference: [39] <author> J. Pearl, </author> <title> Probabilistic Reasoning in Intelligent Systems : Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: In this case, the distribution is even simpler, P (q T T Y P (q t jq t1 ); and it is completely specified by the so-called initial state probabilities P (q 1 ) and transition probabilities P (q t jq t1 ). A Bayesian network <ref> [39] </ref> is a graphical representation of conditional independencies between random variables. A Bayesian network for a Markov model of order 2 is shown in Figure 1. The figure shows a directed acyclic graph (DAG), in which each node corresponds to a random variable. <p> See <ref> [39, 40, 41, 42] </ref> for more formal definitions, and pointers to related literature on graphical probabilistic models and inference algorithms for them. Note that all the probabilistic models described in this paper can be cast in the framework of these Bayesian networks.
Reference: [40] <author> D. Spiegelhalter, A. Dawid, S. Lauritzen, and R. Cowell, </author> <title> "Bayesian analysis in expert systems," </title> <journal> Statistical Science, </journal> <volume> vol. 8, </volume> <pages> pp. 219-283, </pages> <year> 1993. </year>
Reference-contexts: See <ref> [39, 40, 41, 42] </ref> for more formal definitions, and pointers to related literature on graphical probabilistic models and inference algorithms for them. Note that all the probabilistic models described in this paper can be cast in the framework of these Bayesian networks.
Reference: [41] <author> W. Buntine, </author> <title> "Operations for learning with graphical models," </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> vol. 2, </volume> <pages> pp. 159-225, </pages> <year> 1994. </year>
Reference-contexts: See <ref> [39, 40, 41, 42] </ref> for more formal definitions, and pointers to related literature on graphical probabilistic models and inference algorithms for them. Note that all the probabilistic models described in this paper can be cast in the framework of these Bayesian networks.
Reference: [42] <author> D. Heckerman, </author> <title> "A tutorial on learning with bayesian networks," </title> <type> Tech. Rep. </type> <institution> TR-95-06, Microsoft Research, ftp://ftp.research.microsoft.com/pub/Tech-Reports/Winter94-95/TR-95-06.PS, </institution> <month> January </month> <year> 1996. </year>
Reference-contexts: See <ref> [39, 40, 41, 42] </ref> for more formal definitions, and pointers to related literature on graphical probabilistic models and inference algorithms for them. Note that all the probabilistic models described in this paper can be cast in the framework of these Bayesian networks.
Reference: [43] <author> R. Gray, </author> <title> "Vector quantization," </title> <journal> IEEE ASSP Magazine, </journal> <pages> pp. 4-29, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: However, in many applications of interest, y t is multivariate and continuous. To obtain a discrete distribution, two approaches are common: 1. perform a vector quantization <ref> [43] </ref> in order to map each vector-valued y t to a discrete value quantize (y t ), and use P (quantize (y t )jq t ) as emission probability, or more generally, 2. use multiple codebooks [44], i.e., split the vector variable y t in sub-vectors y ti which are as
Reference: [44] <author> K.-F. Lee, </author> <title> Automatic Speech Recognition: the development of the SPHINX system. </title> <publisher> Kluwer Academic Publ., </publisher> <year> 1989. </year>
Reference-contexts: To obtain a discrete distribution, two approaches are common: 1. perform a vector quantization [43] in order to map each vector-valued y t to a discrete value quantize (y t ), and use P (quantize (y t )jq t ) as emission probability, or more generally, 2. use multiple codebooks <ref> [44] </ref>, i.e., split the vector variable y t in sub-vectors y ti which are as sumed to be approximately independent, quantize them separately (with maps quantize i (y ti )), and use i P (quantize i (y ti )jq t ) as emission probability. <p> An example of the topology of a part of an HMM for speech recognition is shown in Figure 5. To reduce the number of free parameters and help generalize, designers of speech recognition HMMs use the notion of a speech unit <ref> [44] </ref> (representing a particular linguistic meaning and the associated distribution on acoustic subsequences) which can be re-used (or shared) in many different places of an HMM. The simplest set of speech unit one can think of is simply the phoneme.
Reference: [45] <author> X. Huang, K.-F. Lee, and H.-W. Hon, </author> <title> "On semi-continuous hidden Markov modeling," </title> <booktitle> in International Conference on Acoustics, Speech and Signal Processing, </booktitle> <pages> pp. 689-692, </pages> <year> 1990. </year> <month> 26 </month>
Reference-contexts: A variant of the continuous HMM with Gaussian mixtures is the so-called semi-continuous HMM <ref> [45, 46] </ref>, in which the Gaussians are shared and the parameters specific to each state are only the mixture weights: P (y t jq t = i) = j where the mixture weights play a role that is similar to the multinomial coefficients of the discrete emission HMMs described above.
Reference: [46] <author> X. Huang, Y. Ariki, and M. Jack, </author> <title> Hidden Markov Models for Speech Recognition. </title> <publisher> Edin--burgh: University Press, </publisher> <year> 1990. </year>
Reference-contexts: A variant of the continuous HMM with Gaussian mixtures is the so-called semi-continuous HMM <ref> [45, 46] </ref>, in which the Gaussians are shared and the parameters specific to each state are only the mixture weights: P (y t jq t = i) = j where the mixture weights play a role that is similar to the multinomial coefficients of the discrete emission HMMs described above.
Reference: [47] <author> A. P. Dempster, N. M. Laird, and D. B. Rubin, </author> <title> "Maximum-likelihood from incomplete data via the EM algorithm," </title> <journal> Journal of Royal Statistical Society B, </journal> <volume> vol. 39, </volume> <pages> pp. 1-38, </pages> <year> 1977. </year>
Reference-contexts: question and restrict the discussion to the general use of prior knowledge in the topology of speech recognition HMMs, and to the numerical free parameters, i.e., those that are chosen numerically with a learning or parameter estimation algorithm. 2.2.4 Parameter Estimation For all the above distributions, the EM (Expectation-Maximization) algorithm <ref> [47, 16, 17, 18] </ref> can be used to estimate the parameters of the HMM in order to maximize the likelihood function l () = P (Dj) = Q T p 1 (p)j) over the set training sequences D (indiced by the letter p). <p> 7, we consider state-space models (in which the hidden state variable is continuous) and hybrids with both discrete and continuous state variables, which have been used in similar time-series modeling applications. 5.2 EM for HMMs and IOHMMs In this section we will sketch the application of the EM (Expectation-Maximization) algorithm <ref> [47] </ref> to HMMs [16, 17, 18] and IOHMMs. The papers by Baum et al. present a special case of the EM algorithm applied to discrete emissions HMMs, but were written before the general version of the EM algorithm was described [47]. <p> we will sketch the application of the EM (Expectation-Maximization) algorithm <ref> [47] </ref> to HMMs [16, 17, 18] and IOHMMs. The papers by Baum et al. present a special case of the EM algorithm applied to discrete emissions HMMs, but were written before the general version of the EM algorithm was described [47]. The basic idea of the EM algorithm is to use a hidden variable whose joint distribution with the observed variable is "simpler" than the marginal distribution of the observed variable itself. In HMMs and IOHMMs, the hidden variable is the state path q T 1 . <p> The EM algorithm is an iterative algorithm successively applying the E-Step and the M-step. The M-Step consists in finding the parameters which maximize the auxiliary function. At the k th iteration, k+1 = argmax Q (j k ): (12) It can be shown <ref> [47] </ref> that an increase of Q brings an increase of the likelihood, and this algorithm converges to a local maximum of the likelihood, P (YjX ; ). When the above maximization cannot be done exactly (but Q increases at each iteration), we have a GEM (Generalized EM) algorithm.
Reference: [48] <author> A. </author> <title> Viterbi, "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm," </title> <journal> IEEE Transactions on Information Theory, </journal> <pages> pp. 260-269, </pages> <year> 1967. </year>
Reference-contexts: This is achieved with algorithms that perform the following maximization: q T fl 1 = argmax q T 1 1 jy T 1 ) = argmax q T 1 1 ; y T The Viterbi algorithm <ref> [48] </ref> finds the above maximum with a relatively efficient recursive solution (of computational cost proportional to the number of non-zero transitions probabilities times the sequence length). This is in fact an application of Bellman's dynamic programming algorithm [49].
Reference: [49] <author> R. Bellman, </author> <title> Dynamic Programming. </title> <address> NJ: </address> <publisher> Princeton University Press, </publisher> <year> 1957. </year>
Reference-contexts: This is in fact an application of Bellman's dynamic programming algorithm <ref> [49] </ref>.
Reference: [50] <author> N. J. Nilsson, </author> <booktitle> Problem-Solving Methods in Artificial Intelligence. </booktitle> <address> New York: </address> <publisher> McGraw-Hill, </publisher> <year> 1971. </year>
Reference-contexts: When the number of non-zero transition probabilities m is large, other graph search algorithms may be used in order to look for the optimal state sequence. Some are optimal (e.g., the A fl search <ref> [50] </ref>) and others are approximate but faster (e.g., the beam search [51]). For very large HMMs (e.g., for speech recognition with several tens of thousands of words), even these methods are not efficient enough.
Reference: [51] <author> H. Ney, D. Mergel, A. Noll, and A. Paesler, </author> <title> "Data driven search organization for continuous speech recognition," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 40, </volume> <pages> pp. 272-281, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: When the number of non-zero transition probabilities m is large, other graph search algorithms may be used in order to look for the optimal state sequence. Some are optimal (e.g., the A fl search [50]) and others are approximate but faster (e.g., the beam search <ref> [51] </ref>). For very large HMMs (e.g., for speech recognition with several tens of thousands of words), even these methods are not efficient enough. The methods that are employed for such large HMMs are based on progressive search, performing multiple passes.
Reference: [52] <author> F. Alleva, X. Huang, and M. Hwang, </author> <title> "An improved search algorithm using incremental knowledge for continuous speech recognition," </title> <booktitle> in International Conference on Acoustics, Speech and Signal Processing, </booktitle> <address> (Minneapolis, </address> <publisher> Minnesota), </publisher> <pages> pp. 307-310, </pages> <year> 1993. </year>
Reference-contexts: For very large HMMs (e.g., for speech recognition with several tens of thousands of words), even these methods are not efficient enough. The methods that are employed for such large HMMs are based on progressive search, performing multiple passes. See <ref> [52, 53, 54, 55] </ref> for more details. 8 3 Speech Recognition with HMMs Because speech recognition has been the most common application of HMMs, we will discuss here some of the issues this involves, although this discussion is relevant to many other applications.
Reference: [53] <author> H. Murveit, J. Butzberger, V. Digilakis, and M. Weintraub, </author> <title> "Large-vocabulary dictation using SRI's DECIPHER speech recognition system: Progressive search techniques knowledge for continuous speech recognition," </title> <booktitle> in International Conference on Acoustics, Speech and Signal Processing, </booktitle> <address> (Minneapolis, </address> <publisher> Minnesota), </publisher> <pages> pp. 319-322, </pages> <year> 1993. </year>
Reference-contexts: For very large HMMs (e.g., for speech recognition with several tens of thousands of words), even these methods are not efficient enough. The methods that are employed for such large HMMs are based on progressive search, performing multiple passes. See <ref> [52, 53, 54, 55] </ref> for more details. 8 3 Speech Recognition with HMMs Because speech recognition has been the most common application of HMMs, we will discuss here some of the issues this involves, although this discussion is relevant to many other applications.
Reference: [54] <author> X. Aubert, C. Dugast, H. Ney, and V. Steinbiss, </author> <title> "Large vocabulary continuous speech recognition of Wall Street journal data," </title> <booktitle> in International Conference on Acoustics, Speech and Signal Processing, </booktitle> <address> (Adelaide, Australia), </address> <pages> pp. 129-132, </pages> <year> 1994. </year>
Reference-contexts: For very large HMMs (e.g., for speech recognition with several tens of thousands of words), even these methods are not efficient enough. The methods that are employed for such large HMMs are based on progressive search, performing multiple passes. See <ref> [52, 53, 54, 55] </ref> for more details. 8 3 Speech Recognition with HMMs Because speech recognition has been the most common application of HMMs, we will discuss here some of the issues this involves, although this discussion is relevant to many other applications.
Reference: [55] <author> F. Kubala, A. Anastasakos, J. Makhoul, L. Nguyen, R. Schwartz, and G. Zavaliagkos, </author> <title> "Comparative experiments on large vocabulary speech recognition," </title> <booktitle> in International Conference on Acoustics, Speech and Signal Processing, </booktitle> <address> (Adelaide, Australia), </address> <pages> pp. 561-564, </pages> <year> 1994. </year>
Reference-contexts: For very large HMMs (e.g., for speech recognition with several tens of thousands of words), even these methods are not efficient enough. The methods that are employed for such large HMMs are based on progressive search, performing multiple passes. See <ref> [52, 53, 54, 55] </ref> for more details. 8 3 Speech Recognition with HMMs Because speech recognition has been the most common application of HMMs, we will discuss here some of the issues this involves, although this discussion is relevant to many other applications.
Reference: [56] <author> R. Cole, J. Mariani, H. Uszkoriet, A. Zaenen, and V. Zue, </author> <title> Survey of the State of the Art in Human Language Technology . http://www.cse.ogi.edu/CSLU/HLTsurvey/HLTsurvey.html: Cambridge University Press, </title> <year> 1996. </year>
Reference-contexts: See <ref> [56] </ref> for a collection of review papers on this subject. The language model is a crucial element of modern speech recognition systems (and speech understanding systems, which translate speech into actions), because most word sequences are very unlikely in a particular language, and in a particular semantic context.
Reference: [57] <editor> Advanced Research Projects Agency, </editor> <booktitle> Proceedings of the 1994 ARPA Human Language Technology Workshop (Princeton, </booktitle> <address> New Jersey, March 1994). </address> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: Benchmarks to compare speech recognition systems have been set up by ARPA <ref> [57] </ref> in the U.S.A.. The difficulty increases with the size of the vocabulary, the variability of the speech among the speakers, and other factors.
Reference: [58] <author> S. Levinson, </author> <title> "Statistical modeling and classification," in Survey of the State of the Art in Human Language Technology (R. </title> <editor> Cole, J. Mariani, H. Uszkoriet, A. Zaenen, and V. Zue, </editor> <booktitle> eds.), </booktitle> <pages> pp. 395-401, </pages> <address> http://www.cse.ogi.edu/CSLU/HLTsurvey/HLTsurvey.html: Cambridge University Press, </address> <year> 1996. </year>
Reference-contexts: For example, on the ATIS benchmark (where the task is to provide airline information to users, and the vocabulary has around 2000 words), laboratory experiments yielded around 5% of incorrectly answered queries <ref> [58] </ref>. This task involves not only recognition but also understanding. On a large vocabulary task set up by ARPA with around 60000 words (no understanding, only recognition), the word error rates reported are below 11%. <p> Speech recognition is now used in commercial applications, as in the AT&T telephone network. This system looks for one of five keywords. It makes an error in less than 5% of the calls and processes around one billion calls per year <ref> [58] </ref>. 3.5 Learning Criteria In many applications of HMMs such as speech recognition, there are actually two sequences of interest: the observation (e.g., acoustic) sequence, y T 1 , and the classification (e.g. correct word) sequence, w L 1 .
Reference: [59] <author> P. Brown, </author> <title> The Acoustic-Modeling problem in Automatic Speech Recognition. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Carnegie-Mellon University, </institution> <year> 1987. </year>
Reference-contexts: Several approaches have been proposed to train HMMs with a discriminant criterion. The most common are the maximum a posteriori criterion, to maximize P (w L 1 jy T 1 ), and the maximum mutual information criterion <ref> [59, 60, 61] </ref>, to maximize log P (y T 1 ) 1 ) .
Reference: [60] <author> L. R. Bahl, P. Brown, P. V. de Souza, and R. L. Mercer, </author> <title> "Speech recognition with continuous-parameter hidden Markov models," </title> <booktitle> Computer, Speech and Language, </booktitle> <volume> vol. 2, </volume> <pages> pp. 219-234, </pages> <year> 1987. </year>
Reference-contexts: Several approaches have been proposed to train HMMs with a discriminant criterion. The most common are the maximum a posteriori criterion, to maximize P (w L 1 jy T 1 ), and the maximum mutual information criterion <ref> [59, 60, 61] </ref>, to maximize log P (y T 1 ) 1 ) .
Reference: [61] <author> A. Nadas, D. Nahamoo, and M. Picheny, </author> <title> "On a model-robust training method for speech recognition," </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> vol. ASSP-36, no. 9, </volume> <pages> pp. 1432-1436, </pages> <year> 1988. </year>
Reference-contexts: Several approaches have been proposed to train HMMs with a discriminant criterion. The most common are the maximum a posteriori criterion, to maximize P (w L 1 jy T 1 ), and the maximum mutual information criterion <ref> [59, 60, 61] </ref>, to maximize log P (y T 1 ) 1 ) .
Reference: [62] <author> B. Juang and S. Katagiri, </author> <title> "Discriminative learning for minimum error classification," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 40, no. 12, </volume> <pages> pp. 3043-3054, </pages> <year> 1992. </year>
Reference-contexts: Maximizing this criterion attempts to increase the likelihood of the correct (i.e., constrained) model while decreasing the likelihood of all the other models. Other criteria have been proposed to approximate the minimization of the number of classification errors <ref> [62, 63] </ref>.
Reference: [63] <author> H. Leprieur and P. Haffner, </author> <title> "Discriminant learning with minimum memory loss for improved non-vocabulary rejection," </title> <booktitle> in EUROSPEECH'95, </booktitle> <address> (Madrid, Spain), </address> <year> 1995. </year> <month> 27 </month>
Reference-contexts: Maximizing this criterion attempts to increase the likelihood of the correct (i.e., constrained) model while decreasing the likelihood of all the other models. Other criteria have been proposed to approximate the minimization of the number of classification errors <ref> [62, 63] </ref>.
Reference: [64] <author> H. Sakoe and C. Chiba, </author> <title> "Dynamic programming algorithm optimization for spoken word recognition," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. ASSP-26, </volume> <pages> pp. 43-49, </pages> <month> February </month> <year> 1978. </year>
Reference-contexts: In the extreme case, if the numerical value of non-zero transition probabilities are completely ignored, the Viterbi algorithm only does a "dynamic time-warping" match <ref> [64] </ref> between the observation sequence and the sequence of probabilistic prototypes associated (through the emission distributions) with a sequence of state values in the HMM. Some operational speech recognition models actually ignore transition probabilities altogether, because of this problem.
Reference: [65] <author> D. Rumelhart, G. Hinton, and R. Williams, </author> <title> "Learning internal representations by error propagation," in Parallel Distributed Processing (D. </title> <editor> Rumelhart and J. McClelland, eds.), </editor> <volume> vol. 1, ch. 8, </volume> <pages> pp. 318-362, </pages> <address> Cambridge: </address> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: This was used for example in [30]. 4 Integrating Artificial Neural Networks and HMMs Artificial Neural Networks (ANNs) or connectionist models have been successfully used in several pattern recognition and sequential data processing problems. Multi-layered ANNs <ref> [65] </ref> can 13 represent a non-linear regression or classification model. Several researchers have proposed ways to combine ANNs with HMMs, in particular for automatic speech recognition. <p> Alternatively, the ANN can be used to re-score the N-best hypotheses of phoneme segmentation produced with an HMM [77], by assigning posterior probabilities to the phonemes for each of the phonetic segments hypothesized with the HMM. An HMM can also be viewed as a particular kind of recurrent <ref> [65] </ref> ANN [78, 79]. Although the ANN and the HMM are sometimes trained separately, most researchers have proposed schemes in which both are trained together, or at least the ANN is trained in a way that depends on the HMM. <p> Therefore, the gradients @C @y t can be used to train the parameters of the ANN: gradient descent using the chain rule for derivatives (also called back-propagation <ref> [65] </ref>) yields the parameter gradients @C = t @y t @ for a single sequence. Two criteria have been considered: the maximum likelihood criterion and the maximum mutual information criterion. <p> Furthermore, these ANNs can take into account a wide context (not just the observations at time t but also neighboring observations in the sequence), without violating the Markov assumptions, because there are no independence assumptions on the conditioning input variable. The ANN can even be recurrent <ref> [65, 2] </ref> (to take into account arbitrarily distant past contexts). * When the output sequence is discrete (e.g., a sequence of phonemes), the transition probabilities and emission probabilities are generally better matched than in HMMs, thus reducing a problem of imbalance (section 3.6) observed in HMMs for speech recognition.
Reference: [66] <author> R. P. Lippmann and B. Gold, </author> <title> "Neural classifiers useful for speech recognition," </title> <booktitle> in IEEE Proc. First Intl. Conf. on Neural Networks, vol. IV, </booktitle> <address> (San Diego, CA), </address> <pages> pp. 417-422, </pages> <year> 1987. </year>
Reference-contexts: Since ANNs were successful at classifying individual phonemes, initial research focused on using the dynamic programming tools of HMMs in order to go from the recognition of individual phonemes (or other local classification) to the recognition of whole sequences <ref> [66, 67, 68, 69, 70, 71, 72, 73, 74, 2] </ref>.
Reference: [67] <author> H. Bourlard and C. Wellekens, </author> <title> "Links between hidden Markov models and multilayer perceptrons," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 12, </volume> <pages> pp. 1167-1178, </pages> <year> 1990. </year>
Reference-contexts: Since ANNs were successful at classifying individual phonemes, initial research focused on using the dynamic programming tools of HMMs in order to go from the recognition of individual phonemes (or other local classification) to the recognition of whole sequences <ref> [66, 67, 68, 69, 70, 71, 72, 73, 74, 2] </ref>. <p> The models proposed by Bourlard et al. rely on a probabilistic interpretation of the ANN outputs <ref> [67, 68, 1, 80] </ref>. The ANN is trained to estimate posterior probabilities of HMM states, given a context of observation vectors, P (q t jy tk ; : : : ; y t1 ; y t ; y t+1 ; y t+k ), centered on the current time step.
Reference: [68] <author> N. Morgan and H. Bourlard, </author> <title> "Continuous speech recognition using multilayer perceptrons with hidden Markov models," </title> <booktitle> in International Conference on Acoustics, Speech and Signal Processing, </booktitle> <address> (Albuquerque, NM), </address> <pages> pp. 413-416, </pages> <year> 1990. </year>
Reference-contexts: Since ANNs were successful at classifying individual phonemes, initial research focused on using the dynamic programming tools of HMMs in order to go from the recognition of individual phonemes (or other local classification) to the recognition of whole sequences <ref> [66, 67, 68, 69, 70, 71, 72, 73, 74, 2] </ref>. <p> The models proposed by Bourlard et al. rely on a probabilistic interpretation of the ANN outputs <ref> [67, 68, 1, 80] </ref>. The ANN is trained to estimate posterior probabilities of HMM states, given a context of observation vectors, P (q t jy tk ; : : : ; y t1 ; y t ; y t+1 ; y t+k ), centered on the current time step.
Reference: [69] <author> H. Bourlard and C. Wellekens, </author> <title> "Speech pattern discrimination and multi-layered perceptrons," </title> <booktitle> Computer Speech and Language, </booktitle> <volume> vol. 3, </volume> <pages> pp. 1-19, </pages> <year> 1989. </year>
Reference-contexts: Since ANNs were successful at classifying individual phonemes, initial research focused on using the dynamic programming tools of HMMs in order to go from the recognition of individual phonemes (or other local classification) to the recognition of whole sequences <ref> [66, 67, 68, 69, 70, 71, 72, 73, 74, 2] </ref>.
Reference: [70] <author> M. Franzini, K. Lee, and A. Waibel, </author> <title> "Connectionist Viterbi training: a new hybrid method for continuous speech recognition," </title> <booktitle> in International Conference on Acoustics, Speech and Signal Processing, </booktitle> <address> (Albuquerque, NM), </address> <pages> pp. 425-428, </pages> <year> 1990. </year>
Reference-contexts: Since ANNs were successful at classifying individual phonemes, initial research focused on using the dynamic programming tools of HMMs in order to go from the recognition of individual phonemes (or other local classification) to the recognition of whole sequences <ref> [66, 67, 68, 69, 70, 71, 72, 73, 74, 2] </ref>.
Reference: [71] <author> A. J. Robinson and F. Fallside, </author> <title> "Phoneme recognition from the TIMIT database using recurrent error propagation networks," </title> <type> Technical Report CUED/F-INFENG/TR.42, </type> <institution> Cam-bridge University Engineering Department, </institution> <year> 1990. </year>
Reference-contexts: Since ANNs were successful at classifying individual phonemes, initial research focused on using the dynamic programming tools of HMMs in order to go from the recognition of individual phonemes (or other local classification) to the recognition of whole sequences <ref> [66, 67, 68, 69, 70, 71, 72, 73, 74, 2] </ref>.
Reference: [72] <author> X. Driancourt, L. Bottou, and P. Gallinari, </author> <title> "Learning vector quantization, multi-layer perceptron and dynamic programming: Comparison and cooperation," </title> <booktitle> in International Joint Conference on Neural Networks, </booktitle> <volume> vol. 2, </volume> <pages> pp. 815-819, </pages> <year> 1991. </year>
Reference-contexts: Since ANNs were successful at classifying individual phonemes, initial research focused on using the dynamic programming tools of HMMs in order to go from the recognition of individual phonemes (or other local classification) to the recognition of whole sequences <ref> [66, 67, 68, 69, 70, 71, 72, 73, 74, 2] </ref>. <p> In some cases <ref> [75, 72, 2, 73, 74] </ref>, the ANN outputs are not interpreted as probabilities, but are rather used as scores and generally combined with a dynamic programming algorithm akin to the Viterbi algorithm to perform the alignment and segmentation. <p> The idea of training a set of modules together (rather than separately) with respect to a global criterion with gradient-based algorithms was proposed several years ago <ref> [82, 83, 72] </ref>.
Reference: [73] <author> P. Haffner, M. Franzini, and A. Waibel, </author> <title> "Integrating time alignment and neural networks for high performance continuous speech recognition," </title> <booktitle> in International Conference on Acoustics, Speech and Signal Processing, (Toronto), </booktitle> <pages> pp. 105-108, </pages> <year> 1991. </year>
Reference-contexts: Since ANNs were successful at classifying individual phonemes, initial research focused on using the dynamic programming tools of HMMs in order to go from the recognition of individual phonemes (or other local classification) to the recognition of whole sequences <ref> [66, 67, 68, 69, 70, 71, 72, 73, 74, 2] </ref>. <p> In some cases <ref> [75, 72, 2, 73, 74] </ref>, the ANN outputs are not interpreted as probabilities, but are rather used as scores and generally combined with a dynamic programming algorithm akin to the Viterbi algorithm to perform the alignment and segmentation. <p> In some cases the dynamic programming algorithm is embedded in the ANN itself <ref> [73, 76] </ref>. Alternatively, the ANN can be used to re-score the N-best hypotheses of phoneme segmentation produced with an HMM [77], by assigning posterior probabilities to the phonemes for each of the phonetic segments hypothesized with the HMM.
Reference: [74] <author> J. Tebelskis, A. Waibel, B. Petek, and O. Schmidbauer, </author> <title> "Continuous speech recognition using linked predictive networks," </title> <booktitle> in Advances in Neural Information Processing Systems 3 (R. </booktitle> <editor> P. Lippman, R. Moody, and D. S. Touretzky, eds.), </editor> <address> (Denver, </address> <publisher> CO), </publisher> <pages> pp. 199-205, </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1991. </year>
Reference-contexts: Since ANNs were successful at classifying individual phonemes, initial research focused on using the dynamic programming tools of HMMs in order to go from the recognition of individual phonemes (or other local classification) to the recognition of whole sequences <ref> [66, 67, 68, 69, 70, 71, 72, 73, 74, 2] </ref>. <p> In some cases <ref> [75, 72, 2, 73, 74] </ref>, the ANN outputs are not interpreted as probabilities, but are rather used as scores and generally combined with a dynamic programming algorithm akin to the Viterbi algorithm to perform the alignment and segmentation.
Reference: [75] <author> L. Bottou, F. Fogelman-Soulie, P. Blanchet, and J. S. Lienard, </author> <title> "Speaker independent isolated digit recognition: multilayer perceptrons vs dynamic time warping," </title> <booktitle> Neural Networks, </booktitle> <volume> vol. 3, </volume> <pages> pp. 453-465, </pages> <year> 1990. </year>
Reference-contexts: In some cases <ref> [75, 72, 2, 73, 74] </ref>, the ANN outputs are not interpreted as probabilities, but are rather used as scores and generally combined with a dynamic programming algorithm akin to the Viterbi algorithm to perform the alignment and segmentation.
Reference: [76] <author> E. Levin, R. Pieraccini, and E. Bocchieri, </author> <title> "Time-warping network: a hybrid framework for speech recognition," </title> <booktitle> in Advances in Neural Information Processing Systems 4 (J. </booktitle> <editor> Moody, S. Hanson, and R. Lipmann, eds.), </editor> <address> (Denver, </address> <publisher> CO), </publisher> <pages> pp. 151-158, </pages> <year> 1992. </year>
Reference-contexts: In some cases the dynamic programming algorithm is embedded in the ANN itself <ref> [73, 76] </ref>. Alternatively, the ANN can be used to re-score the N-best hypotheses of phoneme segmentation produced with an HMM [77], by assigning posterior probabilities to the phonemes for each of the phonetic segments hypothesized with the HMM.
Reference: [77] <author> G. Zavaliagkos, S. Austin, J. Makhoul, and R. Schwartz, </author> <title> "A hybrid continuous speech recognition system using segmental neural nets with hidden Markov models," </title> <journal> Int. Journal of Pattern Recognition and Artificial Intelligence, </journal> <pages> pp. 305-319, </pages> <year> 1993. </year> <title> Special Issue on Applications of Neural Networks to Pattern Recognition (I. </title> <publisher> Guyon Ed.). </publisher>
Reference-contexts: In some cases the dynamic programming algorithm is embedded in the ANN itself [73, 76]. Alternatively, the ANN can be used to re-score the N-best hypotheses of phoneme segmentation produced with an HMM <ref> [77] </ref>, by assigning posterior probabilities to the phonemes for each of the phonetic segments hypothesized with the HMM. An HMM can also be viewed as a particular kind of recurrent [65] ANN [78, 79].
Reference: [78] <author> J. Bridle, "Alphanets: </author> <title> a recurrent `neural' network architecture with a hidden Markov model interpretation," </title> <journal> Speech Communication, </journal> <volume> vol. 9, no. 1, </volume> <pages> pp. 83-92, </pages> <year> 1990. </year>
Reference-contexts: An HMM can also be viewed as a particular kind of recurrent [65] ANN <ref> [78, 79] </ref>. Although the ANN and the HMM are sometimes trained separately, most researchers have proposed schemes in which both are trained together, or at least the ANN is trained in a way that depends on the HMM.
Reference: [79] <author> J. Bridle, </author> <title> "Training stochastic model recognition algorithms as networks can lead to maximum mutual information estimation of parameters," </title> <booktitle> in Advances in Neural Information Processing Systems 2 (D. </booktitle> <editor> Touretzky, </editor> <publisher> ed.), </publisher> <pages> pp. 211-217, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: An HMM can also be viewed as a particular kind of recurrent [65] ANN <ref> [78, 79] </ref>. Although the ANN and the HMM are sometimes trained separately, most researchers have proposed schemes in which both are trained together, or at least the ANN is trained in a way that depends on the HMM.
Reference: [80] <author> N. Morgan, Y. Konig, S. Wu, and H. Bourlard, </author> <title> "Transition-based statistical training for asr," </title> <booktitle> in Proceedings of IEEE Automatic Speech Recognition Workshop (Snowbird), </booktitle> <pages> pp. 133-134, </pages> <year> 1995. </year>
Reference-contexts: The models proposed by Bourlard et al. rely on a probabilistic interpretation of the ANN outputs <ref> [67, 68, 1, 80] </ref>. The ANN is trained to estimate posterior probabilities of HMM states, given a context of observation vectors, P (q t jy tk ; : : : ; y t1 ; y t ; y t+1 ; y t+k ), centered on the current time step. <p> For each time step, the ANN is supervised with a target value of 1 for the correct state and a target value of 0 for the other states. This procedure has been found to converge and yield speech recognition performance at the level of state-of-the-art systems <ref> [1, 80] </ref>. Bourlard et al. draw links between this procedure and the EM algorithm; however, this procedure does not optimize a well-defined criterion during training: training is based on the local targets provided by the constrained Viterbi alignment algorithm.
Reference: [81] <author> Y. Bengio, R. De Mori, G. Flammia, and R. Kompe, </author> <title> "Global optimization of a neural network-hidden Markov model hybrid," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 3, no. 2, </volume> <pages> pp. 252-259, </pages> <year> 1992. </year>
Reference-contexts: Bourlard et al. draw links between this procedure and the EM algorithm; however, this procedure does not optimize a well-defined criterion during training: training is based on the local targets provided by the constrained Viterbi alignment algorithm. Another approach <ref> [2, 81, 30] </ref> uses the ANN to transform the observation sequence into a form that is easier to model for an HMM that has simple (but continuous) emission models (e.g., Gaussian or Gaussian mixture). The ANN is used as a non-linear trainable pre-processor or feature extractor for the HMM. <p> This model was introduced in <ref> [81] </ref> for phoneme recognition. It is also described in [2], and was extended to character recognition in [30]. The ANN transforms an input sequence u T 1 into an intermediate observation sequence y T 1 , with a parameterized function y T 1 = f (u T 1 ; ). <p> However, it has been shown experimentally with the above ANN/HMM hybrid how training the ANN jointly with the HMM improves performance on a speech recognition problem <ref> [81, 2] </ref>, bringing down the error rate on a plosive recognition task from 19% to 14%.
Reference: [82] <author> L. Bottou, </author> <title> Une approche theorique de l'apprentissage connexioniste; applications a la reconnaissance de la parole. </title> <type> PhD thesis, </type> <institution> Universite de Paris XI, </institution> <year> 1991. </year>
Reference-contexts: The idea of training a set of modules together (rather than separately) with respect to a global criterion with gradient-based algorithms was proposed several years ago <ref> [82, 83, 72] </ref>.
Reference: [83] <author> Y. Bengio, </author> <title> Artificial Neural Networks and their Application to Sequence Recognition. </title> <type> PhD thesis, </type> <institution> McGill University, (Computer Science), Montreal, Qc., Canada, </institution> <year> 1991. </year>
Reference-contexts: The idea of training a set of modules together (rather than separately) with respect to a global criterion with gradient-based algorithms was proposed several years ago <ref> [82, 83, 72] </ref>.
Reference: [84] <author> E. Sondik, </author> <title> "The optimal control of partially observable markov processes over the finite horizon," </title> <journal> Operations Research, </journal> <volume> vol. 11, </volume> <pages> pp. 1071-1088, </pages> <year> 1973. </year>
Reference-contexts: In the literature on learning algorithms [4, 5, 6], IOHMMs have been proposed for sequence processing tasks, with complex emission and transition models based on ANNs. In the control and reinforcement learning literature, similar models have been called Partially Observable Markov Decision Processes <ref> [84, 85, 3] </ref>. In this case, the objective is not to model an output sequence given an input sequence, but rather, to find the input sequence (in fact a sequence of actions) which 15 Input-Output Hidden Markov Model.
Reference: [85] <author> E. Sondik, </author> <title> "The optimal control of partially observable markov processes over the infinite horizon: discounted case," </title> <journal> Operations Research, </journal> <volume> vol. 26, </volume> <pages> pp. 282-304, </pages> <year> 1978. </year>
Reference-contexts: In the literature on learning algorithms [4, 5, 6], IOHMMs have been proposed for sequence processing tasks, with complex emission and transition models based on ANNs. In the control and reinforcement learning literature, similar models have been called Partially Observable Markov Decision Processes <ref> [84, 85, 3] </ref>. In this case, the objective is not to model an output sequence given an input sequence, but rather, to find the input sequence (in fact a sequence of actions) which 15 Input-Output Hidden Markov Model.
Reference: [86] <author> Y. Bengio and P. Frasconi, </author> <title> "Diffusion of context and credit information in markovian models," </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> vol. 3, </volume> <pages> pp. 223-244, </pages> <year> 1995. </year>
Reference-contexts: See <ref> [86] </ref> for a development of this argument and an analysis of the difficulty of learning to represent long-term dependencies in Markovian models in general. In the next section we describe particular kinds of IOHMMs which have been proposed in 16 the econometrics literature. <p> What happens when we try to learn what the hidden state should represent? The state variable keeps some informations about the past sequence and discards others. It therefore captures the temporal dependencies. In <ref> [86] </ref>, it was shown that, for Markovian models (including HMMs, IOHMMs, Markov switching models and Partially Observable Markov Decision Processes), learning of long-term dependencies in sequential data becomes exponentially more difficult as the span of these dependencies increases.
Reference: [87] <author> S. Goldfeld and R. Quandt, </author> <title> "A markov model for switching regressions," </title> <journal> Journal of Econometrics, </journal> <volume> vol. 1, </volume> <pages> pp. 3-16, </pages> <year> 1973. </year>
Reference-contexts: In the following section, we present the EM algorithm which can be used for training both HMMs and synchronous HMMs. 5.1 Markov Switching Models Markov Switching Models have been introduced in the econometrics literature <ref> [87, 88, 89, 12, 13] </ref> for modeling non-stationarities due to abrupt changes of regime in the economy [90, 91, 92, 93, 94, 36].
Reference: [88] <author> R. Shumway and D. Stoffer, </author> <title> "An approach to time series smoothing and forecasting using the em algorithm," </title> <journal> Journal of Time Series Analysis, </journal> <volume> vol. 3, no. 4, </volume> <pages> pp. 253-264, </pages> <year> 1982. </year>
Reference-contexts: In the following section, we present the EM algorithm which can be used for training both HMMs and synchronous HMMs. 5.1 Markov Switching Models Markov Switching Models have been introduced in the econometrics literature <ref> [87, 88, 89, 12, 13] </ref> for modeling non-stationarities due to abrupt changes of regime in the economy [90, 91, 92, 93, 94, 36]. <p> See for example [93, 94] for Markov-switching ARCH models applied to analyzing respectively the changes in variance of stock returns and interest rates. The parameters of Markov switching models can generally be estimated using the EM algorithm <ref> [100, 88, 90, 101] </ref> to maximize the likelihood P (y T 1 j) (see next section). Other inference algorithms are used in econometrics applications [102], for filtering, smoothing, and prediction.
Reference: [89] <author> S. Cosslett and L.-F. Lee, </author> <title> "Serial correlation in discrete variable models," </title> <journal> Journal of Econometrics, </journal> <volume> vol. 27, </volume> <pages> pp. 79-97, </pages> <year> 1985. </year>
Reference-contexts: In the following section, we present the EM algorithm which can be used for training both HMMs and synchronous HMMs. 5.1 Markov Switching Models Markov Switching Models have been introduced in the econometrics literature <ref> [87, 88, 89, 12, 13] </ref> for modeling non-stationarities due to abrupt changes of regime in the economy [90, 91, 92, 93, 94, 36].
Reference: [90] <author> J. Hamilton, </author> <title> "Analysis of time series subject to changes in regime," </title> <journal> Journal of Econometrics, </journal> <volume> vol. 45, </volume> <pages> pp. 39-70, </pages> <year> 1990. </year>
Reference-contexts: the following section, we present the EM algorithm which can be used for training both HMMs and synchronous HMMs. 5.1 Markov Switching Models Markov Switching Models have been introduced in the econometrics literature [87, 88, 89, 12, 13] for modeling non-stationarities due to abrupt changes of regime in the economy <ref> [90, 91, 92, 93, 94, 36] </ref>. The point of view taken by most econometricians is to extend time-series regression models by the addition of a discrete hidden state variable, which allows changing the parameters of the regression models when the state variable changes its value. <p> See for example [93, 94] for Markov-switching ARCH models applied to analyzing respectively the changes in variance of stock returns and interest rates. The parameters of Markov switching models can generally be estimated using the EM algorithm <ref> [100, 88, 90, 101] </ref> to maximize the likelihood P (y T 1 j) (see next section). Other inference algorithms are used in econometrics applications [102], for filtering, smoothing, and prediction.
Reference: [91] <author> M. Bonomo and R. Garcia, </author> <title> "Can a well-fitted equilibrium asset-pricing model produce mean reversion?," </title> <journal> Journal of Applied Econometrics, </journal> <volume> vol. 9, </volume> <pages> pp. 19-29, </pages> <year> 1994. </year>
Reference-contexts: the following section, we present the EM algorithm which can be used for training both HMMs and synchronous HMMs. 5.1 Markov Switching Models Markov Switching Models have been introduced in the econometrics literature [87, 88, 89, 12, 13] for modeling non-stationarities due to abrupt changes of regime in the economy <ref> [90, 91, 92, 93, 94, 36] </ref>. The point of view taken by most econometricians is to extend time-series regression models by the addition of a discrete hidden state variable, which allows changing the parameters of the regression models when the state variable changes its value.
Reference: [92] <author> M. Sola and J. Driffill, </author> <title> "Testing the term structure of interest rates using a stationary vector autoregression with regime switching," </title> <journal> Journal of Economic Dynamics and Control, </journal> <volume> vol. 18, </volume> <pages> pp. 601-628, </pages> <year> 1994. </year>
Reference-contexts: the following section, we present the EM algorithm which can be used for training both HMMs and synchronous HMMs. 5.1 Markov Switching Models Markov Switching Models have been introduced in the econometrics literature [87, 88, 89, 12, 13] for modeling non-stationarities due to abrupt changes of regime in the economy <ref> [90, 91, 92, 93, 94, 36] </ref>. The point of view taken by most econometricians is to extend time-series regression models by the addition of a discrete hidden state variable, which allows changing the parameters of the regression models when the state variable changes its value.
Reference: [93] <author> J. Hamilton and R. Susmel, </author> <title> "Autoregressive conditional heteroskedasticity and changes in regime," </title> <journal> Journal of Econometrics, </journal> <volume> vol. 64, no. </volume> <pages> 1-2, pp. 307-33, </pages> <year> 1994. </year>
Reference-contexts: the following section, we present the EM algorithm which can be used for training both HMMs and synchronous HMMs. 5.1 Markov Switching Models Markov Switching Models have been introduced in the econometrics literature [87, 88, 89, 12, 13] for modeling non-stationarities due to abrupt changes of regime in the economy <ref> [90, 91, 92, 93, 94, 36] </ref>. The point of view taken by most econometricians is to extend time-series regression models by the addition of a discrete hidden state variable, which allows changing the parameters of the regression models when the state variable changes its value. <p> The representation of the variance of e t in equation 10 can be made more complex than a single constant parameter: variance can also be a function of the state variable as well as of the input variables. See for example <ref> [93, 94] </ref> for Markov-switching ARCH models applied to analyzing respectively the changes in variance of stock returns and interest rates. The parameters of Markov switching models can generally be estimated using the EM algorithm [100, 88, 90, 101] to maximize the likelihood P (y T 1 j) (see next section).
Reference: [94] <author> J. Cai, </author> <title> "A markov model of unconditional variance in ARCH," </title> <journal> Journal of Business and Economic Statistics, </journal> <year> 1994. </year>
Reference-contexts: the following section, we present the EM algorithm which can be used for training both HMMs and synchronous HMMs. 5.1 Markov Switching Models Markov Switching Models have been introduced in the econometrics literature [87, 88, 89, 12, 13] for modeling non-stationarities due to abrupt changes of regime in the economy <ref> [90, 91, 92, 93, 94, 36] </ref>. The point of view taken by most econometricians is to extend time-series regression models by the addition of a discrete hidden state variable, which allows changing the parameters of the regression models when the state variable changes its value. <p> The representation of the variance of e t in equation 10 can be made more complex than a single constant parameter: variance can also be a function of the state variable as well as of the input variables. See for example <ref> [93, 94] </ref> for Markov-switching ARCH models applied to analyzing respectively the changes in variance of stock returns and interest rates. The parameters of Markov switching models can generally be estimated using the EM algorithm [100, 88, 90, 101] to maximize the likelihood P (y T 1 j) (see next section).
Reference: [95] <author> D. Sichel, </author> <title> "Business cycle duration dependence: a parametric approach," </title> <journal> Review of Economics and Statistics, </journal> <volume> vol. 71, </volume> <pages> pp. 245-260, </pages> <year> 1991. </year>
Reference-contexts: In most of the cases described in the econometrics literature, this distribution is assumed to be time-invariant, and it is specified by a matrix of transition probabilities (as in ordinary HMMs), although more complicated specifications have been suggested <ref> [95, 96, 97, 98, 99] </ref>. The representation of the variance of e t in equation 10 can be made more complex than a single constant parameter: variance can also be a function of the state variable as well as of the input variables.
Reference: [96] <author> F. Diebold, G. Rudebusch, and E. Sichel, </author> <title> "Further evidence on business-cycle duration dependence," in Business Cycles, Indicators, </title> <editor> and Forecasting (J. Stock and M. Watson, eds.), </editor> <publisher> Chicago: University of Chicago Press, </publisher> <year> 1993. </year>
Reference-contexts: In most of the cases described in the econometrics literature, this distribution is assumed to be time-invariant, and it is specified by a matrix of transition probabilities (as in ordinary HMMs), although more complicated specifications have been suggested <ref> [95, 96, 97, 98, 99] </ref>. The representation of the variance of e t in equation 10 can be made more complex than a single constant parameter: variance can also be a function of the state variable as well as of the input variables.
Reference: [97] <author> E. Ghysel, </author> <title> "A time series model with periodic stochastic regime switching," </title> <type> Tech. Rep. C.R.D.E. Discussion paper 1093, </type> <institution> C.R.D.E., Universite de Montreal, </institution> <address> Montreal, Quebec, Canada, </address> <year> 1993. </year>
Reference-contexts: In most of the cases described in the econometrics literature, this distribution is assumed to be time-invariant, and it is specified by a matrix of transition probabilities (as in ordinary HMMs), although more complicated specifications have been suggested <ref> [95, 96, 97, 98, 99] </ref>. The representation of the variance of e t in equation 10 can be made more complex than a single constant parameter: variance can also be a function of the state variable as well as of the input variables.
Reference: [98] <author> R. Garcia and H. Schaller, </author> <title> "Are the effects of monetary policy asymmetric," </title> <type> Tech. Rep. </type> <address> 95s-6, CIRANO, Montreal, Quebec, Canada, </address> <year> 1995. </year>
Reference-contexts: In most of the cases described in the econometrics literature, this distribution is assumed to be time-invariant, and it is specified by a matrix of transition probabilities (as in ordinary HMMs), although more complicated specifications have been suggested <ref> [95, 96, 97, 98, 99] </ref>. The representation of the variance of e t in equation 10 can be made more complex than a single constant parameter: variance can also be a function of the state variable as well as of the input variables.
Reference: [99] <author> F. Diebold, J. Lee, and G. Weinbach, </author> <title> "Regime switching with time-varying transition probabilities," in Nonstationary Time Series Analysis and Cointegration (C. </title> <editor> Hargreaves, ed.), </editor> <publisher> Oxford: Oxford University Press, </publisher> <year> 1993. </year>
Reference-contexts: In most of the cases described in the econometrics literature, this distribution is assumed to be time-invariant, and it is specified by a matrix of transition probabilities (as in ordinary HMMs), although more complicated specifications have been suggested <ref> [95, 96, 97, 98, 99] </ref>. The representation of the variance of e t in equation 10 can be made more complex than a single constant parameter: variance can also be a function of the state variable as well as of the input variables.
Reference: [100] <author> N. Kiefer, </author> <title> "A note on switching regressions and logistic discrimination," </title> <journal> Econometrica, </journal> <volume> vol. 48, </volume> <pages> pp. 1065-1069, </pages> <year> 1980. </year>
Reference-contexts: See for example [93, 94] for Markov-switching ARCH models applied to analyzing respectively the changes in variance of stock returns and interest rates. The parameters of Markov switching models can generally be estimated using the EM algorithm <ref> [100, 88, 90, 101] </ref> to maximize the likelihood P (y T 1 j) (see next section). Other inference algorithms are used in econometrics applications [102], for filtering, smoothing, and prediction.
Reference: [101] <author> C. Kim, </author> <title> "Dynamical linear models with markov-switching," </title> <journal> Journal of Econometrics, </journal> <volume> vol. 60, </volume> <pages> pp. 1-22, </pages> <year> 1994. </year> <month> 29 </month>
Reference-contexts: See for example [93, 94] for Markov-switching ARCH models applied to analyzing respectively the changes in variance of stock returns and interest rates. The parameters of Markov switching models can generally be estimated using the EM algorithm <ref> [100, 88, 90, 101] </ref> to maximize the likelihood P (y T 1 j) (see next section). Other inference algorithms are used in econometrics applications [102], for filtering, smoothing, and prediction.
Reference: [102] <author> J. Hamilton, </author> <title> "State-space models," in Handbook of Econometrics (R. </title> <editor> Engle and D. Mc--Fadden, eds.), </editor> <year> 1993. </year>
Reference-contexts: The parameters of Markov switching models can generally be estimated using the EM algorithm [100, 88, 90, 101] to maximize the likelihood P (y T 1 j) (see next section). Other inference algorithms are used in econometrics applications <ref> [102] </ref>, for filtering, smoothing, and prediction. A filtering algorithm is used to compute an estimate of the current distribution P (q t jy t 1 ; x t state given past inputs and outputs.
Reference: [103] <author> S. Bengio and Y. Bengio, </author> <title> "An EM algorithm for asynchronous input/output hidden Markov models," </title> <booktitle> in International Conference On Neural Information Processing (L. </booktitle> <editor> Xu, ed.), (Hong-Kong), </editor> <year> 1996. </year>
Reference-contexts: See for example the models discussed in section 7.1. 5.3 Asynchronous IOHMMs In a recent paper on asynchronous HMMs <ref> [103] </ref>, it is shown how to extend the IOHMM formalism to the case of output sequences shorter than input sequences, which is normally the case in speech recognition (where the output sequence would typically be a phoneme sequence, and the input sequence a sequence of acoustic vectors). <p> This recognition algorithm has the same computational complexity as the recognition algorithm for ordinary HMMs, i.e., the number of transitions times the length of the input sequence. Asynchronous IOHMMs have been proposed for speech recognition <ref> [103] </ref> but could be used in other applications to map input sequences to output sequences of a different length. They represent a particular type of probabilistic transducers, discussed in the next section. 6 Acceptors and Transducers One way to view an HMM is as a way to weigh various hypotheses.
Reference: [104] <author> L. Bottou, Y. Bengio, and Y. Le Cun, </author> <title> "Document analysis with generalized transduction," </title> <type> Tech. Rep. </type> <institution> HA6156000-960701-01TM, AT&T Laboratories, </institution> <address> Holmdel, New-Jersey, </address> <month> July </month> <year> 1996. </year>
Reference-contexts: Search algorithms (like the Viterbi algorithm, beam search, A fl , etc...) can be used to look for the most likely sequence of values for all the intermediate variables (e.g., states in HMMs, speech units, words). 6.1 Generalized Transducers A way to generalize transducers was recently proposed <ref> [104] </ref> which allows any kind of data structure to be used as "labels" (instead of discrete symbols) in the sequences to be processed, and allows the transducers and acceptors to have parameters that are learned with respect to a global criterion. <p> As in multi-layer neural networks, the parameters of a transformer can be learned by propagating gradients with respect to this criterion in the reverse direction. This approach was successfully used as part of a document analysis system <ref> [104] </ref> that reads amounts from check images. It is used by customers of NCR to process millions of checks per day.
Reference: [105] <author> R. Kalman and R. Bucy, </author> <title> "New results in linear filtering and prediction," </title> <journal> Journal of Basic Engineering (ASME), </journal> <volume> vol. 83D, </volume> <pages> pp. 95-108, </pages> <year> 1961. </year>
Reference-contexts: Similarly, a Gaussian emission model can be expressed as in equation 10. The Kalman filter <ref> [105] </ref> is in fact such a model, and the associated algorithms allow to compute P (q t jx t 1 ; y t 1 ) in a forward recursion (thus solving the filtering problem).
Reference: [106] <author> H. Rauch, </author> <title> "Solutions to the linear smoothing problem," </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> vol. 8, </volume> <pages> pp. 371-372, </pages> <year> 1963. </year>
Reference-contexts: The Kalman filter [105] is in fact such a model, and the associated algorithms allow to compute P (q t jx t 1 ; y t 1 ) in a forward recursion (thus solving the filtering problem). Similarly to Markov switching models, a backward recursion (the Rauch equations <ref> [106] </ref>) allows to compute the posterior probabilities P (q t jx T 1 ; y T 1 ) for T &gt; t (thus solving the smoothing problem).
Reference: [107] <author> L. Ljung and T. Soderstrom, </author> <title> Theory and Practice of recursive identification. </title> <publisher> MIT Press, </publisher> <year> 1983. </year>
Reference-contexts: In the context of real-time control and other applications where learning must be on-line, numerical maximization of the likelihood can be performed recursively with a second-order method which requires only gradients <ref> [107] </ref>.
Reference: [108] <author> Z. Ghahramani and G. Hinton, </author> <title> "Parameter estimation for linear dynamical systems," </title> <type> Tech. Rep. Technical Report CRG-TR-91-1, </type> <institution> University of Toronto, </institution> <year> 1996. </year>
Reference-contexts: In the context of real-time control and other applications where learning must be on-line, numerical maximization of the likelihood can be performed recursively with a second-order method which requires only gradients [107]. For off-line applications, the EM algorithm can also be used <ref> [108] </ref>, with a backward pass that is equivalent to the Rauch equations. 22 7.1 Hybrids of Discrete and Continuous State One disadvantage of the discrete representation of the state is that it is an inefficient representation in comparison to a distributed representation with multiple state variables.
Reference: [109] <author> Z. Ghahramani and M. I. Jordan, </author> <title> "Factorial hidden markov models," </title> <booktitle> in Advances in Neural Information Processing Systems 8 (M. </booktitle> <editor> Mozer, D. Touretzky, and M. Perrone, eds.), </editor> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: For example, if instead n binary variables were used, exponentially more bits would be available. In general such models would be very expensive to maintain, but so-called factorial HMMs <ref> [109] </ref> have been proposed with such properties. On the other hand, models with a continuous-valued state have been typically restricted to a linear-Gaussian model, again for reasons of computational tractability. <p> One promising direction that was proposed to manage this problem is to split the state variable in multiple sub-state variables <ref> [109] </ref>, which may operate at different time scales [115], since the "slow" variables can more easily represent longer-term context. 23 * The above models raise the general problem of intractability of the computation of the likelihood (or of the E-Step of the EM algorithm).
Reference: [110] <author> Y. Bar-Shalom and X. Li, </author> <title> Estimation and Tracking. </title> <address> Boston, MA: Artech House, </address> <year> 1993. </year>
Reference-contexts: To model both the abrupt and gradual changes in time series, several researchers have in fact proposed hybrids of state space models and discrete-state HMMs (or IOHMMs), also known as state space models with switching, or jump-linear systems. See <ref> [110] </ref> and [14] for a review of such models. Many early models assume that some of the parameters of the distribution are known a-priori, and others [13] approximate the EM algorithm with a heuristic, because the E-step would require exponential computations.
Reference: [111] <author> C. Carter and R. Kohn, </author> <title> "On gibbs sampling for state space models," </title> <journal> Biometrika, </journal> <volume> vol. 81, </volume> <pages> pp. 541-553, </pages> <year> 1994. </year>
Reference-contexts: See [110] and [14] for a review of such models. Many early models assume that some of the parameters of the distribution are known a-priori, and others [13] approximate the EM algorithm with a heuristic, because the E-step would require exponential computations. Others <ref> [111, 112] </ref> used expensive Monte-Carlo simulations to address this problem. Instead, in [14], a function that is a lower bound on the log likelihood is maximized with a tractable algorithm. This paper uses the idea of variational approximation that has already been proposed in [113] for other intractable models.
Reference: [112] <author> C. Athaide, </author> <title> Likelihood estimation and state estimation for nonlinear state space models. </title> <type> PhD thesis, </type> <institution> Graduate Group in Managerial Science and Applied Economics, University of Pennsylvania, </institution> <address> Philadelphia, PA, </address> <year> 1995. </year>
Reference-contexts: See [110] and [14] for a review of such models. Many early models assume that some of the parameters of the distribution are known a-priori, and others [13] approximate the EM algorithm with a heuristic, because the E-step would require exponential computations. Others <ref> [111, 112] </ref> used expensive Monte-Carlo simulations to address this problem. Instead, in [14], a function that is a lower bound on the log likelihood is maximized with a tractable algorithm. This paper uses the idea of variational approximation that has already been proposed in [113] for other intractable models.
Reference: [113] <author> L. Saul and M. Jordan, </author> <title> "Exploiting tractable substructures in intractable networks," </title> <booktitle> in Advances in Neural Information Processing Systems 8 (M. </booktitle> <editor> Mozer, D. Touretzky, and M. Per-rone, eds.), </editor> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: Others [111, 112] used expensive Monte-Carlo simulations to address this problem. Instead, in [14], a function that is a lower bound on the log likelihood is maximized with a tractable algorithm. This paper uses the idea of variational approximation that has already been proposed in <ref> [113] </ref> for other intractable models. <p> To address such problems, <ref> [113] </ref> recently introduced a promising methodology of variational approximation based on tractable substructures in the Bayesian network.
Reference: [114] <author> G. Parisi, </author> <title> Statistical Field Theory. </title> <address> Redwood City, CA: </address> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: This paper uses the idea of variational approximation that has already been proposed in [113] for other intractable models. A simpler version of this idea used in physics is the mean-field approximation <ref> [114] </ref> for statistical mechanics systems. 8 Conclusions and Challenges for Future Research Hidden Markov models are powerful models of sequential data which have already been successfully used in several applications, notably speech recognition. They could be applied in many other domains.
Reference: [115] <author> S. ElHihi and Y. Bengio, </author> <title> "Hierarchical recurrent neural networks for long-term dependencies," </title> <booktitle> in Advances in Neural Information Processing Systems 8 (M. </booktitle> <editor> Mozer, D. Touretzky, and M. Perrone, </editor> <booktitle> eds.), </booktitle> <pages> pp. 493-499, </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1996. </year> <month> 30 </month>
Reference-contexts: One promising direction that was proposed to manage this problem is to split the state variable in multiple sub-state variables [109], which may operate at different time scales <ref> [115] </ref>, since the "slow" variables can more easily represent longer-term context. 23 * The above models raise the general problem of intractability of the computation of the likelihood (or of the E-Step of the EM algorithm).
References-found: 115

