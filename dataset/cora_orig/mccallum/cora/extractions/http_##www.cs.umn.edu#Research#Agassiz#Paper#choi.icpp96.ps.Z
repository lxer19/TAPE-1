URL: http://www.cs.umn.edu/Research/Agassiz/Paper/choi.icpp96.ps.Z
Refering-URL: http://www.cs.umn.edu/Research/Agassiz/agassiz_pubs.html
Root-URL: http://www.cs.umn.edu
Email: lchoi@csrd.uiuc.edu yew@cs.umn.edu  
Phone: (217)333-0969 (612)625-7387  
Title: Program Analysis for Cache Coherence: Beyond Procedural Boundaries  
Author: Lynn Choi Pen-Chung Yew 
Keyword: compiler, interprocedural analysis, data-flow analysis, cache coherence, shared-memory multiprocessors  
Note: This work is supported in part by the National Science Foundation under Grant No. MIP 89-20891 and MIP 93-07910.  
Address: Urbana, IL 61801-1351 Minneapolis, MN 55455-0519  
Affiliation: Center for Supercomputing R D Department of Computer Science University of Illinois University of Minnesota  
Abstract: The presence of procedures and procedure calls introduces side effects, which complicates the analysis of stale reference detection in compiler-directed cache coherence schemes [6, 4, 8]. Previous compiler algorithms use cache invalidation at procedure boundary [5, 7] or inlining [7] to avoid reference marking interprocedurally. However, frequent cache invalidations will result in poor performance since locality cannot be exploited across the procedure boundary. Also, the inlining is often prohibitive due to both its code expansion and increase in compilation time and memory requirements. In this paper, we introduce improved intraprocedural and interprocedural algorithms for detecting references to stale data. The intraprocedural algorithm can mark potential stale references without relying on any cache invalidation or inlining at procedure boundaries, thus avoiding unnecessary cache misses for subroutine local data. The interprocedural algorithm performs bottom-up and top-down analysis on the procedure call graph to further exploit locality across procedure boundaries. The result of execution-driven simulations on Perfect benchmarks demonstrates that by avoiding cache invalidations, the intraprocedural algorithm eliminates up to 26.0% of the cache misses for a compiler-directed scheme compared to an existing invalidation-based algorithm [7]. With the full interprocedural analysis, up to 10.8% of additional cache misses can be removed. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Ballance, A. Maccabe, and K. Ottenstein. </author> <title> The Program Dependence Web: a Representation Supporting Control Data- and Demand-Driven Interpretation of Imperative 23 Languages. </title> <booktitle> Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: For this 7 purpose, we use the gated single assignment (GSA) form <ref> [1] </ref> to treat arrays with different access regions as different symbolic variables. * Epoch Flow Graph This is a modified flow graph to represent the epoch boundary information as well as different control flows due to the parallel execution [8].
Reference: [2] <author> M. Berry and others. </author> <title> The Perfect Club Benchmarks: Effective Performance Evaluation of Supercomputers. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall, </month> <year> 1989. </year>
Reference-contexts: For a more precise array analysis, we construct the GSA interprocedurally using a side effect (MAYMOD) information with additional flow analysis. 4 Experimentation 4.1 Experimentation Methodology We use six programs from the Perfect Club benchmark suite <ref> [2] </ref> as our target benchmarks. The Perfect benchmarks are first parallelized by the Polaris compiler. In the parallelized codes, the parallelism is expressed in terms of DOALL loops.
Reference: [3] <author> D. Callahan and K. Kennedy. </author> <title> Analysis of Interprocedural Side Effects in a Parallel Programming Environment. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 517-550, </pages> <year> 1988. </year>
Reference-contexts: The notion of the subarray we use is an extension to the regular section used in <ref> [3, 9, 14] </ref>. * Gated Single Assignment (GSA) form To perform effective array flow analysis, symbolic manipulation of expressions is necessary since the computation of array regions often involves the equality and comparison tests between symbolic expressions. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes <ref> [3, 6, 4, 8, 10] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 7] or selective inlining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [4] <author> H. Cheong. </author> <title> Life Span Strategy A Compiler-Based Approach to Cache Coherence. </title> <booktitle> Proceedings of the 1992 International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Procedure calls introduce complications in most global program analysis and optimizations due to side effects and potential aliasing caused by parameter passing. Stale access detection [5, 8] is a compile time analysis technique to identify data references that may violate cache coherence in compile-directed coherence schemes <ref> [6, 4, 8] </ref>. By identifying these potentially stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. <p> The compiler reference marking algorithms developed here are general enough to be applicable to other compiler-directed coherence schemes <ref> [4, 6] </ref>. 2 1.1 Stale reference sequence First, let us look at the memory reference pattern leading to a stale data access at runtime. compiler. Such references are denoted as Time-Reads in the figure. We view the execution of a parallel program as a sequence of epochs. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes <ref> [3, 6, 4, 8, 10] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 7] or selective inlining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [5] <author> H. Cheong and A. Veidenbaum. </author> <title> Stale Data Detection and Coherence Enforcement Using Flow Analysis. </title> <booktitle> Proceedings of the 1988 International Conference on Parallel Processing, I, </booktitle> <address> Architecture:138-145, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Procedure calls introduce complications in most global program analysis and optimizations due to side effects and potential aliasing caused by parameter passing. Stale access detection <ref> [5, 8] </ref> is a compile time analysis technique to identify data references that may violate cache coherence in compile-directed coherence schemes [6, 4, 8]. <p> By identifying these potentially stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. In stale reference detection, procedure boundaries force all previous algorithms <ref> [5, 7] </ref> to use conservative approaches, such as cache invalidation or inlining, to avoid reference marking across procedure calls. However, both approaches have their own problems. Frequent invalidations at procedure call boundaries incur cold-start effects. <p> In addition, this also causes a problem at the beginning of each procedure since any global COMMON variables and formal parameters could have been previously modified before entering the procedure. To avoid such complications caused by procedure calls, previous algorithms <ref> [5, 7] </ref> use cache invalidation both at the beginning of a procedure and after each call site. Since the algorithms assume a clean cache at procedure boundaries, their analysis can guarantee the correctness of reference marking. <p> For a target reference which does not have a reaching definition inside a procedure, we issue a Time-Read with the minimum offset, implying that the referenced data item can be potentially modified before entering the procedure. This is an improvement over previous algorithms <ref> [5, 7] </ref> which use cache invalidation 10 at the beginning of a procedure since only global and formal variables are affected by the unknown context information. We propagate definitions through the flow graph and increment their offsets when they cross scheduling edges. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes [3, 6, 4, 8, 10] to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation <ref> [5, 7] </ref> or selective inlining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [6] <author> H. Cheong and A. Veidenbaum. </author> <title> A Cache Coherence Scheme with Fast Selective Invalidation. </title> <booktitle> Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Procedure calls introduce complications in most global program analysis and optimizations due to side effects and potential aliasing caused by parameter passing. Stale access detection [5, 8] is a compile time analysis technique to identify data references that may violate cache coherence in compile-directed coherence schemes <ref> [6, 4, 8] </ref>. By identifying these potentially stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. <p> The compiler reference marking algorithms developed here are general enough to be applicable to other compiler-directed coherence schemes <ref> [4, 6] </ref>. 2 1.1 Stale reference sequence First, let us look at the memory reference pattern leading to a stale data access at runtime. compiler. Such references are denoted as Time-Reads in the figure. We view the execution of a parallel program as a sequence of epochs. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes <ref> [3, 6, 4, 8, 10] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 7] or selective inlining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [7] <author> Lynn Choi and Pen-Chung Yew. </author> <title> Eliminating Stale Data References through Array Data-Flow Analysis. </title> <note> To appear in IEEE International Parallel Processing Symposium, </note> <month> April. </month> <year> 1996. </year>
Reference-contexts: By identifying these potentially stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. In stale reference detection, procedure boundaries force all previous algorithms <ref> [5, 7] </ref> to use conservative approaches, such as cache invalidation or inlining, to avoid reference marking across procedure calls. However, both approaches have their own problems. Frequent invalidations at procedure call boundaries incur cold-start effects. <p> To obtain more precise array access information, we compute the array region referenced by each array reference <ref> [7] </ref>. The interprocedural algorithm performs bottom-up and top-down analysis on the procedure call graph to exploit cache locality across procedure boundaries. First, the bottom-up side effect analysis eliminates side effects by summarizing the access information at each call site. <p> We have implemented both the intraprocedural and interprocedu-ral algorithms on the Polaris parallelizing compiler [11] and demonstrate the performance driven by these algorithms by running execution-driven simulations of two compiler-directed coherence schemes <ref> [8, 7] </ref> using Perfect benchmarks. The compiler reference marking algorithms developed here are general enough to be applicable to other compiler-directed coherence schemes [4, 6]. 2 1.1 Stale reference sequence First, let us look at the memory reference pattern leading to a stale data access at runtime. compiler. <p> This memory reference pattern is called a stale reference sequence, and the last read reference is called a potentially stale data reference <ref> [7] </ref>. In the example, the read references to X in epochs 3 and 4 can cause stale data accesses at runtime since the variable has been modified in epoch 2. <p> In addition, this also causes a problem at the beginning of each procedure since any global COMMON variables and formal parameters could have been previously modified before entering the procedure. To avoid such complications caused by procedure calls, previous algorithms <ref> [5, 7] </ref> use cache invalidation both at the beginning of a procedure and after each call site. Since the algorithms assume a clean cache at procedure boundaries, their analysis can guarantee the correctness of reference marking. <p> Frequent invalidations at procedure boundaries can degrade the cache performance substantially since it limits the scope of locality to be exploited within procedural boundaries. invalidation scheme (TPI) using an invalidation-based array data-flow algorithm <ref> [7] </ref> against the underlying machine with no cache coherence support (BASE) which does not cache shared data. The results shown are from our execution-driven simulations on Perfect benchmarks (see section 4 for more details). The miss rates are classified into sharing misses and nonsharing misses. <p> The performance results from our execution-driven simulations follow in section 4. Section 5 concludes the paper. 2 Intraprocedural Algorithm 2.1 Data-Flow Framework We use the following three techniques as a framework for our array data-flow analysis. A more detailed description can be found in <ref> [7] </ref>. * Regular Section Analysis The data-flow information propagated during the flow analysis are implemented as sets of data descriptors D, which consists of three data fields: name (D), subarray (D), and offset (D). <p> These references are called target references. A detailed array data-flow algorithm to find such target references is shown in <ref> [7] </ref>, and for the following discussion, we assume that those target references are already computed. 2.2 Stale reference detection The intraprocedural algorithm for stale reference detection is an improved version of the previous algorithm we developed in [7]. <p> A detailed array data-flow algorithm to find such target references is shown in <ref> [7] </ref>, and for the following discussion, we assume that those target references are already computed. 2.2 Stale reference detection The intraprocedural algorithm for stale reference detection is an improved version of the previous algorithm we developed in [7]. We refine the algorithm to eliminate cache invalidations by considering both side effects and hidden contexts at procedural boundaries. Each definition of a variable v, denoted as d v offset , is associated with an offset. <p> For a target reference which does not have a reaching definition inside a procedure, we issue a Time-Read with the minimum offset, implying that the referenced data item can be potentially modified before entering the procedure. This is an improvement over previous algorithms <ref> [5, 7] </ref> which use cache invalidation 10 at the beginning of a procedure since only global and formal variables are affected by the unknown context information. We propagate definitions through the flow graph and increment their offsets when they cross scheduling edges. <p> Compiler Algorithms We use three different compiler algorithms to generate memory operations for the compiler scheme (CP) and the two-phase invalidation scheme (TPI). 1. Invalidation-based intraprocedural algorithm (ALG1) The algorithm performs stale reference detection per-procedure basis <ref> [7] </ref>. To avoid the complications caused by unknown side effects, cache invalidation operations are inserted after each call site and at the beginning of a procedure. 2. A simple interprocedural algorithm with no cache invalidation (ALG2) Instead of the intraprocedural algorithm in section 2, we use a more sophisticated algorithm. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes [3, 6, 4, 8, 10] to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation <ref> [5, 7] </ref> or selective inlining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes [3, 6, 4, 8, 10] to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 7] or selective inlining <ref> [7] </ref> to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path. Inlining allows the most precise analysis but it is often prohibitive due to potential code size expansion as well as the compile time increase. <p> The results show that by avoiding cache invalidations, the intraprocedural algorithm eliminates up to 26.0% of the cache misses for a compiler-directed scheme compared to an existing invalidation-based algorithm <ref> [7] </ref>. With the full interprocedural analysis, up to 10.8% of additional cache misses can be removed.
Reference: [8] <author> Lynn Choi and Pen-Chung Yew. </author> <title> A Compiler-Directed Cache Coherence Scheme with Improved Intertask Locality. </title> <booktitle> Proceedings of the ACM/IEEE Supercomputing'94, </booktitle> <pages> pages 773-782, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Procedure calls introduce complications in most global program analysis and optimizations due to side effects and potential aliasing caused by parameter passing. Stale access detection <ref> [5, 8] </ref> is a compile time analysis technique to identify data references that may violate cache coherence in compile-directed coherence schemes [6, 4, 8]. <p> 1 Introduction Procedure calls introduce complications in most global program analysis and optimizations due to side effects and potential aliasing caused by parameter passing. Stale access detection [5, 8] is a compile time analysis technique to identify data references that may violate cache coherence in compile-directed coherence schemes <ref> [6, 4, 8] </ref>. By identifying these potentially stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. <p> We have implemented both the intraprocedural and interprocedu-ral algorithms on the Polaris parallelizing compiler [11] and demonstrate the performance driven by these algorithms by running execution-driven simulations of two compiler-directed coherence schemes <ref> [8, 7] </ref> using Perfect benchmarks. The compiler reference marking algorithms developed here are general enough to be applicable to other compiler-directed coherence schemes [4, 6]. 2 1.1 Stale reference sequence First, let us look at the memory reference pattern leading to a stale data access at runtime. compiler. <p> Second, the read reference to X (f (i)) in epoch 4 cannot be analyzed precisely at compile time due to the unknown index value. To overcome these limitations, we have proposed a hardware scheme, called the two-phase invalidation scheme that keeps track of the local cache states at runtime <ref> [8] </ref>. Two-phase invalidation scheme (TPI) In this scheme, each epoch is assigned a unique epoch number. <p> This limitation led us to develop more precise program analysis algorithms which can avoid such invalidations. In section 2, we first briefly describe our program representation methods: epoch flow graph <ref> [8] </ref>, array descriptors, and gated single assignment (GSA). Then, we present an improved intraprocedural stale reference marking algorithm which can detect stale data references in the presence of procedure calls without cache invalidation or inlining. <p> this 7 purpose, we use the gated single assignment (GSA) form [1] to treat arrays with different access regions as different symbolic variables. * Epoch Flow Graph This is a modified flow graph to represent the epoch boundary information as well as different control flows due to the parallel execution <ref> [8] </ref>. Figure 3 shows the epoch flow graph for a program example. Bold arcs denote scheduling edges, which represent epoch boundaries, while the remaining arcs denote normal control flow edges. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes <ref> [3, 6, 4, 8, 10] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 7] or selective inlining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [9] <author> Paul Havlak. </author> <title> Interprocedural Symbolic Analysis. </title> <type> Technical report, </type> <institution> Rice University, Dept. of Computer Science, </institution> <month> May </month> <year> 1994. </year> <type> Ph.D. Thesis. </type>
Reference-contexts: The notion of the subarray we use is an extension to the regular section used in <ref> [3, 9, 14] </ref>. * Gated Single Assignment (GSA) form To perform effective array flow analysis, symbolic manipulation of expressions is necessary since the computation of array regions often involves the equality and comparison tests between symbolic expressions.
Reference: [10] <author> A. Louri and H. Sung. </author> <title> A Compiler Directed Cache Coherence Scheme with Fast and Parallel Explicit Invalidation. </title> <booktitle> Proceedings of the 1992 International Conference on Parallel Processing, I, </booktitle> <address> Architecture:2-9, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which limit existing compiler-directed cache coherence schemes <ref> [3, 6, 4, 8, 10] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 7] or selective inlining [7] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [11] <author> D. A. Padua, R. Eigenmann, J. Hoeflinger, P. Peterson, P. Tu, S. Weatherford, and K. Faign. </author> <title> Polaris: A New-Generation Parallelizing Compiler for MPPs. In CSRD Rept. No. </title> <type> 1306. </type> <institution> Univ. of Illinois at Urbana-Champaign., </institution> <month> June, </month> <year> 1993. </year> <month> 24 </month>
Reference-contexts: This two-pass analysis avoids redundant computation by performing incremental update of reference marking with a minimal number of computations per procedure. We have implemented both the intraprocedural and interprocedu-ral algorithms on the Polaris parallelizing compiler <ref> [11] </ref> and demonstrate the performance driven by these algorithms by running execution-driven simulations of two compiler-directed coherence schemes [8, 7] using Perfect benchmarks. <p> In addition, the top-down pass updates the reference marking result of the side effect analysis incrementally, and thus minimize the compilation time. We have implemented these algorithms on the Polaris parallelizing compiler <ref> [11] </ref>, and demonstrated the performance driven by the new compiler algorithms by running execution-driven simulations of five Perfect benchmarks. The results show that by avoiding cache invalidations, the intraprocedural algorithm eliminates up to 26.0% of the cache misses for a compiler-directed scheme compared to an existing invalidation-based algorithm [7].
Reference: [12] <author> D. K. Poulsen and P.-C. Yew. </author> <title> Execution-Driven Tools for Parallel Simulation of Parallel Architectures and Applications. </title> <booktitle> Proceedings of the Supercomputing 93, </booktitle> <pages> pages 860-869, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: After the compiler marking, we instrument the benchmarks to generate simulation events, which include global and local memory accesses, parallel loop setup and scheduling operations, and synchronization operations. Simulation Execution-driven simulations <ref> [12] </ref> are used to verify the compiler algorithm and to evaluate the performance of our proposed coherence scheme. All the simulations assume a 16-processor, physically distributed shared-memory multiprocessor similar to Cray T3D. Each processor has a 64-KB direct-mapped lock-up free data cache with 4-word cache line.
Reference: [13] <author> J. Torrellas, M. S. Lam, and J. L. Hennessy. </author> <title> False Sharing and Spatial Locality in Multiprocessor Caches. </title> <journal> IEEE Transactions on Computers, C-43 No.6:651-663, </journal> <month> June </month> <year> 1994. </year>
Reference-contexts: Code optimizations usually decrease the frequency of private references. This is because private references are eliminated by register allocation and other optimizations, while the need for shared data 16 consistency prevents existing compilers from optimizing shared data <ref> [13] </ref>. However, code gen-eration steps such as address calculation will increase the frequency of private references due to spill codes. Since these back-end compiler issues usually affect only private references, we ignore them in our simulations as we are interested in comparing different coherence schemes for shared data references.
Reference: [14] <author> Peng Tu. </author> <title> Automatic Array Privatization and Demand-Driven Symbolic Analysis. </title> <type> Technical report, </type> <institution> Univ. of Illinois at Urbana-Champaign, Dept. of Computer Science, </institution> <year> 1995. </year> <type> Ph.D. Thesis. </type>
Reference-contexts: The notion of the subarray we use is an extension to the regular section used in <ref> [3, 9, 14] </ref>. * Gated Single Assignment (GSA) form To perform effective array flow analysis, symbolic manipulation of expressions is necessary since the computation of array regions often involves the equality and comparison tests between symbolic expressions.
References-found: 14

