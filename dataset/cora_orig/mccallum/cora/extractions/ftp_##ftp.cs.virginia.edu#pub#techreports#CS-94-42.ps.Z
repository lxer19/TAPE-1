URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-94-42.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Targetspecific Global Code Improvement: Principles and Applications  
Address: Charlottesville, VA 22903  
Affiliation: Department of Computer Science University of Virginia  
Abstract: Current and future high-performance systems require language processors that can generate code that fully exploits the power of the underlying architecture. A key and necessary component of such language processors is a global code improver. This article describes the key principles behind the design and implementation of a global code improver that has been use to construct several high-quality compilers and other program transformation and analysis tools. The code improver, called vpo , employs a paradigm of compilation that has proven to be flexible and adaptableall code improving transformations are performed on a targetspecific representation of the program. The aggressive use of this paradigm yields a code improver with several valuable properties. Four properties stand out. First, vpo is language and compiler independent. That is, it has been used to implement compilers for several different computer languages. For the C programming language, it has been used with several front ends each of which generates a different intermediate language. Second, because all code improvements are applied to a single low-level intermediate representation, phase ordering programs are minimized. Third, vpo is easily retargeted and handles a wide variety of architectures. In particular, vpo s structure allows new architectures and new implementations of existing architectures to be accommodated quickly and easily. Fourth and finally, because of its flexible structure, vpo has several other interesting uses in addition to its primary use in an optimizing compiler. This article describes the principles that have driven the design of vpo and the implications of these principles on vpo s implementation. The article concludes with a brief description of vpo s use as a back end with front ends for several different languages, and its use as a key component for the realization of several other applications. 
Abstract-found: 1
Intro-found: 1
Reference: [ALEX93] <author> Alexander, M. J., Bailey, M. W., Childers, B. R., Davidson, J. W., and Jinturkar, S., </author> <title> Memory Bandwidth Optimizations for Wide-Bus Machines, </title> <booktitle> in Proceedings of the 26th Annual Hawaii International Conference on System Sciences , January 1993, </booktitle> <pages> pp. 401423. </pages>
Reference-contexts: With some extensions the system can be used to gather information so that execution times of straight-line code sequences can be predicted in hard-real-time systems [HARM92]. vpo s framework also permits analysis of the instruction set architecture of uninstantiated architectures <ref> [DAVI90, DAVI91b, ALEX93] </ref>. This allows early design decisions to be evaluated using applications that will be run on the architecture. Normally the last step of the code improvement process is to translate the RTLs to assembly language for the target machine.
Reference: [ARNO94] <author> Arnold, R., Mueller, F., Whalley, D., and Harmon, M., </author> <title> Bounding Worst-Case Instruction Cache Performance, </title> <booktitle> to appear in Proceedings of the Twelveth IEEE Real-Time Systems Symposium , San Juan, </booktitle> <address> Puerto Rico, </address> <month> December </month> <year> 1994. </year> <month> - 13 </month> - 
Reference-contexts: One difficulty with tracedriven simulation is the expense of gathering traces. vpo supports the efficient gathering and analysis of traces [WHAL93]. (Note: Details to be included in full paper. We also describe vpos use in developing hard-real-time systems <ref> [ARNO94, MUEL94] </ref>.) - 12 - 5 Related Work Auslander and Hopkins describe the implementation of the PL.8 compiler [AUSL82]. The PL.8 code improver employed phase iteration, and the authors also noted that this greatly simplified the implementation of the various code improving transformations.
Reference: [AUSL82] <author> Auslander, M. and Hopkins, M., </author> <title> An Overview of the PL.8 Compiler, </title> <booktitle> Proceedings of the SIGPLAN 82 Symposium on Compiler Construction , Boston, </booktitle> <address> MA, </address> <month> June </month> <year> 1982, </year> <pages> pp. 2231. </pages>
Reference-contexts: We also describe vpos use in developing hard-real-time systems [ARNO94, MUEL94].) - 12 - 5 Related Work Auslander and Hopkins describe the implementation of the PL.8 compiler <ref> [AUSL82] </ref>. The PL.8 code improver employed phase iteration, and the authors also noted that this greatly simplified the implementation of the various code improving transformations. While the PL.8 compiler used a low-level intermediate language, it did not represent target machine instructions.
Reference: [BENE94a] <author> Benitez, M. E., </author> <title> Retargetable Register Allocation , Ph.D. </title> <type> Dissertation, </type> <institution> University of Virginia, </institution> <year> 1994. </year>
Reference-contexts: The part of RTL that encodes machine instructions is based on the ISP notation of Bell and Newell. Original RTL descriptions were ad hoc [DAVI85]. Over the years, this portion of the RTL representation has evolved into a compact, well-defined language for describing the instruction sets of machines <ref> [BENE94a] </ref>. Over 20 architectures have been described. However, to be most effective, a global code improver needs more than target machine information. It needs control over the allocation of objects and information about the source program. Most code improvers do not participate in the placement of data.
Reference: [BENE94b] <author> Benitez, M. E. and Davidson, J. W., </author> <title> The Advantages of MachineDependent Global Optimization, </title> <booktitle> in Proceedings of the 1994 Conference on Programming Languages and Systems Architectures , Zurich, </booktitle> <address> Switzerland, </address> <month> March </month> <year> 1994, </year> <pages> pp. 105124. </pages>
Reference-contexts: A number of vpo s code improvement algorithms have been presented elsewhere <ref> [DAVI94, BENE94b, BENE91, DAVI86] </ref>. This paper describes the principles that have driven the design of vpo and the implications of these principles on vpo s architecture. <p> Unfortunately, these code improvements are not machine-independent. For example, loop-invariant code motion and induction variable elimination are machine dependent because their effective application requires knowledge of the addressing modes available on the target machine <ref> [BENE94b] </ref>. Similarly, common subexpression elimination and evaluation order determination are machine dependent because their effective application requires knowledge of the target machines instruction set [DAVI84a, DAVI86]. Effective constant propagation requires knowledge of the calling convention, the machines data paths, and the instruction set support for dealing with constants [BENE94b]. <p> target machine <ref> [BENE94b] </ref>. Similarly, common subexpression elimination and evaluation order determination are machine dependent because their effective application requires knowledge of the target machines instruction set [DAVI84a, DAVI86]. Effective constant propagation requires knowledge of the calling convention, the machines data paths, and the instruction set support for dealing with constants [BENE94b].
Reference: [BENE91] <author> Benitez, M. E. and Davidson, J. W., </author> <title> Code Generation for Streaming: an Access/Execute Mechanism, </title> <booktitle> in Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> April </month> <year> 1991, </year> <pages> pp. 132141. </pages>
Reference-contexts: A number of vpo s code improvement algorithms have been presented elsewhere <ref> [DAVI94, BENE94b, BENE91, DAVI86] </ref>. This paper describes the principles that have driven the design of vpo and the implications of these principles on vpo s architecture.
Reference: [CHOW83] <author> Chow, F. C., </author> <title> A Portable Machine-Independent Global OptimizerDesign and Measurements , Ph.D. </title> <type> Dissertation, </type> <institution> Stanford University, </institution> <year> 1983. </year>
Reference-contexts: In this organization, there are two intermediate languages. The high-level intermediate language (HIL) corresponds to the intermediate language often used in a compiler with a traditional organization <ref> [CHOW83, NELS79, TANE82] </ref>. The HIL serves to make the front end machine independent so that it can be used for a variety of target architectures with as little modification as possible. The low-level intermediate language (LIL) is RTL. <p> The front end does some low-cost, high-yield code improvements [HANS83]. This in no way hinders the operation of vpo . It has also been used with an ANSI C front end developed by Hewlett-Packard Corporation that emits HPcode-Plus, a proprietary intermediate language similar to MIPS Ucode <ref> [CHOW83] </ref>, and an ANSI C front end which produces trees from the Edison Design Group. In addition to the C compilers, vpo has been used to produce global optimizing compilers for several other imperative languages. It has been used to produce a validated Ada compiler.
Reference: [CYTR91] <author> Cytron, R., Ferrante, J., Rosen, B. K., Wegman, M. N., and Zadeck, F. K., </author> <title> Efficiently Computing Static Single Assignment Form and the Control Dependence Graph, </title> <booktitle> ACM Transactions on Programming Languages and Systems 2 (2), </booktitle> <pages> pp. 451490. </pages>
Reference-contexts: Following these actions, local data flow analysis is performed to set up defuse information. Using this information, a preliminary pass of instruction selection is done. At this point, the preliminary analysis necessary for creating the Static Single Assignment form <ref> [CYTR91] </ref> is performed (lines 710). We have found the SSA form and the RTL representation to be a particularly good match. Following the SSA construction, global defuse information is collected and instruction selection is reinvoked. At this point, local register allocation is performed. This maps any pseudo-registers to hardware registers.
Reference: [DAVI94] <author> Davidson, J. W. and Jinturkar, S., </author> <title> Memory Access Coalescing: A Technique for Eliminating Redundant Memory Accesses, </title> <booktitle> Proceedings of the SIGPLAN 94 Symposium on Programming Language Design and Implementation, </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1994, </year> <pages> pp. 186195. </pages>
Reference-contexts: A number of vpo s code improvement algorithms have been presented elsewhere <ref> [DAVI94, BENE94b, BENE91, DAVI86] </ref>. This paper describes the principles that have driven the design of vpo and the implications of these principles on vpo s architecture. <p> For global data, for example, the code generator simply emits the necessary assembly language directives that allocate space for program objects without regard to their relative location. However, for many of todays high performance processors, proper location of data can affect overall performance <ref> [DAVI94] </ref>. In many cases, a global code improver, using information gathered during its data-flow analysis phase, can place data so that it can be referenced more efficiently. Similarly, to be effective and perform safe code transformations, a code - 6 - improver needs some information from the source program.
Reference: [DAVI91a] <author> Davidson, J. W. and Whalley, D. B., </author> <title> A Design Environment for Addressing Architecture and Compiler Interactions, </title> <journal> Microprocessors and Microsystems, </journal> <volume> 15 (9), </volume> <month> November </month> <year> 1991, </year> <pages> pp. 459472. </pages>
Reference: [DAVI91b] <author> Davidson, J. W. and Whalley, D. B. </author> <title> Methods for Saving and Restoring Register Values across Function Calls, </title> <booktitle> SoftwarePractice & Experience 21 (2), </booktitle> <month> February </month> <year> 1991, </year> <pages> pp. 149165. </pages>
Reference-contexts: With some extensions the system can be used to gather information so that execution times of straight-line code sequences can be predicted in hard-real-time systems [HARM92]. vpo s framework also permits analysis of the instruction set architecture of uninstantiated architectures <ref> [DAVI90, DAVI91b, ALEX93] </ref>. This allows early design decisions to be evaluated using applications that will be run on the architecture. Normally the last step of the code improvement process is to translate the RTLs to assembly language for the target machine.
Reference: [DAVI90] <author> Davidson, J. W. and Whalley, D. B., </author> <title> Reducing the Cost of Branches by Using Registers, </title> <booktitle> Proceedings of the 17th International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1990, </year> <pages> pp. 182191. </pages>
Reference-contexts: With some extensions the system can be used to gather information so that execution times of straight-line code sequences can be predicted in hard-real-time systems [HARM92]. vpo s framework also permits analysis of the instruction set architecture of uninstantiated architectures <ref> [DAVI90, DAVI91b, ALEX93] </ref>. This allows early design decisions to be evaluated using applications that will be run on the architecture. Normally the last step of the code improvement process is to translate the RTLs to assembly language for the target machine.
Reference: [DAVI86] <author> Davidson, J. W., </author> <title> A Retargetable Instruction Reorganizer, </title> <booktitle> Proceedings of the SIGPLAN 86 Symposium on Compiler Construction 21 (7), </booktitle> <month> June </month> <year> 1986, </year> <pages> pp. 23241. </pages>
Reference-contexts: A number of vpo s code improvement algorithms have been presented elsewhere <ref> [DAVI94, BENE94b, BENE91, DAVI86] </ref>. This paper describes the principles that have driven the design of vpo and the implications of these principles on vpo s architecture. <p> Similarly, common subexpression elimination and evaluation order determination are machine dependent because their effective application requires knowledge of the target machines instruction set <ref> [DAVI84a, DAVI86] </ref>. Effective constant propagation requires knowledge of the calling convention, the machines data paths, and the instruction set support for dealing with constants [BENE94b].
Reference: [DAVI85] <author> Davidson, J. W., </author> <title> Simple Machine Description Grammars Technical Report TR85-22, </title> <institution> Department of Computer Science, University of Virginia, </institution> <address> Charlottesville, VA., </address> <month> November </month> <year> 1985. </year>
Reference-contexts: RTL consists of a representation for machine instructions and a method of conveying source language information to vpo . The part of RTL that encodes machine instructions is based on the ISP notation of Bell and Newell. Original RTL descriptions were ad hoc <ref> [DAVI85] </ref>. Over the years, this portion of the RTL representation has evolved into a compact, well-defined language for describing the instruction sets of machines [BENE94a]. Over 20 architectures have been described. However, to be most effective, a global code improver needs more than target machine information.
Reference: [DAVI84a] <author> Davidson, J. W. and Fraser, C. W., </author> <title> Code Selection through Object Code Optimization, </title> <journal> ACM Transactions on Programming Languages and Systems 6 (4), </journal> <month> October </month> <year> 1984, </year> <pages> pp. 732. </pages>
Reference-contexts: Similarly, common subexpression elimination and evaluation order determination are machine dependent because their effective application requires knowledge of the target machines instruction set <ref> [DAVI84a, DAVI86] </ref>. Effective constant propagation requires knowledge of the calling convention, the machines data paths, and the instruction set support for dealing with constants [BENE94b]. <p> Perhaps the most closely related work is the GNU C compiler [STAL92]. This is not surprising as both the GNU C compiler ( gcc ) and vpo are descendents of a compiler that used RTLs and performed local transformations <ref> [DAVI81, DAVI84a] </ref>. While gcc provides support for multiple front ends such as C, C++, and Objective C, these front ends are tightly integrated with the compiler. No independently developed front end has been used with gcc s code improver.
Reference: [DAVI84b] <author> Davidson, J. W. and Fraser, C. W., </author> <title> Automatic Generation of Peephole Optimizations, </title> <booktitle> in Proceedings of the SIGPLAN 84 Symposium on Compiler Construction , Montreal, </booktitle> <address> Canada, </address> <month> June </month> <year> 1984, </year> <pages> pp. 111116. </pages>
Reference-contexts: First, it is impossible, a priori, to determine what post-code generation transformations might be made and construct a comprehensive set of patterns. Second, the ad-hoc approach hampers retargetability. Each new target machine requires a new pattern file. Automatically generating a set of patterns is possible, but suffers from incompleteness <ref> [DAVI84b] </ref>. Third, global program information has been lost. Typical peephole optimizers operate locally on small sections of code. The ability to do instruction selection on-demand solves these problems.
Reference: [DAVI81] <author> Davidson, J. W., </author> <title> Simplifying Code Generation through Object Code Optimization , Ph.D. </title> <type> Dissertation, </type> <institution> University of Arizona, </institution> <year> 1981. </year>
Reference-contexts: Perhaps the most closely related work is the GNU C compiler [STAL92]. This is not surprising as both the GNU C compiler ( gcc ) and vpo are descendents of a compiler that used RTLs and performed local transformations <ref> [DAVI81, DAVI84a] </ref>. While gcc provides support for multiple front ends such as C, C++, and Objective C, these front ends are tightly integrated with the compiler. No independently developed front end has been used with gcc s code improver.
Reference: [FRAS95] <author> Fraser, C. W. and Hanson, D. R., </author> <title> A Retargetable C Compiler: Design and Implementation , Benjamin Cummings, </title> <address> Redwood City, CA, </address> <year> 1995. </year>
Reference-contexts: Indeed, it has been used with a variety of C front ends each of which generates a different intermediate representation. It has been used with lcc s front end (which produces DAGs) <ref> [FRAS95] </ref>. In this case, the middle end (see Figure 1b) traverses the DAGs emitting naive RTLs for the target machine. Work is underway with lcc to emit RTLs via an IBURG-produced code generator. The work with lcc s front end illustrates vpo s flexibility.
Reference: [HANS83] <author> Hanson, D. R., </author> <title> Simple code optimizations, </title> <booktitle> SoftwarePractice & Experience 15 (12), </booktitle> <pages> pp. 1205 1212. </pages>
Reference-contexts: Work is underway with lcc to emit RTLs via an IBURG-produced code generator. The work with lcc s front end illustrates vpo s flexibility. The front end does some low-cost, high-yield code improvements <ref> [HANS83] </ref>. This in no way hinders the operation of vpo .
Reference: [HARM92] <author> Harmon, M. G., Baker, T. P. and Whalley, D. B., </author> <title> A Retargetable Technique for Predicting Execution Time, </title> <booktitle> Proceedings of the Thirteenth IEEE Real-Time Systems Symposium , Phoenix, </booktitle> <address> AZ, </address> <month> December </month> <year> 1992, </year> <pages> pp. 6867. </pages>
Reference-contexts: Implementation and performance details of the system can be found in WHAL90 and DAVI91a. With some extensions the system can be used to gather information so that execution times of straight-line code sequences can be predicted in hard-real-time systems <ref> [HARM92] </ref>. vpo s framework also permits analysis of the instruction set architecture of uninstantiated architectures [DAVI90, DAVI91b, ALEX93]. This allows early design decisions to be evaluated using applications that will be run on the architecture.
Reference: [HENN90] <author> Hennessy, J. L. and Patterson, D. A., </author> <title> Computer Architecture: </title> <publisher> a quantitative approach , Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA, </address> <year> 1990. </year> <month> - 14 </month> - 
Reference-contexts: It has been reported that vpo is able to reduce this to a factor of three. ( Note: We are getting permission to supply more details) . 4.3 Architecture and performance evaluation Todays high-performance processors rely heavily on optimizing compiler technology to produce code that exploits the processors capabilities <ref> [HENN90] </ref>. To explore and evaluate new architectures, it has become crucial to have access to optimizing compiler technology. As shown above, vpo provides this access.
Reference: [HUGU87] <author> Huguet, M., Lang, T., and Tamir, Y., </author> <title> A Block-and-Actions Generator as an Alternative to a Simulator for Collecting Architecture Measurements, </title> <booktitle> Proceedings of the SIGPLAN 87 Symposium on Interpreters and Interpretive Techniques, </booktitle> <address> St. Paul, MN, </address> <month> June </month> <year> 1987, </year> <pages> pp. 1425. </pages>
Reference-contexts: This technique is often used when the architecture in question does not yet exist, or is not yet stable and available for production use. Depending on the level of the simulation, programs can run 100 to 500 times slower than directly-executed code <ref> [HUGU87] </ref>. Tracing is another alternative one can use if the architecture being measured exists, is accessible, and tracing is possible on that machine. Tracing can be even slower than simulation. Because of the large performance penalties with these methods, the tendency is to use small programs with small data sets.
Reference: [JOHN86] <author> Johnson, M. S. and Miller, T. C., </author> <title> Effectiveness of a Machine-Level, Global Optimizer, </title> <booktitle> Proceedings of the SIGPLAN 86 Symposium on Compiler Construction , Palo Alto, </booktitle> <address> CA, </address> <month> June </month> <year> 1986, </year> <pages> pp. 99108. </pages>
Reference-contexts: Consequently, as Auslander and Hopkins note, the compiler is biased in favor of target machines that are similar to the regular and simple register-to-register intermediate language. Johnson and Miller describe a global code improver that operated at the machine-code level <ref> [JOHN86] </ref>. While the code improver supported several front ends, it only generated code for the Hewlett-Packard Precision family of machines.
Reference: [MCFA91] <author> McFarling, S., </author> <title> Procedure Merging with Instruction Caches, </title> <booktitle> Proceedings of the ACM SIGPLAN 91 Conference on Programming Language Design and Implementation , Toronto, </booktitle> <address> Ontario, </address> <month> June, </month> <year> 1991, </year> <pages> pp. 7179. </pages>
Reference-contexts: Obviously, code improvements such as register allocation and instruction scheduling are machine dependent. Somewhat less obvious, but no less machine dependent are inline function expansion and loop unrolling. Inline function expansion can be performed most effectively when details of the target machines instruction cache is available <ref> [MCFA89, MCFA91] </ref>. Similarly, when unrolling a loop, the unroll factor depends on the number of target machine registers available, characteristics of the target machines jump instructions, and characteristics of the instruction pipeline as well as the size of the instruction cache [WEIS87].
Reference: [MCFA89] <author> McFarling, S., </author> <title> Program Optimization for Instruction Caches, </title> <booktitle> Proceedings of the 3rd International Conference on Architectural Support for Programming Languages and Operating Systems , Boston, </booktitle> <address> MA, </address> <month> April </month> <year> 1989, </year> <pages> pp. 183191. </pages>
Reference-contexts: Obviously, code improvements such as register allocation and instruction scheduling are machine dependent. Somewhat less obvious, but no less machine dependent are inline function expansion and loop unrolling. Inline function expansion can be performed most effectively when details of the target machines instruction cache is available <ref> [MCFA89, MCFA91] </ref>. Similarly, when unrolling a loop, the unroll factor depends on the number of target machine registers available, characteristics of the target machines jump instructions, and characteristics of the instruction pipeline as well as the size of the instruction cache [WEIS87].
Reference: [MUEL94] <author> Mueller, F., </author> <title> Static Cache Simulation and Its Application , Ph.D. </title> <type> Dissertation, </type> <institution> Florida State University, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: One difficulty with tracedriven simulation is the expense of gathering traces. vpo supports the efficient gathering and analysis of traces [WHAL93]. (Note: Details to be included in full paper. We also describe vpos use in developing hard-real-time systems <ref> [ARNO94, MUEL94] </ref>.) - 12 - 5 Related Work Auslander and Hopkins describe the implementation of the PL.8 compiler [AUSL82]. The PL.8 code improver employed phase iteration, and the authors also noted that this greatly simplified the implementation of the various code improving transformations.
Reference: [MUEL92] <author> Mueller, F. and Whalley, D. B., </author> <title> Avoiding Unconditional Jumps by Code Replication, </title> <booktitle> Proceedings of the SIGPLAN 92 Conference on Programming Language Design and Implementation , San Francisco, </booktitle> <address> CA, </address> <month> June </month> <year> 1992, </year> <pages> pp. 322330. </pages>
Reference-contexts: For example, most machines support register-to-register copies, register indirect addressing mode, and register-to-register ALU operations. A third advantage is that it is very simple to add new code improvements <ref> [MUEL92] </ref>. This advantage should not be taken Line Line 1. proc Improve is 2. BuildControlFlowGraph () 3. ControlFlowTransformations () 4. SetLocalLinks () 5. InstructionSelection () 6. EvaluationOrderDetermination () 7. BuildDominatorTree () 8. FindDominanceFrontiers 9. LiveVariableAnalysis () 10. BuildMinimalSSAForm () 11. SetGlobalLinks () 12. InstructionSelection () 13.
Reference: [NELS79] <author> Nelson, P. A., </author> <title> A Comparison of PASCAL Intermediate Languages, </title> <booktitle> Proceedings of the SIGPLAN Symposium on Compiler Construction , Denver, </booktitle> <publisher> CO, </publisher> <month> August </month> <year> 1979, </year> <pages> pp. </pages> <year> 208213. </year>
Reference-contexts: In this organization, there are two intermediate languages. The high-level intermediate language (HIL) corresponds to the intermediate language often used in a compiler with a traditional organization <ref> [CHOW83, NELS79, TANE82] </ref>. The HIL serves to make the front end machine independent so that it can be used for a variety of target architectures with as little modification as possible. The low-level intermediate language (LIL) is RTL.
Reference: [SMIT82] <author> Smith, A. J., </author> <title> Cache Memories, </title> <booktitle> Computing Surveys 14 (3), </booktitle> <pages> pp. 473530. </pages>
Reference-contexts: An increasingly important aspect of machine design is the construction of a memory hierarchy that meets the processors demand for instructions and data. One technique for evaluating memory hierarchy performance is to use tracedriven simulation <ref> [SMIT82] </ref>. In this approach, traces of the addresses fetched by programs are captured and used to simulate the cache or memory system. Alternative designs can be simulated to determine what gives the best performance for a particular design.
Reference: [STAL92] <author> Stallman, R., </author> <title> Using and Porting GNU CC , Free Software Foundation, </title> <year> 1992. </year>
Reference-contexts: Much like vpo , the code improver relied on the front ends to collect and pass information about the set of memory locations actually or potentially touched by each variable reference or pointer dereference. Perhaps the most closely related work is the GNU C compiler <ref> [STAL92] </ref>. This is not surprising as both the GNU C compiler ( gcc ) and vpo are descendents of a compiler that used RTLs and performed local transformations [DAVI81, DAVI84a].
Reference: [TANE82] <author> Tanenbaum, A. S., Staveren, H. V., and Stevenson, J. W., </author> <title> Using Peephole Optimization on Intermediate Code, </title> <booktitle> Transactions on Programming Languages and Systems 4 (1), </booktitle> <month> January </month> <year> 1982, </year> <pages> pp. 2136. </pages>
Reference-contexts: In this organization, there are two intermediate languages. The high-level intermediate language (HIL) corresponds to the intermediate language often used in a compiler with a traditional organization <ref> [CHOW83, NELS79, TANE82] </ref>. The HIL serves to make the front end machine independent so that it can be used for a variety of target architectures with as little modification as possible. The low-level intermediate language (LIL) is RTL.
Reference: [WEIS87] <author> Weiss, S. and Smith, J. E., </author> <title> A Study of Scalar Compilation Techniques for Pipelined Supercomputers, </title> <booktitle> Proceedings of the Second International Conference on Architectural Support for Programming Languages and Operating Systems , Palo Alto, </booktitle> <address> CA, </address> <month> October </month> <year> 1987, </year> <pages> pp. 105109. </pages>
Reference-contexts: Similarly, when unrolling a loop, the unroll factor depends on the number of target machine registers available, characteristics of the target machines jump instructions, and characteristics of the instruction pipeline as well as the size of the instruction cache <ref> [WEIS87] </ref>. Machine-independent code improvements are those that do not require specific knowledge of the target machine, and they can be applied effectively independently of machinedependent transformations.
Reference: [WHAL94] <author> Whalley, D. B., </author> <title> Automatic Isolation of Compiler Errors, </title> <note> to appear in ACM Transactions on Programming Languages and Systems </note> . 
Reference-contexts: All code improvements are important sometime. Consequently, the code improver must be improved and enhanced constantly to keep pace with innovations in computer architecture and to be usable in a variety of application domains. A final advantage is that it is possible to automate debugging vpo <ref> [WHAL94] </ref>. 4 Applications 4.1 Retargetable Compilers Obviously, the primary application of vpo is to build optimizing compilers, and it has proven to be very successful.
Reference: [WHAL93] <author> Whalley, D. B., </author> <title> Techniques for Fast Cache Performance Evaluation, </title> <booktitle> SoftwarePractice & Experience 23 (1), </booktitle> <pages> pp. 95118. </pages>
Reference-contexts: Alternative designs can be simulated to determine what gives the best performance for a particular design. One difficulty with tracedriven simulation is the expense of gathering traces. vpo supports the efficient gathering and analysis of traces <ref> [WHAL93] </ref>. (Note: Details to be included in full paper. We also describe vpos use in developing hard-real-time systems [ARNO94, MUEL94].) - 12 - 5 Related Work Auslander and Hopkins describe the implementation of the PL.8 compiler [AUSL82].
Reference: [WHAL90] <author> Whalley, D. B., </author> <title> Ease: An Environment for Architecture Study and Experimentation, </title> <type> Ph.D. Dissertation, </type> <institution> University of Virginia, </institution> <year> 1990. </year>
References-found: 35

