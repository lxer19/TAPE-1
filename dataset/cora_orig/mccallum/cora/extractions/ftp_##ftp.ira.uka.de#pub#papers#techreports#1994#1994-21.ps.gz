URL: ftp://ftp.ira.uka.de/pub/papers/techreports/1994/1994-21.ps.gz
Refering-URL: http://wwwipd.ira.uka.de/~prechelt/
Root-URL: 
Title: Proben1 A Set of Neural Network Benchmark Problems and Benchmarking Rules  
Author: Lutz Prechelt 
Address: 76128 Karlsruhe, Germany  
Affiliation: Fakultat fur Informatik Universitat Karlsruhe  
Pubnum: Technical Report  
Email: (prechelt@ira.uka.de)  
Phone: ++49/721/608-4068, Fax: ++49/721/694092  
Date: September 30, 1994  21/94  
Abstract: Proben1 is a collection of problems for neural network learning in the realm of pattern classification and function approximation plus a set of rules and conventions for carrying out benchmark tests with these or similar problems. Proben1 contains 15 data sets from 12 different domains. All datasets represent realistic problems which could be called diagnosis tasks and all but one consist of real world data. The datasets are all presented in the same simple format, using an attribute representation that can directly be used for neural network training. Along with the datasets, Proben1 defines a set of rules for how to conduct and how to document neural network benchmarking. The purpose of the problem and rule collection is to give researchers easy access to data for the evaluation of their algorithms and networks and to make direct comparison of the published results feasible. This report describes the datasets and the benchmarking rules. It also gives some basic performance measures indicating the difficulty of the various problems. These measures can be used as baselines for comparison. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Yann Le Cun, John S. Denker, and Sara A. Solla. </author> <title> Optimal brain damage. </title> <booktitle> In [22], </booktitle> <pages> pages 598-605, </pages> <year> 1990. </year>
Reference-contexts: This measure is useful because it is independent of a particular machine and implementation. Forward and backward propagation counts individually, for certain algorithms that require more than one quantity to be backwardly propagated through each connection such as <ref> [1, 13] </ref>, each quantity counts as one traversal at each connection. Actual weight update steps also count as one traversal per updated connection. If possible report your training times using the connection traversal measure.
Reference: [2] <author> T.G. Dietterich and G. Bakiri. </author> <title> Error-correcting output codes: A general method for improving multiclass inductive learning programs. </title> <booktitle> In Proc. of the 9th National Conference of Artificial Intelligence (AAAI), </booktitle> <pages> pages 572-577, </pages> <address> Anaheim, CA, 1991. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: The input and output representations used in Proben1 are certainly not optimal, but they are meant to be good or at least reasonable ones. Differences in problem representation, though, can make for large differences in the performance obtained (see for instance <ref> [2] </ref>), so be sure to specify your representation precisely. 2.5 Training algorithm Obviously, an exact specification of the training algorithm used is essential.
Reference: [3] <author> Scott E. Fahlman. </author> <title> An empirical study of learning speed in back-propagation networks. </title> <type> Technical Report CMU-CS-88-162, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA 15213, </address> <month> September </month> <year> 1988. </year>
Reference-contexts: Other training problems that were often used in the 1980s are the generalized XOR problem (n-bit parity), the n-bit encoder, the symmetry problem, the T-C problem, the 2-clumps problem, and others <ref> [3, 18] </ref>. <p> This value can be misleading, because the computational cost of one epoch can differ significantly from one algorithm or network to another. It is nevertheless fine to present the epoch counts in addition to other measures. Regarding non-converging runs <ref> [3] </ref>, the values you report should reflect the actual amount of computation time that was spent. This means that your algorithm should define some stopping or restarting criterion and the sum of all computation actually performed before and after the restart (s) should be reported as the training time.
Reference: [4] <author> Scott E. Fahlman and Christian Lebiere. </author> <title> The cascade-correlation learning architecture. </title> <type> Technical Report CMU-CS-90-100, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA 15213, </address> <month> February </month> <year> 1990. </year>
Reference-contexts: Later works used still other synthetic problems which can not be exactly solved so easily. Instances are the two spirals problem <ref> [4, 5, 10] </ref> or the three discs problem [19]. The problem with these problems 1.5 Related work 7 is, similar to the ones mentioned above, that we know a-priori that a simple exact solution exists | at least when using the right framework to express it.
Reference: [5] <author> Scott E. Fahlman and Christian Lebiere. </author> <booktitle> The Cascade-Correlation learning architecture. In [22], </booktitle> <pages> pages 524-532, </pages> <year> 1990. </year> <note> 38 REFERENCES </note>
Reference-contexts: Later works used still other synthetic problems which can not be exactly solved so easily. Instances are the two spirals problem <ref> [4, 5, 10] </ref> or the three discs problem [19]. The problem with these problems 1.5 Related work 7 is, similar to the ones mentioned above, that we know a-priori that a simple exact solution exists | at least when using the right framework to express it.
Reference: [6] <author> William Finnoff, Ferdinand Hergert, and Hans Georg Zimmermann. </author> <title> Improving model selection by nonconvergent methods. </title> <booktitle> Neural Networks, </booktitle> <volume> 6 </volume> <pages> 771-783, </pages> <year> 1993. </year>
Reference-contexts: The test set performance was then computed for that state of the network which had minimum validation set error during the training process. 24 3 BENCHMARKING PROBLEMS This method, called early stopping <ref> [6, 9, 12] </ref>, is a good way to avoid overfitting [7] of the network to the particular training examples used, which would reduce the generalization performance. For optimal performance, the examples of the validation set should be used for further training afterwards, in order not to waste valuable data.
Reference: [7] <author> Stuart Geman, Elie Bienenstock, and Rene Doursat. </author> <title> Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 1-58, </pages> <year> 1992. </year>
Reference-contexts: due to the overfitting (overtraining) phenomenon: For two networks trained on the same problem, the one with larger training set error may actually be better , since the other has concentrated on peculiarities of the training set at the cost of losing much of the regularities needed for good generalization <ref> [7] </ref>. This is a problem in particular when not very many training examples are available. <p> The test set performance was then computed for that state of the network which had minimum validation set error during the training process. 24 3 BENCHMARKING PROBLEMS This method, called early stopping [6, 9, 12], is a good way to avoid overfitting <ref> [7] </ref> of the network to the particular training examples used, which would reduce the generalization performance. For optimal performance, the examples of the validation set should be used for further training afterwards, in order not to waste valuable data.
Reference: [8] <author> Michael I. Jordan and Robert A. Jacobs. </author> <title> Hierarchical mixtures of experts and the EM algorithm. </title> <journal> Neural Computation, </journal> <volume> 6 </volume> <pages> 181-214, </pages> <year> 1994. </year>
Reference-contexts: With the exception of gene, which uses a 2-bit binary code, Proben1 always employs 1-of-m representation for nominal attributes. Missing attribute values can be replaced by a fixed value (e.g. the mean of the non-missing values of this attribute or a value found using an EM algorithm <ref> [8] </ref>) or can be represented explicitly by adding another input for the attribute that is 1 iff the attribute value is missing. Proben1 uses both methods; the fixed value method is used only when but a few of the values are missing.
Reference: [9] <author> K.J. Lang, A.H. Waibel, and G.E. Hinton. </author> <title> A time-delay neural network architecture for isolated word recognition. </title> <booktitle> Neural Networks, </booktitle> <volume> 3(1) </volume> <pages> 33-43, </pages> <year> 1990. </year>
Reference-contexts: The test set performance was then computed for that state of the network which had minimum validation set error during the training process. 24 3 BENCHMARKING PROBLEMS This method, called early stopping <ref> [6, 9, 12] </ref>, is a good way to avoid overfitting [7] of the network to the particular training examples used, which would reduce the generalization performance. For optimal performance, the examples of the validation set should be used for further training afterwards, in order not to waste valuable data.
Reference: [10] <author> K.J. Lang and M.J. Witbrock. </author> <title> Learning to tell two spirals apart. </title> <booktitle> In Proc. of the 1988 Connectionist Summer School. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: Later works used still other synthetic problems which can not be exactly solved so easily. Instances are the two spirals problem <ref> [4, 5, 10] </ref> or the three discs problem [19]. The problem with these problems 1.5 Related work 7 is, similar to the ones mentioned above, that we know a-priori that a simple exact solution exists | at least when using the right framework to express it.
Reference: [11] <author> Martin Mtller. </author> <title> A scaled conjugate gradient algorithm for fast supervised learning. </title> <booktitle> Neural Networks, </booktitle> <volume> 6(4) </volume> <pages> 525-533, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Conjugate gradient optimization methods would be another class of useful algorithms for this kind of training problems <ref> [11] </ref>. The squared error function was used. For each dataset, training used the training set and the error on the validation set was measured after every fifth epoch (this interval between two measurements of the validation set error is called the strip length, see below).
Reference: [12] <author> N. Morgan and H. Bourlard. </author> <title> Generalization and parameter estimation in feedforward nets: Some experiments. </title> <booktitle> In [22], </booktitle> <pages> pages 630-637, </pages> <year> 1990. </year>
Reference-contexts: The test set performance was then computed for that state of the network which had minimum validation set error during the training process. 24 3 BENCHMARKING PROBLEMS This method, called early stopping <ref> [6, 9, 12] </ref>, is a good way to avoid overfitting [7] of the network to the particular training examples used, which would reduce the generalization performance. For optimal performance, the examples of the validation set should be used for further training afterwards, in order not to waste valuable data.
Reference: [13] <author> Michael C. Mozer and Paul Smolensky. </author> <title> Skeletonization: A technique for trimming the fat from a network via relevance assessment. </title> <booktitle> In [21], </booktitle> <pages> pages 107-115, </pages> <year> 1989. </year>
Reference-contexts: This measure is useful because it is independent of a particular machine and implementation. Forward and backward propagation counts individually, for certain algorithms that require more than one quantity to be backwardly propagated through each connection such as <ref> [1, 13] </ref>, each quantity counts as one traversal at each connection. Actual weight update steps also count as one traversal per updated connection. If possible report your training times using the connection traversal measure.
Reference: [14] <author> Steven J. Nowlan and Geoffry E. Hinton. </author> <title> Simplifying neural networks by soft weight-sharing. </title> <journal> Neural Computation, </journal> <volume> 4(4) </volume> <pages> 473-493, </pages> <year> 1992. </year>
Reference-contexts: For recurrent networks use standard names such as Jordan or Elman network where appropriate and back it up by a reference or further explanation. Non-standard network topologies or non-standard network models such as networks with shared weights <ref> [14] </ref> have to be described in detail. 2.8 Training results 15 Other properties of the network architecture also have to be specified: the range and resolution of the weight parameters (unless plain 32-bit floating point is used), the activation function of each node in the network (except for the input nodes
Reference: [15] <author> Lutz Prechelt. </author> <title> A study of experimental evaluations of neural network learning algorithms: Current research practice. </title> <type> Technical Report 19/94, </type> <institution> Fakultat fur Informatik, Universitat Karlsruhe, D-76128 Karlsruhe, Germany, </institution> <month> August </month> <year> 1994. </year> <note> Anonymous FTP: /pub/papers/techreports/1994/1994-19.ps.Z on ftp.ira.uka.de. </note>
Reference-contexts: necessary at all, what the scope of Proben1 is, and why real data should be used instead of or in addition to artificial problems as they are often used today. 1.1 Why a benchmark set? A recent study of the evaluation performed in journal papers about neural network learning algorithms <ref> [15] </ref> showed that this aspect of neural network research is a rather poor one. Most papers present performance results for the new algorithm only for a very small number of problems | rarely more than three.
Reference: [16] <author> Michael D. Richard and Richard P. Lippmann. </author> <title> Neural network classifiers estimate bayesian a-posteriori probabilities. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 461-483, </pages> <year> 1991. </year>
Reference-contexts: For some of them, the above idea of error percentages is applicable as well. The actual target function for classification problems is usually not the continuous error measure used during training, but the classification performance. However, since neural networks with continuous outputs are able to approximate a-posteriori probabilities <ref> [16] </ref>, which are often useful if the network outputs are to be used for further processing steps, the classification performance is not the only measure we are interested in. If space permits, you should thus report the actual error values in addition to the classification performance.
Reference: [17] <author> Martin Riedmiller and Heinrich Braun. </author> <title> A direct adaptive method for faster backpropagation learning: The RPROP algorithm. </title> <booktitle> In Proceedings of the IEEE International Conference on Neural Networks, </booktitle> <address> San Francisco, CA, </address> <month> April </month> <year> 1993. </year> <note> IEEE. </note>
Reference-contexts: The method applied for training was the same in all cases and can be summarized as follows: Training was performed using the RPROP algorithm <ref> [17] </ref> with parameters as indicated below. RPROP is a fast backpropagation variant similar in spirit to Quickprop. It is about as fast as Quickprop but requires less adjustment of the parameters to be stable. The parameters used were not determined by a trial-and-error search, but are just educated guesses instead.
Reference: [18] <editor> David Rumelhart and John McClelland, editors. </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </booktitle> <volume> volume Volume 1. </volume> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: Other training problems that were often used in the 1980s are the generalized XOR problem (n-bit parity), the n-bit encoder, the symmetry problem, the T-C problem, the 2-clumps problem, and others <ref> [3, 18] </ref>. <p> Proben1 uses both methods; the fixed value method is used only when but a few of the values are missing. Other methods are possible if one extends the training regime away from static examples, e.g. by using a Boltzmann machine <ref> [18] </ref>. 12 2 BENCHMARKING RULES Most of the above discussion applies to outputs as well, except for the fact that there never are missing outputs. Most Proben1 problems are classification problems; all of these are encoded using a 1-of-m output representation for the m classes, even for m = 2.
Reference: [19] <author> Steen Sjtgaard. </author> <title> A Conceptual Approach to Generalisation in Dynamic Neural Networks. </title> <type> PhD thesis, </type> <institution> Aarhus University, Aarhus, Danmark, </institution> <year> 1991. </year>
Reference-contexts: Later works used still other synthetic problems which can not be exactly solved so easily. Instances are the two spirals problem [4, 5, 10] or the three discs problem <ref> [19] </ref>. The problem with these problems 1.5 Related work 7 is, similar to the ones mentioned above, that we know a-priori that a simple exact solution exists | at least when using the right framework to express it.
Reference: [20] <author> Brian A. Telfer and Harold H. Szu. </author> <title> Energy functions for minimizing misclassification error with minimum-complexity networks. </title> <booktitle> Neural Networks, </booktitle> <volume> 7(5) </volume> <pages> 809-818, </pages> <year> 1994. </year>
Reference-contexts: Other error measures include the softmax error, the cross entropy, the classification figure of merit, linear error, exponential error, minimum variance error, and others <ref> [20] </ref>. If you use any of these, state the error term explicitly. For some of them, the above idea of error percentages is applicable as well. The actual target function for classification problems is usually not the continuous error measure used during training, but the classification performance.
Reference: [21] <editor> David S. Touretzky, editor. </editor> <booktitle> Advances in Neural Information Processing Systems 1, </booktitle> <address> San Mateo, California, 1989. </address> <publisher> Morgan Kaufman Publishers Inc. </publisher>
Reference: [22] <editor> David S. Touretzky, editor. </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <address> San Mateo, California, 1990. </address> <publisher> Morgan Kaufman Publishers Inc. </publisher>
Reference: [23] <author> Zijian Zheng. </author> <title> A benchmark for classifier learning. </title> <type> Technical Report TR474, </type> <institution> Basser Department of Computer Science, University of Sydney, </institution> <address> N.S.W Australia 2006, </address> <month> November </month> <year> 1993. </year> <note> anonymous ftp from ftp.cs.su.oz.au in /pub/tr. </note>
Reference-contexts: The Proben1 benchmark collection contains datasets that are taken from the UCI archive (with one exception). The data is, however, encoded for direct neural network use, is pre-partitioned into training, validation, and test examples, and is presented in a very exactly documented and reproducible form. Zheng's benchmark <ref> [23] </ref>, which I recommend everybody to read, does not include its own data, but defines a set of 13 problems, predominantly from the UCI archive, to be used as a benchmark collection for classifier learning algorithms.
References-found: 23

