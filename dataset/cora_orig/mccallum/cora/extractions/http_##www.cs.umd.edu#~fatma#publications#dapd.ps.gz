URL: http://www.cs.umd.edu/~fatma/publications/dapd.ps.gz
Refering-URL: http://www.cs.umd.edu/~fatma/publications.html
Root-URL: 
Title: Distributed and Parallel Databases,  Multidatabase Query Optimization  
Author: CEM EVRENDILEK ASUMAN DOGAC SENA NURAL AND FATMA OZCAN Editor: Tamer Ozsu 
Keyword: Multidatabases, query optimization, Heterogeneity  
Address: 06531 Ankara Turkiye  
Affiliation: Software Research and Development Center Middle East Technical University (METU)  
Note: c 1997 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Pubnum: 5,  
Email: asuman@srdc.metu.edu.tr  
Date: 1-39 (1997)  
Abstract: A multidatabase system (MDBS) allows the users to simultaneously access heterogeneous, and autonomous databases using an integrated schema and a single global query language. The query optimization problem in MDBSs is quite different from the query optimization problem in distributed homogeneous databases due to schema heterogeneity and autonomy of local database systems. In this work, we consider the optimization of query distribution in case of data replication and the optimization of intersite joins, that is, the join of the results returned by the local sites in response to the global subqueries. The algorithms presented for the optimization of intersite joins try to maximize the parallelism in execution and take the federated nature of the problem into account. It has also been shown through a comparative performance study that the proposed in-tersite join optimization algorithms are efficient. The approach presented can easily be generalized to any operation required for intersite query processing. The query optimization scheme presented in this paper is being implemented within the scope of a multidatabase system which is based on OMG's object management architecture. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> E. I. Chong. </author> <title> "Query Optimization in Distributed Database Systems and Multidatabase Systems", </title> <type> Ph.D Thesis, </type> <institution> Northwestern University, </institution> <year> 1994. </year>
Reference-contexts: However, since they start with a left deep join tree and thus do not consider the bushy inners, they may miss less costly bushy trees. Multidatabase query processing, has also been addressed in <ref> [1, 3, 7, 19, 17, 23, 32] </ref>. But, [9] and [31] are the only ones that focus on intersite join optimization and only [9] has considered available parallelism to be exploited for query execution in multidatabases. <p> The semiouterjoin technique is proposed in [3] as an approach to make local selections possible. Semiouterjoin operation produces two results, a semijoin and its complement. As pointed out in the paper this technique works well in all cases, no matter what the aggregation and selection conditions are. In <ref> [1] </ref> and [32], role-based query processing in multidatabase systems are considered and methods are proposed. The approach suggested in [32] is based on the idea of presenting the answer to a query as a set of sets representing the distinct intersections between the relations corresponding to the various roles. <p> Note that even when the local loads of the local DBMSs are not available it is possible to rationalize the global load of local DBMSs by taking previously scheduled global queries into account * The conversion cost parameter which includes entity identification <ref> [1] </ref> and generalized attribute derivation [19]. For the sake of simplicity, the conversion cost parameter is incorporated into the appearance times of global subqueries. This assumption is realistic since conversion is performed only once in the LDAOs, the rest of global query processing being in the canonical data model.
Reference: 2. <author> U. Dayal. </author> <title> "Processing Queries over Generalization Hierarchies in a Multidatabase System", </title> <booktitle> in Proc. of VLDB Conference, </booktitle> <year> 1983. </year>
Reference-contexts: For this NP-Complete assignment problem we propose a heuristic solution. It should be noted that the non-trivial task of query decomposition and modification which has been extensively studied in the literature <ref> [2, 24] </ref>, is not within the scope of this paper. <p> Different join processing strategies like the one given in [32], may easily be incorporated into our query processing and optimization model conforming to the infrastructure of a multidatabase system. 4. Optimizing global subquery assignment in case of data replication Query decomposition has been extensively studied in [3] and <ref> [2] </ref>. The details of query decomposition in multidatabase systems have also been described in [24] for MIND. In this section, we consider only the problem of distributing the global subqueries to the related sites in case there is more than one candidate site that can process the subquery.
Reference: 3. <author> U. Dayal. </author> <title> "Query Processing in a Multidatabase System", Query Processing: Database Systems, </title> <editor> eds. Kim, et al., pp.81-108, </editor> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: However, since they start with a left deep join tree and thus do not consider the bushy inners, they may miss less costly bushy trees. Multidatabase query processing, has also been addressed in <ref> [1, 3, 7, 19, 17, 23, 32] </ref>. But, [9] and [31] are the only ones that focus on intersite join optimization and only [9] has considered available parallelism to be exploited for query execution in multidatabases. <p> In [23], a survey of the previous research on multidatabase query optimization is presented. In <ref> [3] </ref>, it is stated that conventional distributed DBMSs use a variety of tactics for reducing the cost of processing queries. One commonly used tactic is to perform selections and projections at individual sites before executing any intersite joins. <p> These tactics are of limited applicability in a multidatabase system where queries can include outerjoins [28] and aggregates. However, it is still desirable whenever possible to perform local selections before moving data to the global site. The semiouterjoin technique is proposed in <ref> [3] </ref> as an approach to make local selections possible. Semiouterjoin operation produces two results, a semijoin and its complement. As pointed out in the paper this technique works well in all cases, no matter what the aggregation and selection conditions are. <p> Role-based query processing of [32] aims at minimizing the amount of data to be transmitted between the local sites and the global site as well as reducing the processing costs at the global site for dealing with intermediate data and producing the final joins as in <ref> [3] </ref>. The intermediate data to be generated at the global site requires the generation of private and overlap parts of a query. <p> Using role-sets, a new method for data integration that maintains the materialization autonomy of local database systems is developed. In addition, this method reduces data shipments between sites by allowing local selections to be performed for all queries with/without aggregation. The method suggested in <ref> [3] </ref>, on the other hand, requires expensive semiouterjoins in order to find the private and overlap parts which is done more efficiently via a merge-sort in [32]. In [19], query optimization and processing in Federated Database Management Systems (FDBMS) are discussed and methods for query processing and optimization are proposed. <p> It should, therefore, be noted that the cost of a join operation generally accounts for only a fraction of the cost of an intersite join operation. The strategies described in <ref> [3] </ref> and [32] for processing the relational algebra operators such as selection, projection and join involving aggregation for multidatabases can readily be used within the optimization framework described in this paper. <p> Different join processing strategies like the one given in [32], may easily be incorporated into our query processing and optimization model conforming to the infrastructure of a multidatabase system. 4. Optimizing global subquery assignment in case of data replication Query decomposition has been extensively studied in <ref> [3] </ref> and [2]. The details of query decomposition in multidatabase systems have also been described in [24] for MIND. In this section, we consider only the problem of distributing the global subqueries to the related sites in case there is more than one candidate site that can process the subquery.
Reference: 4. <author> A. Dogac, et. al. </author> <title> "METU Object-Oriented Database System", </title> <booktitle> Demo Description in Proceedings of ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pp. 513, </pages> <address> Minneapolis, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: We have defined an interface of a generic Database Object through CORBA IDL and developed multiple implementations of this interface for Sybase 3 , Oracle7 4 , Adabas D 5 and MOOD (METU Object-Oriented DBMS) <ref> [4] </ref>. The problem of dealing with the growth of the number of component systems while using a global schema as the reference model is discussed in [24]. What clients see are homogeneous DBMS objects accessible through a common interface.
Reference: 5. <author> A. Dogac, C. Dengi, E. Kilic, G. Ozhan, F. Ozcan, S. Nural, C. Evrendilek, U. Halici, B. Arpinar, P. Koksal, N. Kesim, and S. Mancuhan. </author> <title> "METU Interoperable Database System", </title> <booktitle> ACM SIGMOD Record, 24(3),pp. </booktitle> <pages> 56-61, </pages> <month> September, </month> <year> 1995. </year> <note> 38 C. </note> <editor> EVRENDILEK AND A. </editor> <publisher> DOGAC </publisher>
Reference-contexts: Our work is influenced by the existing work in the literature in the following respects: * The query processing architecture suggested in [19] affected the design of the system described in [16], <ref> [5] </ref>, [6], [21] and [22]. Yet, our architecture is based on OMG's distributed object management architecture [30], as explained in Section 3. * In this paper, the work presented in [7] is used in estimating the time taken by global subqueries. <p> An Environment for Multidatabase Query Processing The query optimization approach presented in this paper is being implemented in the MIND (METU INteroperable DBMS) project described in <ref> [5, 6, 8, 16, 21, 22] </ref>. MIND architecture is based on OMG's 1 distributed object management architecture [30]. The infrastructure of the system is built on a CORBA implementation, namely DEC's ObjectBroker 2 [16].
Reference: 6. <author> A. Dogac, U. Halici, E. Kilic, G. Ozhan, F. Ozcan, S. Nural, C. Dengi, S. Mancuhan, B. Arpinar, P. Koksal, C. Evrendilek. </author> <title> "METU Interoperable Database System", Demo Description, </title> <booktitle> In Proc. of ACM Sigmod Intl. Conf. on Management of Data, </booktitle> <pages> pp 552, </pages> <address> Montreal, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Our work is influenced by the existing work in the literature in the following respects: * The query processing architecture suggested in [19] affected the design of the system described in [16], [5], <ref> [6] </ref>, [21] and [22]. Yet, our architecture is based on OMG's distributed object management architecture [30], as explained in Section 3. * In this paper, the work presented in [7] is used in estimating the time taken by global subqueries. <p> An Environment for Multidatabase Query Processing The query optimization approach presented in this paper is being implemented in the MIND (METU INteroperable DBMS) project described in <ref> [5, 6, 8, 16, 21, 22] </ref>. MIND architecture is based on OMG's 1 distributed object management architecture [30]. The infrastructure of the system is built on a CORBA implementation, namely DEC's ObjectBroker 2 [16].
Reference: 7. <author> W. Du, R. Krishnamurthy, M-C. Shan. </author> <title> "Query Optimization in Heterogeneous DBMS", </title> <booktitle> Proc. of the 18th Int'l Conf. Very Large Data Bases, </booktitle> <pages> pp. 277-291, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: However, since they start with a left deep join tree and thus do not consider the bushy inners, they may miss less costly bushy trees. Multidatabase query processing, has also been addressed in <ref> [1, 3, 7, 19, 17, 23, 32] </ref>. But, [9] and [31] are the only ones that focus on intersite join optimization and only [9] has considered available parallelism to be exploited for query execution in multidatabases. <p> Our technique or the technique presented in [9], can be used in conjunction with any of the query processing strategies outlined in the related work. In <ref> [7] </ref>, through synthetic database calibration, logical cost model parameters of a local DBMS in a MDBS are estimated. <p> Yet, our architecture is based on OMG's distributed object management architecture [30], as explained in Section 3. * In this paper, the work presented in <ref> [7] </ref> is used in estimating the time taken by global subqueries. In [7], it is assumed that participating DBMSs are autonomous and may not be able, even if they are willing, to provide the cost model parameters. The strategy in [7] is to deduce the necessary information by calibrating a given <p> Yet, our architecture is based on OMG's distributed object management architecture [30], as explained in Section 3. * In this paper, the work presented in <ref> [7] </ref> is used in estimating the time taken by global subqueries. In [7], it is assumed that participating DBMSs are autonomous and may not be able, even if they are willing, to provide the cost model parameters. The strategy in [7] is to deduce the necessary information by calibrating a given DBMS. <p> Section 3. * In this paper, the work presented in <ref> [7] </ref> is used in estimating the time taken by global subqueries. In [7], it is assumed that participating DBMSs are autonomous and may not be able, even if they are willing, to provide the cost model parameters. The strategy in [7] is to deduce the necessary information by calibrating a given DBMS. They propose a calibrating database which is synthetically created so as to make the process of deducing the cost model coefficients reasonably devoid of the unpredictability problems. <p> Note that the cost of processing a subquery at a site can be calculated by obtaining the logical cost parameters through synthetic database calibration <ref> [7] </ref> and by obtaining the related database statistics from the data dictionaries; If a data 12 C. EVRENDILEK AND A. DOGAC Table 1. Initial w 0 Values. <p> Another parameter which is accounted in the appearance time, is the conversion cost arising from the heterogeneity of local DBMSs. In order to estimate the appearance times, we used the approach followed in Pe-gasus <ref> [7] </ref>. The DBMSs that participate in a multidatabase system are classified into three categories in [7]. Proprietary DBMSs provide all the relevant information on cost functions and database statistics. Conforming DBMSs provide database statistics but are incapable of divulging the cost functions. <p> Another parameter which is accounted in the appearance time, is the conversion cost arising from the heterogeneity of local DBMSs. In order to estimate the appearance times, we used the approach followed in Pe-gasus <ref> [7] </ref>. The DBMSs that participate in a multidatabase system are classified into three categories in [7]. Proprietary DBMSs provide all the relevant information on cost functions and database statistics. Conforming DBMSs provide database statistics but are incapable of divulging the cost functions. Non-Conforming DBMSs are incapable of divulging either the database statistics or the cost functions. <p> Non-Conforming DBMSs are incapable of divulging either the database statistics or the cost functions. It is possible to deduce the coefficients of the logical cost model of a conforming DBMS through synthetic database calibration as described in <ref> [7] </ref>. Furthermore, it is argued in [7] that, it is possible to extend this approach to non-conforming DBMSs. 14 C. EVRENDILEK AND A. DOGAC Thus, it is assumed that the appearance times of global subqueries from heterogeneous DBMSs can be estimated. <p> Non-Conforming DBMSs are incapable of divulging either the database statistics or the cost functions. It is possible to deduce the coefficients of the logical cost model of a conforming DBMS through synthetic database calibration as described in <ref> [7] </ref>. Furthermore, it is argued in [7] that, it is possible to extend this approach to non-conforming DBMSs. 14 C. EVRENDILEK AND A. DOGAC Thus, it is assumed that the appearance times of global subqueries from heterogeneous DBMSs can be estimated.
Reference: 8. <author> A. Dogac, C. Dengi, T. Ozsu. </author> <title> "Building Interoperable Databases on Distributed Object Management Platforms", </title> <note> Communications of the ACM (to appear). </note>
Reference-contexts: An Environment for Multidatabase Query Processing The query optimization approach presented in this paper is being implemented in the MIND (METU INteroperable DBMS) project described in <ref> [5, 6, 8, 16, 21, 22] </ref>. MIND architecture is based on OMG's 1 distributed object management architecture [30]. The infrastructure of the system is built on a CORBA implementation, namely DEC's ObjectBroker 2 [16].
Reference: 9. <author> W. Du, M-C Shan and U. Dayal. </author> <title> "Reducing Multidatabase Query Response Time by Tree Balancing", </title> <booktitle> In ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pp. 293-303, </pages> <year> 1995. </year>
Reference-contexts: Although the technique presented increases the parallelism, its complexity hinders its performance. Section 6 presents the performance evaluation of the in-tersite join optimization algorithms proposed in this paper in comparison to the work presented in <ref> [9] </ref>. Finally, the conclusions and future work are given in Section 7. 2. Related Work Some previous work in global query optimization in multidatabases have used the techniques developed for homogeneous distributed database systems. <p> An intuitive example to clarify the point is as follows: Assume the left deep join tree (((AB)C)D) is given. Although the least costly join to select first is (BC), the best plan could be ((AB)(CD)). A technique is proposed in <ref> [9] </ref> to reduce the query response time based on the following observations: Execution of multidatabase queries differs from that of traditional queries in that sort merge and hash joins are more often favored, as nested loop join requires repeated accesses to external data sources. <p> The complexity of these algorithms are O (n 2 ), where n is the number of nodes in the query graph. The algorithms do not guarantee that the resulting tree is optimal with respect to total response time <ref> [9] </ref>. The tree transformation algorithms suggested in [9] try to reduce the response time by finding cost reducing bushy inners. However, since they start with a left deep join tree and thus do not consider the bushy inners, they may miss less costly bushy trees. <p> The complexity of these algorithms are O (n 2 ), where n is the number of nodes in the query graph. The algorithms do not guarantee that the resulting tree is optimal with respect to total response time <ref> [9] </ref>. The tree transformation algorithms suggested in [9] try to reduce the response time by finding cost reducing bushy inners. However, since they start with a left deep join tree and thus do not consider the bushy inners, they may miss less costly bushy trees. <p> However, since they start with a left deep join tree and thus do not consider the bushy inners, they may miss less costly bushy trees. Multidatabase query processing, has also been addressed in [1, 3, 7, 19, 17, 23, 32]. But, <ref> [9] </ref> and [31] are the only ones that focus on intersite join optimization and only [9] has considered available parallelism to be exploited for query execution in multidatabases. The problem of improving query response time that is addressed in [9] and in our work is orthogonal to the problems studied in <p> Multidatabase query processing, has also been addressed in [1, 3, 7, 19, 17, 23, 32]. But, <ref> [9] </ref> and [31] are the only ones that focus on intersite join optimization and only [9] has considered available parallelism to be exploited for query execution in multidatabases. The problem of improving query response time that is addressed in [9] and in our work is orthogonal to the problems studied in the related work. Our technique or the technique presented in [9], can be used in <p> But, <ref> [9] </ref> and [31] are the only ones that focus on intersite join optimization and only [9] has considered available parallelism to be exploited for query execution in multidatabases. The problem of improving query response time that is addressed in [9] and in our work is orthogonal to the problems studied in the related work. Our technique or the technique presented in [9], can be used in conjunction with any of the query processing strategies outlined in the related work. <p> join optimization and only <ref> [9] </ref> has considered available parallelism to be exploited for query execution in multidatabases. The problem of improving query response time that is addressed in [9] and in our work is orthogonal to the problems studied in the related work. Our technique or the technique presented in [9], can be used in conjunction with any of the query processing strategies outlined in the related work. In [7], through synthetic database calibration, logical cost model parameters of a local DBMS in a MDBS are estimated. <p> Since l is proportional to the number of edges e in the global query graph, the complexity may be given as O (e 4 loge). 6. Performance In this section, the performance analysis of the Linear Algorithm (Algorithm 5.2), is compared to the Hybrid Algorithm presented in <ref> [9] </ref>. The Hybrid Algorithm is the only candidate for comparing our work, since, to the best of our knowledge, it is the only algorithm that addresses the problem of improving response time in multidatabase systems by considering the available parallelism in execution of intersite joins.
Reference: 10. <author> C. Evrendilek, A. Dogac, S. Nural, F. Ozcan, </author> <title> "Query Optimization in Multidatabase Systems", </title> <booktitle> in Proc. of Next Generation Information Technologies and Systems, </booktitle> <pages> pp. 49-58, </pages> <address> Israel, </address> <month> June </month> <year> 1995. </year>
Reference: 11. <author> C. Evrendilek. </author> <title> "Multidatabase Query Processing and Optimization", </title> <type> Ph. D. Thesis, </type> <institution> Middle East Technical University, </institution> <note> in Preparation, </note> <year> 1995. </year>
Reference-contexts: Specifically, we consider two problems related to multidatabase systems: (1) The optimization of distribution of global subqueries after query decomposition in case of data replication, and (2) the optimization of intersite joins, that is, the join of the results returned by the local sites in response to the global subqueries <ref> [11] </ref>. The approach we propose could also apply to distributed DBMSs. In such a case, however, the algorithms would become much simpler since parameters coming from heterogeneity and autonomy disappear. <p> As a result, time complexity of Algorithm 4.1 is given by O (nk+k 2 logn) with the locate array and by O (k 2 n) without the locate array <ref> [11] </ref>. We will explain how Algorithm 4.1 works briefly through Example 4.1. Example 4.1 Assume there are three sites with no local loads and the costs of executing the subqueries at those sites are given in Table 1 (w values correspond to the initial w 0 values). <p> If a locate array is used pointing to the elements in the heap, the complexity of Algorithm 5.1 is O (n 2 loge) <ref> [11] </ref> where e denotes the number of edges and n denotes the number of nodes in the global query graph. The complexity would be O (ne + n 2 loge) without the locate array [11]. Example 5.1 illustrates how Algorithm 5.1 works. 18 C. EVRENDILEK AND A. <p> to the elements in the heap, the complexity of Algorithm 5.1 is O (n 2 loge) <ref> [11] </ref> where e denotes the number of edges and n denotes the number of nodes in the global query graph. The complexity would be O (ne + n 2 loge) without the locate array [11]. Example 5.1 illustrates how Algorithm 5.1 works. 18 C. EVRENDILEK AND A. DOGAC Example 5.1 In the global query graph initially given in Figure 2a, the labels of the edges denote the weights, i.e., the cost obtained through weight function 1 . <p> M (i,i+f ) then M (i,i+f ) = ; g end. 2 The complexity of Algorithm 5.2 is: n1 X i (n i) = n fl (n 1) fl (n + 1)=6 that is, O (n 3 ) where n is the number of nodes in the global query graph <ref> [11] </ref>. The parenthesization process described in Algorithm 5.2 expands the search space of execution plans considered from those generated from left-deep trees to a space in which bushy inners are also covered and these plans are more suitable to the distributed nature of a multidatabase system. <p> is d i and e is the number of edges in the global query graph, the order of the maximum length of a replicated sequence for n subqueries is: n X d i = 2e 2 2 Therefore, the time complexity of Algorithm 5.3 is also O (n 2 ) <ref> [11] </ref>. <p> contains the schedule of Figure 7c, assigns e to site 2 instead of its originally scheduled site 1, since such a scheduling is more beneficial in terms of response time. 2 The complexity of this algorithm is O (l 4 logl) where l is the length of the replicated sequence <ref> [11] </ref>. This can roughly be calculated through: MULTIDATABASE QUERY OPTIMIZATION 31 32 C. EVRENDILEK AND A. DOGAC l X (l i + 1)(i 1)(ilogi) = O (l 4 logl) where O (ilogi) is the time required by the subsumption check and the merge phases for segments of length i.
Reference: 12. <author> M. R. Garey, and D. S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness, </title> <publisher> Freeman and Co., </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference-contexts: Adabas D is a trademark of Software AG Corp. 6. By reduction from an NP-Complete problem 2-PARTIT. 2-PARTIT problem decides whether, given m integers summing to 2*k, dividing this set of integers into 2 partitions such that each partition sums up to k, is possible <ref> [12] </ref> 7. With the additional appearance time parameter, the nature of the problem does not change. This follows from the definition of NP-Completeness.
Reference: 13. <author> E. Horowitz, S. Sahni. </author> <title> Fundamentals of Data Structures in Pascal, </title> <publisher> Pitman Publishing Limited, </publisher> <year> 1984. </year>
Reference-contexts: For the sake of simplicity, the schedule is not shown in the computation of the matrix M given in Algorithm 5.2. It is shown in <ref> [13] </ref> that the the number of possible parenthesizations of a linear order with n+1 partial results (i.e., n+1 matrices) and the number of bushy trees for a given left deep tree with n nodes (i.e., number of distinct binary trees with n nodes) are equal to C (2n,n)/(n+1) where C stands
Reference: 14. <author> W. Hong, M. Stonebraker. </author> <title> "Optimization of Parallel Query Execution Plans in XPRS", </title> <journal> Journal of Distributed and Parallel Databases, </journal> <volume> Vol. 1, No. 1, </volume> <pages> pp. 9-32, </pages> <publisher> Kluwer Academic Publishers, </publisher> <month> January, </month> <year> 1993. </year>
Reference-contexts: In a left deep tree, however, join nodes are not allowed in the right subtree, at each node a single table is joined with the results of the previous join in a pipelined fashion <ref> [14] </ref>. [34] states that left deep trees do not necessarily include the optimal plan for a parallel environment. It is further shown in [35] through experiments that bushy tree plans perform better.
Reference: 15. <author> T. Ibaraki, T. Kameda. </author> <title> "On the Optimal Nesting Order for Computing N-Relational Joins", </title> <journal> ACM Trans. on Database Systems, </journal> <volume> Vol. 9, No. 3, </volume> <pages> pp. 482-502, </pages> <month> September </month> <year> 1984. </year>
Reference-contexts: The problem that remains to be solved is the optimization of the intersite joins, given the estimates of the appearance times of the subqueries. Since the classical join ordering problem is NP-Complete <ref> [15] </ref>, the intersite join ordering problem of MDBSs is also an NP-Complete problem 7 . In optimizing the intersite joins, therefore, we propose a two step heuristic algorithm that tries to maximize the parallelism in execution of the join pairs in the global query. <p> For example, System R [33] and R fl [18] consider execution plans in which a single table is joined at each step with the results of previous joins, in a pipelined way, producing a left deep join tree. In <ref> [15] </ref>, the spanning tree of a query graph is used to find a linear order. An observation related to these heuristics is that the linear join orders produced are not necessarily the best candidates for parallel execution [20].
Reference: 16. <author> E. Kilic, G. Ozhan, C. Dengi, N. Kesim, P. Koksal and A. Dogac, </author> <title> "Experiences in Using CORBA in a Multidatabase Implementation", </title> <booktitle> in Proc. of 6th Intl. Workshop on Database and Expert System Applications, </booktitle> <pages> pp. 223-230, </pages> <address> London, </address> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: Our work is influenced by the existing work in the literature in the following respects: * The query processing architecture suggested in [19] affected the design of the system described in <ref> [16] </ref>, [5], [6], [21] and [22]. Yet, our architecture is based on OMG's distributed object management architecture [30], as explained in Section 3. * In this paper, the work presented in [7] is used in estimating the time taken by global subqueries. <p> An Environment for Multidatabase Query Processing The query optimization approach presented in this paper is being implemented in the MIND (METU INteroperable DBMS) project described in <ref> [5, 6, 8, 16, 21, 22] </ref>. MIND architecture is based on OMG's 1 distributed object management architecture [30]. The infrastructure of the system is built on a CORBA implementation, namely DEC's ObjectBroker 2 [16]. <p> MIND architecture is based on OMG's 1 distributed object management architecture [30]. The infrastructure of the system is built on a CORBA implementation, namely DEC's ObjectBroker 2 <ref> [16] </ref>. We have defined an interface of a generic Database Object through CORBA IDL and developed multiple implementations of this interface for Sybase 3 , Oracle7 4 , Adabas D 5 and MOOD (METU Object-Oriented DBMS) [4].
Reference: 17. <author> H. Lu, B-C Ooi, C-H Goh. </author> <title> "On Global Multidatabase Query Optimization", </title> <journal> Sigmod Record, Vol.21, </journal> <volume> No. 4, </volume> <pages> pp. 6-11, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Distinctive features of multidatabase systems give rise to a number of unique issues which do not arise in query optimization for homogeneous distributed database management systems. The important issues are the following <ref> [17] </ref>: * Any component DBMS may terminate its services without any advance notice (Site Autonomy). * Statistical information needed for effective global query optimization are not readily available and may not remain accurate as component systems evolve over time (Site Autonomy). * Multidatabase systems can only interact with component DBMSs via <p> However, since they start with a left deep join tree and thus do not consider the bushy inners, they may miss less costly bushy trees. Multidatabase query processing, has also been addressed in <ref> [1, 3, 7, 19, 17, 23, 32] </ref>. But, [9] and [31] are the only ones that focus on intersite join optimization and only [9] has considered available parallelism to be exploited for query execution in multidatabases. <p> Our technique or the technique presented in [9], can be used in conjunction with any of the query processing strategies outlined in the related work. In [7], through synthetic database calibration, logical cost model parameters of a local DBMS in a MDBS are estimated. In <ref> [17] </ref>, it is claimed that global query optimization problem in multidatabases is fundamentally different from global query optimization in homogeneous distributed database systems, and major issues in the design of a multidatabase query optimizer are highlighted. In [23], a survey of the previous research on multidatabase query optimization is presented.
Reference: 18. <author> G.M. Lohman, C. Mohan, L.M. Haas, B.G. Lindsay, P.G. Selinger, P.F. Wilms, and D. Daniels, </author> <title> "Query Processing in R fl ", Query Processing in Database Systems, </title> <journal> pp. </journal> <pages> 31-47, </pages> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: Using a linear join order in query optimization is an accepted practice and there are heuristics developed for this purpose. For example, System R [33] and R fl <ref> [18] </ref> consider execution plans in which a single table is joined at each step with the results of previous joins, in a pipelined way, producing a left deep join tree. In [15], the spanning tree of a query graph is used to find a linear order. <p> Communication cost and conversion cost for intermediate results are taken to be proportional to the sizes of intermediate results. The left deep tree used as the initial input for the Hybrid Algorithm is obtained as in R* <ref> [18] </ref>. MULTIDATABASE QUERY OPTIMIZATION 33 The performance of the Hybrid Algorithm is worse for increasing variances of selectivity and cardinality values.
Reference: 19. <author> E-P. Lim and J. Srivastava. </author> <title> "Query optimization/processing in federated database systems", </title> <type> Technical Report 92-68, </type> <institution> Dept. of Comp. Sc., University of Minnesota. </institution>
Reference-contexts: However, since they start with a left deep join tree and thus do not consider the bushy inners, they may miss less costly bushy trees. Multidatabase query processing, has also been addressed in <ref> [1, 3, 7, 19, 17, 23, 32] </ref>. But, [9] and [31] are the only ones that focus on intersite join optimization and only [9] has considered available parallelism to be exploited for query execution in multidatabases. <p> The method suggested in [3], on the other hand, requires expensive semiouterjoins in order to find the private and overlap parts which is done more efficiently via a merge-sort in [32]. In <ref> [19] </ref>, query optimization and processing in Federated Database Management Systems (FDBMS) are discussed and methods for query processing and optimization are proposed. Query processing in [19] is treated at two levels: federation level and local level. <p> In <ref> [19] </ref>, query optimization and processing in Federated Database Management Systems (FDBMS) are discussed and methods for query processing and optimization are proposed. Query processing in [19] is treated at two levels: federation level and local level. Activities are assigned at respective levels to Federation Query Manager (FQM) and Federated Query Agent (FQA). In [19], gateways between FQAs and component DBMSs make the local DBMSs appear to be supporting the common data model. <p> Query processing in <ref> [19] </ref> is treated at two levels: federation level and local level. Activities are assigned at respective levels to Federation Query Manager (FQM) and Federated Query Agent (FQA). In [19], gateways between FQAs and component DBMSs make the local DBMSs appear to be supporting the common data model. Gateways handle query statements in the common data manipulation language, and translate them into local query commands. The results returned by the local DBMS are transformed to the common data model. <p> The results returned by the local DBMS are transformed to the common data model. Each gateway has to make its supported set of relational operations known to the federation so that the gateway will not be asked to handle the unsupported operations during query execution. It is stated in <ref> [19] </ref> that in a FDBMS, the distinct feature of autonomy implies that a detailed cost-based query optimization is very difficult, if not impossible. <p> Our work is influenced by the existing work in the literature in the following respects: * The query processing architecture suggested in <ref> [19] </ref> affected the design of the system described in [16], [5], [6], [21] and [22]. <p> Note that even when the local loads of the local DBMSs are not available it is possible to rationalize the global load of local DBMSs by taking previously scheduled global queries into account * The conversion cost parameter which includes entity identification [1] and generalized attribute derivation <ref> [19] </ref>. For the sake of simplicity, the conversion cost parameter is incorporated into the appearance times of global subqueries. This assumption is realistic since conversion is performed only once in the LDAOs, the rest of global query processing being in the canonical data model. <p> This assumption is realistic since conversion is performed only once in the LDAOs, the rest of global query processing being in the canonical data model. The conversion cost parameter may be a dominating factor, since it takes more time to prepare data for transmission in a multidatabase system <ref> [19] </ref>. This is another 10 C. EVRENDILEK AND A. DOGAC justification of our framework that the appearance times should be taken into account in multidatabase query optimization. * The cost of transferring intermediate results among global query processors of involved LDAOs.
Reference: 20. <author> H. Lu, M. Shan, K. Tan. </author> <title> "Optimization of Multi-way Join Queries for Parallel Execution", </title> <booktitle> In Proc. of the 17th Intl. Conf. on Very Large Data Bases, </booktitle> <pages> pp. 549-560, </pages> <address> Barcelona, </address> <month> September, </month> <year> 1991. </year>
Reference-contexts: In [15], the spanning tree of a query graph is used to find a linear order. An observation related to these heuristics is that the linear join orders produced are not necessarily the best candidates for parallel execution <ref> [20] </ref>. Restricting the schedules to synchronized query execution plans as in [20], however, may result in missing an optimal solution which often happens to be an asynchronous bushy plan. <p> In [15], the spanning tree of a query graph is used to find a linear order. An observation related to these heuristics is that the linear join orders produced are not necessarily the best candidates for parallel execution <ref> [20] </ref>. Restricting the schedules to synchronized query execution plans as in [20], however, may result in missing an optimal solution which often happens to be an asynchronous bushy plan.
Reference: 21. <author> A. Dogac, C. Dengi, E. Kilic, G. Ozhan, F. Ozcan, S. Nural, C. Evrendilek, U. Halici, B. Arpinar, P. Koksal, N. Kesim, S. Mancuhan. </author> <title> "A Multidatabase System Implementation on CORBA", </title> <booktitle> 6th Intl. Workshop on Research Issues in Data Engineering (RIDE-NDS '96), </booktitle> <pages> pp. 2-11, </pages> <address> New Orleans, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: Our work is influenced by the existing work in the literature in the following respects: * The query processing architecture suggested in [19] affected the design of the system described in [16], [5], [6], <ref> [21] </ref> and [22]. Yet, our architecture is based on OMG's distributed object management architecture [30], as explained in Section 3. * In this paper, the work presented in [7] is used in estimating the time taken by global subqueries. <p> An Environment for Multidatabase Query Processing The query optimization approach presented in this paper is being implemented in the MIND (METU INteroperable DBMS) project described in <ref> [5, 6, 8, 16, 21, 22] </ref>. MIND architecture is based on OMG's 1 distributed object management architecture [30]. The infrastructure of the system is built on a CORBA implementation, namely DEC's ObjectBroker 2 [16].
Reference: 22. <author> G. Ozhan, A. Dogac, E. Kilic, F. Ozcan, S. Nural, C. Dengi, U. Halici, B. Arpinar, P. Koksal, S. Mancuhan, C. Evrendilek. </author> <title> "Making Oracle7, Sybase and Adabas D Interoperable through CORBA: MIND Project", </title> <booktitle> in Proc. of European Oracle User Group Conference, </booktitle> <pages> pp. 1047-1058, </pages> <address> Amsterdam, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: Our work is influenced by the existing work in the literature in the following respects: * The query processing architecture suggested in [19] affected the design of the system described in [16], [5], [6], [21] and <ref> [22] </ref>. Yet, our architecture is based on OMG's distributed object management architecture [30], as explained in Section 3. * In this paper, the work presented in [7] is used in estimating the time taken by global subqueries. <p> An Environment for Multidatabase Query Processing The query optimization approach presented in this paper is being implemented in the MIND (METU INteroperable DBMS) project described in <ref> [5, 6, 8, 16, 21, 22] </ref>. MIND architecture is based on OMG's 1 distributed object management architecture [30]. The infrastructure of the system is built on a CORBA implementation, namely DEC's ObjectBroker 2 [16].
Reference: 23. <author> W. Meng, C. Yu. </author> <title> "Query Processing in Multidatabase Systems", in Modern Database Systems (Edtr. </title> <type> Won Kim), </type> <pages> pp. 551-572, </pages> <publisher> ACM Press 1995. </publisher>
Reference-contexts: However, since they start with a left deep join tree and thus do not consider the bushy inners, they may miss less costly bushy trees. Multidatabase query processing, has also been addressed in <ref> [1, 3, 7, 19, 17, 23, 32] </ref>. But, [9] and [31] are the only ones that focus on intersite join optimization and only [9] has considered available parallelism to be exploited for query execution in multidatabases. <p> In [17], it is claimed that global query optimization problem in multidatabases is fundamentally different from global query optimization in homogeneous distributed database systems, and major issues in the design of a multidatabase query optimizer are highlighted. In <ref> [23] </ref>, a survey of the previous research on multidatabase query optimization is presented. In [3], it is stated that conventional distributed DBMSs use a variety of tactics for reducing the cost of processing queries.
Reference: 24. <author> S. Nural, P. Koksal, F. Ozcan, A. Dogac. </author> <title> "Query decomposition and Processing in Multi-database Systems", </title> <booktitle> Object Oriented Database Symposium of the 3rd European Joint Conference on Engineering Systems Design and Analysis, </booktitle> <pages> pp. 41-52, </pages> <address> France, </address> <year> 1996. </year>
Reference-contexts: For this NP-Complete assignment problem we propose a heuristic solution. It should be noted that the non-trivial task of query decomposition and modification which has been extensively studied in the literature <ref> [2, 24] </ref>, is not within the scope of this paper. <p> The problem of dealing with the growth of the number of component systems while using a global schema as the reference model is discussed in <ref> [24] </ref>. What clients see are homogeneous DBMS objects accessible through a common interface. The basic components of the system are a Global Database Agent (GDA) class (Object Factory in CORBA terminology) and a Local Database Agent (LDA) class. <p> Optimizing global subquery assignment in case of data replication Query decomposition has been extensively studied in [3] and [2]. The details of query decomposition in multidatabase systems have also been described in <ref> [24] </ref> for MIND. In this section, we consider only the problem of distributing the global subqueries to the related sites in case there is more than one candidate site that can process the subquery. Note that this phase starts after the query decomposition process has been completed. <p> We have a global schema where schema conflicts are resolved by identifying the type of conflicts as described in <ref> [24] </ref>. This global schema contains all the information to decide on query decomposition. If there are n sites and k global subqueries, this algorithm requires the construction of k heaps of n elements each and maintenance of the remaining heaps adjusted at each iteration.
Reference: 25. <author> C. Ozkan, A. Dogac, M. Altinel. </author> <title> "A Cost Model for Path Expressions in Object-Oriented Queries", </title> <journal> Journal of Database Management, Vol.7, </journal> <volume> No.3, </volume> <pages> pp. 25-33, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: It has been observed in <ref> [26, 25, 27] </ref> that size selectivity is more effective. Definition 5.2 Per-Unit Cost. <p> After contraction, the cardinality and unique cardinality of node Q 5 Q 4 Q 1 Q 2 Q 3 Q 7 are estimated given the unique cardinalities and cardinalities of the nodes Q 2 Q 3 Q 7 and Q 1 Q 4 Q 5 [26], <ref> [25] </ref>. Then, 1 (Q 5 Q 4 Q 1 Q 2 Q 3 Q 7 ,Q 6 ) is recalculated. In general, cost of all the edges emanating from a contracted node are recalculated. <p> The calculation of the cardinality and unique cardinality values for intermediate results are performed as in [26] and <ref> [25] </ref>. Initial appearance times for the partial results are also randomly chosen assuming that the sizes of the partial results are uncorrelated with the appearance times but correlated with the type of the global subquery. <p> That is, we can reduce the join ordering problem to the intersite join ordering problem in polynomial time by adding zero for appearance times and communication costs. 8. The effectiveness of these weight functions in ordering the join operations has been experimen tally verified in [26] and <ref> [25] </ref> where the order of joins within a path expression is decided.
Reference: 26. <author> C. Ozkan, A. Dogac, C. Evrendilek. </author> <title> "A Heuristic Approach for Optimization of Path Expressions", </title> <booktitle> in Proc. of 6th Intl. Conf. on Database and Expert System Applications, </booktitle> <pages> pp. 522-534, </pages> <address> London, </address> <month> September </month> <year> 1995. </year> <title> MULTIDATABASE QUERY OPTIMIZATION 39 </title>
Reference-contexts: It has been observed in <ref> [26, 25, 27] </ref> that size selectivity is more effective. Definition 5.2 Per-Unit Cost. <p> After contraction, the cardinality and unique cardinality of node Q 5 Q 4 Q 1 Q 2 Q 3 Q 7 are estimated given the unique cardinalities and cardinalities of the nodes Q 2 Q 3 Q 7 and Q 1 Q 4 Q 5 <ref> [26] </ref>, [25]. Then, 1 (Q 5 Q 4 Q 1 Q 2 Q 3 Q 7 ,Q 6 ) is recalculated. In general, cost of all the edges emanating from a contracted node are recalculated. <p> The sizes of the partial results are changed from 4K to 1M and the selectivities are calculated with respect to cardinality and unique cardinality values assuming uniform distribution for each partial result. The calculation of the cardinality and unique cardinality values for intermediate results are performed as in <ref> [26] </ref> and [25]. Initial appearance times for the partial results are also randomly chosen assuming that the sizes of the partial results are uncorrelated with the appearance times but correlated with the type of the global subquery. <p> That is, we can reduce the join ordering problem to the intersite join ordering problem in polynomial time by adding zero for appearance times and communication costs. 8. The effectiveness of these weight functions in ordering the join operations has been experimen tally verified in <ref> [26] </ref> and [25] where the order of joins within a path expression is decided.
Reference: 27. <author> F. Ozcan, S. Nural, P. Koksal, C. Evrendilek, A. Dogac. </author> <title> "Dynamic Query Optimization on a Distributed Object Management Platform", </title> <booktitle> 5th Intl. Conf. on Information and Knowledge Management, </booktitle> <pages> pp. 117-124, </pages> <address> USA, </address> <year> 1996. </year>
Reference-contexts: It has been observed in <ref> [26, 25, 27] </ref> that size selectivity is more effective. Definition 5.2 Per-Unit Cost.
Reference: 28. <author> A. Rosenthal, D. Reiner. </author> <title> "Extending the Algebraic Framework of Query Processing to Handle Outerjoins", </title> <booktitle> in Proc. of the 10th VLDB Conference, </booktitle> <pages> pp. 334-341, </pages> <address> Singapore, </address> <year> 1984. </year>
Reference-contexts: A second common tactic is to distribute selections, projections and joins over 6 C. EVRENDILEK AND A. DOGAC unions. Another distributed query processing strategy involves using semijoins for reducing the sizes of join operands. These tactics are of limited applicability in a multidatabase system where queries can include outerjoins <ref> [28] </ref> and aggregates. However, it is still desirable whenever possible to perform local selections before moving data to the global site. The semiouterjoin technique is proposed in [3] as an approach to make local selections possible. Semiouterjoin operation produces two results, a semijoin and its complement.
Reference: 29. <author> B. Salzberg. </author> <title> File Structures: An Analytical Approach, </title> <publisher> Prentice Hall Inc., </publisher> <year> 1988. </year>
Reference-contexts: In estimating intersite join times, three join methods, namely, hash-partition, sort-merge and nested loops with hashing are used and the cost calculations to select the least costly of these three join methods are performed as in <ref> [29] </ref>. Communication cost and conversion cost for intermediate results are taken to be proportional to the sizes of intermediate results. The left deep tree used as the initial input for the Hybrid Algorithm is obtained as in R* [18].
Reference: 30. <author> R. M. Soley. </author> <title> Object Management Architecture Guide, OMG, </title> <note> Second Edition, </note> <year> 1992. </year>
Reference-contexts: Our work is influenced by the existing work in the literature in the following respects: * The query processing architecture suggested in [19] affected the design of the system described in [16], [5], [6], [21] and [22]. Yet, our architecture is based on OMG's distributed object management architecture <ref> [30] </ref>, as explained in Section 3. * In this paper, the work presented in [7] is used in estimating the time taken by global subqueries. <p> An Environment for Multidatabase Query Processing The query optimization approach presented in this paper is being implemented in the MIND (METU INteroperable DBMS) project described in [5, 6, 8, 16, 21, 22]. MIND architecture is based on OMG's 1 distributed object management architecture <ref> [30] </ref>. The infrastructure of the system is built on a CORBA implementation, namely DEC's ObjectBroker 2 [16].
Reference: 31. <author> S. Salza, G. Barone, T. Morzy. </author> <title> "Distributed Query Optimization in Loosely Coupled Multi-database Systems", </title> <booktitle> Proc. of Intl. Conf. on Database Theory, </booktitle> <year> 1995. </year>
Reference-contexts: Local autonomy makes it impossible to intervene with local query processing. Furthermore, preparing data for transmission in a multidatabase system may be much more expensive than that in a homogeneous distributed database system and this may affect the optimization algorithm. The distributed query optimization algorithm described in <ref> [31] </ref> is organized as a sequence of steps such that at each step all local DBMSs work in parallel to evaluate the cost of execution plans for partial queries of increasing sizes, and send their cost estimates to other local DBMSs that need them for the next step. <p> The number of messages exchanged, on the other hand, is O (n 2 2 n ) in the case of a fully connected graph <ref> [31] </ref>. Although the query optimization is performed in parallel, this algorithm produces only serial query execution plans. Furthermore, the algorithm does not consider MULTIDATABASE QUERY OPTIMIZATION 5 the plans with bushy inners. Bushy tree plans are binary trees where both left and right subtrees may contain join nodes. <p> However, since they start with a left deep join tree and thus do not consider the bushy inners, they may miss less costly bushy trees. Multidatabase query processing, has also been addressed in [1, 3, 7, 19, 17, 23, 32]. But, [9] and <ref> [31] </ref> are the only ones that focus on intersite join optimization and only [9] has considered available parallelism to be exploited for query execution in multidatabases. <p> Note that the algorithm given in <ref> [31] </ref> is not compared to our work, since it only seeks minimum cost serial execution plans. [31] neither considers bushy plans nor tries to exploit parallelism in the execution of queries, although it utilizes the potential parallelism in multidatabases in favor of the optimization process. <p> Note that the algorithm given in <ref> [31] </ref> is not compared to our work, since it only seeks minimum cost serial execution plans. [31] neither considers bushy plans nor tries to exploit parallelism in the execution of queries, although it utilizes the potential parallelism in multidatabases in favor of the optimization process.
Reference: 32. <author> P. Scheurmann and E. Chong. </author> <title> "Role-based Query Processing in Multidatabase Systems", </title> <booktitle> in Proc. of EDBT, </booktitle> <year> 1994. </year>
Reference-contexts: However, since they start with a left deep join tree and thus do not consider the bushy inners, they may miss less costly bushy trees. Multidatabase query processing, has also been addressed in <ref> [1, 3, 7, 19, 17, 23, 32] </ref>. But, [9] and [31] are the only ones that focus on intersite join optimization and only [9] has considered available parallelism to be exploited for query execution in multidatabases. <p> Semiouterjoin operation produces two results, a semijoin and its complement. As pointed out in the paper this technique works well in all cases, no matter what the aggregation and selection conditions are. In [1] and <ref> [32] </ref>, role-based query processing in multidatabase systems are considered and methods are proposed. The approach suggested in [32] is based on the idea of presenting the answer to a query as a set of sets representing the distinct intersections between the relations corresponding to the various roles. <p> As pointed out in the paper this technique works well in all cases, no matter what the aggregation and selection conditions are. In [1] and <ref> [32] </ref>, role-based query processing in multidatabase systems are considered and methods are proposed. The approach suggested in [32] is based on the idea of presenting the answer to a query as a set of sets representing the distinct intersections between the relations corresponding to the various roles. This set is called a role set. Role-based query processing of [32] aims at minimizing the amount of data to be <p> The approach suggested in <ref> [32] </ref> is based on the idea of presenting the answer to a query as a set of sets representing the distinct intersections between the relations corresponding to the various roles. This set is called a role set. Role-based query processing of [32] aims at minimizing the amount of data to be transmitted between the local sites and the global site as well as reducing the processing costs at the global site for dealing with intermediate data and producing the final joins as in [3]. <p> For the join operation, after selections are performed, the global site sends the identifiers to each local site and each local site sends join attributes corresponding to each identifier <ref> [32] </ref>. If the join condition involves an aggregation, aggregate values are computed. Then, the role-sets are found by scanning each relation once comparing the join attribute values and the qualified tuples are stored in the buffer. <p> The method suggested in [3], on the other hand, requires expensive semiouterjoins in order to find the private and overlap parts which is done more efficiently via a merge-sort in <ref> [32] </ref>. In [19], query optimization and processing in Federated Database Management Systems (FDBMS) are discussed and methods for query processing and optimization are proposed. Query processing in [19] is treated at two levels: federation level and local level. <p> It should, therefore, be noted that the cost of a join operation generally accounts for only a fraction of the cost of an intersite join operation. The strategies described in [3] and <ref> [32] </ref> for processing the relational algebra operators such as selection, projection and join involving aggregation for multidatabases can readily be used within the optimization framework described in this paper. Different join processing strategies like the one given in [32], may easily be incorporated into our query processing and optimization model conforming <p> The strategies described in [3] and <ref> [32] </ref> for processing the relational algebra operators such as selection, projection and join involving aggregation for multidatabases can readily be used within the optimization framework described in this paper. Different join processing strategies like the one given in [32], may easily be incorporated into our query processing and optimization model conforming to the infrastructure of a multidatabase system. 4. Optimizing global subquery assignment in case of data replication Query decomposition has been extensively studied in [3] and [2].
Reference: 33. <author> P.G. Selinger, M.M. Astrahan, D.D. Chamberlin, R.A. Lorie, and T.G. Price, </author> <title> "Access Path Selection in a Relational Database Management System", </title> <booktitle> Proc. of ACM-SIGMOD , 1979. </booktitle>
Reference-contexts: Yet, traditional optimizers (e.g., System-R style <ref> [33] </ref>) produce left deep join trees which are not suitable for sort merge and hash joins with respect to response time, due to the long delay for a sort merge (or hash) join node to produce its last result after the subordinate join node did. <p> Using a linear join order in query optimization is an accepted practice and there are heuristics developed for this purpose. For example, System R <ref> [33] </ref> and R fl [18] consider execution plans in which a single table is joined at each step with the results of previous joins, in a pipelined way, producing a left deep join tree. In [15], the spanning tree of a query graph is used to find a linear order.
Reference: 34. <author> A. Wilschut, P. Apers. </author> <title> Dataflow Query Execution in a Parallel Main-Memory Environment, </title> <journal> Journal of Distributed and Parallel Databases, </journal> <volume> Vol. 1, No. 1, </volume> <pages> pp. 103-128, </pages> <publisher> Kluwer Academic Publishers, </publisher> <month> January, </month> <year> 1993. </year>
Reference-contexts: In a left deep tree, however, join nodes are not allowed in the right subtree, at each node a single table is joined with the results of the previous join in a pipelined fashion [14]. <ref> [34] </ref> states that left deep trees do not necessarily include the optimal plan for a parallel environment. It is further shown in [35] through experiments that bushy tree plans perform better. An intuitive example to clarify the point is as follows: Assume the left deep join tree (((AB)C)D) is given.
Reference: 35. <author> A. Wilschut, J. Flokstra, P. Apers. </author> <title> Parallel Evaluation of Multi-Join Queries, </title> <type> Technical Report, </type> <institution> University of Twente, </institution> <address> the Netherlands, </address> <year> 1994. </year> <note> Received Date Accepted Date Final Manuscript Date </note>
Reference-contexts: It is further shown in <ref> [35] </ref> through experiments that bushy tree plans perform better. An intuitive example to clarify the point is as follows: Assume the left deep join tree (((AB)C)D) is given. Although the least costly join to select first is (BC), the best plan could be ((AB)(CD)).
References-found: 35

