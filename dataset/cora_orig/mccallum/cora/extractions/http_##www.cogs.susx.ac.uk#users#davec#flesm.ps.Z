URL: http://www.cogs.susx.ac.uk/users/davec/flesm.ps.Z
Refering-URL: http://www.cogs.susx.ac.uk/users/davec/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-mail  @cogs.susx.ac.uk  
Title: Artificial Evolution of Visual Control Systems for Robots  
Author: Dave Cliff, Inman Harvey, and Phil Husbands 
Address: Brighton BN1 9QH, U.K.  
Affiliation: Adaptive Systems Research Group, School of Cognitive and Computing Sciences, University of Sussex,  
Note: To appear in M. Srinivisan and S. Venkatesh (eds) From Living Eyes to Seeing Machines. Oxford University Press, in press 1996. The authors are all from the Evolutionary and  davec or philh or inmanh, all  
Abstract: Many arthropods (particularly insects) exhibit sophisticated visually guided behaviours. Yet in most cases the behaviours are guided by input from a few hundreds or thousands of "pixels" (i.e. ommatidia in the compound eye). Inspired by this observation, we have for several years been exploring the possibilities of visually guided robots with low-bandwidth vision. Rather than design the robot controllers by hand, we use artificial evolution (in the form of an extended genetic algorithm) to automatically generate the architectures for artificial neural networks which generate effective sensory-motor coordination when controlling mobile robots. Analytic techniques drawn from neuroethology and dynamical systems theory allow us to understand how the evolved robot controllers function, and to predict their behaviour in environments other than those used during the evolutionary process. Initial experiments were performed in simulation, but the techniques have now been successfully transferred to work with a variety of real physical robot platforms. This chapter reviews our past work, concentrating on the analysis of evolved controllers, and gives an overview of our current research. We conclude with a discussion of the application of our evolutionary techniques to problems in biological vision. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. S. Altman and J. Kien. </author> <title> New models for motor control. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 173-183, </pages> <year> 1989. </year>
Reference-contexts: Activation values (all real numbers in the range <ref> [0; 1] </ref>) are transmitted between units along the connections, all of which have a weight of one, and impose a unit time delay in transmission. Fully asynchronous processing is simulated by fine-time-slice approximation techniques with random variation in time-cycling on each unit to counter periodic effects. <p> This may go some way toward explaining why subsumption-style controllers (i.e. behaviourally decomposed neuronal networks) have been identified in biological creatures <ref> [1, 12] </ref>. 3.2.4 Summary In this section, we have examined two controller networks evolved using incremental genetic algorithms, and found a form of speciation, in that two controllers evolved in separate populations produce convergent behaviours while employing divergent mechanisms for generating those be-haviours.
Reference: [2] <author> R. D. Beer. </author> <title> Intelligence as Adaptive Behaviour: An Experiment in Computational Neuroethol-ogy. </title> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: are performing a task directly analogous to the task faced by biological scientists in the field of neuroethology. (Neuroethology is the study of the neural mechanisms underlying the generation of a creature's behaviour; see e.g. [10].) For further details of the link between neuroethology and artificial neural network research, see <ref> [11, 2] </ref>.
Reference: [3] <author> R. D. Beer. </author> <title> A dynamical systems perspective on agent-environment interaction. </title> <journal> Artificial Intelligence, </journal> <volume> 72 </volume> <pages> 173-215, </pages> <year> 1995. </year>
Reference-contexts: We find this perspective less encumbering than the traditional 2 computational perspective, and also less amenable to the use of potentially misleading intentional language (see e.g. <ref> [3, 4, 33, 30] </ref> for further discussion of the benefits of adopting a dynamical systems perspective). In this chapter we show the analysis of two networks from separate populations, each evolved to perform the same task.
Reference: [4] <author> R. D. Beer. </author> <title> On the dynamics of small continuous-time recurrent neural networks. </title> <booktitle> Adaptive Behavior, </booktitle> <volume> 3(4) </volume> <pages> 471-511, </pages> <year> 1995. </year>
Reference-contexts: We find this perspective less encumbering than the traditional 2 computational perspective, and also less amenable to the use of potentially misleading intentional language (see e.g. <ref> [3, 4, 33, 30] </ref> for further discussion of the benefits of adopting a dynamical systems perspective). In this chapter we show the analysis of two networks from separate populations, each evolved to perform the same task.
Reference: [5] <author> R. A. Brooks. </author> <title> A robust layered control system for a mobile robot. A.I. </title> <type> Memo 864, </type> <institution> M.I.T. A.I. Lab, </institution> <month> September </month> <year> 1985. </year>
Reference-contexts: See <ref> [5, 6] </ref> for details of subsumption architectures, and e.g. [16] for an example of a two-layer subsumption visually guided robot.
Reference: [6] <author> R. A. Brooks. </author> <title> Achieving artificial intelligence through building robots. A.I. </title> <type> Memo 899, </type> <institution> M.I.T. A.I. Lab, </institution> <month> May </month> <year> 1986. </year>
Reference-contexts: See <ref> [5, 6] </ref> for details of subsumption architectures, and e.g. [16] for an example of a two-layer subsumption visually guided robot.
Reference: [7] <author> R. A. Brooks. </author> <title> Intelligence without reason. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (IJCAI-91), </booktitle> <pages> pages 139-159, </pages> <address> San Mateo, California, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Such a traditional approach would indeed require representations, but the need for representations is in the approach, not the problem. Other authors have questioned the need for traditional notions of representation and reasoning in artificial intelligence (e.g. <ref> [8, 7] </ref>). The evolutionary approach we employ entails that the need for representations (in the sense of maintaining internal world models) becomes an empirical question rather than a dogmatic axiom.
Reference: [8] <author> R. A. Brooks. </author> <title> Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 139-159, </pages> <year> 1991. </year>
Reference-contexts: Such a traditional approach would indeed require representations, but the need for representations is in the approach, not the problem. Other authors have questioned the need for traditional notions of representation and reasoning in artificial intelligence (e.g. <ref> [8, 7] </ref>). The evolutionary approach we employ entails that the need for representations (in the sense of maintaining internal world models) becomes an empirical question rather than a dogmatic axiom.
Reference: [9] <author> R. A. Brooks. </author> <title> Artificial life and real robots. </title> <editor> In F. J. Varela and P. Bourgine, editors, </editor> <booktitle> Toward a Practice of Autonomous Systems: Proceedings of the First European Conference on Artificial Life (ECAL91), </booktitle> <pages> pages 3-10, </pages> <address> Cambridge MA, 1992. </address> <publisher> MIT Press Bradford Books. </publisher>
Reference-contexts: a distal sensory modality that has been extensively studied in both natural and artificial systems, and we believe visually-guided agents should be studied from as early a stage as possible. * While we could impose on our robot some visual sensors with fixed properties, we advocate (in common with Brooks <ref> [9] </ref>) the concurrent evolution of visual sensor morphology and the 4 control networks: separating morphology from control is a measure which is difficult to justify from an evolutionary perspective, and potentially misleading. * For reasons of parsimony, studies of visually guided agents should commence by examining minimal systems.
Reference: [10] <author> J. M. Camhi. Neuroethology: </author> <title> Nerve Cells and the Natural Behaviour of Animals. </title> <publisher> Sinauer Associates Inc., </publisher> <address> Sunderland, Mass., </address> <year> 1984. </year> <month> 26 </month>
Reference-contexts: In trying to understand how our artificially evolved networks generate behaviours in the robot, we are performing a task directly analogous to the task faced by biological scientists in the field of neuroethology. (Neuroethology is the study of the neural mechanisms underlying the generation of a creature's behaviour; see e.g. <ref> [10] </ref>.) For further details of the link between neuroethology and artificial neural network research, see [11, 2].
Reference: [11] <author> D. Cliff. </author> <title> Computational neuroethology: A provisional manifesto. </title> <editor> In J.-A. Meyer and S. W. Wilson, editors, </editor> <booktitle> From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior (SAB90), </booktitle> <pages> pages 29-39, </pages> <address> Cambridge MA, </address> <year> 1991. </year> <institution> M.I.T. Press Bradford Books. Also available as University of Sussex School of Cognitive and Computing Sciences Technical Report CSRP162. </institution>
Reference-contexts: are performing a task directly analogous to the task faced by biological scientists in the field of neuroethology. (Neuroethology is the study of the neural mechanisms underlying the generation of a creature's behaviour; see e.g. [10].) For further details of the link between neuroethology and artificial neural network research, see <ref> [11, 2] </ref>.
Reference: [12] <author> D. Cliff. </author> <title> Neural networks for visual tracking in an artificial fly. </title> <editor> In F. J. Varela and P. Bourgine, editors, </editor> <title> Towards a Practice of Autonomous Systems: </title> <booktitle> Proceedings of the First European Conference on Artificial Life (ECAL91), </booktitle> <pages> pages 78-87. </pages> <publisher> MIT Press Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: This may go some way toward explaining why subsumption-style controllers (i.e. behaviourally decomposed neuronal networks) have been identified in biological creatures <ref> [1, 12] </ref>. 3.2.4 Summary In this section, we have examined two controller networks evolved using incremental genetic algorithms, and found a form of speciation, in that two controllers evolved in separate populations produce convergent behaviours while employing divergent mechanisms for generating those be-haviours.
Reference: [13] <author> D. Cliff, I. Harvey, and P. Husbands. </author> <title> Incremental evolution of neural network architectures for adaptive behaviour. </title> <type> Technical Report CSRP 256, </type> <institution> University of Sussex School of Cognitive and Computing Sciences, </institution> <year> 1992. </year>
Reference-contexts: Following that, Section 3 describes our experimental regime, and provides analysis of the two networks. Finally, Section 4 discusses our current research directions. 2 Background 2.1 Rationale The rationale for our work, and some early results, have been discussed elsewhere <ref> [24, 21, 15, 13] </ref>. The notes below present a brief summary of the important concepts. In common with a growing number of other researchers, we believe that the generation of adaptive behaviour should form the primary focus for research into cognitive systems. <p> For further details of the excitation transfer function, see <ref> [13] </ref>. *** Figure 1 near here *** We have found that this neuron model is sufficiently sophisticated that there has been no need 7 to introduce variable connection weights or variable delays for controllers based on the minimal visual systems studied so far. <p> Given that in the current system all units have the same excitatory transfer function, with a fixed gradient of 0.5 on the linear ramp between the lower and upper thresholds (c.f. Figure 1 and <ref> [13] </ref>), distributor units are acting as doubly-delayed connections with weight 0.5. In Section 3.1.2 it was stated that all links have a weight of one and impose a unit time delay: the use of distributor units allows for "virtual connections" to evolve which have different weights or delays. <p> Such networks exhibited graceful degradation in the presence of increased noise. During evolution, an internal noise distribution of 0:1 was used; we found the robots could still approach the centre with noise distributions as high as (in the case of C1) 0:8: see <ref> [13] </ref>. In almost all of the networks we have analysed, there has been no clearly identifiable structure. C2 is a clear example.
Reference: [14] <author> D. Cliff, I. Harvey, and P. Husbands. </author> <booktitle> Explorations in evolutionary robotics. Adaptive Behavior, </booktitle> <volume> 2(1) </volume> <pages> 71-108, </pages> <year> 1993. </year>
Reference-contexts: The simulations involve a model of a real robot built at Sussex, and advanced computer graphics techniques (namely, ray-tracing with antialiasing via sixteen-fold supersampling: see e.g. [17]) are used to faithfully simulate optical image-formation. For reasons given in <ref> [14] </ref>, we are approaching the task of creating artificial agents that exhibit adaptive behaviour in accordance with the following set of beliefs: * `Neural'-network processors are likely to be most useful in building controllers for agents that exhibit adaptive behaviour. * Manual design of such networks is likely to become prohibitively <p> The direction of view of the photoreceptors, and their acceptance angles, are under evolutionary control: it in this sense that the visual morphology is concurrently evolved along with the controller network. For full details of the genetic encoding for both the control networks and the visual system, see <ref> [14] </ref>. Because there are only two photoreceptors, we can only expect to evolve robots which exhibit relatively simple behaviours. Nevertheless, we have concentrated on evolving robots which perform tasks that would be difficult or impossible using only tactile information. <p> Each genotype consists of two chromosomes: one is an encoding of the control network, the other encodes parameters governing the visual morphology <ref> [14] </ref>. Initially, all the genotypes in the population are random. On every generation, each genotype is evaluated, and assigned a fitness score. The genotypes are then `interbred', with mutation and crossover according to saga principles [19, 20], thereby creating a new population.
Reference: [15] <author> D. Cliff, P. Husbands, and I. Harvey. </author> <title> Evolving visually guided robots. </title> <editor> In J.-A. Meyer, H. Roitblat, and S. Wilson, editors, </editor> <booktitle> Proceedings of the Second International Conference on Simulation of Adaptive Behaviour (SAB92), </booktitle> <pages> pages 374-383. </pages> <publisher> MIT Press Bradford Books, </publisher> <address> Cam-bridge, MA, </address> <year> 1993. </year> <note> Also available as University of Sussex School of Cognitive and Computing Sciences Technical Report CSRP220. </note>
Reference-contexts: Following that, Section 3 describes our experimental regime, and provides analysis of the two networks. Finally, Section 4 discusses our current research directions. 2 Background 2.1 Rationale The rationale for our work, and some early results, have been discussed elsewhere <ref> [24, 21, 15, 13] </ref>. The notes below present a brief summary of the important concepts. In common with a growing number of other researchers, we believe that the generation of adaptive behaviour should form the primary focus for research into cognitive systems. <p> The rear wheel is a large ball-bearing freewheel castor. The robot is equipped with tactile sensors giving a six-bit input vector: it has four radially oriented binary `whiskers', and binary `bumper-bars' at front and rear. For illustration, see <ref> [15] </ref>. The simulated robots are accurate models of such a vehicle, with the addition of visual sensors. While our early tactile-only work involved the robot roving around cluttered office-like environments, the visually-guided tasks analysed here were set in a closed circular arena. <p> Essentially, the population of robots has to evolve to correlate visual input (and internal 6 state) with motor outputs in order to score highly on whatever fitness metric we impose on the robot's behaviours. As was demonstrated in <ref> [15] </ref>, visual guidance emerges without explicit reference to vision in the evaluation process. In the early stages of evolution, the tactile sensors can be useful in helping correlate visual input with the robot's situation.
Reference: [16] <author> N. Franceschini, J.-M. Pichon, and C. Blanes. </author> <title> Real time visuomotor control: from flies to robots. </title> <booktitle> In Proceedings of the 1991 International Conference on Advanced Robotics, </booktitle> <address> Pisa, </address> <year> 1991. </year>
Reference-contexts: In effect, our intention is to evolve a specification for a robot with electronic compound eyes (c.f. <ref> [16] </ref>). 3 Analysing Evolved Sensory-Motor Controllers In accordance with the last item in the above list, our early work addressed evolving visually guided robots with just two photoreceptors (i.e. two `pixels' in the input images). <p> See [5, 6] for details of subsumption architectures, and e.g. <ref> [16] </ref> for an example of a two-layer subsumption visually guided robot.
Reference: [17] <author> A. S. Glassner, </author> <title> editor. An Introduction to Ray Tracing. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1989. </year> <month> 27 </month>
Reference-contexts: The work discussed here uses artificial evolution on populations of simulated robots. The simulations involve a model of a real robot built at Sussex, and advanced computer graphics techniques (namely, ray-tracing with antialiasing via sixteen-fold supersampling: see e.g. <ref> [17] </ref>) are used to faithfully simulate optical image-formation.
Reference: [18] <author> D. E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Inspired by this observation, we have for several years been exploring the possibilities of visually guided robots with ultra-low-bandwidth vision. Rather than design the robot controllers by hand, we use artificial evolution (in the form of an extended genetic algorithm: see e.g. <ref> [23, 18] </ref>) to automatically generate the architectures for artificial neural networks which generate effective sensory-motor coordination when controlling mobile robots. Initial experiments were performed in simulation, but the techniques have since been successfully transferred to work with a variety of real physical robot platforms.
Reference: [19] <author> I. Harvey. </author> <title> Species adaptation genetic algorithms: A basis for a continuing SAGA. </title> <editor> In F.J. Varela and P. Bourgine, editors, </editor> <title> Towards a Practice of Autonomous Systems: </title> <booktitle> Proceedings of the First European Conference on Artificial Life (ECAL91), </booktitle> <pages> pages 346-354. </pages> <publisher> M.I.T. Press Bradford Books, </publisher> <address> Cambridge MA, </address> <year> 1992. </year> <note> Also available as University of Sussex School of Cognitive and Computing Sciences Technical Report CSRP221. </note>
Reference-contexts: Rather than design-by-hand, we are employing artificial evolution techniques, based on Harvey's saga variable-length genotype methods <ref> [19, 20] </ref>. * Almost all adaptive behaviours benefit from distal (i.e. long-range) sensory information. <p> Initially, all the genotypes in the population are random. On every generation, each genotype is evaluated, and assigned a fitness score. The genotypes are then `interbred', with mutation and crossover according to saga principles <ref> [19, 20] </ref>, thereby creating a new population. This process continues for a specified number of generations (in the work discussed here, genotypes were evolved over 100 generations). <p> The two populations therefore show a form of speciation, in that the two populations can be considered as different species, performing the same task. This is an accordance with the principles underlying the saga genetic algorithm we used <ref> [19, 20] </ref>. Such networks exhibited graceful degradation in the presence of increased noise. During evolution, an internal noise distribution of 0:1 was used; we found the robots could still approach the centre with noise distributions as high as (in the case of C1) 0:8: see [13].
Reference: [20] <author> I. Harvey. </author> <title> Evolutionary robotics and SAGA: the case for hill crawling and tournament selection. </title> <editor> In C. Langton, editor, </editor> <booktitle> Artificial Life 3 Proceedings, </booktitle> <pages> pages 299-326. </pages> <booktitle> Santa Fe Institute Studies in the Sciences of Complexity, Proc. </booktitle> <volume> Vol. </volume> <pages> XVI, </pages> <publisher> Addison Wesley., </publisher> <year> 1993. </year> <note> Also available as University of Sussex School of Cognitive and Computing Sciences Technical Report CSRP222, </note> <year> 1992. </year>
Reference-contexts: Rather than design-by-hand, we are employing artificial evolution techniques, based on Harvey's saga variable-length genotype methods <ref> [19, 20] </ref>. * Almost all adaptive behaviours benefit from distal (i.e. long-range) sensory information. <p> Initially, all the genotypes in the population are random. On every generation, each genotype is evaluated, and assigned a fitness score. The genotypes are then `interbred', with mutation and crossover according to saga principles <ref> [19, 20] </ref>, thereby creating a new population. This process continues for a specified number of generations (in the work discussed here, genotypes were evolved over 100 generations). <p> The two populations therefore show a form of speciation, in that the two populations can be considered as different species, performing the same task. This is an accordance with the principles underlying the saga genetic algorithm we used <ref> [19, 20] </ref>. Such networks exhibited graceful degradation in the presence of increased noise. During evolution, an internal noise distribution of 0:1 was used; we found the robots could still approach the centre with noise distributions as high as (in the case of C1) 0:8: see [13].
Reference: [21] <author> I. Harvey, P. Husbands, and D. Cliff. </author> <title> Issues in evolutionary robotics. </title> <editor> In J.-A. Meyer, H. Roit-blat, and S. Wilson, editors, </editor> <booktitle> Proceedings of the Second International Conference on Simulation of Adaptive Behaviour (SAB92), </booktitle> <pages> pages 364-373. </pages> <publisher> M.I.T. Press Bradford Books, </publisher> <address> Cambridge MA, </address> <year> 1993. </year> <note> Also available as University of Sussex School of Cognitive and Computing Sciences Technical Report CSRP219. </note>
Reference-contexts: Following that, Section 3 describes our experimental regime, and provides analysis of the two networks. Finally, Section 4 discusses our current research directions. 2 Background 2.1 Rationale The rationale for our work, and some early results, have been discussed elsewhere <ref> [24, 21, 15, 13] </ref>. The notes below present a brief summary of the important concepts. In common with a growing number of other researchers, we believe that the generation of adaptive behaviour should form the primary focus for research into cognitive systems. <p> For demonstration of our methods working with only proximal sensors, see <ref> [24, 21] </ref>.
Reference: [22] <author> I. Harvey, P. Husbands, and D. Cliff. </author> <title> Seeing the light: Artificial evolution; real vision. </title> <editor> In D. Cliff, P. Husbands, J.-A. Meyer, and S. W. Wilson, editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior (SAB94), </booktitle> <pages> pages 392-401. </pages> <publisher> MIT Press Bradford Books, </publisher> <year> 1994. </year>
Reference-contexts: Although Thompson's work to date has concentrated on sonar-guided robots, there is no a priori reason why his techniques could not be applied to develop semiconductor circuits for controlling visually guided robots. 4.1.3 Working with Real Vision We <ref> [22] </ref> developed a specialised `gantry' robot which included a mobile video-camera head with one rotational and three translational degrees of freedom. The video camera supplied 50Hz input of 64fi 64 grey-level images, which were used for real-time guidance as the head moved around simple visual environments. <p> Evolved behaviours included tracking of a (slowly) moving target, and a discrimination task. The discrimination task involved the controller moving the camera-head towards a triangular target while avoiding moving near to a rectangular target. The final evolved controller described in <ref> [22] </ref> successfully performed this task using the equivalent of just two individual photoreceptors. 4.2 Artificial Evolution in Biological Modelling So far, we have concentrated on describing our techniques as applied to the engineering problems of designing sensory-motor controllers.
Reference: [23] <author> J. H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> University of Michigan Press, </publisher> <address> Ann Arbour, </address> <year> 1975. </year> <month> 28 </month>
Reference-contexts: Inspired by this observation, we have for several years been exploring the possibilities of visually guided robots with ultra-low-bandwidth vision. Rather than design the robot controllers by hand, we use artificial evolution (in the form of an extended genetic algorithm: see e.g. <ref> [23, 18] </ref>) to automatically generate the architectures for artificial neural networks which generate effective sensory-motor coordination when controlling mobile robots. Initial experiments were performed in simulation, but the techniques have since been successfully transferred to work with a variety of real physical robot platforms.
Reference: [24] <author> P. Husbands and I. Harvey. </author> <title> Evolution versus design: Controlling autonomous robots. In Inte--grating Perception, Planning and Action, </title> <booktitle> Proceedings of 3rd Annual Conference on Artificial Intelligence, Simulation and Planning, </booktitle> <pages> pages 139-146. </pages> <publisher> IEEE Press, </publisher> <year> 1992. </year>
Reference-contexts: Following that, Section 3 describes our experimental regime, and provides analysis of the two networks. Finally, Section 4 discusses our current research directions. 2 Background 2.1 Rationale The rationale for our work, and some early results, have been discussed elsewhere <ref> [24, 21, 15, 13] </ref>. The notes below present a brief summary of the important concepts. In common with a growing number of other researchers, we believe that the generation of adaptive behaviour should form the primary focus for research into cognitive systems. <p> For demonstration of our methods working with only proximal sensors, see <ref> [24, 21] </ref>.
Reference: [25] <author> P. Husbands, I. Harvey, and D. Cliff. </author> <title> Circle in the round: State space attractors for evolved sighted robots. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 15 </volume> <pages> 83-106, </pages> <year> 1995. </year>
Reference-contexts: Hence, to complement the qualitative analysis, we developed a quantitative analysis of C2, drawing on ideas from dynamical systems theory. Full details are given in <ref> [25] </ref>: we present a brief summary here.
Reference: [26] <author> N. Jakobi. </author> <title> Evolving sensorimotor control architectures in simulation for a real robot. </title> <type> Master's thesis, </type> <institution> University of Sussex School of Cognitive and Computing Sciences, </institution> <year> 1994. </year> <note> Unpublished. </note>
Reference-contexts: Here we briefly review results from our work with real robots. For a review of related research by others, see [28]. 4.1.1 Transferring from Simulation to Reality Jakobi <ref> [26, 27] </ref> developed a simulator for a proprietary small differentially driven mobile robot which has eight infra-red emitter-detector proximity sensors. The detector elements have some sensitivity to visible wavelengths, and the emitters can be disabled to allow the sensors to operate as photoreceptors.
Reference: [27] <author> N. Jakobi, P. Husbands, and I. Harvey. </author> <title> Noise and the reality gap: The use of simulation in evolutionary robotics. </title> <editor> In F. Moran, A. Moreno, J. J. Merelo, and P.Chacon, editors, </editor> <booktitle> Advances in Artificial Life: Proceedings of the Third European Conference on Artificial Life, </booktitle> <pages> pages 704-720. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Here we briefly review results from our work with real robots. For a review of related research by others, see [28]. 4.1.1 Transferring from Simulation to Reality Jakobi <ref> [26, 27] </ref> developed a simulator for a proprietary small differentially driven mobile robot which has eight infra-red emitter-detector proximity sensors. The detector elements have some sensitivity to visible wavelengths, and the emitters can be disabled to allow the sensors to operate as photoreceptors.
Reference: [28] <author> M. J. Mataric and D. Cliff. </author> <title> Challenges in evolving controllers for physical robots. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <year> 1995. </year> <journal> Special issue on "Evolutional Robotics". Forthcoming 1995/96. </journal>
Reference-contexts: Here we briefly review results from our work with real robots. For a review of related research by others, see <ref> [28] </ref>. 4.1.1 Transferring from Simulation to Reality Jakobi [26, 27] developed a simulator for a proprietary small differentially driven mobile robot which has eight infra-red emitter-detector proximity sensors.
Reference: [29] <author> G. F. Miller and D. Cliff. </author> <title> Protean behavior in dynamic games: Arguments for the co-evolution of pursuit-evasion tactics. </title> <editor> In D. Cliff, P. Husbands, J.-A. Meyer, and S. Wilson, editors, </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior (SAB94), </booktitle> <pages> pages 411-420. </pages> <publisher> MIT Press Bradford Books, </publisher> <address> Cambridge MA, </address> <year> 1994. </year>
Reference-contexts: To evaluate the feasibility of this approach, we are currently evolving neural circuits for 24 visually-guided pursuit behaviours, with the intention of comparing the evolved controllers to the neuroethological data on visual control of pursuit in flying insects: see <ref> [29] </ref> for further details. 5 Conclusion In this chapter we have demonstrated that low-bandwidth visual systems can be evolved and analysed. The important achievement is not that we got a simulated robot to perform a particular visually guided behaviour, nor that the behaviours were generated by evolved neural networks.
Reference: [30] <author> T. Smithers. </author> <title> Taking eliminative materialism seriously: A methodology for autonomous systems research. </title> <editor> In F. J. Varela and P. Bourgine, editors, </editor> <title> Towards a Practice of Autonomous Systems: </title> <booktitle> Proceedings of the First European Conference on Artificial Life (ECAL91), </booktitle> <pages> pages 31-40. </pages> <publisher> MIT Press Bradford Books, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year> <month> 29 </month>
Reference-contexts: We find this perspective less encumbering than the traditional 2 computational perspective, and also less amenable to the use of potentially misleading intentional language (see e.g. <ref> [3, 4, 33, 30] </ref> for further discussion of the benefits of adopting a dynamical systems perspective). In this chapter we show the analysis of two networks from separate populations, each evolved to perform the same task.
Reference: [31] <author> D. Stork, B. Jackson, and S. Walker. </author> <title> `Non-Optimality' via pre-adaptation in simple neural systems. </title> <editor> In C. Langton, C. Taylor, J. D. Farmer, and S. Rasmussen, editors, </editor> <booktitle> Artificial Life II, </booktitle> <pages> pages 409-429. </pages> <publisher> Addison Wesley, </publisher> <year> 1992. </year>
Reference-contexts: Many of the redundant units or connections are likely to be "evolutionary scaffolding": i.e. vestigial parts of the network which served a purpose in earlier generations but are now no longer useful c.f. <ref> [31] </ref>. Furthermore, we can attempt to identify different sensory-motor pathways.
Reference: [32] <author> A. Thompson. </author> <title> Evolving electronic robot controllers that exploit hardware resources. </title> <editor> In F. Moran, A. Moreno, J. J. Merelo, and P.Chacon, editors, </editor> <booktitle> Advances in Artificial Life: Proceedings of the Third European Conference on Artificial Life, </booktitle> <pages> pages 640-656. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: The behaviours included obstacle avoidance and phototaxis. 4.1.2 Evolving Controller Hardware Circuits Thompson <ref> [32] </ref> has demonstrated the successful evolution of reconfigurable electronic hardware for robot control. Rather than evolve designs for parallel neural networks which are simulated 22 on serial computers, Thompson's technique evolves real physical semiconductor circuits which are evaluated in situ in the real robot.

References-found: 32

