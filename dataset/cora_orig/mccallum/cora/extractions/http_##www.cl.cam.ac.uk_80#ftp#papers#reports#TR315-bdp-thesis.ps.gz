URL: http://www.cl.cam.ac.uk:80/ftp/papers/reports/TR315-bdp-thesis.ps.gz
Refering-URL: http://www.cl.cam.ac.uk:80/ftp/papers/reports/
Root-URL: 
Title: Strategy Generation and Evaluation for Meta-Game Playing  
Author: Barney Darryl Pell 
Degree: A dissertation submitted for the degree of Doctor of Philosophy in the  
Date: August 1993  
Address: College  Cambridge  
Affiliation: Trinity  University of  
Abstract-found: 0
Intro-found: 1
Reference: [Abramson, 1990] <author> Bruce Abramson. Expected-outcome: </author> <title> A general model of static evaluation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(2), </volume> <month> February </month> <year> 1990. </year>
Reference-contexts: Abramson <ref> [Abramson, 1990] </ref> found a similar result when learning weights for base-level features in chess: a program using a random assignment of weights for chess pieces (i.e. material values) performed significantly better than a program which assigned random values to positions as a whole. <p> 10 4 4 avg-static-mob 8.96 2.4 3.2 avg-eventual-mob 8.8 2.56 3.24 eradicate 0 0 0 victims 6 6 6 immunity 0 0 0 giveaway 3 3 3 stalemate -1 -1 -1 arrive 0 0 0 Total 47.8 21 22.4 Table 15.6: Material value analysis for turncoat-chess. 15.6.6.1 Expected Outcome Abramson <ref> [Abramson, 1990] </ref> developed a technique for determining feature values based on predicting the expected-outcome of a position in which particular features (not only piece values) were present. <p> Unless indicated otherwise, the results are significant at the .01 (1%) level. In using this test, draws have been absorbed into the total outcomes such that two draws are considered equivalent to one win and one loss (this absorption was also used by <ref> [Abramson, 1990] </ref>). 16.4 Results The results of the competition on each game are presented in Table 16.2-Table 16.6. Table 16.7 summarises the results of the competition between each pair of players summed across all 5 games. Table 16.8 summarises the results of each player on each game. <p> Diagram 23 Final Position. 0Z0Z0Z0L 0Z0ZnZpZ Z0lpokZ0 0Z0Z0ZpZ 0Z0J0Z0Z 17.4.3 Games against Chess Material Function For purposes of comparison, a version of metagamer with only a standard hand-encoded material evaluation function (queen=9, rook=5, bishop=3.25, knight=3, and pawn=1) <ref> [Botvinnik, 1970; Abramson, 1990] </ref> played against the versions of meta-gamer and GnuChess used in the example games here. The result was that the material program lost every game at knight's handicap against GnuChess, and lost 182 CHAPTER 17. EXAMPLES ON KNOWN GAMES every game at even material against metagamer.
Reference: [Aho et al., 1983] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman. </author> <title> Data Structures and Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1983. </year>
Reference-contexts: We also remove all triples where SqT is a losing square but not in promotion region (as those squares in promotion region may allow us to promote into a new kind of piece). Distance-matrix: Based on the constrained-matrix, this matrix contains the solution of the all-pairs-shortest-paths (APSP) problem <ref> [Aho et al., 1983] </ref> to determine for each piece P and pair of squares hSqF; SqT i, the number of moves P would take to move from SqF to SqT .
Reference: [Allis et al., 1991a] <author> L.V. Allis, H.J. van den Herik, </author> <title> and I.S. Herschberg. Which games will survive. </title> <editor> In D.N.L. Levy and D.F. Beal, editors, </editor> <booktitle> Heuristic Programming in Artificial Intelligence 2 The Second Computer Olympiad. </booktitle> <publisher> Ellis Horwood, </publisher> <year> 1991. </year>
Reference: [Allis et al., 1991b] <editor> L.V. Allis, M. van der Meulen, and H.J. van den Herik. Databases in awari. In D.N.L. Levy and D.F. Beal, editors, </editor> <booktitle> Heuristic Programming in Artificial Intelligence 2 The Second Computer Olympiad. </booktitle> <publisher> Ellis Horwood, </publisher> <year> 1991. </year>
Reference: [Allis, 1992] <editor> Victor Allis. Qubic solved again. In H.J. van den Herik and L.V. Allis, editors, </editor> <booktitle> Heuristic Programming in Artificial Intelligence 3 The Third Computer Olympiad, </booktitle> <pages> pages 192-204. </pages> <publisher> Ellis Horwood, </publisher> <year> 1992. </year>
Reference: [Angeline and Pollack, 1993] <author> P. Angeline and J. Pollack. </author> <title> Competitive environments evolve better solutions for complex tasks. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Another idea would be to use a genetic approach with competition among a population of players with different weights (subject to the constraints on weights listed in Section 15.5). One interesting recent approach to weight learning <ref> [Angeline and Pollack, 1993] </ref> has a population of programs compete repeatedly in a knockout tournament, in which winners advance to the next round and losers play against each other.
Reference: [Axelrod, 1987] <author> Robert Axelrod. </author> <title> The evolution of strategies in the iterated prisoner's dilemma. </title> <editor> In Lawrence Davis, editor, </editor> <title> Genetic Algorithms and Simulated Annealing. </title> <publisher> Pitman, </publisher> <year> 1987. </year>
Reference: [Banerji and Ernst, 1971] <author> R. B. Banerji and G.W. Ernst. </author> <title> Changes of representation which preserve strategies in games. </title> <booktitle> In Proceedings of the Second International Joint Conference on AI, </booktitle> <year> 1971. </year>
Reference: [Banks, 1988] <author> Iain M. </author> <title> Banks. The Player of Games. </title> <publisher> Macmillan (London) Ltd, </publisher> <year> 1988. </year>
Reference: [Baum and Smith, 1993] <author> Eric B. Baum and Warren D. Smith. </author> <title> Best play for imperfect players and game tree search. </title> <booktitle> In Proceedings of the AAAI Fall Symposium on Games: Planning and Learning. </booktitle> <publisher> AAAI Press, </publisher> <year> 1993. </year> <note> To Appear. 259 260 BIBLIOGRAPHY </note>
Reference-contexts: These would need to be extended to games beyond just chess. Another approach would be to apply some of the recent developments in rational game-tree search <ref> [Russell and Wefald, 1992; Baum and Smith, 1993; Good, 1968] </ref> to SCL-Metagame.
Reference: [Bell, 1969] <author> R.C. Bell. </author> <title> Board and Table Games from Many Civilizations. </title> <publisher> Oxford University Press, </publisher> <year> 1969. </year>
Reference: [Benjamin, 1990] <author> D. Paul Benjamin, </author> <title> editor. Change of Representation and Inductive Bias. </title> <publisher> Kluwer, </publisher> <year> 1990. </year>
Reference-contexts: However, the issue of automatic efficient change of representation is a very important scientific problem <ref> [Benjamin, 1990] </ref>. This chapter has shown how techniques from logic programming can greatly assist in this endeavour. 112 CHAPTER 12.
Reference: [Berlekamp et al., 1982] <author> E.R. Berlekamp, J.H. Conway, and R.K. Guy. </author> <title> Winning Ways for your mathematical plays. </title> <publisher> Academic Press, </publisher> <year> 1982. </year>
Reference: [Berliner, 1974] <author> Hans Berliner. </author> <title> Chess as Problem Solving: The Developments of a Tactics Analyzer. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Carnegie-Mellon University, Pittsburgh, </institution> <year> 1974. </year>
Reference-contexts: One way to address this problem might be through a tactics analyzer as developed by Berliner <ref> [Berliner, 1974] </ref> or a knowledge-based planner as developed by Wilkins [Wilkins, 1982]. These would need to be extended to games beyond just chess. To summarise metagamer's performance in chess, it's play is reasonable and it looks like it has a basic understanding of some chess strategy. <p> Almost any improvement should produce a markedly better player. One way to address this problem might be through a tactics analyser as developed by Berliner <ref> [Berliner, 1974] </ref> or a knowledge-based planner as developed by Wilkins [Wilkins, 1982]. These would need to be extended to games beyond just chess. Another approach would be to apply some of the recent developments in rational game-tree search [Russell and Wefald, 1992; Baum and Smith, 1993; Good, 1968] to SCL-Metagame.
Reference: [Berliner, 1978] <author> Hans Berliner. </author> <title> A chronology of computer chess and its literature. </title> <journal> Artificial Intelligence, </journal> <volume> 10 </volume> <pages> 201-214, </pages> <year> 1978. </year>
Reference: [Berliner, 1984] <author> Hans Berliner. </author> <title> Search vs knowledge: An analysis from the domain of games. </title> <editor> In Elithorn and Banerji, editors, </editor> <booktitle> Artificial and Human Intelligence. </booktitle> <publisher> Elsevier Science Publishers, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: strong opponent from which to learn. 15.5.1 Constraints on Weights By the construction of some of the advisors, we can determine at least a few significant constraints on their possible weights. 9 In the current implementation, only the final promotion square is inspected dynamically, due to efficiency considerations. 10 Berliner <ref> [Berliner, 1984] </ref> discussed at length this issue of the tradeoff between knowledge and search in game-playing programs. 15.5. WEIGHTS FOR ADVISORS 143 15.5.1.1 Regressed Goals are Always Fractional First, for advisors which anticipate goal-achievement (promote-distance and threats), it seems that their weights should always be at most 1. <p> In other words, the time taken to apply the knowledge during problem-solving may be better spent searching more deeply instead. This problem has been called the utility problem [Minton, 1990], and the tradeoff between knowledge and search has been considered in depth within both the game-playing and problem-solving communities <ref> [Berliner, 1984; Callan, 1993; Fawcett and Utgoff, 1992] </ref>. Moreover, it could also be possible that the generator produced only drawn or hopelessly complicated games, in which case metagamer could not demonstrate an advantage even if its knowledge was correct and efficient.
Reference: [Botvinnik, 1970] <author> M. M. Botvinnik. </author> <title> Computers, chess and long-range planning. </title> <publisher> Springer-Verlag New York, Inc., </publisher> <year> 1970. </year>
Reference-contexts: The result of this is that a player could achieve goals which require thousands of moves by making only immediate decisions. The static analysis table constructed for this purpose (distance-matrix) was motivated by a dynamic version of the same computation developed by <ref> [Botvinnik, 1970] </ref> and later extended by [Church and Church, 1979] and [Snyder, 1993]. Two systems exist which derive step functions directly from problem specifications: Zenith [Fawcett and Utgoff, 1992] and CINDI [Callan and Utgoff, 1991]. <p> The advisors can be categorised into four groups, based on the general concept from which they derive. 15.3.1 Mobility Advisors The first group is concerned with different indicators of mobility. These advisors were inspired in part by [Church and Church, 1979] and <ref> [Botvinnik, 1970] </ref>, and are motivated in Section 14.2 and Section 14.4. * dynamic-mobility:counts the number of squares to which a piece can move directly from its current square on the current board, using a moving power. 3 * static-mobility:a static version of immediate-mobility, this counts the number of squares to which <p> Diagram 23 Final Position. 0Z0Z0Z0L 0Z0ZnZpZ Z0lpokZ0 0Z0Z0ZpZ 0Z0J0Z0Z 17.4.3 Games against Chess Material Function For purposes of comparison, a version of metagamer with only a standard hand-encoded material evaluation function (queen=9, rook=5, bishop=3.25, knight=3, and pawn=1) <ref> [Botvinnik, 1970; Abramson, 1990] </ref> played against the versions of meta-gamer and GnuChess used in the example games here. The result was that the material program lost every game at knight's handicap against GnuChess, and lost 182 CHAPTER 17. EXAMPLES ON KNOWN GAMES every game at even material against metagamer.
Reference: [Bratko, 1986] <author> Ivan Bratko. </author> <title> Prolog Programming for Artificial Intelligence. </title> <publisher> Addison Wesley, </publisher> <year> 1986. </year>
Reference-contexts: It is based on a Prolog implementation of the minimax algorithm with alpha-beta pruning, as presented in <ref> [Bratko, 1986, page 366] </ref>. In order to cope with the dual issues of time limits and varying search spaces, this basic algorithm is extended with iterative deepening [Korf, 1985].
Reference: [Callan and Utgoff, 1991] <author> J. P. Callan and P.E. Utgoff. </author> <title> Constructive induction on domain knowledge. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 614-619, </pages> <year> 1991. </year>
Reference-contexts: Two systems exist which derive step functions directly from problem specifications: Zenith [Fawcett and Utgoff, 1992] and CINDI <ref> [Callan and Utgoff, 1991] </ref>. <p> This same consideration also applies to other work on self-play, which was discussed in Section 3.3.4. 15.6.6.2 Automatic Feature Generation There has recently been much progress in developing programs which generate features automatically from the rules of games <ref> [de Grey, 1985; Callan and Utgoff, 1991; Fawcett and Utgoff, 1992] </ref>. When applied to chess such programs produce features which count the number of chess pieces of each type, and when applied to Othello they produce features which measure different aspects of positions which are corre 15.7.
Reference: [Callan et al., 1991] <author> James P. Callan, Tom E. Fawcett, and Edwina L. Rissland. </author> <title> Adaptive case-based reasoning. </title> <booktitle> In Proceedings of the 12th International Joint Conference on Artificial Intelligence, </booktitle> <year> 1991. </year>
Reference: [Callan, 1993] <author> James P. Callan. </author> <title> Knowledge-Based Feature Generation for Inductive Learning. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Science, University of Massachusetts, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: In other words, the time taken to apply the knowledge during problem-solving may be better spent searching more deeply instead. This problem has been called the utility problem [Minton, 1990], and the tradeoff between knowledge and search has been considered in depth within both the game-playing and problem-solving communities <ref> [Berliner, 1984; Callan, 1993; Fawcett and Utgoff, 1992] </ref>. Moreover, it could also be possible that the generator produced only drawn or hopelessly complicated games, in which case metagamer could not demonstrate an advantage even if its knowledge was correct and efficient. <p> One approach to this problem would be to extend the techniques used for efficiency specialisation in Chapter 12 to derive useful subgoals and invariant properties for a given game by abstract interpretation. It might also be possible to apply knowledge 19.4. LIMITATIONS AND FUTURE WORK 195 based feature construction <ref> [Callan, 1993; Fawcett and Utgoff, 1992] </ref> directly to this problem, as it is designed to extract functional features from a logical encoding of problem definitions. 19.4.3 Advanced Search Techniques Chapter 17 noted that while metagamer's analysis of each game seemed to give it a basic understanding of strategy, it is noticeably
Reference: [Campbell, 1988] <author> Murray S. Campbell. </author> <title> Chunking as an Abstraction Mechanism. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1988. </year>
Reference-contexts: It would be an interesting area for future work to develop a general reasoning method which could be applied to checkers and similar games to solve problems like this. One possibility would be a generalisation of work on using knowledge and plans to control search <ref> [Wilkins, 1982; Campbell, 1988; Tadepalli, 1989a] </ref>. Another possibility is to add an advisor to metagamer which is able to construct simple endgame databases, perhaps generating first those which are simplest and most common.
Reference: [Chaitin, 1987] <author> Gregory J. Chaitin. </author> <title> Algorithmic information theory. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1987. </year>
Reference: [Chomsky, 1965] <author> Noam Chomsky. </author> <title> Aspects of the Theory of Syntax. </title> <publisher> MIT Press, </publisher> <address> Boston, </address> <year> 1965. </year> <note> BIBLIOGRAPHY 261 </note>
Reference-contexts: This will be demonstrated 13 There is an important connection here to the subfield of linguistics called universal grammar <ref> [Chomsky, 1965] </ref> or more recently principles-based parsing [Fong, 1991]. Rather than writing detailed parsers for specific languages, this field develops general linguistic principles.
Reference: [Church and Church, 1979] <author> Russell M. Church and Kenneth W. Church. </author> <title> Plans, goals, and search strategies for the selection of a move in chess. </title> <editor> In Peter W. Frey, editor, </editor> <booktitle> Chess Skill in Man and Machine. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1979. </year>
Reference-contexts: The result of this is that a player could achieve goals which require thousands of moves by making only immediate decisions. The static analysis table constructed for this purpose (distance-matrix) was motivated by a dynamic version of the same computation developed by [Botvinnik, 1970] and later extended by <ref> [Church and Church, 1979] </ref> and [Snyder, 1993]. Two systems exist which derive step functions directly from problem specifications: Zenith [Fawcett and Utgoff, 1992] and CINDI [Callan and Utgoff, 1991]. <p> For example, it can be determined statically that a pawn defends a piece because it could capture any enemy piece on the same square as the defended piece, and this replacement necessarily occurs whenever the enemy captures the defended piece. This property is exploited by several strategic chess programs <ref> [Church and Church, 1979; Botvin-nik, 1970; Snyder, 1993] </ref>. However, the assumptions behind this approach become clear when we consider pieces with capturing methods other than clobbering. <p> The advisors can be categorised into four groups, based on the general concept from which they derive. 15.3.1 Mobility Advisors The first group is concerned with different indicators of mobility. These advisors were inspired in part by <ref> [Church and Church, 1979] </ref> and [Botvinnik, 1970], and are motivated in Section 14.2 and Section 14.4. * dynamic-mobility:counts the number of squares to which a piece can move directly from its current square on the current board, using a moving power. 3 * static-mobility:a static version of immediate-mobility, this counts the
Reference: [Collins and Birnbaum, 1988] <author> Gregg Collins and Lawrence Birnbaum. </author> <title> Learning strategic concepts in competitive planning: An explanation-based approach to the transfer of knowledge across domains. </title> <type> Technical Report UIUCDCS-R-88-1443, </type> <institution> Univesrity of Illinois, Dept. of Computer Science, Urbana, IL, </institution> <year> 1988. </year>
Reference-contexts: This has the advantage over the first approach, in that the relationship between all particular games in the class is here specified declaratively, in addition to the relationship between positions in a particular game. This might facilitate analogical reasoning across games (see <ref> [Collins and Birnbaum, 1988] </ref>). 12.2.1 Game description language To this end, we have represented the rules for the entire class of games in a game description language (gdl).
Reference: [Collins et al., 1991] <author> Gregg Collins, Lawrence Birnbaum, Bruce Krulwich, and Michael Freed. </author> <title> Plan debugging in an intentional system. </title> <booktitle> In Proceedings of the 12th International Joint Conference on Artificial Intelligence, </booktitle> <year> 1991. </year>
Reference: [Collins, 1987] <author> Gregg Collins. </author> <title> Plan Creation: Using Strategies as Blueprints. </title> <type> PhD thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <year> 1987. </year>
Reference: [Cousot and Cousot, 1977] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation: A unified lattice model for static analysis of programs by construction or approximation of fixpoints. </title> <booktitle> In Proceedings of the Fourth ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1977. </year>
Reference-contexts: A natural way to reconcile these two opposing goals to some extent is to automate the process by which a general program is specialised to handle specific sets of problems. Two well-understood techniques for doing this are partial evaluation [Sahlin, 1991; van Harmelen and Bundy, 1988] and abstract interpretation <ref> [Cousot and Cousot, 1977; Cousot and Cousot, 1992] </ref>. <p> This is a question which partial evaluation alone does not answer, as it is concerned with specialising a theory, not gathering information about it. However, this question can be answered using abstract interpretation <ref> [Cousot and Cousot, 1977; Cousot and Cousot, 1992] </ref>. Abstract interpretation is a technique by which we generalise a program to make a new approximate program. <p> As a result of this abstract execution, we will have an approximate characterisation of its behaviour. An example of abstract interpretation, from <ref> [Cousot and Cousot, 1977] </ref>, is the use of the rule of signs to determine that the result of 12638 fl 156 is negative, without actually doing the multiplication. <p> At this point we are finished with the abstract interpretation, and by the construction of our abstract mapping we are guaranteed that we have correctly classified all of our defined goals in terms of their state-dependency number (a proof of this can be found in <ref> [Cousot and Cousot, 1977] </ref>). An Example In case the above description was too abstract, this analysis can be interpreted algorithmically, as follows: we begin by assuming that all defined goals have state-dependency (henceforth stativity) 0, which means we know nothing about their stativity.
Reference: [Cousot and Cousot, 1992] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract Interpretation and Application to Logic Programs. </title> <journal> Journal of Logic Programming, </journal> <volume> 13(2-3):103-179, </volume> <year> 1992. </year>
Reference-contexts: A natural way to reconcile these two opposing goals to some extent is to automate the process by which a general program is specialised to handle specific sets of problems. Two well-understood techniques for doing this are partial evaluation [Sahlin, 1991; van Harmelen and Bundy, 1988] and abstract interpretation <ref> [Cousot and Cousot, 1977; Cousot and Cousot, 1992] </ref>. <p> This is a question which partial evaluation alone does not answer, as it is concerned with specialising a theory, not gathering information about it. However, this question can be answered using abstract interpretation <ref> [Cousot and Cousot, 1977; Cousot and Cousot, 1992] </ref>. Abstract interpretation is a technique by which we generalise a program to make a new approximate program.
Reference: [de Grey, 1985] <author> Aubrey de Grey. </author> <title> Towards a versatile self-learning board game program. Final Project, </title> <institution> Tripos in Computer Science, University of Cambridge, </institution> <year> 1985. </year>
Reference-contexts: The sequence of transformations starts with the necessary and sufficient conditions for making a legal move, and then drops conditions. The result is an abstract indicator of mobility, which is necessary but not sufficient. <ref> [de Grey, 1985] </ref> independently developed a similar approach, and used it to derive automatically mobility-related features in several other games, 14.2. GENERALISING EXISTING FEATURES 123 functions which count the moves available to each piece owned by each player in the current position. <p> This same consideration also applies to other work on self-play, which was discussed in Section 3.3.4. 15.6.6.2 Automatic Feature Generation There has recently been much progress in developing programs which generate features automatically from the rules of games <ref> [de Grey, 1985; Callan and Utgoff, 1991; Fawcett and Utgoff, 1992] </ref>. When applied to chess such programs produce features which count the number of chess pieces of each type, and when applied to Othello they produce features which measure different aspects of positions which are corre 15.7.
Reference: [Dickins, 1971] <author> Anthony Dickins. </author> <title> A Guide to Fairy Chess. </title> <publisher> Dover, </publisher> <year> 1971. </year>
Reference-contexts: Beyond this, the relative value of the pieces is surprisingly close to the values used in conventional chess programs, given that the analysis was so simplistic. 15.6.3 Fairy Chess Table 15.3 lists material values determined by metagamer for some fairy-chess pieces <ref> [Dickins, 1971] </ref>, which are useful for comparison with the standard chess pieces. The definitions for these pieces are presented in Appendix D.2.3, page 250. In the table, D is short for diagleap, a piece which can move only one square diagonally.
Reference: [Donninger, 1992] <author> Ch. Donninger. </author> <title> The relation of mobility, strategy and the mean dead rabbit in chess. </title> <editor> In H.J. van den Herik and L.V. Allis, editors, </editor> <booktitle> Heuristic Programming in Artificial Intelligence 3 The Third Computer Olympiad. </booktitle> <publisher> Ellis Horwood, </publisher> <year> 1992. </year>
Reference: [Ebeling, 1986] <author> C. Ebeling. </author> <title> All the Right Moves: A VLSI Architecture for Chess. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <year> 1986. </year>
Reference-contexts: This explains why much current research in CGP focusses on extremely efficient implementations of the basic computations, to the extent that each idiosyncrasy of the rules of a particular game are optimised in advance by the designers of the playing program (for example, <ref> [Ebeling, 1986] </ref>). However, an approach relying on a highly-efficient but special-purpose representation encounters difficulties when applied to developing a SCL-Metagame-player. First, as the class itself is fairly general (see Section 9.2), it is difficult to see a way of hand-optimising the entire class of games in advance. <p> Thus, the issue is largely empirical, and to address it properly might well require a significant effort to construct special-purpose machines to provide a search-engine with maximum efficiency, as has been done for chess <ref> [Ebeling, 1986] </ref>.
Reference: [Epstein, 1989a] <author> Susan Epstein. </author> <title> Mediation among Advisors. </title> <booktitle> In Proceedings on AI and Limited Rationality, </booktitle> <pages> pages 35-39. </pages> <booktitle> AAAI Spring Symposium Series, </booktitle> <year> 1989. </year>
Reference-contexts: case where expensive knowledge is more valuable than cheap search, observed on a wide variety of games. 10 15.5 Weights for Advisors The last major issue concerning the construction of the strategic evaluation function involves assigning weights to each advisor, or more generally, developing a function for mediation among advisors <ref> [Epstein, 1989a] </ref>.
Reference: [Epstein, 1989b] <author> Susan Epstein. </author> <title> The Intelligent Novice Learning to Play Better. </title> <editor> In D.N.L. Levy and D.F. Beal, editors, </editor> <booktitle> Heuristic Programming in Artificial Intelligence The First Computer Olympiad. </booktitle> <publisher> Ellis Horwood, </publisher> <year> 1989. </year> <note> 262 BIBLIOGRAPHY </note>
Reference-contexts: This number is used by the search engine in the standard manner. 15.2.1 Overview of Advisors Following the approach used in hoyle <ref> [Epstein, 1989b] </ref>, we view each component of the evaluation function as an advisor, which encapsulates a piece of advice about why 2 In the current system, the mediator returns just a weighted sum of the advice, where each piece of advice is weighted according to the weight attached to the advisor <p> These are all examples of passive analysis, and are not of use to a program until it has had significant experience with strong players. This issue is discussed in detail in Section 3.3. 15.6.6.4 Hoyle hoyle <ref> [Epstein, 1989b] </ref> is a program, similar in spirit to metagamer, in which general knowledge is encapsulated using the metaphor of advisors. hoyle has an advisor responsible for guiding the program into positions in which it has high mobility. <p> This appears to be the first case of a program taking in the rules of two games as complicated as chess and checkers and playing both of them with some degree of skill. The only other program which can play multiple games like this at all is hoyle <ref> [Epstein, 1989b] </ref>, but there is no evidence to date that hoyle's advisors give it any useful guidance on these games.
Reference: [Epstein, 1990] <author> Susan Epstein. </author> <title> Learning Plans for Competitive Domains. </title> <editor> In B. W. Porter and R. J. Mooney, editors, </editor> <booktitle> Proceedings of the Seventh International Conference on Machine Learning. </booktitle> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference: [Epstein, 1991] <author> Susan Epstein. </author> <title> Deep Forks In Strategic Maps. </title> <editor> In D.N.L. Levy and D.F. Beal, editors, </editor> <booktitle> Heuristic Programming in Artificial Intelligence 2 The Second Computer Olympiad. </booktitle> <publisher> Ellis Horwood, </publisher> <year> 1991. </year>
Reference: [Epstein, 1992] <author> Susan Epstein. </author> <title> Learning Expertise from the Opposition: The role of the trainer in a competitive environment. </title> <booktitle> In The Proceedings of AI 92, </booktitle> <pages> pages 236-243, </pages> <year> 1992. </year>
Reference: [Fawcett and Utgoff, 1992] <author> Tom E. Fawcett and Paul E. Utgoff. </author> <title> Automatic feature generation for problem solving systems. </title> <editor> In Derek Sleeman and Peter Edwards, editors, </editor> <booktitle> Proceedings of the Ninth Interntational Workshop on Machine Learning, </booktitle> <address> Aberdeen, Scotland, </address> <year> 1992. </year>
Reference-contexts: that they compute a set of properties which are necessary, but not always sufficient, for a player to have a legal move in a position. 1 Both chess and checkers programs contain terms in their evaluation 1 [Rosenbloom, 1982] developed a set of mobility-related features for the game of Othello. <ref> [Fawcett and Utgoff, 1992] </ref> showed how many of these features could be derived automatically through a process of transformations on the game rules. The sequence of transformations starts with the necessary and sufficient conditions for making a legal move, and then drops conditions. <p> The static analysis table constructed for this purpose (distance-matrix) was motivated by a dynamic version of the same computation developed by [Botvinnik, 1970] and later extended by [Church and Church, 1979] and [Snyder, 1993]. Two systems exist which derive step functions directly from problem specifications: Zenith <ref> [Fawcett and Utgoff, 1992] </ref> and CINDI [Callan and Utgoff, 1991]. <p> METAGAMER some advisors refer to other advisors in making their assessments. 15.2.2 Representation of Advisors In terms of the representation of the advisors, I follow an approach similar to that used in Zenith <ref> [Fawcett and Utgoff, 1992] </ref>, in which each advisor is defined by a nondeterministic rule for assigning additional value to a position. The total contribution (value) of the advisor is the sum of the values for each solution of the rule. <p> This same consideration also applies to other work on self-play, which was discussed in Section 3.3.4. 15.6.6.2 Automatic Feature Generation There has recently been much progress in developing programs which generate features automatically from the rules of games <ref> [de Grey, 1985; Callan and Utgoff, 1991; Fawcett and Utgoff, 1992] </ref>. When applied to chess such programs produce features which count the number of chess pieces of each type, and when applied to Othello they produce features which measure different aspects of positions which are corre 15.7. <p> In other words, the time taken to apply the knowledge during problem-solving may be better spent searching more deeply instead. This problem has been called the utility problem [Minton, 1990], and the tradeoff between knowledge and search has been considered in depth within both the game-playing and problem-solving communities <ref> [Berliner, 1984; Callan, 1993; Fawcett and Utgoff, 1992] </ref>. Moreover, it could also be possible that the generator produced only drawn or hopelessly complicated games, in which case metagamer could not demonstrate an advantage even if its knowledge was correct and efficient. <p> One approach to this problem would be to extend the techniques used for efficiency specialisation in Chapter 12 to derive useful subgoals and invariant properties for a given game by abstract interpretation. It might also be possible to apply knowledge 19.4. LIMITATIONS AND FUTURE WORK 195 based feature construction <ref> [Callan, 1993; Fawcett and Utgoff, 1992] </ref> directly to this problem, as it is designed to extract functional features from a logical encoding of problem definitions. 19.4.3 Advanced Search Techniques Chapter 17 noted that while metagamer's analysis of each game seemed to give it a basic understanding of strategy, it is noticeably
Reference: [Flann and Dietterich, 1989] <author> Nicholas S. Flann and Thomas G. Dietterich. </author> <title> A study of explanation-based methods for inductive learning. </title> <journal> Machine Learning, </journal> <volume> 4 </volume> <pages> 187-226, </pages> <year> 1989. </year>
Reference-contexts: In some ways, this is syntactically cleaner than representations which have state as an explicit argument in their domain axioms (for example, the situation calculus <ref> [Flann and Dietterich, 1989; Genesereth and Nilsson, 1987; H olldobler, 1992] </ref>), as we can transform from implicit to explicit representation quite easily, whereas the opposite direction requires giving a particular argument of certain predicates (the state predicates) a special status throughout any routines which operate on a theory so expressed.
Reference: [Flann, 1990] <author> Nicholas S. Flann. </author> <title> Applying abstraction and simplification to learn in intractable domains. </title> <booktitle> In Proceedings of the International Machine Learning Conference, </booktitle> <pages> pages 235-239, </pages> <year> 1990. </year>
Reference: [Flann, 1992] <author> Nicholas S. Flann. </author> <title> Correct Abstraction in Counter-planning: A Knowledge Compilation Approach. </title> <type> PhD thesis, </type> <institution> Oregon State University, </institution> <year> 1992. </year>
Reference-contexts: When actually playing a specific game, the program functions as if its knowledge were specialised to just that specific game. The overall process is a form of knowledge-compilation <ref> [Flann, 1992] </ref>, as general knowledge is specialised to a particular problem. Section 15.5 discussed the important issue of weights for advisors. <p> Another possibility is to add an advisor to metagamer which is able to construct simple endgame databases, perhaps generating first those which are simplest and most common. A general method for achieving precisely this task was developed by Flann <ref> [Flann, 1992] </ref>, and has been applied to construct databases for chess and checkers end-games using only a logical representation of the rules for those games. 17.4 Chess This section discusses the results of two games of chess played by metagamer when given as input only the rules of the game.
Reference: [Fong, 1991] <author> Sandiway Fong. </author> <title> Computational Properties of Principle-Based Grammatical Theories. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <year> 1991. </year>
Reference-contexts: This will be demonstrated 13 There is an important connection here to the subfield of linguistics called universal grammar [Chomsky, 1965] or more recently principles-based parsing <ref> [Fong, 1991] </ref>. Rather than writing detailed parsers for specific languages, this field develops general linguistic principles. Given a set of parameters which affect the principles, and a high-level grammar for the specific language, the principles are compiled to produce a parser for the specific language.
Reference: [Fraenkel et al., 1978] <author> A. S. Fraenkel, M.R. Garey, D.S. Johnson, T. Schaefer, and Y. Yesha. </author> <title> The complexity of checkers on an nxn board preliminary report. </title> <booktitle> In Proceedings of the 19th Ann. Symp. on Foundations of Computer Science. IEEE Computer Society, </booktitle> <year> 1978. </year>
Reference: [Frey, 1983] <author> Peter W. Frey. </author> <title> The alpha-beta algorithm: Incremental updating, well behaved evaluation functions, and non-speculative forward pruning. </title> <editor> In M. A. Bramer, editor, </editor> <booktitle> Computer Game-Playing: theory and practice, </booktitle> <pages> pages 285-289. </pages> <publisher> Ellis-Horwood Publishers, Northwestern University, </publisher> <address> Evanston IL 60201, USA, </address> <year> 1983. </year>
Reference-contexts: An associated question was how to weight these terms (remember that we are not using a learning system yet). For purposes of experimentation, these weights were left as parameters. 13.3 Search Engine The search engine incorporates several standard search techniques from the game-playing literature (see <ref> [Rich, 1983; Frey, 1983; Levy and Newborn, 1991; Kierulf, 1990] </ref>). It is based on a Prolog implementation of the minimax algorithm with alpha-beta pruning, as presented in [Bratko, 1986, page 366].
Reference: [Garey and Johnson, 1979] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability, a Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman and Company, </publisher> <year> 1979. </year> <note> BIBLIOGRAPHY 263 </note>
Reference: [Genesereth and Nilsson, 1987] <author> Michael R. Genesereth and Nils J. Nilsson. </author> <booktitle> Logical Foundations of Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year>
Reference-contexts: In some ways, this is syntactically cleaner than representations which have state as an explicit argument in their domain axioms (for example, the situation calculus <ref> [Flann and Dietterich, 1989; Genesereth and Nilsson, 1987; H olldobler, 1992] </ref>), as we can transform from implicit to explicit representation quite easily, whereas the opposite direction requires giving a particular argument of certain predicates (the state predicates) a special status throughout any routines which operate on a theory so expressed. <p> REPRESENTATION AND EFFICIENCY representation, whereas implementing them as situational fluents corresponds to a situation-calculus representation <ref> [Genesereth and Nilsson, 1987] </ref>. 12.2.3 Bidirectionality In addition, these predicates are all logical, in that state is represented as a relation between two variables, StateIn and StateOut, instead of a global structure which is changed by side-effects (as in a current board array used in many traditional playing programs).
Reference: [Ginsberg and Geddis, 1991] <author> Matthew L. Ginsberg and Donald F. Geddis. </author> <booktitle> Is there any need for domain-dependent control information? In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 452-457, </pages> <year> 1991. </year>
Reference: [Good, 1968] <author> I. J. </author> <title> Good. A five-year plan for automatic chess. </title> <editor> In E. Dale and D. Michie, editors, </editor> <booktitle> Machine Intelligence 2, </booktitle> <pages> pages 89-118. </pages> <publisher> Oliver and Boyd, </publisher> <year> 1968. </year>
Reference-contexts: These would need to be extended to games beyond just chess. Another approach would be to apply some of the recent developments in rational game-tree search <ref> [Russell and Wefald, 1992; Baum and Smith, 1993; Good, 1968] </ref> to SCL-Metagame.
Reference: [Good, 1977] <author> I. J. </author> <title> Good. Dynamic probability, computer chess, and the measurement of knowledge. </title> <editor> In E. W. Elcock and D. Michie, editors, </editor> <booktitle> Machine Intelligence 8, </booktitle> <pages> pages 139-150. </pages> <publisher> Ellis Horwood, </publisher> <address> Chichester, </address> <year> 1977. </year>
Reference: [Hartmann, 1987] <author> D. Hartmann. </author> <title> How to Extract Relevant Knowledge from Grand Master Games, part 1. </title> <journal> ICCA-Journal, </journal> <volume> 10(1), </volume> <month> March </month> <year> 1987. </year>
Reference-contexts: To help programs distinguish squares and pieces having the same value in terms of immediate mobility, they are often provided with piece-square tables or centrality bonuses <ref> [Hartmann, 1987] </ref> which provide bonuses for having pieces on more central squares. As our programs will play unknown games, it was necessary to enable them to construct and use similar tables directly from the rules of the game.
Reference: [H olldobler, 1992] <author> Steffen H olldobler. </author> <title> On deductive planning and the frame problem. </title> <editor> In A. Voronkov, editor, </editor> <booktitle> Logic Programming and Automated Reasoning. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: In some ways, this is syntactically cleaner than representations which have state as an explicit argument in their domain axioms (for example, the situation calculus <ref> [Flann and Dietterich, 1989; Genesereth and Nilsson, 1987; H olldobler, 1992] </ref>), as we can transform from implicit to explicit representation quite easily, whereas the opposite direction requires giving a particular argument of certain predicates (the state predicates) a special status throughout any routines which operate on a theory so expressed.
Reference: [Hooper and Whyld, 1984] <author> David Hooper and Kenneth Whyld. </author> <title> The Oxford Companion to Chess. </title> <publisher> Oxford University Press, </publisher> <year> 1984. </year>
Reference-contexts: Finally, it would lessen the value of the pawn, whose value is influenced by its ability to promote into a queen (promote). If players have two kings instead of one in the initial position and win by capturing both enemy kings? Chess programs have two values for kings <ref> [Hooper and Whyld, 1984] </ref>: one when used as an ordinary piece and another when considered during piece exchanges. In the first case the king is similar in value to a knight (based on mobility).
Reference: [Huntsberger and Billingsley, 1981] <author> David V. Huntsberger and Patrick Billingsley. </author> <title> Elements of Statistical Inference. </title> <publisher> Allyn and Bacon, Inc., </publisher> <address> fifth edition, </address> <year> 1981. </year>
Reference: [Hunvald, 1972] <author> Henry Hunvald. </author> <title> Chess: Quotations from the Masters. </title> <publisher> Peter Pauper Press, Mount Vernon, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: In chess, where all pieces capture the same number of pieces, 11 The chess-master Tartakover (quoted in <ref> [Hunvald, 1972] </ref>) said, A threat is more powerful than its execution.
Reference: [Hyatt, 1984] <author> R.M. Hyatt. </author> <title> Using time wisely. </title> <journal> ICCA Journal, </journal> <volume> 7(1) </volume> <pages> 4-9, </pages> <year> 1984. </year>
Reference-contexts: Effective time management <ref> [Hyatt, 1984; Markovitch and Sella, 1993] </ref> is an important and difficult topic even within the context of a specific game known in advance.
Reference: [Kierulf et al., 1990] <author> A. Kierulf, K. Chen, and J. Nievergelt. </author> <title> Smart Game Board and Go explorer: A case study in software and knowledge engineering. </title> <journal> Communications of the ACM, </journal> <volume> 33(2), </volume> <month> February </month> <year> 1990. </year>
Reference: [Kierulf, 1990] <author> Anders Kierulf. </author> <title> Smart Game Board: a Workbench for Game-Playing Programs, with Go and Othello as Case Studies. </title> <type> Technical Report NR 22, </type> <institution> Informatik ETH, </institution> <address> Zurich, </address> <year> 1990. </year> <type> (PhD Thesis). </type>
Reference-contexts: An associated question was how to weight these terms (remember that we are not using a learning system yet). For purposes of experimentation, these weights were left as parameters. 13.3 Search Engine The search engine incorporates several standard search techniques from the game-playing literature (see <ref> [Rich, 1983; Frey, 1983; Levy and Newborn, 1991; Kierulf, 1990] </ref>). It is based on a Prolog implementation of the minimax algorithm with alpha-beta pruning, as presented in [Bratko, 1986, page 366].
Reference: [Koffman, 1968] <author> Elliot B. Koffman. </author> <title> Learning games through pattern recognition. </title> <journal> IEEE Transactions on Systems Science and Cybernetics, </journal> <volume> SSC-4(1):12-16, </volume> <year> 1968. </year>
Reference: [Korf, 1985] <author> Richard E. Korf. Iteratively-Deepening-a*: </author> <title> An optimal admissible tree search. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1034-1036, </pages> <address> Los Angeles, California, </address> <year> 1985. </year> <note> 264 BIBLIOGRAPHY </note>
Reference-contexts: It is based on a Prolog implementation of the minimax algorithm with alpha-beta pruning, as presented in [Bratko, 1986, page 366]. In order to cope with the dual issues of time limits and varying search spaces, this basic algorithm is extended with iterative deepening <ref> [Korf, 1985] </ref>. That is, the engine performs a search down to 1 ply, then 2 ply, and so on, until it has run out of time.
Reference: [Kuttner, 1983] <author> Henry Kuttner. </author> <title> Chessboard Planet. </title> <publisher> Arrow Books Limited, </publisher> <year> 1983. </year>
Reference: [Lee and Mahajan, 1988] <author> Kai-Fu Lee and Sanjoy Mahajan. </author> <title> A pattern classification approach to evaluation function learning. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 1-25, </pages> <year> 1988. </year>
Reference: [Lenat and Feigenbaum, 1991] <editor> D.B. Lenat and E.A. Feigenbaum. </editor> <title> On the thresholds of knowledge. </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 185-250, </pages> <year> 1991. </year>
Reference: [Lenat, 1983] <author> Douglas B. Lenat. </author> <title> The role of heuristics in learning by discovery: Three case studies. In R.S. </title> <editor> Michalski, J.G. Carbonnel, and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> volume 1. Morgan-Kaufman, </volume> <year> 1983. </year>
Reference: [Levinson and Snyder, 1991] <author> Robert A. Levinson and R. Snyder. </author> <title> Adaptive, pattern-oriented chess. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <year> 1991. </year>
Reference: [Levinson et al., 1991] <author> Robert Levinson, Feng-Hsiung Hsu, T. Anthony Marsland, Jonathan Schaeffer, and David E. Wilkins. </author> <title> Panel: </title> <booktitle> The role of chess in artificial intelligence research. In Proceedings of the 12th International Joint Conference on Artificial Intelligence, </booktitle> <year> 1991. </year>
Reference: [Levy and Newborn, 1991] <author> David Levy and Monty Newborn. </author> <title> How Computers Play Chess. W.H. </title> <publisher> Freeman and Company, </publisher> <year> 1991. </year>
Reference-contexts: An associated question was how to weight these terms (remember that we are not using a learning system yet). For purposes of experimentation, these weights were left as parameters. 13.3 Search Engine The search engine incorporates several standard search techniques from the game-playing literature (see <ref> [Rich, 1983; Frey, 1983; Levy and Newborn, 1991; Kierulf, 1990] </ref>). It is based on a Prolog implementation of the minimax algorithm with alpha-beta pruning, as presented in [Bratko, 1986, page 366]. <p> As the efficiency of alpha-beta search is improved by better move orderings, a standard technique in CGP is to use heuristic ordering functions at this point <ref> [Levy and Newborn, 1991, page 172] </ref>. The current search engine chooses one of two possible orderings, depending on the value of an internal parameter (called ordering): fixed Uses the moves in the order in which they are generated.
Reference: [Markovitch and Sella, 1993] <author> Shaul Markovitch and Yaron Sella. </author> <title> Learning of resource allocation strategies for game playing. </title> <booktitle> In Proceedings of IJCAI, </booktitle> <year> 1993. </year>
Reference-contexts: Effective time management <ref> [Hyatt, 1984; Markovitch and Sella, 1993] </ref> is an important and difficult topic even within the context of a specific game known in advance. <p> Before moving on to more sophisticated Metagame-players, we can summarise a few tentative conclusions from the early experience with search and minimal evaluation functions applied to SCL-Metagame. 2 <ref> [Markovitch and Sella, 1993] </ref> presents an algorithm which learns resource allocation strategies by observing the change in performance when different types of moves are allocated additional resources.
Reference: [Minton, 1984] <author> Steven Minton. </author> <title> Constraint-based generalization: Learning game-playing plans from single examples. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 251-254, </pages> <year> 1984. </year>
Reference: [Minton, 1990] <author> Steven Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 363-391, </pages> <year> 1990. </year>
Reference-contexts: In other words, the time taken to apply the knowledge during problem-solving may be better spent searching more deeply instead. This problem has been called the utility problem <ref> [Minton, 1990] </ref>, and the tradeoff between knowledge and search has been considered in depth within both the game-playing and problem-solving communities [Berliner, 1984; Callan, 1993; Fawcett and Utgoff, 1992].
Reference: [Newell et al., 1963] <author> Allen Newell, J.C. Shaw, and H.A. Simon. </author> <title> Chess-playing programs and the problem of complexity. In E.A. </title> <editor> Feigenbaum and J. Feldman, editors, </editor> <booktitle> Computers and Thought. </booktitle> <publisher> McGraw-Hill Book Company, </publisher> <year> 1963. </year>
Reference: [Pell, 1992] <author> Barney Pell. </author> <title> Metagame in Symmetric, Chess-Like Games. </title> <editor> In H.J. van den Herik and L.V. Allis, editors, </editor> <booktitle> Heuristic Programming in Artificial Intelligence 3 - The Third Computer Olympiad. </booktitle> <publisher> Ellis Horwood, </publisher> <year> 1992. </year> <note> Also appears as University of Cambridge Computer Laboratory Technical Report No. 277. </note>
Reference: [Polya, 1945] <author> G. Polya. </author> <title> How To Solve It. </title> <publisher> Penguin, </publisher> <year> 1945. </year>
Reference: [Reznitsky and Chudakoff, 1990] <author> A. Reznitsky and M. Chudakoff. </author> <title> A Chess Program Modeling a Chess Master's Mind. </title> <journal> ICCA-Journal, </journal> <volume> 13(4) </volume> <pages> 175-195, </pages> <year> 1990. </year> <note> BIBLIOGRAPHY 265 </note>
Reference: [Rich, 1983] <author> Elaine Rich. </author> <booktitle> Artificial Intelligence. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: An associated question was how to weight these terms (remember that we are not using a learning system yet). For purposes of experimentation, these weights were left as parameters. 13.3 Search Engine The search engine incorporates several standard search techniques from the game-playing literature (see <ref> [Rich, 1983; Frey, 1983; Levy and Newborn, 1991; Kierulf, 1990] </ref>). It is based on a Prolog implementation of the minimax algorithm with alpha-beta pruning, as presented in [Bratko, 1986, page 366].
Reference: [Rosenbloom, 1982] <author> Paul S. Rosenbloom. </author> <title> A world-championship-level othello program. </title> <journal> Artificial Intelligence, </journal> <volume> 19 </volume> <pages> 279-320, </pages> <year> 1982. </year>
Reference-contexts: The common factor in most mobility features is that they compute a set of properties which are necessary, but not always sufficient, for a player to have a legal move in a position. 1 Both chess and checkers programs contain terms in their evaluation 1 <ref> [Rosenbloom, 1982] </ref> developed a set of mobility-related features for the game of Othello. [Fawcett and Utgoff, 1992] showed how many of these features could be derived automatically through a process of transformations on the game rules.
Reference: [Roycroft, 1990] <author> A. J. Roycroft. </author> <title> Expert Against Oracle. </title> <editor> In D. Michie, editor, </editor> <booktitle> Machine Intelligence 11, </booktitle> <pages> pages 347-373. </pages> <publisher> Ellis Horwood, </publisher> <address> Chichester, </address> <year> 1990. </year>
Reference: [Russell and Wefald, 1992] <author> Stuart Russell and Eric Wefald. </author> <title> Do the Right Thing. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Finally, Chapter 18 concludes this part of the thesis. 98 CHAPTER 11. INTRODUCTION TO Part III Chapter 12 Representation and Efficiency 12.1 Introduction Of particular importance in developing more general problem solving systems, such as a Metagame-playing program, are the linked issues of representation and efficiency. As discussed in <ref> [Russell and Wefald, 1992] </ref>, AI is concerned with making reasonable decisions with limited resources. If we neglect time concerns, then all the games in this class can be seen, from the pure game-theoretic perspective, as trivial, in that their value can be calculated perfectly [von Neumann and Morgenstern, 1944]. <p> These would need to be extended to games beyond just chess. Another approach would be to apply some of the recent developments in rational game-tree search <ref> [Russell and Wefald, 1992; Baum and Smith, 1993; Good, 1968] </ref> to SCL-Metagame.
Reference: [Sahlin, 1991] <author> Dan Sahlin. </author> <title> An automatic partial evaluator for full prolog. </title> <type> Technical Report Research Report No. </type> <institution> SICS/D-91/04-SE, Swedish Institute of Computer Science, </institution> <year> 1991. </year>
Reference-contexts: A natural way to reconcile these two opposing goals to some extent is to automate the process by which a general program is specialised to handle specific sets of problems. Two well-understood techniques for doing this are partial evaluation <ref> [Sahlin, 1991; van Harmelen and Bundy, 1988] </ref> and abstract interpretation [Cousot and Cousot, 1977; Cousot and Cousot, 1992]. <p> As this technique is well described in the literature (for example <ref> [Sahlin, 1991; van Harmelen and Bundy, 1988] </ref>), we will here only illustrate its application to specialising a playing program for a particular game. <p> Because of this, 110 CHAPTER 12. REPRESENTATION AND EFFICIENCY checking the occupancy status of each square on a chess board (8x8) requires 16 steps instead of 1. I anticipate further speedup from other optimisations using the automatic partial evaluator in MIXTUS-PROLOG <ref> [Sahlin, 1991] </ref>.
Reference: [Sahlin, 1992] <author> Dan Sahlin. </author> <type> Personal communication, </type> <month> November </month> <year> 1992. </year>
Reference-contexts: I anticipate further speedup from other optimisations using the automatic partial evaluator in MIXTUS-PROLOG [Sahlin, 1991]. As this is one of the largest applications of MIXTUS to date, more work on it appears necessary before it can be applied usefully to this domain theory <ref> [Sahlin, 1992] </ref>. 12.4 Summary This chapter dealt with the initial issues involved in realizing a SCL-Metagame-playing program, given the rigorous definition of the problem developed in Part II.
Reference: [Samuels, 1959] <author> A. L. Samuels. </author> <title> Some studies in machine learning using the game of Checkers. </title> <journal> IBM Journal, </journal> <volume> 3 </volume> <pages> 210-229, </pages> <year> 1959. </year>
Reference: [Samuels, 1967] <author> A. L. Samuels. </author> <title> Some studies in machine learning using the game of Checkers. ii. </title> <journal> IBM Journal, </journal> <volume> 11 </volume> <pages> 601-617, </pages> <year> 1967. </year>
Reference: [Schaeffer et al., 1991] <author> J. Schaeffer, J. Culberson, N. Treloar, B. Knight, P. Lu, and D. Szafron. </author> <title> Reviving the game of checkers. </title> <editor> In D.N.L. Levy and D.F. Beal, editors, </editor> <booktitle> Heuristic Programming in Artificial Intelligence 2 The Second Computer Olympiad. </booktitle> <publisher> Ellis Horwood, </publisher> <year> 1991. </year>
Reference-contexts: The program then played the game with a move-time-limit of one minute. 17.3. CHECKERS 167 17.3.1 One Man Handicap against Chinook The following game is a typical instance of a small set of handicap games played between metagamer and Chinook <ref> [Schaeffer et al., 1991] </ref>. Chinook is the world's strongest computer checkers player, and the second strongest checkers player in general.
Reference: [Snyder, 1993] <author> Richard Snyder. </author> <title> Distance: Toward the unification of chess knowledge. </title> <type> Master's thesis, </type> <institution> University of California, Santa Cruz, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: The static analysis table constructed for this purpose (distance-matrix) was motivated by a dynamic version of the same computation developed by [Botvinnik, 1970] and later extended by [Church and Church, 1979] and <ref> [Snyder, 1993] </ref>. Two systems exist which derive step functions directly from problem specifications: Zenith [Fawcett and Utgoff, 1992] and CINDI [Callan and Utgoff, 1991]. <p> For example, it can be determined statically that a pawn defends a piece because it could capture any enemy piece on the same square as the defended piece, and this replacement necessarily occurs whenever the enemy captures the defended piece. This property is exploited by several strategic chess programs <ref> [Church and Church, 1979; Botvin-nik, 1970; Snyder, 1993] </ref>. However, the assumptions behind this approach become clear when we consider pieces with capturing methods other than clobbering. <p> It should be noted that this set is not final, and there are several important general heuristics which are not yet incorporated (such as distance and control <ref> [Snyder, 1993] </ref>). The advisors can be categorised into four groups, based on the general concept from which they derive. 15.3.1 Mobility Advisors The first group is concerned with different indicators of mobility.
Reference: [Sutton, 1984] <author> Richard S. Sutton. </author> <title> Temporal Credit Assignment in Reinforcement Learning. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Science, University of Massachusetts, </institution> <year> 1984. </year>
Reference: [Tadepalli, 1989a] <author> Prasad Tadepalli. </author> <title> Lazy explanation-based learning: A solution to the intractable theory problem. </title> <booktitle> In Proceedings of the 11th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 694-700, </pages> <year> 1989. </year>
Reference-contexts: It would be an interesting area for future work to develop a general reasoning method which could be applied to checkers and similar games to solve problems like this. One possibility would be a generalisation of work on using knowledge and plans to control search <ref> [Wilkins, 1982; Campbell, 1988; Tadepalli, 1989a] </ref>. Another possibility is to add an advisor to metagamer which is able to construct simple endgame databases, perhaps generating first those which are simplest and most common.
Reference: [Tadepalli, 1989b] <author> Prasad Tadepalli. </author> <title> Planning in games using approximately learned macros. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <pages> pages 221-223, </pages> <year> 1989. </year>
Reference: [Tesauro, 1993] <author> G. Tesauro. </author> <title> TD-Gammon, A Self-Teaching Backgammon Program, Achieves Master-Level Play. </title> <booktitle> Neural Computation, </booktitle> <year> 1993. </year> <note> To Appear. 266 BIBLIOGRAPHY </note>
Reference-contexts: The issue of finding weights for advisors used by metagamer or similar programs is thus an important area for research. One idea for future research would be to apply temporal-difference learning [Sut-ton, 1984] and self-play <ref> [Tesauro, 1993] </ref> to this problem. It would be interesting to investigate whether the knowledge-free approach which was so successful in learning backgammon [Tesauro, 1993] also transfers to these different games, or whether it depends for its success on properties specific to backgammon. <p> One idea for future research would be to apply temporal-difference learning [Sut-ton, 1984] and self-play <ref> [Tesauro, 1993] </ref> to this problem. It would be interesting to investigate whether the knowledge-free approach which was so successful in learning backgammon [Tesauro, 1993] also transfers to these different games, or whether it depends for its success on properties specific to backgammon. Another idea would be to use a genetic approach with competition among a population of players with different weights (subject to the constraints on weights listed in Section 15.5).
Reference: [Tunstall-Pedoe, 1991] <author> William Tunstall-Pedoe. </author> <title> Genetic Algorithms Optimizing Evaluation Functions. </title> <journal> ICCA-Journal, </journal> <volume> 14(3) </volume> <pages> 119-128, </pages> <month> September </month> <year> 1991. </year>
Reference: [van Harmelen and Bundy, 1988] <author> Frank van Harmelen and Alan Bundy. </author> <title> Explanation-based generalisation = partial evaluation. </title> <journal> Artificial Intelligence, </journal> <volume> 36(3) </volume> <pages> 401-412, </pages> <year> 1988. </year>
Reference-contexts: A natural way to reconcile these two opposing goals to some extent is to automate the process by which a general program is specialised to handle specific sets of problems. Two well-understood techniques for doing this are partial evaluation <ref> [Sahlin, 1991; van Harmelen and Bundy, 1988] </ref> and abstract interpretation [Cousot and Cousot, 1977; Cousot and Cousot, 1992]. <p> As this technique is well described in the literature (for example <ref> [Sahlin, 1991; van Harmelen and Bundy, 1988] </ref>), we will here only illustrate its application to specialising a playing program for a particular game.
Reference: [van Tiggelen, 1991] <author> A. van Tiggelen. </author> <title> Neural Networks as a Guide to Optimization. </title> <journal> ICCA-Journal, </journal> <volume> 14(3) </volume> <pages> 115-118, </pages> <month> September </month> <year> 1991. </year>
Reference: [von Neumann and Morgenstern, 1944] <author> J. von Neumann and O. Morgenstern. </author> <title> Theory of Games and Economic Behavior. </title> <publisher> Princeton University Press, </publisher> <year> 1944. </year>
Reference-contexts: As discussed in [Russell and Wefald, 1992], AI is concerned with making reasonable decisions with limited resources. If we neglect time concerns, then all the games in this class can be seen, from the pure game-theoretic perspective, as trivial, in that their value can be calculated perfectly <ref> [von Neumann and Morgenstern, 1944] </ref>. If we take time resources into consideration, however, it is clear that programs which perform their basic computations (such as move generation) more efficiently than others have a marked competitive advantage, other factors being equal.
Reference: [Warren, 1992] <author> David Scott Warren. </author> <title> Memoing for Logic Programs. </title> <journal> Communications of the ACM, </journal> <volume> 35(3), </volume> <month> March </month> <year> 1992. </year>
Reference-contexts: Although this example is simple, the method is very powerful, and has been used in applications ranging from data-flow analysis to mode inference in logic programs <ref> [Warren, 1992] </ref>. As this technique, like partial evaluation, is thoroughly described elsewhere, we shall not discuss the formal foundations here, but shall instead detail its application to the game analysis problem concerning us in this section.
Reference: [Wellman and Doyle, 1991] <author> Michael P. Wellman and John Doyle. </author> <title> Preferential semantics for goals. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <volume> volume 2, </volume> <pages> pages 698-703, </pages> <year> 1991. </year>
Reference-contexts: The knowledge represented in each advisor recognises properties of a position which should be valuable to a player, other things being equal (sharing the view of goals advocated in <ref> [Wellman and Doyle, 1991] </ref>, see also Section 3.2.2.2). Aspects of a position which are bad for a player are designed to be recognised as aspects which are good for the opponent, and so need not be recognised separately.
Reference: [Wilkins, 1982] <author> David E. Wilkins. </author> <title> Using knowledge to control tree search. </title> <journal> Artificial Intelligence, </journal> <volume> 18 </volume> <pages> 1-51, </pages> <year> 1982. </year>
Reference-contexts: It would be an interesting area for future work to develop a general reasoning method which could be applied to checkers and similar games to solve problems like this. One possibility would be a generalisation of work on using knowledge and plans to control search <ref> [Wilkins, 1982; Campbell, 1988; Tadepalli, 1989a] </ref>. Another possibility is to add an advisor to metagamer which is able to construct simple endgame databases, perhaps generating first those which are simplest and most common. <p> One way to address this problem might be through a tactics analyzer as developed by Berliner [Berliner, 1974] or a knowledge-based planner as developed by Wilkins <ref> [Wilkins, 1982] </ref>. These would need to be extended to games beyond just chess. To summarise metagamer's performance in chess, it's play is reasonable and it looks like it has a basic understanding of some chess strategy. <p> Almost any improvement should produce a markedly better player. One way to address this problem might be through a tactics analyser as developed by Berliner [Berliner, 1974] or a knowledge-based planner as developed by Wilkins <ref> [Wilkins, 1982] </ref>. These would need to be extended to games beyond just chess. Another approach would be to apply some of the recent developments in rational game-tree search [Russell and Wefald, 1992; Baum and Smith, 1993; Good, 1968] to SCL-Metagame.
Reference: [Williams, 1972] <author> Thomas G. Williams. </author> <title> Some studies in game playing with a digital computer. </title> <editor> In Siklossy and H. Simon, editors, </editor> <title> Representation and Meaning. </title> <publisher> Prentice-Hall, </publisher> <year> 1972. </year>
Reference: [Yee et al., 1990] <author> Richard C. Yee, Sharad Saxena, Paul E. Utgoff, and Andrew C. Barto. </author> <title> Explaining temporal-differences to create useful concepts for evaluating states. </title> <booktitle> In Proceedings of AAAI-90, </booktitle> <year> 1990. </year>
References-found: 98

