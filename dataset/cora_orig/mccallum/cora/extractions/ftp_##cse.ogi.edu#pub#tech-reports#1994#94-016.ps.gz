URL: ftp://cse.ogi.edu/pub/tech-reports/1994/94-016.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/anneal/www/tech_reports.html
Root-URL: 
Email: o@ipncls.in2p3.fr  otto@cse.ogi.edu  
Title: Combining Simulated Annealing with Local Search Heuristics  
Author: Olivier C. Martin martin and Steve W. Otto 
Date: September 29, 1993  
Address: Orsay CEDEX 91406 France  20000 NW Walker Rd, PO Box 91000 Portland, Oregon, USA 97291-1000  
Affiliation: Division de Physique Theorique Institut de Physique Nucleaire,  Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  
Abstract: We introduce a meta-heuristic to combine simulated annealing with local search methods for CO problems. This new class of Markov chains leads to significantly more powerful optimization methods than either simulated annealing or local search. The main idea is to embed deterministic local search techniques into simulated annealing so that the chain explores only local optima. It makes large, global changes, even at low temperatures, thus overcoming large barriers in configuration space. We have tested this meta-heuristic for the traveling salesman and graph partitioning problems. Tests on instances from public libraries and random ensembles quantify the power of the method. Our algorithm is able to solve large instances to optimality, improving upon state of the art local search methods very significantly. For the traveling salesman problem with randomly distributed cities in a square, the procedure improves on 3-opt by 1.6%, and on Lin-Kernighan local search by 1.3%. For the partitioning of sparse random graphs of average degree equal to 5, the improvement over Kernighan-Lin local search is 8.9%. For both CO problems, we obtain new champion heuristics.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O. Martin, S.W. Otto, </author> <title> and E.W. Felten. Large-step Markov chains for the traveling salesman problem. </title> <journal> J. Complex Syst., </journal> <volume> 5:3:299, </volume> <year> 1991. </year>
Reference-contexts: This meta-heuristic is very general since simulated annealing and local search are viable techniques for most CO problems. It is also flexible, enabling the incorporation of problem specific aspects of the CO problem. We have implemented the method <ref> [1, 2, 3, 4] </ref> for two graph-based problems, the traveling salesman and the graph partitioning problems (TSP and GPP). The results are significant performance gains for both the TSP and the GPP. <p> In the earliest such work of which we are aware [14], Muhlenbein et. al. used 2-opt to improve children configurations in a TSP before evaluating the cost function. This enabled them to partly overcome the difficulty of combining two parents to create a child of good quality. In <ref> [1] </ref>, we show how the use of many parents can alleviate this difficulty. The method was called a "post reduction procedure" because it is not totally faithful to the GA approach. <p> We have been not able to obtain such an elegant solution in the case of the GPP, but nevertheless the kick procedure leads to an effective algorithm. Let us first motivate the choice of 1 See <ref> [1] </ref> for an explanation. 5 connectivity of the tour on large scales. kick appropriate for geometric graphs (see section 6). <p> It turns out that this choice of kick is very effective, not only for geometric graphs, but also for random graphs as discussed in section 6. 5 Results for the TSP We originally tested <ref> [1, 2] </ref> C-L-O on randomly generated instances with N points in a unit square. For N up to 200, we were able to determine the optimum tour using a branch and bound program. Then we ran chained local optimization using Lin-Kernighan as the embedded local search. <p> The "standard" instances are: (1) instances with cities randomly distributed in the unit square; (2) instances with random distance matrices d ij ; and (3) publicly available instances solved to optimality by branch and cut methods [9]. The performance of L-K on these problems has been studied <ref> [16, 27, 1, 2] </ref>. As N becomes large, the distribution of lengths (normalized to the minimum) of tours found by L-K becomes Gaussian with a width decreasing as N 1=2 . Thus the performance of L-K is essentially described by the mean value of this distribution.
Reference: [2] <author> O. Martin, S.W. Otto, </author> <title> and E.W. Felten. Large-step Markov chains for the TSP incorporating local search heuristics. </title> <journal> Oper. Res. Lett., </journal> <volume> 11 </volume> <pages> 219-24, </pages> <year> 1992. </year>
Reference-contexts: This meta-heuristic is very general since simulated annealing and local search are viable techniques for most CO problems. It is also flexible, enabling the incorporation of problem specific aspects of the CO problem. We have implemented the method <ref> [1, 2, 3, 4] </ref> for two graph-based problems, the traveling salesman and the graph partitioning problems (TSP and GPP). The results are significant performance gains for both the TSP and the GPP. <p> It turns out that this choice of kick is very effective, not only for geometric graphs, but also for random graphs as discussed in section 6. 5 Results for the TSP We originally tested <ref> [1, 2] </ref> C-L-O on randomly generated instances with N points in a unit square. For N up to 200, we were able to determine the optimum tour using a branch and bound program. Then we ran chained local optimization using Lin-Kernighan as the embedded local search. <p> The "standard" instances are: (1) instances with cities randomly distributed in the unit square; (2) instances with random distance matrices d ij ; and (3) publicly available instances solved to optimality by branch and cut methods [9]. The performance of L-K on these problems has been studied <ref> [16, 27, 1, 2] </ref>. As N becomes large, the distribution of lengths (normalized to the minimum) of tours found by L-K becomes Gaussian with a width decreasing as N 1=2 . Thus the performance of L-K is essentially described by the mean value of this distribution.
Reference: [3] <author> O. Martin and S.W. Otto. </author> <title> Partitioning of unstructured meshes for load balancing. </title> <type> Technical report, </type> <year> 1993. </year> <note> Submitted to Concurrency Practice and Experience. </note>
Reference-contexts: This meta-heuristic is very general since simulated annealing and local search are viable techniques for most CO problems. It is also flexible, enabling the incorporation of problem specific aspects of the CO problem. We have implemented the method <ref> [1, 2, 3, 4] </ref> for two graph-based problems, the traveling salesman and the graph partitioning problems (TSP and GPP). The results are significant performance gains for both the TSP and the GPP. <p> The implication is that, for C-L-O, the effective energy landscape has only one (or just a few) local minima! Almost all of the local minima have been modified to saddle points by the extended neighborhood structure of the algorithm. 6 Results for the GPP In <ref> [3, 4] </ref>, we compare C-L-O to K-L and to improvements to K-L. K-L is known to be significantly better than simulated annealing for certain types of sparse graphs of relevance to load-balancing, while being less good for random graphs [20]. <p> K-L is known to be significantly better than simulated annealing for certain types of sparse graphs of relevance to load-balancing, while being less good for random graphs [20]. Here we give the performances of our algorithm for "geometric" graphs and for sparse random graphs. In <ref> [3] </ref>, we also compare with graphs obtained from real world load balancing instances. Again, the C-L-O algorithm improves significantly on local search. Performance on geometric graphs This ensemble of graphs is motivated by load balancing problems.
Reference: [4] <author> O. Martin and S.W. Otto. </author> <title> A comparison of heuristics for the partitioning of random graphs. </title> <type> Technical report, </type> <year> 1993. </year> <note> Submitted to SIAM. 13 </note>
Reference-contexts: This meta-heuristic is very general since simulated annealing and local search are viable techniques for most CO problems. It is also flexible, enabling the incorporation of problem specific aspects of the CO problem. We have implemented the method <ref> [1, 2, 3, 4] </ref> for two graph-based problems, the traveling salesman and the graph partitioning problems (TSP and GPP). The results are significant performance gains for both the TSP and the GPP. <p> The implication is that, for C-L-O, the effective energy landscape has only one (or just a few) local minima! Almost all of the local minima have been modified to saddle points by the extended neighborhood structure of the algorithm. 6 Results for the GPP In <ref> [3, 4] </ref>, we compare C-L-O to K-L and to improvements to K-L. K-L is known to be significantly better than simulated annealing for certain types of sparse graphs of relevance to load-balancing, while being less good for random graphs [20].
Reference: [5] <author> A. L. Beguelin, J. J. Dongarra, A. Geist, R. J. Manchek, and V. S. Sunderam. </author> <title> Heterogeneous network computing. </title> <booktitle> In Sixth SIAM Conference on Parallel Processing, </booktitle> <year> 1993. </year>
Reference-contexts: Thus we have only considered implementations where a given processor has a complete configuration in local memory. We work in the framework of a distributed memory architecture and have implemented the codes on a network of workstations under the PVM <ref> [5, 6] </ref> protocol. The simplest way to parallelize chained local optimization is to have each processor run independent Markov chains. This is analogous to running multiple random starts on a single processor.
Reference: [6] <author> Jack Dongarra, Al Geist, Robert Manchek, and Vaidy Sunderam. </author> <title> Integrated PVM framework supports heterogeneous network computing. </title> <booktitle> Computers in Physics, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: Thus we have only considered implementations where a given processor has a complete configuration in local memory. We work in the framework of a distributed memory architecture and have implemented the codes on a network of workstations under the PVM <ref> [5, 6] </ref> protocol. The simplest way to parallelize chained local optimization is to have each processor run independent Markov chains. This is analogous to running multiple random starts on a single processor.
Reference: [7] <author> E.L. Lawler, J.K. Lenstra, A.H.G. Rinooy Kan, </author> <title> and D.B. Shmoys, editors. The Traveling Salesman Problem. </title> <publisher> John Wiley & and Sons, </publisher> <year> 1984. </year>
Reference-contexts: TSP and the GPP, along with specific details concerning the state of the art local searches, can be found in two appendices. 2 Status of TSP and GPP heuristics Traveling salesman heuristics The important exact algorithms for TSP are branch and bound methods, and more recently branch and cut methods <ref> [7] </ref>. These methods have progressed tremendously in the last ten years, so that instances with N of several thousand have now been solved to optimality [8]. A library of solved instances is available electronically [9], enabling users to test their algorithms. <p> We consider only the symmetric TSP where d ij = d ji . The problem of finding the optimum tour is NP-complete. The main exact algorithms are branch and bound methods, and branch and cut methods. See Lawler et. al. for an overview <ref> [7] </ref>. These methods have progressed tremendously in the last ten years, so that instances with N of several thousand have now been solved to optimality [8]. A library of solved instances is available electronically [9], enabling us to test our algorithm.
Reference: [8] <author> M.W. Padberg and G. Rinaldi. </author> <title> A branch and cut algorithm for the resolution of large-scale symmetric traveling salesman problems. </title> <journal> SIAM Review, </journal> <volume> 33:60, </volume> <year> 1991. </year>
Reference-contexts: These methods have progressed tremendously in the last ten years, so that instances with N of several thousand have now been solved to optimality <ref> [8] </ref>. A library of solved instances is available electronically [9], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [10, 11], simulated annealing [12, 13], genetic algorithms [14], and neural network approaches [15]. <p> The main exact algorithms are branch and bound methods, and branch and cut methods. See Lawler et. al. for an overview [7]. These methods have progressed tremendously in the last ten years, so that instances with N of several thousand have now been solved to optimality <ref> [8] </ref>. A library of solved instances is available electronically [9], enabling us to test our algorithm. Many heuristic methods have been proposed for the TSP, among them direct tour construction, local search [10, 11], simulated annealing [12, 13], genetic algorithms [14], and neural network approaches [15].
Reference: [9] <institution> A Library of TSP instances is electronically available. For further details, contact R. Bixby at bixby@rice.edu. </institution>
Reference-contexts: These methods have progressed tremendously in the last ten years, so that instances with N of several thousand have now been solved to optimality [8]. A library of solved instances is available electronically <ref> [9] </ref>, enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [10, 11], simulated annealing [12, 13], genetic algorithms [14], and neural network approaches [15]. <p> Previously, when L-K was the champion heuristic, it was believed that the exact optimum was at 1% or more above the Held-Karp bound, but C-L-O has lowered this number. Finally, we tested the C-L-O algorithm on large, specific instances solved to optimality by other groups and available <ref> [9] </ref>. These instances were: (1) LIN-318 [24]; (2) AT&T-532 [25]; and (3) RAT-783 [26]. The numbers denote the number of cities, and the references give the authors who first solved the problem to optimality using branch and cut methods. <p> See Lawler et. al. for an overview [7]. These methods have progressed tremendously in the last ten years, so that instances with N of several thousand have now been solved to optimality [8]. A library of solved instances is available electronically <ref> [9] </ref>, enabling us to test our algorithm. Many heuristic methods have been proposed for the TSP, among them direct tour construction, local search [10, 11], simulated annealing [12, 13], genetic algorithms [14], and neural network approaches [15]. <p> The "standard" instances are: (1) instances with cities randomly distributed in the unit square; (2) instances with random distance matrices d ij ; and (3) publicly available instances solved to optimality by branch and cut methods <ref> [9] </ref>. The performance of L-K on these problems has been studied [16, 27, 1, 2]. As N becomes large, the distribution of lengths (normalized to the minimum) of tours found by L-K becomes Gaussian with a width decreasing as N 1=2 .
Reference: [10] <author> S. Lin. </author> <title> Computer solutions of the traveling salesman problem. </title> <institution> Bell Syst. Tech. J., 44:2245, </institution> <year> 1965. </year>
Reference-contexts: A library of solved instances is available electronically [9], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search <ref> [10, 11] </ref>, simulated annealing [12, 13], genetic algorithms [14], and neural network approaches [15]. The present consensus [16] is that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). <p> A library of solved instances is available electronically [9], enabling us to test our algorithm. Many heuristic methods have been proposed for the TSP, among them direct tour construction, local search <ref> [10, 11] </ref>, simulated annealing [12, 13], genetic algorithms [14], and neural network approaches [15]. It is generally recognized that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). <p> Define the neighborhood of a tour, T , to be all those 10 tours which can be obtained by changing at most k edges of T . One can search for local k-opt tours <ref> [10] </ref> by starting with a random tour T 1 and constructing a sequence of tours T 1 , T 2 , ... <p> The k-changes are required to decrease the length of the tour. When the process stops at a tour for which there is no possible improvement under a k-change, the tour is k-opt. Lin <ref> [10] </ref> introduced and studied the case of k=2 and k=3, and showed that one could get quite good tours quickly. In order to find the globally optimum tour, he suggested repeating the search from many random starts.
Reference: [11] <author> S. Lin and B. Kernighan. </author> <title> An effective heuristic algorithm for the traveling salesman problem. </title> <type> Oper. </type> <institution> Res., 21:498, </institution> <year> 1973. </year>
Reference-contexts: A library of solved instances is available electronically [9], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search <ref> [10, 11] </ref>, simulated annealing [12, 13], genetic algorithms [14], and neural network approaches [15]. The present consensus [16] is that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). <p> The present consensus [16] is that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan <ref> [11] </ref> (L-K). L-K is essentially a breadth-first search (3-opt) followed by a depth-first search (using greedy 2-changes). It is the benchmark against which all heuristics are tested. Simulated annealing (S-A) also gives very good tours, but it is many times slower than L-K [16]. <p> A library of solved instances is available electronically [9], enabling us to test our algorithm. Many heuristic methods have been proposed for the TSP, among them direct tour construction, local search <ref> [10, 11] </ref>, simulated annealing [12, 13], genetic algorithms [14], and neural network approaches [15]. It is generally recognized that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). <p> It is generally recognized that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan <ref> [11] </ref> (L-K). Simulated annealing (S-A) also gives very good tours, but it is many times slower than L-K [16]. Since our work builds on both L-K and S-A, we give some further details below. The Lin-Kernighan local search L-K is a variable depth local search. <p> Lin [10] introduced and studied the case of k=2 and k=3, and showed that one could get quite good tours quickly. In order to find the globally optimum tour, he suggested repeating the search from many random starts. Later, Lin and Kernighan <ref> [11] </ref> realized it was better to let k be variable. Essentially, their algorithm (L-K) is a breadth-first search (3-opt) followed by a depth-first search (using greedy 2-changes). It is the benchmark against which all heuristics are tested.
Reference: [12] <author> S. Kirkpatrick, C. Gelatt, and M. Vecchi. </author> <title> Optimization by simulated annealing. </title> <booktitle> Science, </booktitle> <address> 220:671, </address> <year> 1983. </year>
Reference-contexts: A library of solved instances is available electronically [9], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [10, 11], simulated annealing <ref> [12, 13] </ref>, genetic algorithms [14], and neural network approaches [15]. The present consensus [16] is that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). <p> Graph partitioning heuristics Exact methods for GPP are not as highly developed as for the TSP, and only recently has there been an efficient integer linear programming approach [17]. Numerous heuristic methods have been proposed, ranging from the general purpose simulated annealing <ref> [12] </ref> approach to methods such as the recursive spectral bisection [18] and compaction methods [19] which are best adapted 2 to graphs which have a built-in geometric structure. For generic (random) graphs, the consensus [20] is that the "best" heuristics are simulated annealing [12] and a variable depth search due to <p> ranging from the general purpose simulated annealing <ref> [12] </ref> approach to methods such as the recursive spectral bisection [18] and compaction methods [19] which are best adapted 2 to graphs which have a built-in geometric structure. For generic (random) graphs, the consensus [20] is that the "best" heuristics are simulated annealing [12] and a variable depth search due to Kernighan and Lin [21], hereafter referred to as K-L. <p> A library of solved instances is available electronically [9], enabling us to test our algorithm. Many heuristic methods have been proposed for the TSP, among them direct tour construction, local search [10, 11], simulated annealing <ref> [12, 13] </ref>, genetic algorithms [14], and neural network approaches [15]. It is generally recognized that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). <p> Interestingly, all local search methods except for L-K are rather poor for this category, giving rise to a mean length which increases with N [27]. Simulated Annealing Simulated annealing has been applied with success to the TSP <ref> [12, 13, 16, 20] </ref>. One starts by constructing a sequence of tours T 1 , T 2 , etc... Each step of this chain is obtained by doing a k-change (moving to a neighboring tour). Usually, k is 2 or 3. <p> For heuristics, the situation is quite analogous to that for the TSP. The two "best" heuristics are a variable depth search heuristic due to Kernighan and Lin [21] (K-L), and simulated annealing <ref> [12] </ref>. Again, these two algorithms are comparable in terms of "quality" of solution, but S-A is substantially slower. However, these algorithms as not very good for many practical instances such as occur in load balancing and layout problems, so much effort has been spent finding problem specific improvements. <p> Another possibility is to move one element at a time, but never let the imbalance be greater than one or k elements [35]. Or, one can simply accept any imbalance, but include an extra penalty cost which grows with the imbalance, so that on average the imbalance stays small <ref> [12] </ref>. It turns out that moves consisting in exchanging elements pairwise are not efficient; it is simpler and faster to allow any imbalance, and usually this is done in conjunction with a penalty which is quadratic in the imbalance.
Reference: [13] <author> V. Cerny. </author> <title> Thermodynamical approach to the traveling salesman problem: an efficient simulation algorithm. </title> <journal> J. of Opt. Theo. and Appl., </journal> <volume> 45:41, </volume> <year> 1985. </year>
Reference-contexts: A library of solved instances is available electronically [9], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [10, 11], simulated annealing <ref> [12, 13] </ref>, genetic algorithms [14], and neural network approaches [15]. The present consensus [16] is that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). <p> A library of solved instances is available electronically [9], enabling us to test our algorithm. Many heuristic methods have been proposed for the TSP, among them direct tour construction, local search [10, 11], simulated annealing <ref> [12, 13] </ref>, genetic algorithms [14], and neural network approaches [15]. It is generally recognized that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). <p> Interestingly, all local search methods except for L-K are rather poor for this category, giving rise to a mean length which increases with N [27]. Simulated Annealing Simulated annealing has been applied with success to the TSP <ref> [12, 13, 16, 20] </ref>. One starts by constructing a sequence of tours T 1 , T 2 , etc... Each step of this chain is obtained by doing a k-change (moving to a neighboring tour). Usually, k is 2 or 3.
Reference: [14] <author> H. Muhlenbein, M. Georges-Schleuter, and O. Kramer. </author> <title> Evolution algorithms in combinatorial optimization. </title> <booktitle> Parallel Computing, </booktitle> <address> 7:65, </address> <year> 1988. </year>
Reference-contexts: A library of solved instances is available electronically [9], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [10, 11], simulated annealing [12, 13], genetic algorithms <ref> [14] </ref>, and neural network approaches [15]. The present consensus [16] is that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). L-K is essentially a breadth-first search (3-opt) followed by a depth-first search (using greedy 2-changes). <p> In a different spirit, a number of authors have embedded local searches inside genetic algorithms (GA). In the earliest such work of which we are aware <ref> [14] </ref>, Muhlenbein et. al. used 2-opt to improve children configurations in a TSP before evaluating the cost function. This enabled them to partly overcome the difficulty of combining two parents to create a child of good quality. <p> A library of solved instances is available electronically [9], enabling us to test our algorithm. Many heuristic methods have been proposed for the TSP, among them direct tour construction, local search [10, 11], simulated annealing [12, 13], genetic algorithms <ref> [14] </ref>, and neural network approaches [15]. It is generally recognized that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). Simulated annealing (S-A) also gives very good tours, but it is many times slower than L-K [16].
Reference: [15] <author> J. Hopfield and D. Tank. </author> <title> Neural computation of decisions in optimization problems. </title> <journal> Biol. Cybern., </journal> <volume> 52:141, </volume> <year> 1985. </year>
Reference-contexts: A library of solved instances is available electronically [9], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [10, 11], simulated annealing [12, 13], genetic algorithms [14], and neural network approaches <ref> [15] </ref>. The present consensus [16] is that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). L-K is essentially a breadth-first search (3-opt) followed by a depth-first search (using greedy 2-changes). <p> A library of solved instances is available electronically [9], enabling us to test our algorithm. Many heuristic methods have been proposed for the TSP, among them direct tour construction, local search [10, 11], simulated annealing [12, 13], genetic algorithms [14], and neural network approaches <ref> [15] </ref>. It is generally recognized that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). Simulated annealing (S-A) also gives very good tours, but it is many times slower than L-K [16].
Reference: [16] <author> D.S. Johnson, C.R. Aragon, L.A. McGeoch, and C. Schevon. </author> <title> Optimization by simulated annealing: An experimental evaluation, part III (the TSP). </title> <type> Technical report. </type> <institution> Bell Labs preprint. </institution>
Reference-contexts: A library of solved instances is available electronically [9], enabling users to test their algorithms. In terms of heuristics, many methods have been proposed, such as direct tour construction, local search [10, 11], simulated annealing [12, 13], genetic algorithms [14], and neural network approaches [15]. The present consensus <ref> [16] </ref> is that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). L-K is essentially a breadth-first search (3-opt) followed by a depth-first search (using greedy 2-changes). It is the benchmark against which all heuristics are tested. <p> L-K is essentially a breadth-first search (3-opt) followed by a depth-first search (using greedy 2-changes). It is the benchmark against which all heuristics are tested. Simulated annealing (S-A) also gives very good tours, but it is many times slower than L-K <ref> [16] </ref>. Graph partitioning heuristics Exact methods for GPP are not as highly developed as for the TSP, and only recently has there been an efficient integer linear programming approach [17]. <p> It is generally recognized that the heuristic which leads to the best solutions is a local search method due to Lin and Kernighan [11] (L-K). Simulated annealing (S-A) also gives very good tours, but it is many times slower than L-K <ref> [16] </ref>. Since our work builds on both L-K and S-A, we give some further details below. The Lin-Kernighan local search L-K is a variable depth local search. One begins with a notion of a neighborhood structure on the set of all feasible solutions (tours). <p> The "standard" instances are: (1) instances with cities randomly distributed in the unit square; (2) instances with random distance matrices d ij ; and (3) publicly available instances solved to optimality by branch and cut methods [9]. The performance of L-K on these problems has been studied <ref> [16, 27, 1, 2] </ref>. As N becomes large, the distribution of lengths (normalized to the minimum) of tours found by L-K becomes Gaussian with a width decreasing as N 1=2 . Thus the performance of L-K is essentially described by the mean value of this distribution. <p> Interestingly, all local search methods except for L-K are rather poor for this category, giving rise to a mean length which increases with N [27]. Simulated Annealing Simulated annealing has been applied with success to the TSP <ref> [12, 13, 16, 20] </ref>. One starts by constructing a sequence of tours T 1 , T 2 , etc... Each step of this chain is obtained by doing a k-change (moving to a neighboring tour). Usually, k is 2 or 3. <p> include "noisiness." For the TSP, S-A is significantly slower than Lin-Kernighan, but it has the advantage that one can run for long times and slowly improve the quality of the solutions [28], eventually getting comparable or even better results than L-K. (See for instance the studies of Johnson et. al. <ref> [16] </ref>.) In the simplest version of S-A, the elementary move when going from T n to T n+1 is a random 2-change. A number of studies have considered more complicated moves, and also non-random ways of choosing the 2-changes.
Reference: [17] <author> F. Barahona and A. Casari. </author> <title> On the magnetisation of the ground states in two dimensional ising spin glasses. </title> <journal> Comp. Phys. Communications, </journal> <volume> 49:417, </volume> <year> 1988. </year>
Reference-contexts: Simulated annealing (S-A) also gives very good tours, but it is many times slower than L-K [16]. Graph partitioning heuristics Exact methods for GPP are not as highly developed as for the TSP, and only recently has there been an efficient integer linear programming approach <ref> [17] </ref>. Numerous heuristic methods have been proposed, ranging from the general purpose simulated annealing [12] approach to methods such as the recursive spectral bisection [18] and compaction methods [19] which are best adapted 2 to graphs which have a built-in geometric structure.
Reference: [18] <author> A. Pothen, H. Simon, and K.P. Liou. </author> <title> Partitioning sparse matrices with eigenvectors of graphs. </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 11(3):430, </volume> <year> 1990. </year>
Reference-contexts: Numerous heuristic methods have been proposed, ranging from the general purpose simulated annealing [12] approach to methods such as the recursive spectral bisection <ref> [18] </ref> and compaction methods [19] which are best adapted 2 to graphs which have a built-in geometric structure. For generic (random) graphs, the consensus [20] is that the "best" heuristics are simulated annealing [12] and a variable depth search due to Kernighan and Lin [21], hereafter referred to as K-L.
Reference: [19] <author> T. Bui, C. Heigham, C. Jones, and T. Leighton. </author> <title> Improving the performance of the Kernighan-Lin and simulated annealing graph bisection algorithms. </title> <booktitle> In 26'th ACM/IEEE Design Automation Conference, </booktitle> <pages> page 775, </pages> <year> 1989. </year>
Reference-contexts: Numerous heuristic methods have been proposed, ranging from the general purpose simulated annealing [12] approach to methods such as the recursive spectral bisection [18] and compaction methods <ref> [19] </ref> which are best adapted 2 to graphs which have a built-in geometric structure. For generic (random) graphs, the consensus [20] is that the "best" heuristics are simulated annealing [12] and a variable depth search due to Kernighan and Lin [21], hereafter referred to as K-L. <p> For graphs which have an embedded structure such as occurs in load balancing applications, K-L and S-A behave much more poorly. Thus quite a bit of effort has been spent on trying to improve K-L for these types of graphs. One method, called compaction <ref> [19] </ref>, combines pairwise nearby vertices and runs K-L on the half-sized problem. Then the solution is unpacked to get 12 a new trial partition which itself will be K-L-opted. This procedure can be done recursively, giving rise to a hierarchical or multiple scales algorithm [33].
Reference: [20] <author> D.S. Johnson, C.R. Aragon, L.A. McGeoch, and C. Schevon. </author> <title> Optimization by simulated annealing: An experimental evaluation, part I (graph partitioning). </title> <type> Oper. </type> <institution> Res., 37:865, </institution> <year> 1989. </year>
Reference-contexts: Numerous heuristic methods have been proposed, ranging from the general purpose simulated annealing [12] approach to methods such as the recursive spectral bisection [18] and compaction methods [19] which are best adapted 2 to graphs which have a built-in geometric structure. For generic (random) graphs, the consensus <ref> [20] </ref> is that the "best" heuristics are simulated annealing [12] and a variable depth search due to Kernighan and Lin [21], hereafter referred to as K-L. <p> K-L is known to be significantly better than simulated annealing for certain types of sparse graphs of relevance to load-balancing, while being less good for random graphs <ref> [20] </ref>. Here we give the performances of our algorithm for "geometric" graphs and for sparse random graphs. In [3], we also compare with graphs obtained from real world load balancing instances. Again, the C-L-O algorithm improves significantly on local search. <p> As R increases, the connectivity as measured by d, the average degree of a vertex, increases. Neglecting boundary effects, one has d = R 2 N . Johnson et. al. <ref> [20] </ref> did a thorough comparison of local search, K-L, and simulated annealing for these types of graphs. They found that a certain improvement to K-L, which they called Line-K-L (L-K-L), in which one starts K-L on a non-random partition, was by far the best method. <p> One can also compare the average performances, taking into account the different speeds of the algorithms. One run of 100 steps of C-L-O takes about the same computation time as 100 L-K-Ls. Thus from the 2000 L-K-L data points, we obtained, following the method described in <ref> [20] </ref>, the distribution of the best cut found in 100 independent trials. The mean and standard deviation were then compared with the corresponding moments of the best found in each of the C-L-O runs. <p> Thus we have chosen an intermediate value, d = 5, which leads to cut sizes which scale with N at large N and which enables us to compare our results with those in <ref> [20] </ref>. Denoting the cut size per vertex for the various algorithms by C (N ), we find C KL (500) = 0:49 0:01. The error is quite large because the fluctuations from instance to instance are important. <p> Interestingly, all local search methods except for L-K are rather poor for this category, giving rise to a mean length which increases with N [27]. Simulated Annealing Simulated annealing has been applied with success to the TSP <ref> [12, 13, 16, 20] </ref>. One starts by constructing a sequence of tours T 1 , T 2 , etc... Each step of this chain is obtained by doing a k-change (moving to a neighboring tour). Usually, k is 2 or 3. <p> This procedure can be done recursively, giving rise to a hierarchical or multiple scales algorithm [33]. A second approach consists in using better than random starting partitions. In particular, Berger and Bokhari [34], and later Johnson et. al. <ref> [20] </ref> proposed using a dividing line for the initial partition, and applied K-L to such starts. The resulting algorithm, called L-K-L, gives for "geometric" graphs (c.f. section 6) as good results as a hierarchical compaction approach while being much simpler. <p> Relaxing this hard constraint into a soft one gives the system new routes to escape from local minima. Also, it has the advantage of reducing the size of neighborhoods from N (N 1)=2 to N . A comparison of S-A and K-L was made in <ref> [20] </ref>: S-A is better than K-L for random graphs, (they find for random graphs of average degree d = 5, C SA =C KL = 0:918), but significantly worse than K-L for "geometric" graphs. Acknowledgements We especially thank E.W. Felten, our collaborator on the TSP work.
Reference: [21] <author> B. Kernighan and S. Lin. </author> <title> An effective heuristic procedure for partitioning graphs. </title> <institution> Bell Syst. Tech. J., 49:291, </institution> <year> 1970. </year>
Reference-contexts: For generic (random) graphs, the consensus [20] is that the "best" heuristics are simulated annealing [12] and a variable depth search due to Kernighan and Lin <ref> [21] </ref>, hereafter referred to as K-L. Discussion For most CO problems, and certainly for the TSP and the GPP, as the characteristic size N of the instance grows, the number of configurations (feasible solutions) which are locally optimal under a given local search method grows very quickly with N . <p> graph partitioning problem in which N is even and A and B are of equal 11 size. (One then talks of the graph bi-partitioning problem, hereafter referred to simply as the GPP.) This is not a significant restriction as unequal sizes can also be dealt with using the same heuristics <ref> [21] </ref>. The GPP has great practical importance: it is a major ingredient in the problem of cell placement for VLSI [29], chip layout, and program segmentation [30]. These optimization problems use some form of graph partitioning or generalizations thereof [31] in their solution. <p> For heuristics, the situation is quite analogous to that for the TSP. The two "best" heuristics are a variable depth search heuristic due to Kernighan and Lin <ref> [21] </ref> (K-L), and simulated annealing [12]. Again, these two algorithms are comparable in terms of "quality" of solution, but S-A is substantially slower. <p> One calls a 1-change an exchange of one element of A against an element of B. It turns out that 1-opt is a mediocre algorithm, and that going to higher k-opt is very expensive and does not lead to much improvement. Kernighan and Lin <ref> [21] </ref> suggested a variable k-change algorithm which is much more effective than either 1-opt or 2-opt while being quite fast. Their algorithm is essentially a greedy tabu 1-exchange sweep of sets A and B: at each step, one exchanges the most favorable (or least unfavorable) pair of elements.
Reference: [22] <author> Z. Li and H.A. Scheraga. </author> <title> Monte carlo-minimization approach to the multiple-minima problem in protein folding. </title> <journal> Proc. Natl. Acad. Sci., </journal> <volume> 84 </volume> <pages> 6611-6615, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: Comparable improvements should occur for other CO problems as long as the biased sampling of the Markov chain is more efficient than random sampling. This will generally be possible whenever local search heuristics are useful. Weaker forms of this meta-heuristic have been proposed. In <ref> [22] </ref>, Li and Scheraga implemented a Markov chain with a kick followed by a quench for a protein folding problem. The 4 algorithm did lead to some cost improvement, but the authors did not consider it a general optimization method.
Reference: [23] <author> E.B. Baum. </author> <title> Towards practical `neural' computation for combinatorial optimization problems. </title> <editor> In J. Denker, editor, </editor> <booktitle> Neural Networks for Computing, 1986. AIP conference proceedings 151. </booktitle>
Reference: [24] <author> H. Crowder and M.W. Padberg. </author> <title> Solving large-scale symmetric traveling salesman problems to optimality. </title> <booktitle> Management Science, </booktitle> <address> 26:495, </address> <year> 1984. </year>
Reference-contexts: Finally, we tested the C-L-O algorithm on large, specific instances solved to optimality by other groups and available [9]. These instances were: (1) LIN-318 <ref> [24] </ref>; (2) AT&T-532 [25]; and (3) RAT-783 [26]. The numbers denote the number of cities, and the references give the authors who first solved the problem to optimality using branch and cut methods.
Reference: [25] <author> M.W. Padberg and G. Rinaldi. </author> <title> Optimization of a 532-city symmetric traveling salesman problem by branch and cut. </title> <journal> Oper. Res. Lett., </journal> <volume> 6(1) </volume> <pages> 1-7, </pages> <year> 1987. </year>
Reference-contexts: Finally, we tested the C-L-O algorithm on large, specific instances solved to optimality by other groups and available [9]. These instances were: (1) LIN-318 [24]; (2) AT&T-532 <ref> [25] </ref>; and (3) RAT-783 [26]. The numbers denote the number of cities, and the references give the authors who first solved the problem to optimality using branch and cut methods.
Reference: [26] <author> W. Cook, V. Chvatal, and D. </author> <title> Applegate. </title> <editor> In R. Bixby, editor, </editor> <volume> TSP 90, </volume> <year> 1992. </year> <institution> Workshop held at Rice University, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: Finally, we tested the C-L-O algorithm on large, specific instances solved to optimality by other groups and available [9]. These instances were: (1) LIN-318 [24]; (2) AT&T-532 [25]; and (3) RAT-783 <ref> [26] </ref>. The numbers denote the number of cities, and the references give the authors who first solved the problem to optimality using branch and cut methods.
Reference: [27] <author> D.S. Johnson. </author> <title> Local optimization and the traveling salesman problem. </title> <booktitle> In 17'th Colloquium on Automata, Languages, and Progamming, 1990. </booktitle> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The "standard" instances are: (1) instances with cities randomly distributed in the unit square; (2) instances with random distance matrices d ij ; and (3) publicly available instances solved to optimality by branch and cut methods [9]. The performance of L-K on these problems has been studied <ref> [16, 27, 1, 2] </ref>. As N becomes large, the distribution of lengths (normalized to the minimum) of tours found by L-K becomes Gaussian with a width decreasing as N 1=2 . Thus the performance of L-K is essentially described by the mean value of this distribution. <p> For category (2) instances, it is theoretically known that the minimum length is O (1) for large N . Interestingly, all local search methods except for L-K are rather poor for this category, giving rise to a mean length which increases with N <ref> [27] </ref>. Simulated Annealing Simulated annealing has been applied with success to the TSP [12, 13, 16, 20]. One starts by constructing a sequence of tours T 1 , T 2 , etc... Each step of this chain is obtained by doing a k-change (moving to a neighboring tour).
Reference: [28] <author> S. Kirkpatrick. </author> <title> Optimization by simulated annealing: Quantitative studies. </title> <journal> J. Statis. Phys., </journal> <volume> 34:975, </volume> <year> 1984. </year>
Reference-contexts: The stochastic construction of a sequence of T 's can be viewed as a modification of local search to include "noisiness." For the TSP, S-A is significantly slower than Lin-Kernighan, but it has the advantage that one can run for long times and slowly improve the quality of the solutions <ref> [28] </ref>, eventually getting comparable or even better results than L-K. (See for instance the studies of Johnson et. al. [16].) In the simplest version of S-A, the elementary move when going from T n to T n+1 is a random 2-change. <p> Indeed, if one uses only 2-changes, the final tour (when the temperature has reached 0) is only guaranteed to be 2-opt. By including both 2 and 3-changes, the final tour becomes 3-opt, leading to significant improvements <ref> [28] </ref>. Appendix II: The Graph Partitioning Problem Consider an un-oriented graph G=(V,E), i.e., a collection of vertices V i , i = 1; :::N, and edges E i;j (E i;j joins vertices V i and V j ).
Reference: [29] <author> M. Hanan and J.M. Kertzberg. </author> <title> A review of the placement and quadratic assignment problems. </title> <journal> SIAM Review, </journal> <volume> 14, No. 2:324, </volume> <year> 1972. </year>
Reference-contexts: The GPP has great practical importance: it is a major ingredient in the problem of cell placement for VLSI <ref> [29] </ref>, chip layout, and program segmentation [30]. These optimization problems use some form of graph partitioning or generalizations thereof [31] in their solution. The GPP is NP-complete; exact methods are less developed than for the TSP, so that there are few large instances which have been solved to optimality.
Reference: [30] <author> B.W. Kernighan. </author> <title> Some graph partitioning problems related to program segmentation, 1969. </title> <type> Ph.D. Thesis. </type>
Reference-contexts: The GPP has great practical importance: it is a major ingredient in the problem of cell placement for VLSI [29], chip layout, and program segmentation <ref> [30] </ref>. These optimization problems use some form of graph partitioning or generalizations thereof [31] in their solution. The GPP is NP-complete; exact methods are less developed than for the TSP, so that there are few large instances which have been solved to optimality.
Reference: [31] <author> A.E. Dunlop and B.W. Kernighan. </author> <title> A procedure for placement of standard-cell VLSI circuits. </title> <journal> IEEE Transactions on Computer-Aided Design, CAD-4, </journal> <volume> No. 1:92, </volume> <year> 1985. </year>
Reference-contexts: The GPP has great practical importance: it is a major ingredient in the problem of cell placement for VLSI [29], chip layout, and program segmentation [30]. These optimization problems use some form of graph partitioning or generalizations thereof <ref> [31] </ref> in their solution. The GPP is NP-complete; exact methods are less developed than for the TSP, so that there are few large instances which have been solved to optimality. For heuristics, the situation is quite analogous to that for the TSP.
Reference: [32] <author> Y. Fu and P.W. Anderson. </author> <title> Application of statistical mechanics to NP-complete problems in combinatorial optimization. </title> <journal> J. Phys. A: Math. Gen., </journal> <volume> 19:1605, </volume> <year> 1986. </year>
Reference-contexts: A natural ensemble of graphs is G (N; p) the ensemble of random graphs of N vertices, each pair (V i ,V j ) being connected with probability p. If p is kept N independent, the average min cut size at large N is given by <ref> [32] </ref>: &lt; MinCut &gt;= pN 2 =4 U N 3=2 [p (1 p)] 1=2 =2 U = 0:38::: The first term is simply the contribution from a random cut; the second term is the improvement due to the optimization.
Reference: [33] <author> M.K. Goldberg and R. Gardner. </author> <title> On the minimal cut problem. </title> <booktitle> In Progress in Graph Theory, </booktitle> <pages> page 295, </pages> <year> 1984. </year> <editor> Ed. J.A. Bondy and U.S.R. </editor> <publisher> Murty. </publisher>
Reference-contexts: One method, called compaction [19], combines pairwise nearby vertices and runs K-L on the half-sized problem. Then the solution is unpacked to get 12 a new trial partition which itself will be K-L-opted. This procedure can be done recursively, giving rise to a hierarchical or multiple scales algorithm <ref> [33] </ref>. A second approach consists in using better than random starting partitions. In particular, Berger and Bokhari [34], and later Johnson et. al. [20] proposed using a dividing line for the initial partition, and applied K-L to such starts.
Reference: [34] <author> M. Berger and S. Bokhari. </author> <title> A partitioning strategy for non-uniform problems on multiprocessors. </title> <journal> IEEE Trans. Computers, </journal> <volume> C-36(5):570, </volume> <year> 1987. </year>
Reference-contexts: Then the solution is unpacked to get 12 a new trial partition which itself will be K-L-opted. This procedure can be done recursively, giving rise to a hierarchical or multiple scales algorithm [33]. A second approach consists in using better than random starting partitions. In particular, Berger and Bokhari <ref> [34] </ref>, and later Johnson et. al. [20] proposed using a dividing line for the initial partition, and applied K-L to such starts. The resulting algorithm, called L-K-L, gives for "geometric" graphs (c.f. section 6) as good results as a hierarchical compaction approach while being much simpler.
Reference: [35] <author> C.M. Fiduccia and R.M. Mattheyses. </author> <title> A linear-time heuristic for improving network partitions. </title> <booktitle> In Proceedings 19'th Design Automation Workshop, </booktitle> <pages> page 175, </pages> <year> 1982. </year> <month> 15 </month>
Reference-contexts: Simulated Annealing In S-A for the GPP, the natural choice is to exchange pairs of vertices between A and B. Another possibility is to move one element at a time, but never let the imbalance be greater than one or k elements <ref> [35] </ref>. Or, one can simply accept any imbalance, but include an extra penalty cost which grows with the imbalance, so that on average the imbalance stays small [12].
References-found: 35

