URL: ftp://ftp.cs.columbia.edu/reports/reports-1996/cucs-024-96.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1996.html
Root-URL: http://www.cs.columbia.edu
Title: Overview of Information-Based Complexity  
Affiliation: Columbia University Computer Science Department  
Date: 00, 1996  Henryk Wozniakowski  
Note: Lectures in Applied Mathematics Volume  
Pubnum: Report CUCS-024-96  
Abstract: We present a brief introduction to information-based complexity. An example of zero finding is chosen to illustrate the basic notions such as nonadaptive and adaptive information, as well as the "-complexity in the worst case, average case and randomized settings. In the second part, we survey recent results on complexity of multivariate problems. We concentrate on tractability and strong tractability issues as well as on path integration. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Bakhvalov, N. S., </author> <title> On approximate calculation of integrals (in Russian), </title> <journal> Vestnik MGU, Ser. Mat. Mekh. Astron. Fiz. Khim. </journal> <volume> 4 (1959), </volume> <pages> 3-18. </pages>
Reference-contexts: The interested reader is referred to a survey of the current state of our knowledge in [13]. For given (nonadaptive or adaptive ) information N , we approximate a zero of f by an algorithm : R n ! <ref> [0; 1] </ref>. That is, z = (N (f )) is to be an "-approximation to a zero of f. We now comment on the algorithm . Formally, is given as a finite composition of operations which are allowed in the model of computation, i.e., arithmetic and branching operations. <p> This makes the lower bounds stronger since they also hold if the model of computation is extended by allowing more operations. We are ready to define the local error of z = (N (f)) as e (f; ; N ) = inff jz xj : x 2 <ref> [0; 1] </ref> such that f (x) = 0 g: The global error depends on the setting. <p> The case r &lt; 2 is open. 3. Multivariate Problems We now discuss complexity of multivariate problems. By a multivariate problem we mean an approximation of an operator defined on functions f of d variables. More precisely, let F d be a class of functions f : <ref> [0; 1] </ref> d ! R, and let S d : F d ! G d ; where G d is a normed linear space. We wish to approximate S d (f ) for f 2 F d . <p> Note that our two examples are linear problems. We consider two classes of (partial) information. The first class fl std is given by function evaluations, that is, L 2 fl std iff for some x 2 <ref> [0; 1] </ref> d , we have L (f) = f (x); 8 f 2 F d . The second class fl all is more general and consists of all linear functionals L : F d ! R. <p> Problems which suffer the curse of dimension in the worst case setting include integration, approximation, global optimization, integral and partial differential equations for classes of functions whose rth derivatives are uniformly bounded in L 1 , see <ref> [1, 4, 8, 9, 17, 24, 32] </ref>. <p> We now turn to the class fl std of function values and consider the approximation problem S d f = f in the average case setting for the class of continuous functions f : <ref> [0; 1] </ref> d ! R equipped with the Wiener sheet measure. <p> Consider now the integration problem S d f = R [0;1] d f (x)dx in the average case setting for the class of continuous functions f : <ref> [0; 1] </ref> d ! R equipped with the Wiener sheet measure.
Reference: 2. <author> Blum, L., Shub, M. and Smale S., </author> <title> On a Theory of Computation and Complexity over the Real Numbers: NP-Completeness, Recursive Functions and Universal Machines, </title> <journal> Bull. Amer. Math. Soc. </journal> <volume> 21 (1989), </volume> <pages> 1-46. </pages>
Reference-contexts: For many problems, we can find algorithms which enjoy optimality properties in the real number model and which are numerically stable in floating point arithmetic. However, there are some counterexamples as well, see [6]. For the precise definition of the real number model the reader is referred to <ref> [2, 12] </ref>. Continuous computational complexity may be split into two branches. The first branch deals with problems for which the information is complete. Informally, 1991 Mathematics Subject Classification. 68Q25. Key words and phrases. complexity, zero finding, multivariate problems, tractability, strong tractability, path integration. <p> Examples include matrix multiplication, and the solution of linear algebraic systems or systems of polynomial equations. Problems with complete information may be NP-complete over the reals. The first such problem was established in <ref> [2] </ref> and this is the problem of deciding whether a system of n real polynomials of degree 4 has a real root. The other branch of continuous computational complexity is information-based complexity, denoted for brevity as IBC.
Reference: 3. <author> Heinrich, S., </author> <title> Random Approximation in Numerical Analysis, </title> <booktitle> in Proc. of the Functional Analysis Conference, Essen 1991, Lecture Notes in Pure and Applied Mathematics (K. </booktitle> <editor> D. Bierstedt et al., eds.), </editor> <volume> vol. 150, </volume> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1993, </year> <pages> pp. 123-171. </pages> <month> 4. </month> , <title> Complexity of integral equations and relations to s-numbers, </title> <editor> J. </editor> <booktitle> Complexity 9 (1993), </booktitle> <pages> 141-153. </pages>
Reference-contexts: Questions, concepts, and results from approximation theory, numerical analysis, applied mathematics, statistics, complexity theory, algorithmic analysis, number theory, analysis and measure theory have all been influential. The reader who wants to find more about IBC is referred to the books and recent surveys <ref> [3, 9, 11, 18, 24, 26] </ref>. In Section 2, we illustrate the basic concepts of IBC by an example of zero finding for scalar functions. These concepts include nonadaptive and adaptive information, as well as the concepts of error and cost in various settings.
Reference: 5. <author> Kung, H. T., </author> <title> The complexity of obtaining starting points for solving operator equations by Newton's method, Analytical Computational Complexity (J. </title> <editor> F. Traub, eds.), </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1976, </year> <pages> pp. 35-75. </pages>
Reference-contexts: Hence, we can compute an "-approximation using roughly 0:5 (b a)=" nonadaptive function values. If adaptive information with n function values is used then the minimal error is exponentially smaller and is equal to (b a)=2 n+1 , see <ref> [5] </ref>. Hence, an "- approximation can be computed using roughly log 2 (b a)=" function values. This can be done by using bisection for which the number of arithmetic and branching operations is also roughly log 2 (b a)=".
Reference: 6. <author> Miller, W., </author> <title> Computational complexity and numerical stability, </title> <journal> SIAM J. Comput. </journal> <volume> 4 (1975), </volume> <pages> 97-107. </pages>
Reference-contexts: In floating point arithmetic we have rounding errors, and numerical stability becomes an important issue. For many problems, we can find algorithms which enjoy optimality properties in the real number model and which are numerically stable in floating point arithmetic. However, there are some counterexamples as well, see <ref> [6] </ref>. For the precise definition of the real number model the reader is referred to [2, 12]. Continuous computational complexity may be split into two branches. The first branch deals with problems for which the information is complete. Informally, 1991 Mathematics Subject Classification. 68Q25.
Reference: 7. <author> Mathe, P., </author> <title> Random approximation of Sobolev embedding, </title> <editor> J. </editor> <booktitle> Complexity 7 (1993), </booktitle> <pages> 261-281. </pages>
Reference-contexts: In the average case and randomized settings, the curse of dimension is present for approximation over the class of functions with r continuous derivatives which is equipped with the folded isotropic Wiener measure, see [20, 28] for the average case and <ref> [7, 10, 27] </ref> for the randomized setting. For some problems we can break the curse of dimension by switching to a different setting. For example, in the randomized setting, it is well known that the classical Monte Carlo algorithm breaks the curse of dimension for multivariate integration.
Reference: 8. <author> Nemirovsky, A. S. and Yudin, D. B., </author> <title> Problem Complexity and Method Efficiency in Optimization, </title> <publisher> Wiley-Interscience, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: Problems which suffer the curse of dimension in the worst case setting include integration, approximation, global optimization, integral and partial differential equations for classes of functions whose rth derivatives are uniformly bounded in L 1 , see <ref> [1, 4, 8, 9, 17, 24, 32] </ref>.
Reference: 9. <author> Novak, E., </author> <title> Deterministic and Stochastic Error Bounds in Numerical Analysis, </title> <booktitle> vol. 1349, Lectures Notes in Math., </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1988. </year> <title> 10. , Optimal linear randomization methods for linear operators in Hilbert spaces, </title> <editor> J. </editor> <booktitle> Complexity 8 (1992), </booktitle> <pages> 22-36. </pages> <month> 11. </month> , <title> Algorithms and complexity for continuous problems, Geometry, Analysis, </title> <editor> and Mechanics (J. M. Rassias, eds.), </editor> <publisher> World Scientific, </publisher> <address> Singapore, </address> <year> 1994, </year> <pages> pp. 96-128. </pages> <month> 12. </month> , <title> The real number model in numerical analysis, </title> <journal> J. </journal> <note> Complexity 11 (1995), 57-73. 13. , On the power of adaption (1995) (to appear). </note>
Reference-contexts: Questions, concepts, and results from approximation theory, numerical analysis, applied mathematics, statistics, complexity theory, algorithmic analysis, number theory, analysis and measure theory have all been influential. The reader who wants to find more about IBC is referred to the books and recent surveys <ref> [3, 9, 11, 18, 24, 26] </ref>. In Section 2, we illustrate the basic concepts of IBC by an example of zero finding for scalar functions. These concepts include nonadaptive and adaptive information, as well as the concepts of error and cost in various settings. <p> Problems which suffer the curse of dimension in the worst case setting include integration, approximation, global optimization, integral and partial differential equations for classes of functions whose rth derivatives are uniformly bounded in L 1 , see <ref> [1, 4, 8, 9, 17, 24, 32] </ref>.
Reference: 14. <author> Novak, E., and Ritter, K., </author> <title> Some complexity results for zero finding for univariate functions, </title> <editor> J. </editor> <booktitle> Complexity 9 (1993), </booktitle> <pages> 15-40. </pages>
Reference-contexts: In this case, the classical Monte Carlo algorithm is almost optimal in the randomized setting. We conclude with a remark on Feynman-Kac path integrals. 2. Zero Finding We illustrate the basic concepts of IBC by using an example of zero finding for scalar functions. More can be found in <ref> [14, 15, 21] </ref>. Let F be a class of scalar functions f : [a; b] ! R that have a zero.
Reference: 15. <author> Novak, E., Ritter, K. and Wozniakowski, </author> <title> Average case optimality of a hybrid secant-bisection method, </title> <journal> Math. Comput. </journal> <volume> 64 (1995), </volume> <pages> 1517-1539. </pages>
Reference-contexts: In this case, the classical Monte Carlo algorithm is almost optimal in the randomized setting. We conclude with a remark on Feynman-Kac path integrals. 2. Zero Finding We illustrate the basic concepts of IBC by using an example of zero finding for scalar functions. More can be found in <ref> [14, 15, 21] </ref>. Let F be a class of scalar functions f : [a; b] ! R that have a zero. <p> That is, as shown in [21, 22], we may allow the computation of arbitrary linear functionals on f , and we may take as F the class of polynomials (with unbounded degrees) for which f (a)f (b) &lt; 0. We now turn to the average case setting, see <ref> [15, 19] </ref>. We need to equip the class F of (2.1) with a probability measure . We choose to be a folded Wiener INFORMATION-BASED COMPLEXITY 7 measure which is concentrated on functions with continuous rth derivatives and with fixed boundary conditions at the end points a and b. <p> So we may compute an "-approximation with the average case cost of order log 2 (b a)=" which also is the worst case complexity. It turns out that adaptive choice of n (f) is crucial. That is, as shown in <ref> [15] </ref>, there exists a hybrid secant-bisection method that computes an "-approximation with cost proportional to log 2 log 2 (b a)=", which is exponentially smaller than the previous bound. Furthermore, this method is optimal since the average case complexity is of the same order.
Reference: 16. <author> Pan, V. V., </author> <title> Optimal (up to polylog factors) sequential and parallel algorithms for approximating complex polynomial zeros, </title> <booktitle> Proc. 27th Ann. ACM Symp. on Theory of Computing (1995), </booktitle> <publisher> ACM Press, </publisher> <address> New York. </address>
Reference-contexts: Then the (worst case) complexity is the minimal number of such operations needed to compute an "-approximation for all f from F n . The bounds on the complexity may be found in <ref> [16] </ref>. Assume now that the class F is given as (2.1) F = ff : [a; b] ! R : f (a)f (b) &lt; 0; f is continuousg: In this case, the function f cannot be identified by a finite number of coefficients.
Reference: 17. <author> Pereverzev, S. V., </author> <title> On the complexity of the problem of finding solutions of Fredholm equations of the second kind with differentiable kernels (in Russian), Ukrain. </title> <journal> Mat. Sh. </journal> <volume> 41 (1989), </volume> <pages> 1422-1425. </pages>
Reference-contexts: Problems which suffer the curse of dimension in the worst case setting include integration, approximation, global optimization, integral and partial differential equations for classes of functions whose rth derivatives are uniformly bounded in L 1 , see <ref> [1, 4, 8, 9, 17, 24, 32] </ref>.
Reference: 18. <author> Plaskota, L., </author> <title> Noisy Information and Computational Complexity, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1996. </year>
Reference-contexts: Questions, concepts, and results from approximation theory, numerical analysis, applied mathematics, statistics, complexity theory, algorithmic analysis, number theory, analysis and measure theory have all been influential. The reader who wants to find more about IBC is referred to the books and recent surveys <ref> [3, 9, 11, 18, 24, 26] </ref>. In Section 2, we illustrate the basic concepts of IBC by an example of zero finding for scalar functions. These concepts include nonadaptive and adaptive information, as well as the concepts of error and cost in various settings. <p> It may be random if f (t) is observed and it is deterministic if f (t) is computed (in floating point arithmetic we will definitely have some rounding errors). This means that our information is noisy. A thorough study of noisy information may be found in the forthcoming book <ref> [18] </ref>. To simplify our exposition, we assume that = 0, that is, the information is exact and we can compute (or observe) y = f (t). The oracle may be used a finite number of times to obtain function values at different points.
Reference: 19. <author> Ritter, K., </author> <title> Average errors for zero finding: lower bounds for smooth or monotone functions, </title> <journal> Aequationes Math. </journal> <volume> 48 (1994), </volume> <pages> 194-219. </pages>
Reference-contexts: That is, as shown in [21, 22], we may allow the computation of arbitrary linear functionals on f , and we may take as F the class of polynomials (with unbounded degrees) for which f (a)f (b) &lt; 0. We now turn to the average case setting, see <ref> [15, 19] </ref>. We need to equip the class F of (2.1) with a probability measure . We choose to be a folded Wiener INFORMATION-BASED COMPLEXITY 7 measure which is concentrated on functions with continuous rth derivatives and with fixed boundary conditions at the end points a and b. <p> As before, first consider nonadaptive information. In fact, we may even consider adaptive information with fixed n (f) = n. That is, the choice of the sample points t i can now be adaptive; however, the total number of t i is always the same. It is proven in <ref> [19] </ref> that in this case, the minimal average case error is of the same order as the minimal worst case error, i.e., it is of order (b a)=2 n+1 .
Reference: 20. <author> Ritter, K. and Wasilkowski, G. W., </author> <title> Integration and L 2 -approximation: average case setting with isotropic Wiener measure for smooth functions, Rocky Mount. </title> <journal> J. Math. </journal> <note> (1995) (to appear). </note>
Reference-contexts: In the average case and randomized settings, the curse of dimension is present for approximation over the class of functions with r continuous derivatives which is equipped with the folded isotropic Wiener measure, see <ref> [20, 28] </ref> for the average case and [7, 10, 27] for the randomized setting. For some problems we can break the curse of dimension by switching to a different setting. <p> For multivariate approximation, the curse of dimension is broken only for some probability measures. For instance, it is broken for the Wiener sheet measure, see [29, 34], however, as already mentioned, it is not broken for the isotropic Wiener measure, see <ref> [20, 28] </ref>. It seems natural to characterize which multivariate problems are tractable or strongly tractable in various settings.
Reference: 21. <author> K. Sikorski, </author> <title> Optimal solution of nonlinear equations, </title> <editor> J. </editor> <booktitle> Complexity 1 (1985), </booktitle> <pages> 197-209. </pages> <month> 22. </month> , <title> Study of linear information of polynomial equations, </title> <journal> Aequationes Math. </journal> <volume> 37 (1989), </volume> <pages> 1-14. </pages>
Reference-contexts: In this case, the classical Monte Carlo algorithm is almost optimal in the randomized setting. We conclude with a remark on Feynman-Kac path integrals. 2. Zero Finding We illustrate the basic concepts of IBC by using an example of zero finding for scalar functions. More can be found in <ref> [14, 15, 21] </ref>. Let F be a class of scalar functions f : [a; b] ! R that have a zero. <p> This proves that the worst case complexity is given by comp (") c log 2 (b a)=": The same complexity, as well as optimality of bisection, holds if we permit more general information and/or if we shrink the class F . That is, as shown in <ref> [21, 22] </ref>, we may allow the computation of arbitrary linear functionals on f , and we may take as F the class of polynomials (with unbounded degrees) for which f (a)f (b) &lt; 0. We now turn to the average case setting, see [15, 19].
Reference: 23. <author> Smolyak, S. A., </author> <title> Quadrature and interpolation formulas for tensor products of certain classes of functions, </title> <journal> Dokl. Akad. Nauk SSSR 4 (1963), </journal> <pages> 240-243. </pages> <note> INFORMATION-BASED COMPLEXITY 13 </note>
Reference-contexts: It turns out that, under mild assumptions, tractability and strong tractability in these two classes are equivalent, although the proof is, in general, not constructive. For multivariate tensor products, we know a constructive proof. Based on Smolyak's algorithm, see <ref> [23] </ref>, we derived explicit cost bounds for tensor products, see [29]. We specialize these bounds for multivariate integration and approximation. The final section deals with path integration, see [30, 31]. Usually Monte Carlo algorithms are used to approximate path integrals. We study deterministic algorithms in the worst case setting. <p> For tractable tensor product problems and for the class fl std , we construct polynomial-time algorithms, see [29]. This construction is based on Smolyak's algorithm, see <ref> [23] </ref>.
Reference: 24. <author> Traub, J. F., Wasilkowski, G. W., and Wozniakowski, H., </author> <title> Information-Based Complexity, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Questions, concepts, and results from approximation theory, numerical analysis, applied mathematics, statistics, complexity theory, algorithmic analysis, number theory, analysis and measure theory have all been influential. The reader who wants to find more about IBC is referred to the books and recent surveys <ref> [3, 9, 11, 18, 24, 26] </ref>. In Section 2, we illustrate the basic concepts of IBC by an example of zero finding for scalar functions. These concepts include nonadaptive and adaptive information, as well as the concepts of error and cost in various settings. <p> Problems which suffer the curse of dimension in the worst case setting include integration, approximation, global optimization, integral and partial differential equations for classes of functions whose rth derivatives are uniformly bounded in L 1 , see <ref> [1, 4, 8, 9, 17, 24, 32] </ref>. <p> This follows easily from [10]. Similarly, tractability and strong tractability in the probabilistic setting and the average case setting are equivalent due to relations between these two settings for linear problems, see <ref> [24] </ref>. We stress that for the class fl all the construction of an "-approximation with minimal cost is easy since we know the optimal choice of linear functionals, and that linear algorithms are optimal. We now turn to the class fl std .
Reference: 25. <author> Traub, J. F. and Wozniakowski, H., </author> <title> A general theory of optimal algorithms, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1980. </year> <title> 26. , Recent Progress in Information-Based Complexity, </title> <journal> Bulletin of EATCS 51 (1993), </journal> <pages> 141-154. </pages>
Reference-contexts: We begin with the worst case setting. Assume first that nonadaptive information with n function values is used. It is easy to show, see <ref> [25] </ref>, that the minimal error of algorithms using such nonadaptive information is 0:5 (b a)=(n + 1). Hence, we can compute an "-approximation using roughly 0:5 (b a)=" nonadaptive function values.
Reference: 27. <author> Wasilkowski, G. W., </author> <title> Randomization for Continuous Problems, </title> <editor> J. </editor> <booktitle> Complexity 5 (1989), </booktitle> <pages> 195-218. </pages> <month> 28. </month> , <title> Integration and approximation of multivariate functions: average case complexity with isotropic Wiener measure, </title> <journal> Bull. Amer. Math. Soc. </journal> <volume> (N.S) 28 (1993), </volume> <pages> 308-314. </pages>
Reference-contexts: In the average case and randomized settings, the curse of dimension is present for approximation over the class of functions with r continuous derivatives which is equipped with the folded isotropic Wiener measure, see [20, 28] for the average case and <ref> [7, 10, 27] </ref> for the randomized setting. For some problems we can break the curse of dimension by switching to a different setting. For example, in the randomized setting, it is well known that the classical Monte Carlo algorithm breaks the curse of dimension for multivariate integration.
Reference: 29. <author> Wasilkowski, G. W. and Wozniakowski, H., </author> <title> Explicit cost bounds of algorithms for multivariate tensor product problems, </title> <journal> J. </journal> <note> Complexity 11 (1995), 1-56. 30. , On tractability of path integration (1995) (to appear). 31. , Worst case complexity of Feynman-Kac path integration (1995) (to appear). </note>
Reference-contexts: It turns out that, under mild assumptions, tractability and strong tractability in these two classes are equivalent, although the proof is, in general, not constructive. For multivariate tensor products, we know a constructive proof. Based on Smolyak's algorithm, see [23], we derived explicit cost bounds for tensor products, see <ref> [29] </ref>. We specialize these bounds for multivariate integration and approximation. The final section deals with path integration, see [30, 31]. Usually Monte Carlo algorithms are used to approximate path integrals. We study deterministic algorithms in the worst case setting. <p> However, in general, the proof is not constructive. For the Wiener sheet measure, the proof is constructive and we know almost optimal algorithms, see <ref> [29, 33] </ref>. For multivariate approximation, the curse of dimension is broken only for some probability measures. For instance, it is broken for the Wiener sheet measure, see [29, 34], however, as already mentioned, it is not broken for the isotropic Wiener measure, see [20, 28]. <p> For the Wiener sheet measure, the proof is constructive and we know almost optimal algorithms, see [29, 33]. For multivariate approximation, the curse of dimension is broken only for some probability measures. For instance, it is broken for the Wiener sheet measure, see <ref> [29, 34] </ref>, however, as already mentioned, it is not broken for the isotropic Wiener measure, see [20, 28]. It seems natural to characterize which multivariate problems are tractable or strongly tractable in various settings. <p> This is discussed in the next section. 4. Multivariate Tensor Products Assume that the linear multivariate problem S d : F d ! G d is given by tensor products of a one dimensional linear problem S 1 : F 1 ! G 1 , see <ref> [29, 36] </ref>. For such multivariate problems tractability and strong tractability are equivalent under mild assumptions, and this holds for both classes fl all and fl std . <p> For tractable tensor product problems and for the class fl std , we construct polynomial-time algorithms, see <ref> [29] </ref>. This construction is based on Smolyak's algorithm, see [23]. <p> Then we know a linear algorithm, see <ref> [29] </ref>, that computes an "-approximation with cost cost ("; d) c (d) 0:8489 0:9189 + ln 1=" 2 (d1) " : This algorithm has optimal powers of " 1 and ln 1=" since comp ("; d) = fi 2 (d1) ; see [35]. <p> Consider now the integration problem S d f = R [0;1] d f (x)dx in the average case setting for the class of continuous functions f : [0; 1] d ! R equipped with the Wiener sheet measure. Then we know a linear algorithm, see <ref> [29] </ref>, which computes an "-approximation with cost ("; d) bounded by cost ("; d) c (d) 3:304 1:12167 + ln 1=" 1:5 (d1) " The power of " 1 is optimal and the power of ln 1=" is too large since comp ("; d) = fi (d1)=2 ; see [33].
Reference: 32. <author> Werschulz, A. G., </author> <title> The Computational Complexity of Differential and Integral Equations: An Information-Based Approach, </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1991. </year>
Reference-contexts: Problems which suffer the curse of dimension in the worst case setting include integration, approximation, global optimization, integral and partial differential equations for classes of functions whose rth derivatives are uniformly bounded in L 1 , see <ref> [1, 4, 8, 9, 17, 24, 32] </ref>.
Reference: 33. <author> Wozniakowski, H., </author> <title> Average Case Complexity of Multivariate Integration, </title> <journal> Bull. Amer. Math. Soc. </journal> <volume> (N.S) 24 (1991), </volume> <pages> 185-194. </pages> <month> 34. </month> , <title> Average case complexity of linear multivariate problems: Part I. Theory, Part II. Applications, </title> <editor> J. </editor> <booktitle> Complexity 8 (1992), </booktitle> <pages> 337-372, 373-392. </pages> <month> 35. </month> , <title> Tractability and strong tractability of linear multivariate problems, </title> <editor> J. </editor> <booktitle> Complexity 10 (1994), </booktitle> <pages> 96-128. </pages> <month> 36. </month> , <title> Tractability and strong tractability of multivariate tensor product problems, </title> <editor> J. </editor> <booktitle> Computing and Information 4 (1994), </booktitle> <pages> 1-19. </pages> <institution> Department of Computer Science, Columbia University, </institution> <address> New York, NY 10027, </address> <institution> and Institute of Applied Mathematics, University of Warsaw, </institution> <address> ul. Banacha 2, 02-097 Warsaw, Poland. </address> <publisher> E-mail address: henryk@cs.columbia.edu </publisher>
Reference-contexts: However, in general, the proof is not constructive. For the Wiener sheet measure, the proof is constructive and we know almost optimal algorithms, see <ref> [29, 33] </ref>. For multivariate approximation, the curse of dimension is broken only for some probability measures. For instance, it is broken for the Wiener sheet measure, see [29, 34], however, as already mentioned, it is not broken for the isotropic Wiener measure, see [20, 28]. <p> see [29], which computes an "-approximation with cost ("; d) bounded by cost ("; d) c (d) 3:304 1:12167 + ln 1=" 1:5 (d1) " The power of " 1 is optimal and the power of ln 1=" is too large since comp ("; d) = fi (d1)=2 ; see <ref> [33] </ref>. This integration problem is strongly tractable since cost ("; d) c (d) 7:26 " 2:454 : The exponent 2:454 is too high. It is well known that there exist algorithms with an exponent at most two. The proof of this latter fact is, however, not constructive. <p> It is well known that there exist algorithms with an exponent at most two. The proof of this latter fact is, however, not constructive. INFORMATION-BASED COMPLEXITY 11 This integration problem is related to discrepancy in the L 2 -norm, see <ref> [33] </ref>. Using this relation we obtain an upper bound, which is independent of d, for the number n ("; d) of points for which discrepancy (with unequal weights) is at most ", n ("; d) 7:26 " 2:454 ; 8 d; 8 " 1: 5.
References-found: 23

