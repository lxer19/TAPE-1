URL: http://www.sls.lcs.mit.edu/~jwc/pub/eurospeech97.ps
Refering-URL: http://www.sls.lcs.mit.edu/~jwc/pub/pub.html
Root-URL: 
Email: fjwc, jrgg@sls.lcs.mit.edu  
Title: SEGMENTATION AND MODELING IN SEGMENT-BASED RECOGNITION  
Author: Jane W. Chang and James R. Glass 
Web: http://www.sls.lcs.mit.edu  
Address: Cambridge, Massachusetts 02139 USA  
Affiliation: Spoken Language Systems Group Laboratory for Computer Science Massachusetts Institute of Technology  
Abstract: Recently, we have developed a probabilistic framework for segment-based speech recognition that represents the speech signal as a network of segments and associated feature vectors [2]. Although in general, each path through the network does not traverse all segments, we argued that each path must account for all feature vectors in the network. We then demonstrated an efficient search algorithm that uses a single additional model to account for segments that are not traversed. In this paper, we present two new extensions to our framework. First, we replace our acoustic segmentation algorithm with segmentation by recognition, a probabilistic algorithm that can combine multiple contextual constraints towards hypothesizing only the most likely segments. Second, we generalize our framework to near-miss modeling and describe a search algorithm that can efficiently use multiple models to enforce contextual constraints across all segments in a network. We report experiments in phonetic recognition on the TIMIT corpus in which we achieve a diphone context-dependent error rate of 26.6% on the NIST core test set over 39 classes. This is a 12.8% reduction in error rate from our best previously reported result. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Cohen. </author> <title> Segmenting speech using dynamic programming. </title> <type> Journ. ASA, </type> <institution> 69(5):14301438, </institution> <month> May </month> <year> 1981. </year>
Reference-contexts: For example, we can use a forward pass Viterbi search to consider all possible segmentations of a set of frames and then use a backwards A fl search to create a network. This idea shares similarities with other work in segmentation and search <ref> [1, 4] </ref>. Segmentation by recognition has several desirable characteristics. First, it is flexible and can use any first pass recognition strategy. This strategy may be simple or complex depending on available computation. For example, we can still use local acoustic measures, or we can combine context-dependent acoustic and language models.
Reference: [2] <author> J. Glass, J. Chang, and M. McCandless. </author> <title> A probabilistic framework for feature-based speech recognition. </title> <booktitle> In Proc. ICSLP, </booktitle> <pages> pages 22772280, </pages> <year> 1996. </year>
Reference-contexts: 1. INTRODUCTION Unlike recognizers that use an acoustic representation based on a temporal sequence of frames, the SUMMIT speech recog-nizer developed by our group uses a more general representation based on a temporal network of segments, where each segment is associated with a fixed-dimensional feature vector <ref> [2] </ref>. Segment-based representation enables the extraction of information from the speech signal based on hypothesized segment start and end times. However, before we can exploit this ability in recognition, we must address issues in segmentation, modeling and search. <p> These tradeoffs have confounded the evaluation of segment-based approaches, as losses in segmentation may be larger than gains in modeling. We have been using a segmentation algorithm based on local acoustic change <ref> [2] </ref>. This algorithm hypothesizes a reason 1 This research was supported by DARPA under contract N66001-94-C-6040, monitored though Naval Command, Control and Ocean Surveillance Center. J. Chang receives support from Lucent Technologies. able number of segments with a reasonable number of errors. <p> We have recently developed an efficient search algorithm based on the introduction of a not model for segments that are not in a segmentation <ref> [2] </ref>. For segments at the phonetic level, we also refer to this additional model as the anti-phone. The not model can normalize each path to account for all segments in the network. <p> This information can be used in subsequent segment-based recognition. For example, since our recognition framework is general and allows both frame and segment-based features, we can directly re-use scores from first pass recognition in subsequent segment-based recognition <ref> [2] </ref>. This allows us to combine complementary recogniz-ers that take advantage of different recognition strategies. Furthermore, we can explore hierarchical strategies in segment-based recognition. <p> MODELING While segmentation allows the extraction of segment-based features, we must address problems in modeling and search in order to use these features in recognition. To explain the issues, we first review our probabilistic framework <ref> [2] </ref>. <p> Not modeling Recently, we have described an algorithm that efficiently computes P (A S A S jW ) for segment-based recognition by using an additional nonlexical not model, w, to account for all segments that are not in a segmentation and therefore A S <ref> [2] </ref>. <p> For all experiments, we use the NIST 462 speaker training set and 24 speaker core test set and an independent 50 speaker development set. We report error rates on the test set for the 39 phonetic classes commonly used for evaluation <ref> [2, 5, 7] </ref>. In the following subsections, we describe three recognizers we have used in our experiments. All recognizers initially represent the speech signal using 10 Mel-scale cepstral coefficients (MFCCs) every 10 ms. Each recognizer then further extracts frame or segment-based features.
Reference: [3] <author> A. Halberstadt and J. Glass. </author> <title> Heterogeneous acoustic measurements for phonetic classification. </title> <booktitle> In these proceedings. </booktitle>
Reference-contexts: Furthermore, we can explore hierarchical strategies in segment-based recognition. For example, since most confusions in phonetic classification occur between phones of the same manner class, we can focus on reducing these confusions by designing a set of segment-based features specifically to discriminate between the phones of each class <ref> [3] </ref>. In training, we produce multiple sets of models, one for each set of class-dependent features. However, in testing, we only score each segment against a single set of models based on first pass hypotheses. This enables us to use class-dependent features without sacrificing probabilistic integrity or computational efficiency. 3. <p> Based on these results, we believe that better feature extraction and modeling can improve performance for both frame and segment-based recognition. In this paper, we have briefly discussed one way to improve feature extraction and modeling using a hierarchical strategy. We plan to pursue this direction in future research <ref> [3] </ref>. In addition, there are other techniques for segment modeling that may be able to better capture correlations across a segment [6]. Finally, we plan to continue exploring the similarities and differences between frame and segment-based approaches.
Reference: [4] <author> L. Hetherington, M. Phillips, J. Glass, and V. Zue. </author> <title> A* word network search for continuous speech recognition. </title> <booktitle> In Proc. Eu-rospeech, </booktitle> <pages> pages 15331536, </pages> <year> 1993. </year>
Reference-contexts: For example, we can use a forward pass Viterbi search to consider all possible segmentations of a set of frames and then use a backwards A fl search to create a network. This idea shares similarities with other work in segmentation and search <ref> [1, 4] </ref>. Segmentation by recognition has several desirable characteristics. First, it is flexible and can use any first pass recognition strategy. This strategy may be simple or complex depending on available computation. For example, we can still use local acoustic measures, or we can combine context-dependent acoustic and language models.
Reference: [5] <author> L. Lamel and J. Gauvain. </author> <title> High performance speaker-independent phone recognition using cdhmm. </title> <booktitle> In Proc. Eurospeech, </booktitle> <pages> pages 121 124, </pages> <year> 1993. </year>
Reference-contexts: For all experiments, we use the NIST 462 speaker training set and 24 speaker core test set and an independent 50 speaker development set. We report error rates on the test set for the 39 phonetic classes commonly used for evaluation <ref> [2, 5, 7] </ref>. In the following subsections, we describe three recognizers we have used in our experiments. All recognizers initially represent the speech signal using 10 Mel-scale cepstral coefficients (MFCCs) every 10 ms. Each recognizer then further extracts frame or segment-based features. <p> The overall result of 26.6% is a 31.3% improvement over the baseline result of 38.7%. This is a 12.8% improvement over our best previously reported result of 30.5% and is competitive with the best results reported using other approaches, including neural networks and the more common HMMs <ref> [5, 7] </ref>. In the near future, we plan to run similar experiments in word recognition. We believe segmentation by recognition will facilitate working with segment-based approaches.
Reference: [6] <author> M. Ostendorf and S. Roukos. </author> <title> A stochastic segment model for phoneme-based continuous speech recognition. </title> <journal> Trans. ASSP, </journal> <volume> 37(12):18571869, </volume> <month> Dec. </month> <year> 1989. </year>
Reference-contexts: In this paper, we have briefly discussed one way to improve feature extraction and modeling using a hierarchical strategy. We plan to pursue this direction in future research [3]. In addition, there are other techniques for segment modeling that may be able to better capture correlations across a segment <ref> [6] </ref>. Finally, we plan to continue exploring the similarities and differences between frame and segment-based approaches. On the one hand, we believe we can design more complementary rec-ognizers that can reduce computation without sacrificing overall performance.
Reference: [7] <author> A. Robinson. </author> <title> An application of recurrent neural nets to phone probability estimation. </title> <journal> Trans. Neural Networks, </journal> <volume> 5(2):298305, </volume> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: For all experiments, we use the NIST 462 speaker training set and 24 speaker core test set and an independent 50 speaker development set. We report error rates on the test set for the 39 phonetic classes commonly used for evaluation <ref> [2, 5, 7] </ref>. In the following subsections, we describe three recognizers we have used in our experiments. All recognizers initially represent the speech signal using 10 Mel-scale cepstral coefficients (MFCCs) every 10 ms. Each recognizer then further extracts frame or segment-based features. <p> The overall result of 26.6% is a 31.3% improvement over the baseline result of 38.7%. This is a 12.8% improvement over our best previously reported result of 30.5% and is competitive with the best results reported using other approaches, including neural networks and the more common HMMs <ref> [5, 7] </ref>. In the near future, we plan to run similar experiments in word recognition. We believe segmentation by recognition will facilitate working with segment-based approaches.
References-found: 7

