URL: http://www.cs.mu.oz.au/tr_db/mu_93_11.ps.gz
Refering-URL: http://www.cs.mu.oz.au/tr_db/TR.html
Root-URL: 
Title: Fast Ranking in Limited Space  
Author: Alistair Moffat Justin Zobel 
Date: May 1993  
Abstract: Ranking techniques have long been suggested as alternatives to more conventional Boolean methods for searching document collections. The cost of computing a ranking is, however, greater than the cost of performing a Boolean search, in terms of both memory space and processing time. Here we consider the resources required by the cosine method of ranking, and show that with a careful application of indexing and selection techniques both the space and time required by ranking can be substantially reduced. The methods described in this paper have been used to build a retrieval system for a collection of over two million pages of text, with which it is possible to process ranked queries of 50-60 terms in about 5% of the space required by previous implementations; in as little as 25% of the time; and with no loss of retrieval effectiveness.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Buckley and A.F. Lewit. </author> <title> Optimization of inverted vector searches. </title> <booktitle> In Proc. ACM-SIGIR International Conference on Research and Development 18 in Information Retrieval, </booktitle> <pages> pages 97-110, </pages> <address> Montreal, Canada, June 1985. </address> <publisher> ACM Press, </publisher> <address> New York. </address>
Reference-contexts: 1 Introduction Ranking techniques are used to find the documents in a document collection that are most likely to be relevant to an informally-phrased query [10, 11]. When the documents are stored in a database that is indexed by an inverted file <ref> [1, 5, 12] </ref>, several structures must be used if ranked query evaluation is to be acceptably fast. <p> more demanding similarity measures, in that the similarity value assigned to each document depends not just upon that document, but also upon all of the other documents in the collection. 2.2 Document databases In an inverted file document database, each distinct word in the database is held in a vocabulary <ref> [1, 5, 7, 12] </ref>. The vocabulary entry for each word contains an address pointer to an index entry , a contiguous list of the documents containing the word. Each document is known by a unique identifier , which we assume to 3 be its ordinal number. <p> Knowledge of the value f t allows inverted file entries to be processed in order of decreasing term weight <ref> [1, 7] </ref>. This ability is crucial to the schemes we describe, and is also a useful heuristic when processing Boolean queries. The index entry for each word stores a list of the documents that contain that word, and, with each document identifier d, stores the "within-document frequency" f d;t . <p> The space required for these lengths is discussed below. 2.3 Ranked query evaluation The usual method for determining which of the documents in a collection have a high cosine measure with respect to a query is to compute cosine from the inverted file structure and document lengths <ref> [1, 3, 5, 7] </ref>. In this method, an accumulator variable A d is created for each document d containing any of the words in the query, in which the result of the expression P t w q;t w d;t is accrued as index entries are processed. <p> Identify the r highest values of C d , where r is the number of records to be presented to the user, and retrieve the corresponding documents. in the inverted file entries, not the raw f d;t values described above, but instead scaled values f d;t =W d <ref> [1, 7] </ref>. Such scaling is, however, incompatible with index compression: it does reduce memory requirements by several megabytes but this reduction comes at the cost of several hundred megabytes of disk space. <p> That is, we seek to demonstrate that our techniques are scalable. 3 Bounding the accumulator space The accumulators required for ranking could be stored in an array that has one element for each document in the database; this is the usual method described in the information retrieval literature <ref> [1, 3, 5] </ref>. Alternatively, if the number of non-zero accumulators is small compared to the number of documents stored, a dynamic data structure such as a balanced search tree or a hash table can be employed to store the set of accumulators [2].
Reference: [2] <author> T.H. Cormen, C.E. Leiserson, and R.L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <address> Massachusetts, </address> <year> 1990. </year>
Reference-contexts: A simple form of this query evaluation algorithm is shown in Figure 1. We note in passing that the partial ordering required by step 4 can be performed efficiently using a priority queue data structure such as a heap <ref> [2] </ref>, and there is no need for the set of C d values to be completely ordered. The effect of applying the document lengths is to reorder the ranking, sometimes significantly. <p> Alternatively, if the number of non-zero accumulators is small compared to the number of documents stored, a dynamic data structure such as a balanced search tree or a hash table can be employed to store the set of accumulators <ref> [2] </ref>. In this case the document identifier for each non-zero accumulator must also be stored, so that the set can be searched, together with pointers or other structural information. In total, as many as sixteen to twenty bytes of memory might be consumed for each non-zero accumulator.
Reference: [3] <author> W.B. Frakes and R. Baeza-Yates, </author> <title> editors. Information Retrieval: Data Structures and Algorithms. </title> <publisher> Prentice-Hall, </publisher> <address> New Jersey, </address> <year> 1992. </year>
Reference-contexts: The space required for these lengths is discussed below. 2.3 Ranked query evaluation The usual method for determining which of the documents in a collection have a high cosine measure with respect to a query is to compute cosine from the inverted file structure and document lengths <ref> [1, 3, 5, 7] </ref>. In this method, an accumulator variable A d is created for each document d containing any of the words in the query, in which the result of the expression P t w q;t w d;t is accrued as index entries are processed. <p> That is, we seek to demonstrate that our techniques are scalable. 3 Bounding the accumulator space The accumulators required for ranking could be stored in an array that has one element for each document in the database; this is the usual method described in the information retrieval literature <ref> [1, 3, 5] </ref>. Alternatively, if the number of non-zero accumulators is small compared to the number of documents stored, a dynamic data structure such as a balanced search tree or a hash table can be employed to store the set of accumulators [2].
Reference: [4] <editor> D. Harman, editor. </editor> <booktitle> Proc. TREC Text Retrieval Conference, </booktitle> <address> Gaithersburg, Maryland, </address> <year> 1992. </year> <institution> National Institute of Standards. </institution>
Reference-contexts: This was the methodology suggested during the TREC experiment <ref> [4] </ref>, and we have chosen to continue with this convention. From each of the TREC topics we extracted two sets of query terms. To create the first set we removed all non-alphabetic characters, case-folded and stemmed the resulting words, and then removed all duplicates.
Reference: [5] <author> D. Harman and G. Candela. </author> <title> Retrieving records from a gigabyte of text on a minicomputer using statistical ranking. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41(8) </volume> <pages> 581-589, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction Ranking techniques are used to find the documents in a document collection that are most likely to be relevant to an informally-phrased query [10, 11]. When the documents are stored in a database that is indexed by an inverted file <ref> [1, 5, 12] </ref>, several structures must be used if ranked query evaluation is to be acceptably fast. <p> more demanding similarity measures, in that the similarity value assigned to each document depends not just upon that document, but also upon all of the other documents in the collection. 2.2 Document databases In an inverted file document database, each distinct word in the database is held in a vocabulary <ref> [1, 5, 7, 12] </ref>. The vocabulary entry for each word contains an address pointer to an index entry , a contiguous list of the documents containing the word. Each document is known by a unique identifier , which we assume to 3 be its ordinal number. <p> The space required for these lengths is discussed below. 2.3 Ranked query evaluation The usual method for determining which of the documents in a collection have a high cosine measure with respect to a query is to compute cosine from the inverted file structure and document lengths <ref> [1, 3, 5, 7] </ref>. In this method, an accumulator variable A d is created for each document d containing any of the words in the query, in which the result of the expression P t w q;t w d;t is accrued as index entries are processed. <p> That is, we seek to demonstrate that our techniques are scalable. 3 Bounding the accumulator space The accumulators required for ranking could be stored in an array that has one element for each document in the database; this is the usual method described in the information retrieval literature <ref> [1, 3, 5] </ref>. Alternatively, if the number of non-zero accumulators is small compared to the number of documents stored, a dynamic data structure such as a balanced search tree or a hash table can be employed to store the set of accumulators [2].
Reference: [6] <author> J.B. Lovins. </author> <title> Development of a stemming algorithm. Mechanical Translation and Computation, </title> <address> 11(1-2):22-31, </address> <year> 1968. </year>
Reference-contexts: In our paged form of TREC there are 2,054,497 records; an average of 162.5 words per record; 538,244 distinct words, after folding all letters to lowercase and removal of variant endings using Lovin's stemming algorithm <ref> [6] </ref>; and 50 "topics" for which we have relevance judgements. Retrieval effectiveness is usually based on recall (the proportion of relevant documents that have been retrieved) and precision (the proportion of retrieved documents that are relevant) [11].
Reference: [7] <author> D. Lucarella. </author> <title> A document retrieval system based upon nearest neighbour searching. </title> <journal> Journal of Information Science, </journal> <volume> 14 </volume> <pages> 25-33, </pages> <year> 1988. </year>
Reference-contexts: more demanding similarity measures, in that the similarity value assigned to each document depends not just upon that document, but also upon all of the other documents in the collection. 2.2 Document databases In an inverted file document database, each distinct word in the database is held in a vocabulary <ref> [1, 5, 7, 12] </ref>. The vocabulary entry for each word contains an address pointer to an index entry , a contiguous list of the documents containing the word. Each document is known by a unique identifier , which we assume to 3 be its ordinal number. <p> Knowledge of the value f t allows inverted file entries to be processed in order of decreasing term weight <ref> [1, 7] </ref>. This ability is crucial to the schemes we describe, and is also a useful heuristic when processing Boolean queries. The index entry for each word stores a list of the documents that contain that word, and, with each document identifier d, stores the "within-document frequency" f d;t . <p> The space required for these lengths is discussed below. 2.3 Ranked query evaluation The usual method for determining which of the documents in a collection have a high cosine measure with respect to a query is to compute cosine from the inverted file structure and document lengths <ref> [1, 3, 5, 7] </ref>. In this method, an accumulator variable A d is created for each document d containing any of the words in the query, in which the result of the expression P t w q;t w d;t is accrued as index entries are processed. <p> Identify the r highest values of C d , where r is the number of records to be presented to the user, and retrieve the corresponding documents. in the inverted file entries, not the raw f d;t values described above, but instead scaled values f d;t =W d <ref> [1, 7] </ref>. Such scaling is, however, incompatible with index compression: it does reduce memory requirements by several megabytes but this reduction comes at the cost of several hundred megabytes of disk space.
Reference: [8] <author> A. Moffat and J. Zobel. </author> <title> Coding for compression in full-text retrieval systems. </title> <editor> In J.A. Storer and M. Cohn, editors, </editor> <booktitle> Proc. IEEE Data Compression Conference, </booktitle> <pages> pages 72-81, </pages> <address> Snowbird, Utah, March 1992. </address> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> California. </address>
Reference-contexts: The high cost of processing these inverted file entries is exacerbated if, for space efficiency, the inverted file entries are stored compressed <ref> [8, 9] </ref>. Compression can result in a net space reduction of over 80% of the inverted file size, but even with fast decompression|decoding at approximately 250,000 numbers per second on a Sun Sparc 10|it is a substantial overhead on processing time. <p> In the absence of compression we might allocate four bytes and two bytes respectively to store these two values, that is, six bytes for each hd; f d;t i pair. Using compression techniques such as those described by Moffat and Zobel <ref> [8, 9] </ref>, the space required can be reduced to about one byte per pair. On the two gigabyte TREC collection, described below, these techniques compress the inverted file from 1100 megabytes to 193 megabytes, an irresistible saving. <p> The whole entry must be decoded to access this last pair because it is not possible to randomly access points in a compressed inverted file entry|they are typically stored as a sequence of 10 runlengths, with each runlength coded using some variable width code <ref> [8, 9] </ref>. That is, the first bit of the compressed entry is, conventionally, the only point at which decoding can commence. 4.1 Skipping When k t p, faster performance is possible if synchronisation points |additional locations at which decoding can commence|are introduced into the compressed inverted file entry.
Reference: [9] <author> A. Moffat and J. Zobel. </author> <title> Parameterised compression for sparse bitmaps. </title> <editor> In N. Belkin, P. Ingwersen, and A.M. Pejtersen, editors, </editor> <booktitle> Proc. ACM-SIGIR International Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 274-285, </pages> <address> Copenhagen, June 1992. </address> <publisher> ACM Press, </publisher> <address> New York. </address>
Reference-contexts: The high cost of processing these inverted file entries is exacerbated if, for space efficiency, the inverted file entries are stored compressed <ref> [8, 9] </ref>. Compression can result in a net space reduction of over 80% of the inverted file size, but even with fast decompression|decoding at approximately 250,000 numbers per second on a Sun Sparc 10|it is a substantial overhead on processing time. <p> In the absence of compression we might allocate four bytes and two bytes respectively to store these two values, that is, six bytes for each hd; f d;t i pair. Using compression techniques such as those described by Moffat and Zobel <ref> [8, 9] </ref>, the space required can be reduced to about one byte per pair. On the two gigabyte TREC collection, described below, these techniques compress the inverted file from 1100 megabytes to 193 megabytes, an irresistible saving. <p> The whole entry must be decoded to access this last pair because it is not possible to randomly access points in a compressed inverted file entry|they are typically stored as a sequence of 10 runlengths, with each runlength coded using some variable width code <ref> [8, 9] </ref>. That is, the first bit of the compressed entry is, conventionally, the only point at which decoding can commence. 4.1 Skipping When k t p, faster performance is possible if synchronisation points |additional locations at which decoding can commence|are introduced into the compressed inverted file entry. <p> The larger the value of L, the smaller the blocksize b that will be used, and thus the greater the space storage overhead of skipping. Table 2 shows the size of the compressed inverted files for the various strategies shown in Figure 5, where the V G encoding <ref> [9] </ref> is used for the base inverted file and for all skipping 15 levels. The most expensive regime|the use of variable skips of as little as four pointers with L = 100; 000|increases the inverted file size by about 25%.
Reference: [10] <author> G. Salton. </author> <title> Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction Ranking techniques are used to find the documents in a document collection that are most likely to be relevant to an informally-phrased query <ref> [10, 11] </ref>. When the documents are stored in a database that is indexed by an inverted file [1, 5, 12], several structures must be used if ranked query evaluation is to be acceptably fast. <p> the end of the paper. 2 2 Ranked Queries In this section we briefly describe the structures and techniques typically used during evaluation of a ranked query with respect to a large document database. 2.1 The cosine measure The ranking technique we use in this paper is the cosine measure <ref> [10, 11] </ref>. <p> The cosine measure is just one method that can be used to perform ranking, and there are many others|see, for example, Salton <ref> [10] </ref> for a description of alternatives.
Reference: [11] <author> G. Salton and M.J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: 1 Introduction Ranking techniques are used to find the documents in a document collection that are most likely to be relevant to an informally-phrased query <ref> [10, 11] </ref>. When the documents are stored in a database that is indexed by an inverted file [1, 5, 12], several structures must be used if ranked query evaluation is to be acceptably fast. <p> the end of the paper. 2 2 Ranked Queries In this section we briefly describe the structures and techniques typically used during evaluation of a ranked query with respect to a large document database. 2.1 The cosine measure The ranking technique we use in this paper is the cosine measure <ref> [10, 11] </ref>. <p> Retrieval effectiveness is usually based on recall (the proportion of relevant documents that have been retrieved) and precision (the proportion of retrieved documents that are relevant) <ref> [11] </ref>. For example, if for some query there are known to be 76 relevant documents, and some query evaluation mechanism has retrieved 100 documents of which 26 are relevant, the precision is 26=100 = 26% and the recall is 26=76 = 34%.
Reference: [12] <author> J. Zobel, A. Moffat, and R. Sacks-Davis. </author> <title> An efficient indexing technique for full-text database systems. </title> <editor> In L.-Y. Yuan, editor, </editor> <booktitle> Proc. International Conference on Very Large Databases, </booktitle> <pages> pages 352-362, </pages> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year> <month> 19 </month>
Reference-contexts: 1 Introduction Ranking techniques are used to find the documents in a document collection that are most likely to be relevant to an informally-phrased query [10, 11]. When the documents are stored in a database that is indexed by an inverted file <ref> [1, 5, 12] </ref>, several structures must be used if ranked query evaluation is to be acceptably fast. <p> more demanding similarity measures, in that the similarity value assigned to each document depends not just upon that document, but also upon all of the other documents in the collection. 2.2 Document databases In an inverted file document database, each distinct word in the database is held in a vocabulary <ref> [1, 5, 7, 12] </ref>. The vocabulary entry for each word contains an address pointer to an index entry , a contiguous list of the documents containing the word. Each document is known by a unique identifier , which we assume to 3 be its ordinal number.

References-found: 12

