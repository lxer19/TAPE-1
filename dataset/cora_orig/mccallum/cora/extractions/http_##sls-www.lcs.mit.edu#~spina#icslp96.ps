URL: http://sls-www.lcs.mit.edu/~spina/icslp96.ps
Refering-URL: http://sls-www.lcs.mit.edu/~spina/resume.html
Root-URL: 
Title: Automatic Transcription of General Audio Data: Preliminary Analyses  
Author: Michelle S. Spina and Victor W. Zue 
Address: Cambridge, Massachusetts 02139 USA  
Affiliation: Spoken Language Systems Group Laboratory for Computer Science Massachusetts Institute of Technology  
Abstract: The task of automatically transcribing general audio data is very different from the transcription task typically required of current automatic speech recognition systems. The general goal of this work is to quantify the difficult issues posed by such data, thus leading to an understanding of how a speech recognition system may have to be altered to accommodate the added complexities. Specifically, we describe some preliminary analyses and experiments we have conducted on data collected from a radio news program. We found that using relatively straightforward acoustic measurements and classification techniques, we were able to achieve better than 80% classification accuracy for seven salient sound classes present in the data, and nearly 94% classification accuracy for a speech/non-speech decision. In addition, lexical analysis revealed that while the vocabulary size of a single broadcast is moderate, it grows exponentially as more shows are added. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <editor> Gopalakrishnan, P.S. et al. </editor> <title> Transcription of radio broadcast news with the IBM large vocabulary speech recognition system, </title> <booktitle> In Proc. DARPA Speech Recognition Workshop, </booktitle> <month> Feb., </month> <year> 1996. </year>
Reference-contexts: M. Spina also receives support from Intel Corporation. processing step, in which the signal is first segmented into homogeneous chunks <ref> [1, 4, 6, 7] </ref>. This is because accurate sound segmentation will enable us to utilize acoustic models appropriate for each environment. Furthermore, knowing the particular nature of the speech material may help limit the active vocabulary.
Reference: 2. <author> Hetherington, I.L. and McCandless, M. SAPPHIRE: </author> <title> An extensible speech analysis and recognition tool based on Tcl/Tk, </title> <booktitle> These proceedings. </booktitle>
Reference-contexts: The first hour of the labeled data was used for algorithm development and training, whereas the second hour was set aside for testing. Throughout our investigation, we made heavy use of the Transcription View facility in SAPPHIRE <ref> [2] </ref>, which can simultaneously display the waveform, spectrogram, actual transcription and classification output for each file. data. Studio-quality speech constitutes only about half of the entire corpus, and another 20% of the data contain speech superimposed with other sounds.
Reference: 3. <author> Hetherington, I.L. and Zue, V.W. </author> <title> New words: Implications for continuous speech recognition, </title> <booktitle> In 3rd European Conf. on Speech Comm. and Tech., </booktitle> <address> Berlin, Germany, </address> <month> Sept., </month> <year> 1993. </year>
Reference-contexts: This trend is similar to, but slightly worse than those of the other large vocabulary corpora such as the Wall Street Journal corpus or the Switchboard corpus <ref> [3] </ref>. As more shows are included, the size of the common vocabulary across the shows will obviously decrease.
Reference: 4. <editor> Jain, U. et al. </editor> <title> Recognition of continuous broadcast news with multiple unknown speakers and environments, </title> <booktitle> In Proc. DARPA Speech Recognition Workshop, </booktitle> <month> Feb., </month> <year> 1996. </year>
Reference-contexts: M. Spina also receives support from Intel Corporation. processing step, in which the signal is first segmented into homogeneous chunks <ref> [1, 4, 6, 7] </ref>. This is because accurate sound segmentation will enable us to utilize acoustic models appropriate for each environment. Furthermore, knowing the particular nature of the speech material may help limit the active vocabulary.
Reference: 5. <author> James, David Anthony. </author> <title> The Application of Classical Information Retrieval Techniques to Spoken Documents. </title> <type> PhD thesis, </type> <institution> Univ. of Cambridge, </institution> <month> Feb., </month> <year> 1995. </year>
Reference-contexts: More recently, ASR research has broadened its scope to include the transcription of general audio data (GAD), from sources such as radio, television, or movies. This shift in research focus is largely brought on by the growing need to shift content-based information retrieval from text to speech <ref> [5] </ref>, so that the computer can satisfy requests such as, Play me the speech by President Kennedy in which he said, `Ich bin ein Berliner.' GAD pose new challenges to present-day ASR technology because they often contain extemporaneously-generated, and therefore dis-fluent speech, with words drawn from a very large vocabulary, and
Reference: 6. <author> Kubala, F. et al. </author> <title> Toward automatic recognition of broadcast news, </title> <booktitle> In Proc. DARPA Speech Recognition Workshop, </booktitle> <month> Feb., </month> <year> 1996. </year>
Reference-contexts: M. Spina also receives support from Intel Corporation. processing step, in which the signal is first segmented into homogeneous chunks <ref> [1, 4, 6, 7] </ref>. This is because accurate sound segmentation will enable us to utilize acoustic models appropriate for each environment. Furthermore, knowing the particular nature of the speech material may help limit the active vocabulary.
Reference: 7. <author> Wegmann, S. et al. </author> <title> Marketplace recognition using Dragon's continuous speech recognition system, </title> <booktitle> In Proc. DARPA Speech Recognition Workshop, </booktitle> <month> Feb., </month> <year> 1996. </year>
Reference-contexts: M. Spina also receives support from Intel Corporation. processing step, in which the signal is first segmented into homogeneous chunks <ref> [1, 4, 6, 7] </ref>. This is because accurate sound segmentation will enable us to utilize acoustic models appropriate for each environment. Furthermore, knowing the particular nature of the speech material may help limit the active vocabulary.
References-found: 7

