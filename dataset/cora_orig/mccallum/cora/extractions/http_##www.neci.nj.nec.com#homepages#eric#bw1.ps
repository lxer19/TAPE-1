URL: http://www.neci.nj.nec.com/homepages/eric/bw1.ps
Refering-URL: http://www.neci.nj.nec.com/homepages/eric/
Root-URL: 
Email: eric@research.nj.nec.com  
Title: Toward a Model of Intelligence as an Economy of  
Author: Idiots Eric B. Baum 
Date: November 12, 1997  
Address: 4 Independence Way Princeton, NJ 08540  
Affiliation: NEC Research Institute  
Abstract: A market-based algorithm is presented which autonomously apportions complex tasks to multiple cooperating agents giving each agent the motivation of improving performance of the whole system. A specific model, called "The Hayek Machine" is proposed and tested on a simulated Blocks World (BW) planning problem. Hayek learns to solve more complex BW problems than any previous learning algorithm. Given intermediate reward and simple features, it has learned to efficiently solve arbitrary BW problems. The Hayek Machine can also be seen as a model of evolutionary economics. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Andersen, Esben Sloth, </author> <title> Evolutionary Economics: Post-Schumpeterian Contributions, </title> <publisher> Pinter Publishers, </publisher> <address> London, </address> <year> 1996 </year>
Reference-contexts: I hope in the future that Hayek will be improved to autonomously expand its representational capability as necessary [7]. In the meantime, I introduced three terms: top <ref> [1] </ref>, top [2], top [3]. top [i] is the height at which the next block will go, if placed on stack i. <p> profits from successful innovation are a disequilibrium phenomena, at least by the standard of equilibrium proposed in the models in question." Increasingly the nascent field of evolutionary economics has attempted to deal with these questions by modelling the interaction of agents who initially have little rationality but learn (cf. [45], <ref> [1] </ref>.) The Hayek Machine can be seen as another entrant into this approach, with some novel features. The Hayek Machine's individual agents are simple, automatically generated rules which only make one decision (to bid or not to bid), and hence might be expected to be far from perfectly rational.
Reference: [2] <editor> Anderson, P W., K. J. Arrow, and D. Pines, eds, </editor> <year> (1988), </year> <title> The Economy as an evolving complex system, </title> <publisher> Addison Wesley, </publisher> <address> Redwood City CA. </address>
Reference-contexts: Miller and Drexler [37][38] have proposed applying economic ideas to create a complex programming environment for distributed computing, and also commented briefly on the possibility of producing intelligence as an economy of agents. They identified the cheating problem mentioned above, and proposed 1 Holland [25] and others <ref> [2] </ref> have similarly generalized economies as well as many other natural systems as "Complex Adaptive Systems". CAS include what I am calling economies of agents. Unfortunately, I do not know of an extent compact definition of CAS. 2 that enforcing local conservation of "money" would solve it. <p> I hope in the future that Hayek will be improved to autonomously expand its representational capability as necessary [7]. In the meantime, I introduced three terms: top [1], top <ref> [2] </ref>, top [3]. top [i] is the height at which the next block will go, if placed on stack i.
Reference: [3] <author> Bacchus, F., Kabanza, F. </author> <title> (1995) Using temporal logic to control search in planning, </title> <note> unpublished document available from http://logos.uwaterloo.ca/tlplan/tlplan.html. A short version was presented at the European Workshop on Planning, </note> <year> 1995. </year>
Reference-contexts: Otherwise he sees a new random instance. A picture of a BW problem is shown in figure 2, in x 4.1 below. Blocks World has been a benchmark domain since the '60's [64] and remains widely studied today, c.f. <ref> [3] </ref>, [18]. It can be treated as a planning problem, where the solver is told the objective, but must construct a plan for solution. Alternatively it can be a learning and planning problem, as here, where the learner only receives reinforcement and must discover the goal. <p> Recent experiments have applied several sophisticated general purpose AI planning algorithms to Blocks World problems, finding that they could solve problems involving only small, roughly single digit, numbers of blocks, unless given hand crafted knowledge specific to Blocks World <ref> [3] </ref>. With such domain knowledge, problems involving a few tens of blocks can be solved. The Blocks World problems in these experiments were similar but not identical to those experimented with in this paper. See x4.4 below for further discussion. <p> I hope in the future that Hayek will be improved to autonomously expand its representational capability as necessary [7]. In the meantime, I introduced three terms: top [1], top [2], top <ref> [3] </ref>. top [i] is the height at which the next block will go, if placed on stack i. <p> Moreover our simple efforts to hand-program in Hayek's restricted representation (simply as a test of our software), without the top [i] variables, were inferior to the solutions Hayek produced. Bacchus and Kabanza <ref> [3] </ref> experimented with SNLP [36],[52], Prodigy 4.0 [10], and their own TLPlan Blocks World Problems closely related to (but different from) ours. These are sophisticated programs representing many years of effort, utilizing hand coded general purpose heuristics, doing extensive searches, and of course given a specified goal.
Reference: [4] <author> Barto, A. G., Bradtke, S. J., Singh, S. P. </author> <title> (1995) learning to act using real-time dynamic programming, </title> <journal> AI Journal, </journal> <note> to appear. </note>
Reference-contexts: In this paper I take the point of view that a multiagent system must learn how to reward its agents as it learns to perform tasks. This picture is similar to that of the Reinforcement Learning community <ref> [4] </ref> that one learns policy and value simultaneously, except that I am proposing that the rewards themselves be computed by agents, possibly in collaboration. I define an economy of agents 1 to be any set of agents that pass around rewards and modify their behavior in response to these rewards.
Reference: [5] <author> Baum, E. B., Boneh, D. Garrett, C. </author> <booktitle> (1995) On Genetic Algorithms, in Proceedings of the Eighth Annual Conference on Computational Learning Theory, </booktitle> <pages> pp 230-239. </pages>
Reference-contexts: Ongoing work is experimenting with ways in which Hayek can expand its representations to achieve the necessary flexibility. In this paper, intermediate reward functions yielded the desired expressive power. Holland (and much if not all of the following literature) used Genetic Algorithms (GA's) to train classifier systems. Recently <ref> [5] </ref> has shown that some GA's can in some contexts be more efficient than Hill Climbing. However, the same paper, as well as much experience, indicates that in many contexts GA's are dramatically worse.
Reference: [6] <author> Baum, E. B. </author> <year> (1996), </year> <title> Toward a model of mind as a laissez-faire economy of idiots, extended abstract, </title> <booktitle> Proc. 13th ICML '96, </booktitle> <editor> ed. L. Saitta, </editor> <publisher> Morgan Kaufman, </publisher> <address> San Fran. CA. </address>
Reference-contexts: Thus here too one finds a growing consensus that human caliber intelligence must somehow originate in the interaction of many simpler agents c.f. [17], [24], [31], [35], [39], [44], [50], [56], [57]. fl An extended abstract of this paper appeared in ICML '96 <ref> [6] </ref>. 1 Arguably the critical problem in producing intelligence as a multiagent sys-tem is attributing credit when several agents together collaborate on a project. As Minsky wrote already in 1963 [40] "suppose that one million tasks are involved in a complex task (such as winning a chess game).
Reference: [7] <author> Baum, E. B., Durdanovic, I., </author> <note> (1997) Economic Metalearning, submitted for publication. </note>
Reference-contexts: In this paper Hayek's agents are restricted to be productions with a single fixed bid and action. (More complex agents are experimented with in <ref> [7] </ref>). Thus for this paper each agent has a triplet: condition, action, bid. The condition is a Boolean conjunction. If the condition is true, the agent makes its bid, otherwise it bids zero. Thus each agent is a specialist. <p> In general, no claim is asserted that the constitution of Hayek's economy is optimal. Devising other, and perhaps better, constitutions is posed as an open problem. Ongoing experiments with generalizations to constitutions allowing more complex agents are reported on elswhere <ref> [7] </ref>. x2 describes the Blocks World environment in more detail. x3 gives more details on the version of The Hayek Machine experimented with here including subsections: x3.1 that describes how new agents are generated; x3.2 that describes how bid values are generated; x3.3 that analyzes convergence properties; and x3.4 that gives <p> We also experimented with a naive metalearning scheme, in which all parameters were themselves learned from tabula rasa. Neither the choice of P fl nor the replacement of parameters by metalearning noticeably impacted Hayek's performance. Ongoing work on sophisticated metalearning is reported elsewhere <ref> [7] </ref>. We mention these naive metalearning experiments here only as further evidence that our results were not generated by sophisticated choice of parameters in agent creation. 3.2 Bid Assignment Human contractors and purchasers think hard about when and how much to bid. Hayek's agents must decide on bids autonomously. <p> I hope in the future that Hayek will be improved to autonomously expand its representational capability as necessary <ref> [7] </ref>. In the meantime, I introduced three terms: top [1], top [2], top [3]. top [i] is the height at which the next block will go, if placed on stack i. <p> Hayek by contrast allows only one rule at any given time to act. Property rights are clear and not shared, and thus there is no tragedy of the commons. In ongoing work <ref> [7] </ref> Hayek is generalized to allow multiple computational actions in parallel, but with only one auction winner able to take actions affecting the world. That rule then collects any payoff. Some of Holland's non-economic design choices should also be reconsidered (and see also [49]). <p> Hayek is currently trained by hill climbing. Ongoing work is experimenting with met-alearning approaches that might be viewed as vaguely genetic, since they have the ability to combine other agents, but use more complex combinations than simple crossover <ref> [7] </ref>. 5.2 Temporal Difference Learning/RTDP There is a large literature (c.f. [8]) on learning methods that maintain an evaluation function U (i) mapping states to values, update the evaluation of a state in terms of the evaluation of the next state reached (plus any reward in transition), and make move choices <p> Within the framework of The Hayek Machine, we are free to explore more complex representations (i.e. more complex types of agents) while still maintaining the intuition that each update improves performance. Indeed, I am currently exploring complex representations that would be difficult to conceive within standard RTDP frameworks <ref> [7] </ref>. Collections of agents are a modular way to represent evaluation functions. In very complex environments, and especially in systems like the mind that must function in many different environments, this modularity may be critical to learning. <p> In simulation, interesting phenomena observed in real economies, like speculative bubbles and inflation (c.f. x3.2), cherrypicking (c.f. x3.3), intellectual property <ref> [7] </ref>, formation of corporations [7], and technological progress arise in Hayek. <p> In simulation, interesting phenomena observed in real economies, like speculative bubbles and inflation (c.f. x3.2), cherrypicking (c.f. x3.3), intellectual property <ref> [7] </ref>, formation of corporations [7], and technological progress arise in Hayek.
Reference: [8] <author> Bertsekas, D. P., J. N. Tsitsiklis, </author> <title> (1996) Neuro-dynamic Programming, </title> <publisher> Athena Scientific, </publisher> <address> Belmont MA. </address> <month> 30 </month>
Reference-contexts: Hayek is currently trained by hill climbing. Ongoing work is experimenting with met-alearning approaches that might be viewed as vaguely genetic, since they have the ability to combine other agents, but use more complex combinations than simple crossover [7]. 5.2 Temporal Difference Learning/RTDP There is a large literature (c.f. <ref> [8] </ref>) on learning methods that maintain an evaluation function U (i) mapping states to values, update the evaluation of a state in terms of the evaluation of the next state reached (plus any reward in transition), and make move choices by choosing the action maximizing the expected evaluation of next state,
Reference: [9] <author> Birk, A., Paul, W. J., </author> <title> (1995) Schemas and Genetic Programming, </title> <note> document to be published. </note>
Reference: [10] <author> Carbonell, J. G., J. Blythe, O. Etzioni, Y. Gill, R. Joseph, D. Khan, C. Knoblock, S. Minton, A. Perez, S. Reilly, M. Veloso, and X. </author> <title> Wang (1992) Prodigy 4.0: The manual and Tutorial. </title> <type> Technical Report CMU-CS-92-150, </type> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference-contexts: Moreover our simple efforts to hand-program in Hayek's restricted representation (simply as a test of our software), without the top [i] variables, were inferior to the solutions Hayek produced. Bacchus and Kabanza [3] experimented with SNLP [36],[52], Prodigy 4.0 <ref> [10] </ref>, and their own TLPlan Blocks World Problems closely related to (but different from) ours. These are sophisticated programs representing many years of effort, utilizing hand coded general purpose heuristics, doing extensive searches, and of course given a specified goal.
Reference: [11] <author> Clearwater, S. H., ed. </author> <year> (1996), </year> <title> Market-Based Control, A Paradigm for Distributed Resource Allocation, </title> <publisher> World Scientific, Singapore. </publisher>
Reference-contexts: c.f. x4.1, and because this is a problem in which 2 dimensional topology, built in in the form of wildcards and cartesian coordinates, was very helpful. 5.3 Agoric Computation There is a sizeable and interesting literature discussing use of equilibrium economic models to allocate resources in a distributed environment, c.f. <ref> [11] </ref>. Much if not all of this literature, however, deals with programming environments rather than learning machines. Wellman's WALRAS [59] is a programming environment where users may describe agents and provide them with appropriate cost and demand curves. Prices are then determined by equilibrating cost and demand for various commodities.
Reference: [12] <author> Coase, R. H., </author> <note> (1997) Interview in January 1997 issue of "Reason". </note>
Reference-contexts: To the extent that Hayek suggests alternate explanations for phenomena: e.g. markets are efficient because of disequilibrium phenomena, it may call into question accepted lore. For example, the agents surviving evolution apparently behave very rationally. Coase <ref> [12] </ref> has intuitively remarked that such a selection mechanism might be the cause of rationality in economic systems. 15 It is perhaps interesting to present a computer model which realizes this picture.
Reference: [13] <author> Coase, R. H., </author> <year> (1937), </year> <title> "The nature of the firm", </title> <journal> Economica, New Series, </journal> <volume> Vol 4, </volume> <pages> pp 386-405. </pages>
Reference: [14] <author> Cosimidies, L. and J. </author> <title> Tooby (1992) Cognitive adaptations for Social Exchange, </title> <editor> in Barkow, J. H., L. Cosimidies, and J. </editor> <title> Tooby (1992) The adapted mind, </title> <publisher> Oxford University Press. NY., </publisher> <pages> pp 163-228. </pages>
Reference-contexts: This view is separately expressed by workers in a wide variety of disciplines, each discipline offering independent empirical evidence, c.f. the literatures of evolutionary psychology <ref> [14] </ref>, cognitive psychology [44],brain imaging,[55] [21], philosophy [16], neuroanatomy [34] and elsewhere. Much work within the computer science literature focusses on a constructivist approach to intelligence. Divide and conquer is a natural approach for complex computational tasks. <p> However topology seems broadly useful. I regard biological evolution as having started with an a priori knowledge of topology, since it manipulates objects embedded in three dimensional space. Experiments indicate human infants are born with implicit knowledge of topology and object permanence <ref> [14] </ref>. Of course, a child capable of solving these BW problems, would already have learned much about the world. Experiments were typically performed with a rent of .05 or .5. I do not have a clear analytic understanding of how to optimize the choice of rent.
Reference: [15] <author> Crites R. H. and A. G. Barto, </author> <title> "Improving Elevator Performance Using Reinforcement Learning", </title> <editor> in D. S. Touretzky, M. C. Mozer, and M. E. Hasselmo (Eds.) </editor> <booktitle> Advances in Neural Information Processing Systems. </booktitle>
Reference: [16] <author> D. C. Dennett, </author> <title> Consciousness Explained, </title> <publisher> Little Brown and Co, </publisher> <address> Boston, </address> <year> 1991 </year>
Reference-contexts: This view is separately expressed by workers in a wide variety of disciplines, each discipline offering independent empirical evidence, c.f. the literatures of evolutionary psychology [14], cognitive psychology [44],brain imaging,[55] [21], philosophy <ref> [16] </ref>, neuroanatomy [34] and elsewhere. Much work within the computer science literature focusses on a constructivist approach to intelligence. Divide and conquer is a natural approach for complex computational tasks.
Reference: [17] <author> Drescher, </author> <title> G.L.(1991)Made-Up Minds, </title> <publisher> MIT Press. </publisher>
Reference-contexts: Much work within the computer science literature focusses on a constructivist approach to intelligence. Divide and conquer is a natural approach for complex computational tasks. Thus here too one finds a growing consensus that human caliber intelligence must somehow originate in the interaction of many simpler agents c.f. <ref> [17] </ref>, [24], [31], [35], [39], [44], [50], [56], [57]. fl An extended abstract of this paper appeared in ICML '96 [6]. 1 Arguably the critical problem in producing intelligence as a multiagent sys-tem is attributing credit when several agents together collaborate on a project. <p> And note that, given topi variables and incremental payoff, Hayek generated a general and efficient solution to arbitrary size problems the first time it evidently could express one. 5 Related Work The origin of mental capabilities in the interaction of smaller units has been widely studied, e.g. <ref> [17] </ref>, [24], [31], [35], [39], [44], [50], [57], [56]. These models are not explicitly economic. We commented in the introduction that non-economic multi-agent models risk unintended consequences arising from distorted implicit incentives.
Reference: [18] <author> Estlin, T. A., and R, J. </author> <title> Mooney (1996) "Multi-Strategy Learning of Search Control for Partial-Order Planning", </title> <booktitle> Proceedings of the Thirteenth National Conference on Aritificial Intelligence, </booktitle> <pages> pp. 843-848. </pages>
Reference-contexts: Otherwise he sees a new random instance. A picture of a BW problem is shown in figure 2, in x 4.1 below. Blocks World has been a benchmark domain since the '60's [64] and remains widely studied today, c.f. [3], <ref> [18] </ref>. It can be treated as a planning problem, where the solver is told the objective, but must construct a plan for solution. Alternatively it can be a learning and planning problem, as here, where the learner only receives reinforcement and must discover the goal.
Reference: [19] <author> Erol, K., Nau, D. S., Subrahmanian, V. S.. </author> <title> (1992) On the complexity of domain independent planning. </title> <booktitle> In Proceedings of the AAAI National Conference, </booktitle> <pages> pp 381-386. </pages>
Reference: [20] <author> Forrest, S. </author> <title> (1985) Implementing semantic network structures using the classifier system. </title> <booktitle> In Proc. First International Conference on Genetic Algorithms, </booktitle> <pages> pp 188-196. </pages> <address> Hillsdale NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: That rule then collects any payoff. Some of Holland's non-economic design choices should also be reconsidered (and see also [49]). Holland Classifiers use a particular representation rather different than that used to date by Hayek. This representation has been shown Turing equivalent <ref> [20] </ref>. However, universal computers require infinite memory. Practical considerations force size limitations. It is unclear whether Holland's representation is a particularly efficient or learnable realization of finite state machines.
Reference: [21] <author> P. Fox, </author> <title> "Functional Volume Models: System Level Models for Functional Neuroimaging", </title> <type> ICNN '97. </type>
Reference-contexts: This view is separately expressed by workers in a wide variety of disciplines, each discipline offering independent empirical evidence, c.f. the literatures of evolutionary psychology [14], cognitive psychology [44],brain imaging,[55] <ref> [21] </ref>, philosophy [16], neuroanatomy [34] and elsewhere. Much work within the computer science literature focusses on a constructivist approach to intelligence. Divide and conquer is a natural approach for complex computational tasks.
Reference: [22] <author> Gurvits, L., L.-J. Lin, and S. J. Hanson, </author> <title> (1994) "Incremental learning of evaluation functions for absorbing Markov chains: New methods and theorems", </title> <type> unpublished report. </type>
Reference-contexts: I will refer to this class of methods as Real Time Dynamic Programming (RTDP) or Temporal Difference Learning (TDL) methods. This class of methods is powerful, and for Markovian environments, if U (i) is a lookup table (Q-Learning [61]) can be shown to converge <ref> [22] </ref>. Unfortunately, in environments with a huge number of states, one must regularize by using an evaluation mapping which is many to one, e.g. a neural net, and also give up on exploring the 24 entire state space.
Reference: [23] <author> Hardin, G. </author> <title> "The Tragedy of the Commons", </title> <booktitle> Science, 1968, </booktitle> <volume> 162, </volume> <pages> 1243-1248. 31 </pages>
Reference: [24] <author> Holland, J. H. </author> <title> (1986) Escaping brittleness: the possibilities of general pur-pose learning algorithms applied to parallel rule-based systems. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, (eds.) </editor> <booktitle> Machine Learning II pp 593-623, </booktitle> <publisher> Los Altos CA Morgan Kauffman. </publisher>
Reference-contexts: Much work within the computer science literature focusses on a constructivist approach to intelligence. Divide and conquer is a natural approach for complex computational tasks. Thus here too one finds a growing consensus that human caliber intelligence must somehow originate in the interaction of many simpler agents c.f. [17], <ref> [24] </ref>, [31], [35], [39], [44], [50], [56], [57]. fl An extended abstract of this paper appeared in ICML '96 [6]. 1 Arguably the critical problem in producing intelligence as a multiagent sys-tem is attributing credit when several agents together collaborate on a project. <p> It is proposed to seek an appropriate constitution for an economy of agents that promotes the evolution of intelligence. Many previous models can be viewed as economies of agents, including prominently Lenat's Eurisko [31] and Holland's Classifier Systems <ref> [24] </ref>. A new definition is useful if it leads to insight. We discuss below economic insights into assignment of credit in Eurisko, Classifier Systems, and a new model presented here, and pose several open questions. <p> or H (the current content of the hand) or a grid location of form (x; y) where x 2 fflx; 0; 1; 2; 3g is a stack and y 2 ffly; 1; 2; :::; hg is a height. flx and fly here are existentially quantified variables, analagous to Holland's wildcards <ref> [24] </ref>. The condition is said to be valid, and thus the agent bids, if there is any assignment of f0; 1; 2; 3g to flx and f1; 2; :::; hg to fly rendering the Boolean condition true. <p> Thus higher rent favors using more general agents over more specific ones. This favoritism is perhaps useful for learning, but is precisely the opposite of what intuition <ref> [24] </ref> says we should do at any given time to solve the current instance- i.e. favor the more specific, and hence presumably more pertinent, agent. A higher rent does, however, help to remove marginally unprofitable agents who might otherwise survive for some time by luck. <p> Our experiments with this method were done before we instituted the backup, described above, and so this method did not work well, but rather generated inflationary speculative bubbles on small instances, never progressing beyond stage 2. Holland <ref> [24] </ref> set bids in his classifier systems by b = ffsW for ff a small constant, where s is the "specificity" of a classifier, and W its wealth. His motivation was to set the bid (a dependent variable) so as to prefer wealthier and more specific rules. <p> And note that, given topi variables and incremental payoff, Hayek generated a general and efficient solution to arbitrary size problems the first time it evidently could express one. 5 Related Work The origin of mental capabilities in the interaction of smaller units has been widely studied, e.g. [17], <ref> [24] </ref>, [31], [35], [39], [44], [50], [57], [56]. These models are not explicitly economic. We commented in the introduction that non-economic multi-agent models risk unintended consequences arising from distorted implicit incentives. <p> This may be a hard task. Minsky's "Society of Mind"[39] proposes many subsystems at a high level, but does not address their dynamic interaction. Specifying this interaction without vast unintended consequences may be a challenging task, akin to centrally managing a complex economy. 5.1 Classifier Systems Holland <ref> [24] </ref> first proposed an explicitly economic model of intelligence, also based on condition, action, bid agents. His seminal work has sparked a whole literature, and greatly influenced my own ideas. However, some have viewed the empirical results with Holland-style "classifier systems" as disappointing, c.f. [62]. <p> But the cost of running in generations is that the system can not evolve smoothly. By contrast Hayek learns continuously, slowly adding new agents. Many rules act simultaneously in Holland's Classifier Systems. When payoff arives from the world, all active rules share it <ref> [24] </ref>. This invites a phenomenon called "the tragedy of the commons"[23], [33]. The "tragedy of the commons" is a ubiquitous problem in economies wherever property rights are shared or unclear.
Reference: [25] <author> Holland, J. H. </author> <title> (1995) Hidden Order, </title> <publisher> Addison-Wesley Reading Ma. </publisher>
Reference-contexts: Miller and Drexler [37][38] have proposed applying economic ideas to create a complex programming environment for distributed computing, and also commented briefly on the possibility of producing intelligence as an economy of agents. They identified the cheating problem mentioned above, and proposed 1 Holland <ref> [25] </ref> and others [2] have similarly generalized economies as well as many other natural systems as "Complex Adaptive Systems". CAS include what I am calling economies of agents. Unfortunately, I do not know of an extent compact definition of CAS. 2 that enforcing local conservation of "money" would solve it.
Reference: [26] <editor> Huberman,B. A., ed, </editor> <booktitle> The Ecology of Computation, Studies in Computer Science and Artificial Intelligence 2, </booktitle> <publisher> North Holland, </publisher> <address> New York, </address> <year> (1988) </year>
Reference: [27] <author> Khardon, R., Roth, D. </author> <title> (1994) Learning to reason. </title> <booktitle> Proc. 12th National Conference on Artificial Intelligence, </booktitle> <publisher> AAAI Press/ MIT Press pp 682-687. </publisher>
Reference: [28] <editor> Koza, J.R., </editor> <booktitle> (1992) Genetic Programming, </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge MA, </address> <pages> pp 459-470. </pages>
Reference: [29] <author> Lang, </author> <title> K, (1995) "Hill Climbing Beats Genetic Search on a Boolean Circuit Synthesis Task of Koza's", </title> <booktitle> The Twelfth International Conference on Machine Learning, </booktitle> <pages> pp. 340-343. </pages>
Reference-contexts: A recent comparison of Genetic Programming to a strawman hillclimbing algorithm found the hill-climbing algorithm faster by a factor of 50 on a small Boolean function learning task, and found a gradient descent neural algorithm yet faster than the straw-man hillclimbing algorithm by a factor of several hundred <ref> [29] </ref>, [30]. Hayek is currently trained by hill climbing.
Reference: [30] <author> Lang, </author> <title> K, (1995) "Comments on `A Response to...'", Post to Machine Learning List Vol. </title> <journal> 7, </journal> <volume> No. </volume> <month> 14 August 18. </month>
Reference-contexts: A recent comparison of Genetic Programming to a strawman hillclimbing algorithm found the hill-climbing algorithm faster by a factor of 50 on a small Boolean function learning task, and found a gradient descent neural algorithm yet faster than the straw-man hillclimbing algorithm by a factor of several hundred [29], <ref> [30] </ref>. Hayek is currently trained by hill climbing.
Reference: [31] <author> Lenat, D. B., </author> <title> "The role of heuristics in learning by discovery: three case studies", </title> <editor> in Michalski,R.,S., Carbonell, J.G., and Mitchell, T., eds, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <publisher> (Tioga Pub. Co., </publisher> <address> Palo Alto CA 1983 pp 243-306. </address>
Reference-contexts: Divide and conquer is a natural approach for complex computational tasks. Thus here too one finds a growing consensus that human caliber intelligence must somehow originate in the interaction of many simpler agents c.f. [17], [24], <ref> [31] </ref>, [35], [39], [44], [50], [56], [57]. fl An extended abstract of this paper appeared in ICML '96 [6]. 1 Arguably the critical problem in producing intelligence as a multiagent sys-tem is attributing credit when several agents together collaborate on a project. <p> It is proposed to seek an appropriate constitution for an economy of agents that promotes the evolution of intelligence. Many previous models can be viewed as economies of agents, including prominently Lenat's Eurisko <ref> [31] </ref> and Holland's Classifier Systems [24]. A new definition is useful if it leads to insight. We discuss below economic insights into assignment of credit in Eurisko, Classifier Systems, and a new model presented here, and pose several open questions. <p> And note that, given topi variables and incremental payoff, Hayek generated a general and efficient solution to arbitrary size problems the first time it evidently could express one. 5 Related Work The origin of mental capabilities in the interaction of smaller units has been widely studied, e.g. [17], [24], <ref> [31] </ref>, [35], [39], [44], [50], [57], [56]. These models are not explicitly economic. We commented in the introduction that non-economic multi-agent models risk unintended consequences arising from distorted implicit incentives.
Reference: [32] <author> Lettau, M., Uhlig, H. </author> <title> (1995) Rule of Thumb and Dynamic Programming, unpublished manuscript, </title> <booktitle> presented at the European Economic Association Meeting, </booktitle> <address> Maastricht, </address> <year> 1994, </year> <note> available at: http://greywww.kub.nl:2080/greyfiles/center/1995/27.html </note>
Reference-contexts: But this is precisely the opposite of what one would like, if using the bids to specify default hierarchies. Thus the representation is less flexible than naively appears (c.f.x4.1). This problem has been independently pointed out by Lettau and Uhlig <ref> [32] </ref>. Hayek (and classifier systems) are therefor intrinsically not free to use bids to specify default hierarchies. It is unclear whether this is a flaw. One certainly needs some way that the representation can be flexible enough so that Hayek can learn to solve its problems.
Reference: [33] <author> Lloyd, W. </author> <title> 1833 "Two Lectures on the Checks to Population". </title> <publisher> Oxford, </publisher> <address> England, </address> <publisher> Oxford University Press. </publisher>
Reference-contexts: By contrast Hayek learns continuously, slowly adding new agents. Many rules act simultaneously in Holland's Classifier Systems. When payoff arives from the world, all active rules share it [24]. This invites a phenomenon called "the tragedy of the commons"[23], <ref> [33] </ref>. The "tragedy of the commons" is a ubiquitous problem in economies wherever property rights are shared or unclear. Just like herders are motivated to overgraze land held in common, each rule's motivation is to be active even if its action lowers the payoff.
Reference: [34] <author> A. R. Luria, </author> <title> The Working Brain, an Introduction to Neuropsychology, </title> <publisher> Basic Books, </publisher> <address> NY, </address> <year> 1973 </year>
Reference-contexts: This view is separately expressed by workers in a wide variety of disciplines, each discipline offering independent empirical evidence, c.f. the literatures of evolutionary psychology [14], cognitive psychology [44],brain imaging,[55] [21], philosophy [16], neuroanatomy <ref> [34] </ref> and elsewhere. Much work within the computer science literature focusses on a constructivist approach to intelligence. Divide and conquer is a natural approach for complex computational tasks.
Reference: [35] <editor> Maes, Pattie, </editor> <year> (1990), </year> <title> "How to do the right thing", </title> <journal> Connection Science 1:3 </journal>
Reference-contexts: Divide and conquer is a natural approach for complex computational tasks. Thus here too one finds a growing consensus that human caliber intelligence must somehow originate in the interaction of many simpler agents c.f. [17], [24], [31], <ref> [35] </ref>, [39], [44], [50], [56], [57]. fl An extended abstract of this paper appeared in ICML '96 [6]. 1 Arguably the critical problem in producing intelligence as a multiagent sys-tem is attributing credit when several agents together collaborate on a project. <p> And note that, given topi variables and incremental payoff, Hayek generated a general and efficient solution to arbitrary size problems the first time it evidently could express one. 5 Related Work The origin of mental capabilities in the interaction of smaller units has been widely studied, e.g. [17], [24], [31], <ref> [35] </ref>, [39], [44], [50], [57], [56]. These models are not explicitly economic. We commented in the introduction that non-economic multi-agent models risk unintended consequences arising from distorted implicit incentives.
Reference: [36] <author> McAllester, D., and D. </author> <booktitle> Rosenblitt (1991) "Systematic nonlinear planning" in Proceedings of the AAAI National Conference, </booktitle> <pages> pp 634-639. </pages>
Reference: [37] <author> Miller, M. S., and K. E. Drexler, </author> <title> "Markets and computation: Agoric open systems", </title> <note> pp 133-176 in [26]. </note>
Reference-contexts: It was remarked that when agents generalize, and indeed in any economy (even a "perfect computational economy", c.f. <ref> [37] </ref>) with imperfect price discrimination, a "cherrypicking" phenomenon in principle could allow updates that fail to improve performance. More generally, I argued "The Hayek Machine" has interest also as a new evolutionary model of economics. There are many open questions.
Reference: [38] <author> Miller, M. S., and K. E. Drexler, </author> <title> "Comparative ecology", </title> <note> pp 51-76 in [26]. 32 </note>
Reference-contexts: In particular they noted that without such a conservation law, positive feedback loops would corrupt assignment of credit, and remarked that such corruption plagued Lenat's multi-agent intelligence Eurisko <ref> [38] </ref>. This paper describes an economy of agents I call "The Hayek Machine". Hayek interacts with an external world, modelled here as a complex system where Hayek may take actions, and which will make payoffs to Hayek in response to appropriate series of actions. <p> These models are not explicitly economic. We commented in the introduction that non-economic multi-agent models risk unintended consequences arising from distorted implicit incentives. For one example, Miller and Drexler <ref> [38] </ref> discuss how imprecise motivation of meta-agents led to parasitic behavior in Lenat's "Eu 22 risko". We discuss some distorted incentives in Holland style classifiers below. Valiant's neuroid model [57], proposes many specialized agents, but assumes a peripheral system that will arbitrate in large measure their interaction.
Reference: [39] <author> Minsky, M., </author> <title> (1986)The Society of Mind, </title> <publisher> Simon and Schuster, </publisher> <address> NY. </address>
Reference-contexts: Divide and conquer is a natural approach for complex computational tasks. Thus here too one finds a growing consensus that human caliber intelligence must somehow originate in the interaction of many simpler agents c.f. [17], [24], [31], [35], <ref> [39] </ref>, [44], [50], [56], [57]. fl An extended abstract of this paper appeared in ICML '96 [6]. 1 Arguably the critical problem in producing intelligence as a multiagent sys-tem is attributing credit when several agents together collaborate on a project. <p> note that, given topi variables and incremental payoff, Hayek generated a general and efficient solution to arbitrary size problems the first time it evidently could express one. 5 Related Work The origin of mental capabilities in the interaction of smaller units has been widely studied, e.g. [17], [24], [31], [35], <ref> [39] </ref>, [44], [50], [57], [56]. These models are not explicitly economic. We commented in the introduction that non-economic multi-agent models risk unintended consequences arising from distorted implicit incentives. For one example, Miller and Drexler [38] discuss how imprecise motivation of meta-agents led to parasitic behavior in Lenat's "Eu 22 risko".
Reference: [40] <author> Minsky, </author> <title> M.,(1963) "Steps Towards Artificial Intelligence" in Computers and Thought, </title> <editor> E. A. Feigenbaum and J. Feldman, eds, </editor> <publisher> AAAI press, </publisher> <address> Menlo Park, </address> <note> (1995) pp 406-450. </note>
Reference-contexts: As Minsky wrote already in 1963 <ref> [40] </ref> "suppose that one million tasks are involved in a complex task (such as winning a chess game). Could we assign to each decision one-millionth of the credit for the completed task?...
Reference: [41] <author> Minsky, M., </author> <title> "A framework for representing knowledge", in Psychology of Computer Vision, </title> <editor> ed. P. Winston, </editor> <publisher> McGraw Hill, </publisher> <year> 1975. </year>
Reference: [42] <author> Myhrvold, N., </author> <title> (1994) Roadkill on the information highway, </title> <institution> Stanford, Calif.: University Video Communications, Distinguished Lecture Series IX; Leaders in Computer Science and electrical Engineering. </institution>
Reference: [43] <author> Richard R. Nelson and Sidney G. Winter. </author> <title> (1994) An Evolutionary Theory of Economic Change, </title> <publisher> Harvard U. Press, 5th printing, p28. </publisher>
Reference-contexts: One drawback of this approach is that it is not evident exactly what direction to perturb in [45]. Moreover, orthodox economics models typically discuss equilibrium phenomena. Yet, to quote one text <ref> [43] </ref>, "It is, however, an institutional fact of life that in the Western market economies- the economies that growth theory purports to model- much technical advance results from profit-oriented investment on the part of business firms.
Reference: [44] <author> Newell, A. </author> <year> (1990), </year> <title> Unified Theories of Cognition, </title> <publisher> Harvard University Press, </publisher> <address> Cambridge MA. </address>
Reference-contexts: Divide and conquer is a natural approach for complex computational tasks. Thus here too one finds a growing consensus that human caliber intelligence must somehow originate in the interaction of many simpler agents c.f. [17], [24], [31], [35], [39], <ref> [44] </ref>, [50], [56], [57]. fl An extended abstract of this paper appeared in ICML '96 [6]. 1 Arguably the critical problem in producing intelligence as a multiagent sys-tem is attributing credit when several agents together collaborate on a project. <p> that, given topi variables and incremental payoff, Hayek generated a general and efficient solution to arbitrary size problems the first time it evidently could express one. 5 Related Work The origin of mental capabilities in the interaction of smaller units has been widely studied, e.g. [17], [24], [31], [35], [39], <ref> [44] </ref>, [50], [57], [56]. These models are not explicitly economic. We commented in the introduction that non-economic multi-agent models risk unintended consequences arising from distorted implicit incentives. For one example, Miller and Drexler [38] discuss how imprecise motivation of meta-agents led to parasitic behavior in Lenat's "Eu 22 risko".
Reference: [45] <author> Palmer, R. G., W. B. Arthur, J. H. Holland, B. LeBaron, P. Tayler, </author> <title> (1994) "Artificial economic life: a simple model of a stockmarket", </title> <journal> Physica D 75 pp264-274. </journal>
Reference-contexts: A literature on "bounded rationality", cf [51] attempts to improve economic 27 analysis by perturbing away from perfect rationality. One drawback of this approach is that it is not evident exactly what direction to perturb in <ref> [45] </ref>. Moreover, orthodox economics models typically discuss equilibrium phenomena. Yet, to quote one text [43], "It is, however, an institutional fact of life that in the Western market economies- the economies that growth theory purports to model- much technical advance results from profit-oriented investment on the part of business firms. <p> The profits from successful innovation are a disequilibrium phenomena, at least by the standard of equilibrium proposed in the models in question." Increasingly the nascent field of evolutionary economics has attempted to deal with these questions by modelling the interaction of agents who initially have little rationality but learn (cf. <ref> [45] </ref>, [1].) The Hayek Machine can be seen as another entrant into this approach, with some novel features. The Hayek Machine's individual agents are simple, automatically generated rules which only make one decision (to bid or not to bid), and hence might be expected to be far from perfectly rational.
Reference: [46] <author> Ray, T. S. </author> <title> (1991) An approach to the synthesis of life. </title> <editor> In C. Langton, C. Taylor, J. D. Farmer, and Rasmussen, editors, </editor> <booktitle> Artificial Life II, </booktitle> <volume> volume XI, </volume> <pages> pages 371-408. </pages> <publisher> Addison-Wesley, </publisher> <address> Redwood City, CA. </address>
Reference: [47] <author> Read, Leonard, </author> <title> "I, Pencil: My Family Tree as Told to Leonard E. Read", </title> <publisher> Freeman, </publisher> <month> December </month> <year> 1958. </year>
Reference: [48] <author> Rumelhart, D.E., Hinton, G. E., and Williams, R. J. </author> <title> (1986) Learning internal representations by error propagation, in Parallel Distributed Processing eds. </title> <editor> Rumelhart, D.E. and McClelland, J.L., </editor> <publisher> MIT Press, </publisher> <address> Cambridge MA. </address>
Reference-contexts: Could we assign to each decision one-millionth of the credit for the completed task?... For more complex problems, with decisions in hierarchies... the running times would become fantastic." Back propagation <ref> [48] </ref> addresses this problem at the level of the individual neuron, but after 15 years of study it does not seem likely to provide the whole answer.
Reference: [49] <author> Schuurmans, D, and J. </author> <title> Schaeffer (1989) "Representational Difficulties with Classifier Systems", </title> <booktitle> Proceedings of International Conference on Genetic Algorithms, </booktitle> <address> Fairfax VA. pp328 -333. </address>
Reference-contexts: In ongoing work [7] Hayek is generalized to allow multiple computational actions in parallel, but with only one auction winner able to take actions affecting the world. That rule then collects any payoff. Some of Holland's non-economic design choices should also be reconsidered (and see also <ref> [49] </ref>). Holland Classifiers use a particular representation rather different than that used to date by Hayek. This representation has been shown Turing equivalent [20]. However, universal computers require infinite memory. Practical considerations force size limitations.
Reference: [50] <author> Selfridge, O. G. </author> <year> (1959) </year> <month> "Pandemonium: </month> <title> a paradigm for learning", </title> <booktitle> Proceedings of the Symposium on Mechanisation of Thought Process. </booktitle> <institution> National Physics Laboratory. </institution>
Reference-contexts: Divide and conquer is a natural approach for complex computational tasks. Thus here too one finds a growing consensus that human caliber intelligence must somehow originate in the interaction of many simpler agents c.f. [17], [24], [31], [35], [39], [44], <ref> [50] </ref>, [56], [57]. fl An extended abstract of this paper appeared in ICML '96 [6]. 1 Arguably the critical problem in producing intelligence as a multiagent sys-tem is attributing credit when several agents together collaborate on a project. <p> given topi variables and incremental payoff, Hayek generated a general and efficient solution to arbitrary size problems the first time it evidently could express one. 5 Related Work The origin of mental capabilities in the interaction of smaller units has been widely studied, e.g. [17], [24], [31], [35], [39], [44], <ref> [50] </ref>, [57], [56]. These models are not explicitly economic. We commented in the introduction that non-economic multi-agent models risk unintended consequences arising from distorted implicit incentives. For one example, Miller and Drexler [38] discuss how imprecise motivation of meta-agents led to parasitic behavior in Lenat's "Eu 22 risko".
Reference: [51] <author> Simon, H.A. </author> <year> (1987b): </year> <title> Bounded rationality. </title> <editor> In: J. Eatwell, M. Millgate, and P. Newman (Eds.): </editor> <title> The New Palgrave: A Dictionary of Economics. </title> <publisher> London and Basingstoke: Macmillan </publisher>
Reference-contexts: Real economies, however, involve interaction between humans who, while computationally powerful, are not infinitely so, and who have differing information. A literature on "bounded rationality", cf <ref> [51] </ref> attempts to improve economic 27 analysis by perturbing away from perfect rationality. One drawback of this approach is that it is not evident exactly what direction to perturb in [45]. Moreover, orthodox economics models typically discuss equilibrium phenomena.
Reference: [52] <author> Soderlan, S. , Barrett, T., and Weld, D. </author> <title> (1990) The SNLP planner implementation, contact bug-snlp@cs.washington.edu. </title> <type> 33 </type>
Reference: [53] <author> Sutton, R. S. </author> <title> (1988) Learning to predict by the methods of temporal dif-ferences, </title> <booktitle> Machine Learning 3: </booktitle> <pages> 9-44. </pages>
Reference-contexts: As will be discussed more in the next subsection, we want the bid to converge to the expected value of using the agent, given it wins the auction. A direct approach is to learn this value by Real Time Dynamic Programming (RTDP) or Temporal Difference type (TD) learning <ref> [53] </ref>.
Reference: [54] <author> Tesauro, G. </author> <title> (1992) Practical issues in temporal difference learing, </title> <booktitle> Machine Learning 8. </booktitle>
Reference-contexts: Possibly the most impressive example of RTDP success is Tesauro's backgammon player, which starting from zero knowledge trained a neural network to serve as a strong evaluation function for the game of backgammon <ref> [54] </ref>. If started with hand coded features, the evaluation function produced sufficed to play at near championship level. Here is a theory of why TD was so successful at backgammon.
Reference: [55] <author> A. W. Toga and J. C. Mazziotta, </author> <title> Brain Mapping, the methods, </title> <publisher> Academic Press, </publisher> <address> 1996, New York. </address>
Reference: [56] <author> Valiant, L. </author> <title> (1995) Rationality, </title> <booktitle> in Proceedings of the Eighth Annual Conference on Computational Learning Theory, </booktitle> <pages> 3-14. </pages>
Reference-contexts: Divide and conquer is a natural approach for complex computational tasks. Thus here too one finds a growing consensus that human caliber intelligence must somehow originate in the interaction of many simpler agents c.f. [17], [24], [31], [35], [39], [44], [50], <ref> [56] </ref>, [57]. fl An extended abstract of this paper appeared in ICML '96 [6]. 1 Arguably the critical problem in producing intelligence as a multiagent sys-tem is attributing credit when several agents together collaborate on a project. <p> variables and incremental payoff, Hayek generated a general and efficient solution to arbitrary size problems the first time it evidently could express one. 5 Related Work The origin of mental capabilities in the interaction of smaller units has been widely studied, e.g. [17], [24], [31], [35], [39], [44], [50], [57], <ref> [56] </ref>. These models are not explicitly economic. We commented in the introduction that non-economic multi-agent models risk unintended consequences arising from distorted implicit incentives. For one example, Miller and Drexler [38] discuss how imprecise motivation of meta-agents led to parasitic behavior in Lenat's "Eu 22 risko".
Reference: [57] <author> Valiant, L. </author> <title> (1994) Circuits of the Mind, </title> <publisher> Oxford University Press. </publisher>
Reference-contexts: Divide and conquer is a natural approach for complex computational tasks. Thus here too one finds a growing consensus that human caliber intelligence must somehow originate in the interaction of many simpler agents c.f. [17], [24], [31], [35], [39], [44], [50], [56], <ref> [57] </ref>. fl An extended abstract of this paper appeared in ICML '96 [6]. 1 Arguably the critical problem in producing intelligence as a multiagent sys-tem is attributing credit when several agents together collaborate on a project. <p> topi variables and incremental payoff, Hayek generated a general and efficient solution to arbitrary size problems the first time it evidently could express one. 5 Related Work The origin of mental capabilities in the interaction of smaller units has been widely studied, e.g. [17], [24], [31], [35], [39], [44], [50], <ref> [57] </ref>, [56]. These models are not explicitly economic. We commented in the introduction that non-economic multi-agent models risk unintended consequences arising from distorted implicit incentives. For one example, Miller and Drexler [38] discuss how imprecise motivation of meta-agents led to parasitic behavior in Lenat's "Eu 22 risko". <p> For one example, Miller and Drexler [38] discuss how imprecise motivation of meta-agents led to parasitic behavior in Lenat's "Eu 22 risko". We discuss some distorted incentives in Holland style classifiers below. Valiant's neuroid model <ref> [57] </ref>, proposes many specialized agents, but assumes a peripheral system that will arbitrate in large measure their interaction. This may be a hard task. Minsky's "Society of Mind"[39] proposes many subsystems at a high level, but does not address their dynamic interaction.
Reference: [58] <author> Venturini, G. </author> <title> (1994) "Adaptation in dynamic environments through a minimal probability of exploration". </title> <booktitle> In Proceedings of the Third International Conference on Simulation of Adaptive Behavior (pp 371-379. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge MA. </address>
Reference-contexts: In very complex environments, and especially in systems like the mind that must function in many different environments, this modularity may be critical to learning. When new agents enter, their bid may be an unreliable guide to the actual value of using that action in that state <ref> [58] </ref>. But by backing up to ignore agents 14 Q-learning maintains a table assigning a value to every state, and at each step goes probabilistically to the next state, with preference to the one of highest value. It learns by dynamic backup of values from end states.
Reference: [59] <author> Wellman,M. </author> <title> P.,(1993) A market oriented programming environment and its application to distributed multicommodity flow problems. </title> <journal> Jouiranl of Artificial Intelligence Research V1 pp 1-23. </journal>
Reference-contexts: Much if not all of this literature, however, deals with programming environments rather than learning machines. Wellman's WALRAS <ref> [59] </ref> is a programming environment where users may describe agents and provide them with appropriate cost and demand curves. Prices are then determined by equilibrating cost and demand for various commodities. The WALRAS environment implements general equilibrium theory.
Reference: [60] <author> Whitehead, S. D. and D. H. Ballard. </author> <title> (1991) "Learning to Perceive and Act." </title> <journal> Machine Learning 7, </journal> <volume> 1, </volume> <pages> 45-83. </pages>
Reference-contexts: See x4.4 below for further discussion. No author that I'm aware of has addressed the abstract goal discovery problem in Blocks World, although a number of authors have been interested in learning in Blocks World contexts. Whitehead and Ballard <ref> [60] </ref> applied a Temporal Difference algorithm to learn to pick up a green block, initially under at 4 most three other blocks. Birk and Paul [9]'s Schema Mechanism moved a sin-gle block around an otherwise empty table.
Reference: [61] <author> Watkins, C. J. C. H. </author> <title> (1989) Learning from delayed rewards, </title> <type> Doctoral thesis, </type> <institution> Cambridge University, </institution> <address> Cambridge England. </address>
Reference-contexts: I will refer to this class of methods as Real Time Dynamic Programming (RTDP) or Temporal Difference Learning (TDL) methods. This class of methods is powerful, and for Markovian environments, if U (i) is a lookup table (Q-Learning <ref> [61] </ref>) can be shown to converge [22]. Unfortunately, in environments with a huge number of states, one must regularize by using an evaluation mapping which is many to one, e.g. a neural net, and also give up on exploring the 24 entire state space.
Reference: [62] <author> Wilson, S. W., Goldberg, D. E. </author> <title> (1989) A critical review of classifier systems. </title> <editor> In J. D. Schaffer, ed. </editor> <booktitle> Proc. Third International Conf. </booktitle> <address> on Genetic Algorithms San Mateo CA, </address> <publisher> Morgan Kauffman. </publisher>
Reference-contexts: To my knowledge, Holland was the first author to use economic terminology and insight in a multi-agent learning machine. His Classifier Systems work attracted considerable interest, but has had difficulties in rewarding long chains of agents to collaborate <ref> [62] </ref>. This suggests that the assignment of credit for agents collaborating in sequence is flawed. x 5.1 proposes several potential flaws. <p> His seminal work has sparked a whole literature, and greatly influenced my own ideas. However, some have viewed the empirical results with Holland-style "classifier systems" as disappointing, c.f. <ref> [62] </ref>. My research indicates that problems may stem from misguided incentives. One critical problem in my view is that agents enter Holland's economy with initial wealth. This creates an unfortunate incentive for agents to fleece new agents, rather than to earn money in the real world.
Reference: [63] <author> Wilson, S. </author> <title> W.,(1995) "Classifier fitness based on accuracy.", Evolutionary Computation, </title> <address> 3(2) pp149-175. </address>
Reference-contexts: The Hayek machine maps state, action pairs to values. This is a particular form of bias which may intutively be particularly effective in environments with combinatorial numbers of states, but relatively few actions <ref> [63] </ref>. By keeping around those agents which are profitable, Hayek dynamically addresses the bias variance tradeoff. Profitable agents, by definition, are well trained and so Hayek can maintain more of them as it has data to justify a more complex representation.
Reference: [64] <author> Winograd, T., </author> <title> (1972) Understanding Natural Language, </title> <publisher> Academic Press, </publisher> <address> NY. </address>
Reference-contexts: Otherwise he sees a new random instance. A picture of a BW problem is shown in figure 2, in x 4.1 below. Blocks World has been a benchmark domain since the '60's <ref> [64] </ref> and remains widely studied today, c.f. [3], [18]. It can be treated as a planning problem, where the solver is told the objective, but must construct a plan for solution.

References-found: 64

