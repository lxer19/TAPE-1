URL: http://www.cs.utexas.edu/users/vlr/papers/tr97-17a.ps
Refering-URL: http://www.cs.utexas.edu/users/vlr/pub.html
Root-URL: 
Title: Experimental Evaluation and Comparison of Algorithms for Incremental Graph Biconnectivity  
Author: Ramgopal Mettu Yuke Zhao Vijaya Ramachandran 
Date: June 9, 1997  
Address: Austin, Austin TX 78712  
Affiliation: Department of Computer Sciences University of Texas at  
Abstract: We describe our implementation of an algorithm to maintain the connected components and the biconnected components of a graph where vertex and edge insertions are allowed. Algorithms for this problem can be applied to task decomposition in engineering design. Connected components are maintained using a disjoint set data structure and the biconnected components are maintained by a block forest. We implemented an incremental biconnectivity algorithm presented in Westbrook and Tarjan [8] which runs in O(nlogn + m) time, where n is the number of vertices and m is the number of operations. However, the algorithm in [8] does not address the issue of deletions in disjoint sets, which seem to be needed in order to implement the algorithm correctly. Hence we develop the concepts of dynamic holes and static holes to support variations of the standard disjoint set structure that allow the deletion of certain elements. We present four different implementations of the incremental biconnectivity algorithm which utilize these variants of the standard disjoint set structure, and analyze their performance. We present extensive timing information for each of these implementations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Alberts, G. Cattaneo, and G. F. </author> <title> Italiano. An Empirical Study of Dynamic Graph Algorithms. </title> <booktitle> Proc. ACM-SIAM SODA (1996): </booktitle> <pages> 192-201. </pages>
Reference-contexts: Since new_vertex operation is only invoked during the initialization, this explanation shows why the initialization time was improved much more than the update time in Implementation IV. We also made a comparison between our implementations and those of Alberts et al. <ref> [1] </ref>, the only other experimental study of dynamic graph algorithms that we knew of (see Table 5).
Reference: [2] <author> J. Dimarco. </author> <title> SPEC list. </title> <address> http://hpwww.epfl.ch/bench/SPEC.html </address>
Reference-contexts: Hence it is not surprising that our algorithm runs much faster than the ones tested by Alberts et al. 30 vertices edges #updt Alberts Imp. IV 500 250 500 0.276* 0.005125 Table 5. Common data points between Alberts et. al and Implementation IV (* normalized time <ref> [2] </ref>) Plots of Test Results The plots on the following pages were made from the test data given in Tables 1-4; all graphs have n vertices.
Reference: [3] <author> M. Korupolu, R. Mettu, V. Ramachandran, and Y. Zhao. </author> <title> Experimental Evaluation of Algorithms for Incremental Graph Connectivity and Biconnectivity. </title> <booktitle> Presented at the Fifth DIMACS Implementation Challenge, </booktitle> <year> 1996. </year>
Reference-contexts: In each of these sections, we analyze the running time for the respective implementations. Section 7 concludes the discussion of biconnectivity with an experimental evaluation and analysis of all four of the implementations. The first of our four implementations is described in <ref> [3] </ref>, and hence Section 3 is very brief. 3. <p> The details of this implementation are discussed in <ref> [3] </ref>. A minor difference in the current implementation with the one described in [3] is that the node_ptr field in the elements of the disjoint set structure is removed. <p> The details of this implementation are discussed in <ref> [3] </ref>. A minor difference in the current implementation with the one described in [3] is that the node_ptr field in the elements of the disjoint set structure is removed. Children sets of nodes in a block tree are maintained using the disjoint set data structure, so that merging the children of two nodes can be done in one pointer step. <p> This means the running time of k find and merge operations will be O (k a (k, 2n-1)), and the amortized time per operation will be O ( a (k, 2n-1)). The proof given below is similar to the one for implementation I <ref> [3] </ref>. THEOREM 1. The data structure above can maintain the graph connectivity and biconnectivity incrementally in O (nlogn + m) time and O (n) space. PROOF. Westbrook and Tarjan [8] show that the total number of pointer steps taken by block_evert and block_condense is O (nlogn).
Reference: [4] <author> Quantify 2.1. </author> <note> Version 2.1, </note> <institution> Pure Corporation, </institution> <year> 1996. </year>
Reference-contexts: We also noticed that in Implementation IV, the initialization time improved much more significantly than the update time. With profiling information obtained from the software Program Quantify 2.1 <ref> [4] </ref>, we observed that this discrepancy is explained by the differences in the cost of new_vertex operations across implementations. The use of the standard disjoint set structure in Implementation IV meant that within each new_vertex call, a single memory allocation is made for the vertex node.
Reference: [5] <author> J. H. Spencer. </author> <title> Ten Lectures on the Probabilistic Method. </title> <publisher> Capital City Press, </publisher> <year> 1994, </year> <note> 2nd edition. </note>
Reference-contexts: The largest sequence size was chosen as 2 ((nlnn)/2 - n) since a random graph is very likely to become connected (and in fact, contain a Hamiltonian cycle, - i.e. become biconnected) when the number of its edges reaches nlnn/2+o (nlnn) <ref> [5] </ref>, after which every operation will be within one block. At this stage the performance of the algorithm speeds up substantially from q (logn) amortized time per step to q ( a (m, n)) amortized time.
Reference: [6] <author> R. E. Tarjan. </author> <title> Efficiency of a Good But Not Linear Set Union Algorithm. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 22 (1975), </volume> <pages> 215-225. </pages>
Reference-contexts: We first present the standard disjoint set structure which supports find and merge operations <ref> [6] </ref>. Then we present a variation of the disjoint set data structure that allows selective deletion of elements. 2.1.1 Standard Disjoint Set Structure A disjoint set structure is a group of x objects such that each of them is a member of exactly one set at any given time. <p> The size of the combined tree is obj1.size+obj2.size. Return the combined set/tree. Although the work done by find to relink elements to point to the root seems excessive, it has been proven that the work done reduces the cost of future find operations <ref> [6] </ref>. In addition, the use of size to merge trees bounds the height of the tree to log x, where x is the number of elements in the set. <p> Thus, the path compression performed by the find operation and the use of size for merging two disjoint set trees allows a running time of O (k a (k, x)) as described in <ref> [6] </ref>. 2.1.2 Dynamic holes in the Disjoint Set Data Structure In order to manipulate the children sets of nodes in our block forest, we need to both merge two sets together, as well as delete certain elements in a given set efficiently.
Reference: [7] <author> R. E. Tarjan and J. van Leeuwen. </author> <title> Worst-Case Analysis of Set Union Algorithms. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 31 (1984), </volume> <pages> 245-281. </pages>
Reference-contexts: It is interesting to note that the use of either size or rank along with path compression yields an optimal running time of O (k a (k, n)) for k find and merge operations on sets with a total of n elements <ref> [7] </ref>. We show in Lemma 2 that size must be used for block tree eversion.
Reference: [8] <author> J. Westbrook and R. E. Tarjan. </author> <title> Maintaining Bridge-Connected and Biconnected Components OnLine. </title> <booktitle> Algorithmica (1992) 7: </booktitle> <pages> 433-464 </pages>
Reference-contexts: These vertices lie in more than one biconnected components and are called cut-vertices. Incremental graph algorithms that maintain connectivity and biconnectivity can be applied to task decomposition in engineering design. The need for maintaining biconnectivity incrementally also comes up in problems relating to networks, CAD/CAM, and distributed computing <ref> [8] </ref>. In this paper, we describe an incremental biconnectivity implementation design that uses an algorithm presented in Westbrook and Tarjan [8] which runs in O (nlogn + m) time, where n is the number of vertices and m is the number of operations. <p> The need for maintaining biconnectivity incrementally also comes up in problems relating to networks, CAD/CAM, and distributed computing <ref> [8] </ref>. In this paper, we describe an incremental biconnectivity implementation design that uses an algorithm presented in Westbrook and Tarjan [8] which runs in O (nlogn + m) time, where n is the number of vertices and m is the number of operations. In order to implement the algorithm, we found the need to delete certain elements from disjoint sets. This issue is not addressed in [8], however. <p> in Westbrook and Tarjan <ref> [8] </ref> which runs in O (nlogn + m) time, where n is the number of vertices and m is the number of operations. In order to implement the algorithm, we found the need to delete certain elements from disjoint sets. This issue is not addressed in [8], however. Hence we developed the concepts of dynamic holes and static holes to support variations of the standard disjoint set structure that allow the deletion of certain elements. <p> These variants of the standard disjoint set structure are used to maintain the connected components and enables efficient block tree operations in the block forest. Westbrook and Tarjan <ref> [8] </ref> also describe another algorithm that uses dynamic trees to maintain the block forest, which runs in O (m a (m, n)) time. For the data sets we consider, the first algorithm is likely to be faster in practice due to a smaller constant factor in the running time. <p> C 5 6 B block node vertex node (ii) block tree T of G 2.2 Block Tree Data Structure In order to maintain the biconnected components of a graph incrementally, we make use of a tree structure of the blocks and vertices of a connected graph called the block tree <ref> [8] </ref>. The collection of block trees given by the components of a graph G = (V, E) is called the block forest. The block tree has two types of nodes: vertex (square) nodes, which represent the vertices of G; and block (round) nodes, which represent the blocks. <p> By defining the size of a block tree to be the same as the size of its corresponding connected component, Westbrook and Tarjan <ref> [8] </ref> show that everting the smaller 12 block tree ensures O (nlogn) performance. This and the lemma below justify the use of size instead of rank in our modified disjoint set data structure. LEMMA 2. The connected component with smaller rank does not necessarily have smaller size. PROOF. <p> a vertex add the children set of b2 to the children set of b1; remove b2 from the children set of its parent, lcav; free (b2); end. block_condense Subroutine findlcav takes O (P) pointer steps, where P is the length of the path between the two given vertices (see findpath, <ref> [8] </ref>), and condense_path is a sequence of pointer operations along the path, hence it runs in O (P ) pointer steps as well. <p> The proof given below is similar to the one for implementation I [3]. THEOREM 1. The data structure above can maintain the graph connectivity and biconnectivity incrementally in O (nlogn + m) time and O (n) space. PROOF. Westbrook and Tarjan <ref> [8] </ref> show that the total number of pointer steps taken by block_evert and block_condense is O (nlogn). For a sequence of m insert_edge, find_block, and new_vertex operations where m is in W (n), it is shown in [8] that the total number of pointer steps required is O (m + nlogn). <p> PROOF. Westbrook and Tarjan <ref> [8] </ref> show that the total number of pointer steps taken by block_evert and block_condense is O (nlogn). For a sequence of m insert_edge, find_block, and new_vertex operations where m is in W (n), it is shown in [8] that the total number of pointer steps required is O (m + nlogn). However, this analysis does not take into account the dynamic holes that need to be created in the block tree data structure by block_evert . By the analysis given in [8], our data structures support a sequence <p> W (n), it is shown in <ref> [8] </ref> that the total number of pointer steps required is O (m + nlogn). However, this analysis does not take into account the dynamic holes that need to be created in the block tree data structure by block_evert . By the analysis given in [8], our data structures support a sequence of m operations in O (m + n'logn') time, where n' represents the total number of elements in the disjoint sets of the block tree including dynamic holes. From Lemma 3 it follows that n' 2n-1, hence n' is O (n). <p> The algorithm allows insertions of edges and vertices and answers biconnectivity queries, i.e., "given two vertices of a graph, are they in the same biconnected component ?" In the course of implementing the algorithm given by <ref> [8] </ref>, we discovered an issue that was not addressed in [8]: the need for deletions in disjoint sets to preserve the efficiency of the algorithm. We modified the standard disjoint set data structure and developed two new concepts in dealing with deletions: dynamic holes and static holes. <p> The algorithm allows insertions of edges and vertices and answers biconnectivity queries, i.e., "given two vertices of a graph, are they in the same biconnected component ?" In the course of implementing the algorithm given by <ref> [8] </ref>, we discovered an issue that was not addressed in [8]: the need for deletions in disjoint sets to preserve the efficiency of the algorithm. We modified the standard disjoint set data structure and developed two new concepts in dealing with deletions: dynamic holes and static holes.
References-found: 8

