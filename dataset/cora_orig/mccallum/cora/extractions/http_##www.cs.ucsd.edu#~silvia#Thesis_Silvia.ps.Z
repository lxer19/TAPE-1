URL: http://www.cs.ucsd.edu/~silvia/Thesis_Silvia.ps.Z
Refering-URL: http://www.cs.ucsd.edu/~silvia/
Root-URL: http://www.cs.ucsd.edu
Title: Modeling the Effects of Contention on Application Performance in MultiUser Environments  
Author: Silvia Maria Barbosa Figueira 
Degree: A dissertation submitted in partial satisfaction of the requirements for the degree Doctor of Philosophy in Computer Science by  Committee in charge: Professor Francine Berman, Chair Professor Larry Carter Professor Sidney Karin Professor Keith Marzullo Professor Laurence Milstein Professor Ramesh Rao  
Date: 1997  
Affiliation: UNIVERSITY OF CALIFORNIA, SAN DIEGO  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> C. Anglano, J. Schopf, R. Wolski, and F. Berman, Zoom: </author> <title> A Hierarchical Representation for Heterogeneous Applications, </title> <type> UCSD CS Technical Report #CS95-451. </type>
Reference-contexts: Since the number of tasks for coarse-grained heterogeneous applications in practice is typically , and the number of machines used is typically <ref> [1, 28, 37, 44] </ref>, both C and L are small. Note that we cannot execute the algorithm without a value for all paths.
Reference: [2] <author> R. H. Arpaci, A. C. Dusseau, A. M. Vahdat, L. T. Liu, T. E. Anderson, and D. A. Patterson, </author> <title> The Interaction of Parallel and Sequential Workloads on a Network of Workstations, </title> <booktitle> in Proceedings of SIG-METRICS95/PERFORMANCE95 Joint International Conference on Measurement and Modeling of Computer Systems May 1995. </booktitle>
Reference-contexts: In particular, it does not consider differences in application behavior or idle cycles in applications caused by imbalances in the system. Additional researchers have studied the effects of contention in networks of workstations. In <ref> [2] </ref>, Arpaci et al. examine the plausibility of using 11 a network of workstations for a mixture of parallel and sequential jobs.
Reference: [3] <author> M. Atallah, C. Black, D. Marinescu, H. Siegel, and T. Casavant, </author> <title> Models and Algorithms for Coscheduling Compute-Intensive Tasks on a Network of Workstations, </title> <journal> Journal of Parallel and Distributed Computing , vol. </journal> <volume> 16, </volume> <pages> pp. 319-327, </pages> <year> 1992. </year>
Reference-contexts: They define a selection algorithm that considers contention. A load average factor accounts for how much slower the machine was last known to be executing due to other jobs. This load average is updated each time a new job starts. Atallah et al. <ref> [3] </ref> have developed a model for cosched-uling compute-intensive tasks on a network of workstations. Their model takes into account the ratio of cycles that each workstation commits to local tasks to the number of cycles available for the compute-intensive guest tasks.
Reference: [4] <author> A. Beguelin, J. Dongarra, G. Geist, R. Manchek, and V. Sunderam, </author> <title> Graphical Development Tools for Network-Based Concurrent Supercomputing, </title> <booktitle> in Proceedings of Supercomputing 91 </booktitle>
Reference-contexts: Machine workload has been used to parameterize the allocation of tasks to workstations in a network, however, many allocation strategies do not consider load characteristics in the measurement of workload (e.g., <ref> [4, 10, 14, 27] </ref>). Load characteristics have been included in performance prediction models for networks of workstations (e.g., [30, 55]), however such models assume that each workstation is shared by at most one compute-intensive task and one or more local tasks that alternate idle with busy cycles. <p> The following sections discuss results related to contention for different platforms. 1.5.1 Contention in Networks of Workstations Workload on the machines is sometimes used to parameterize the allocation decision for schedulers targeted to networks of workstations. HeNCE <ref> [4] </ref>, a graphical tool that assists programmers in executing applications on heterogeneous systems using PVM [46], keeps track of the aggregate load allocated to each machine and attempts to balance the load when scheduling new tasks. <p> Most mapping strategies in the literature assume a distributed X m X m ded, sd = ded m nfi X m ded, ded model in which execution sites are timeshared (e.g. <ref> [4, 14, 27, 33, 47] </ref>). In practice, an execution site in a heterogeneous system may be an MPP (such as the Intel Paragon or the Cray T3D) or a dedicated cluster (such as the IBM SP-2 or the DEC Alpha Farm).
Reference: [5] <author> F. Berman and R. Wolski, </author> <title> Scheduling from the Perspective of the Application, </title> <booktitle> in Proceedings of the Fifth IEEE International Symposium on High Performance Distributed Computing , August 1996. </booktitle>
Reference-contexts: Different groups have proposed systems that focus on scheduling of parallel applications on distributed systems in different ways (e.g., AppLeS 9 <ref> [5, 6] </ref>, Legion [24], Globus [23], Prophet [51], MARS [22], Condor [10], SmartNet [27], and Nile [34, 35]). In general, current scheduling systems assign tasks (or entire applications) to machines according to computation time and communication costs using several different performance measures (e.g., [25, 31]), but few consider contention effects. <p> Although this may be a common scenario for high-performance heterogeneous applications executing on distributed systems, it is not a general one. In this section we discuss how the slowdown factors developed in chapters 3 and 4 can be integrated into AppLeS <ref> [5, 6] </ref> and used in metacomputing environments. The goal of the AppLeS project is to develop software to assist and enhance the scheduling activities of the user on a distributed metacomput-ing system. AppLeS (Application Level Scheduler) scheduling agents [5, 6] are being developed by the Heterogeneous Computing Group at UCSD to <p> factors developed in chapters 3 and 4 can be integrated into AppLeS <ref> [5, 6] </ref> and used in metacomputing environments. The goal of the AppLeS project is to develop software to assist and enhance the scheduling activities of the user on a distributed metacomput-ing system. AppLeS (Application Level Scheduler) scheduling agents [5, 6] are being developed by the Heterogeneous Computing Group at UCSD to perform the scheduling activity for the user. AppLeS agents consist of four subsystems and a single active agent called the Coordinator.
Reference: [6] <author> F. Berman, R. Wolski, S. Figueira, J. Schopf, and G. Shao, </author> <title> Application-Level Scheduling on Distributed Heterogeneous Networks, </title> <booktitle> in Proceedings of Supercomputing96 , November 1996. </booktitle>
Reference-contexts: Different groups have proposed systems that focus on scheduling of parallel applications on distributed systems in different ways (e.g., AppLeS 9 <ref> [5, 6] </ref>, Legion [24], Globus [23], Prophet [51], MARS [22], Condor [10], SmartNet [27], and Nile [34, 35]). In general, current scheduling systems assign tasks (or entire applications) to machines according to computation time and communication costs using several different performance measures (e.g., [25, 31]), but few consider contention effects. <p> At runtime, the value for k the average bandwidth available on the links used by competing applications can be predicted by statistic tools (e.g. the Network Weather Service <ref> [6, 54] </ref>), and used to determine . dela y comm i k, dela y comm i k, dela y comm i k, dela y comm i k, dela y comm i k, i = 2. In low-bandwidth systems, may be approximated by just one curve or by just one value. <p> The benchmark sends 1024 messages with 1024 words each from one node to another and waits for the answer. The value for can be obtained at runtime with statistical methods employed by performance prediction tools, such as the Network Weather Service <ref> [6, 54] </ref>. <p> In fact, the error correlates inversely with the granularity of the applications executing on the nodes. In the cases where cannot be calculated based on information about the applications executing, it can be obtained by tools, such as the Network Weather Service <ref> [6, 54] </ref>, which predicts the load on networked resources using statistical models, and provides CPU and/or communica 0 400 800 1200 3000 3500 4000 4500 5000 no contention modeled measured t i m ( s e n s problem size (N) 105 tion link capacities at runtime. <p> For example, if there are three CPU-bound applications executing on a node and spliting its CPU cycles evenly, each appli cations CPU-usage would be 33%. Statistical tools such as the Network Weather Service <ref> [6] </ref> are able to provide estimates of CPU-usage based on this information. <p> Although this may be a common scenario for high-performance heterogeneous applications executing on distributed systems, it is not a general one. In this section we discuss how the slowdown factors developed in chapters 3 and 4 can be integrated into AppLeS <ref> [5, 6] </ref> and used in metacomputing environments. The goal of the AppLeS project is to develop software to assist and enhance the scheduling activities of the user on a distributed metacomput-ing system. AppLeS (Application Level Scheduler) scheduling agents [5, 6] are being developed by the Heterogeneous Computing Group at UCSD to <p> factors developed in chapters 3 and 4 can be integrated into AppLeS <ref> [5, 6] </ref> and used in metacomputing environments. The goal of the AppLeS project is to develop software to assist and enhance the scheduling activities of the user on a distributed metacomput-ing system. AppLeS (Application Level Scheduler) scheduling agents [5, 6] are being developed by the Heterogeneous Computing Group at UCSD to perform the scheduling activity for the user. AppLeS agents consist of four subsystems and a single active agent called the Coordinator. <p> This can be done when the time to execute the targeted application in dedicated mode is known or can be predicted, and information about the load is available. The contention models can also be integrated into the Network Weather Service <ref> [6, 54] </ref> to leverage its predictions when information about applications is available. The Network Weather Service relies basically on information obtained by probes that measure system performance periodically. It uses this information to provide statistical predictions of system behavior.
Reference: [7] <author> BLAS, </author> <note> http://www.netlib.org/blas. </note>
Reference-contexts: A parallel implementation was developed for clusters using C++ and Fortran 77. It was implemented on top of KeLP [19] and MPI [40]. A second parallel implementation executes on the DEC Alpha-Farm at SDSC and uses BLAS <ref> [7] </ref> for the local matrix multiplication on each node. For this benchmark, data is divided evenly among the nodes of the cluster, each of which is responsible for an equal amount of work. Gaussian Elimination The Gaussian Elimination benchmark [20] was developed for the Sun/CM2 19 platform using CM-Fortran.
Reference: [8] <author> S. H. Bokhari, </author> <title> Communication Overhead on the Intel Paragon, IBM SP2 & Meiko CS-2, </title> <type> NASA Contractor Report 198211, ICASE Interim Report No. 28, </type> <month> September </month> <year> 1995. </year> <month> 194 </month>
Reference-contexts: Their results indicate that contention for the interconnection network is only a problem when many large messages 12 compete for the same link at once. Bokhari has shown, in <ref> [8] </ref>, that specific communication patterns presented by certain applications generate contention for interconnection links, causing degradation in the interprocessor communication and, consequently, a slowdown in the application execution. Tron and Plateau [48] have developed a model for network contention in multiprocessors.
Reference: [9] <author> S. H. Bokhari, </author> <title> On the Mapping Problem, </title> <journal> IEEE Transactions on Computers , vol. </journal> <volume> C-30, </volume> <pages> pp. 207-214, </pages> <month> March </month> <year> 1981. </year>
Reference-contexts: These applications are formed by a small number of coarse-grain, serial or data-parallel tasks, which need to be assigned to machines in a performance-efficient way. Many approaches have been proposed to the mapping of tasks to machines in a distributed system, which is known to be an NP-hard problem <ref> [9, 21] </ref>. These approaches are classified by Casavant and Kuhl in [12]. Our strategy reects the fact that generally high-performance applications are formed by few tasks and execute on heterogeneous systems formed by few machines.
Reference: [10] <author> A. Bricker, M. Litzkow, and M. Livny, </author> <title> Condor Technical Summary, </title> <type> Technical Report #1069, </type> <institution> University of Wisconsin, Computer Science Department, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: Machine workload has been used to parameterize the allocation of tasks to workstations in a network, however, many allocation strategies do not consider load characteristics in the measurement of workload (e.g., <ref> [4, 10, 14, 27] </ref>). Load characteristics have been included in performance prediction models for networks of workstations (e.g., [30, 55]), however such models assume that each workstation is shared by at most one compute-intensive task and one or more local tasks that alternate idle with busy cycles. <p> Different groups have proposed systems that focus on scheduling of parallel applications on distributed systems in different ways (e.g., AppLeS 9 [5, 6], Legion [24], Globus [23], Prophet [51], MARS [22], Condor <ref> [10] </ref>, SmartNet [27], and Nile [34, 35]). In general, current scheduling systems assign tasks (or entire applications) to machines according to computation time and communication costs using several different performance measures (e.g., [25, 31]), but few consider contention effects. <p> HeNCE [4], a graphical tool that assists programmers in executing applications on heterogeneous systems using PVM [46], keeps track of the aggregate load allocated to each machine and attempts to balance the load when scheduling new tasks. Condor <ref> [10] </ref>, a resource management system for networks of workstations, does not consider the load on the machines, but tracks the number of guest jobs each workstation is willing to host and how many they are running at a particular time. <p> Virtual clusters can take advantage of fastspeed network links and idle workstations to form an ad hoc virtual parallel computer. In fact, they have been used largely in the execution of serial and data-parallel tasks <ref> [10, 42, 46] </ref>. In this dissertation, we develop a contention model for virtual clusters formed by nodes containing one processor each.
Reference: [11] <author> W. L. Briggs, </author> <title> A Multigrid Tutorial, </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia, Pennsylvania, </address> <year> 1987. </year>
Reference-contexts: The following subsections summarize these benchmarks. 18 SOR The SOR algorithm solves Laplaces equation on a 2-dimensional matrix using a red-black successive over-relaxation strategy <ref> [11] </ref>. It employs a strip decomposition and executes for a fixed number of steps, each of which consists of a 5-point stencil operation on each element of the matrix. <p> The 2-dimensional matrix is divided evenly among the nodes of the cluster, each of which is responsible for an equal amount of work. Jacobi2D The Jacobi2D benchmark solves Laplaces equation on a 2-dimensional matrix using Jacobi relaxation <ref> [11] </ref>. It employs a block decomposition and executes for a fixed number of steps, each of which consists of a 5-point stencil operation on each element of the matrix. The parallel algorithm was developed for clusters using C++ and Fortran 77. <p> It was implemented on top of KeLP [19] and MPI [40]. The 2-dimensional matrix is divided evenly among the nodes of the cluster, each of which is responsible for an equal amount of work. Jacobi3D The Jacobi3D benchmark solves Laplaces equation on a 3-dimensional matrix using Jacobi relaxation <ref> [11] </ref>. It employs a block decomposition and executes for a fixed number of steps, each of which consists of a 7-point stencil operation on each element of the matrix. The parallel algorithm was developed for clusters using C++ and Fortran 77. <p> It was implemented on top of KeLP [19] and MPI [40]. The 3-dimensional matrix is divided evenly among the nodes of the cluster, each of which is responsible for an equal amount of work. Multigrid The Multigrid algorithm implements a Multigrid Poisson solver on an 20 irregular grid <ref> [11] </ref>. It employs a block decomposition of the lowest level matrix, and employs the same decomposition at upper levels, i.e., at each level, a portion of the matrix is hosted by the same node that hosts its corresponding portion at the lowest level.
Reference: [12] <author> T. L. Casavant and J. G. Kuhl, </author> <title> A Taxonomy of Scheduling in Gener-alPurpose Distributed Computing System, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 14, no. 2, </volume> <pages> pp. 141-154, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Many approaches have been proposed to the mapping of tasks to machines in a distributed system, which is known to be an NP-hard problem [9, 21]. These approaches are classified by Casavant and Kuhl in <ref> [12] </ref>. Our strategy reects the fact that generally high-performance applications are formed by few tasks and execute on heterogeneous systems formed by few machines.
Reference: [13] <author> D. M. Deaven, N. Tit, J. R. Morris, and K. M. Ho, </author> <title> Structural Optimization of Lennard-Jones Clusters by a Genetic Algorithm, </title> <journal> Chemical Physical Letters 256, </journal> <pages> pp. 195, </pages> <year> 1996. </year>
Reference-contexts: Genetic algorithms form a class of applications originally developed by the artificial intelligence community as an optimization technique for NP-complete and NP-hard problems. As such, they are now being used by several groups of computational scientists <ref> [13, 43, 45] </ref> to address problems such as protein modeling. This application is structured in a master/slave paradigm.
Reference: [14] <author> H. Dietz, W. Cohen, and B. Grant, </author> <title> Would you run it here...or there? (AHS: Automatic Heterogeneous Supercomputing), </title> <booktitle> in Proceedings of the International Conference on Parallel Processing , vol. II, </booktitle> <pages> pp. 217-221, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: Machine workload has been used to parameterize the allocation of tasks to workstations in a network, however, many allocation strategies do not consider load characteristics in the measurement of workload (e.g., <ref> [4, 10, 14, 27] </ref>). Load characteristics have been included in performance prediction models for networks of workstations (e.g., [30, 55]), however such models assume that each workstation is shared by at most one compute-intensive task and one or more local tasks that alternate idle with busy cycles. <p> Condor [10], a resource management system for networks of workstations, does not consider the load on the machines, but tracks the number of guest jobs each workstation is willing to host and how many they are running at a particular time. In <ref> [14] </ref>, Dietz et al. discuss AHS (Automatic Heterogeneous Super 10 computing), a system to control the execution of applications on a heteroge neous network. They define a selection algorithm that considers contention. <p> Most mapping strategies in the literature assume a distributed X m X m ded, sd = ded m nfi X m ded, ded model in which execution sites are timeshared (e.g. <ref> [4, 14, 27, 33, 47] </ref>). In practice, an execution site in a heterogeneous system may be an MPP (such as the Intel Paragon or the Cray T3D) or a dedicated cluster (such as the IBM SP-2 or the DEC Alpha Farm).
Reference: [15] <author> M. A. Driscoll and W. R. Daasch, </author> <title> Accurate Predictions of Parallel Program Execution Time, </title> <journal> Journal of Parallel and Distributed Computing , vol. </journal> <volume> 25, </volume> <pages> pp. 16-30, </pages> <year> 1995. </year>
Reference-contexts: These can be provided by the user or obtained from a model such as Driscoll and Daaschs <ref> [15] </ref>, who have developed a strategy to estimate these amounts for MPPs. Our split-partition algorithm utilizes a function time (t, n t ) that provides the time to execute task t with n t nodes.
Reference: [16] <author> X. Du and X. Zhang, </author> <title> Coordinating Parallel Processes on Networks of Workstations, </title> <type> Technical Report, </type> <institution> High Performance Computing and Software Lab, University of Texas at San Antonio, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: They have measured contention effects in order to show the necessity of mechanisms like coscheduling and migration of parallel jobs to idle workstations, but they do not predict contention effects. In fact, both <ref> [16] </ref> and [17] propose coscheduling strategies (or an approximation) for parallel applications executing in network of workstations. <p> It shows a 4-node virtual cluster whose well-balanced load is described in Table 4-22. We define a nodes weight as the ratio of the speed of the slowest node to its own speed, as described by <ref> [16] </ref>. As defined earlier, slowdown is the local slowdown imposed on each node. <p> Weights depend not only on the speed of the machines CPU, but also on application characteristics such as language and compiler used, memory requirements, and memory access pattern. For this reason, weights are application-dependent and vary not only with the type of application but also, as discussed in <ref> [16] </ref>, with application sizes. In fact, it is important to use an appropriate benchmark, tailored to the problem size, to calculate the weights. The following section provides models to calculate the aggregate slowdown factor for data-parallel tasks executing on a virtual cluster.
Reference: [17] <author> A. C. Dusseau, R. H. Arpaci, and D. E. Culler, </author> <title> Effective Distributed Scheduling of Parallel Workloads, </title> <booktitle> in Proceedings of ACM SIGMET-RICS96 , pp. </booktitle> <pages> 25-36, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: They have measured contention effects in order to show the necessity of mechanisms like coscheduling and migration of parallel jobs to idle workstations, but they do not predict contention effects. In fact, both [16] and <ref> [17] </ref> propose coscheduling strategies (or an approximation) for parallel applications executing in network of workstations. In [26], Harchol-Balter and Downey show that preemptive migration , in which running processes may be suspended, moved to a remote host, and restarted, can minimize the effect imposed by contention on the hosts. <p> In practice, most operating systems executing on workstations employ a priority-based scheduling strategy that reduces to a round-robin policy when the executing applications are CPU-bound <ref> [17] </ref>. Since we assume the applications to be coarse-grain, considering a round-robin local scheduler for the timeshared systems is a reasonable assumption.
Reference: [18] <author> S. M. Figueira and F. Berman, </author> <title> Modeling the Effects of Contention on the Performance of Heterogeneous Applications, </title> <booktitle> in Proceedings of the Fifth IEEE International Symposium on High Performance Distributed Computing , August 1996. </booktitle>
Reference-contexts: This chapter discusses issues related to contention modeling. 2.1 About Contention Effects contention model synthesizes system characteristics and load behavior into a slowdown factor that can be used to adjust computation and communication costs to account for contention for resources in multiuser systems <ref> [18] </ref>. The slowdown factor is a componentspecific measure, i.e., there is a factor for computation and communication for each component of the system (machines and network links). This factor reects the current load on that component.
Reference: [19] <author> S. J. Fink, S. B. Baden, and S. R. Kohn, </author> <title> Flexible Communication Mechanisms for Dynamic Structured Applications, </title> <booktitle> in Proceedings of the Third International Workshop on Parallel Algorithms for Irregularly Structured Problems , Santa Barbara, </booktitle> <address> CA, </address> <month> August </month> <year> 1996. </year> <month> 195 </month>
Reference-contexts: Matrix Multiply This benchmark multiplies two matrices using a 1-dimensional blocked layout on a ring with broadcast [36]. A parallel implementation was developed for clusters using C++ and Fortran 77. It was implemented on top of KeLP <ref> [19] </ref> and MPI [40]. A second parallel implementation executes on the DEC Alpha-Farm at SDSC and uses BLAS [7] for the local matrix multiplication on each node. <p> It employs a block decomposition and executes for a fixed number of steps, each of which consists of a 5-point stencil operation on each element of the matrix. The parallel algorithm was developed for clusters using C++ and Fortran 77. It was implemented on top of KeLP <ref> [19] </ref> and MPI [40]. The 2-dimensional matrix is divided evenly among the nodes of the cluster, each of which is responsible for an equal amount of work. Jacobi3D The Jacobi3D benchmark solves Laplaces equation on a 3-dimensional matrix using Jacobi relaxation [11]. <p> It employs a block decomposition and executes for a fixed number of steps, each of which consists of a 7-point stencil operation on each element of the matrix. The parallel algorithm was developed for clusters using C++ and Fortran 77. It was implemented on top of KeLP <ref> [19] </ref> and MPI [40]. The 3-dimensional matrix is divided evenly among the nodes of the cluster, each of which is responsible for an equal amount of work. Multigrid The Multigrid algorithm implements a Multigrid Poisson solver on an 20 irregular grid [11]. <p> The parallel benchmark was developed using C++ and Fortran 77. It was implemented on top of KeLP <ref> [19] </ref> and MPI [40]. We implemented two versions of this benchmark: one implementation employs a blocked, even data distribution, i.e., the lowest level matrix is divided evenly among the nodes independently of the load or the node computational capacity.
Reference: [20] <author> I. Foster, </author> <title> Designing and Building Parallel Programs - Concepts and Tools for Parallel Software Engineering, </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1995. </year>
Reference-contexts: For this benchmark, data is divided evenly among the nodes of the cluster, each of which is responsible for an equal amount of work. Gaussian Elimination The Gaussian Elimination benchmark <ref> [20] </ref> was developed for the Sun/CM2 19 platform using CM-Fortran. The 2-dimensional matrix is divided evenly among the nodes of the cluster, each of which is responsible for an equal amount of work. Jacobi2D The Jacobi2D benchmark solves Laplaces equation on a 2-dimensional matrix using Jacobi relaxation [11].
Reference: [21] <author> M. R. Garey and D. S. Johnson, </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness, </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Fran-cisco, </address> <year> 1979. </year>
Reference-contexts: These applications are formed by a small number of coarse-grain, serial or data-parallel tasks, which need to be assigned to machines in a performance-efficient way. Many approaches have been proposed to the mapping of tasks to machines in a distributed system, which is known to be an NP-hard problem <ref> [9, 21] </ref>. These approaches are classified by Casavant and Kuhl in [12]. Our strategy reects the fact that generally high-performance applications are formed by few tasks and execute on heterogeneous systems formed by few machines.
Reference: [22] <author> J. Gehring and A. Reinefeld, </author> <title> MARS - A Framework for Minimizing the Job Execution Time in a Metacomputing Environment, </title> <booktitle> in Proceedings of Future General Computer Systems </booktitle>
Reference-contexts: Different groups have proposed systems that focus on scheduling of parallel applications on distributed systems in different ways (e.g., AppLeS 9 [5, 6], Legion [24], Globus [23], Prophet [51], MARS <ref> [22] </ref>, Condor [10], SmartNet [27], and Nile [34, 35]). In general, current scheduling systems assign tasks (or entire applications) to machines according to computation time and communication costs using several different performance measures (e.g., [25, 31]), but few consider contention effects.
Reference: [23] <author> GLOBUS, </author> <note> http://www.mcs.anl.gov/globus. </note>
Reference-contexts: Different groups have proposed systems that focus on scheduling of parallel applications on distributed systems in different ways (e.g., AppLeS 9 [5, 6], Legion [24], Globus <ref> [23] </ref>, Prophet [51], MARS [22], Condor [10], SmartNet [27], and Nile [34, 35]). In general, current scheduling systems assign tasks (or entire applications) to machines according to computation time and communication costs using several different performance measures (e.g., [25, 31]), but few consider contention effects.
Reference: [24] <author> A. Grimshaw, W. Wulf, J. French, A. Weaver, and P. Reynolds Jr., Legion: </author> <title> The Next Logical Step Toward a Nationwide Virtual Computer, </title> <institution> University of Virginia, </institution> <type> CS Technical Report CS-94-21, </type> <month> June, </month> <year> 1994. </year>
Reference-contexts: Different groups have proposed systems that focus on scheduling of parallel applications on distributed systems in different ways (e.g., AppLeS 9 [5, 6], Legion <ref> [24] </ref>, Globus [23], Prophet [51], MARS [22], Condor [10], SmartNet [27], and Nile [34, 35]). In general, current scheduling systems assign tasks (or entire applications) to machines according to computation time and communication costs using several different performance measures (e.g., [25, 31]), but few consider contention effects.
Reference: [25] <author> J. L. Gustafson, </author> <title> The Consequences of Fixed Time Performance Measurement, </title> <booktitle> in Proceedings of the Twenty-Fifth Hawaii International Conference on System Sciences , Vol. III, </booktitle> <pages> pp. 113-124, </pages> <month> January </month> <year> 1992 </year>
Reference-contexts: In general, current scheduling systems assign tasks (or entire applications) to machines according to computation time and communication costs using several different performance measures (e.g., <ref> [25, 31] </ref>), but few consider contention effects. Among metacom-puting application developers, Mechoso et al. [37] have identified contention effects, which they express as an expansion factor on their experiments with NGCM (Network General Circulation Model).
Reference: [26] <author> M. Harchol-Balter and A. B. Downey, </author> <title> Exploiting Process Lifetime Distributions for Dynamic Load Balance, </title> <booktitle> in Proceedings of ACM SIGMETRICS96 , pp. </booktitle> <pages> 13-24, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: In fact, both [16] and [17] propose coscheduling strategies (or an approximation) for parallel applications executing in network of workstations. In <ref> [26] </ref>, Harchol-Balter and Downey show that preemptive migration , in which running processes may be suspended, moved to a remote host, and restarted, can minimize the effect imposed by contention on the hosts. Leutenegger and Sun [30] have created a model to show the viability of non-dedicated homogeneous distributed systems.
Reference: [27] <author> D. Hensgen, T. Kidd, and E. Keith, </author> <title> Adding Rescheduling to and Integrating Condor with SmartNet, </title> <booktitle> in Proceedings of the Heterogeneous Computing Workshop , pp. </booktitle> <pages> 4-11, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: Machine workload has been used to parameterize the allocation of tasks to workstations in a network, however, many allocation strategies do not consider load characteristics in the measurement of workload (e.g., <ref> [4, 10, 14, 27] </ref>). Load characteristics have been included in performance prediction models for networks of workstations (e.g., [30, 55]), however such models assume that each workstation is shared by at most one compute-intensive task and one or more local tasks that alternate idle with busy cycles. <p> Different groups have proposed systems that focus on scheduling of parallel applications on distributed systems in different ways (e.g., AppLeS 9 [5, 6], Legion [24], Globus [23], Prophet [51], MARS [22], Condor [10], SmartNet <ref> [27] </ref>, and Nile [34, 35]). In general, current scheduling systems assign tasks (or entire applications) to machines according to computation time and communication costs using several different performance measures (e.g., [25, 31]), but few consider contention effects. <p> Most mapping strategies in the literature assume a distributed X m X m ded, sd = ded m nfi X m ded, ded model in which execution sites are timeshared (e.g. <ref> [4, 14, 27, 33, 47] </ref>). In practice, an execution site in a heterogeneous system may be an MPP (such as the Intel Paragon or the Cray T3D) or a dedicated cluster (such as the IBM SP-2 or the DEC Alpha Farm).
Reference: [28] <author> A. Kuppermann and M. Wu, </author> <title> Quantum Reaction Dynamics on a Gi-gabit/Sec Network, </title> <booktitle> in Proceedings of the Gigabit Testbed Maxijam November 1994. </booktitle>
Reference-contexts: Current experience shows that many high-performance distributed applications are composed of a few coarse-grained tasks and execute on heterogeneous platforms composed of 2 or 3 machines <ref> [28, 38, 44, 49] </ref>. These platforms are formed by smart instruments and machines which can be SIMD MPPs, MIMD MPPs, vector computers, and/or workstations. For many of these applications, both heterogeneity and parallelism in the code are exploited. <p> B 21 24 5 In particular, a model to predict contention effects on application perfor mance should reect both system characteristics and workload behavior. 1.2 Scheduling Parallel Applications on Distributed Systems One would assume that for heterogeneous applications, typically composed of few tasks and targeted to 2 or 3 machines <ref> [28, 38, 44, 49] </ref>, the scheduling problem would be easy in particular, exhaustive search of the best allocation of tasks to resources would solve the problem. In fact, determining the best allocation between tasks and machines depends on performance estimate and is hard for reasons other than scalability. <p> Since the number of tasks for coarse-grained heterogeneous applications in practice is typically , and the number of machines used is typically <ref> [1, 28, 37, 44] </ref>, both C and L are small. Note that we cannot execute the algorithm without a value for all paths.
Reference: [29] <author> Lawler, Lenstra, Kan and Shmoys. </author> <title> The Traveling Salesman Problem, </title> <publisher> John Wiley & Sons, </publisher> <year> 1985. </year>
Reference-contexts: It employs a cyclic, even distribution of data in two dimensions, and it is characterized by the transference of large numbers of very small (40 byte) messages. Genetic Algorithm The Genetic Algorithm performs an optimization for the Traveling Sales 21 man Problem (TSP) <ref> [29, 53] </ref>. Genetic algorithms form a class of applications originally developed by the artificial intelligence community as an optimization technique for NP-complete and NP-hard problems. As such, they are now being used by several groups of computational scientists [13, 43, 45] to address problems such as protein modeling.
Reference: [30] <author> S. Leutenegger and X. Sun, </author> <title> Distributed Computing Feasibility in a Non-Dedicated Homogeneous Distributed System, </title> <type> NASA - ICASE Technical Report 93-65, </type> <month> September </month> <year> 1993. </year>
Reference-contexts: Machine workload has been used to parameterize the allocation of tasks to workstations in a network, however, many allocation strategies do not consider load characteristics in the measurement of workload (e.g., [4, 10, 14, 27]). Load characteristics have been included in performance prediction models for networks of workstations (e.g., <ref> [30, 55] </ref>), however such models assume that each workstation is shared by at most one compute-intensive task and one or more local tasks that alternate idle with busy cycles. We believe that considering the load on the machines in a network of workstations is important, but may not be enough. <p> In [26], Harchol-Balter and Downey show that preemptive migration , in which running processes may be suspended, moved to a remote host, and restarted, can minimize the effect imposed by contention on the hosts. Leutenegger and Sun <ref> [30] </ref> have created a model to show the viability of non-dedicated homogeneous distributed systems.
Reference: [31] <author> D. Lilja, </author> <title> Experiments with a Task Partitioning Model for Heterogeneous Computing, </title> <booktitle> in Proceedings of the Heterogeneous Computing Workshop , pp. </booktitle> <pages> 29-35, </pages> <month> April </month> <year> 1993. </year> <month> 196 </month>
Reference-contexts: In general, current scheduling systems assign tasks (or entire applications) to machines according to computation time and communication costs using several different performance measures (e.g., <ref> [25, 31] </ref>), but few consider contention effects. Among metacom-puting application developers, Mechoso et al. [37] have identified contention effects, which they express as an expansion factor on their experiments with NGCM (Network General Circulation Model). <p> = size i a s un X c m2 Y s u n fi ( ) N i a cm2 size i b cm2 i data sets - = 29 The values for , , , and are system-dependent and can be calculated by benchmarks similar to those described in <ref> [31] </ref>. One benchmark transfers one array with 10 elements from the Sun to the CM2 and then transfers one word from the CM2 to the Sun. If this takes onds, where and then words per second. The value for can be calculated in a similar way.
Reference: [32] <author> W. Liu, V. Lo, K. Windisch, and B. Nitzberg, </author> <title> NonContiguous Processor Allocation Algorithms for Distributed Memory Multicomput-ers, </title> <booktitle> in Proceedings of Supercomputing 94 </booktitle>
Reference-contexts: However, both these works assume that each workstation is shared by at most one compute-intensive task and one or more local tasks that alternate idle with busy cycles. 1.5.2 Contention in MPPs In <ref> [32] </ref>, Liu et al. show that noncontiguous allocation algorithms for distributed memory multicomputers perform better overall than a contiguous allocation algorithm, even when contention effects on interprocessor communication are considered. <p> We wanted to determine the effects of traffic in a link on the time to transfer messages through the same link. We developed a benchmark (similar to the one discussed by Liu et al. in <ref> [32] </ref>) to show these effects. The strip benchmark executes on a strip with an even number of nodes that communicate in a pairwise way. A strip of nodes is a contiguous partition formed by a set of nodes in the same row or column of the mesh. <p> Corroborating Liu et al.s results <ref> [32] </ref>, our experi 1 2 3 4 5 N ments showed this delay to be negligible in the typical case. For this reason, we will not include this delay in our contention model.
Reference: [33] <author> V. M. Lo, </author> <title> Heuristic Algorithms for Task Assignment in Distributed Systems, </title> <journal> IEEE Transactions on Computers , vol. </journal> <volume> 37, no. 11, </volume> <pages> pp. 1384-1397, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: Most mapping strategies in the literature assume a distributed X m X m ded, sd = ded m nfi X m ded, ded model in which execution sites are timeshared (e.g. <ref> [4, 14, 27, 33, 47] </ref>). In practice, an execution site in a heterogeneous system may be an MPP (such as the Intel Paragon or the Cray T3D) or a dedicated cluster (such as the IBM SP-2 or the DEC Alpha Farm).
Reference: [34] <author> K. Marzullo, M. Ogg, A. Ricciardi, A. Amoroso, F. A. Calkins, and E. Rothfus, NILE: </author> <title> Wide-Area Computing for High-Energy Physics, </title> <booktitle> in Proceedings of the Seventh ACM SIGOPS European Workshop 49-54, </booktitle> <month> September </month> <year> 1996. </year>
Reference-contexts: Different groups have proposed systems that focus on scheduling of parallel applications on distributed systems in different ways (e.g., AppLeS 9 [5, 6], Legion [24], Globus [23], Prophet [51], MARS [22], Condor [10], SmartNet [27], and Nile <ref> [34, 35] </ref>). In general, current scheduling systems assign tasks (or entire applications) to machines according to computation time and communication costs using several different performance measures (e.g., [25, 31]), but few consider contention effects.
Reference: [35] <author> K. Marzullo, M. Ogg, and A. Ricciardi, </author> <title> The NILE System Architectures, </title> <booktitle> in Proceedings of the Eleventh International Conference on Systems Engineering , pp. </booktitle> <pages> 414-419, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: Different groups have proposed systems that focus on scheduling of parallel applications on distributed systems in different ways (e.g., AppLeS 9 [5, 6], Legion [24], Globus [23], Prophet [51], MARS [22], Condor [10], SmartNet [27], and Nile <ref> [34, 35] </ref>). In general, current scheduling systems assign tasks (or entire applications) to machines according to computation time and communication costs using several different performance measures (e.g., [25, 31]), but few consider contention effects.
Reference: [36] <editor> Matrix Multiply, </editor> <address> http://HTTP.CS.Berkeley.EDU/~demmel/cs267. </address>
Reference-contexts: Matrix Multiply This benchmark multiplies two matrices using a 1-dimensional blocked layout on a ring with broadcast <ref> [36] </ref>. A parallel implementation was developed for clusters using C++ and Fortran 77. It was implemented on top of KeLP [19] and MPI [40]. A second parallel implementation executes on the DEC Alpha-Farm at SDSC and uses BLAS [7] for the local matrix multiplication on each node.
Reference: [37] <author> C. Mechoso, J. Farrara, and J. Spahr, </author> <title> Achieving Superlinear Speedup on a Heterogeneous Distributed System, </title> <journal> IEEE Parallel and Distributed Technology , pp. </journal> <pages> 57-61, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: In general, current scheduling systems assign tasks (or entire applications) to machines according to computation time and communication costs using several different performance measures (e.g., [25, 31]), but few consider contention effects. Among metacom-puting application developers, Mechoso et al. <ref> [37] </ref> have identified contention effects, which they express as an expansion factor on their experiments with NGCM (Network General Circulation Model). <p> To illustrate, consider the application formed by three tasks (A, B, and C) shown in Figure 5-1. This is the ow-graph for one iteration of a General Circulation Model (GCM) <ref> [37, 38, 39] </ref> that can be used to study the nonlinear interaction and feedback between components of a climate system. Task A (an Atmospheric/Physics task) generates data to be used by tasks B (an Atmospheric/Dynamics task) and C (an Ocean Simulation), which can execute concurrently. <p> Since the number of tasks for coarse-grained heterogeneous applications in practice is typically , and the number of machines used is typically <ref> [1, 28, 37, 44] </ref>, both C and L are small. Note that we cannot execute the algorithm without a value for all paths.
Reference: [38] <author> C. Mechoso, J. Farrara, and J. Spahr, </author> <title> Running a Climate Model in a Heterogeneous, Distributed Computer Environment, </title> <booktitle> in Proceedings of the Third IEEE International Symposium on High Performance Distributed Computing , pp. </booktitle> <pages> 79-84, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Current experience shows that many high-performance distributed applications are composed of a few coarse-grained tasks and execute on heterogeneous platforms composed of 2 or 3 machines <ref> [28, 38, 44, 49] </ref>. These platforms are formed by smart instruments and machines which can be SIMD MPPs, MIMD MPPs, vector computers, and/or workstations. For many of these applications, both heterogeneity and parallelism in the code are exploited. <p> B 21 24 5 In particular, a model to predict contention effects on application perfor mance should reect both system characteristics and workload behavior. 1.2 Scheduling Parallel Applications on Distributed Systems One would assume that for heterogeneous applications, typically composed of few tasks and targeted to 2 or 3 machines <ref> [28, 38, 44, 49] </ref>, the scheduling problem would be easy in particular, exhaustive search of the best allocation of tasks to resources would solve the problem. In fact, determining the best allocation between tasks and machines depends on performance estimate and is hard for reasons other than scalability. <p> To illustrate, consider the application formed by three tasks (A, B, and C) shown in Figure 5-1. This is the ow-graph for one iteration of a General Circulation Model (GCM) <ref> [37, 38, 39] </ref> that can be used to study the nonlinear interaction and feedback between components of a climate system. Task A (an Atmospheric/Physics task) generates data to be used by tasks B (an Atmospheric/Dynamics task) and C (an Ocean Simulation), which can execute concurrently. <p> For now, assume that both M 1 and M 2 have a single processor. Suppose further that task A can only exe-9. This is indeed how the heterogeneous implementation is performed in practice <ref> [37 , 38, 39] </ref>. For instance, in the UCLA implementation of GCM, machine M 1 is a Cray C90 and machine M 2 is an Intel Paragon. cute on machine M 1 , but both tasks B and C can run on M 1 or M 2 .
Reference: [39] <author> C. R. Mechoso, C. Ma, J. D. Farrara, J. A. Spahr, and R. W. Moore, </author> <title> Distribution of a Climate Model across HighSpeed Networks, </title> <booktitle> in Proceedings of the Supercomputing91 </booktitle>
Reference-contexts: To illustrate, consider the application formed by three tasks (A, B, and C) shown in Figure 5-1. This is the ow-graph for one iteration of a General Circulation Model (GCM) <ref> [37, 38, 39] </ref> that can be used to study the nonlinear interaction and feedback between components of a climate system. Task A (an Atmospheric/Physics task) generates data to be used by tasks B (an Atmospheric/Dynamics task) and C (an Ocean Simulation), which can execute concurrently. <p> For now, assume that both M 1 and M 2 have a single processor. Suppose further that task A can only exe-9. This is indeed how the heterogeneous implementation is performed in practice <ref> [37 , 38, 39] </ref>. For instance, in the UCLA implementation of GCM, machine M 1 is a Cray C90 and machine M 2 is an Intel Paragon. cute on machine M 1 , but both tasks B and C can run on M 1 or M 2 .
Reference: [40] <author> Message-Passing Interface Forum, </author> <title> MPI: A Message-Passing Interface Standard, </title> <institution> University of Tennessee, Knoxville, TN, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: Matrix Multiply This benchmark multiplies two matrices using a 1-dimensional blocked layout on a ring with broadcast [36]. A parallel implementation was developed for clusters using C++ and Fortran 77. It was implemented on top of KeLP [19] and MPI <ref> [40] </ref>. A second parallel implementation executes on the DEC Alpha-Farm at SDSC and uses BLAS [7] for the local matrix multiplication on each node. For this benchmark, data is divided evenly among the nodes of the cluster, each of which is responsible for an equal amount of work. <p> The parallel algorithm was developed for clusters using C++ and Fortran 77. It was implemented on top of KeLP [19] and MPI <ref> [40] </ref>. The 2-dimensional matrix is divided evenly among the nodes of the cluster, each of which is responsible for an equal amount of work. Jacobi3D The Jacobi3D benchmark solves Laplaces equation on a 3-dimensional matrix using Jacobi relaxation [11]. <p> The parallel algorithm was developed for clusters using C++ and Fortran 77. It was implemented on top of KeLP [19] and MPI <ref> [40] </ref>. The 3-dimensional matrix is divided evenly among the nodes of the cluster, each of which is responsible for an equal amount of work. Multigrid The Multigrid algorithm implements a Multigrid Poisson solver on an 20 irregular grid [11]. <p> The parallel benchmark was developed using C++ and Fortran 77. It was implemented on top of KeLP [19] and MPI <ref> [40] </ref>. We implemented two versions of this benchmark: one implementation employs a blocked, even data distribution, i.e., the lowest level matrix is divided evenly among the nodes independently of the load or the node computational capacity. <p> It is a simulated CFD application, which uses symmetric successive over-relaxation (SSOR) to solve a block-lower-triangular / block-upper-triangular system of equations resulting from an unfactored implicit finite-difference discretization of the Navier-Stokes equations in three dimensions. The parallel benchmark was developed using Fortran 77 and MPI <ref> [40] </ref>. It employs a cyclic, even distribution of data in two dimensions, and it is characterized by the transference of large numbers of very small (40 byte) messages. Genetic Algorithm The Genetic Algorithm performs an optimization for the Traveling Sales 21 man Problem (TSP) [29, 53]. <p> Applications executing on the Paragon generally use NX (the communication interface provided by Intel) for communication between the compute nodes. For communication with other machines, TCP/IP (sometimes underneath a communication interface like PVM [46] or MPI <ref> [40] </ref>) is used. Table 3-4: Experiments with Communication Frequency Amount of Communication per Competing Application Burst Size (number of messages / message size in words) per Competing Application Average Error 90% 900 / 5000 18% happens in different ways.
Reference: [41] <institution> NAS Parallel Benchmarks, </institution> <note> http://www.nas.nasa.gov/NAS/NPB. </note>
Reference-contexts: A second implementation allows the user to determine an uneven distribution at the lowest level matrix. LU Solver The LU Solver benchmark used is part of the NAS Parallel Benchmarks <ref> [41] </ref>. It is a simulated CFD application, which uses symmetric successive over-relaxation (SSOR) to solve a block-lower-triangular / block-upper-triangular system of equations resulting from an unfactored implicit finite-difference discretization of the Navier-Stokes equations in three dimensions. The parallel benchmark was developed using Fortran 77 and MPI [40].
Reference: [42] <institution> NOW, </institution> <note> http://now.cs.berkeley.edu. </note>
Reference-contexts: Virtual clusters can take advantage of fastspeed network links and idle workstations to form an ad hoc virtual parallel computer. In fact, they have been used largely in the execution of serial and data-parallel tasks <ref> [10, 42, 46] </ref>. In this dissertation, we develop a contention model for virtual clusters formed by nodes containing one processor each.
Reference: [43] <author> J. Pedersen and J. Moult, </author> <title> Determination of the Structure of Small Protein Fragments using Torsion Space Monte Carlo and Genetic Algorithm Methods, in Proceedings of the Meeting on Critical Assessment of Techniques for Protein Structure Prediction , December 1994. </title> <type> 197 </type>
Reference-contexts: Genetic algorithms form a class of applications originally developed by the artificial intelligence community as an optimization technique for NP-complete and NP-hard problems. As such, they are now being used by several groups of computational scientists <ref> [13, 43, 45] </ref> to address problems such as protein modeling. This application is structured in a master/slave paradigm.
Reference: [44] <author> A. Phillips, J. Rosen, and V. Walke, </author> <title> Molecular Structure Determination by Convex Global Underestimation of Local Energy Minima, </title> <institution> University of Minnesota Supercomputer Institute Research Report UMSI 94/126, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: Current experience shows that many high-performance distributed applications are composed of a few coarse-grained tasks and execute on heterogeneous platforms composed of 2 or 3 machines <ref> [28, 38, 44, 49] </ref>. These platforms are formed by smart instruments and machines which can be SIMD MPPs, MIMD MPPs, vector computers, and/or workstations. For many of these applications, both heterogeneity and parallelism in the code are exploited. <p> For many of these applications, both heterogeneity and parallelism in the code are exploited. For example, in a molecular structure application, an MPP is used for the parallel part of the code whereas a vector computer is used to execute the serial portion <ref> [44] </ref>. For such applications, the development of a performance-efficient allocation of tasks to machines is dependent upon a realistic prediction of application behavior and, in particular, of application computation and communication costs under changing system load. <p> B 21 24 5 In particular, a model to predict contention effects on application perfor mance should reect both system characteristics and workload behavior. 1.2 Scheduling Parallel Applications on Distributed Systems One would assume that for heterogeneous applications, typically composed of few tasks and targeted to 2 or 3 machines <ref> [28, 38, 44, 49] </ref>, the scheduling problem would be easy in particular, exhaustive search of the best allocation of tasks to resources would solve the problem. In fact, determining the best allocation between tasks and machines depends on performance estimate and is hard for reasons other than scalability. <p> Since the number of tasks for coarse-grained heterogeneous applications in practice is typically , and the number of machines used is typically <ref> [1, 28, 37, 44] </ref>, both C and L are small. Note that we cannot execute the algorithm without a value for all paths.
Reference: [45] <editor> S. Schulze-Kremer, </editor> <address> http://www.techfak.uni-bielefeld.de/bcd/Curric/ ProtEn/proten.html, </address> <year> 1996. </year>
Reference-contexts: Genetic algorithms form a class of applications originally developed by the artificial intelligence community as an optimization technique for NP-complete and NP-hard problems. As such, they are now being used by several groups of computational scientists <ref> [13, 43, 45] </ref> to address problems such as protein modeling. This application is structured in a master/slave paradigm.
Reference: [46] <author> V. Sunderam, </author> <title> PVM: A Framework for Parallel Distributed Computing, </title> <journal> Concurrency: Practice and Experience , vol. </journal> <volume> 2, </volume> <editor> n. </editor> <volume> 4, </volume> <pages> pp. 315-339, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: HeNCE [4], a graphical tool that assists programmers in executing applications on heterogeneous systems using PVM <ref> [46] </ref>, keeps track of the aggregate load allocated to each machine and attempts to balance the load when scheduling new tasks. <p> We have implemented three versions of this algorithm: a Sun/CM2 version was implemented in CM-Fortran; a serial version, implemented for workstations, was written in C; and a parallel version, developed for clusters, was implemented in C on top of PVM <ref> [46] </ref>. The PVM version was developed to allow for load-dependent work distribution, i.e., the number of rows assigned to each node of the cluster may depend on the computational capacity of the nodes, which varies with CPU speed and contention for the CPU. <p> This data is sent back to the master. Once all the sets of children are received by the master, they are sorted (by efficiency of the tour), some are chosen to form the next generation, and the cycle begins again. Our implementation was developed in C using PVM <ref> [46] </ref>. The part of the code corresponding to the slaves executes in parallel on a cluster of workstations. Each node is responsible for a number of children. <p> Applications executing on the Paragon generally use NX (the communication interface provided by Intel) for communication between the compute nodes. For communication with other machines, TCP/IP (sometimes underneath a communication interface like PVM <ref> [46] </ref> or MPI [40]) is used. Table 3-4: Experiments with Communication Frequency Amount of Communication per Competing Application Burst Size (number of messages / message size in words) per Competing Application Average Error 90% 900 / 5000 18% happens in different ways. <p> Virtual clusters can take advantage of fastspeed network links and idle workstations to form an ad hoc virtual parallel computer. In fact, they have been used largely in the execution of serial and data-parallel tasks <ref> [10, 42, 46] </ref>. In this dissertation, we develop a contention model for virtual clusters formed by nodes containing one processor each.
Reference: [47] <author> L. Tao, B. Narahari, and Y. C. Zhao, </author> <title> Heuristics for Mapping Parallel Computations to Heterogeneous Parallel Architectures, </title> <booktitle> in Proceedings of the Heterogeneous Computing Workshop , pp. </booktitle> <pages> 36-41, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Most mapping strategies in the literature assume a distributed X m X m ded, sd = ded m nfi X m ded, ded model in which execution sites are timeshared (e.g. <ref> [4, 14, 27, 33, 47] </ref>). In practice, an execution site in a heterogeneous system may be an MPP (such as the Intel Paragon or the Cray T3D) or a dedicated cluster (such as the IBM SP-2 or the DEC Alpha Farm).
Reference: [48] <author> C. Tron and B. </author> <title> Plateau, Modeling of Communication Contention in Multiprocessors, </title> <booktitle> in Proceedings of Modeling Techniques and Tools for Computers - Performance Evaluation , LNCS, </booktitle> <pages> pp. 406-424, </pages> <year> 1994. </year>
Reference-contexts: Bokhari has shown, in [8], that specific communication patterns presented by certain applications generate contention for interconnection links, causing degradation in the interprocessor communication and, consequently, a slowdown in the application execution. Tron and Plateau <ref> [48] </ref> have developed a model for network contention in multiprocessors. Their experiments involved a ping-pong application and a contention generator. The contention is generated based on parameters , each of which denotes the probability associated with a range of message sizes.
Reference: [49] <institution> Virtual Environments and Distributed Computing at SC95. </institution> <note> GII Testbed and HPC Challenge Applications on the I-WAY. Edited by Holly Korab and Maxine D. Brown. A publication of ACM/IEEE Su-percomputing95. </note>
Reference-contexts: Current experience shows that many high-performance distributed applications are composed of a few coarse-grained tasks and execute on heterogeneous platforms composed of 2 or 3 machines <ref> [28, 38, 44, 49] </ref>. These platforms are formed by smart instruments and machines which can be SIMD MPPs, MIMD MPPs, vector computers, and/or workstations. For many of these applications, both heterogeneity and parallelism in the code are exploited. <p> B 21 24 5 In particular, a model to predict contention effects on application perfor mance should reect both system characteristics and workload behavior. 1.2 Scheduling Parallel Applications on Distributed Systems One would assume that for heterogeneous applications, typically composed of few tasks and targeted to 2 or 3 machines <ref> [28, 38, 44, 49] </ref>, the scheduling problem would be easy in particular, exhaustive search of the best allocation of tasks to resources would solve the problem. In fact, determining the best allocation between tasks and machines depends on performance estimate and is hard for reasons other than scalability.
Reference: [50] <author> M. Wan, R. Moore, G. Kremenek, K. Steube, </author> <title> A Batch Scheduler for the Intel Paragon with a NonContiguous Node Allocation Algorithm, </title> <booktitle> in Proceedings of the Workshop on Job Scheduling Strategies for Parallel Processing , pp. </booktitle> <pages> 29-40, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: The number of applications executing on a computer is generally limited by the computers resources and is typically small (e.g., 7.7 on the average in the Intel Paragon at SDSC <ref> [50] </ref>). dela y comm i j, pm i 1 i p SOR benchmark on the Sun in non-dedicated mode, parameterized by prob lem size (which is NN). In this experiment, two more applications are exe cuting on the Sun.
Reference: [51] <author> J. Weissman, </author> <title> Scheduling Parallel Computations in a Heterogeneous Environment, </title> <type> Ph.D. dissertation, </type> <institution> University of Virginia, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: Different groups have proposed systems that focus on scheduling of parallel applications on distributed systems in different ways (e.g., AppLeS 9 [5, 6], Legion [24], Globus [23], Prophet <ref> [51] </ref>, MARS [22], Condor [10], SmartNet [27], and Nile [34, 35]). In general, current scheduling systems assign tasks (or entire applications) to machines according to computation time and communication costs using several different performance measures (e.g., [25, 31]), but few consider contention effects.
Reference: [52] <author> J. Weissman, </author> <title> The Interference Paradigm for Network Job Scheduling, </title> <booktitle> in Proceedings of the Heterogeneous Computing Workshop 38-45, </booktitle> <month> April </month> <year> 1996. </year>
Reference-contexts: Atallah et al. [3] have developed a model for cosched-uling compute-intensive tasks on a network of workstations. Their model takes into account the ratio of cycles that each workstation commits to local tasks to the number of cycles available for the compute-intensive guest tasks. Weissman <ref> [52] </ref> proposed a scheduling model based on resource contention using an interference paradigm . The interference measure determines how much slower an application will compute or a parallel application will communicate.
Reference: [53] <author> D. Whitley, T. Starkweather, and DUAnn Fuquay, </author> <title> Scheduling Problems and Traveling Salesman: The Genetic Edge Recombination Operator, </title> <booktitle> in Proceedings of International Conference on Genetic Algorithms 198 </booktitle>
Reference-contexts: It employs a cyclic, even distribution of data in two dimensions, and it is characterized by the transference of large numbers of very small (40 byte) messages. Genetic Algorithm The Genetic Algorithm performs an optimization for the Traveling Sales 21 man Problem (TSP) <ref> [29, 53] </ref>. Genetic algorithms form a class of applications originally developed by the artificial intelligence community as an optimization technique for NP-complete and NP-hard problems. As such, they are now being used by several groups of computational scientists [13, 43, 45] to address problems such as protein modeling.
Reference: [54] <author> R. Wolski, </author> <title> Dynamically Forecasting Network Performance Using the Network Weather Service, </title> <type> UCSD CS Technical Report #CS96-494. </type>
Reference-contexts: At runtime, the value for k the average bandwidth available on the links used by competing applications can be predicted by statistic tools (e.g. the Network Weather Service <ref> [6, 54] </ref>), and used to determine . dela y comm i k, dela y comm i k, dela y comm i k, dela y comm i k, dela y comm i k, i = 2. In low-bandwidth systems, may be approximated by just one curve or by just one value. <p> The benchmark sends 1024 messages with 1024 words each from one node to another and waits for the answer. The value for can be obtained at runtime with statistical methods employed by performance prediction tools, such as the Network Weather Service <ref> [6, 54] </ref>. <p> In fact, the error correlates inversely with the granularity of the applications executing on the nodes. In the cases where cannot be calculated based on information about the applications executing, it can be obtained by tools, such as the Network Weather Service <ref> [6, 54] </ref>, which predicts the load on networked resources using statistical models, and provides CPU and/or communica 0 400 800 1200 3000 3500 4000 4500 5000 no contention modeled measured t i m ( s e n s problem size (N) 105 tion link capacities at runtime. <p> This can be done when the time to execute the targeted application in dedicated mode is known or can be predicted, and information about the load is available. The contention models can also be integrated into the Network Weather Service <ref> [6, 54] </ref> to leverage its predictions when information about applications is available. The Network Weather Service relies basically on information obtained by probes that measure system performance periodically. It uses this information to provide statistical predictions of system behavior.
Reference: [55] <author> X. Zhang and Y. Yan, </author> <title> A Framework of Performance Prediction of Parallel Computing on Non-dedicated Heterogeneous Networks of Workstations, </title> <booktitle> in Proceedings of 1995 International Conference of Parallel Processing , vol. </booktitle> <volume> I, </volume> <pages> pp. 163-167, </pages> <year> 1995. </year>
Reference-contexts: Machine workload has been used to parameterize the allocation of tasks to workstations in a network, however, many allocation strategies do not consider load characteristics in the measurement of workload (e.g., [4, 10, 14, 27]). Load characteristics have been included in performance prediction models for networks of workstations (e.g., <ref> [30, 55] </ref>), however such models assume that each workstation is shared by at most one compute-intensive task and one or more local tasks that alternate idle with busy cycles. We believe that considering the load on the machines in a network of workstations is important, but may not be enough. <p> They use a probabilistic model to predict the local use of the workstations and introduce a task ratio to determine how large the demand of a parallel application must be in order to make efficient use of a non-dedicated distributed system. In <ref> [55] </ref>, Zhang and Yan also use a probabilistic model for contention in their performance prediction model.
References-found: 55

