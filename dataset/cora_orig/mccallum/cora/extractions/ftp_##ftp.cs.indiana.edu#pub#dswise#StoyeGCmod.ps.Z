URL: ftp://ftp.cs.indiana.edu/pub/dswise/StoyeGCmod.ps.Z
Refering-URL: http://www.cs.indiana.edu/l/www/classes/b501/PLseminar.oct2.html
Root-URL: http://www.cs.indiana.edu
Title: Stop-and-copy and One-bit Reference Counting  
Author: David S. Wise 
Keyword: CR categories and Subject Descriptors: D.4.2 [Storage Management]: Allocation/Deallocation strategies; E.2 [Data Storage Representations]: Linked representations. General Term: Algorithms. Additional Key Words and Phrases: multiple reference bit, MRB.  
Address: Bloomington, Indiana 47405 USA  
Affiliation: Indiana University  
Pubnum: Technical Report 360  
Email: Email: dswise@cs.indiana.edu  
Phone: Fax: +1 (812) 855-4829  
Date: (revised) March 1993  
Abstract: A stop-and-copy garbage collector updates one-bit reference counting with essentially no extra space and minimal memory cycles beyond the conventional collection algorithm. Any object that is uniquely referenced during a collection becomes a candidate for cheap recovery before the next one, or faster recopying then if it remains uniquely referenced. Since most objects stay uniquely referenced, subsequent collections run faster even if none are recycled between garbage collections. This algorithm extends to generation scavenging, it admits uncounted references from roots, and it corrects conservatively stuck counters, that result from earlier uncertainty whether references were unique. fl Research reported herein was sponsored, in part, by the National Science Foundation under Grant Number CCR 90-02797. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Appel. </author> <title> Compiling with Continuations, </title> <publisher> Cambridge Univ. Press (1992), </publisher> <pages> 205-206. </pages>
Reference-contexts: On the other hand, successful reference counting can postpone need for garbage collection, or accelerate that collection [3]. Recovery of zero-count objects is worthwhile only when the per-node cost of reference-counting recovery undercuts that for garbage collecting <ref> [1] </ref>. The cost, however, must include the impact of synchronization in a real-time or multiprocessor environment. One way to improve the performance of both is to use hardware [32] to maintain the counts without any extra cycles. <p> Quite appropriately certain shared references may go uncounted. This relaxation allows, for instance, a unique reference to be relocated "atomically" without its count rising from unique to sticky. A similar idea is used in some usual patterns of coding [6], in simple list manipulations [25], in tail-recursion protocols <ref> [7, 1, 4] </ref>, and in linear languages [17, 27, 5]. However, run-time management like this can be more comprehensive than any of these. <p> Define * = q (r + 2) 2 and observe that * &gt; 0 if r &gt; 6% and q &gt; 97%, as Clark and Green [10] observed, or even when r &gt; 22% and q &gt; 90%. Appel <ref> [1] </ref> observed u = 1=3 without generation scavenging. If we then approximate 4p p 2 as 2 (p 59%) and * = 0 conservatively, then memory-cycles-per-collected-node becomes 3. <p> It conjectured that Stoye's one-bit counter is more powerful than compile-time linear-logic [27], but both can be hobbled by obfuscated code. The former may prove more appropriate in general packages (interpreted code) and the latter in general-purpose programming (compiled code). Appel <ref> [1, p. 206] </ref> claims fractional cycle-per-node efficiency for generation-scavenging garbage-collection recovery. His arguments are valid with a heap much larger than active data structure, and when generation scavenging is effective; his application, a strict (eager) language on a large, dedicated uniprocessor, meets these criteria.
Reference: [2] <author> A. Appel. </author> <title> Garbage collection. </title> <editor> In P. Lee (ed.), </editor> <booktitle> Topics in Advanced Language Implementation, </booktitle> <address> Cambridge MA, </address> <publisher> M.I.T. </publisher> <month> Press </month> <year> (1991) </year> <month> 89-100. </month>
Reference-contexts: If it points into the range of to space, we say mark is "set"; if it has any other value|including a pointer into from space|then it is "clear." This convention is consistent with the role of marking in all garbage collectors. The stop-and-copy collector <ref> [8, 2] </ref> is a "two finger" algorithm, whose effect is to move all nodes out of the from semispace, compacting them into the to semispace. <p> Thereafter, one "finger," called next, always points to the first unused address in to space. The other, called scan, starts at the beginning of to space and updates every pointer in sequence until it catches up with next. For a complete description and figure, see Appel <ref> [2] </ref>. Next and scan are denoted Nfl and Sfl in the figures; this description focuses on scan. references to a binary node at address A.
Reference: [3] <author> H.G. Baker. </author> <title> Cache-conscious copying collectors. </title> <booktitle> OOPSLA '91 GC Workshop. </booktitle> <month> (October </month> <year> 1991). </year> <institution> c flNimble Computer Corp, </institution> <address> 16231 Meadow Ridge Way, Encino, CA 91436, USA. </address>
Reference-contexts: Although counting is too weak to handle certain circular structures [20, 16], garbage collection can back it up. On the other hand, successful reference counting can postpone need for garbage collection, or accelerate that collection <ref> [3] </ref>. Recovery of zero-count objects is worthwhile only when the per-node cost of reference-counting recovery undercuts that for garbage collecting [1]. The cost, however, must include the impact of synchronization in a real-time or multiprocessor environment. <p> When scan encounters a unique pointer to from space, it copies the content at next, but does not install any forwarding information. (Since the object is uniquely referenced, there aren't any other references to forward.) Thus, every unique reference (even if just installed during a previous collection) accelerates conventional collection <ref> [3] </ref>. Scan also encounters sticky pointers to locations in from space, some of whose contents have been copied|but some not yet copied|into to space. The difference is determined by mark on that node.
Reference: [4] <author> H.G. Baker. </author> <title> Cons should not cons its arguments. </title> <journal> SIGPLAN Notices 27, </journal> <month> 3 (March </month> <year> 1992), </year> <pages> 24-34. </pages>
Reference-contexts: Quite appropriately certain shared references may go uncounted. This relaxation allows, for instance, a unique reference to be relocated "atomically" without its count rising from unique to sticky. A similar idea is used in some usual patterns of coding [6], in simple list manipulations [25], in tail-recursion protocols <ref> [7, 1, 4] </ref>, and in linear languages [17, 27, 5]. However, run-time management like this can be more comprehensive than any of these.
Reference: [5] <author> H.G. Baker. </author> <title> Lively linear lisp|`Look Ma, </title> <journal> no garbage!' SIGPLAN Notices 27, </journal> <month> 8 (August </month> <year> 1992), </year> <pages> 89-98. </pages>
Reference-contexts: This relaxation allows, for instance, a unique reference to be relocated "atomically" without its count rising from unique to sticky. A similar idea is used in some usual patterns of coding [6], in simple list manipulations [25], in tail-recursion protocols [7, 1, 4], and in linear languages <ref> [17, 27, 5] </ref>. However, run-time management like this can be more comprehensive than any of these.
Reference: [6] <author> J. Barth. </author> <title> Shifting garbage collection overhead to compile time. </title> <journal> Comm. ACM 20, </journal> <month> 7 (July </month> <year> 1977), </year> <pages> 513-518. </pages>
Reference-contexts: a "model" node is copied except for a single field, but if the compiler or the run-time environment ascertains that the model node is uniquely referenced and that the current environment|the source of the reference|is about to be abandoned (as in tail recursion), then it can side-effect that field, instead <ref> [6] </ref>. In effect, the model node is pre-allocated, and much of its initialization| reflexive copying|is annihilated; the only difference results from the side-effect. <p> Quite appropriately certain shared references may go uncounted. This relaxation allows, for instance, a unique reference to be relocated "atomically" without its count rising from unique to sticky. A similar idea is used in some usual patterns of coding <ref> [6] </ref>, in simple list manipulations [25], in tail-recursion protocols [7, 1, 4], and in linear languages [17, 27, 5]. However, run-time management like this can be more comprehensive than any of these.
Reference: [7] <author> A. Bloss & P. Hudak. </author> <title> Variations on strictness analysis. </title> <booktitle> Conf. Rec. 1986 ACM Symp. on Lisp and Functional Programming, </booktitle> <pages> 132-142. </pages>
Reference-contexts: Quite appropriately certain shared references may go uncounted. This relaxation allows, for instance, a unique reference to be relocated "atomically" without its count rising from unique to sticky. A similar idea is used in some usual patterns of coding [6], in simple list manipulations [25], in tail-recursion protocols <ref> [7, 1, 4] </ref>, and in linear languages [17, 27, 5]. However, run-time management like this can be more comprehensive than any of these.
Reference: [8] <author> C.J. </author> <title> Cheney. A nonrecursive list compacting algorithm. </title> <journal> Comm. ACM 13, </journal> <month> 11 (November </month> <year> 1970), </year> <pages> 677-678. </pages>
Reference-contexts: 1 One-bit Reference Counts The most commonly used garbage collector is the stop and copy algorithm due to Minsky, Finichel, and Yokelson <ref> [15, 8] </ref>. Sometimes it is a generation scavenging [22, 26] variant that more frequently recovers shorter-lived structures with less effort. <p> If it points into the range of to space, we say mark is "set"; if it has any other value|including a pointer into from space|then it is "clear." This convention is consistent with the role of marking in all garbage collectors. The stop-and-copy collector <ref> [8, 2] </ref> is a "two finger" algorithm, whose effect is to move all nodes out of the from semispace, compacting them into the to semispace. <p> Of those, let r be the proportion that is actually tagged unique at the beginning of garbage collection. Consider the memory cycles (read or write) necessary to collect a semispace, recopying uM nodes to recover (1 u)M: In its naive, two-semispace version <ref> [8] </ref> a collection requires three memory cycles to copy and forward (read, write, write) each of uM binary nodes to to space.
Reference: [9] <author> T. Chikayama & Y. Kimura. </author> <title> Multiple reference management in flat GHC. </title> <editor> In J.-L. Lassez (ed.), </editor> <booktitle> Logic Programming, Proc. 4th Intl. Conf. 1. </booktitle> <address> Cambridge, MA, </address> <publisher> M.I.T. Press (1987), </publisher> <pages> 276-293. </pages>
Reference-contexts: The first proposal for one-bit reference counting [31] only addresses the need to save space for the counter; it uses the mark bit, already in every node, as a reference count between garbage collections. The second formulation [24] is far superior. It has since been rediscovered <ref> [9] </ref> and developed [18, 23, 19] in logic programming, where it is called a multiple reference bit or MRB. Stoye, Clarke, and Norman [24] designated one bit within every pointer (rather than one at every node); thus, a binary node has two such bits.
Reference: [10] <author> D.W. Clark & C.C. Green. </author> <title> A note on shared list structure in Lisp. </title> <journal> Inf. Proc. Lett. </journal> <volume> 7, </volume> <month> 6 (October </month> <year> 1978), </year> <pages> 312-315. </pages>
Reference-contexts: The cost, however, must include the impact of synchronization in a real-time or multiprocessor environment. One way to improve the performance of both is to use hardware [32] to maintain the counts without any extra cycles. Clark and Green <ref> [10] </ref> present experimental results showing that less than 3% of Lisp's nodes have reference counts above one. Therefore, it is usual to use a very small field for such counts, with its maximal value designated sticky, a limit which neither increments nor decrements can change. <p> Define * = q (r + 2) 2 and observe that * &gt; 0 if r &gt; 6% and q &gt; 97%, as Clark and Green <ref> [10] </ref> observed, or even when r &gt; 22% and q &gt; 90%. Appel [1] observed u = 1=3 without generation scavenging. If we then approximate 4p p 2 as 2 (p 59%) and * = 0 conservatively, then memory-cycles-per-collected-node becomes 3.
Reference: [11] <author> J. Cohen. </author> <title> Garbage collection of linked data structures. </title> <journal> Comput Surveys 13, </journal> <month> 3 (September </month> <year> 1981), </year> <pages> 341-367. </pages>
Reference-contexts: Sometimes it is a generation scavenging [22, 26] variant that more frequently recovers shorter-lived structures with less effort. Reference counting [12] is an orthogonal strategy for storage management <ref> [11] </ref> that again is receiving attention in the context of parallel heap management because its transactions are all local [21, 30, 32]. Reference counting is best used along with a garbage collector as a hybrid manager [28, 20, 13, 29].
Reference: [12] <author> G.E. </author> <title> Collins A method for overlapping and erasure of lists. </title> <journal> Comm. ACM 3, </journal> <month> 12 (December </month> <year> 1960), </year> <pages> 655-657. </pages>
Reference-contexts: 1 One-bit Reference Counts The most commonly used garbage collector is the stop and copy algorithm due to Minsky, Finichel, and Yokelson [15, 8]. Sometimes it is a generation scavenging [22, 26] variant that more frequently recovers shorter-lived structures with less effort. Reference counting <ref> [12] </ref> is an orthogonal strategy for storage management [11] that again is receiving attention in the context of parallel heap management because its transactions are all local [21, 30, 32]. Reference counting is best used along with a garbage collector as a hybrid manager [28, 20, 13, 29].
Reference: [13] <author> L.P. Deutsch & D.G. Bobrow. </author> <title> An efficient, incremental, automatic garbage collector. </title> <journal> Comm. ACM 19, </journal> <month> 9 (September </month> <year> 1976), </year> <pages> 522-526. 15 </pages>
Reference-contexts: Reference counting [12] is an orthogonal strategy for storage management [11] that again is receiving attention in the context of parallel heap management because its transactions are all local [21, 30, 32]. Reference counting is best used along with a garbage collector as a hybrid manager <ref> [28, 20, 13, 29] </ref>. Although counting is too weak to handle certain circular structures [20, 16], garbage collection can back it up. On the other hand, successful reference counting can postpone need for garbage collection, or accelerate that collection [3].
Reference: [14] <author> E.W. Dijkstra, L. Lamport, A.J. Martin, C.S. Sholten, & E.F.M. Stef--fens. </author> <title> On-the-fly garbage collection: an exercise in cooperation. </title> <journal> Comm. ACM 21, </journal> <month> 11 (November </month> <year> 1976), </year> <pages> 966-975. </pages>
Reference-contexts: As appropriate, the collector can later restore it to unique, compensating somewhat for earlier conservatism. 4 3 Collection and Count Tags The previous section reviews how one-bit reference counts can be sustained by the mutator <ref> [14] </ref> with few memory cycles|one more for every sticky count as it rises from unique. This section shows that the collector [14] can recompute all tags accurately for nearly the same cost: one less memory cycle for every uniquely referenced object entering collection, and two extra memory cycles for each sticky <p> restore it to unique, compensating somewhat for earlier conservatism. 4 3 Collection and Count Tags The previous section reviews how one-bit reference counts can be sustained by the mutator <ref> [14] </ref> with few memory cycles|one more for every sticky count as it rises from unique. This section shows that the collector [14] can recompute all tags accurately for nearly the same cost: one less memory cycle for every uniquely referenced object entering collection, and two extra memory cycles for each sticky count. Nodes with only one reference require no more cycles than a conventional stop-and-copy collection, and probably less.
Reference: [15] <author> R.R. Fenichel & J.C. Yochelson. </author> <title> A Lisp garbage collector for virtual-memory computer systems. </title> <journal> Comm. ACM 12, </journal> <month> 11 (November </month> <year> 1969), </year> <pages> 611-612. </pages>
Reference-contexts: 1 One-bit Reference Counts The most commonly used garbage collector is the stop and copy algorithm due to Minsky, Finichel, and Yokelson <ref> [15, 8] </ref>. Sometimes it is a generation scavenging [22, 26] variant that more frequently recovers shorter-lived structures with less effort.
Reference: [16] <author> D.P. Friedman & D.S. Wise. </author> <title> Reference counting can manage the circular environments of mutual recursion. </title> <journal> Inf. Proc. Lett. </journal> <volume> 8, </volume> <month> 1 (January </month> <year> 1979), </year> <pages> 41-45. </pages>
Reference-contexts: Reference counting is best used along with a garbage collector as a hybrid manager [28, 20, 13, 29]. Although counting is too weak to handle certain circular structures <ref> [20, 16] </ref>, garbage collection can back it up. On the other hand, successful reference counting can postpone need for garbage collection, or accelerate that collection [3]. Recovery of zero-count objects is worthwhile only when the per-node cost of reference-counting recovery undercuts that for garbage collecting [1].
Reference: [17] <author> J.-Y. Girard. </author> <title> Linear logic. </title> <type> Theoret. </type> <institution> Comput. Sci. </institution> <month> 50 </month> <year> (1987), </year> <pages> 1-102. </pages>
Reference-contexts: This relaxation allows, for instance, a unique reference to be relocated "atomically" without its count rising from unique to sticky. A similar idea is used in some usual patterns of coding [6], in simple list manipulations [25], in tail-recursion protocols [7, 1, 4], and in linear languages <ref> [17, 27, 5] </ref>. However, run-time management like this can be more comprehensive than any of these.
Reference: [18] <author> Y. Inamura, N. Ichiyoshi, K. Rokusawa, & K. Nakajima. </author> <title> Optimization techniques using the MRB and their evaluation on the Multi-PSI/V2. </title> <editor> In E.L. Lusk & R.A. Overbeek, </editor> <booktitle> Logic Programming, Proc. of North American Conf. </booktitle> <address> 1989 2 Cambridge, MA, </address> <publisher> M.I.T. Press (1989), </publisher> <pages> 907-921. </pages>
Reference-contexts: The first proposal for one-bit reference counting [31] only addresses the need to save space for the counter; it uses the mark bit, already in every node, as a reference count between garbage collections. The second formulation [24] is far superior. It has since been rediscovered [9] and developed <ref> [18, 23, 19] </ref> in logic programming, where it is called a multiple reference bit or MRB. Stoye, Clarke, and Norman [24] designated one bit within every pointer (rather than one at every node); thus, a binary node has two such bits. <p> that a uniquely referenced node needs no forwarding pointer, accelerating collection by minimizing "dirty" cache lines and pages. seventy percent of wasted cells are immediately reclaimed [24]." "We have found 40 to 90 percent of garbage data is incrementally reclaimed by the MRB [Stoye's] scheme in benchmark [committed-choice logic] programs <ref> [18] </ref>." 14
Reference: [19] <author> Y. Kimura, T. Chikayama, T. Shigoni, & A. Goto. </author> <title> Incremental garbage collection scheme in KL1 and its architectural support of PIM. </title> <editor> In J.G. Delgado-Frias & W.R. Moore (eds.), </editor> <booktitle> VLSI for Artificial Intelligence and Neural Networks, </booktitle> <address> New York, </address> <publisher> Plenum (1991), </publisher> <pages> 33-45. </pages>
Reference-contexts: The first proposal for one-bit reference counting [31] only addresses the need to save space for the counter; it uses the mark bit, already in every node, as a reference count between garbage collections. The second formulation [24] is far superior. It has since been rediscovered [9] and developed <ref> [18, 23, 19] </ref> in logic programming, where it is called a multiple reference bit or MRB. Stoye, Clarke, and Norman [24] designated one bit within every pointer (rather than one at every node); thus, a binary node has two such bits.
Reference: [20] <author> D.E. </author> <title> Knuth The Art of Computer Programming I, Fundamental Algorithms (2nd ed.), </title> <address> Reading MA, </address> <publisher> Addison-Wesley (1975). </publisher>
Reference-contexts: Reference counting [12] is an orthogonal strategy for storage management [11] that again is receiving attention in the context of parallel heap management because its transactions are all local [21, 30, 32]. Reference counting is best used along with a garbage collector as a hybrid manager <ref> [28, 20, 13, 29] </ref>. Although counting is too weak to handle certain circular structures [20, 16], garbage collection can back it up. On the other hand, successful reference counting can postpone need for garbage collection, or accelerate that collection [3]. <p> Reference counting is best used along with a garbage collector as a hybrid manager [28, 20, 13, 29]. Although counting is too weak to handle certain circular structures <ref> [20, 16] </ref>, garbage collection can back it up. On the other hand, successful reference counting can postpone need for garbage collection, or accelerate that collection [3]. Recovery of zero-count objects is worthwhile only when the per-node cost of reference-counting recovery undercuts that for garbage collecting [1]. <p> Finally, variable sizing of nodes creates problems for any run-time recycling. One can use different registers or different available-space lists for different ranges of size, but maintaining several available-space lists <ref> [20, x2.5] </ref> requires yet more memory cycles. 7 Conclusion Experiments with real systems are necessary to determine the success of these algorithms in different applications. For instance, a parallel, real-time program that uses constant-sized objects should find this technique quite useful.
Reference: [21] <author> B. Lang, C. Queinnec, & J. Piquer. </author> <title> Garbage collecting the world. </title> <booktitle> Conf. Rec. 19th ACM Symp. on Principles of Programming Languages (1992), </booktitle> <pages> 39-50. </pages>
Reference-contexts: Sometimes it is a generation scavenging [22, 26] variant that more frequently recovers shorter-lived structures with less effort. Reference counting [12] is an orthogonal strategy for storage management [11] that again is receiving attention in the context of parallel heap management because its transactions are all local <ref> [21, 30, 32] </ref>. Reference counting is best used along with a garbage collector as a hybrid manager [28, 20, 13, 29]. Although counting is too weak to handle certain circular structures [20, 16], garbage collection can back it up.
Reference: [22] <author> H. Lieberman & C. Hewitt. </author> <title> A real-time garbage collector based on the lifetimes of objects. </title> <journal> Comm. ACM 26, </journal> <month> 6 (June </month> <year> 1983), </year> <pages> 419-429. </pages>
Reference-contexts: 1 One-bit Reference Counts The most commonly used garbage collector is the stop and copy algorithm due to Minsky, Finichel, and Yokelson [15, 8]. Sometimes it is a generation scavenging <ref> [22, 26] </ref> variant that more frequently recovers shorter-lived structures with less effort. Reference counting [12] is an orthogonal strategy for storage management [11] that again is receiving attention in the context of parallel heap management because its transactions are all local [21, 30, 32].
Reference: [23] <author> K. Nishida, Y. Kimura, A. Matsumoto, & A. Goto. </author> <title> Evaluation of MRB garbage collection on parallel logic programming architectures. </title> <editor> In D.H.D. Warren & P. Szeredi (eds.), </editor> <booktitle> Logic Programming, Proc. 7th Intl. Conf. </booktitle> , <address> Cambridge, MA, </address> <publisher> M.I.T. Press (1990), </publisher>
Reference-contexts: The first proposal for one-bit reference counting [31] only addresses the need to save space for the counter; it uses the mark bit, already in every node, as a reference count between garbage collections. The second formulation [24] is far superior. It has since been rediscovered [9] and developed <ref> [18, 23, 19] </ref> in logic programming, where it is called a multiple reference bit or MRB. Stoye, Clarke, and Norman [24] designated one bit within every pointer (rather than one at every node); thus, a binary node has two such bits.
Reference: [24] <author> W.R. Stoye, T.J.W. Clarke, & A.C. Norman. </author> <title> Some practical methods for rapid combinator reduction. </title> <booktitle> Conf. Rec. 1984 ACM Symp. on Lisp and Functional Programming, </booktitle> <pages> 159-166. 16 </pages>
Reference-contexts: The first proposal for one-bit reference counting [31] only addresses the need to save space for the counter; it uses the mark bit, already in every node, as a reference count between garbage collections. The second formulation <ref> [24] </ref> is far superior. It has since been rediscovered [9] and developed [18, 23, 19] in logic programming, where it is called a multiple reference bit or MRB. Stoye, Clarke, and Norman [24] designated one bit within every pointer (rather than one at every node); thus, a binary node has two <p> The second formulation <ref> [24] </ref> is far superior. It has since been rediscovered [9] and developed [18, 23, 19] in logic programming, where it is called a multiple reference bit or MRB. Stoye, Clarke, and Norman [24] designated one bit within every pointer (rather than one at every node); thus, a binary node has two such bits. <p> Henry Baker observed that a uniquely referenced node needs no forwarding pointer, accelerating collection by minimizing "dirty" cache lines and pages. seventy percent of wasted cells are immediately reclaimed <ref> [24] </ref>." "We have found 40 to 90 percent of garbage data is incrementally reclaimed by the MRB [Stoye's] scheme in benchmark [committed-choice logic] programs [18]." 14
Reference: [25] <author> N. Suzuki. </author> <title> Analysis of pointer `rotation.' </title> <journal> Comm. ACM 25, </journal> <month> 5 (May </month> <year> 1982), </year> <pages> 330-335. </pages>
Reference-contexts: Quite appropriately certain shared references may go uncounted. This relaxation allows, for instance, a unique reference to be relocated "atomically" without its count rising from unique to sticky. A similar idea is used in some usual patterns of coding [6], in simple list manipulations <ref> [25] </ref>, in tail-recursion protocols [7, 1, 4], and in linear languages [17, 27, 5]. However, run-time management like this can be more comprehensive than any of these.
Reference: [26] <author> D. Ungar. </author> <title> Generation scavenging: a non-disruptive high-performance storage-reclamation algorithm. </title> <booktitle> Proc. ACM SIGPLAN/SIGSOFT Software Engineering Symp. on Practical Software Development Environments, SIGPLAN Notices 19, 5 & Software Engineering Notes 9, </booktitle> <month> 3 (May </month> <year> 1984), </year> <pages> 157-167. </pages>
Reference-contexts: 1 One-bit Reference Counts The most commonly used garbage collector is the stop and copy algorithm due to Minsky, Finichel, and Yokelson [15, 8]. Sometimes it is a generation scavenging <ref> [22, 26] </ref> variant that more frequently recovers shorter-lived structures with less effort. Reference counting [12] is an orthogonal strategy for storage management [11] that again is receiving attention in the context of parallel heap management because its transactions are all local [21, 30, 32].
Reference: [27] <author> P. Wadler. </author> <title> Is there a use for linear logic? Proc. Symp. on Partial Evaluation and Semantics-Based Program Manipulation, </title> <journal> SIGPLAN Notices 26, </journal> <month> 9 (September </month> <year> 1991), </year> <pages> 255-273. </pages>
Reference-contexts: This relaxation allows, for instance, a unique reference to be relocated "atomically" without its count rising from unique to sticky. A similar idea is used in some usual patterns of coding [6], in simple list manipulations [25], in tail-recursion protocols [7, 1, 4], and in linear languages <ref> [17, 27, 5] </ref>. However, run-time management like this can be more comprehensive than any of these. <p> It conjectured that Stoye's one-bit counter is more powerful than compile-time linear-logic <ref> [27] </ref>, but both can be hobbled by obfuscated code. The former may prove more appropriate in general packages (interpreted code) and the latter in general-purpose programming (compiled code). Appel [1, p. 206] claims fractional cycle-per-node efficiency for generation-scavenging garbage-collection recovery.
Reference: [28] <author> J. Weizenbaum. </author> <title> Symmetric list processor. </title> <journal> Comm. ACM 6, </journal> <volume> 9 (Septem-ber 1963), </volume> <pages> 524-554. </pages>
Reference-contexts: Reference counting [12] is an orthogonal strategy for storage management [11] that again is receiving attention in the context of parallel heap management because its transactions are all local [21, 30, 32]. Reference counting is best used along with a garbage collector as a hybrid manager <ref> [28, 20, 13, 29] </ref>. Although counting is too weak to handle certain circular structures [20, 16], garbage collection can back it up. On the other hand, successful reference counting can postpone need for garbage collection, or accelerate that collection [3]. <p> See Figure 2. Uncounted references are "scanned" differently from heap-resident ref 1 In the hardware reference-counter [32], popping is just as fast because a decrement is postponed until the stack cell is overwritten <ref> [28] </ref> later|contemporary with an increment| during a subsequent push. 8 9 erences and, therefore, they can occur only as roots. Each uncounted ref-erence causes the usual long-read from from space; if the node is already marked, nothing further happens. <p> An inexpensive remedy is to dedicate a register or a cache-resident vector to holding a few available addresses. A poor-man's available-space list, this can be effected with no memory cycles. When a node is allocated from such a register its stale contents should be inspected for additional unique references <ref> [28] </ref>. Depending on hardware, this requires another memory cycle (for the binary node illustrated), or if read-modify-write is available it can be effected by the existing write that initially fills the new node. The idea here is to enable reuse of released nodes on-the-spot. <p> It costs n + 1 memory cycles to return a uniquely referenced chain of n nodes to available space (n reads and a write), but often n is only one. Moreover, a new node must be read again before it is written (in absence of read-modify-write) <ref> [28] </ref>, so the cost is above three memory-cycles per node-recycled, before that node can be filled. Finally, variable sizing of nodes creates problems for any run-time recycling.
Reference: [29] <author> D.S. Wise. </author> <title> Morris's garbage compaction algorithm restores reference counts. </title> <journal> ACM Trans. Progr. Lang. Sys. </journal> <volume> 1, </volume> <month> 1 (July </month> <year> 1979), </year> <pages> 115-120. </pages>
Reference-contexts: Reference counting [12] is an orthogonal strategy for storage management [11] that again is receiving attention in the context of parallel heap management because its transactions are all local [21, 30, 32]. Reference counting is best used along with a garbage collector as a hybrid manager <ref> [28, 20, 13, 29] </ref>. Although counting is too weak to handle certain circular structures [20, 16], garbage collection can back it up. On the other hand, successful reference counting can postpone need for garbage collection, or accelerate that collection [3]. <p> Moreover, that same traversal can also recompute all counts from zero (unmarked)|perhaps reducing a sticky count to a lower value without yet recovering that space <ref> [29] </ref>. In this way, a small-but-stuck counter can be reset, so that reference counting could recover that space before the next collection.
Reference: [30] <author> D.S. Wise. </author> <title> Design for a multiprocessing heap with on-board reference-counting. </title> <editor> in J.-P. Jouannaud (ed.), </editor> <booktitle> Functional Programming and Computer Architecture, LNCS 201, </booktitle> <address> Berlin, </address> <publisher> Springer (1985), </publisher> <pages> 289-304. </pages>
Reference-contexts: Sometimes it is a generation scavenging [22, 26] variant that more frequently recovers shorter-lived structures with less effort. Reference counting [12] is an orthogonal strategy for storage management [11] that again is receiving attention in the context of parallel heap management because its transactions are all local <ref> [21, 30, 32] </ref>. Reference counting is best used along with a garbage collector as a hybrid manager [28, 20, 13, 29]. Although counting is too weak to handle certain circular structures [20, 16], garbage collection can back it up. <p> When garbage collection is more frequent or less tolerable, as in real-time or parallel applications, then reference counting is the better strategy|and decidedly better with the counting off-processor in memory hardware <ref> [30, 32] </ref>. The idea here is to modify each garbage collection in a cost-efficient effort to postpone and to accelerate the next one. This modification to a stop-and-copy collector makes it run faster even if no nodes are recycled between collections through reference counting.
Reference: [31] <author> D.S. Wise & D.P. Friedman. </author> <title> The one-bit reference count. </title> <type> BIT 17, </type> <month> 3 (September </month> <year> 1977), </year> <pages> 351-359. </pages>
Reference-contexts: The smallest reference-count field is only a single bit, whose value can only represent "uniquely referenced" or "shared." The terms unique and sticky will be associated with these two alternatives, which are indicated as ufl and sfl in the figures. The first proposal for one-bit reference counting <ref> [31] </ref> only addresses the need to save space for the counter; it uses the mark bit, already in every node, as a reference count between garbage collections. The second formulation [24] is far superior.
Reference: [32] <author> D.S. Wise, C. Hess, W. Hunt, & E. </author> <title> Ost. Uniprocessor performance of reference-counting hardware heap. </title> <institution> Computer Science Dept., Indiana Univ., Tech. Rept. </institution> <year> (1992). </year> <month> 17 </month>
Reference-contexts: Sometimes it is a generation scavenging [22, 26] variant that more frequently recovers shorter-lived structures with less effort. Reference counting [12] is an orthogonal strategy for storage management [11] that again is receiving attention in the context of parallel heap management because its transactions are all local <ref> [21, 30, 32] </ref>. Reference counting is best used along with a garbage collector as a hybrid manager [28, 20, 13, 29]. Although counting is too weak to handle certain circular structures [20, 16], garbage collection can back it up. <p> Recovery of zero-count objects is worthwhile only when the per-node cost of reference-counting recovery undercuts that for garbage collecting [1]. The cost, however, must include the impact of synchronization in a real-time or multiprocessor environment. One way to improve the performance of both is to use hardware <ref> [32] </ref> to maintain the counts without any extra cycles. Clark and Green [10] present experimental results showing that less than 3% of Lisp's nodes have reference counts above one. <p> Such threads through the code can sometimes be unwound and split, but they are, in general, quite tortuous: more difficult to engineer correctly than are garbage collectors <ref> [32] </ref>. Although low-level systems coding like this is touchy, thank goodness it needs to be coded only rarely even though it is used frequently. All of the above paraphrases Stoye's contribution. <p> The following protocol shows how to initiate a collection under Stoye's scheme without counting the root's reference. See Figure 2. Uncounted references are "scanned" differently from heap-resident ref 1 In the hardware reference-counter <ref> [32] </ref>, popping is just as fast because a decrement is postponed until the stack cell is overwritten [28] later|contemporary with an increment| during a subsequent push. 8 9 erences and, therefore, they can occur only as roots. <p> When garbage collection is more frequent or less tolerable, as in real-time or parallel applications, then reference counting is the better strategy|and decidedly better with the counting off-processor in memory hardware <ref> [30, 32] </ref>. The idea here is to modify each garbage collection in a cost-efficient effort to postpone and to accelerate the next one. This modification to a stop-and-copy collector makes it run faster even if no nodes are recycled between collections through reference counting.
References-found: 32

