URL: ftp://ftp.cs.columbia.edu/pub/cs4999/brill94.ps
Refering-URL: http://www.cs.columbia.edu/~becky/cs-readings.html
Root-URL: http://www.cs.columbia.edu
Email: brill@goldilocks.lcs.mit.edu  
Title: Some Advances in Transformation-Based Part of Speech Tagging  
Author: Eric Brill 
Address: Cambridge, Massachusetts 02139  
Affiliation: Spoken Language Systems Group Laboratory for Computer Science Massachusetts Institute of Technology  
Abstract: Most recent research in trainable part of speech taggers has explored stochastic tagging. While these taggers obtain high accuracy, linguistic information is captured indirectly, typically in tens of thousands of lexical and contextual probabilities. In (Brill 1992), a trainable rule-based tagger was described that obtained performance comparable to that of stochastic taggers, but captured relevant linguistic information in a small number of simple non-stochastic rules. In this paper, we describe a number of extensions to this rule-based tagger. First, we describe a method for expressing lexical relations in tagging that stochastic taggers are currently unable to express. Next, we show a rule-based approach to tagging unknown words. Finally, we show how the tagger can be extended into a k-best tagger, where multiple tags can be assigned to words in some cases of uncertainty. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Brill, E. </author> <year> 1992. </year> <title> A simple rule-based part of speech tagger. </title> <booktitle> In Proceedings of the Third Conference on Applied Natural Language Processing, ACL. </booktitle>
Reference-contexts: Almost all recent work in developing automatically trained part of speech taggers has been on further exploring Markov-model based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1991; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993). In <ref> (Brill 1992) </ref>, a trainable rule-based tagger is described that achieves performance comparable to that of stochastic taggers. Training this tagger is fully automated, but unlike trainable stochastic taggers, linguistic information is encoded directly in a set of simple non-stochastic rules. <p> Once an ordered list of transformations is learned, new text can be annotated by first applying the initial state annotator to it and then applying each of the learned transformations, in order. 3 As specified in a manually annotated corpus. An Earlier Tranformation-Based Tagger The original transformation-based tagger <ref> (Brill 1992) </ref> works as follows. The initial state annotator assigns each word its most likely tag as indicated in the training corpus.
Reference: <author> Brill, E. </author> <year> 1993a. </year> <title> Automatic grammar induction and parsing free text: A transformation-based approach. </title> <booktitle> In Proceedings of the 31st Meeting of the Association of Computational Linguistics. </booktitle>
Reference: <author> Brill, E. </author> <year> 1993b. </year> <title> A Corpus-Based Approach to Language Learning. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer and Information Science, University of Pennsylvania. </institution>
Reference-contexts: This approach has already been successfully applied to a system for prepositional phrase disambiguation <ref> (Brill 1993b) </ref>. Unknown Words In addition to not being lexicalized, another problem with the original transformation-based tagger was its relatively low accuracy at tagging unknown words. 10 In the initial state annotator for tagging, words are assigned their most likely tag, estimated from a training corpus. <p> The 17th learned rule fixes this problem. This rule states: change a tag from plural common noun to singular common noun if the word has suffix ss. 13 This learner has also been applied to tagging Old English. See <ref> (Brill 1993b) </ref>. training and the next 150,000 words were used for test-ing. Annotations of the test corpus were not used in any way to train the system.
Reference: <author> Charniak, E.; Hendrickson, C.; Jacobson, N.; and Perkowitz, M. </author> <year> 1993. </year> <title> Equations for part of speech tagging. </title> <booktitle> In Proceedings of the Conferenceof the American Association for Artificial Intelligence. </booktitle>
Reference: <author> Church, K. </author> <year> 1988. </year> <title> A stochastic parts program and noun phrase parser for unrestricted text. </title> <booktitle> In Proceedings of the Second Conference on Applied Natural Language Processing, ACL. </booktitle>
Reference: <author> Cutting, D.; Kupiec, J.; Pedersen, J.; and Sibun, P. </author> <year> 1992. </year> <title> A practical part-of-speech tagger. </title> <booktitle> In Proceedings of the Third Conference on Applied Natural Language Processing, ACL. </booktitle>
Reference: <author> DeMarcken, C. </author> <year> 1990. </year> <title> Parsing the lob corpus. </title> <booktitle> In Proceedings of the 1990 Conference of the Association for Computational Linguistics. </booktitle>
Reference-contexts: In <ref> (DeMarcken 1990) </ref>, the test set is included in the training set, and so it is difficult to know how this system would do on fresh text. In (Weischedel et al. 1993), a k-best tag experiment was run on the Wall Street Journal corpus.
Reference: <author> Derose, S. </author> <year> 1988. </year> <title> Grammatical category disambiguation by statistical optimization. </title> <note> Computational Linguistics 14. </note>
Reference: <author> Harris, Z. </author> <year> 1962. </year> <title> String Analysis of Language Structure. The Hague: </title> <publisher> Mouton and Co. </publisher>
Reference: <author> Jelinek, F. </author> <year> 1985. </year> <title> Markov Source modeling of text generation. Dordrecht. In Impact of Processing Techniques on Communication, </title> <editor> J. Skwirzinski, </editor> <publisher> ed. </publisher>
Reference-contexts: As large corpora became available, it became clear that simple Markov-model based stochastic taggers that were automatically trained could achieve high rates of tagging accuracy <ref> (Jelinek 1985) </ref>. Markov-model based taggers assign a sentence the tag sequence that maximizes P rob (wordjtag) fl P rob (tagjprevious n tags).
Reference: <author> Klein, S., and Simmons, R. </author> <year> 1963. </year> <title> A computational approach to grammatical coding of English words. </title> <type> JACM 10. </type>
Reference: <author> Kupiec, J. </author> <year> 1992. </year> <title> Robust part of speech tagging using a hidden markov model. </title> <booktitle> Computer Speech and Language. </booktitle>
Reference: <author> Marcus, M.; Santorini, B.; and Marcinkiewicz, M. </author> <year> 1993. </year> <title> Building a large annotated corpus of English: the Penn Treebank. </title> <note> Computational Linguistics. </note>
Reference-contexts: The second transformation arises from the fact that when a verb appears in a context such as We do n't 6 All experiments were run on the Penn Treebank tagged Wall Street Journal corpus, version 0.5 <ref> (Marcus, Santorini, & Marcinkiewicz 1993) </ref>. 7 In the Penn Treebank, n't is treated as a separate token, so don't becomes do/VB-NON3rd-SING n't/ADVERB. or We did n't usually , the verb is in base form.
Reference: <author> Merialdo, B. </author> <year> 1991. </year> <title> Tagging text with a probabilistic model. </title> <booktitle> In IEEE International Conference on Acoustics, Speech and Signal Processing. </booktitle>
Reference-contexts: A similar approach is being explored for machine translation (Su, Wu, & Chang model on a large untagged corpus (see <ref> (Merialdo 1991) </ref>). 2 The programs described in this paper can be obtained by contacting the author. 1992). Figure 1 illustrates the learning process. First, unannotated text is passed through the initial-state annotator.
Reference: <author> Miller, G. </author> <year> 1990. </year> <title> Wordnet: an on-line lexical database. </title> <journal> International Journal of Lexicography. </journal>
Reference-contexts: We are currently exploring the possibility of incorporating word classes into the rule-based learner in hopes of overcoming this problem. The idea is quite simple. Given a source of word class information, such as WordNet <ref> (Miller 1990) </ref>, the learner is extended such that a rule is allowed to make reference to parts of speech, words, and word 8 Where a star can match any part of speech tag. 9 In both (Weischedel et al. 1993) and here, the test set was incorporated into the lexicon, but
Reference: <author> Su, K.; Wu, M.; and Chang, J. </author> <year> 1992. </year> <title> A new quan-titiative quality measure for machine translation. </title> <booktitle> In Proceedings of COLING-1992. </booktitle>
Reference: <author> Weischedel, R.; Meteer, M.; Schwartz, R.; Ramshaw, L.; and Palmucci, J. </author> <year> 1993. </year> <title> Coping with ambiguity and unknown words through probabilistic models. </title> <note> Computational Linguistics. </note>
Reference-contexts: In <ref> (Weischedel et al. 1993) </ref>, results are given when training and testing a Markov-model based tagger on the Penn Treebank Tagged Wall Street Journal Corpus. They cite results making the closed vocabulary assumption that all possible tags for all words in the test set are known. <p> Given a source of word class information, such as WordNet (Miller 1990), the learner is extended such that a rule is allowed to make reference to parts of speech, words, and word 8 Where a star can match any part of speech tag. 9 In both <ref> (Weischedel et al. 1993) </ref> and here, the test set was incorporated into the lexicon, but was not used in learning contextual information. Testing with no unknown words might seem like an unrealistic test. <p> Unknown word accuracy on the test corpus was 85.0%, and overall tagging accuracy on the test corpus was 96.5%. To our knowledge, this is the highest overall tagging accuracy ever quoted on the Penn Treebank Corpus when making the open vocabulary assumption. In <ref> (Weischedel et al. 1993) </ref>, a statistical approach to tagging unknown words is shown. In this approach, a number of suffixes and important features are prespec-ified. <p> In (DeMarcken 1990), the test set is included in the training set, and so it is difficult to know how this system would do on fresh text. In <ref> (Weischedel et al. 1993) </ref>, a k-best tag experiment was run on the Wall Street Journal corpus. They quote the average number of tags per word for various threshold settings, but do not provide accuracy results.
References-found: 17

