URL: http://www.cs.pitt.edu/~berson/papers/TR94-10.ps
Refering-URL: http://www.cs.pitt.edu/~berson/papers.html
Root-URL: 
Email: (berson@cs.pitt.edu)  
Phone: Fax: (412) 624-5249  
Title: in URSA  
Author: David A. Berson Rajiv Gupta Mary Lou Soffa 
Date: February 1994  
Address: Pittsburgh Pittsburgh, PA 15260  Pittsburgh  
Affiliation: Department of Computer Science University of  University of  
Note: Representing Architecture Constraints  Partially supported by National Science Foundation Presidential Young Investigator Award CCR-9157371 and Grant CCR 91090809 to the  
Abstract: Technical Report 94-10 
Abstract-found: 1
Intro-found: 1
Reference: [AGL93] <author> A. Adl-Tabatabai, T. Gross, G. Lueh and J. Reinders, </author> <title> Modelling Instruction-Level Parallelism for Software Pipelining, </title> <booktitle> Proc. IFIP WG 10.3 Working Conference on Architectures and Compliation Techniques for Fine and Medium Grain Parallelism, </booktitle> <address> Orlando, Florida, </address> <month> Jan. </month> <year> 1993, </year> <pages> pp. 321-330. </pages>
Reference-contexts: The information computed by this algorithm is used in extending URSA so that the pipeline interlock information is used when deciding how to allocate resources effectively. In some instruction sets, particular instructions implicitly make use of specific registers <ref> [AGL93] </ref>. To make efficient use of all registers, compilers for these architectures must identify the live ranges that result from these implicit uses. The live ranges must be considered during both allocation and assignment. <p> The assignment phase must make sure that the implicitly used registers do not contain another live value when an implicit use instruction is executed. Previous work has shown how to handle implicit uses <ref> [AGL93] </ref>. However, the work does not integrate register allocation with instruction scheduling. Representing the problem in URSA permits such an integration. URSA also allows the concept of implicit uses to be extended to any resource implicitly required by an instruction. <p> The tasks of scheduling separate types of functional units are 1 relatively independent of each other. However, some architectures support instructions that can be executed on any one of several types of functional units <ref> [AGL93] </ref>. This increases the interaction between the scheduling tasks. For each generic instruction the scheduling phase must decide which type of functional unit it should be executed on to minimize the schedule's total time. <p> As with implicit uses, previous work has shown how to handle this problem, but not in a manner that allows integration of instruction scheduling and register allocation <ref> [AGL93] </ref>. The previous method creates an additional generic functional unit, such that non-generic instructions require both a normal functional unit and a generic functional unit while a generic instruction requires only a generic functional unit. Our extension to URSA uses a similar approach, but in a unified resource allocation environment. <p> For example, some architectures allow moves to be performed by either integer or floating point functional units. Instructions that can be executed by one of several types of functional units are called generic instructions <ref> [AGL93] </ref>. The technique in this paper generalizes this concept to generic requirements for resources; an instruction may have specific register type requirements but generic functional unit type requirements, or vise versa. Generic requirements should be scheduled on whatever compatible resource is available.
Reference: [AiN88] <author> A. Aiken and A. Nicolau, </author> <title> A Development Environment for Horizontal Microcode, </title> <journal> IEEE Trans. on Software Engineering 14 , 5(May 1988) pp. </journal> <pages> 584-594. </pages>
Reference-contexts: The increased useful idle time may be put to use by URSA's reduction transformations or migration of parallel instructions across DAG boundaries as performed by percolation scheduling <ref> [AiN88] </ref>, region scheduling [GuS90], Resource Spackling [BGS94], or other global scheduling methods [BeR91, SHL92].
Reference: [BeR91] <author> D. Bernstein and M. Rodeh, </author> <title> Global Instruction Scheduling for Superscalar Machines, </title> <booktitle> Proc. Sigplan '91 Conf. on Programming Language Design and Implementation, </booktitle> <address> Toronto, Ontario, Canada, </address> <month> June 26-28, </month> <year> 1991, </year> <pages> pp. 241-255. </pages>
Reference-contexts: The increased useful idle time may be put to use by URSA's reduction transformations or migration of parallel instructions across DAG boundaries as performed by percolation scheduling [AiN88], region scheduling [GuS90], Resource Spackling [BGS94], or other global scheduling methods <ref> [BeR91, SHL92] </ref>. The minimum increase path algorithm can be augmented to minimize the weights of non-increasing edges by using length (u; v) as secondary key in the priority queue and adding the shortest path relaxation logic to Relax Minimum Increase () when v.max = new max.
Reference: [BGS92] <author> D. A. Berson, R. Gupta and M. L. Soffa, </author> <title> URSA: A Unified ReSource Allocator for Registers and Functional Units in VLIW Architectures, </title> <type> Technical Report 92-21, </type> <institution> University of Pittsburgh, Computer Science Department, </institution> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: Reuse F U DAG's can be computed in O (N 3 ) time, where N is the number of nodes in the program DAG. However computing a Reuse Reg DAG that represents maximum register parallelism has been shown to be NP-Complete <ref> [BGS92] </ref>. Reasonable heuristics that require O (N 3 ) time can be used, resulting in possibly finding less than the maximum number of register allocation chains required. 2.2 Reducing Resource Requirements URSA's transformations remove excess requirements by sequencing separate allocations.
Reference: [BGS93] <author> D. A. Berson, R. Gupta and M. L. Soffa, </author> <title> URSA: A Unified ReSource Allocator for Registers and Functional Units in VLIW Architectures, </title> <booktitle> Proc. IFIP WG 10.3 Working Conference on Architectures and Compliation Techniques for Fine and Medium Grain Parallelism, </booktitle> <address> Orlando, Florida, </address> <month> Jan. </month> <year> 1993, </year> <pages> pp. 243-254. </pages>
Reference-contexts: In addition, it can incorporate a new algorithm for assigning instructions on pipelined multiple issue architectures. URSA addresses the well known interactions between the instruction scheduling and register allocation phases of a compiler by creating a unified technique that uses a single representation of resource requirements for both problems <ref> [BGS93] </ref>. This representation allows both tasks to be performed concurrently, taking into account the impact of potential allocation decisions on each other and on the overall execution time of the program being compiled. The technique uses a representation of resource instance reuses that allows resource requirements to be measured. <p> Section 4 discusses techniques to model architecture restrictions as resource requirements used by URSA. Finally, section 5 summarizes the contribution of this work. 2 URSA This section presents an overview of URSA, a previously developed technique that measures and removes excess resource requirements in programs being compiled <ref> [BGS93] </ref>. In URSA each sequential section of code is represented as Directed Acyclic Graph (DAG) which shows all semantically correct schedules. URSA considers resource requirements, including functional units and registers. Functional unit requirements correspond to maximum parallelism. Register requirements represent the maximum number of registers required to support the parallelism.
Reference: [BGS94] <author> D. A. Berson, R. Gupta and M. L. Soffa, </author> <title> Resource Spackling: A Framework for Integrating Register Allocation in Local and Global Schedulers, </title> <booktitle> Proc. IFIP WG 10.3 Working Conference on Parallel Architectures and Compilation Techniques, </booktitle> <address> Montreal, Canada, </address> <month> Aug. 24-26 </month> <year> 1994, </year> <pages> pp. 135-146. </pages>
Reference-contexts: The increased useful idle time may be put to use by URSA's reduction transformations or migration of parallel instructions across DAG boundaries as performed by percolation scheduling [AiN88], region scheduling [GuS90], Resource Spackling <ref> [BGS94] </ref>, or other global scheduling methods [BeR91, SHL92].
Reference: [BEH91] <author> D. G. Bradlee, S. J. Eggers and R. R. Henry, </author> <title> Integrating Register Allocation and Instruction Scheduling for RISCs, </title> <booktitle> Proc. Fourth International Conf. on ASPLOS, </booktitle> <address> Santa Clara, CA, </address> <month> April 8-11, </month> <year> 1991, </year> <pages> pp. 122-131. </pages>
Reference-contexts: The effectiveness of instruction pipelining is limited by dependences introduced by register reuse and competition for pipeline stages. Previous work has addressed this problem by code reordering [GiM86, HeG83] and integration of the separate phases of instruction scheduling and register allocation <ref> [BEH91, GoH88] </ref>. Pipelined multiple issue architectures introduce more complexity in scheduling as an instruction being scheduled may need to wait for values from several currently executing instructions.
Reference: [Dil50] <author> R. P. </author> <title> Dilworth, A Decomposition Theorem for Partially Ordered Sets, </title> <booktitle> Annuals of Mathematics 51 (1950) pp. </booktitle> <pages> 161-166. </pages>
Reference-contexts: The decomposition is also one of the minimal decompositions. Previous results show that the number of chains in a minimum chain decomposition of a partial order is exactly equal to the maximum amount of parallelism in that partial order <ref> [Dil50] </ref>. Thus, since a minimal decomposition of the DAG in Figure 1 (b) has four chains, the sequential code in Figure 1 (a) requires four functional units to exploit all of its parallelism.
Reference: [Fis81] <author> J. A. Fisher, </author> <title> Trace Scheduling: A Technique for Global Microcode Compaction, </title> <journal> IEEE Trans. on Computers C-30 , 7(July 1981) pp. </journal> <pages> 478-490. </pages>
Reference-contexts: URSA separates the allocation and assignment of resources. The allocation is performed using a Measure and Reduce paradigm. URSA operates on a partial order corresponding to the DAG representation of a sequential section of code, e.g., a trace <ref> [Fis81] </ref> or basic block. The partial order allows the measurement of the maximum number of each type of resource needed. To obtain these measures, URSA assumes that the DAG is scheduled to maximize exploitation of that resource's parallelism.
Reference: [FoF65] <author> L. R. Ford and D. R. Fulkerson, </author> <title> Flows in Networks, </title> <publisher> Princeton University Press, </publisher> <address> Princeton, N.J., </address> <year> 1965. </year>
Reference-contexts: A minimum decomposition of a partial order can be found by using a straightforward transformation to a bipartite graph matching problem <ref> [FoF65] </ref>. URSA measures requirements for each resource R by finding a minimal decomposition of a Reuse R DAG, representing a partial order. The chains in the decomposition are called allocation chains. Functional unit and register reuse DAGs are denoted as Reuse F U DAG and Reuse Reg DAG respectively. <p> The minimum value returned is 1, indicating that B can be issued on the next cycle after issuing A. The problem of assigning of functional units to a set of instructions can be modeled as a weighted bipartite matching problem <ref> [FoF65] </ref>. One set of nodes represents the functional units and the other represents the instructions. Edges are added between all pairs of functional unit and instruction nodes. Each edge is weighted with the cost of assigning the instruction to the functional unit.
Reference: [GiM86] <author> P. B. Gibbons and S. S. Muchnick, </author> <title> Efficient Instruction Scheduling for Pipelined Architectures, </title> <booktitle> Proc. Sigplan '86 Symp. on Compiler Construction Sigplan Notices 21 , 7(July 1986) pp. </booktitle> <pages> 11-16. </pages>
Reference-contexts: This technique can be used either in a single issue instruction architecture or in a multiple issue architectures such as superscalar architectures. The effectiveness of instruction pipelining is limited by dependences introduced by register reuse and competition for pipeline stages. Previous work has addressed this problem by code reordering <ref> [GiM86, HeG83] </ref> and integration of the separate phases of instruction scheduling and register allocation [BEH91, GoH88]. Pipelined multiple issue architectures introduce more complexity in scheduling as an instruction being scheduled may need to wait for values from several currently executing instructions.
Reference: [GoH88] <author> J. R. Goodman and W. Hsu, </author> <title> Code Scheduling and Register Allocation in Large Basic Blocks, </title> <booktitle> Proc. of the ACM Supercomputing Conference, </booktitle> <year> 1988, </year> <pages> pp. 442-452. </pages>
Reference-contexts: The effectiveness of instruction pipelining is limited by dependences introduced by register reuse and competition for pipeline stages. Previous work has addressed this problem by code reordering [GiM86, HeG83] and integration of the separate phases of instruction scheduling and register allocation <ref> [BEH91, GoH88] </ref>. Pipelined multiple issue architectures introduce more complexity in scheduling as an instruction being scheduled may need to wait for values from several currently executing instructions.
Reference: [GuS90] <author> R. Gupta and M. L. Soffa, </author> <title> Region Scheduling: An Approach for Detecting and Redistributing Parallelism, </title> <journal> IEEE Trans. on Software Engineering 16 , 4(April 1990) pp. </journal> <pages> 421-431. </pages>
Reference-contexts: The increased useful idle time may be put to use by URSA's reduction transformations or migration of parallel instructions across DAG boundaries as performed by percolation scheduling [AiN88], region scheduling <ref> [GuS90] </ref>, Resource Spackling [BGS94], or other global scheduling methods [BeR91, SHL92].
Reference: [HeG83] <author> J. L. Hennessy and T. Gross, </author> <title> Postpass Code Optimization of Pipeline Constraints, </title> <journal> ACM Trans. Prog. Lang. and Systems 5 , 3(July 1983) pp. </journal> <pages> 422-448. 12 </pages>
Reference-contexts: This technique can be used either in a single issue instruction architecture or in a multiple issue architectures such as superscalar architectures. The effectiveness of instruction pipelining is limited by dependences introduced by register reuse and competition for pipeline stages. Previous work has addressed this problem by code reordering <ref> [GiM86, HeG83] </ref> and integration of the separate phases of instruction scheduling and register allocation [BEH91, GoH88]. Pipelined multiple issue architectures introduce more complexity in scheduling as an instruction being scheduled may need to wait for values from several currently executing instructions.
Reference: [SHL92] <author> M. D. Smith, M. Horowitz and M. Lam, </author> <title> Efficient Superscalar Performance Through Boosting, </title> <booktitle> Proc. 5th International Conf. on ASPLOS, </booktitle> <address> Boston, Massachusetts, </address> <month> Oct. </month> <pages> 12-15, </pages> <year> 1992, </year> <pages> pp. 248-259. </pages>
Reference-contexts: The increased useful idle time may be put to use by URSA's reduction transformations or migration of parallel instructions across DAG boundaries as performed by percolation scheduling [AiN88], region scheduling [GuS90], Resource Spackling [BGS94], or other global scheduling methods <ref> [BeR91, SHL92] </ref>. The minimum increase path algorithm can be augmented to minimize the weights of non-increasing edges by using length (u; v) as secondary key in the priority queue and adding the shortest path relaxation logic to Relax Minimum Increase () when v.max = new max.
Reference: [Tar83] <author> R. E. Tarjan, </author> <title> Data Structures and Network Algorithms, </title> <institution> Society for Industrial and Applied Mathematics, </institution> <year> 1983. </year> <month> 13 </month>
Reference-contexts: The solution has the same form as the minimum weighted matching solution; only a supporting procedure and cost function need to be modified. In these algorithms, the matching problem is represented as a network flow problem with each edge in the bipartite graph having unit flow <ref> [Tar83] </ref>. The function length () as defined above is used as the basis for the cost function for the edges. The minimum weighted matching algorithm operates by finding a shortest path to any unmatched node t 2 T for each node s 2 S.
References-found: 16

