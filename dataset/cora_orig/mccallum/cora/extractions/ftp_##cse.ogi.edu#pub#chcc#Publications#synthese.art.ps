URL: ftp://cse.ogi.edu/pub/chcc/Publications/synthese.art.ps
Refering-URL: http://www.cse.ogi.edu/CHCC/Publications/text.html
Root-URL: http://www.cse.ogi.edu
Title: On Team Formation  
Author: Philip R. Cohen Hector J. Levesque and Ira Smith 
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> K. Bach and R. Harnish. </author> <title> Linguistic Communication and Speech Acts. </title> <editor> M. I. T. </editor> <publisher> Press, </publisher> <address> Cam-bridge, Massachusetts, </address> <year> 1979. </year>
Reference-contexts: In our case, we have used this method to show how our earlier definitions subsume many of the properties of illocutionary acts described by philosophers of language (e.g., <ref> [1, 34, 37] </ref>). However, because of the fine-grainedness of the logical operators, the logic can often make distinctions that others cannot. <p> We claim that a request followed by a commissive action should result in a joint commitment's being formed. It is important to notice that the classical definitions of requesting (e.g, those in <ref> [1, 34, 37] </ref>), our earlier definition [11] and those of other computer scientists [27, 29], do not have this property.
Reference: [2] <author> M. Bratman. </author> <title> Intentions, Plans, and Practical Reason. </title> <publisher> Harvard University Press, </publisher> <year> 1987. </year>
Reference-contexts: How do joint intentions to perform complex actions lead to appropriate intentions to perform the pieces? Assuming that an agent will only intend to do her own actions, what is her attitude towards the others' share? The functional role of joint intentions: Bratman <ref> [2] </ref> has argued that in the case of individuals, intentions play certain functional roles: they pose problems for agents, which can be solved by means-end analysis; they rule out the adoption of intentions that conflict with existing ones; they dispose agents to monitor their attempts to achieve them; and, barring major <p> Although agents can commit to other's actions, they do not intend them, as we will see shortly. 3 This definition differs slightly from that presented in our earlier work [8], but that difference is immaterial here. 7 3.2 Individual Intention We adopt Bratman's <ref> [2] </ref> methodological concern for treating the future-directed properties of intention as primary, and the intention-in-action properties as secondary, contra Searle [35, 36]. <p> In our earlier paper [8], we also show how this analysis of intention satisfies Bratman's <ref> [2, 3] </ref> functional roles for intentions and solves his "package deal" problem, by not requiring agents also to intend the known side-effects of their intended actions, despite our possible-world account of belief and goal.
Reference: [3] <author> M. Bratman. </author> <title> What is intention? In P. </title> <editor> R. Cohen, J. Morgan, and M. E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: In our earlier paper [8], we also show how this analysis of intention satisfies Bratman's <ref> [2, 3] </ref> functional roles for intentions and solves his "package deal" problem, by not requiring agents also to intend the known side-effects of their intended actions, despite our possible-world account of belief and goal. <p> Such a commitment to Y 's action means that X will screen out incompatible options <ref> [3] </ref>, track the success of the commitment, etc. Thus, merely by requesting Y to do something, X has committed resources, and has taken on the need to communicate should his attitude towards the action change.
Reference: [4] <author> M. E. Bratman. </author> <title> Shared cooperative activity. </title> <journal> Philosophical Review, </journal> <volume> 101 </volume> <pages> 327-341, </pages> <year> 1992. </year>
Reference-contexts: In support of these mutual commitments, teams involve an inherent overhead | in establishing, monitoring, and disbanding the team. A theory of joint action therefore needs to explain how this occurs. Unfortunately, although there are numerous analyses of joint action in the literature (e.g, <ref> [4, 12, 19, 18, 44, 43, 36] </ref> how agents in fact form and disband teams is rarely discussed. In some cases, it is suggested that joint activities are formed by "agreements," but that concept is left relatively unformalized. <p> goal. * The agent believes that p is true, will never be true, or is irrelevant (that is, q is false), but has as a persistent* goal that the status of p be mutually believed by all the team members. 11 In response to our criticism to this effect, Bratman <ref> [4] </ref> postulated an intends that * operator that allows an agent to intend that another agent act. Grosz and Kraus [19] base their theoretical apparatus on this concept. <p> Much of the analysis rests on the introduction of the new and controversial intends-that operator (following <ref> [4] </ref>) that is used to characterize one agent's attitude towards another's or a group's actions or plans.
Reference: [5] <author> H. H. Clark and C. Marshall. </author> <title> Definite reference and mutual knowledge. In Elements of Discourse Understanding. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: We now turn to the problem of showing how agents can form and discharge these joint commitments and intentions. Although the conditions proposed in the analysis rely on mutual belief, strictly speaking, there are ways to acquire mutual beliefs without explicit speech acts (see <ref> [5, 28, 31] </ref>), such as circumstances in which agents are copresent and can observe one another. However, we will primarily be concerned here with mutual belief acquired via explicit communication.
Reference: [6] <author> P. R. Cohen. </author> <title> On Knowing what to Say: Planning Speech Acts. </title> <type> PhD thesis, </type> <institution> University of Toronto, Toronto, Canada, </institution> <month> January </month> <year> 1978. </year> <type> Technical Report No. 118, </type> <institution> Department of Computer Science. </institution>
Reference-contexts: It is also useful to define (linear) temporal expressions from these action expressions, such as a proposition's being eventually, always, or never true henceforth; similar expressions can be 2 A fixed point definition is given in [8], and a circular data structure for encoding mutual beliefs is described in <ref> [6] </ref>. defined for the past.
Reference: [7] <author> P. R. Cohen, M. Johnston, D. McGee, S. L. Oviatt, J. Pittman, L. Chen, and J. Clow. Quickset: </author> <title> Multimodal interaction for simulation set-up and control. </title> <booktitle> In Proceedings of the Fifth Applied Natural Language Processing Conference, Association for Computational Linguistics, </booktitle> <address> Washington, D. C., </address> <month> April </month> <year> 1997. </year>
Reference-contexts: In fact, computer systems are being designed to support simultaneously human-human collaboration and teamwork, human-computer interaction, and interactions among artificial agents <ref> [7] </ref>. Building a robust and reliable system that incorporates these three components requires a single model of collaboration and teamwork.
Reference: [8] <author> P. R. Cohen and H. J. Levesque. </author> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> 42(3), </volume> <year> 1990. </year>
Reference-contexts: In particular, we redefine directive actions such that they support team formation. Finally, we then show how these communicative actions can be used to form and disband teams. 2 Joint actions | collective actions by agents who share a joint intention In our previous work <ref> [8] </ref>, we have presented a belief-goal-commitment model of the mental states of individuals in which intentions are specified not as primitive mental features, but as internal commitments to perform an action while in a certain mental state. <p> Moreover, it is this divergence among the agents that makes communication necessary. Whereas the model of individual intention in our earlier work <ref> [8, 10] </ref> was sufficient to show how communicative acts were defined in terms of beliefs and intentions, and could be used to achieve various goals, it did so only from the perspective of each individual agent, by constraining the rational balance that agents maintain among their own beliefs, goals, commitments, intentions, <p> To see this in detail, we first briefly describe our analysis of individual commitment and intention, and then discuss the joint case. 3 Individual Commitment and Intention Our formal account of individual and joint commitments and intentions <ref> [8, 26] </ref> is given in terms of beliefs, mutual beliefs, goals, and events. In this paper, we will not present the formal language, but simply describe its features in general terms. <p> It is also useful to define (linear) temporal expressions from these action expressions, such as a proposition's being eventually, always, or never true henceforth; similar expressions can be 2 A fixed point definition is given in <ref> [8] </ref>, and a circular data structure for encoding mutual beliefs is described in [6]. defined for the past. <p> Although agents can commit to other's actions, they do not intend them, as we will see shortly. 3 This definition differs slightly from that presented in our earlier work <ref> [8] </ref>, but that difference is immaterial here. 7 3.2 Individual Intention We adopt Bratman's [2] methodological concern for treating the future-directed properties of intention as primary, and the intention-in-action properties as secondary, contra Searle [35, 36]. <p> In our earlier paper <ref> [8] </ref>, we also show how this analysis of intention satisfies Bratman's [2, 3] functional roles for intentions and solves his "package deal" problem, by not requiring agents also to intend the known side-effects of their intended actions, despite our possible-world account of belief and goal. <p> Similarly, if one agent believes the other's action is impossible, he can drop the joint commitment even though he is left with the residual commitment to attain mutual belief of impossibility. These and other properties of the definition of joint intention are described in <ref> [8, 12] </ref>. <p> Of course, due care needs to be taken with "quantifying into" the various mental states involved in the joint intention definition. The interested reader is referred to <ref> [8, 12] </ref> for more details.
Reference: [9] <author> P. R. Cohen. and H. J. Levesque. </author> <title> Performatives in a rationally based speech act theory. </title> <booktitle> In Pro--ceedings of the 28th Annual Meeting, Association for Computational Linguistics, </booktitle> <address> Pittsburgh, Pennsylvania, </address> <year> 1990. </year>
Reference-contexts: Although problems of natural language interpretation are important to our research program (e.g, see [10]), they shall be ignored here. Rather, we will assume communication takes place by way of performative utterances <ref> [9] </ref>. Thus, we assume every communicative act specifies what type of act it is, which is typical for artificial agent communication languages (e.g., KQML [15]). In other work [9], we have demonstrated how the present analysis supports a precise theory of natural language performatives. <p> Rather, we will assume communication takes place by way of performative utterances <ref> [9] </ref>. Thus, we assume every communicative act specifies what type of act it is, which is typical for artificial agent communication languages (e.g., KQML [15]). In other work [9], we have demonstrated how the present analysis supports a precise theory of natural language performatives.
Reference: [10] <author> P. R. Cohen and H. J. Levesque. </author> <title> Rational interaction as the basis for communication. </title> <editor> In P. R. Cohen, J. Morgan, and M. E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: Moreover, it is this divergence among the agents that makes communication necessary. Whereas the model of individual intention in our earlier work <ref> [8, 10] </ref> was sufficient to show how communicative acts were defined in terms of beliefs and intentions, and could be used to achieve various goals, it did so only from the perspective of each individual agent, by constraining the rational balance that agents maintain among their own beliefs, goals, commitments, intentions, <p> Although problems of natural language interpretation are important to our research program (e.g, see <ref> [10] </ref>), they shall be ignored here. Rather, we will assume communication takes place by way of performative utterances [9]. Thus, we assume every communicative act specifies what type of act it is, which is typical for artificial agent communication languages (e.g., KQML [15]). <p> With these assumptions, if it is mutually believed that a message was received, it is mutually believed that the named action took place. Methodologically speaking, we have elsewhere provided definitions of illocutionary acts as action expressions in the dynamic logic described in this paper <ref> [10] </ref>. Given an event sequence, multiple actions could be said to have been performed (and thus we side with Davidson [14] in analyzing action sentences). But, as argued by Sadock [32], pragmatics is too easy. That is, there are few constraints on what constitutes an illocutionary act definition. <p> Thus, this work considers topics that we have not | specifically, we do not treat the first and third of these steps. However, regarding team formation, although the authors state that the formation of the team is done by communicative actions in the style of <ref> [10] </ref>, the specific speech act definitions are not provided. In [24] Kinny et al. present a formulation of joint intentions in the BDI logic framework.
Reference: [11] <author> P. R. Cohen and H. J. Levesque. </author> <booktitle> Confirmations and joint action. In Proceedings of the 12th International Joint Conference on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, California, </address> <month> August </month> <year> 1991, </year> <pages> pp. 951-957. </pages>
Reference-contexts: We claim that a request followed by a commissive action should result in a joint commitment's being formed. It is important to notice that the classical definitions of requesting (e.g, those in [1, 34, 37]), our earlier definition <ref> [11] </ref> and those of other computer scientists [27, 29], do not have this property.
Reference: [12] <author> P. R. Cohen and H. J. Levesque. </author> <title> Teamwork. </title> <journal> No^us, </journal> <volume> 25(4) </volume> <pages> 487-512, </pages> <year> 1991. </year> <note> Also Technical Note 504, Artificial Intelligence Center, </note> <institution> SRI International, </institution> <address> Menlo Park, California, </address> <year> 1991. </year>
Reference-contexts: In support of these mutual commitments, teams involve an inherent overhead | in establishing, monitoring, and disbanding the team. A theory of joint action therefore needs to explain how this occurs. Unfortunately, although there are numerous analyses of joint action in the literature (e.g, <ref> [4, 12, 19, 18, 44, 43, 36] </ref> how agents in fact form and disband teams is rarely discussed. In some cases, it is suggested that joint activities are formed by "agreements," but that concept is left relatively unformalized. <p> Similarly, if one agent believes the other's action is impossible, he can drop the joint commitment even though he is left with the residual commitment to attain mutual belief of impossibility. These and other properties of the definition of joint intention are described in <ref> [8, 12] </ref>. <p> Of course, due care needs to be taken with "quantifying into" the various mental states involved in the joint intention definition. The interested reader is referred to <ref> [8, 12] </ref> for more details. <p> We then agree (in a different sense) with Tuomela on the examples so far, but leave open the possibility that joint intentions can be formed when the appropriate mutual beliefs are in force, without stating how they came to be operative. Finally, in <ref> [12] </ref>, we pointed out that all analyses of joint intention based on mutual belief fall apart as soon as one of the agents doubts the commitment of the others, or believes privately that the joint action is impossible, irrelevant, or satisfied, etc.
Reference: [13] <author> P. R. Cohen and H. J. Levesque. </author> <title> Communicative actions for artificial agents. </title> <booktitle> In Proceedings of the International Conference on Multiagent Systems, </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, California, </address> <year> 1995. </year>
Reference-contexts: Finally, analyses of how communicative actions can be used to establish and discharge joint intentions can have an impact on the design of interagent communication languages for the Internet <ref> [13, 39] </ref>. In fact, computer systems are being designed to support simultaneously human-human collaboration and teamwork, human-computer interaction, and interactions among artificial agents [7]. Building a robust and reliable system that incorporates these three components requires a single model of collaboration and teamwork.
Reference: [14] <author> D. Davidson. </author> <title> Actions, reasons, and causes. </title> <editor> In A. R. White, editor, </editor> <booktitle> The Philosophy of Action. </booktitle> <publisher> Oxford University Press, </publisher> <year> 1968. </year>
Reference-contexts: Methodologically speaking, we have elsewhere provided definitions of illocutionary acts as action expressions in the dynamic logic described in this paper [10]. Given an event sequence, multiple actions could be said to have been performed (and thus we side with Davidson <ref> [14] </ref> in analyzing action sentences). But, as argued by Sadock [32], pragmatics is too easy. That is, there are few constraints on what constitutes an illocutionary act definition.
Reference: [15] <author> T. Finin, R. Fritzson, D. McKay, and R. McEntire. </author> <title> KQML as an agent communication language. </title> <booktitle> In Proceedings of the Third International Conference on Information and Knowledge Management (CIKM'94), </booktitle> <publisher> ACM Press, </publisher> <address> New York, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Rather, we will assume communication takes place by way of performative utterances [9]. Thus, we assume every communicative act specifies what type of act it is, which is typical for artificial agent communication languages (e.g., KQML <ref> [15] </ref>). In other work [9], we have demonstrated how the present analysis supports a precise theory of natural language performatives.
Reference: [16] <author> A. I. Goldman. </author> <title> A Theory of Human Action. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, New Jersey, </address> <year> 1970. </year>
Reference-contexts: The axiomatic analysis in GK concentrates on characterizing shared plans both partial and full. The action specification language follows Goldman's <ref> [16] </ref> and Pollack's [30], and is targeted at hierarchical composition, especially how one action contributes to the performance of another.
Reference: [17] <author> H. P. Grice. </author> <title> Meaning. </title> <journal> Philosophical Review, </journal> <volume> 66 </volume> <pages> 377-388, </pages> <year> 1957. </year>
Reference-contexts: Y 's response could then establish a true joint commitment/intention, or could let X off the hook. To see how, we need at least one more basic communicative action, assertion. 12 This intention (labeled 1 in the definition) is satisfied in fashion reminiscent of Grice <ref> [17] </ref> and Schiffer [33] in that it is satisfied by the mutual recognition that it held. 16 5.3 Assertion Definition 8 An assertion using event e from speaker Y to X that p is true is defined to be: An attempt using event e by Y to X , where 1.
Reference: [18] <author> B. Grosz and C. Sidner. </author> <title> Plans for discourse. </title> <editor> In P. R. Cohen, J. Morgan, and M. E. Pollack, editors, </editor> <title> Intentions in Communication, </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990, </year> <pages> pp. 417-444. </pages>
Reference-contexts: In support of these mutual commitments, teams involve an inherent overhead | in establishing, monitoring, and disbanding the team. A theory of joint action therefore needs to explain how this occurs. Unfortunately, although there are numerous analyses of joint action in the literature (e.g, <ref> [4, 12, 19, 18, 44, 43, 36] </ref> how agents in fact form and disband teams is rarely discussed. In some cases, it is suggested that joint activities are formed by "agreements," but that concept is left relatively unformalized.
Reference: [19] <author> B. J. Grosz and S. Kraus. </author> <title> Collaborative plans for complex group action. </title> <journal> Artificial Intelligence, </journal> <volume> 86(2), </volume> <month> October </month> <year> 1996. </year>
Reference-contexts: In support of these mutual commitments, teams involve an inherent overhead | in establishing, monitoring, and disbanding the team. A theory of joint action therefore needs to explain how this occurs. Unfortunately, although there are numerous analyses of joint action in the literature (e.g, <ref> [4, 12, 19, 18, 44, 43, 36] </ref> how agents in fact form and disband teams is rarely discussed. In some cases, it is suggested that joint activities are formed by "agreements," but that concept is left relatively unformalized. <p> Grosz and Kraus <ref> [19] </ref> base their theoretical apparatus on this concept. However,the semantics of intends-that, as well its relationship to commitment, remain murky. 15 5.2.1 Request We are now finally in position to define a request. <p> Thus, perhaps the present analysis is elaborating what was meant in [43] in more precise terms. Grosz and Kraus <ref> [19] </ref> (hereafter, GK) develop an elaborate axiomatic theory of collaborative plans based on a four-fold distinction among intentions intending to do a complex action, intending that a proposition be true, and potential intentions to do actions or achieve propositions.
Reference: [20] <author> J. Y. Halpern and Y. O. Moses. </author> <title> Knowledge and common knowledge in a distributed environment. </title> <booktitle> In Proceedings of the 3rd ACM Conference on Principles of Distributed Computing, </booktitle> <address> New York City, New York, </address> <year> 1984. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: These clauses also will prevent a convoy member from simply being abandoned by the rest of the convoy if she is forced to stop due to mechanical 6 For readers familiar with the results in distributed systems theory <ref> [20] </ref> in which it is shown that mutual knowledge is impossible to obtain for computers by simply passing messages, we point out that those results do not hold for mutual beliefs acquired by default, nor for agents that can be co-present or communicate instantly. 7 Actually, agents do have the option
Reference: [21] <author> D. Harel. </author> <title> First-Order Dynamic Logic. </title> <publisher> Springer-Verlag, </publisher> <address> New York City, New York, </address> <year> 1979. </year>
Reference-contexts: These dynamic logic primitives are sufficient to form a significant class of complex actions, such as the "if-then-else" and "while-loops" familiar from computer science <ref> [21] </ref>. In all cases, the agents of the action in question are taken to be the set of agents of any of the primitive events that constitute the performance of the action.
Reference: [22] <author> N. R. Jennings. </author> <title> Commitments and conventions: The foundation of coordination in multi-agent systems. </title> <journal> The Knowledge Engineering Review, </journal> <volume> 8(3) </volume> <pages> 223-250, </pages> <year> 1993. </year> <month> 23 </month>
Reference-contexts: Human-computer interaction may profitably be regarded as human-computer collaboration [38], and theories of collaboration can help to provide new mechanisms for supporting human collaboration. In the field of artificial intelligence, there are numerous attempts to build multiagent systems that can be said to collaborate <ref> [23, 22, 40] </ref>. For example, Jennings and Mamdani [23] have shown that the present analysis can be used to specify and guide the design of a multiagent system for electric power managment, in which grid-diagnostic agents share a joint intention.
Reference: [23] <author> N. R. Jennings and E. H. Mamdani. </author> <title> Using joint responsibility to coordinate collaborative problem solving in dynamic environments. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <publisher> AAAI Press/MIT Press, </publisher> <address> Menlo Park, California, </address> <month> July </month> <year> 1992, </year> <pages> pp. 269-275. </pages>
Reference-contexts: Human-computer interaction may profitably be regarded as human-computer collaboration [38], and theories of collaboration can help to provide new mechanisms for supporting human collaboration. In the field of artificial intelligence, there are numerous attempts to build multiagent systems that can be said to collaborate <ref> [23, 22, 40] </ref>. For example, Jennings and Mamdani [23] have shown that the present analysis can be used to specify and guide the design of a multiagent system for electric power managment, in which grid-diagnostic agents share a joint intention. <p> In the field of artificial intelligence, there are numerous attempts to build multiagent systems that can be said to collaborate [23, 22, 40]. For example, Jennings and Mamdani <ref> [23] </ref> have shown that the present analysis can be used to specify and guide the design of a multiagent system for electric power managment, in which grid-diagnostic agents share a joint intention.
Reference: [24] <author> D. Kinny, M. Ljungberg, A. Rao, E. Sonenberg, G. Tidhar, and E. Werner. </author> <title> Planned team activity. </title> <booktitle> In Artificial Social Systems, Lecture Notes in Computer Science 830. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: However, regarding team formation, although the authors state that the formation of the team is done by communicative actions in the style of [10], the specific speech act definitions are not provided. In <ref> [24] </ref> Kinny et al. present a formulation of joint intentions in the BDI logic framework. Their definition of join intentions require that each team member to have the intention and that there be mutual belief among the team members that all have the proper intentions.
Reference: [25] <author> H. J. Levesque. </author> <title> A logic of implicit and explicit belief. </title> <booktitle> In Proceedings of the National Conference of the American Association for Artificial Intelligence, </booktitle> <address> Austin, Texas, </address> <year> 1984. </year>
Reference-contexts: This account of the attitudes suffers from the usual possible-world problem of logical omniscience (see <ref> [25] </ref>, for example), but we will ignore that difficulty here. We assume positive introspection for belief and goal, Moreover, we will take knowledge simply (and simplistically) to be true belief, and mutual knowledge to be true mutual belief.
Reference: [26] <author> H. J. Levesque, P. R. Cohen, and J. Nunes. </author> <title> On acting together. </title> <booktitle> In Proceedings of AAAI-90, </booktitle> <address> San Mateo, California, July 1990. </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: To see this in detail, we first briefly describe our analysis of individual commitment and intention, and then discuss the joint case. 3 Individual Commitment and Intention Our formal account of individual and joint commitments and intentions <ref> [8, 26] </ref> is given in terms of beliefs, mutual beliefs, goals, and events. In this paper, we will not present the formal language, but simply describe its features in general terms. <p> This property is captured by the following theorem, taken from our earlier work <ref> [26] </ref>. <p> an unknown part), 8 The normality conditions referred to here are merely that once the agent comes to a belief about the final status of the goal, she does not change her mind before arriving at a mutual belief with the others. 9 A more precise version of this definition <ref> [26] </ref> also requires that they mutually know when they started. 12 using existential quantification over events. Of course, due care needs to be taken with "quantifying into" the various mental states involved in the joint intention definition. The interested reader is referred to [8, 12] for more details.
Reference: [27] <author> D. J. Litman and J. F. Allen. </author> <title> A plan recognition model for subdialogues in conversation. </title> <journal> Cognitive Science, </journal> <volume> 11 </volume> <pages> 163-200, </pages> <year> 1987. </year>
Reference-contexts: We claim that a request followed by a commissive action should result in a joint commitment's being formed. It is important to notice that the classical definitions of requesting (e.g, those in [1, 34, 37]), our earlier definition [11] and those of other computer scientists <ref> [27, 29] </ref>, do not have this property. Although there is due consideration for the speaker's wanting the hearer to do an act, and perhaps for the speaker's wanting the hearer to form an intention to do so, nothing in those definitions commits the speaker to anything.
Reference: [28] <author> C. R. Perrault. </author> <title> An application of default logic to speech act theory. </title> <editor> In P. R. Cohen, J. Mor-gan, and M. E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mas-sachusetts, </address> <year> 1990. </year>
Reference-contexts: We now turn to the problem of showing how agents can form and discharge these joint commitments and intentions. Although the conditions proposed in the analysis rely on mutual belief, strictly speaking, there are ways to acquire mutual beliefs without explicit speech acts (see <ref> [5, 28, 31] </ref>), such as circumstances in which agents are copresent and can observe one another. However, we will primarily be concerned here with mutual belief acquired via explicit communication.
Reference: [29] <author> C. R. Perrault and J. F. Allen. </author> <title> A plan-based analysis of indirect speech acts. </title> <journal> American Journal of Computational Linguistics, </journal> <volume> 6(3) </volume> <pages> 167-182, </pages> <year> 1980. </year>
Reference-contexts: We claim that a request followed by a commissive action should result in a joint commitment's being formed. It is important to notice that the classical definitions of requesting (e.g, those in [1, 34, 37]), our earlier definition [11] and those of other computer scientists <ref> [27, 29] </ref>, do not have this property. Although there is due consideration for the speaker's wanting the hearer to do an act, and perhaps for the speaker's wanting the hearer to form an intention to do so, nothing in those definitions commits the speaker to anything.
Reference: [30] <author> M. E. Pollack. </author> <title> Plans as complex mental attitudes. </title> <editor> In P. R. Cohen, J. Morgan, and M. E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: The axiomatic analysis in GK concentrates on characterizing shared plans both partial and full. The action specification language follows Goldman's [16] and Pollack's <ref> [30] </ref>, and is targeted at hierarchical composition, especially how one action contributes to the performance of another.
Reference: [31] <author> D. Sadek. </author> <title> Dialogue acts are rational plans. </title> <booktitle> In Proceedings of the ESCA/ETRW Workshop on "The structure of multimodal dialogue" (VENACO II), </booktitle> <address> Maratea, Italy, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: We now turn to the problem of showing how agents can form and discharge these joint commitments and intentions. Although the conditions proposed in the analysis rely on mutual belief, strictly speaking, there are ways to acquire mutual beliefs without explicit speech acts (see <ref> [5, 28, 31] </ref>), such as circumstances in which agents are copresent and can observe one another. However, we will primarily be concerned here with mutual belief acquired via explicit communication.
Reference: [32] <author> J. M. Sadock. </author> <title> Comments on Vanderveken and on Cohen and Levesque. </title> <editor> In P. R. Cohen, J. Morgan, , and M. E. Pollack, editors, </editor> <title> Intentions in Communication, </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990, </year> <pages> pp. 257-270. </pages>
Reference-contexts: Given an event sequence, multiple actions could be said to have been performed (and thus we side with Davidson [14] in analyzing action sentences). But, as argued by Sadock <ref> [32] </ref>, pragmatics is too easy. That is, there are few constraints on what constitutes an illocutionary act definition. We have argued elsewhere for a methodology that involves describing the action in a logical description language thereby enabling 13 the theorist to derive various properties entailed by those definitions and semantics.
Reference: [33] <author> S. Schiffer. </author> <title> Meaning. </title> <publisher> Oxford University Press, </publisher> <address> London, </address> <year> 1972. </year>
Reference-contexts: Y 's response could then establish a true joint commitment/intention, or could let X off the hook. To see how, we need at least one more basic communicative action, assertion. 12 This intention (labeled 1 in the definition) is satisfied in fashion reminiscent of Grice [17] and Schiffer <ref> [33] </ref> in that it is satisfied by the mutual recognition that it held. 16 5.3 Assertion Definition 8 An assertion using event e from speaker Y to X that p is true is defined to be: An attempt using event e by Y to X , where 1.
Reference: [34] <author> J. R. Searle. </author> <title> Speech acts: An essay in the philosophy of language. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1969. </year>
Reference-contexts: In our case, we have used this method to show how our earlier definitions subsume many of the properties of illocutionary acts described by philosophers of language (e.g., <ref> [1, 34, 37] </ref>). However, because of the fine-grainedness of the logical operators, the logic can often make distinctions that others cannot. <p> However, because of the fine-grainedness of the logical operators, the logic can often make distinctions that others cannot. As a result, there are sometimes properties of illocutionary acts that are new, and need to accord with intuitions, if not actual dialogues. 5.1 Communicative Action Generalizing a remark by Searle <ref> [34] </ref>, a communicative action will be treated as an attempt by the speaker to convey his mental state. The analysis will assume the usual distinction between illocutionary and perlocutionary effects. <p> We claim that a request followed by a commissive action should result in a joint commitment's being formed. It is important to notice that the classical definitions of requesting (e.g, those in <ref> [1, 34, 37] </ref>), our earlier definition [11] and those of other computer scientists [27, 29], do not have this property.
Reference: [35] <author> J. R. Searle. Intentionality: </author> <title> An Essay in the Philosophy of Mind. </title> <publisher> Cambridge University Press, </publisher> <address> New York, New York, </address> <year> 1983. </year>
Reference-contexts: we will see shortly. 3 This definition differs slightly from that presented in our earlier work [8], but that difference is immaterial here. 7 3.2 Individual Intention We adopt Bratman's [2] methodological concern for treating the future-directed properties of intention as primary, and the intention-in-action properties as secondary, contra Searle <ref> [35, 36] </ref>. By doing so, we avoid the notoriously difficult issue of how an intention self-referentially causes an agent to act, as discussed in [35], although many of those properties are captured by our account. <p> By doing so, we avoid the notoriously difficult issue of how an intention self-referentially causes an agent to act, as discussed in <ref> [35] </ref>, although many of those properties are captured by our account. Rather, we are concerned with how adopting an intention constrains the agents' adoption of other mental states.
Reference: [36] <editor> J. R. Searle. Collective intentionality. In P. R. Cohen, J. Morgan, and M. E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> M.I.T. Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: Agents can be acting in a coordinated fashion, as in ordinary automobile traffic, but not be acting together. Conversely, agents can be acting together, but not be coordinated except at the start and end of their joint action (e.g, see <ref> [36] </ref>) The key property distinguishing joint or collaborative action from mere coordinated action is the joint mental state of the participants. The best way to explore what this mental state must be is to imagine a joint action going astray. <p> In support of these mutual commitments, teams involve an inherent overhead | in establishing, monitoring, and disbanding the team. A theory of joint action therefore needs to explain how this occurs. Unfortunately, although there are numerous analyses of joint action in the literature (e.g, <ref> [4, 12, 19, 18, 44, 43, 36] </ref> how agents in fact form and disband teams is rarely discussed. In some cases, it is suggested that joint activities are formed by "agreements," but that concept is left relatively unformalized. <p> we will see shortly. 3 This definition differs slightly from that presented in our earlier work [8], but that difference is immaterial here. 7 3.2 Individual Intention We adopt Bratman's [2] methodological concern for treating the future-directed properties of intention as primary, and the intention-in-action properties as secondary, contra Searle <ref> [35, 36] </ref>. By doing so, we avoid the notoriously difficult issue of how an intention self-referentially causes an agent to act, as discussed in [35], although many of those properties are captured by our account. <p> A group of spectators running for cover from a 4 Of course, the agent may still intend to achieve p again if she is committed to doing so herself. 8 sudden rainstorm may all have a common goal | remaining dry | but there is no coordinated team activity <ref> [36] </ref>. While the spectators have a common goal they do not have a shared goal. Each has the goal independently of the others, and the success of an individual neither affects nor is affected by the success of any of the other participants.
Reference: [37] <author> J. R. Searle and D. Vanderveken. </author> <title> Foundations of Illocutionary Logic. </title> <publisher> Cambridge Univ. Press, </publisher> <address> New York City, New York, </address> <year> 1985. </year> <month> 24 </month>
Reference-contexts: In our case, we have used this method to show how our earlier definitions subsume many of the properties of illocutionary acts described by philosophers of language (e.g., <ref> [1, 34, 37] </ref>). However, because of the fine-grainedness of the logical operators, the logic can often make distinctions that others cannot. <p> We claim that a request followed by a commissive action should result in a joint commitment's being formed. It is important to notice that the classical definitions of requesting (e.g, those in <ref> [1, 34, 37] </ref>), our earlier definition [11] and those of other computer scientists [27, 29], do not have this property.
Reference: [38] <author> C. Sidner and C. Rich. COLLAGEN: </author> <title> When agents and people collaborate. </title> <booktitle> In Proceedings of the First International Conference on Autonomous Agents, </booktitle> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1997, </year> <pages> pp. 284-291. </pages>
Reference-contexts: The theory of joint action has important practical ramifications. As computer scientists, we are interested in applications of those models in a variety of domains. Human-computer interaction may profitably be regarded as human-computer collaboration <ref> [38] </ref>, and theories of collaboration can help to provide new mechanisms for supporting human collaboration. In the field of artificial intelligence, there are numerous attempts to build multiagent systems that can be said to collaborate [23, 22, 40].
Reference: [39] <author> I. Smith and P. R. Cohen. </author> <title> Toward a semantics for an agent communications language based on speech-acts. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI'96), </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, California, </address> <year> 1996, </year> <pages> pp. 24-31. </pages>
Reference-contexts: Finally, analyses of how communicative actions can be used to establish and discharge joint intentions can have an impact on the design of interagent communication languages for the Internet <ref> [13, 39] </ref>. In fact, computer systems are being designed to support simultaneously human-human collaboration and teamwork, human-computer interaction, and interactions among artificial agents [7]. Building a robust and reliable system that incorporates these three components requires a single model of collaboration and teamwork. <p> The paper has redefined a number of basic communicative actions and shown that they can be used to form and to discharge teams. Finally, other work of ours <ref> [39] </ref> has argued that these definitions of communicative actions can induce the familiar finite-state analyses of dialogue, explaining the nature of the individual states and state transitions.
Reference: [40] <author> M. Tambe, W.L. Johnson, R. Jones, F. Koss, J.E. Laird, P.S. Rosenbloom, and K. Schwamb. </author> <title> Intelligent agents for interactive simulation environments. </title> <journal> AI Magazine, </journal> <volume> 16(1), </volume> <year> 1995. </year>
Reference-contexts: Human-computer interaction may profitably be regarded as human-computer collaboration [38], and theories of collaboration can help to provide new mechanisms for supporting human collaboration. In the field of artificial intelligence, there are numerous attempts to build multiagent systems that can be said to collaborate <ref> [23, 22, 40] </ref>. For example, Jennings and Mamdani [23] have shown that the present analysis can be used to specify and guide the design of a multiagent system for electric power managment, in which grid-diagnostic agents share a joint intention. <p> As a group, the jointly committed agents waste less time in resolving circuit outages than a collection of "selfishly" motivated agents because they keep each other up to date when the jointly intended actions are satisfied, impossible, or irrelevant. Tambe et al. <ref> [40] </ref> are using the joint intention theory discussed here to enhance the performance of teams of aircraft in a military simulation. A typical mission will have a team of helicopters fly to a prearranged jump-off point, carry-out their assigned mission, and return to base.
Reference: [41] <author> M. Tambe. </author> <title> Teamwork in real-world, dynamic environments. </title> <booktitle> In Proceedings Second International Conference on Multi-Agent Systems, </booktitle> <publisher> AAAI Press,Menlo Park, </publisher> <address> California, </address> <year> 1996, </year> <pages> pp. 361-368. </pages>
Reference-contexts: A typical mission will have a team of helicopters fly to a prearranged jump-off point, carry-out their assigned mission, and return to base. Joint intention theory is used to control individual pilot's actions <ref> [41] </ref> with respect to the team goal, and to reason about the actions of members of opposing teams [42]. The first implementation of these agents was designed without any explicit model of teamwork; a team of agents was simply a group of agents with common goals.
Reference: [42] <author> M. Tambe. </author> <title> Tracking dynamic team activity. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. </booktitle> <publisher> AAAI, AAAI Press, </publisher> <year> 1996. </year>
Reference-contexts: Joint intention theory is used to control individual pilot's actions [41] with respect to the team goal, and to reason about the actions of members of opposing teams <ref> [42] </ref>. The first implementation of these agents was designed without any explicit model of teamwork; a team of agents was simply a group of agents with common goals. These agents could not form teams that stayed together in the face of changing circumstances or adversity.
Reference: [43] <author> R. Tuomela. </author> <title> The importance of us. </title> <publisher> Stanford University Press, Stanford, </publisher> <address> California, </address> <year> 1995. </year>
Reference-contexts: In support of these mutual commitments, teams involve an inherent overhead | in establishing, monitoring, and disbanding the team. A theory of joint action therefore needs to explain how this occurs. Unfortunately, although there are numerous analyses of joint action in the literature (e.g, <ref> [4, 12, 19, 18, 44, 43, 36] </ref> how agents in fact form and disband teams is rarely discussed. In some cases, it is suggested that joint activities are formed by "agreements," but that concept is left relatively unformalized. <p> Thus, the definitions of offer, propose, and accept will need to be revised to use the PWAG operator in order to be able to form a joint commitment. 7 Comparison with other approaches Tuomela <ref> [43] </ref> has written a definitive work on joint action, relating the concept to that of "we-intentions," norms, and social roles, and culiminating in a "general dynamic theory of society." The present analysis of joint action does not attempt such wide coverage, but rather attempts in the small to link joint action <p> Tuomela and colleagues have been concerned with the relationship of "we-intending" to individual intentions, but until recently <ref> [43] </ref> the conditions under which one can drop joint intentions and commitments have been of secondary concern. The present analysis derives the individual commitment of all team members to the actions of their partners from the semantics of the concepts involved in our definition of joint commitment. <p> A second area of comparison with other theories is that of how joint intentions are formed and discharged. In one major explication, it is claimed that joint intentions require "agreements," either explicit or implicit <ref> [43, 73-77] </ref>. For example, regarding explicit agreements: Agreement-making requires a "communicative" change in the world | a relevant sign indicating agreement. (However, I shall not here attempt to give an exhaustive list of speech acts and other communicative acts which can result in agreement-making and the entailed obligations). [p. 74]. <p> This is because the mutual belief operator is false as soon as there is even one embedded negated belief operator. The subsequent analysis in <ref> [43] </ref> then argued that surely, even if the joint intention is gone, "given the agreement-view, we can say that the agreement by A and B that they drive in convoy to B's home: : : obviously is not yet gone: A is obligated to communicate to B his private belief. <p> Thus, perhaps the present analysis is elaborating what was meant in <ref> [43] </ref> in more precise terms. Grosz and Kraus [19] (hereafter, GK) develop an elaborate axiomatic theory of collaborative plans based on a four-fold distinction among intentions intending to do a complex action, intending that a proposition be true, and potential intentions to do actions or achieve propositions.
Reference: [44] <author> R. Tuomela and K. Miller. </author> <title> We-intentions. </title> <journal> Philosophical Studies, </journal> <volume> 53 </volume> <pages> 367-389, </pages> <year> 1988. </year>
Reference-contexts: In support of these mutual commitments, teams involve an inherent overhead | in establishing, monitoring, and disbanding the team. A theory of joint action therefore needs to explain how this occurs. Unfortunately, although there are numerous analyses of joint action in the literature (e.g, <ref> [4, 12, 19, 18, 44, 43, 36] </ref> how agents in fact form and disband teams is rarely discussed. In some cases, it is suggested that joint activities are formed by "agreements," but that concept is left relatively unformalized.
Reference: [45] <author> M. Wooldridge and N. R. Jennings. </author> <title> Towards a theory of cooperative problem solving. </title> <booktitle> In Distributed Software Agents and Applications (MAAMAW '94), Lecture Notes in Computer Science 1069, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1996, </year> <pages> pp. 40-53. 25 </pages>
Reference-contexts: As a result, many of the claims are in need of further support. However, the authors attempt to explain numerous phenomena that we have not tried to capture, especially, how agents further elaborate upon their partial joint and individual plans. Woolridge and Jennings <ref> [45] </ref> provide an analysis with a branching-time semantics that generalizes the present one, situating it as one point in a space of possible definitions of joint intention.
References-found: 45

