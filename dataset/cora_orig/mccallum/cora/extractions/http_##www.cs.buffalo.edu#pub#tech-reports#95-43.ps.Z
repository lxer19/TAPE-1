URL: http://www.cs.buffalo.edu/pub/tech-reports/95-43.ps.Z
Refering-URL: ftp://ftp.cs.buffalo.edu/pub/tech-reports/README.html
Root-URL: 
Title: On Self-Testing without the Generator Bottleneck  
Author: S. Ravikumar D. Sivakumar 
Abstract: Suppose P is a program designed to compute a linear function f on a group G. The task of self-testing f, that is, testing if P computes f correctly on most inputs, usually involves checking if P computes f correctly on all the generators of G. Recently, F. Ergun presented self-testers that avoid this generator bottleneck for specific functions. In this paper, we generalize Ergun's results, and extend them to a much larger class of functions. Our results give efficient self-testers for polynomial differentiation, integration, arithmetic in large finite field extensions, and constant-degree polynomials over large rings.
Abstract-found: 1
Intro-found: 1
Reference: [BFL91] <author> L. Babai, L. Fortnow, and C. Lund. </author> <title> Non-deterministic exponential time has two-prover interactive protocols. </title> <journal> Computational Complexity, </journal> <volume> 1 </volume> <pages> 3-40, </pages> <year> 1991. </year>
Reference-contexts: Moreover if f is symmetric, then all the h i 's are identical. The self-tester for f consists of the following tests: (1) Multilinearity Test : Use the self-tester for multilinearity from <ref> [BFL91, FGL + 91] </ref>, which also works in our vector space setting, to verify that P agrees with some mul-tilinear function g on all but an * fraction of the inputs. (Note, however, that these tests impose a limit * *(k) = (1=k) O (1) .
Reference: [BK89] <author> M. Blum and S. Kannan. </author> <title> Designing programs that check their work. </title> <booktitle> In Proc. 21st Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 86-97, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction The notions of program result-checking, self-testing, and self-correcting <ref> [BK89, Lip91, BLR93] </ref> have proved to be very useful concepts. The theoretical developments in this area are at the heart of the recent breakthrough results on probabilistically checkable proofs and the subsequent results that show non-approximability of hard combinatorial problems. <p> Given a program P that computes f correctly on most inputs, a self-corrector for f is a program that uses P as an oracle and computes f correctly on every input with high probability. The existence of a self-tester/corrector pair implies the existence of a result-checker. Blum and Kannan <ref> [BK89] </ref> and Blum, Luby, and Rubinfeld [BLR93] have laid out the minimal requirements for self-testers and result-checkers. <p> Clearly the low-degree test and the basis test work as before. The interpolation identity is valid, too. The missing ingredient is the availability of nice identities like "f (xp) = x d f (p)." We get around this difficulty using the notion of program result-checkers <ref> [BK89] </ref>. Recall that a checker for a function f is a probabilistic program that, given a program P purporting to compute f and an input p, outputs "CORRECT" if P (q) = f (q) for all q, outputs "WRONG" if P (p) 6= f (p).
Reference: [BLR93] <author> M. Blum, M. Luby, and R. Rubinfeld. </author> <title> Self-testing/correcting with applications to numerical problems. </title> <journal> J. Comp. Sys. Sci., </journal> <volume> 47(3) </volume> <pages> 549-595, </pages> <year> 1993. </year> <note> An earlier version appeared in STOC 1990. </note>
Reference-contexts: 1 Introduction The notions of program result-checking, self-testing, and self-correcting <ref> [BK89, Lip91, BLR93] </ref> have proved to be very useful concepts. The theoretical developments in this area are at the heart of the recent breakthrough results on probabilistically checkable proofs and the subsequent results that show non-approximability of hard combinatorial problems. <p> The existence of a self-tester/corrector pair implies the existence of a result-checker. Blum and Kannan [BK89] and Blum, Luby, and Rubinfeld <ref> [BLR93] </ref> have laid out the minimal requirements for self-testers and result-checkers. <p> Various linear and low-degree polynomials, and functions described by functional equations have been shown to have self-testers and/or self-correctors <ref> [BLR93, Lip91, GLR + 91, RS92, RS93, Rub94] </ref>. Using the notions of robust characterizations and self-correcting, the self-testing scheme for a program P that purports to compute a linear function f can be described as follows. <p> This is called the generator bottleneck. It is desirable to build self-testers that make only O (1) calls to the program P being tested. Such self-testers are called efficient in <ref> [BLR93] </ref>. The problem of generator bottleneck was first addressed by Ergun [Erg95], who shows how to obtain efficient self-testers for specific functions like Fourier transforms, polynomial multiplication, etc. We generalize and extend Ergun's idea to a larger class of functions. <p> For simplicity, we will assume that the field K is finite; our testers work for infinite fields as well, but additional complications arise. For example, it is not clear how to choose a random element from the field of real numbers. The self-tester we build follows the framework of <ref> [BLR93] </ref>. For 1 i n, let e i denote the vector that has a 1 in the i-th position and 0's in the other positions. The vectors e 1 ; e 2 ; : : : ; e n form a collection of basis vectors that span V . <p> Viewed as an abelian group under vector addition, V is generated by e 1 ; : : : ; e n . Suppose P is a program that purports to compute f . The framework of <ref> [BLR93] </ref> comprises the following two tests: (1) Linearity Test: By checking if P (ff + fi) = P (ff) + P (fi) on many randomly chosen inputs ff; fi 2 V , ensure that P satisfies the linearity property. 3 It is shown in [BLR93] that the linearity property is robust, <p> The framework of <ref> [BLR93] </ref> comprises the following two tests: (1) Linearity Test: By checking if P (ff + fi) = P (ff) + P (fi) on many randomly chosen inputs ff; fi 2 V , ensure that P satisfies the linearity property. 3 It is shown in [BLR93] that the linearity property is robust, that is, if the program P passes Test (1) sufficiently often, then there is a unique linear function g that agrees with P on most inputs. <p> There are two problems with this: one is that the self-tester is inefficient|if the inputs are n-element vectors, the self-tester makes O (n) calls to the program, which is not desirable. The requirement in <ref> [BLR93] </ref> for an efficient self-tester is that it make O (1) calls to the program being tested. Secondly, the self-tester needs to know the correct value of f on n different points, which is also undesirable. Our primary interest is to avoid this generator bottleneck. <p> Notice that the number of points on which the self-tester needs to know the value of f is just one, in contrast to knowing the values of f on all the n generators (as in the original approach of <ref> [BLR93] </ref>). We note that this idea has a natural generalization to vector spaces. <p> Recall that if P passes Test (1) there is a unique linear function g that agrees with P on most inputs, and that can be computed by P sc (using P as an oracle). The basis tests of <ref> [BLR93] </ref> can now be replaced by: (2) Verify that g (e 1 ) = f (e 1 ). (3) For many randomly chosen ff's, verify that g ((ff)) = h (; ff; g (ff)). <p> The fact that this yields a self-tester is presented in Theorem 3. Note that hypotheses (1), (2), and (3) above are conditions on P and g, not tests performed by a self-tester. Proof. The proof that the function g is linear and self-corrects P is due to <ref> [BLR93] </ref> (the "2/9" in the theorem is the bound obtained there). For the rest of this proof, we will assume that g is linear and that it satisfies conditions (2) and (3) above. <p> Higher Order Differentiation. Let D k denote the k-th differential operator. It is easy to write a recurrence-like identity for D k in terms of D j ; j &lt; k. This gives us a self-tester in the "library setting" described in <ref> [BLR93, Rub90] </ref>, where one assumes that there are programs to compute all these differential operators. However, if we wish to self-test a program that only computes D k , this assumption is not valid. To remedy this, we will use the following lemma. <p> Following [Erg95], our main motivating example is polynomial multiplication: suppose we wish to test a program that purports to multiply polynomials of degree n over a finite field K. The naive approach would require testing the program at n 2 pairs of generators. Blum, Luby, and Rubinfeld <ref> [BLR93] </ref> give a "bootstrap" self-tester that makes O (log n) calls to the program. Ergun's work presents an efficient self-tester that avoids the generator bottleneck. As in the previous section, we generalize this to arbitrary multilinear functions over large groups. <p> There we made essential use of the fact that g (x (p q) + xq) = g (x (p q)) + g (xq). When g is nonlinear, this identity is no longer true. To circumvent this problem, we follow the ideas of Rubinfeld and Sudan [RS93], who extended the <ref> [BLR93] </ref> result from linear functions to low-degree polynomials. They used the fact that the Lagrange interpolation identity for polynomials is robust. Here our task is to verify that g (xp) = x d g (p) for all p.
Reference: [BW94] <author> M. Blum and H. Wasserman. </author> <title> Program result-checking: A theory of testing meets a test of theory. </title> <booktitle> In Proc. 35th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 382-392, </pages> <year> 1994. </year>
Reference-contexts: From a practical viewpoint, these methods offer realistic and efficient tools for program verification. See the survey articles by Blum and Wasserman <ref> [BW94] </ref> and by Madhu Sudan [Sud94] for interesting expositions and pointers. Suppose we are given a program P designed to compute a function f . Informally, a self-tester for f enables us to estimate the fraction of the inputs on which P computes f correctly.
Reference: [Erg95] <author> F. Ergun. </author> <title> Testing multivariate linear functions: Overcoming the generator bottleneck. </title> <booktitle> In Proc. 27th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 407-416, </pages> <year> 1995. </year>
Reference-contexts: This is called the generator bottleneck. It is desirable to build self-testers that make only O (1) calls to the program P being tested. Such self-testers are called efficient in [BLR93]. The problem of generator bottleneck was first addressed by Ergun <ref> [Erg95] </ref>, who shows how to obtain efficient self-testers for specific functions like Fourier transforms, polynomial multiplication, etc. We generalize and extend Ergun's idea to a larger class of functions. First we show that the technique can be applied in a more natural and general setting, namely that of vector spaces. <p> Using this reduction and the notion of result-checker, we construct a self-tester for degree d polynomials over finite field extensions of dimension n that make O (2 d ) calls to the program being tested. 2 Linear Functions over Vector Spaces In this section, we generalize the idea of <ref> [Erg95] </ref> to the case of linear functions on a vector space. We begin with the basic definitions. Definition 1 Let f be a function on a domain D. <p> The requirement in [BLR93] for an efficient self-tester is that it make O (1) calls to the program being tested. Secondly, the self-tester needs to know the correct value of f on n different points, which is also undesirable. Our primary interest is to avoid this generator bottleneck. Ergun <ref> [Erg95] </ref> introduced an elegant trick that accomplishes this for specific functions. The key idea is to find an easy uniform way that "converts" one generator into the next generator. We illustrate this idea through the following example. Let V denote the group of all degree n polynomials under addition. <p> By the linearity of g, it would follow that g agrees with f on all inputs. We are now faced with the task of verifying g (xp) = cg (p) for all p 2 V , which is hopeless. Ergun <ref> [Erg95] </ref> shows that in order to verify this, it suffices to check if g (xp) = cg (p) holds almost everywhere. <p> What is more important is that h be easy to compute, given just ff and f (ff). Using this scheme, we show that besides the functions self-tested in <ref> [Erg95] </ref>, many other natural functions f have a suitable candidate for h. Recall that if P passes Test (1) there is a unique linear function g that agrees with P on most inputs, and that can be computed by P sc (using P as an oracle). <p> Details will be given in the full version of the paper. Our first application concerns linear functions of polynomials. Besides obtaining self-testers for polynomial evaluation and Fourier Transforms as in <ref> [Erg95] </ref>, we obtain new self-testers for polynomial differentiation, integration, and the "mod" function of polynomials. Moreover, the vector space setting lets us generalize some of these results in terms of the matrices that compute linear transforms of vector spaces. <p> Following <ref> [Erg95] </ref>, our main motivating example is polynomial multiplication: suppose we wish to test a program that purports to multiply polynomials of degree n over a finite field K. The naive approach would require testing the program at n 2 pairs of generators.
Reference: [FGL + 91] <author> U. Feige, S. Goldwasser, L. Lovasz, S. Safra, and M. Szegedy. </author> <title> Approximating clique is almost NP-complete. </title> <booktitle> In Proc. 32nd Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 2-12, </pages> <year> 1991. </year> <month> 15 </month>
Reference-contexts: Moreover if f is symmetric, then all the h i 's are identical. The self-tester for f consists of the following tests: (1) Multilinearity Test : Use the self-tester for multilinearity from <ref> [BFL91, FGL + 91] </ref>, which also works in our vector space setting, to verify that P agrees with some mul-tilinear function g on all but an * fraction of the inputs. (Note, however, that these tests impose a limit * *(k) = (1=k) O (1) .
Reference: [GLR + 91] <author> P. Gemmell, R. Lipton, R. Rubinfeld, M. Sudan, and A. Wigderson. </author> <title> Self testing/ correcting for polynomials and for approximate functions. </title> <booktitle> In Proc. 23rd Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 32-42, </pages> <year> 1991. </year>
Reference-contexts: Various linear and low-degree polynomials, and functions described by functional equations have been shown to have self-testers and/or self-correctors <ref> [BLR93, Lip91, GLR + 91, RS92, RS93, Rub94] </ref>. Using the notions of robust characterizations and self-correcting, the self-testing scheme for a program P that purports to compute a linear function f can be described as follows.
Reference: [Lip91] <author> R. Lipton. </author> <title> New directions in testing. </title> <booktitle> In Proc. of DIMACS Workshop on Distributed Computing and Cryptography, </booktitle> <pages> pages 191-202, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction The notions of program result-checking, self-testing, and self-correcting <ref> [BK89, Lip91, BLR93] </ref> have proved to be very useful concepts. The theoretical developments in this area are at the heart of the recent breakthrough results on probabilistically checkable proofs and the subsequent results that show non-approximability of hard combinatorial problems. <p> Various linear and low-degree polynomials, and functions described by functional equations have been shown to have self-testers and/or self-correctors <ref> [BLR93, Lip91, GLR + 91, RS92, RS93, Rub94] </ref>. Using the notions of robust characterizations and self-correcting, the self-testing scheme for a program P that purports to compute a linear function f can be described as follows.
Reference: [RS92] <author> R. Rubinfeld and M. Sudan. </author> <title> Testing polynomial functions efficiently and over rational domains. </title> <booktitle> In Proc. 3rd Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 23-43, </pages> <year> 1992. </year>
Reference-contexts: Various linear and low-degree polynomials, and functions described by functional equations have been shown to have self-testers and/or self-correctors <ref> [BLR93, Lip91, GLR + 91, RS92, RS93, Rub94] </ref>. Using the notions of robust characterizations and self-correcting, the self-testing scheme for a program P that purports to compute a linear function f can be described as follows.
Reference: [RS93] <author> R. Rubinfeld and M. Sudan. </author> <title> Robust characterizations of polynomials and their applications to program testing. </title> <type> TR 93-1387, </type> <institution> Dept. of Computer Science, Cornell University, </institution> <year> 1993. </year> <note> To appear in SIAM Journal of Computing. </note>
Reference-contexts: Various linear and low-degree polynomials, and functions described by functional equations have been shown to have self-testers and/or self-correctors <ref> [BLR93, Lip91, GLR + 91, RS92, RS93, Rub94] </ref>. Using the notions of robust characterizations and self-correcting, the self-testing scheme for a program P that purports to compute a linear function f can be described as follows. <p> Suppose a program P claims to perform this exponentiation for all degree n polynomials p 2 P n K [x], the ring of all polynomials over the field K. Using the "low-degree" test of Rubinfeld and Sudan <ref> [RS93] </ref> we can first test if the function computed by P is a degree d polynomial. As before, we can also verify that g, the self-corrected version of P , satisfies g (e 1 ) = f (e 1 ). <p> There we made essential use of the fact that g (x (p q) + xq) = g (x (p q)) + g (xq). When g is nonlinear, this identity is no longer true. To circumvent this problem, we follow the ideas of Rubinfeld and Sudan <ref> [RS93] </ref>, who extended the [BLR93] result from linear functions to low-degree polynomials. They used the fact that the Lagrange interpolation identity for polynomials is robust. Here our task is to verify that g (xp) = x d g (p) for all p. <p> of P n , g (p) = i=1 Y p q j ; and also g (xp) = d+1 X g (xq i ) j6=i q i q j The self-tester for f (x) = x d comprises the following tests: (1) Degree Test : Use the low-degree test of <ref> [RS93] </ref> to verify that P computes a degree d polynomial. (2) Basis Test : Using P sc to compute g, verify that g (e 1 ) = f (e 1 ). 12 (3) Inductive Test: Using P sc to compute g, verify that Pr ff [g (xff) 6= x d (g
Reference: [Rub90] <author> R. Rubinfeld. </author> <title> A Mathematical Theory of Self-Checking, Self-Testing, and Self Correcting Programs. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <year> 1990. </year>
Reference-contexts: Higher Order Differentiation. Let D k denote the k-th differential operator. It is easy to write a recurrence-like identity for D k in terms of D j ; j &lt; k. This gives us a self-tester in the "library setting" described in <ref> [BLR93, Rub90] </ref>, where one assumes that there are programs to compute all these differential operators. However, if we wish to self-test a program that only computes D k , this assumption is not valid. To remedy this, we will use the following lemma.
Reference: [Rub94] <author> R. Rubinfeld. </author> <title> Robust functional equations with applications to self-testing/ correcting. </title> <booktitle> In Proc. 35th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 288-299, </pages> <year> 1994. </year>
Reference-contexts: Various linear and low-degree polynomials, and functions described by functional equations have been shown to have self-testers and/or self-correctors <ref> [BLR93, Lip91, GLR + 91, RS92, RS93, Rub94] </ref>. Using the notions of robust characterizations and self-correcting, the self-testing scheme for a program P that purports to compute a linear function f can be described as follows.
Reference: [Sud94] <author> Madhu Sudan. </author> <title> On the role of algebra in the efficient verification of proofs. </title> <editor> In M. Agrawal, V. Arvind, and M. Mahajan, editors, </editor> <booktitle> Proc. Workshop on Algebraic Methods in Complexity Theory (AMCOT), </booktitle> <pages> pages 58-68, </pages> <year> 1994. </year> <type> Technical Report IMSc 94/51, </type> <institution> The Institute of Mathematical Sciences, Madras, India. </institution> <month> 16 </month>
Reference-contexts: From a practical viewpoint, these methods offer realistic and efficient tools for program verification. See the survey articles by Blum and Wasserman [BW94] and by Madhu Sudan <ref> [Sud94] </ref> for interesting expositions and pointers. Suppose we are given a program P designed to compute a function f . Informally, a self-tester for f enables us to estimate the fraction of the inputs on which P computes f correctly.
References-found: 13

