URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-88-742/CS-TR-88-742.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-88-742/
Root-URL: http://www.cs.wisc.edu
Title: A Performance Analysis of the Gamma Database Machine  
Author: David J. DeWitt Shahram Ghandeharizadeh Donovan Schneider 
Note: This research was partially supported by the Defense Advanced Research Projects Agency under contract N00039-86-C-0578, by the National Science Foundation under grants DCR-8512862, MCS82-01870, and MCS81-05904, and by a Digital Equipment Corporation External Research Grant.  
Address: Wisconsin  
Affiliation: Computer Sciences Department University of  
Abstract-found: 0
Intro-found: 1
Reference: [ASTR76] <author> Astrahan, M. M., et. al., </author> <title> System R: A Relational Approach to Database Management, </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 1, No. 2, </volume> <month> June, </month> <year> 1976. </year>
Reference-contexts: The index maps key values to the records of the sequential file that contain a 5 matching value. Furthermore, one indexed attribute may be used as a clustering attribute for the file. The scan mechanism is similar to that provided by System R's RSS <ref> [ASTR76] </ref> except that predicates are compiled into machine language. 3. Teradata Hardware and Software Configuration The Teradata machine tested consists of 4 Interface Processors (IFPs), 20 Access Module Processors (AMPs), and 40 Disk Storage Units (DSUs).
Reference: [BABB79] <author> Babb, E., </author> <title> Implementing a Relational Database by Means of Specialized Hardware ACM Transactions on Database Systems, </title> <journal> Vol. </journal> <volume> 4, No. 1, </volume> <month> March, </month> <year> 1979. </year>
Reference-contexts: The store operators assume the responsibility for writing the result tuples to disk. To enhance the performance of certain operations, an array of bit vector filters <ref> [BABB79, VALD84] </ref> is inserted into the split table. In the case of a join operation, each join process builds a bit vector filter by hashing the join attribute values while building its hash table using the inner relation [BRAT84, DEWI85, DEWI84, VALD84].
Reference: [BITT83] <author> Bitton D., D.J. DeWitt, and C. Turbyfill, </author> <title> Benchmarking Database Systems A Systematic Approach, </title> <booktitle> Proceedings of the 1983 Very Large Database Conference, </booktitle> <month> October, </month> <year> 1983. </year>
Reference-contexts: Consequently, whenever a range query over an indexed attribute is performed, the entire index must be scanned. 4. Description of Benchmark Relations The benchmark relations used are based on the standard Wisconsin Benchmark relations <ref> [BITT83] </ref>. Each relation consists of thirteen 4-byte integer attributes and three 52-byte string attributes. Thus, each tuple is 208 bytes long. In order to more meaningfully stress the two database machines, we constructed 100,000 and 1,000,000 tuple versions of the original 1,000 and 10,000 tuple benchmark relations.
Reference: [BRAT84] <author> Bratbergsengen, Kjell, </author> <title> Hashing Methods and Relational Algebra Operations Proceedings of the 1984 Very Large Database Conference, </title> <month> August, </month> <year> 1984. </year>
Reference-contexts: In the case of a join operation, each join process builds a bit vector filter by hashing the join attribute values while building its hash table using the inner relation <ref> [BRAT84, DEWI85, DEWI84, VALD84] </ref>. When the hash table for the inner relation has been completed, the process sends its filter to its scheduler. After the scheduler has received all the filters, it sends them to the processes responsible for producing the outer relation of the join.
Reference: [CHOU85] <author> Chou, H-T, DeWitt, D. J., Katz, R., and T. Klug, </author> <title> Design and Implementation of the Wisconsin Storage System (WiSS) Software Practices and Experience, </title> <journal> Vol. </journal> <volume> 15, No. 10, </volume> <month> October, </month> <year> 1985. </year>
Reference-contexts: Messages between two processes on the same processor are short-circuited by the communications software. File services in NOSE are based on the Wisconsin Storage System (WiSS) <ref> [CHOU85] </ref>. These services include structured sequential files, B + indices, byte-stream files as in UNIX, long data items, a sort utility, and a scan mechanism. A sequential file is a sequence of records.
Reference: [DEWI84] <author> DeWitt, D. J., Katz, R., Olken, F., Shapiro, D., Stonebraker, M. and D. Wood, </author> <title> Implementation Techniques for Main Memory Database Systems, </title> <booktitle> Proceedings of the 1984 SIGMOD Conference, </booktitle> <address> Boston, MA, </address> <month> June, </month> <year> 1984. </year>
Reference-contexts: In the case of a join operation, each join process builds a bit vector filter by hashing the join attribute values while building its hash table using the inner relation <ref> [BRAT84, DEWI85, DEWI84, VALD84] </ref>. When the hash table for the inner relation has been completed, the process sends its filter to its scheduler. After the scheduler has received all the filters, it sends them to the processes responsible for producing the outer relation of the join. <p> The solution we are in the process of adopting is to replace the current algorithm with a parallel version of the Hybrid hash-join algorithm <ref> [DEWI84, DEWI85] </ref>. This algorithm outperforms the Simple hash-join algorithm because it recognizes memory limitations and repartitions the source relations such that no partition of the smaller relation should exceed available memory.
Reference: [DEWI85] <author> DeWitt, D., and R. Gerber, </author> <title> Multiprocessor Hash-Based Join Algorithms, </title> <booktitle> Proceedings of the 1985 VLDB Conference, </booktitle> <address> Stockholm, Sweden, </address> <month> August, </month> <year> 1985. </year>
Reference-contexts: In the case of a join operation, each join process builds a bit vector filter by hashing the join attribute values while building its hash table using the inner relation <ref> [BRAT84, DEWI85, DEWI84, VALD84] </ref>. When the hash table for the inner relation has been completed, the process sends its filter to its scheduler. After the scheduler has received all the filters, it sends them to the processes responsible for producing the outer relation of the join. <p> For our test queries, this was the only algorithm used. Gamma also partitions its source relations by hashing on the join attributes but, instead of using sort-merge to effect the join, Gamma employs an algorithm based on hashing (see <ref> [KITS83, DEWI85, DEWI86, GERB86] </ref>). During the first phase of the algorithm, Gamma partitions the smaller source relation by hashing on the joining attribute and builds main-memory hash tables. <p> Of course, whenever main-memory hashing is used there is a danger of hash-table overflow. Gamma currently uses a distributed version of the Simple hash-partitioned join algorithm described in <ref> [DEWI85] </ref> to handle this phenomenon. Basically, whenever a processor detects hash-table overflow it spools tuples to a temporary file based on a second hash function until the hash table is successfully built. <p> From the shape of the curves in Figure 14 it is obvious that performance deteriorates rapidly as memory becomes more limited due to our use of a distributed version of the Simple Hash join algorithm to resolve hash-partition overflow (as predicted analytically in <ref> [DEWI85] </ref>). When viewing the graphs it should be kept in mind that the number of overflows represents the number of overflows detected at each of the eight joining sites. Thus, the total number of occurrences of partition overflow is the labeled number times eight. <p> The solution we are in the process of adopting is to replace the current algorithm with a parallel version of the Hybrid hash-join algorithm <ref> [DEWI84, DEWI85] </ref>. This algorithm outperforms the Simple hash-join algorithm because it recognizes memory limitations and repartitions the source relations such that no partition of the smaller relation should exceed available memory.
Reference: [DEWI86] <author> DeWitt, D., Gerber, B., Graefe, G., Heytens, M., Kumar, K. and M. Muralikrishna, </author> <title> GAMMA A High Performance Dataflow Database Machine, </title> <booktitle> Proceedings of the 1986 VLDB Conference, </booktitle> <address> Japan, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: 1. Introduction This report presents the results of a single-user performance evaluation of the Gamma database machine <ref> [DEWI86, GERB86, GERB87] </ref>. This evaluation is based on two principal metrics: the absolute performance achieved by Gamma and the performance relative to the number of processors used. <p> Detailed descriptions of the algorithms used for implementing the various relational operations are presented in Sections 5 through 8 along with 2 the performance results obtained during the benchmarking process. For a complete description of Gamma see <ref> [DEWI86, GERB86] </ref>. 2.1. Hardware Configuration Presently, Gamma consists of 17 VAX 11/750 processors, each 1 with two megabytes of memory. An 80 megabit/second token ring [PROT85] is used to connect the processors to each other and to another VAX 11/750 running Berkeley UNIX. <p> For our test queries, this was the only algorithm used. Gamma also partitions its source relations by hashing on the join attributes but, instead of using sort-merge to effect the join, Gamma employs an algorithm based on hashing (see <ref> [KITS83, DEWI85, DEWI86, GERB86] </ref>). During the first phase of the algorithm, Gamma partitions the smaller source relation by hashing on the joining attribute and builds main-memory hash tables. <p> These diskless processors are exploited by the Remote and Allnodes joins. 21 processors. As was pointed out in <ref> [DEWI86] </ref> this is not the case because the building and probing phases of the join operator are not overlapped and hence the response time of the query is bounded below by the sum of the elapsed time of these two phases. <p> This shows that join operators can indeed be off-loaded to remote processors even for large relations. This substantiates results obtained in <ref> [DEWI86] </ref> for smaller relations. 6.2.2. Join Overflow In this set of experiments, we kept both the configuration size (16 query processors) and disk page size (4 Kbytes) constant but varied the total amount of memory.
Reference: [DEWI87] <author> DeWitt, D., Smith, M., and H. Boral, </author> <title> A Single-User Performance Evaluation of the Teradata Database Machine, </title> <type> MCC Technical Report Number DB-081-87, </type> <month> March 5, </month> <year> 1987. </year>
Reference-contexts: This evaluation is based on two principal metrics: the absolute performance achieved by Gamma and the performance relative to the number of processors used. As a basis for determining the absolute performance of Gamma, we have used results obtained from a similar study <ref> [DEWI87] </ref> of the Teradata DBC/1012 database machine [TERA83, TERA85a, TERA85b]. When interpreting the results presented below, the reader should remember that Gamma is not a commercial product and, as such, its results may look slightly better for some queries. <p> Since the Teradata insert code is currently optimized for single tuple and not bulk updates, at least 3 I/Os are incurred for each tuple inserted (see <ref> [DEWI87] </ref> for a more complete description of the problem). A straightforward optimization would be for the the "insert into" code to recognize when it was operating on an empty relation. <p> First, for both machines the execution time of each query scales in a linear fashion as the size of the input and output relations are increased. Second, as expected, the clustered B-tree organization provides a significant improvement in performance. As discussed in <ref> [DEWI87] </ref>, the results for the 1% and 10% selection using a non-clustered index (rows three and four of Table 1) for the Teradata machine look puzzling. <p> As discussed in Section 4, since the semantics of QUEL and SQL are different, the results presented in Table 1 are slightly misleading and the times for the two machines are not directly comparable. Teradata treats each insertion as a separate operation <ref> [DEWI87] </ref>. Thus, the time required to insert tuples into a result relation sometimes accounts for a significant fraction of the execution time of the query. Gamma, on the other hand, pipelines the output of the selection, handling it as a bulk update. <p> They deserve special credit for being willing to debug the machine code produced by the compiler. Finally, we would like to thank the Microelectronics and Computer Technology Corporation for their support in funding the study of the Teradata machine described in <ref> [DEWI87] </ref>.
Reference: [GERB86] <author> Gerber, R., </author> <title> Dataflow Query Processing using Multiprocessor Hash-Partitioned Algorithms, </title> <type> PhD Thesis and Computer Sciences Technical Report #672, </type> <institution> University of Wisconsin-Madison, </institution> <month> October </month> <year> 1986. </year>
Reference-contexts: 1. Introduction This report presents the results of a single-user performance evaluation of the Gamma database machine <ref> [DEWI86, GERB86, GERB87] </ref>. This evaluation is based on two principal metrics: the absolute performance achieved by Gamma and the performance relative to the number of processors used. <p> Detailed descriptions of the algorithms used for implementing the various relational operations are presented in Sections 5 through 8 along with 2 the performance results obtained during the benchmarking process. For a complete description of Gamma see <ref> [DEWI86, GERB86] </ref>. 2.1. Hardware Configuration Presently, Gamma consists of 17 VAX 11/750 processors, each 1 with two megabytes of memory. An 80 megabit/second token ring [PROT85] is used to connect the processors to each other and to another VAX 11/750 running Berkeley UNIX. <p> As more processors are used, the fraction of tuples short circuited decreases (with n processors, n 1 hh th the result tuples will be short-circuited). While the actual network is never a bottleneck <ref> [GERB86, GERB87] </ref>, the bandwidth from memory to the communications network is limited by the speed (4 megabits/second) of the Unibus on the VAX 11/750. As the selectivity factor of a query is increased and the number of short circuited tuples decreases, the path to the network becomes a bottleneck. <p> For our test queries, this was the only algorithm used. Gamma also partitions its source relations by hashing on the join attributes but, instead of using sort-merge to effect the join, Gamma employs an algorithm based on hashing (see <ref> [KITS83, DEWI85, DEWI86, GERB86] </ref>). During the first phase of the algorithm, Gamma partitions the smaller source relation by hashing on the joining attribute and builds main-memory hash tables.
Reference: [GERB87] <author> Gerber, R. and D. DeWitt, </author> <title> The Impact of Hardware and Software Alternatives on the Performance of the Gamma Database Machine, </title> <note> submitted for publication, also Computer Sciences Technical Report #708, </note> <institution> University of Wisconsin-Madison, </institution> <month> July </month> <year> 1987. </year> <month> 31 </month>
Reference-contexts: 1. Introduction This report presents the results of a single-user performance evaluation of the Gamma database machine <ref> [DEWI86, GERB86, GERB87] </ref>. This evaluation is based on two principal metrics: the absolute performance achieved by Gamma and the performance relative to the number of processors used. <p> As more processors are used, the fraction of tuples short circuited decreases (with n processors, n 1 hh th the result tuples will be short-circuited). While the actual network is never a bottleneck <ref> [GERB86, GERB87] </ref>, the bandwidth from memory to the communications network is limited by the speed (4 megabits/second) of the Unibus on the VAX 11/750. As the selectivity factor of a query is increased and the number of short circuited tuples decreases, the path to the network becomes a bottleneck.
Reference: [JARK84] <author> Jarke, M. and J. Koch, </author> <title> Query Optimization in Database System, </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 16, No. 2, </volume> <month> June, </month> <year> 1984. </year>
Reference-contexts: In the third strategy the user specifies a range of key values for each site. In the last partitioning strategy the user specifies the partitioning attribute and the system distributes the tuples uniformly across all sites. Query Execution Gamma uses traditional relational techniques for query parsing, optimization <ref> [SELI79, JARK84] </ref>, and code generation. Queries are compiled into a tree of operators with predicates compiled into machine language.
Reference: [KITS83] <author> Kitsuregawa, M., Tanaka, H., and T. Moto-oka, </author> <title> Application of Hash to Data Base Machine and Its Architecture, </title> <journal> New Generation Computing, </journal> <volume> Vol. 1, No. 1, </volume> <year> 1983. </year>
Reference-contexts: For our test queries, this was the only algorithm used. Gamma also partitions its source relations by hashing on the join attributes but, instead of using sort-merge to effect the join, Gamma employs an algorithm based on hashing (see <ref> [KITS83, DEWI85, DEWI86, GERB86] </ref>). During the first phase of the algorithm, Gamma partitions the smaller source relation by hashing on the joining attribute and builds main-memory hash tables.
Reference: [MC 2 86] <author> Measurement Concepts Corp., </author> <title> C 3 I Teradata Study, </title> <type> Technical Report RADC-TR-85-273, </type> <institution> Rome Air Development Center, Griffiss Air Force Base, Rome, </institution> <address> NY, </address> <month> March </month> <year> 1986. </year>
Reference-contexts: The hash value and a sequence number are concatenated to form a unique tuple id <ref> [TERA85a, MC 2 86] </ref>. Once an entire relation has been loaded, the tuples in each horizontal fragment are in what is termed hash-key order. Thus, given a value for the key attribute, it is possible to locate the tuple in a single disk access (assuming no buffer pool hits). <p> Second, we wanted to explore how Gamma's performance is affected as the number of processors with disks is increased, as the disk page size is increased, and as the amount of available memory is reduced. Join Algorithms The Teradata machine uses four alternative join algorithms <ref> [TERA85a, MC 2 86] </ref>. One computes an outer-join, while two others are used only in special cases (e.g., when the inner relation contains a single tuple). The fourth and most commonly used join method involves first redistributing the two source relations by hashing on the join attribute.
Reference: [NECH83] <author> Neches, </author> <title> P.M., et al., </title> <type> U.S. Patent No. </type> <institution> 4,412,285, </institution> <month> October 25, </month> <year> 1983. </year>
Reference-contexts: The IFPs communicate with the host, and parse, optimize, and direct the execution of user requests. The AMPs perform the actual storage and retrieval of data on the DSUs. IFPs and AMPs are interconnected by a dual redundant, tree-shaped interconnect called the Y-net <ref> [TERA83, NECH83] </ref>. The Y-net has an aggregate bandwidth of 12 megabytes/second. Intel 80286 processors are used in all IFPs and AMPs. Like the Gamma processors, each AMP has 2 megabytes of memory and two 2 8.8", 525 megabyte (unformatted) Hitachi disk drives (model DK 8155).
Reference: [PROT85] <author> Proteon Associates, </author> <title> Operation and Maintenance Manual for the ProNet Model p8000, </title> <address> Waltham, Mass, </address> <year> 1985. </year>
Reference-contexts: For a complete description of Gamma see [DEWI86, GERB86]. 2.1. Hardware Configuration Presently, Gamma consists of 17 VAX 11/750 processors, each 1 with two megabytes of memory. An 80 megabit/second token ring <ref> [PROT85] </ref> is used to connect the processors to each other and to another VAX 11/750 running Berkeley UNIX. This processor acts as the host machine for Gamma. Attached to eight of the processors are 333 megabyte Fujitsu disk drives (8") which are used for database storage.
Reference: [RIES78] <author> Ries, D. and R. Epstein, </author> <title> Evaluation of Distribution Criteria for Distributed Database Systems, </title> <type> UCB/ERL Technical Report M78/22, </type> <institution> UC Berkeley, </institution> <month> May, </month> <year> 1978. </year>
Reference-contexts: The remaining diskless processors are used to execute join, projection, and aggregate operations. Selection and update operations are executed only on the processors with disk drives attached. 2.2. Software Overview Physical Database Design In Gamma, all relations are horizontally partitioned <ref> [RIES78] </ref> across all disk drives in the system. Four alternative ways of distributing the tuples of a relation are provided: round-robin, hashed, range partitioned with user-specified placement by key value, and range partitioned with uniform distribution. <p> The host processor was an AMDAHL V570 running the MVS operating system. Software release 2.3 was used for the tests conducted. All relations on the Teradata machine are horizontally partitioned <ref> [RIES78] </ref> across multiple AMPs. While it is possible to limit the number of AMPs over which relations are partitioned, all 20 AMPs were used for the tests presented below.
Reference: [SELI79] <author> Selinger,P. G., et. al., </author> <title> Access Path Selection in a Relational Database Management System, </title> <booktitle> Proceedings of the 1979 SIGMOD Conference, </booktitle> <address> Boston, MA., </address> <month> May </month> <year> 1979. </year>
Reference-contexts: In the third strategy the user specifies a range of key values for each site. In the last partitioning strategy the user specifies the partitioning attribute and the system distributes the tuples uniformly across all sites. Query Execution Gamma uses traditional relational techniques for query parsing, optimization <ref> [SELI79, JARK84] </ref>, and code generation. Queries are compiled into a tree of operators with predicates compiled into machine language.
Reference: [STON76] <author> Stonebraker, Michael, Eugene Wong, and Peter Kreps, </author> <title> The Design and Implementation of INGRES, </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 1, No. 3, </volume> <month> September, </month> <year> 1976. </year>
Reference-contexts: In this case, there are substantial differences between the two systems. Gamma, which provides an extended version of the query language QUEL <ref> [STON76] </ref>, uses the construct "retrieve into result_relation ... " to specify that the result of a query is to be stored in a relation. The semantics of this construct are that the relation name specified must not exist when the query is executed.
Reference: [TANE81] <author> Tanenbaum, A. S., </author> <title> Computer Networks, </title> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: NOSE provides lightweight processes with shared memory and reliable, datagram communication services between NOSE processes on Gamma processors and to UNIX processes on the host machine using a multiple bit, sliding window protocol <ref> [TANE81] </ref>. Messages between two processes on the same processor are short-circuited by the communications software. File services in NOSE are based on the Wisconsin Storage System (WiSS) [CHOU85].
Reference: [TERA83] <institution> Teradata Corp., DBC/1012 Data Base Computer Concepts & Facilities, Teradata Corp. </institution> <note> Document No. C02-0001-00, </note> <year> 1983. </year>
Reference-contexts: As a basis for determining the absolute performance of Gamma, we have used results obtained from a similar study [DEWI87] of the Teradata DBC/1012 database machine <ref> [TERA83, TERA85a, TERA85b] </ref>. When interpreting the results presented below, the reader should remember that Gamma is not a commercial product and, as such, its results may look slightly better for some queries. <p> The IFPs communicate with the host, and parse, optimize, and direct the execution of user requests. The AMPs perform the actual storage and retrieval of data on the DSUs. IFPs and AMPs are interconnected by a dual redundant, tree-shaped interconnect called the Y-net <ref> [TERA83, NECH83] </ref>. The Y-net has an aggregate bandwidth of 12 megabytes/second. Intel 80286 processors are used in all IFPs and AMPs. Like the Gamma processors, each AMP has 2 megabytes of memory and two 2 8.8", 525 megabyte (unformatted) Hitachi disk drives (model DK 8155).
Reference: [TERA85a] <author> Teradata Corp., </author> <title> DBC/1012 Data Base Computer System Manual, </title> <type> Rel. </type> <institution> 2.0, Teradata Corp. </institution> <note> Document No. C10-0001-02, </note> <month> November </month> <year> 1985. </year>
Reference-contexts: As a basis for determining the absolute performance of Gamma, we have used results obtained from a similar study [DEWI87] of the Teradata DBC/1012 database machine <ref> [TERA83, TERA85a, TERA85b] </ref>. When interpreting the results presented below, the reader should remember that Gamma is not a commercial product and, as such, its results may look slightly better for some queries. <p> The hash value and a sequence number are concatenated to form a unique tuple id <ref> [TERA85a, MC 2 86] </ref>. Once an entire relation has been loaded, the tuples in each horizontal fragment are in what is termed hash-key order. Thus, given a value for the key attribute, it is possible to locate the tuple in a single disk access (assuming no buffer pool hits). <p> Second, we wanted to explore how Gamma's performance is affected as the number of processors with disks is increased, as the disk page size is increased, and as the amount of available memory is reduced. Join Algorithms The Teradata machine uses four alternative join algorithms <ref> [TERA85a, MC 2 86] </ref>. One computes an outer-join, while two others are used only in special cases (e.g., when the inner relation contains a single tuple). The fourth and most commonly used join method involves first redistributing the two source relations by hashing on the join attribute.
Reference: [TERA85b] <author> Teradata Corp., </author> <title> DBC/1012 Data Base Computer Reference Manual, </title> <type> Rel. </type> <institution> 2.0, Teradata Corp. </institution> <note> Document No. C03-0001-02, </note> <month> November </month> <year> 1985. </year>
Reference-contexts: As a basis for determining the absolute performance of Gamma, we have used results obtained from a similar study [DEWI87] of the Teradata DBC/1012 database machine <ref> [TERA83, TERA85a, TERA85b] </ref>. When interpreting the results presented below, the reader should remember that Gamma is not a commercial product and, as such, its results may look slightly better for some queries.
Reference: [VALD84] <author> Valduriez, P., and G. Gardarin, </author> <title> Join and Semi-Join Algorithms for a Multiprocessor Database Machine ACM Transactions on Database Systems, </title> <journal> Vol. </journal> <volume> 9, No. 1, </volume> <month> March, </month> <year> 1984. </year>
Reference-contexts: The store operators assume the responsibility for writing the result tuples to disk. To enhance the performance of certain operations, an array of bit vector filters <ref> [BABB79, VALD84] </ref> is inserted into the split table. In the case of a join operation, each join process builds a bit vector filter by hashing the join attribute values while building its hash table using the inner relation [BRAT84, DEWI85, DEWI84, VALD84]. <p> In the case of a join operation, each join process builds a bit vector filter by hashing the join attribute values while building its hash table using the inner relation <ref> [BRAT84, DEWI85, DEWI84, VALD84] </ref>. When the hash table for the inner relation has been completed, the process sends its filter to its scheduler. After the scheduler has received all the filters, it sends them to the processes responsible for producing the outer relation of the join.
References-found: 24

