URL: http://www.research.digital.com/SRC/personal/monika/papers/sigir98.ps.gz
Refering-URL: http://www.research.digital.com/SRC/personal/Krishna_Bharat/WebArcheology/
Root-URL: http://www.research.digital.com
Email: bharat@pa.dec.com  monika@pa.dec.com  
Title: Improved Algorithms for Topic Distillation in a Hyperlinked Environment  
Author: Krishna Bharat Monika R. Henzinger 
Address: 130 Lytton Avenue Palo Alto, CA 94301  130 Lytton Avenue Palo Alto, CA 94301  
Affiliation: Digital Equipment Corporation Systems Research Center  Digital Equipment Corporation Systems Research Center  
Date: 1998  
Note: To appear at the 21st ACM SIGIR Conference on Research and Development in Information Retrieval  
Abstract: This paper addresses the problem of topic distillation on the World Wide Web, namely, given a typical user query to find quality documents related to the query topic. Connectivity analysis has been shown to be useful in identifying high quality pages within a topic specific graph of hyperlinked documents. The essence of our approach is to augment a previous connectivity analysis based algorithm with content analysis. We identify three problems with the existing approach and devise algorithms to tackle them. The results of a user evaluation are reported that show an improvement of precision at 10 documents by at least 45% over pure connectivity analysis. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> AltaVista, </author> <note> www.altavista.digital.com/ </note>
Reference: [2] <author> Anick, P.G. </author> <title> 1994 "Adapting a Full-text Information Retrieval System to Computer the Troubleshooting Domain." </title> <booktitle> Proc. of ACM SIGIR '94 pp. </booktitle> <pages> 349-358. </pages>
Reference-contexts: As argued by Marchionini [23] "end users want to achieve their goals with a minimum of cognitive load and a maximum of enjoyment." Correspondingly, in the context of Web searches we observe that users tend to type short queries (one to three words) <ref> [2, 9] </ref>, without giving much thought to query formulation. Additionally, it is often the case that users themselves are unclear about their information need [12] when framing the query. <p> The situation on the World Wide Web is different from the setting of conventional information retrieval systems for several reasons. The main reasons are: * Users tend to use very short queries (1 to 3 words per query <ref> [2, 9] </ref>) and are very reluctant to give feed back. * The collection changes continuously. * The quality and usefulness of documents varies widely. Some documents are very focused; others involve a patchwork of subjects.
Reference: [3] <author> Anick, P.G. and Vaithyanathan, S. </author> <year> 1997. </year> <title> "Exploiting Clustering and Phrases for Context-Based Information Retrieval." </title> <booktitle> Proc. of ACM SIGIR '97 pp. </booktitle> <pages> 314-323. </pages>
Reference-contexts: There has been much work in IR on supporting topic exploration. This is typically done by letting users browse topic hierarchies that are either predetermined (e.g., Cat-a-Cone [19]), or dynamically constructed by clustering based on user selection (e.g., Scatter/Gather [10], Paraphrase <ref> [3] </ref>). Another approach to topic exploration is interactive query expansion where new terms are suggested to help focus the query (e.g., [24, 15]). On the Web there are examples of topic hierarchies (e.g., Yahoo! [30, 16]), dynamic clustering (AltaVista's Live-Topics [5]) and query expansion (as in Excite [13]).
Reference: [4] <author> Bharat, K., Broder, A., Henzinger, M., Kumar, P., and Venkatasubramian, S. </author> <year> 1998. </year> <title> "The Connectivity Server: Fast Access to Linkage Information on the Web.", </title> <booktitle> Proc. of 7th World Wide Web Conference, </booktitle> <pages> pp. 469-477, </pages> <note> available as www7.conf. au/programme/fullpapers/1938/com1938.htm </note>
Reference-contexts: The running time is completely dominated by the time it takes to fetch the documents. With a download rate of 1 document per second queries takes about 30 minutes. To get fast access to linkage information within the World Wide Web, we built a Connectivity Server <ref> [4] </ref> that provides linkage information for all pages indexed by the AltaVista search engine. The server provides a specialized interface to compute the neighborhood graph for a set of URLs.
Reference: [5] <author> Bourdoncle, F. </author> <year> 1997 </year> <month> "LiveTopics: </month> <institution> Recherche Vi-suelle d'Information sur l'Internet." Dossiers de l'Audiovisuel, La Documentation Francaise No. </institution> <month> 74 (July-Aug </month> <year> 1997), </year> <pages> pp. 36-38. </pages>
Reference-contexts: Another approach to topic exploration is interactive query expansion where new terms are suggested to help focus the query (e.g., [24, 15]). On the Web there are examples of topic hierarchies (e.g., Yahoo! [30, 16]), dynamic clustering (AltaVista's Live-Topics <ref> [5] </ref>) and query expansion (as in Excite [13]). The goal of topic exploration is to locate a set of documents dealing with the user's topic of interest, whereas topic distillation assumes such a set and finds quality documents within it.
Reference: [6] <author> Chakrabarti, S., Dom, B., Gibson, D., Kleinberg, J., Raghavan P., and Rajagopalan, S. </author> <title> 1998 "Automatic Resource Compilation by Analyzing Hyperlink Structure and Associated Text" Proc. </title> <booktitle> of 7th World Wide Web Conference, </booktitle> <pages> pp. 65-74. </pages>
Reference-contexts: The last problem is by far the most common, and our general solution is to use content analysis to help keep the connectivity-based computation "on the topic." We compare the performance of 10 algorithms with the basic Kleinberg algorithm on 28 topics that were used previously in <ref> [6] </ref>. The best approach increases the precision over basic Kleinberg by at least 45% and takes less than 3 minutes. This running time is dominated by the time to fetch 130 documents from the World Wide Web and can be reduced considerably when term vectors for the documents are available. <p> We used relative recall instead of recall since we do not know the number of relevant documents for a topic on the Web, or even in the Neighborhood Graph. We used a set of 28 queries previously used by <ref> [6] </ref> in comparing the rankings from their version of Kleinberg's algorithm with category listings on the Web. <p> In terms of relative recall, compared with the best previous algorithm, selective pruning performed comparably for authority documents, and about 10% worse for hub documents. 7 Related Work The ARC algorithm of Chakrabarti et al <ref> [6] </ref> also extends Kleinberg's algorithm with textual analysis. ARC computes a distance-2 neighborhood graph and weights edges. The weight of each edge is based on the match between the query terms and the text surrounding the hyperlink in the source document.
Reference: [7] <author> Chu, H. and Rosenthal, M. </author> <title> 1996 "Search En--gines for the World Wide Web: A Comparative Study and Evaluation Methodology." </title> <booktitle> Proc. of ASIS 1996 Annual Conference. </booktitle>
Reference-contexts: Finally, our approach to evaluating precision at a fixed number of result documents based on user relevance ratings seems typical of ranking evaluations done on the Web (e.g., search service comparisons <ref> [7, 11] </ref>). 8 Conclusions In this paper we showed that Kleinberg's connectivity analysis has three problems. We presented various algorithms to address them. The simple modification suggested in algorithm imp achieved a considerable improvement in precision.
Reference: [8] <author> Cronin, B. and Snyder, B. </author> <note> 1996 "Citation Indexing's Achilles Heel? Evaluative Bibliomet-rics and Non Coverage of the Monographic Literature." www.slis.indiana.edu/Research/ cronin-achilles.html </note>
Reference-contexts: This is used to discover influential publications and authors with similar interests within the articles of a certain field of study. See [22] for a discussion on applying bibliometrics to the World Wide Web. Citation analysis has been criticized (see <ref> [8] </ref>) as a source of systematic bias, since members of cliquish communities tend to Without Regulation With Regulation Partial base imp med startmed maxby10 impr medr startmedr maxby10r pca0 pca1 Authorities At 5 0.15 0.19 0.22 0.2 0.21 0.2 0.22 0.19 0.21 0.22 0.23 At 10 0.27 0.35 0.39 0.41 0.37
Reference: [9] <author> Croft, W.B., Cook, R., and Wilder, D. </author> <year> 1995. </year> <title> "Providing Government Information on the Internet: Experience with `THOMAS'." U. of Mass. </title> <type> Technical Report 95-45. </type>
Reference-contexts: As argued by Marchionini [23] "end users want to achieve their goals with a minimum of cognitive load and a maximum of enjoyment." Correspondingly, in the context of Web searches we observe that users tend to type short queries (one to three words) <ref> [2, 9] </ref>, without giving much thought to query formulation. Additionally, it is often the case that users themselves are unclear about their information need [12] when framing the query. <p> The situation on the World Wide Web is different from the setting of conventional information retrieval systems for several reasons. The main reasons are: * Users tend to use very short queries (1 to 3 words per query <ref> [2, 9] </ref>) and are very reluctant to give feed back. * The collection changes continuously. * The quality and usefulness of documents varies widely. Some documents are very focused; others involve a patchwork of subjects.
Reference: [10] <author> Cutting, D.R., Karger, D.R., Pedersen, J., and Tukey, J.W. </author> <year> 1992. </year> <title> "Scatter/Gather: A Cluster-Based Approach to Browsing Large Document Collections." </title> <booktitle> Proc. of ACM SIGIR '92. </booktitle>
Reference-contexts: There has been much work in IR on supporting topic exploration. This is typically done by letting users browse topic hierarchies that are either predetermined (e.g., Cat-a-Cone [19]), or dynamically constructed by clustering based on user selection (e.g., Scatter/Gather <ref> [10] </ref>, Paraphrase [3]). Another approach to topic exploration is interactive query expansion where new terms are suggested to help focus the query (e.g., [24, 15]). On the Web there are examples of topic hierarchies (e.g., Yahoo! [30, 16]), dynamic clustering (AltaVista's Live-Topics [5]) and query expansion (as in Excite [13]).
Reference: [11] <author> Ding, W. and Marchionini. G. </author> <title> 1996 "Search Engines for the World Wide Web: A Comparative Study and Evaluation Methodology." </title> <booktitle> Proc. of ASIS 1996 Annual Conference. </booktitle>
Reference-contexts: Finally, our approach to evaluating precision at a fixed number of result documents based on user relevance ratings seems typical of ranking evaluations done on the Web (e.g., search service comparisons <ref> [7, 11] </ref>). 8 Conclusions In this paper we showed that Kleinberg's connectivity analysis has three problems. We presented various algorithms to address them. The simple modification suggested in algorithm imp achieved a considerable improvement in precision.
Reference: [12] <author> Efthimiadis, </author> <title> E.N. 1993 "A User-Centered Evaluation of Ranking Algorithms for Interactive Query Expansion", </title> <booktitle> Proc. of ACM SIGIR '93, </booktitle> <pages> pp. 146-159. </pages>
Reference-contexts: Additionally, it is often the case that users themselves are unclear about their information need <ref> [12] </ref> when framing the query. Since determining relevance accurately under these circumstances is hard, most search services are content to return exact query matches which may or may not satisfy the user's actual information need.
Reference: [13] <author> Excite, </author> <note> www.excite.com/ </note>
Reference-contexts: Another approach to topic exploration is interactive query expansion where new terms are suggested to help focus the query (e.g., [24, 15]). On the Web there are examples of topic hierarchies (e.g., Yahoo! [30, 16]), dynamic clustering (AltaVista's Live-Topics [5]) and query expansion (as in Excite <ref> [13] </ref>). The goal of topic exploration is to locate a set of documents dealing with the user's topic of interest, whereas topic distillation assumes such a set and finds quality documents within it. Hence, topic exploration may be viewed as a powerful preliminary step to topic distillation.
Reference: [14] <author> Golub, G., Van Loan, C. F., </author> <title> "Matrix Computations", </title> <publisher> Johns Hopkins University Press, </publisher> <address> Balti-more, </address> <year> 1989. </year>
Reference: [15] <author> Harman, D.K. </author> <title> 1988 "Towards Interactive Query Expansion." </title> <booktitle> Proc. of ACM SIGIR '88 pp. </booktitle> <pages> 321-331. </pages>
Reference-contexts: Another approach to topic exploration is interactive query expansion where new terms are suggested to help focus the query (e.g., <ref> [24, 15] </ref>). On the Web there are examples of topic hierarchies (e.g., Yahoo! [30, 16]), dynamic clustering (AltaVista's Live-Topics [5]) and query expansion (as in Excite [13]).
Reference: [16] <author> Infoseek, </author> <note> www.infoseek.com/ </note>
Reference-contexts: Another approach to topic exploration is interactive query expansion where new terms are suggested to help focus the query (e.g., [24, 15]). On the Web there are examples of topic hierarchies (e.g., Yahoo! <ref> [30, 16] </ref>), dynamic clustering (AltaVista's Live-Topics [5]) and query expansion (as in Excite [13]). The goal of topic exploration is to locate a set of documents dealing with the user's topic of interest, whereas topic distillation assumes such a set and finds quality documents within it.
Reference: [17] <author> Harman, D.K. </author> <title> 1995 "The TREC Conferences" R. </title> <editor> Kuhnlen and M. Rittberger (Eds.) </editor> <booktitle> Hypertext - Information Retrieval Multimedia: Synergieef-fekte Elektronischer Informationssysteme, Proc. of HIM '95 pp. </booktitle> <pages> 9-28. </pages>
Reference-contexts: Hence we used term frequencies measured in a crawl of 400,000 Yahoo! [30] documents in January 1997. 5 Evaluation Traditionally, ranking schemes are evaluated by computing precision and recall on a pre-labeled corpus, such as the TREC <ref> [17] </ref> collection. We compare our algorithms based on precision and relative recall at 5 and 10 documents. We used relative recall instead of recall since we do not know the number of relevant documents for a topic on the Web, or even in the Neighborhood Graph.
Reference: [18] <author> Hearst, M. </author> <title> 1997 "Distinguishing between Web Data Mining and Information Access: Position Statement." KDD '97 Panel on Web Data Mining. </title>
Reference-contexts: Hence, topic exploration may be viewed as a powerful preliminary step to topic distillation. This was suggested by Hearst in <ref> [18] </ref>, who observed that Klein-berg's algorithm does not bring forth documents that deal with less popular interpretations of the query. She suggests first clustering the documents to separate out the subtopics and then analyzing the induced subgraphs individually.
Reference: [19] <author> Hearst, M. and Karadi, C. </author> <year> 1997 </year> <month> "Cat-a-Cone: </month> <title> An Interactive Interface for Specifying Searches and Viewing Retrieval Results using a Large Category Hierarchy." </title> <booktitle> Proc. of ACM SIGIR '97, </booktitle> <pages> pp. 246-255. </pages>
Reference-contexts: PageRank [25] is a ranking algorithm for Web documents that uses connectivity to compute a topic-independent score for each document. There has been much work in IR on supporting topic exploration. This is typically done by letting users browse topic hierarchies that are either predetermined (e.g., Cat-a-Cone <ref> [19] </ref>), or dynamically constructed by clustering based on user selection (e.g., Scatter/Gather [10], Paraphrase [3]). Another approach to topic exploration is interactive query expansion where new terms are suggested to help focus the query (e.g., [24, 15]).
Reference: [20] <author> Karlin, S., Taylor, H. M., </author> <title> "A first course in stochastic processes", </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1975. </year>
Reference: [21] <author> Kleinberg, J. </author> <year> 1998. </year> <title> "Authoritative sources in a hyperlinked environment." </title> <note> Proc. of 9th ACM-SIAM Symposium on Discrete Algorithms. Also appeared as IBM Research Report RJ 10076, </note> <month> May </month> <year> 1997. </year>
Reference-contexts: However, transitivity is worth exploiting as well. If A is seen to point to a lot of good documents, then A's opinion becomes more valuable, and the fact that A points to B would suggest that B is a good document as well. Using this basic idea, Kleinberg <ref> [21] </ref> developed a connectivity analysis algorithm for hyperlinked environments. Given an initial set of results from a search service, the algorithm extracts a subgraph from the Web containing the result set and its neighboring documents. <p> In 1997 Kleinberg <ref> [21] </ref> published an algorithm for connectivity analysis on the World Wide Web which we describe next. 2.1 Kleinberg's Algorithm The algorithm computes two scores for each document: a hub score and an authority score. <p> Kleinberg <ref> [21] </ref> proved that the H and A vectors will eventually converge, i.e., that termination is guaranteed. In practice we found the vectors to converge in about 10 iterations. The documents are then ranked by hub and authority scores respectively. <p> Note that the algorithm does not claim to find all relevant pages, since there may be some that have good content but have not been linked to by many authors. In our evaluation of different algorithms we use Kleinberg's algorithm <ref> [21] </ref> as our baseline, which we call base. 2.2 Implementation To determine the neighborhood of the start set the algorithm needs to follow links that point in and out of these documents. Outlinks are easily obtained by fetching the document. <p> Outlinks are easily obtained by fetching the document. One way of obtaining inlinks is to use AltaVista queries of the form link : u, which returns a list of documents that point to the URL u. This was the implementation used by <ref> [21] </ref>. In our queries, the neighborhood graph contained on the order of 2000 nodes. The running time is completely dominated by the time it takes to fetch the documents. With a download rate of 1 document per second queries takes about 30 minutes.
Reference: [22] <author> Larson, </author> <title> R.R. 1996 "Bibliometrics of the World Wide Web: An Exploratory Analysis of the Intellectual Structure of Cyberspace." </title> <booktitle> Proc. of ASIS '96 Annual Conference. </booktitle>
Reference-contexts: Connectivity analysis of Web hyperlinks resembles the work on citation and co-citation analysis in the area of bibliometrics. This is used to discover influential publications and authors with similar interests within the articles of a certain field of study. See <ref> [22] </ref> for a discussion on applying bibliometrics to the World Wide Web.
Reference: [23] <author> Marchionini, G. </author> <year> 1992. </year> <title> "Interfaces for End-User Information Seeking." </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 43(2) </volume> <pages> 156-163. </pages>
Reference-contexts: 1 Introduction Search services on the World Wide Web are the information retrieval systems that most people are familiar with. As argued by Marchionini <ref> [23] </ref> "end users want to achieve their goals with a minimum of cognitive load and a maximum of enjoyment." Correspondingly, in the context of Web searches we observe that users tend to type short queries (one to three words) [2, 9], without giving much thought to query formulation.
Reference: [24] <author> Magennis, M. and van Rijsbergen, C.J. </author> <title> 1997 "The Potential and Actual Effectiveness of Interactive Query Expansion." </title> <booktitle> Proc. of ACM SIGIR '97, </booktitle> <pages> pp. 324-332. </pages>
Reference-contexts: Another approach to topic exploration is interactive query expansion where new terms are suggested to help focus the query (e.g., <ref> [24, 15] </ref>). On the Web there are examples of topic hierarchies (e.g., Yahoo! [30, 16]), dynamic clustering (AltaVista's Live-Topics [5]) and query expansion (as in Excite [13]).
Reference: [25] <author> Page, L. </author> <year> 1997 </year> <month> "PageRank: </month> <title> Bringing Order to the Web." </title> <booktitle> Stanford Digital Libraries Working Paper, </booktitle> <pages> 1997-0072. </pages>
Reference-contexts: Others have used inter-document linkage to compute useful data on the Web as well. Pirolli et al [26] run a computation on a inter-document matrix, with weights derived from linkage, content similarity and usage data, to identify usable structures. PageRank <ref> [25] </ref> is a ranking algorithm for Web documents that uses connectivity to compute a topic-independent score for each document. There has been much work in IR on supporting topic exploration.
Reference: [26] <author> Pirolli, P., Pitkow, J., and Rao, R. </author> <title> 1996 "Silk from a sow's ear: Extracting usable structures from the Web." </title> <booktitle> Proc. of ACM SIGCHI '96, </booktitle> <pages> pp. 118-125. </pages>
Reference-contexts: Indeed, the importance of considering referential statistics in document selection is increased since there is no quality control on the Web. Others have used inter-document linkage to compute useful data on the Web as well. Pirolli et al <ref> [26] </ref> run a computation on a inter-document matrix, with weights derived from linkage, content similarity and usage data, to identify usable structures. PageRank [25] is a ranking algorithm for Web documents that uses connectivity to compute a topic-independent score for each document.
Reference: [27] <author> Porter, M.F. </author> <title> 1980 "An Algorithm for Suffix Stripping." </title> <booktitle> Program, </booktitle> <volume> 14, </volume> <pages> 130-137. </pages>
Reference-contexts: To build term vectors we eliminate stop words and use Porter stemming <ref> [27] </ref>. For IDF weights, since we know of no source of IDF weights for the Web and of no official representative collection, we had to build our own collection.
Reference: [28] <author> Salton, G. and Buckley, C. </author> <year> 1988. </year> <title> "Term-Weighting Approaches in Automatic Text Retrieval." </title> <booktitle> Information Processing and Management, </booktitle> <volume> 24(5), </volume> <pages> 513-23. </pages>
Reference-contexts: In our implementation, since queries are long and the document vocabulary tends to be varied we use term frequency weighting. We use cosine normalization in weighting both the query and the documents since the deviation in term vector lengths is large. See Salton and Buckley <ref> [28] </ref> for a discussion of weighting options.
Reference: [29] <author> Velex, Weiss R., Sheldon M. A., Gifford, D. K. </author> <year> 1997. </year> <title> "Fast and Effective Query Refinement." </title> <booktitle> Proc. of ACM SIGIR '97, </booktitle> <pages> pp. 6-15. </pages>

References-found: 29

