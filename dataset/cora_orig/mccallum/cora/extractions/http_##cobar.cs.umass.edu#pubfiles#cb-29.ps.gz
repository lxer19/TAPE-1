URL: http://cobar.cs.umass.edu/pubfiles/cb-29.ps.gz
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: Email: fDaniels, Risslandg@cs.umass.edu  
Title: Integrating IR and CBR to Locate Relevant Texts and Passages.  
Author: Jody J. Daniels and Edwina L. Rissland 
Address: Amherst, MA 01003 USA  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: This paper presents the SPIRE system, a hybrid case-based reasoning (CBR) and information retrieval (IR) system that (1) from a large text collection, retrieves documents that are relevant to a presented problem case, and (2) highlights within those retrieved documents passages that contain relevant information about specific case features. We present an overview of SPIRE, run through an extended example, and present results comparing SPIRE's with human performance. We also compare the results obtained by varying the method by which queries are generated. SPIRE aids not only problem-solving but knowledge acquisition by focusing a text extractor-person or program-on areas of text where needed information is likely to be found. Once extracted, this information can be used to create new cases or data-base objects thus closing the loop in the problem-solving-knowledge-acquisition process. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> James P. Callan, W. Bruce Croft, and Stephen M. Harding. </author> <title> The INQUERY Retrieval System. </title> <editor> In A. M. Tjoa and I. Ramos, editors, </editor> <booktitle> Database and Expert Systems Applications: Proceedings of the International Conference in Valencia, Spain, </booktitle> <pages> pages 78-83, </pages> <address> Valencia, Spain, 1992. </address> <publisher> Springer Verlag, </publisher> <address> NY. </address>
Reference-contexts: In both stages, SPIRE uses cases to drive the INQUERY IR engine. In both stages, the cases are used as the basis for generating queries, which are then run by INQUERY <ref> [1] </ref> in the usual way. In the first stage, the query is run on the text col lection; in the second stage, it is run on individual documents. The rest of the paper is organized as follows.
Reference: [2] <author> William S. Cooper. </author> <title> Expected Search Length: A Single Measure of Retrieval Effectiveness Based on the Weak Ordering Action of Retrieval Systems. </title> <journal> American Documentation, </journal> <volume> 19 </volume> <pages> 30-41, </pages> <year> 1968. </year>
Reference: [3] <author> Jody J. Daniels. </author> <title> Retreival of Passages for Information Reduction. </title> <type> PhD thesis, </type> <institution> University of Mas-sachusetts, </institution> <address> Amherst, Amherst, MA, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: These came from a set of five base methods. The others in this set are: bag of words plus phrases, sum plus phrases, and set of words. Formation and results for these queries is discussed in more detail in <ref> [3] </ref>. We had SPIRE build two other sets of queries. The first is based on a term weighting scheme suggested by Kwok [5] and the second set is what we called semi-random. The latter incorporated only one-half or one-third of the available query terms from the excerpt case-base. <p> The latter incorporated only one-half or one-third of the available query terms from the excerpt case-base. Neither of these sets performed better than the two base queries. (See <ref> [3] </ref> for details.) To provide another point of comparison, we also had a human expert, familiar with both the domain and INQUERY query operators, create a set of sophisticated queries. The manual queries were refined over time and may use many more types of operators than the SPIRE-generated queries.
Reference: [4] <author> Jody J. Daniels and Edwina L. Rissland. </author> <title> A Case-Based Approach to Intelligent Information Retrieval. </title> <booktitle> In Proceedings of the 18th Annual International ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 238-245, </pages> <address> Seattle, WA, </address> <month> July </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: This query is then run against the larger corpus of texts, with the result that new documents are retrieved and ranked according to IN-QUERY's belief as to their relevance to the posed query. (Details on this process of stage one can be found in <ref> [4, 6] </ref>.) In the second stage, SPIRE locates germane passages within each of the texts retrieved in stage one.
Reference: [5] <author> K. L. Kwok. </author> <title> A New Method of Weighting Query Terms for Ad-Hoc Retrieval. </title> <booktitle> In Proceedings of the 19th Annual International ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 187-195, </pages> <address> Zurich, Switzerland, </address> <month> August </month> <year> 1996. </year> <note> ACM. </note>
Reference-contexts: Formation and results for these queries is discussed in more detail in [3]. We had SPIRE build two other sets of queries. The first is based on a term weighting scheme suggested by Kwok <ref> [5] </ref> and the second set is what we called semi-random. The latter incorporated only one-half or one-third of the available query terms from the excerpt case-base.
Reference: [6] <author> Edwina L. Rissland and Jody J. Daniels. </author> <title> The Synergistic Application of CBR to IR. </title> <journal> Artificial Intelligence Review, </journal> <volume> 10 </volume> <pages> 441-475, </pages> <year> 1996. </year>
Reference-contexts: This query is then run against the larger corpus of texts, with the result that new documents are retrieved and ranked according to IN-QUERY's belief as to their relevance to the posed query. (Details on this process of stage one can be found in <ref> [4, 6] </ref>.) In the second stage, SPIRE locates germane passages within each of the texts retrieved in stage one.
References-found: 6

