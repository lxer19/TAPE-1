URL: http://www.merl.com/reports/TR93-04/TR93-04.ps.gz
Refering-URL: http://www.merl.com/reports/TR93-04/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: schabes@merl.com dick@merl.com  
Title: A Cubic-Time Parsable, Lexicalized Normal Form For Context-Free Grammar That Preserves Tree Structure  
Author: Yves Schabes and Richard C. Waters 
Note: Submitted to Computational Linguistics Copyright c Mitsubishi Electric Research Laboratories, 1993 201 Broadway,  
Address: 201 Broadway; Cambridge, MA 02139  Cambridge, Massachusetts 02139  
Date: 93-04 June 1993  
Affiliation: MITSUBISHI ELECTRIC RESEARCH LABORATORIES CAMBRIDGE RESEARCH CENTER  Mitsubishi Electric Research Laboratories  
Pubnum: Technical Report  
Abstract: Lexicalized context-free grammar (LCFG) is a tree-based formalism that makes use of both tree substitution and a restricted form of tree adjunction. Because of its use of adjunction, LCFG allows sufficient freedom in the way derivations can be performed that lexicalization of context-free grammars (CFGs) is possible while preserving the structure of the trees derived by the CFGs. However, the tree adjunction permitted is sufficiently restricted that LCFGs are string-wise equivalent to CFGs and have the same cubic-time worst-case complexity bounds for recognition and parsing. This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories of Cambridge, Massachusetts; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories. All rights reserved. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jay C. Earley. </author> <title> An Efficient Context-Free Parsing Algorithm. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1968. </year>
Reference-contexts: As illustrated in Figure 21, the traversal begins left and above the root node and ends right and above the root node. In a manner analogous to dotted rules for CFG as defined by Earley <ref> [1] </ref>, being at a particular position with regard to a particular node, divides the tree containing the node into two parts: a left context consisting of nodes that have been already been traversed and a right context that still needs to be traversed.
Reference: [2] <author> Jay C. Earley. </author> <title> An efficient context-free parsing algorithm. </title> <journal> Commun. ACM, </journal> <volume> 13(2) </volume> <pages> 94-102, </pages> <year> 1970. </year>
Reference-contexts: By recording how each pair was introduced in each cell of the array C, one can extend the recognizer to produce all derivations of the input. 24 Schabes & Waters 6 An Earley-Style Cubic-Time Parser For LCFG By combining top-down prediction as in Earley's algorithm for parsing CFGs <ref> [2] </ref> with bottom-up recognition as in the last section, one can obtain a more efficient left-to-right parsing algorithm for LCFG that maintains the valid prefix property and requires O (n 3 ) time in the worst case. <p> The traversal rules in Figure 23 control the left-to-right traversal of elementary trees. The scanning, and substitution rules recognize substitutions of trees and are similar to the steps found in Earley's parser for CFGs <ref> [2] </ref>. The left and right adjunction rules recognize the adjunction of left and right auxiliary trees. These 14 rules are discussed in detail below. The traversal rules (2-4) move from node to node in initial trees as indicated by the arrows in Figure 21.
Reference: [3] <author> S. A. Greibach. </author> <title> A new normal-form theorem for context-free phrase-structure grammars. </title> <journal> J. ACM, </journal> <volume> 12 </volume> <pages> 42-52, </pages> <year> 1965. </year>
Reference-contexts: It can be shown that for any CFG G (that does not derive the empty string), there is a GNF grammar G 0 that derives the same strings <ref> [3] </ref>. For most grammars G, strings can be recognized much more quickly using G 0 than G, using left-to-right bottom-up algorithms.
Reference: [4] <author> Aravind K. Joshi and Yves Schabes. </author> <title> Tree-adjoining grammars and lexicalized grammars. </title> <editor> In Maurice Nivat and Andreas Podelski, editors, </editor> <title> Tree Automata and Languages. </title> <publisher> Elsevier Science, </publisher> <year> 1992. </year>
Reference-contexts: An interesting example of a formalism with greater derivational freedom than CFG is tree substitution grammar (TSG) <ref> [4] </ref>. In TSG, the combining operation is substitution just as in CFG, however, the items to be combined are extended to multi-level trees (called initial trees) instead of just one-level rules. Substitution combines two trees by replacing a leaf in one tree with another tree. <p> A TSG G can be altered by combining initial trees with substitution to create larger initial trees without changing the trees produced. The extra derivational freedom provided by TSG makes it possible to lexicalize many CFGs. However, as shown by Schabes and Joshi <ref> [7, 4] </ref>, TSG cannot be used to lexicalize every CFG. Derivational freedom can be increased further by using the context-sensitive operation of adjunction. Adjunction combines two trees by expanding an internal node in one tree by inserting another tree. <p> Adjunction combines two trees by expanding an internal node in one tree by inserting another tree. This opens up many more possibilities for altering a grammar without changing the trees produced and makes it possible to lexicalize CFG. In particular, Schabes 2 Schabes & Waters and Joshi <ref> [7, 4] </ref> have shown that lexicalized tree adjoining grammar (LTAG) lexicalizes CFG in the strong sense defined above. Unfortunately, context-sensitive operations entail much larger computation costs for parsing and recognition than CFGs. <p> As a result, there are no computational advantages to lexicalizing a grammar using LTAG because the speedup due to the grammar becoming lexicalized is swamped by the dramatic increase in fundamental worst-case cost. Heretofore, every method for lexicalizing CFGs in the strong sense defined above has required context-sensitive operations <ref> [4] </ref>. As a result, every method for lexicalizing CFGs has shared with LTAG the unfortunate feature that lexicalization leads to dramatically decreased rather than increased computational performance. <p> Lexicalized Context-Free Grammar 3 2 Lexicalized Context-Free Grammar Lexicalized context-free grammar (LCFG) [11] is a tree generating system that is a restricted form of lexicalized tree-adjoining grammar (LTAG) <ref> [7, 4] </ref>. Informally speaking, the grammar consists of two sets of trees: initial trees, which are combined by substitution and auxiliary trees, which are combined by adjunction. An LCFG is lexicalized because every initial and auxiliary tree is required to contain a terminal symbol on its frontier. <p> If each elementary structure contains a lexical item as its leftmost non-empty constituent, the grammar is said to be left anchored. This facilitates efficient left to right parsing. Definition 3 (lexicalization <ref> [4] </ref>) A formalism F is lexicalized by another formalism F 0 , if for every finitely ambiguous grammar G in F that does not derive the empty string, there is a lexicalized grammar G 0 in F 0 such that G and G 0 generate the same tree set (and therefore <p> A lexicalization procedure is a procedure that generates G 0 from G. The restrictions on the form of G are motivated by two key properties of lexicalized grammars <ref> [4] </ref>. Lexicalized grammars cannot derive the empty string, because every structure introduces at least one lexical item. Thus, if a grammar is to be lexicalized, it must not be the case that S fl )". <p> In particular, in addition to many other trees, the CFG in Figure 7 generates a balanced tree of the form shown on the right of the figure with minimum path length i + 1 for the string a 2 i . As argued in <ref> [4] </ref>, due to the unbounded nature of the trees produced, neither GNF, CFG, nor TSG is capable of lexicalizing the grammar in Figure 7. 3.1 GNF Does Not lexicalize CFG Greibach normal form (GNF) is a restricted form of CFG where every production rule is required to be of the form
Reference: [5] <author> Joachim Lambek. </author> <title> The mathematics of sentence structure. </title> <journal> American Mathematical Monthly, </journal> <volume> 65 </volume> <pages> 154-170, </pages> <year> 1958. </year>
Reference-contexts: If more than one lexical item appears, either just one lexical item is designated as the anchor or a subset of the lexical items local to the structure are designated as a multi-component anchor. Note that Categorial Grammars <ref> [5, 13] </ref> are lexicalized according to the definition above since each basic category has a lexical item associated with it. A lexicalized grammar can be organized as a lexicon where each lexical item is associated with a finite number of structures for which that item is the anchor.
Reference: [6] <author> Bernard Lang. </author> <title> The systematic constructions of Earley parsers: Application to the production of O(n 6 ) Earley parsers for Tree Adjoining Grammars. </title> <booktitle> In Proceedings of the 1st International Workshop on Tree Adjoining Grammars, </booktitle> <address> Dagstuhl Castle, FRG, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: Lexicalized Context-Free Grammar 19 5 LCFG is Cubic-Time Parsable Since LCFG is a restricted case of tree-adjoining grammar (TAG), standard O (n 6 )-time TAG parsers <ref> [15, 8, 6] </ref> can be used for parsing LCFG. Further, they can be straightforwardly modified to require at most O (n 4 )-time when applied to LCFG. However, this still does not take full advantage of the context-freeness of LCFG.
Reference: [7] <author> Yves Schabes. </author> <title> Mathematical and Computational Aspects of Lexicalized Grammars. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <address> Philadelphia, PA, </address> <month> August </month> <year> 1990. </year> <note> Available as technical report (MS-CIS-90-48, LINC LAB179) from the Department of Computer Science. </note>
Reference-contexts: A TSG G can be altered by combining initial trees with substitution to create larger initial trees without changing the trees produced. The extra derivational freedom provided by TSG makes it possible to lexicalize many CFGs. However, as shown by Schabes and Joshi <ref> [7, 4] </ref>, TSG cannot be used to lexicalize every CFG. Derivational freedom can be increased further by using the context-sensitive operation of adjunction. Adjunction combines two trees by expanding an internal node in one tree by inserting another tree. <p> Adjunction combines two trees by expanding an internal node in one tree by inserting another tree. This opens up many more possibilities for altering a grammar without changing the trees produced and makes it possible to lexicalize CFG. In particular, Schabes 2 Schabes & Waters and Joshi <ref> [7, 4] </ref> have shown that lexicalized tree adjoining grammar (LTAG) lexicalizes CFG in the strong sense defined above. Unfortunately, context-sensitive operations entail much larger computation costs for parsing and recognition than CFGs. <p> Lexicalized Context-Free Grammar 3 2 Lexicalized Context-Free Grammar Lexicalized context-free grammar (LCFG) [11] is a tree generating system that is a restricted form of lexicalized tree-adjoining grammar (LTAG) <ref> [7, 4] </ref>. Informally speaking, the grammar consists of two sets of trees: initial trees, which are combined by substitution and auxiliary trees, which are combined by adjunction. An LCFG is lexicalized because every initial and auxiliary tree is required to contain a terminal symbol on its frontier. <p> The key concept is that each structure (e.g., production rule, elementary tree) in the grammar contains a lexical item that is realized. More precisely, a lexicalized grammar <ref> [9, 7] </ref> can be defined as follows: Definition 2 (Lexicalized Grammars) A lexicalized grammar consists of a finite set of elementary structures of finite size, each of which contains an overt (i.e., non-empty) lexical item, and a finite set of operations for creating derived structures.
Reference: [8] <author> Yves Schabes. </author> <title> The valid prefix property and left to right parsing of tree-adjoining grammar. </title> <booktitle> In Proceedings of the second International Workshop on Parsing Technologies, </booktitle> <address> Cancun, Mexico, </address> <month> February </month> <year> 1991. </year>
Reference-contexts: Lexicalized Context-Free Grammar 19 5 LCFG is Cubic-Time Parsable Since LCFG is a restricted case of tree-adjoining grammar (TAG), standard O (n 6 )-time TAG parsers <ref> [15, 8, 6] </ref> can be used for parsing LCFG. Further, they can be straightforwardly modified to require at most O (n 4 )-time when applied to LCFG. However, this still does not take full advantage of the context-freeness of LCFG. <p> The algorithm is a general recognizer for LCFGs, which requires no condition on the grammar. It is particularly interesting in light of the fact that the best known parser for LTAG that maintains the valid prefix property requires O (n 9 )-time in the worst case <ref> [8] </ref> versus only O (n 6 ) for LTAG parsers that do not maintain the valid prefix property. The algorithm collects states into a set called the chart C.
Reference: [9] <author> Yves Schabes, Anne Abeille, and Aravind K. Joshi. </author> <title> Parsing strategies with `lexicalized' grammars: Application to tree adjoining grammars. </title> <booktitle> In Proceedings of the 12 th International Conference on Computational Linguistics (COLING'88), </booktitle> <address> Budapest, Hungary, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: The key concept is that each structure (e.g., production rule, elementary tree) in the grammar contains a lexical item that is realized. More precisely, a lexicalized grammar <ref> [9, 7] </ref> can be defined as follows: Definition 2 (Lexicalized Grammars) A lexicalized grammar consists of a finite set of elementary structures of finite size, each of which contains an overt (i.e., non-empty) lexical item, and a finite set of operations for creating derived structures.
Reference: [10] <author> Yves Schabes and Aravind K. Joshi. </author> <title> Parsing with lexicalized tree adjoining grammar. In Masaru Tomita, editor, Current Issues in Parsing Technologies. </title> <publisher> Kluwer Accademic Publishers, </publisher> <year> 1990. </year>
Reference-contexts: For efficiency sake, the prediction of an elementary tree at position j (by rules 5, 11, & 13) should be prevented if the anchor of the ruled does not appear in a j+1 a n <ref> [10] </ref>. A number of the rules in Figure 23 (in particular, 2, 3, 4, 9, and 10) merely move from state to state without changing the left context i; j. These rules reflect facts about the grammar and the traversal and do not refer to the input.
Reference: [11] <author> Yves Schabes and Waters R.C. </author> <title> Lexicalized context-free grammars. </title> <booktitle> In 21 st Meeting of the Association for Computational Linguistics (ACL'93), </booktitle> <address> Columbus, Ohio, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Lexicalized Context-Free Grammar 3 2 Lexicalized Context-Free Grammar Lexicalized context-free grammar (LCFG) <ref> [11] </ref> is a tree generating system that is a restricted form of lexicalized tree-adjoining grammar (LTAG) [7, 4]. Informally speaking, the grammar consists of two sets of trees: initial trees, which are combined by substitution and auxiliary trees, which are combined by adjunction. <p> The adjunction of a left auxiliary tree is referred to as left adjunction (see Figure 3). The adjunction of a right auxiliary tree is referred to as right adjunction (see Figure 4). 1 In <ref> [11] </ref> these three kinds of auxiliary trees are referred to differently as right recursive, left recursive, and centrally recursive, respectively. 4 Schabes & Waters Dfl boy NP seems V VP* pretty A N* VP* smoothl y Adv NP 0 fl V NP 1 fl S e i l eft VP S
Reference: [12] <author> Yves Schabes and Stuart Shieber. </author> <title> An alternative conception of tree-adjoining derivation. </title> <booktitle> In 20 th Meeting of the Association for Computational Linguistics (ACL'92), </booktitle> <year> 1992. </year>
Reference-contexts: The procedure could easily be modified to account for other constraints on the way derivation should proceed such as those suggested for LTAGs <ref> [12] </ref>. The procedure Add puts a pair into the array C. If the pair is already present, nothing is done. However, if it is new, it is added to C and other pairs may be added as well. <p> For the sake of simplicity, it was assumed above that there are no constraints on adjunction. However, the algorithm can easily be extended to handle such constraints. It can also be extended to handle the alternative definition of TAG derivation found in <ref> [12] </ref>. 6.1 Efficiency Improvements To the Earley-Style Parser When implementing the algorithm above, two steps should be taken to improve the efficiency of the result: grammar pruning and equivalent state merging.
Reference: [13] <author> Mark Steedman. </author> <title> Combinatory grammars and parasitic gaps. </title> <booktitle> Natural Language and Linguistic Theory, </booktitle> <volume> 5 </volume> <pages> 403-439, </pages> <year> 1987. </year>
Reference-contexts: If more than one lexical item appears, either just one lexical item is designated as the anchor or a subset of the lexical items local to the structure are designated as a multi-component anchor. Note that Categorial Grammars <ref> [5, 13] </ref> are lexicalized according to the definition above since each basic category has a lexical item associated with it. A lexicalized grammar can be organized as a lexicon where each lexical item is associated with a finite number of structures for which that item is the anchor.
Reference: [14] <author> J. W. Thatcher. </author> <title> Characterizing derivations trees of context free grammars through a generalization of finite automata theory. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 5 </volume> <pages> 365-396, </pages> <year> 1971. </year>
Reference-contexts: The path set is a set of strings over [ NT [ f"g.) The path sets for CFG (and TSG) are regular languages <ref> [14] </ref>. In contrast, just as for LTAGS and TAGS, the path sets for LCFGs are context-free languages. To see this, consider that adjunction makes it possible to embed a sequence of nodes (the spine of the auxiliary tree) in place of a node on a path.
Reference: [15] <author> K. Vijay-Shanker. </author> <title> A Study of Tree Adjoining Grammars. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Science, University of Pennsylvania, </institution> <year> 1987. </year>
Reference-contexts: Lexicalized Context-Free Grammar 19 5 LCFG is Cubic-Time Parsable Since LCFG is a restricted case of tree-adjoining grammar (TAG), standard O (n 6 )-time TAG parsers <ref> [15, 8, 6] </ref> can be used for parsing LCFG. Further, they can be straightforwardly modified to require at most O (n 4 )-time when applied to LCFG. However, this still does not take full advantage of the context-freeness of LCFG.
References-found: 15

