URL: http://www.cs.dartmouth.edu/~gdavis/papers/spie.ps.gz
Refering-URL: http://www.cs.dartmouth.edu/~gdavis/
Root-URL: http://www.cs.dartmouth.edu
Title: Adaptive Time-Frequency Decompositions with Matching Pursuits  
Author: Geoffrey Davis, Stephane Mallat, and Zhifeng Zhang 
Address: 251 Mercer Street, New York, NY 10012  
Affiliation: New York University, Courant Institute  
Abstract: Computing the optimal expansion of a signal in a redundant dictionary of waveforms is an NP-hard problem. We introduce a greedy algorithm, called a matching pursuit, which computes a suboptimal expansion. The dictionary waveforms which best match a signal's structures are chosen iteratively. An orthogonalized version of the matching pursuit is also developed. Matching pursuits are general procedures for computing adaptive signal representations. With a dictionary of Gabor functions, a matching pursuit defines an adaptive time-frequency transform. We derive a signal energy distribution in the time-frequency plane which does not contain interference terms, unlike the Wigner and Cohen class distributions. Matching pursuits are chaotic maps whose attractors define a generic noise with respect to the dictionary. We derive an algorithm that isolates the coherent structures of a signal and describe an application to pattern extraction from noisy signals. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Chen, S. A. Billings, and W. Luo, </author> <title> "Orthogonal least squares methods and their application to non-linear system identification", </title> <journal> International Journal of Control, </journal> <volume> vol. 50, No. 5, </volume> <pages> pp. 1873-1896, </pages> <year> 1989. </year>
Reference-contexts: We accomplish this by orthogonalizing the set of dictionary vectors as we proceed with the decomposition. This iterative orthogonalization is equivalent to performing the back-projection described above at each step of the decomposition, but is much more efficient. This type of algorithm was first introduced for control applications <ref> [1] </ref> and also studied independently from this work by Pati et al. [11]. It has the advantage of providing better approximations than the matching pursuit algorithm, but it requires much more computation and can introduce numerical instabilities into the expansions. We describe by induction this orthogonal pursuit.
Reference: [2] <author> L. Cohen, </author> <title> "Time-frequency distributions: </title> <journal> a review" Proceedings of the IEEE, </journal> <volume> Vol. 77, No. 7, </volume> <pages> pp. 941-979, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: It also remains positive if W g (t; !) is positive, which the case when g (t) is Gaussian. On the other hand, the energy density Ef (t; !) does not satisfy marginal properties, as opposed to certain Cohen class distributions <ref> [2] </ref>. However, the importance of these marginal properties for signal processing is not clear.
Reference: [3] <author> I. Daubechies, </author> <title> Ten Lectures on Wavelets, </title> <journal> CBMS-NSF Series in Appl. Math., SIAM, </journal> <year> 1991. </year>
Reference-contexts: For our numerical examples we use the Gaussian window g (t) = 2 1=4 e t 2 . The dictionary of time-frequency atoms D = (g fl (t)) fl2 is a very redundant set of functions that includes window Fourier frames and wavelet frames <ref> [3] </ref>. When the signals include time-frequency structures of very different types, one cannot choose a priori a frame that is well adapted to performing the expansion. Instead, we need to find the atoms in the dictionary that best match each given signal's structures in order to perform a compact decomposition.
Reference: [4] <author> G. Davis, S. Mallat, and M. Avellaneda, </author> <title> "Chaos in Adaptive Approximations", </title> <type> Technical Report, </type> <institution> Computer Science, NYU, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: If we restrict the number of bits of a n to fi (N j ) and the number of vectors in D to fi (N k ), for fixed j; k, then we can prove <ref> [4] </ref> that finding an optimal expansion is NP-hard. Because of the difficulty of finding optimal solutions, we instead develop a greedy algorithm that computes a good sub-optimal approximation. Let f 2 H. <p> In <ref> [4] </ref> we show that p iterations of a pursuit requires O (pI Z) operations. The number of times we sub-decompose the residues of a given signal f depends upon the desired precision of the approximation, *. <p> The next theorem is similar to Theorem 1 and guarantees the convergence of the orthogonal pursuit <ref> [4] </ref>. Theorem 2 Let f 2 H. Let N be the dimension of H (N may be infinite). The orthogonal matching pursuit converges in M N iterations (M may be infinite if N is infinite). <p> Because the updating relation (38) involves the orthogonalized dictionary vectors, u n , instead of the g fl n , updating the inner products &lt; R n f; g fl &gt; requires much more work. In <ref> [4] </ref> we show that computing p iterations of an orthogonalized pursuit requires O (p 2 IZ) operations, as compared to O (pI Z) for a non-orthogonal pursuit. <p> The left shift map is known to be a chaotic map. The topological properties of the renormalized matching pursuit map are similar to those of the left shift map, at least locally. We proved <ref> [4] </ref> that for a particular dictionary in R 3 , the renormalized matching pursuit map is topologically equivalent to a shift map, which proves that this renormalized matching pursuit map is a chaotic map with well-understood properties. <p> Experimental data suggest that the residues of a normalized matching pursuit converge to a chaotic attractor in high dimensional spaces as well. This is proved <ref> [4] </ref> for a simple dictionary composed of Diracs and complex exponentials, and the similar behavior is observed for more complicated dictionaries such as the one composed of Gabor functions. The residues converge to realizations of a specific process that we call dictionary noise. <p> The residues converge to realizations of a specific process that we call dictionary noise. If the dictionary is invariant when we translate its elements or multiply them by a complex exponential, one can then prove <ref> [4] </ref> that this process is white and stationary. This is the case for a Gabor dictionary. Realizations of a dictionary noise are signals whose inner products with elements of the dictionary are uniformly small.
Reference: [5] <author> J. H. Friedman and W. Stuetzle, </author> <title> "Projection pursuit regression," </title> <journal> Journal of the American Statistical Association, </journal> <volume> Vol. 76, </volume> <pages> pp. 817-823, </pages> <year> 1981. </year>
Reference-contexts: Although this decomposition is non-linear, we maintain an energy conservation as though it were a linear, orthogonal decomposition. An important issue is to understand the behavior of the residue R m f when m increases. By adapting a result proved by Jones [9] for projection pursuit algorithms <ref> [5] </ref>, one can prove [10] that the matching pursuit algorithm converges, even in infinite dimensional spaces. 4 Theorem 1 Let f 2 H.
Reference: [6] <author> M. R. Garey and D. S. Johnson, </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness, </title> <editor> W. H. </editor> <publisher> Freeman and Co., </publisher> <address> New York, </address> <year> 1979. </year>
Reference: [7] <author> R. Gray, </author> <title> "Vector quantization", </title> <journal> IEEE Acoustic Speech and Signal Processing Magazine, </journal> <month> April </month> <year> 1984. </year>
Reference: [8] <author> P. J. Huber, </author> <title> "Projection Pursuit", </title> <journal> The Annals of Statistics, </journal> <volume> vol. 13, No. 2, </volume> <pages> p. 435-475, </pages> <year> 1985. </year>
Reference: [9] <author> L. K. Jones, </author> <title> "On a conjecture of Huber concerning the convergence of projection pursuit regression", </title> <journal> The Annals of Statistics, </journal> <volume> vol. 15, No. 2, </volume> <pages> p. 880-882, </pages> <year> 1987. </year>
Reference-contexts: Although this decomposition is non-linear, we maintain an energy conservation as though it were a linear, orthogonal decomposition. An important issue is to understand the behavior of the residue R m f when m increases. By adapting a result proved by Jones <ref> [9] </ref> for projection pursuit algorithms [5], one can prove [10] that the matching pursuit algorithm converges, even in infinite dimensional spaces. 4 Theorem 1 Let f 2 H.
Reference: [10] <author> S. Mallat and Z. </author> <title> Zhang "Matching Pursuit with Time-Frequency Dictionaries", </title> <journal> IEEE Trans. on Signal Processing, </journal> <month> Dec. </month> <year> 1993. </year> <month> 14 </month>
Reference-contexts: An important issue is to understand the behavior of the residue R m f when m increases. By adapting a result proved by Jones [9] for projection pursuit algorithms [5], one can prove <ref> [10] </ref> that the matching pursuit algorithm converges, even in infinite dimensional spaces. 4 Theorem 1 Let f 2 H. <p> Dictionaries are generally built so that this inner product is computed with a small number of operations. We describe in <ref> [10] </ref> how to compute efficiently the inner product of two discrete Gabor atoms, in O (1) operations. 5 Let I be the number of operations required to compute &lt; g fl n ; g fl &gt; and let Z be the average number of g fl 's in D ff for <p> Let G = (&lt; g fl n ; g fl k &gt;) 0k&lt;m;0n&lt;m be the Gram matrix of the selected vectors. The linear system of equations (30) can be written Y = GX. A solution of this system is computed efficiently with a conjugate gradient algorithm <ref> [10] </ref>. If H is of finite dimension N , there are many classes of dictionaries for which any collection of N distinct dictionary vectors is a basis of H. This is the case for the Gabor dictionary used for time-frequency decompositions. <p> The coherent components of f , then, are the first m selected dictionary vectors (g fl n ) 0n&lt;m . The expected value e has been measured numerically for a Gabor dictionary <ref> [10] </ref>. The values of ( ~ R m f ) as a function of m for the "wavelets" signal and the noisy "wavelets" signal are shown in Figure 8. The coherence ratio for the noisy signal converges much more quickly to e because the noise has diluted the coherent structures.
Reference: [11] <author> Y. C. Pati R. Rezaiifar, and P. S. Krishnaprasad, </author> <title> "Orthogonal Matching Pursuit: Recursive Function Approximation with Applications to Wavelet Decomposition," </title> <booktitle> Proceedings of the 27 th Annual Asilomar Conference on Signals, Systems, and Computers, </booktitle> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: This iterative orthogonalization is equivalent to performing the back-projection described above at each step of the decomposition, but is much more efficient. This type of algorithm was first introduced for control applications [1] and also studied independently from this work by Pati et al. <ref> [11] </ref>. It has the advantage of providing better approximations than the matching pursuit algorithm, but it requires much more computation and can introduce numerical instabilities into the expansions. We describe by induction this orthogonal pursuit. For n = 0, we set R 0 f = f .
Reference: [12] <author> S. Qian and D. Chen, </author> <title> "Signal Representation via Adaptive Normalized Gaussian Functions," </title> <journal> IEEE Trans. on Signal Processing, </journal> <volume> vol. 36, no. 1, </volume> <month> Jan. </month> <year> 1994. </year> <month> 15 </month>
Reference-contexts: We therefore only keep the first sum and define Ef (t; !) = n=0 A similar decomposition algorithm over time-frequency atoms was derived independently by Qian and Chen <ref> [12] </ref>, in order to define this energy distribution in the time-frequency plane.
References-found: 12

