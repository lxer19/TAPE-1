URL: http://www.cri.ensmp.fr/doc/A-295.ps.gz
Refering-URL: http://www.cri.ensmp.fr/rapports.html
Root-URL: 
Title: par Mme Beatrice CREUSILLET Sujet Analyses de regions de tableaux et applications  
Author: Th ese presentee Date de soutenance Devant le jury compose de MM. Yves Rouchaleau President Fran~cois Irigoin Directeur Paul Feautrier Rapporteur William Pugh Rapporteur Patrice Quinton Rapporteur Fran~cois Bourdoncle Examinateur Alain Darte Examinateur Bernard Dion Examinateur 
Address: Paris, 60, bd Saint-Michel, Paris  
Date: 5 decembre 1996  
Affiliation: Ecole des mines de Paris Centre de Recherche en Informatique  pour obtenir le grade de Docteur en sciences Informatique Temps R eel, Robotique et Automatique de l' Ecole des mines de Paris  Lieu de soutenance Ecole des mines de  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1986. </year>
Reference-contexts: In a commercial compiler where compilation time is a choice criterion, all the previous analyses, except out regions, should be performed simultaneously, to avoid multiple traversals of the program representation. 6.10 Related Work Traditionally, data flow analysis techniques were first devoted to scalar variables <ref> [117, 82, 113, 1, 153] </ref>; accesses to array elements were treated as accesses to the whole array. This was however insufficient to efficiently parallelize many scientific programs dealing with structured data. The first improvement was the introduction of array data dependence analysis [21]. <p> ensemble de droites L = fl 1 ; : : : ; l ffi g. * Un sommet est un point v 2 P qui n'est pas combinaison lineaire d'autres points de P : &gt; &gt; &gt; &gt; &gt; &gt; &lt; v = i=1 i x i 8 i 2 <ref> [1; p] </ref> i 0 P p =) (8 i 2 [1; p]; i= 0 ou v = x i ) * Un rayon est un vecteur r 2 R n tel qu'il existe une demi-droite parallele a r, et entierement contenue dans P : 8 x 2 P; 8 2 Z <p> : ; l ffi g. * Un sommet est un point v 2 P qui n'est pas combinaison lineaire d'autres points de P : &gt; &gt; &gt; &gt; &gt; &gt; &lt; v = i=1 i x i 8 i 2 <ref> [1; p] </ref> i 0 P p =) (8 i 2 [1; p]; i= 0 ou v = x i ) * Un rayon est un vecteur r 2 R n tel qu'il existe une demi-droite parallele a r, et entierement contenue dans P : 8 x 2 P; 8 2 Z + ; x + r 2 P * Une droite <p> QUELQUES RAPPELS 129 P est alors defini par : P = x : fi fi fi fi 9 -1 ; : : : ; -ff 2 <ref> [0; 1] </ref> i=1 i= 1 9 1 ; : : : ; ffi 2 Z ff X i v i + i=1 ffi X i l i Ces deux representations sont equivalentes, et des algorithmes permettent de passer de l'une a l'autre [90, 74]. <p> a set of lines L = fl 1 ; : : : ; l ffi g. * A vertex is a point v 2 P which is not a linear combination of other points of P : 8 &gt; &gt; &gt; &gt; &gt; &gt; : P p 8 i 2 <ref> [1; p] </ref> x i 2 P 8 i; j 2 [1; p] i 6= j ) x i 6= x j i=1 i= 1 * A ray is a vector r 2 R n such that there exists an half-line parallel to r, and entirely included in P : 8 x <p> : : ; l ffi g. * A vertex is a point v 2 P which is not a linear combination of other points of P : 8 &gt; &gt; &gt; &gt; &gt; &gt; : P p 8 i 2 <ref> [1; p] </ref> x i 2 P 8 i; j 2 [1; p] i 6= j ) x i 6= x j i=1 i= 1 * A ray is a vector r 2 R n such that there exists an half-line parallel to r, and entirely included in P : 8 x 2 P; 8 2 Z + ; x + r <p> a vector l 2 R n such that l and l are rays of P : 8 x 2 P 8 2 Z x + l 2 P P is then defined by: P = x : fi fi fi fi 9 -1 ; : : : ; -ff 2 <ref> [0; 1] </ref> i=1 i= 1 9 1 ; : : : ; ffi 2 Z ff X i v i + i=1 ffi X i l i These two representations are equivalent, and algorithms [90, 74] have been designed for the conversion between them. <p> Tout d'abord, le graphe des cha^nes <ref> [1, 133] </ref> est construit a partir des effets des instructions, ou des regions de tableaux read et write, qui expriment aussi ces effets, mais de maniere plus precise ; ceci est permis par l'utilisation d'une m^eme structure de donnee. 2. <p> During the translation process, effects on array variables are enlarged to the whole variable, thus loosing accuracy. The translated effects are used at call sites in the same manner as intraprocedural effects. 219 220 CHAPTER 13. DEPENDENCE ANALYSIS * Use-def, def-use and def-def chains <ref> [1, 133] </ref> are built from effects or array regions; the result is an initial dependence graph: Each node represents a statement; edges correspond to dependences and are annotated with lists of conflicts.
Reference: [2] <author> F. E. Allen. </author> <title> Control flow analysis. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 5(7) </volume> <pages> 1-19, </pages> <year> 1970. </year>
Reference-contexts: Facing these obstacles, the solution is either to restrict the input language (as in [70, 72, 159, 130]), or to perform conservative approximate analyses [55] on real-life programs. This last characteristics has played a great role in the popularity of the method <ref> [2, 111, 55, 134, 153, 161, 37, 86] </ref>. Here, the complexity of the computation directly depends on the accuracy of the analysis. Up to now, no measurement of this accuracy has been proposed [55]. This section describes some usual characteristics of exact and approximate semantic analysis frameworks.
Reference: [3] <author> J. Allen and S. Johnson. </author> <title> Compiling C for vectorization, parallelization and inline expansion. </title> <booktitle> In International Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 241-249, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: More details on these studies can be found in Chapters 8 and 11. In most parallelizing compilers (petit [176], paraphrase-2 [142], fiat/suif [92], panorama [135], : : : ), induction variables are recognized and substituted <ref> [4, 3, 174, 180, 69] </ref>, and dependence tests do not have to deal with variables modified in loop bodies. While this may sometimes allow to disprove dependences, this may also lead to non-linear subscripts, which often prevent subsequent dependence tests.
Reference: [4] <author> J. Allen and K. Kennedy. </author> <title> Automatic translation of FORTRAN programs to vector form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(4), </volume> <month> October </month> <year> 1987. </year>
Reference-contexts: It is not added in the dependence system for the first tests, because inner level dependences may be useful for some program transformations, such as code distribu tion <ref> [4] </ref>. Context constraints Depending on pips compilation options, some context constraints may be taken into account when building the dependence system. <p> More details on these studies can be found in Chapters 8 and 11. In most parallelizing compilers (petit [176], paraphrase-2 [142], fiat/suif [92], panorama [135], : : : ), induction variables are recognized and substituted <ref> [4, 3, 174, 180, 69] </ref>, and dependence tests do not have to deal with variables modified in loop bodies. While this may sometimes allow to disprove dependences, this may also lead to non-linear subscripts, which often prevent subsequent dependence tests. <p> Calland et al. [38, 39] . Another array expansion method is proposed by Calland. It is a generalization of two program transformations originally introduced by Padua and Wolfe in [136] to remove anti and output dependences. The transformed loops can then be parallelized using Allen and Kennedy algorithm <ref> [4] </ref>. Creusillet [17] In a previous work, we presented another algorithm also based on in and out regions. This algorithm did not cope with the copy-in problem, and the approximations of the many intermediate regions used, as well as the resulting regions, were not clearly given.
Reference: [5] <author> S. Amarasinghe, J. Anderson, C. Wilson, S.-W. Liao, R. French, and M. Lam. </author> <title> Multiprocessors from a software perspective. </title> <journal> IEEE Micro, </journal> <volume> 16(3) </volume> <pages> 52-61, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Cette approche qui paraissait utopique il y a peu de temps encore, commence a donner des resultats encourageants, comme en temoignent des etudes recentes <ref> [5] </ref>. L'avantage majeur de cette approche est de permettre au programmeur d'ecrire ses programmes dans un langage sequentiel familier, de haut niveau, et donc de concevoir plus facilement son application, et d'en assurer la portabilite. <p> The most recent results are quite encouraging <ref> [5] </ref>. The major advantage of this method is that it provides a mean to build programs in a familiar, high level language; and thus facilitates the conception of applications, and ensures their portability.
Reference: [6] <author> Saman Amarasinghe and Monica Lam. </author> <title> Communication optimization and code generation for distributed memory machines. </title> <booktitle> In International Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 126-138, </pages> <month> June </month> <year> 1993. </year> <journal> In ACM SIGPLAN Notices. </journal>
Reference-contexts: Given the resulting regions, the problem is then to generate code using 14.5. RELATED WORK 237 this information. This has already been handled by others <ref> [6] </ref>. Though it is not our main concern in this study, we give here a few hints about the problems which arise. Once privatizable array regions have been determined, the dependence graph must be refined. In fact, read and write regions are recomputed, private regions being taken into account. <p> Generating these private copies from array regions represented by convex polyhedra, and converting former accesses to the global array into references to the local array, are themselves not trivial issues (see <ref> [12, 145, 44, 43, 6] </ref>). Handling copy-in and copy-out regions also depends on the target parallel model. <p> This last constraint is lessened by the fact that copy-in and copy-out are handled. This method has two drawbacks. The first is that too many array elements are declared as local. In another work from the same team <ref> [6] </ref>, this problem is tackled when generating the code. The second problem lies in the fact that the copy-out set is equal to the set of outward-exposed definitions, and not to the outward exposed definitions actually used in the continuation of the program, as out regions.
Reference: [7] <author> Zahira Amarguellat. </author> <title> A control-flow normalization algorithm and its complexity. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(3) </volume> <pages> 237-251, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Less drastic solutions should however be devised for do while loops built with goto statements, which are common in dusty decks. These hidden loops could be discovered using normalization techniques such as those described in <ref> [7] </ref>. 6.4 WRITE Regions The definition of write regions is very similar to read regions. Except that, since the expressions in L have no side effects, write regions are solely defined on the domain of statements S.
Reference: [8] <author> American National Standard Institute. </author> <title> Programming Language FORTRAN, ANSI X3.9-1978, </title> <type> ISO 1539-1980, </type> <year> 1983. </year>
Reference-contexts: EXPRESSION EVALUATION 69 ( ! V ) by Symb, then: O 1 : O 1 ! (Symb ! Symb) O 2 : O 2 ! (Symb fi Symb ! Symb) Obviously, this non-standard semantics is closely related to the standard semantics described by the fortran 77 standard <ref> [8] </ref>. The exact non-standard semantics of expressions can then be defined as: E [[c]] = :c E [[op 1 exp]] = O 1 [[op1]](E [[exp]]) In practice, all types of symbolic expressions are generally not handled, because of the resulting complexity. <p> The most important and complicated are detailed below. 6.5.1 Assignment The in regions of an assignment are identical to the corresponding read regions because the values of the referenced elements cannot come from the assignment itself, according to the fortran standard <ref> [8] </ref>. Henceforth, the write on the left hand side cannot cover the reads performed while evaluating the right hand side and the subscript expressions of the left hand side: R i [[ref = exp]] = R r [[ref = exp]] Corresponding approximations are straightforwardly derived from the exact semantics. <p> If variable aliasing is not taken into account, we may, for instance, fail to discover that a read is covered by a write, or we may underestimate the over-approximation of an intersection, which would yield an erroneous result. In fact, in programs respectful of the fortran standard <ref> [8] </ref>, both problems cannot be due to an interprocedural aliasing because the standard forbids the aliasing of arguments which are modified in the called procedure, and over-approximate intersections are only used to combine write regions. <p> Et dans la section suivante, nous presenterons un nouvel algorithme de traduction des regions. 9.1 Propagation Interprocedurale Dans pips, les analyses interprocedurales sont effectuees sur le graphe des appels du programme. C'est un graphe acyclique car la norme fortran <ref> [8] </ref> ne permet pas la recursivite. Les regions read, write, et in sont propagees en arriere sur cette representation du programme. <p> suite de cette section, nous utiliserons les notations suivantes : 1 Rappelons que les regions out de la procedure principale sont initialisees a l'ensemble vide. 2 La valeur d'indice d'un element de tableau est son rang dans le tableau a partir du premier element, les elements etant ranges par colonnes <ref> [8] </ref>. 9.2. TRADUCTION DES R EGIONS 173 174 CHAPTER 9. <p> Here, the purpose is to find the read and write regions of the call site, from the summary regions of procedure BAR. 1 The subscript value of an array elements is its rank in the array, array elements being stored in column order (see <ref> [8] </ref>, Section 5.4.3). 187 188 CHAPTER 11. INTERPROCEDURAL TRANSLATION SUBROUTINE AMHMTM (DEL,RPI,SV,P1,P2,AM,HM,TM) DIMENSION TM (12,12) ... CALL IMINV (TM,12,DET,LLL,MMM) ... SUBROUTINE IMINV (A,N,D,L,M) DIMENSION A (1),L (1),M (1) ... PROGRAM OCEAN ... REAL A (NA1,NA2) ... CALL IN (A (1,K2Q),KZN,NWH) ... SUROUTINE IN (ARRAY,LOC,NW) DIMENSION ARRAY (1) ... <p> This information is provided differently, depending on the type of aliasing between A and B: 2 Unit: numerical storage unit (see <ref> [8] </ref>, Section 4). 3 With the convention that Q k 2 k=k 1 = 1 when k 2 &lt; k 1 . 190 CHAPTER 11. <p> = 40. 11.1.2 Equivalent memory unit arrays If s a and s b are different, or if A and B belong to a COMMON which does not have the same layout in the target and source procedures, the array elements that are associated are said to be partially associated (see <ref> [8] </ref>, Section 17.1.3). This means that two corresponding elements may have non-matching storage units as shown in Figure 11.6. Identifying partially associated elements thus involves refering to individual memory units. <p> PRIVATISATION DE TABLEAUX 213 Dans le deuxieme appel, deux references a un element de tableau correspondent a un m^eme argument de dum2. Ceci n'est permis par la norme fortran <ref> [8] </ref> que si l'argument formel n'est pas modifie par la procedure. Dans ce cas, la region de l'argument formel scalaire est simplement remplacee par la region read de l'expression passee en argument. Et l'on obtient les m^emes regions que dans le cas precedent.
Reference: [9] <author> Corinne Ancourt. </author> <title> Generation de code pour multiprocesseurs a memoires locales. </title> <type> PhD thesis, </type> <institution> Universite Paris VI, </institution> <month> mars </month> <year> 1991. </year>
Reference-contexts: P peut ^etre vu comme l'intersection des demi-espaces definis par ses inegalites. Un polyedre peut aussi ^etre represente par son systeme generateur <ref> [9, 59] </ref>. Definition 7.2 Soit P un polyedre convexe. <p> Alors convex hull (P 1 ; P 2 ) = P 1 [ P 2 ssi P c _ :P 1 _ :P 2 n'est pas faisable. Difference La difference de deux polyedres convexes n'est pas necessairement un polyedre convexe. Des algorithmes <ref> [9, 121] </ref> permettent de representer de maniere exacte cette difference sous la forme d'une liste de polyedres convexes, ou fnd : P 1 P 2 = P 1 ^ :P 2 est une fcn qui peut ^etre convertie en une fnd. Nous noterons l'operateur correspondant dnf . <p> ne pas permettre de representer certains motifs d'ensembles d'elements de tableaux assez frequents dans les applications reelles, comme les stencils a neuf points, les acces aux elements pairs d'un vecteur, : : : Nous prevoyons donc d'implanter d'autres representations des regions, sous forme de listes de polyedres ou de Z-polyedres <ref> [9] </ref>. Chapter 8 Representation and Operators Obviously, a lot of efforts have been spent over the last ten years to summarize memory effects on array elements. Time and space complexity, as well as accuracy are the usual issues. <p> P can be viewed as the intersection of the half-spaces defined by its inequalities. A polyhedron can also be represented by a generating system <ref> [9, 59] </ref>. Definition 8.2 Let P be a convex polyhedron. <p> In pips, we only use the Fourier-Motzkin and simplex algorithms. All these algorithms have an exponential complexity. However, they perform relatively well on usual cases <ref> [9] </ref>. Moreover, the convex polyhedra used in pips contain equalities as well as inequalities, and the feasibility tests we use explicitly deal with equalities, thus reducing the complexity of pair-wise combination of inequalities. <p> This operation is not even straightforward. Algorithms <ref> [9, 147, 176, 121] </ref> have been designed that generate a list of polyhedra, or dnf, that exactly represents the difference. The method used in pips relies on cnf and dnf. <p> But they are very useful when symbolic information is required, because any linear constraint can be included in polyhedra. However, the complexity of the operators is theoretically exponential, and is generally high, even though it has been shown to be polynomial in practical cases <ref> [9] </ref>. Regular Section Descriptors There are several definitions for rsds. The initial ones [37] can represent elements, rows, columns, diagonals and their higher dimensional analogs, but cannot be used to represent triangular regions or discontinuous portions of rows. <p> The patterns that can be represented by convex polyhedra are very various. But some very common patterns, such as discontinuous rows or nine-point stencils, are nevertheless missed. One of our intentions for the future is therefore to implement other types of representations, in particular lists of polyhedra or Z-polyhedra <ref> [9] </ref>. The accuracy would be increased, without sacrificing the ability to retain context information. Moreover, it would allow comparisons between the representations, independently of the program representation, and of other factors such as the degree of symbolic information available. <p> CONTRIBUTIONS ET PERSPECTIVES dans les calculs dits red-black (voir figure 15.2). Nous prevoyons donc d'implanter d'autres representations des regions, sous forme de listes de polyedres ou de Z polyedres <ref> [9] </ref>. Experiences Nous avons deja effectue avec succes plusieurs experiences sur les regions de tableaux et la privatisation, demontrant ainsi la robustesse de l'implantation. Mais d'autres experiences mesurant le gain obtenu apres analyse des dependances avec les regions et privatisation des tableaux seraient necessaires. <p> However, it cannot represent some very common patterns such as nine-points stencils used in seismic computations (see Figure 16.1) or such as red-black computation patterns (see such as lists of polyhedra or Z-polyhedra <ref> [9] </ref>. Experiments We have already performed successful experiments with array region analyses and array privatization, thus assessing the robustness of our implementation. However, more experiments measuring the gain obtained by using regions for the dependence analysis and by applying array privatization would be neces sary.
Reference: [10] <author> Corinne Ancourt, Fabien Coelho, Fran~cois Irigoin, and Ronan Keryell. </author> <title> A Linear Algebra Framework for Static HPF Code Distribution. </title> <booktitle> In Fourth International Workshop on Compilers for Parallel Computers, </booktitle> <month> December </month> <year> 1993. </year> <note> To appear in Scientific Programming. Available on http://www.cri.ensmp.fr. </note>
Reference-contexts: fine advantage: First, the integration of the various phases (Figure A.3) within the PipsMake system allows to reuse without new developments all Pips analyses, and to benefit from the results of these analyses for better code generation and optimizations; Second, the Linear C 3 library has provided the mathematical framework <ref> [10, 11] </ref> and its implementation to develop new optimizations techniques targeted at generating efficient communication codes. It has been applied to I/O communications [46] and general remappings [48]. Parallelization The primary parallelization method used for shared-memory machines is based on Allen&Kennedy algorithm and on dependence levels.
Reference: [11] <author> Corinne Ancourt, Fabien Coelho, Fran~cois Irigoin, and Ronan Keryell. </author> <title> A Linear Algebra Framework for Static HPF Code Distribution. </title> <booktitle> Scientific Programming, </booktitle> <year> 1997. </year> <note> To appear. 301 302 BIBLIOGRAPHIE BIBLIOGRAPHY </note>
Reference-contexts: fine advantage: First, the integration of the various phases (Figure A.3) within the PipsMake system allows to reuse without new developments all Pips analyses, and to benefit from the results of these analyses for better code generation and optimizations; Second, the Linear C 3 library has provided the mathematical framework <ref> [10, 11] </ref> and its implementation to develop new optimizations techniques targeted at generating efficient communication codes. It has been applied to I/O communications [46] and general remappings [48]. Parallelization The primary parallelization method used for shared-memory machines is based on Allen&Kennedy algorithm and on dependence levels.
Reference: [12] <author> Corinne Ancourt and Fran~cois Irigoin. </author> <title> Scanning polyhedra with DO loops. </title> <booktitle> In Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 39-50, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Cette operation est exacte car les bornes de boucle ont des expressions affines et la projection est exacte selon <ref> [12, 144] </ref>. 3.1. R EGIONS EXACTES OU APPROXIMATIONS ? 25 La sur-approximation obtenue pour la boucle externe est f 1 : 1 1 5g. En utilisant le critere d'exactitude precedant, on peut conclure que cette operation est exacte, et que la region est une sous-approximation valide. <p> obtained by adding the loop bound constraints to the above polyhedron, and eliminating the loop index j: f 1 : 1 = i ^ 1 j 5g f 1 : 1 = ig This operation is exact because the loop bounds are affine, and the projection is exact according to <ref> [12, 144] </ref>j. For the outermost loop, computing the over-approximation gives: f 1 : 1 1 5g Again, the loop bounds are affine, and the elimination of i is exact. Since the previous regions are exact, they are valid under-approximations. <p> L'algorithme de Fourier-Motzkin permet d'effectuer cette elimination. En realite, il calcule l'enveloppe convexe de la projection des points entiers du polye-dre de depart. Le resultat est donc une sur-approximation de l'ensemble recherche. Ancourt <ref> [12] </ref> et Pugh [144] ont propose une condition necessaire et suf fisante pour tester l'exactitude de cette operation (theoreme 8.1). Intersection L'intersection de deux polyedres convexes est un polyedre convexe. Un polyedre convexe est l'intersection de plusieurs demi-espaces. <p> Ancourt <ref> [12] </ref> and Pugh [144] have proposed a necessary and sufficient condition for testing the exactness of the elimination of a variable between two inequalities. <p> REPRESENTATION AND OPERATORS Proof We do not give the proof here, because it is beyond the scope of this thesis. We refer the reader to the previously cited works <ref> [12, 144] </ref> for more details. fl Note 1. The previous necessary and sufficient condition becomes a sufficient condition if the redundancy test (which is in fact a feasibility test) is not exact. 2. <p> At Steps 10 and 11, the exactness of the variable elimination is verified with the usual conditions <ref> [12, 144] </ref>. Step 13 is performed using the relations between formal and actual parameters, and between the declarations of global variables in the source and target routines (this gives 11.4. RELATED WORK 203 a translation context system). <p> Generating these private copies from array regions represented by convex polyhedra, and converting former accesses to the global array into references to the local array, are themselves not trivial issues (see <ref> [12, 145, 44, 43, 6] </ref>). Handling copy-in and copy-out regions also depends on the target parallel model.
Reference: [13] <author> Corinne Ancourt and Fran~cois Irigoin. </author> <title> Automatic code distribution. </title> <booktitle> In Third Workshop on Compilers for Parallel Computers, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: It is now mainly targeted at generating code for distributed memory machines, using different methods (processor and memory bank code for control distribution <ref> [13] </ref>, cmf, craft polyhedral method [140] or message-passing code from HPF [45]). As we see in Section A.3, the translation process is broken into smaller modular operations called phases in Pips. For the user, these phases can be classified into various categories according to their usage. <p> The development run-time is implemented over PVM but the target is Inmos T9000 with C104 transputer-powered parallel machines with an hight speed interconnection network. This prototype was built as part of the European Puma project <ref> [13] </ref>. Parallelization with a polyhedral method By using the Array Data Flow Graph, it is possible to track the movement of each value in a program where control flow can be statically represented in a linear way.
Reference: [14] <author> Jennifer Anderson, Saman Amarasinghe, and Monica Lam. </author> <title> Data and computation transformations for multiprocessors. </title> <booktitle> In Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: The second approach is to transform the array element layout in shared memory so that all the data accessed by one processor are contiguous in the shared address space <ref> [14] </ref>. However, these techniques reorganize the computation or the data sets so that accesses are contiguous, but they do not remove dependences when an array region is used as a temporary by several iterations.
Reference: [15] <institution> Applied-Parallel Research. </institution> <note> The Forge User's Guide, Version 8:0, </note> <year> 1992. </year>
Reference-contexts: Mais nous pensons qu'a terme elle permettra de traiter de maniere satisfaisante la plupart des cas courants, et que son usage ne peut donc que se developper. Des paralleliseurs commerciaux existent deja (comme kap [118], forge <ref> [15] </ref>, et le compilateur d'ibm, xl hpf), et ils feront certainement un jour partie de l'offre logicielle standard sur toute machine parallele. 1.2 Regions de Tableaux Plusieurs problemes se posent lors de la generation automatique de code pour machines paralleles a memoire distribuee ou a memoire partagee (mais a acces non <p> But we believe that it will one day be mature enough to handle most current programs, and that its usage can only spread out. Some commercial parallelizers are already available (such as kap [118], forge <ref> [15] </ref>, xl ibm hpf compiler). And they will certainly be part of the standard software package for parallel systems in the future. 2.2 Array Regions Several problems need to be solved when generating code for parallel machines with distributed, shared but with non-uniform access, or hierarchical memories.
Reference: [16] <author> Beatrice Apvrille. </author> <title> Calcul de regions de tableaux exactes. </title> <booktitle> In Rencontres Franco-phones du Parallelisme, </booktitle> <pages> pages 65-68, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Seuls Wonnacott et Pugh [171, 170, 176] se sont penches sur ces problemes dans le cas des formules de Presburger. Nous avions nous-m^emes presente nos analyses de regions dans plusieurs rapports et articles <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. Cependant, cette partie apporte de nouvelles contributions. Nous avons ainsi etudie le cadre theorique des analyses de regions de tableaux, independamment de leur type, et avons propose une solution aux problemes poses par les analyses approchees inferieurement. <p> However, no attempt is done to actually represent the conditions under which the break is performed, as we do with continuation conditions (see Page 5.5). And lastly, Wonnacott proposes an interprocedural extension. 6.11 Conclusion We have already presented our array region analyses in several reports or papers <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. However, the present chapter is new in several respects. 122 CHAPTER 6. ARRAY REGION ANALYSES First, array regions are presented using denotational semantics or attributed grammars. <p> The possible applications are numerous. Among others, in and out regions are already used in Pips to privatize array sections <ref> [16, 61] </ref>, and we intend to use them for memory allocation when compiling signal processing specifications based on dynamic single assignments. Another unique feature of Pips array Regions lies in the fact that, although they are over-approximations of the element sets actually referenced, they are flagged as exact whenever possible.
Reference: [17] <author> Beatrice Apvrille-Creusillet. </author> <title> Regions exactes et privatisation de tableaux (Exact array region analyses and array privatization). </title> <type> Master's thesis, </type> <institution> Universite Paris VI, France, </institution> <month> September </month> <year> 1994. </year> <note> Available via http://www.cri.ensmp.fr/~creusil. </note>
Reference-contexts: (Resume des chapitres 4, 5, et 6) Comme nous l'avions annonce dans l'introduction, cette partie est consacree a l'etude du cadre theorique des analyses de regions de tableaux, et a la semantique de quatre types de regions : read, write, in et out, qui ont ete introduites lors d'etudes anterieures <ref> [161, 162, 17, 65] </ref>. En effet, si de nombreuses etudes se sont interessees a de telles analyses, peu se sont penchees sur les problemes theoriques sous-jacents, et jamais d'une fa~con aussi complete et uniforme que nous le proposons ici. <p> Detecter ces regions de tableaux privatisables requiert une analyse precise du flot des elements de tableaux. Plusieurs algorithmes de privatisation ou d'expansion 1 on deja ete proposees <ref> [70, 130, 123, 166, 93, 17, 63] </ref>. Ils reposent sur differents types d'analyse du flot des elements de tableaux. La premiere approche [70, 130] effectue une analyse exacte, mais a partir 1 Une technique similaire pour les machines a moire partagee. 21 22 CHAPTER 3. <p> S EMANTIQUE DES R EGIONS DE TABLEAUX d'un langage source restreint, dit langage monoprocedural a controle statique. La plupart des autres methodes utilise des analyses de regions de tableaux approchees, sur-ou sous-estimees selon un ordre predefini. Au contraire, la derniere approche <ref> [17, 63] </ref> consiste a calculer des solutions exactes tant que cela est possible, et a n'effectuer des approximations que lorsque l'exactitude ne peut ^etre conservee. Cette section montre les avantages de cette derniere methode. <p> Seuls Wonnacott et Pugh [171, 170, 176] se sont penches sur ces problemes dans le cas des formules de Presburger. Nous avions nous-m^emes presente nos analyses de regions dans plusieurs rapports et articles <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. Cependant, cette partie apporte de nouvelles contributions. Nous avons ainsi etudie le cadre theorique des analyses de regions de tableaux, independamment de leur type, et avons propose une solution aux problemes poses par les analyses approchees inferieurement. <p> Solving such problems requires a precise intra- and inter-procedural analysis of array data flow. Several algorithms for array privatization or array expansion 2 , based on different types of array data flow analyses, have already been proposed <ref> [70, 130, 123, 166, 93, 17, 63] </ref>, . The first approach [70, 130] performs an exact analysis of array data flow, but for a restricted source language 3 . Most of the other methods use conservative approximations of array element sets, such as MayBeDefined and MustBeDefined sets. <p> Most of the other methods use conservative approximations of array element sets, such as MayBeDefined and MustBeDefined sets. In fact, may sets are over-approximations of exact solutions, while must sets are under-approximations, according to a predefined approximation ordering. On the contrary, the last approach <ref> [17, 63] </ref> tries to compute exact solutions whenever possible, switching to conservative approximations only when exactness cannot be preserved anymore. However, except for specific applications [46, 47] requiring the knowledge of exactness, the advantages of our approach are still an open issue, which is discussed in this chapter. <p> However, this approach may fail to compute under-approximations equal to the corresponding exact solutions whereas the computation of the latter is decidable, which is possible as shown in <ref> [17, 63] </ref>. <p> We have therefore introduced in and out regions <ref> [17, 63, 65] </ref> to enable such transformations, but their description was rather informal. This chapter formally describes the flow and context sensitive analysis of read, write, in and out regions. Their exact semantics are defined, as well as their under-and over-approximations. <p> This problem cannot be solved using write regions, because this analysis does not take into account the order in which writes occur. This is why we introduced out regions <ref> [17] </ref>: They contain the downward exposed written and used afterwards, or exported, array elements (see Figure 6.2). <p> However, since the exactness criterion for the if construct is built from the definition for the under-approximation, it may fails in the situation described in the previous paragraph. This drawback had been reported in <ref> [17] </ref>. One solution would be to use preconditions only when they are necessary. In addition, it could decrease the complexity of analyses. <p> However, no attempt is done to actually represent the conditions under which the break is performed, as we do with continuation conditions (see Page 5.5). And lastly, Wonnacott proposes an interprocedural extension. 6.11 Conclusion We have already presented our array region analyses in several reports or papers <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. However, the present chapter is new in several respects. 122 CHAPTER 6. ARRAY REGION ANALYSES First, array regions are presented using denotational semantics or attributed grammars. <p> Missing [[S]] and corresponding universal quantifiers can be trivially added by the careful reader. * As already implicitly done in Definition 8.3, we consider that array region analyses only have to deal with a single array. The extension to lists of array regions is trivial, as shown in <ref> [17] </ref>. * Also, operators are independent of the types of region they combine, either read, write, in or out. Corresponding subscripts are therefore omitted. <p> Dans pips, les regions sont representees par des polyedres convexes. Cepen-dant, l'algorithme que nous presentons ici est independant de toute representation. 12.2.1 Un peu de vocabulaire Il y a a peu pres autant de definitions de la privatisabilite d'un tableau que de papiers a ce propos <ref> [123, 166, 92, 17] </ref>. Nous presentons donc ici les differents criteres que nous prenons en compte. <p> Our algorithm is then presented in Section 14.2. Section 14.4 discusses code generation issues. The related work is then presented in Section 14.5. 14.1 Several Definitions There are almost as many definitions of array privatizability as papers about it <ref> [123, 166, 92, 17] </ref>. In this section, we try to distinguish the different criteria for array privatizability which are used in these definitions; we discuss their usefulness, and give our own definition. <p> This is very similar to generating communications for a distributed memory machine. In our algorithm, both problems are handled, but this can be toggled off depending on circumstances such as the target architecture for instance. In a previous work <ref> [17] </ref>, the copy-in problem was not considered. <p> The last approach for enhancing the locality of references is then to privatize or expand array regions, that is to say to replicate data onto several processors when they are used as temporaries. Many work has already been done is this direction <ref> [123, 165, 166, 164, 92, 70, 130, 17] </ref>, 238 CHAPTER 14. ARRAY PRIVATIZATION and the differences with our approach are described below. Notice also that run-time techniques have been recently introduced to privatize arrays in cases which cannot be discovered using static analyses [148, 149]. <p> Another array expansion method is proposed by Calland. It is a generalization of two program transformations originally introduced by Padua and Wolfe in [136] to remove anti and output dependences. The transformed loops can then be parallelized using Allen and Kennedy algorithm [4]. Creusillet <ref> [17] </ref> In a previous work, we presented another algorithm also based on in and out regions. This algorithm did not cope with the copy-in problem, and the approximations of the many intermediate regions used, as well as the resulting regions, were not clearly given.
Reference: [18] <author> Beatrice Apvrille-Creusillet. </author> <title> Calcul de regions de tableaux exactes. </title> <journal> TSI, Numero special RenPar'6, </journal> <volume> 14(5) </volume> <pages> 585-600, </pages> <month> mai </month> <year> 1995. </year>
Reference-contexts: Seuls Wonnacott et Pugh [171, 170, 176] se sont penches sur ces problemes dans le cas des formules de Presburger. Nous avions nous-m^emes presente nos analyses de regions dans plusieurs rapports et articles <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. Cependant, cette partie apporte de nouvelles contributions. Nous avons ainsi etudie le cadre theorique des analyses de regions de tableaux, independamment de leur type, et avons propose une solution aux problemes poses par les analyses approchees inferieurement. <p> However, no attempt is done to actually represent the conditions under which the break is performed, as we do with continuation conditions (see Page 5.5). And lastly, Wonnacott proposes an interprocedural extension. 6.11 Conclusion We have already presented our array region analyses in several reports or papers <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. However, the present chapter is new in several respects. 122 CHAPTER 6. ARRAY REGION ANALYSES First, array regions are presented using denotational semantics or attributed grammars. <p> In practice, we do not compute the under-approximation, but use a series of criteria the test whether the combination (union, intersection or difference) of an over-approximate region and an exact one can be exact. These criteria were given in <ref> [18, 65] </ref>. do j = 1, m 1 + A (i,j+1) + A (i,j+2) 3 + A (i-1,j) + A (i-2,j) enddo enddo 8.7 Related Work Who would not dream of an ideal representation? It would allow an exact representation of all access patterns found in real life applications, and so
Reference: [19] <author> V. Balasundaram and K. Kennedy. </author> <title> A technique for summarizing data access and its use in parallelism enhancing transformations. </title> <booktitle> In International Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 41-53, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Mais ce critere de necessite reste a definir. 3.4 Autres Travaux et Conclusion De nombreuses etudes ont aborde les analyses de regions de tableaux depuis leur introduction par Triolet [161]. Les plus anciennes concernent generalement le choix de la representation des elements de tableaux <ref> [37, 19, 98, 99] </ref>, probleme que nous traiterons dans la partie III, pour des analyses approchees superieurement, et insensibles au flot de controle du programme. Dans les etudes plus recentes [151, 86, 92, 135, 164], nous retrouvons des types d'analyses similaires aux notres, a l'exception des regions out. <p> For instance, array element index sets are parts of Z n . Due to the complexity of being able to represent any part of Z n , several compact representations have been defined: Convex polyhedra [161], rsd [37], dad <ref> [19] </ref>, : : : Another example is the abstraction of statement effects on variables values (the so-called transformers in pips). <p> ANALYSIS FRAMEWORKS 47 v; :?; :Z d ; convex hull; u) is a complete lattice, but is not a sub-lattice of L because in general convex hull (R 1 ; R 2 ) 6= R 1 t R 2 . (This is also the case for rsds [37] or dads <ref> [19] </ref> : : : ). However, since convex hull (R 1 ; R 2 ) w R 1 t R 2 , the resulting analyses necessarily are over-approximations. But we also need under-approximations. The next theorem characterizes the complete lattices which allow such analyses. <p> A second problem is due to the fact that early approaches <ref> [161, 37, 19] </ref> only performed over-approximate analyses of read and write regions. <p> To solve the first problem, a new technique, based on the summarization of the array elements accessed by procedures, was introduced by Triolet [161], soon followed by many others <ref> [37, 19, 98, 99] </ref> who introduced different representations of array element sets. For the second problem, two approaches were proposed: * Extensions of classical data flow frameworks to array element sets. Earliest works were due to Rosene or Gross and Steenkiste [151, 86]. <p> And combinations of both representations are also used, for instance in [164]. The advantage of rsds is that the complexity of merging and comparison operators is very low. However, they cannot include symbolic information, such as if conditions for instance. Data Access Descriptors dads have been defined by Balasundaram <ref> [19] </ref> as a compromise between the low complexity provided by rsds and the accuracy of convex polyhedra. They are based on simple sections, which are convex polyhedra in which constraints are either parallel to the axes, or at a 45 degree angle to a pair of axes. <p> supposed to have no side effect, viewed from the outside (I/Os are performed from within the program itself). 10.3 Other Approaches The purpose of earliest implementations of array region analyses was to support data dependence analysis across procedure boundaries [161, 163, 35, 37, 122, 98, 99] or between different tasks <ref> [19] </ref>. Hence, only over-approximations of effects on array element sets were required. Moreover, the necessity of symbolic analyses had not yet been brought to light, and usually, context information such as if conditions were not taken into account. The desired result was therefore inherently flow-insensitive. <p> Many other less recent works <ref> [37, 99, 19] </ref> have addressed the problem of the in-terprocedural propagation of array element sets. But they did not provide sufficient symbolic analyses, and did not tackle array reshaping. <p> Les travaux sur l'analyse de dependance a l'aide de regions de tableaux sont tres nombreux <ref> [162, 163, 122, 37, 19, 98, 99, 35, 92] </ref>. Les differences portent essentiellement sur le type de representation choisi pour les ensembles d'elements de tableaux, et les tests de dependance utilises, de maniere a obtenir un compromis entre precision et complexite. <p> However, most of the above studies only deal with individual references, and not with compound instructions, such as procedures. To analyze dependences across procedure boundaries, Triolet introduced a novel approach, based on array regions. Section 13.2.1 shows how this technique is applied in pips. Related works are numerous <ref> [162, 163, 122, 37, 19, 98, 99, 35, 92] </ref>, the main issues being again complexity and accuracy, but with respect to the representation of array regions. More details on these studies can be found in Chapters 8 and 11. <p> La prise en compte de l'etat memoire est necessaire car il permet de ne pas manipuler directement les valeurs de variables, et facilite donc les analyses symboliques. Des etudes precoces <ref> [37, 19] </ref> proposaient des representation des regions ne prenant pas en compte cette dimension, et ne permettaient donc pas des analyses precises lorsque des variables 243 244 CHAPITRE 15.
Reference: [20] <author> Utpal Banerjee. </author> <title> Dependence Analysis for Supercomputing. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston / Dordrecht / London, </address> <year> 1988. </year>
Reference-contexts: particular analysis is devoted in pips to the detection of privatizable array sections (see Chapter 14). 13.3 Related Work There has been a lot of work over the years about dependence analysis techniques, the main issues being complexity and accuracy: Cheap tests, such as the gcd test and Banerjee's test <ref> [20] </ref> perform well on many cases, but more complex algorithms based on the Fourier-Motzkin pair-wise elimination method, or on the simplex, are necessary to achieve a good accuracy. Therefore, dependence tests combining successive individual tests have been suggested [35, 105, 129, 175, 143].
Reference: [21] <author> Utpal Banerjee, Rudolf Eigenmann, Alexandru Nicolau, and David A. Padua. </author> <title> Automatic program parallelisation. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 81(2), </volume> <month> February </month> <year> 1993. </year>
Reference-contexts: This was however insufficient to efficiently parallelize many scientific programs dealing with structured data. The first improvement was the introduction of array data dependence analysis <ref> [21] </ref>. But this was still insufficient to deal with interprocedural boundaries, and to achieve optimizations such as array expansion or privatization, which require the knowledge of the flow of array elements.
Reference: [22] <author> H. P. Barendregt. </author> <title> The Lambda Calculus: Its Syntax and Semantics. </title> <publisher> North-Holland, </publisher> <year> 1981. </year>
Reference-contexts: [[S 1 ]] = R w [[S 1 ]] " (R o [[S 1 ; S 2 ]] fi R o [[S 2 ]] * T [[S 1 ]]) [ R i [[S 2 ]] * T [[S 1 ]] * To describe our semantical functions, we use Church's -calculus <ref> [22] </ref>. As stated in the introduction of this section, the solutions defined by A may be extremely difficult, indeed impossible, to compute.
Reference: [23] <author> Bruno Baron, Fran~cois Irigoin, and Pierre Jouvelot. </author> <title> Projet PIPS, </title> <editor> Manuel util-isateur du paralleliseur batch. </editor> <address> rapport interne EMP-CRI E144. </address>
Reference-contexts: The necessity of using these analyses, which comes from the characteristics of the language, is informally shown using examples in Section 5.2. 5.1 Language The source language of pips is fortran 77, minus a few syntactic restrictions <ref> [23] </ref>. However, for the sake of clarity, only a small subset L of the language is considered here, with a few additional constructs. Its syntax provided in Figure 5.1.
Reference: [24] <author> Denis Barthou, Jean-Fran~cois Collard, and Paul Feautrier. </author> <title> Applications of fuzzy array data-flow analysis. </title> <booktitle> In Europar'96, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: Some of the intra-procedural restrictions have since been partially removed, sometimes at the expense of accuracy: Maslov [127] extends this method to handle, to some extent, if constructs and general variables. Collard [49, 50] proposes an extension for do while constructs. Collard et al. <ref> [51, 73, 24] </ref> remove some linearity limitations, but at the expense of accuracy. collard and Griebl [52] finally extend the framework to explicitly (con trol) parallel programs containing doall and doacross loops. Interprocedural extensions have been formulated by Leservot: This is described below.
Reference: [25] <author> M. Berry, D. Chen, P. Koss, D. Kuck, V. Lo, Y. Pang, R. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox, P. Messina, D. Walker, C. Hsi-ung, J. Schwarzmeier, K. Lue, S. Orzag, F. Seidl, O. Johnson, G. Swanson, R. Goodrum, and J. Martin. </author> <title> The PERFECT Club benchmarks : Effective performance evaluation of supercomputers. </title> <type> Technical Report CSRD-827, </type> <institution> CSRD, University of Illinois, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: De m^eme, dans l'exemple de la figure 1.2 | extrait du programme du Perfect Club <ref> [25] </ref> OCEAN | la boucle la plus externe ne peut ^etre parallelisee si l'on ne s'aper~coit pas qu'a chaque iteration les elements du tableau WORK ne sont utilises qu'apres avoir ete definis. <p> Also, in the example of Figure 2.2 | extracted from the Perfect Club benchmark <ref> [25] </ref> OCEAN | the outermost loop cannot be parallelized if we do not find out that at each iteration the elements of WORK are used only after being defined. <p> Continuation conditions are currently being implemented, also as convex polyhedra. 8 Preconditions are of type transformer in pips internal representation, and were presented as transformers in [105]. 86 CHAPTER 5. SOURCE LANGUAGE AND PRELIMINARY ANALYSES Chapter 6 Array Region Analyses Many scientific programs (see <ref> [25] </ref> for instance) make a wide use of array structures. This may render their compilation for complex machines (e.g. parallel or hierarchical memory machines) or even their maintenance, particularly tricky, especially when such data structures are accessed through procedure calls. <p> However, this is not the case when array subscripts or assignments to variables used in array subscripts are nonlinear. Sophisticated techniques, which are not available in pips, are then necessary. For example, when nonlinear subscripts are due to the hand linearization of a multidimensional array, as in TRFD <ref> [25] </ref>, the data structure may be recovered from the flat array [42]. Finally, even in pieces of code where all expressions are perfectly linear, convex polyhedra are not always sufficient to exactly represent array regions. The first reason is that some access patterns intrinsically are non-convex. <p> Comme les variables source et cible peuvent ne pas avoir la m^eme declaration (array reshaping), cette operation n'est pas aisee a realiser. En examinant les programmes du Perfect Club <ref> [25] </ref>, nous avons identifie un certain nombre de cas non-exclusifs qu'il est necessaire de pouvoir traiter : 1. l'array reshaping d^u a des declarations de dimensions differentes ; 2. les decalages (offsets) entre les premiers elements des tableaux source et cible, d^us au passage de parametres (CALL F (A (1,J)) par <p> This chapter focuses on the translation part of array region interprocedural analyses. Because the source and target arrays may not have the same declaration (array reshaping), this operation is not straightforward. In particular, by examining the Perfect Club benchmarks <ref> [25] </ref>, we found it necessary to handle several non-exclusive cases: 1. Array reshaping due to different dimension declarations (see Figure 11.1). 2. Offsets between the first elements of the source and target arrays due to param eter passing (see an example from the program OCEAN in Figure 11.2). 3.
Reference: [26] <author> David Binkley. </author> <title> Interprocedural constant propagation using dependence graphs and a data-flow model. </title> <booktitle> In International Conference on Compiler Construction, </booktitle> <month> April </month> <year> 1994. </year> <note> BIBLIOGRAPHIE BIBLIOGRAPHY 303 </note>
Reference-contexts: INTERPROCEDURAL PROPAGATION OF REGIONS IN PIPS 183 To reduce this complexity, several sparse representations have been designed for particular classes of problems, such as the program summary graph [36], the ssa form [67, 158], the sparse data flow evaluation graph [41], the system dependence graph <ref> [75, 26] </ref>, : : : The unified interprocedural graph [96] provides a demand-driven unified representation which combines the advantages of the sparse rep resentations without restricting the scope of the possible analyses. * Another issue is the ability to avoid taking into account unrealizable paths [119].
Reference: [27] <author> Garrett Birkhoff. </author> <title> Lattice Theory, </title> <publisher> volume XXV of AMS Colloqium Publications. American Mathematical Society, </publisher> <address> Providence, Rhode Island, third edition, </address> <year> 1967. </year>
Reference-contexts: Ce probleme est connu dans le domaine de l'interpretation abstraite [33, 57], et pas seulement pour la sous-approximation des ensembles a coordonnees dans Z. Une solution consiste a changer de domaine d'etude. Par exemple, dans le cadre des analyses 2 Le lecteur pourra se referer a <ref> [27] </ref> pour plus de details sur la theorie des treillis, et a [132, 88] pour une description plus complete des domaines semantiques. 3 Sauf si l'on prend l'intersection, mais on ne peut en attendre de resultats interessants. 3.1. <p> MAY, MUST OR EXACT? 4.1.4 Usual ad-hoc solutions When the approximate solution space A 00 is a lattice or cpo, its relations with the exact solution space A can be described by a Galois connection <ref> [27, 56] </ref>, which defines two monotone functions: An abstraction function ff : A ! A 00 , and a concretization or meaning function fl : A 00 ! A (see Figure 4.2).
Reference: [28] <author> Bill Blume, Rudolf Eigenmann, Keith Faigin, John Grout, Jay Hoeflinger, David Padua, Paul Petersen, Bill Pottenger, Lawrence Rauchwerger, Peng Tu, and Stephen Weatherford. </author> <title> Polaris : The next generation in parallelizing compilers. </title> <type> CSRD report 1375, </type> <institution> CSRD, University of Illinois, </institution> <year> 1994. </year>
Reference-contexts: And the proposed algorithm actually goes along each possible path. However, since no symbolic information is propagated downward, they do not take advantage of this possibility. Finally, notice that despite the arguments against full inlining, it is still used in one of the most advanced parallelizers, polaris <ref> [28] </ref>, which successfully parallelizes medium sized applications.
Reference: [29] <author> W. Blume and R. Eigenmann. </author> <title> Performance analysis of parallelizing compilers on the Perfect Benchmarks programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(6) </volume> <pages> 643-656, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Cette transformation est couramment appelee privatisation de tableau et est cruciale dans le processus de parallelisation <ref> [29] </ref>. Beaucoup de travail a deja ete effectue dans le domaine de l'analyse des programmes comportant des references a des elements de tableaux. <p> ARRAY REGIONS 15 due to WORK. The loop can be parallelized if there exists no other dependence. This transformation is usually called array privatization and is determinant in the parallelization process <ref> [29] </ref>. do J = 1, N1, 2 II = I + I WORK (II-1) = ... <p> La section 3.2 presentera ensuite notre langage d'etude et les analyses preliminaires necessaires a la definition de la semantique des regions, qui sera presentee dans la section 3.3. 3.1 Regions Exactes ou Approximations ? Plusieurs etudes <ref> [29, 79] </ref> ont montre la necessite de recourir a des optimisations de programme puissantes pour pouvoir gerer la memoire de maniere efficace lors de la compilation pour des machines a memoire distribuee ou a hierarchie de memoires. <p> Par exemple, Blume et Eigenmann <ref> [29] </ref> ont demontre par l'experience que la privatisation de tableaux pouvait augmenter de maniere cruciale le degre de parallelisme potentiel des programmes sequentiels. <p> Dans la partie suivante, nous presenterons l'implantation effectuee dans pips ; et dans la partie IV, nous montrerons comment effectuer ces analyses en presence d'appels de procedures. 40 CHAPTER 3. S EMANTIQUE DES R EGIONS DE TABLEAUX Chapter 4 May, Must or Exact? Several studies <ref> [79, 29] </ref> have highlighted the need for advanced program optimizations to deal with memory management issues. For instance, Blume and Eigenmann [29] have shown that array privatization could greatly enhance the amount of potential parallelism in sequential programs. <p> S EMANTIQUE DES R EGIONS DE TABLEAUX Chapter 4 May, Must or Exact? Several studies [79, 29] have highlighted the need for advanced program optimizations to deal with memory management issues. For instance, Blume and Eigenmann <ref> [29] </ref> have shown that array privatization could greatly enhance the amount of potential parallelism in sequential programs. This technique basically aims at discovering array sections that are used as temporaries in loops, and can thus be replaced by local copies on each processor. <p> EXACT? 4.4 Conclusion Due to a considerable amount of efforts over the last ten years, over-approximate array regions analyses are now well-known techniques, even if debates about the choice of the representation are still alive: Time and space complexity versus accuracy is the main issue, but usefulness is widely acknowledged <ref> [163, 29, 101, 92, 65] </ref>. The need for under-approximations appeared only recently [165, 123, 92, 171], mainly for locality analysis or direct dependence analysis. Pugh and Wonnacott have provided extended studies [171, 170, 176] when the underlying semantic analysis framework is the domain of Presburger formulae. <p> Elle permettrait de prendre en compte des informations de contexte symboliques, comme certaines etudes ont montre que cela etait necessaire <ref> [29, 89] </ref>. <p> It would allow to take symbolic context information into account, since it has been shown to be necessary by several studies <ref> [29, 89] </ref>. <p> Pour la plupart des compilateurs, les appels de procedures sont des barrieres infranchissables, et emp^echent la plupart des analyses et des optimisations, comme la propagation de constantes, ou l'analyse des dependances, qui sont pourtant de la plus grande utilite dans les paralleliseurs pour esperer des gains de performances <ref> [29] </ref>. La solution de l'expansion de procedure qui consiste a rem-placer chaque appel par le code de la procedure appelee n'est pas toujours possible, ni souhaitable a cause de la complexite qu'elle engendre. Les analyses interprocedurales sont donc de plus en plus repandues. <p> In traditional compilers, procedure boundaries prevent most analyses and optimizations, such as constant propagation or dependence analyses for instance, which have been shown to be of paramount importance in parallelizing compilers <ref> [29] </ref> to achieve reasonable performances. The present part is thus devoted to the interprocedural analysis of array regions. It can be decomposed into two components: The propagation along the interprocedural control flow graph, and the translation of regions from the source procedure name space into the target procedure name space. <p> Mais leur domaine d'utilisation privi-legie reste celui de la parallelisation automatique. Les deux applications qui generent les gains de performance les plus importants sont l'analyse des dependances interproce-durales et la privatisation de tableaux <ref> [29] </ref>. Triolet proposait d'utiliser les regions read et write sur-estimees pour effectuer des analyses de dependances interprocedurales. Sa methode fut d'abord implantee dans parafrase [162], puis dans pips [105, 139, 177]. Nous presentons dans une premiere section l'implantation existant actuellement dans pips. <p> The purpose of this part is to describe two applications in this field, which are implemented in pips: This chapter is devoted to dependence analysis, and the next one to array region privatization, which has been shown to be of paramount importance to achieve good performances <ref> [29] </ref>. Triolet originally proposed to use over-approximate read and write array regions to enhance dependence tests across procedure boundaries, which hide actual array references. His approach was first implemented in paraphrase [162], work later resumed within the framework of pips [105, 139, 177]. <p> Since using in and out regions is equivalent to declare arrays or array sections as local variables, a specific analysis has been preferred in pips. This is the object of the next chapter. Chapter 14 Array Privatization Recent studies <ref> [79, 29] </ref> have highlighted the need for advanced program optimizations to deal with memory management issues when compiling programs for massively parallel machines or hierarchical memory systems. For instance, Blume and Eigenmann [29] have shown that array privatization could greatly enhance the amount of potential parallelism in sequential programs. <p> This is the object of the next chapter. Chapter 14 Array Privatization Recent studies [79, 29] have highlighted the need for advanced program optimizations to deal with memory management issues when compiling programs for massively parallel machines or hierarchical memory systems. For instance, Blume and Eigenmann <ref> [29] </ref> have shown that array privatization could greatly enhance the amount of potential parallelism in sequential programs. This technique basically aims at discovering array regions that are used as temporaries in loops, and can thus be replaced by local copies on each processor. <p> However, these techniques reorganize the computation or the data sets so that accesses are contiguous, but they do not remove dependences when an array region is used as a temporary by several iterations. It was shown that, in several benchmarks, many loops are not parallelizable because of this problem <ref> [29] </ref>. The last approach for enhancing the locality of references is then to privatize or expand array regions, that is to say to replicate data onto several processors when they are used as temporaries. <p> The algorithm trivially derives from the algorithm given above; but code generation is again the remaining issue. VI CONCLUSION 241 Chapitre 15 Contributions et Perspectives Les analyses de regions de tableaux ont suscite de nombreuses etudes lors de la derniere decennie. Leur utilite n'est plus a demontrer <ref> [163, 29, 101, 92, 65] </ref>, et les debats actuels concernent le choix de la representation des ensembles d'elements de tableaux, ainsi que le type et la quantite d'information symbolique a prendre en compte pour analyser de maniere suffisamment precise des applications reelles, sans pour autant degrader la complexite en temps et <p> C'est l'un de nos projets. 247 248 CHAPITRE 15. CONTRIBUTIONS ET PERSPECTIVES Chapter 16 Contributions and Perspectives Array region analyses have raised a considerable amount of effort over the last decade. Their usefulness is now widely acknowledged <ref> [163, 29, 101, 92, 65] </ref>, and current debates are concerned with the representation of array element sets, and the type and amount of symbolic information required to handle real life programs, time and space complexity versus accuracy being the main issue.
Reference: [30] <author> William Blume and Rudolf Eigenmann. </author> <title> The range test: A dependence test for symbolic, non-linear expressions. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <pages> pages 528-537, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: While this may sometimes allow to disprove dependences, this may also lead to non-linear subscripts, which often prevent subsequent dependence tests. Several studies have been dedicated to solving such problems in the general case <ref> [68, 97, 30, 89, 176] </ref>. By using regions, some dependences may be disproved, whereas other techniques based on linear algebra may fail. Consider for instance the program of Figure 13.3. After induction variable substitution, array subscripts are non-linear, and an advanced dependence test is required.
Reference: [31] <author> F. Bodin, C. Eisenbeis, W. Jalby, T. Montaut, P. Rabain, and D. Windheiser. </author> <title> Algorithms for data locality optimization. </title> <booktitle> Deliverable CoD3, </booktitle> <address> APPARC, </address> <year> 1994. </year>
Reference-contexts: The first approach is based on loop transformations (loop reversal, fusion and interchange in [155], compound loop transformation with loop interchange, reversal, skewing, and tiling in [172], loop permutation in [114] and loop interchange and blocking in <ref> [80, 31] </ref>), basically to concentrate near array references in innermost loops, so that processors access compact sets of data (array contraction [155]).
Reference: [32] <author> Fran~cois Bourdoncle. </author> <title> Abstract interpretation by dynamic partitioning. </title> <journal> Journal of Functional Programming, </journal> <volume> 2(4) </volume> <pages> 407-435, </pages> <year> 1992. </year>
Reference-contexts: Ce sera le point de depart de notre solution. * La deuxieme solution, appelee partitionnement dynamique <ref> [32] </ref>, revient a determiner au vol le treillis adequat. Chaque region exacte est alors approchee in-ferieurement par une liste de sous-regions representables. <p> Our solution and the exactness criterion are presented in Section 4.2 in relation with our previous work. We finally complete the description of our semantic framework, with a presentation of the properties of its main operators. 5 He also proposes a more precise technique called dynamic partitioning <ref> [32] </ref>. Very briefly, it consists in dynamically determining an approximate solution built over simpler domains. But its complexity would be too high in the case of array region computations. 6 More precisely the dual of his widening operator. 4.1.
Reference: [33] <author> Fran~cois Bourdoncle. </author> <title> Semantique des Langages Imperatifs d'Ordre Superieur et Interpretation Abstraite. </title> <type> PhD thesis, </type> <institution> Ecole Polytechnique, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Les fonctions recursives faisant intervenir cet operateur ne sont donc pas continues ; et l'on ne peut definir leur plus petit point fixe, et donc en donner une meilleure definition. Ce probleme est connu dans le domaine de l'interpretation abstraite <ref> [33, 57] </ref>, et pas seulement pour la sous-approximation des ensembles a coordonnees dans Z. Une solution consiste a changer de domaine d'etude. <p> MAY, MUST OR EXACT? polyhedra or rsds. This means that, given an exact array region, no best under-approximation can be defined. This is illustrated in Figure 4.1 where several possible under-approximations of an array region are provided for two different representations. In this case, Bourdoncle <ref> [33] </ref> suggests to approximate fixed points by decreasing under-approximate iterations 5 , using a narrowing operator 6 . However, this approach may fail to compute under-approximations equal to the corresponding exact solutions whereas the computation of the latter is decidable, which is possible as shown in [17, 63]. <p> In fact, this kind of problem is not unfrequent <ref> [57, 33] </ref>. And whereas we restrain our discussion to array region analyses in this section, the same argumentation would hold for other types of analyses. <p> An ad-hoc computable under-approximation must then be built in the chosen domain. Some possible choices have already been described in <ref> [33] </ref>. This will be the subject of the next subsection. <p> points can then be safely approximated by successive iterations relying on sequences of narrowing operators [56, 55]. ff abstraction function approximate solution space exact solution space meaning function fl To handle cases where the approximate solution space is not a lattice or a cpo, but a mere partial order, Bourdoncle <ref> [33] </ref> generalizes the traditional approach of Galois connections by defining representations, in which ff is not required to be a monotone function. <p> But in the case of a continuous function, its computability is not necessarily decidable [55]. Convergence acceleration methods, very similar to those presented in Section 4.1.4 for representations, can nevertheless be used when the cpo is also a complete lattice <ref> [55, 33] </ref>. They are not presented here, because they would provide no useful insights, but their use is assumed whenever necessary. 4.3.3 Composing analyses As will be shown in the following chapters, many analyses rely on the results given by preceding analyses. <p> Since array elements are stored in column order in fortran, this is sufficient to describe the complete aliased memory suites. But in fact, this set is not computable in the general case, due to interprocedu-ral aliasing, and it must be approximated <ref> [33] </ref>: M ayBeAliased and M ustBeAliased sets respectively are its over- and under-approximations. Since the smallest variable declaration scope in fortran is the procedure, both sets are constant during intrapro-cedural analyses. <p> PIPS OVERVIEW Appendix B Over- and Under Representations This appendix presents the generalization of Galois connections proposed by Bour-doncle in his thesis <ref> [33] </ref>, in the case of over- and under-approximations. An example then shows the limitations of this approach for under-approximate array region analyses.
Reference: [34] <author> Thomas Brandes. </author> <title> The importance of direct dependences for automatic paral-lelization. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <pages> pages 407-417, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: The first studies were due to Brandes <ref> [34] </ref> and Feautrier [70]. This approach also encountered a frank success for the quality of information it can provide. However, early implementations only dealt with very limited subset languages. Recent extensions lessen this drawback, some times at the expense of accuracy. <p> Direct or value-based dependence computations are based on the same principle. In addition, the order in which instructions are executed must be taken into account, which is achieved through different methods <ref> [34, 70, 147] </ref>. The differences between this approach and the former one (extensions of standard data flow analyses), are not easy to isolate. <p> Our main concern are the class of programs which are treated, the accuracy of the computed information, the way the order in which instructions are executed is handled, and how the context (variable values, variable modifications, if conditions) is taken into account. Brandes <ref> [34] </ref> Brandes was one of the first to propose to compute direct dependences, that is to say dependences that cannot be transitively represented by other dependences. <p> Pugh and Wonnacott [146, 147, 176] Last but not the least, Pugh and Wonnacott have built a framework to compute value-based dependences. It is essentially based on the same equations as Bran-des <ref> [34] </ref>, but is formulated using dependence relations, and can handle many more cases. It is quite different from Feautrier's approach. First, instead of using a lexicographical maximum, they express the ordering constraints using negated existentially quantified predicates. <p> in et out ont ete introduites pour modeliser le flot des valeurs, la tentation est grande de les utiliser pour construire un graphe de dependance base sur les conflits de valeurs ; et ceci m^eme si les regions in et out fournissent une information moins precise que les fonctions sources <ref> [34, 72, 147] </ref>. La question est donc : que peut-on esperer de l'utilisation des regions in et out pour l'analyse des dependances ? Les regions in d'une instruction representent les elements de tableau qu'elle im-porte, tandis que ces regions out contiennent les elements qu'elle exporte. <p> Les differences portent essentiellement sur le type de representation choisi pour les ensembles d'elements de tableaux, et les tests de dependance utilises, de maniere a obtenir un compromis entre precision et complexite. Une autre tendance actuelle est d'utiliser les dependances directes <ref> [34, 72, 147] </ref> pour generer du code, au lieu des dependances sur la memoire, de maniere a detecter le parallelisme cache par la reutilisation des variables. Ces analyses sont tres precises, mais assez co^uteuses, et imposent souvent des restrictions sur le langage source. <p> Since in and out regions have been introduced to model the flow of values, the temptation is high to use them to build value based dependence graphs. However, in and out regions carry less information than source functions <ref> [34, 72, 147] </ref> for instance, because they do not keep trace of the precise references responsible for the accesses they collectively represent. <p> All the previously cited works deal with memory based dependences. However, these techniques fail to discover parallelism hidden by variable reuse. Several approaches have therefore been designed to study value based dependences <ref> [34, 72, 130, 147] </ref>. They chiefly differ on the algorithms used to compute the dependences, which has an effect on complexity, and the restrictions on the source language (see Sections 6.10 and 14.5). in and out regions were not designed to achieve the same accuracy as these methods. <p> The second problem lies in the fact that the copy-out set is equal to the set of outward-exposed definitions, and not to the outward exposed definitions actually used in the continuation of the program, as out regions. Brandes <ref> [34] </ref> Brandes also proposes an algorithm for array expansion based on direct dependence analyses, for monoprocedural general control flow programs. Calland et al. [38, 39] . Another array expansion method is proposed by Calland.
Reference: [35] <author> Michael Burke and Ron Cytron. </author> <title> Interprocedural dependence analysis and par-allelization. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 21(7) </volume> <pages> 162-175, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: There are several methods to handle this kind of problem: * The first one is to have a single representative for any set of may or must aliased variables. A well-known technique <ref> [35] </ref> is to introduce a new one-dimensional array to represent the corresponding memory suite, and to provide the offset of the first element of each aliased variable from the first element of the memory suite. <p> Nous avons egalement presente un nouvel algorithme de traduction des regions de tableaux au niveau des appels de procedure. Il peut ^etre vu comme la synthese et l'extension des techniques existantes. En effet, celles-ci utilisaient soit uniquement la detection des cas triviaux, soit uniquement la linearisation <ref> [35] </ref> ; ou encore l'une et l'autre des deux methodes [92] selon la reussite ou l'echec de la premiere. Cependant, notre algorithme ne permet toujours pas de traiter certains cas de figure, comme la traduction entre des tableaux declares comme MAT (N,M) et V (N*M). <p> routine are initialized to the empty set, since a program is supposed to have no side effect, viewed from the outside (I/Os are performed from within the program itself). 10.3 Other Approaches The purpose of earliest implementations of array region analyses was to support data dependence analysis across procedure boundaries <ref> [161, 163, 35, 37, 122, 98, 99] </ref> or between different tasks [19]. Hence, only over-approximations of effects on array element sets were required. Moreover, the necessity of symbolic analyses had not yet been brought to light, and usually, context information such as if conditions were not taken into account. <p> which is the case when A and B belong to a COMMON that is not similarly declared in the source and target routine. 11.4 Related Work The previous work closest to ours for the interprocedural translation are those of Triolet [161], Tang [159] Hall [93], Leservot [121], Burke and Cytron <ref> [35] </ref> and Maslov [128]. Many other less recent works [37, 99, 19] have addressed the problem of the in-terprocedural propagation of array element sets. But they did not provide sufficient symbolic analyses, and did not tackle array reshaping. <p> This implies that no partial association is allowed at procedure boundaries (i.e. the source and target arrays have the same type); furthermore, only very simple array reshapes are handled (the same cases as in [161] and [159]). Burke and Cytron <ref> [35] </ref> They alleviate the memory disambiguation problem by linearizing all array accesses when possible. This is equivalent to using (S) in our method. However, we have seen that this may lead to non linear expressions, that may prevent further dependence testing for instance. <p> Les travaux sur l'analyse de dependance a l'aide de regions de tableaux sont tres nombreux <ref> [162, 163, 122, 37, 19, 98, 99, 35, 92] </ref>. Les differences portent essentiellement sur le type de representation choisi pour les ensembles d'elements de tableaux, et les tests de dependance utilises, de maniere a obtenir un compromis entre precision et complexite. <p> Therefore, dependence tests combining successive individual tests have been suggested <ref> [35, 105, 129, 175, 143] </ref>. If an individual test concludes to the existence or non-existence of a solution, then the analysis is complete, otherwise a more complicated test is applied. pips dependence test ranks among these approaches [105, 177]. <p> However, most of the above studies only deal with individual references, and not with compound instructions, such as procedures. To analyze dependences across procedure boundaries, Triolet introduced a novel approach, based on array regions. Section 13.2.1 shows how this technique is applied in pips. Related works are numerous <ref> [162, 163, 122, 37, 19, 98, 99, 35, 92] </ref>, the main issues being again complexity and accuracy, but with respect to the representation of array regions. More details on these studies can be found in Chapters 8 and 11.
Reference: [36] <author> D. Callahan. </author> <title> The program summary graph and flow-sensitive interprocedural data-flow analysis. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 23(7) </volume> <pages> 47-56, </pages> <month> July </month> <year> 1988. </year> <booktitle> Also published in the proceedings of the International Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: INTERPROCEDURAL PROPAGATION OF REGIONS IN PIPS 183 To reduce this complexity, several sparse representations have been designed for particular classes of problems, such as the program summary graph <ref> [36] </ref>, the ssa form [67, 158], the sparse data flow evaluation graph [41], the system dependence graph [75, 26], : : : The unified interprocedural graph [96] provides a demand-driven unified representation which combines the advantages of the sparse rep resentations without restricting the scope of the possible analyses. * Another
Reference: [37] <author> D. Callahan and K. Kennedy. </author> <title> Analysis of interprocedural side effects in a parallel programming environment. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 517-550, </pages> <year> 1988. </year>
Reference-contexts: de tableaux en fonction du type d'application considere, de la complexite souhaitee, de la prise en compte d'informations symboliques comme le contexte, : : : Par contre, tres peu d'etudes se sont penchees sur le cadre theorique de la semantique des analyses de regions ; ou alors pour certaines representations <ref> [37] </ref>, et toujours pour les analyses approchees superieurement [108]. <p> But very few studies have brooded over the theoretical framework underlying array region analyses; and only 16 CHAPTER 2. CONTEXT AND OPEN ISSUES for a particular representation <ref> [37] </ref>, and always for over-approximate analyses [108]. <p> Pour les analyses de regions, les solutions exactes appartiennent au treillis (-(Z n ); ?; Z n ; [; "). Les analyses approchees superieurement sont aussi definies sur des treillis : treillis des polyedres convexes dans pips, treillis des sections regulieres dans le cas des rsds <ref> [37] </ref>, : : : Ainsi, tout comme la semantique exacte, la semantique approchee des regions de tableaux est parfaitement definie. <p> Deux cas peuvent se presenter : 1. Le codomaine 4 de l'analyse preliminaire est le m^eme que le domaine de l'analyse de regions. L'utilisation de la loi de composition usuelle (ffi) peut alors donner des solutions non representables. Par exemple, si les regions sont representees par des rsds <ref> [37] </ref>, alors la region de l'instruction (S) dans : if (i.eq.3) then (S) ...= A (i) endif est A (i : i). Pour l'ensemble du programme, on doit composer ce resultat avec l'evaluation de la condition : si (i.eq.3) alors A (i : i) sinon ?. <p> Mais ce critere de necessite reste a definir. 3.4 Autres Travaux et Conclusion De nombreuses etudes ont aborde les analyses de regions de tableaux depuis leur introduction par Triolet [161]. Les plus anciennes concernent generalement le choix de la representation des elements de tableaux <ref> [37, 19, 98, 99] </ref>, probleme que nous traiterons dans la partie III, pour des analyses approchees superieurement, et insensibles au flot de controle du programme. Dans les etudes plus recentes [151, 86, 92, 135, 164], nous retrouvons des types d'analyses similaires aux notres, a l'exception des regions out. <p> For instance, exact solutions of array region analyses belong to the lattice (-(Z n ); ?; Z n ; [; "). Over-approximate analyses of array regions are also defined on lattices: Lattice of convex polyhedra in pips, or regular section lattice in the case of rsds <ref> [37] </ref> for instance 4 , or lattice of Presburger formulae as proposed in [176]. <p> Facing these obstacles, the solution is either to restrict the input language (as in [70, 72, 159, 130]), or to perform conservative approximate analyses [55] on real-life programs. This last characteristics has played a great role in the popularity of the method <ref> [2, 111, 55, 134, 153, 161, 37, 86] </ref>. Here, the complexity of the computation directly depends on the accuracy of the analysis. Up to now, no measurement of this accuracy has been proposed [55]. This section describes some usual characteristics of exact and approximate semantic analysis frameworks. <p> For instance, array element index sets are parts of Z n . Due to the complexity of being able to represent any part of Z n , several compact representations have been defined: Convex polyhedra [161], rsd <ref> [37] </ref>, dad [19], : : : Another example is the abstraction of statement effects on variables values (the so-called transformers in pips). <p> SEMANTIC ANALYSIS FRAMEWORKS 47 v; :?; :Z d ; convex hull; u) is a complete lattice, but is not a sub-lattice of L because in general convex hull (R 1 ; R 2 ) 6= R 1 t R 2 . (This is also the case for rsds <ref> [37] </ref> or dads [19] : : : ). However, since convex hull (R 1 ; R 2 ) w R 1 t R 2 , the resulting analyses necessarily are over-approximations. But we also need under-approximations. The next theorem characterizes the complete lattices which allow such analyses. <p> Let us consider the analysis of the set of array elements read by a program; let us assume that array element sets are represented by rsds <ref> [37] </ref>. And let us compute the solution for the following conditional instruction: if (i.eq.3) then (S) ...= A (i) endif The rsd for instruction (S) is A (i : i). <p> A second problem is due to the fact that early approaches <ref> [161, 37, 19] </ref> only performed over-approximate analyses of read and write regions. <p> Note 1. Using sets such as f T 1 : r 1 ( T 1 ; )g does not preclude any representation. In pips, r 1 ; : : : ; r n are convex polyhedra parameterized by the program variables. For rsd's <ref> [37] </ref>, r i is a conjunction of affine constraints with unit coefficients, which only depend on loop indices and symbolic constants: r i ( T i ; ) = j=1 j = I k + ff j ) or r i ( T i ; ) = j=1 j = ff <p> To solve the first problem, a new technique, based on the summarization of the array elements accessed by procedures, was introduced by Triolet [161], soon followed by many others <ref> [37, 19, 98, 99] </ref> who introduced different representations of array element sets. For the second problem, two approaches were proposed: * Extensions of classical data flow frameworks to array element sets. Earliest works were due to Rosene or Gross and Steenkiste [151, 86]. <p> However, the complexity of the operators is theoretically exponential, and is generally high, even though it has been shown to be polynomial in practical cases [9]. Regular Section Descriptors There are several definitions for rsds. The initial ones <ref> [37] </ref> can represent elements, rows, columns, diagonals and their higher dimensional analogs, but cannot be used to represent triangular regions or discontinuous portions of rows. Havlak also gives a definition of rsds with bounds and strides [98, 99], but it cannot represent diagonals. <p> routine are initialized to the empty set, since a program is supposed to have no side effect, viewed from the outside (I/Os are performed from within the program itself). 10.3 Other Approaches The purpose of earliest implementations of array region analyses was to support data dependence analysis across procedure boundaries <ref> [161, 163, 35, 37, 122, 98, 99] </ref> or between different tasks [19]. Hence, only over-approximations of effects on array element sets were required. Moreover, the necessity of symbolic analyses had not yet been brought to light, and usually, context information such as if conditions were not taken into account. <p> Many other less recent works <ref> [37, 99, 19] </ref> have addressed the problem of the in-terprocedural propagation of array element sets. But they did not provide sufficient symbolic analyses, and did not tackle array reshaping. <p> Les travaux sur l'analyse de dependance a l'aide de regions de tableaux sont tres nombreux <ref> [162, 163, 122, 37, 19, 98, 99, 35, 92] </ref>. Les differences portent essentiellement sur le type de representation choisi pour les ensembles d'elements de tableaux, et les tests de dependance utilises, de maniere a obtenir un compromis entre precision et complexite. <p> However, most of the above studies only deal with individual references, and not with compound instructions, such as procedures. To analyze dependences across procedure boundaries, Triolet introduced a novel approach, based on array regions. Section 13.2.1 shows how this technique is applied in pips. Related works are numerous <ref> [162, 163, 122, 37, 19, 98, 99, 35, 92] </ref>, the main issues being again complexity and accuracy, but with respect to the representation of array regions. More details on these studies can be found in Chapters 8 and 11. <p> La prise en compte de l'etat memoire est necessaire car il permet de ne pas manipuler directement les valeurs de variables, et facilite donc les analyses symboliques. Des etudes precoces <ref> [37, 19] </ref> proposaient des representation des regions ne prenant pas en compte cette dimension, et ne permettaient donc pas des analyses precises lorsque des variables 243 244 CHAPITRE 15.
Reference: [38] <author> Pierre-Yves Calland, Alain Darte, Yves Robert, and Frederic Vivien. </author> <title> On the removal of anti and output dependences. </title> <institution> Rapport de Recherche 2800, INRIA, </institution> <month> February </month> <year> 1996. </year>
Reference-contexts: Brandes [34] Brandes also proposes an algorithm for array expansion based on direct dependence analyses, for monoprocedural general control flow programs. Calland et al. <ref> [38, 39] </ref> . Another array expansion method is proposed by Calland. It is a generalization of two program transformations originally introduced by Padua and Wolfe in [136] to remove anti and output dependences. The transformed loops can then be parallelized using Allen and Kennedy algorithm [4].
Reference: [39] <author> Pierre-Yves Calland, Alain Darte, Yves Robert, and Frederic Vivien. </author> <title> Plugging anti and output dependence removal techniques into loop parallelization algorithms. </title> <institution> Rapport de Recherche 2914, INRIA, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: Brandes [34] Brandes also proposes an algorithm for array expansion based on direct dependence analyses, for monoprocedural general control flow programs. Calland et al. <ref> [38, 39] </ref> . Another array expansion method is proposed by Calland. It is a generalization of two program transformations originally introduced by Padua and Wolfe in [136] to remove anti and output dependences. The transformed loops can then be parallelized using Allen and Kennedy algorithm [4].
Reference: [40] <author> Philippe Chassany. </author> <title> Les methodes de parallelisation interprocedurales. </title> <type> Master's thesis, </type> <institution> Universite Paris VI, Septembre 1990. DEA Systemes Informatiques. </institution> <address> Rapport interne CRI-ENSMP EMP-CAI-I E/129. 304 BIBLIOGRAPHIE BIBLIOGRAPHY </address>
Reference-contexts: The main advantage is that usual intraprocedural analyses and transformations can be applied on the resulting code, with the same precision. However, there are several counter-arguments: * First, inlining is not always possible <ref> [40] </ref>, due to array reshaping, or recursive procedures in languages other than fortran. * Second, the resulting code is usually much larger than the original.
Reference: [41] <author> J Choi, R. Cytron, and J Ferrante. </author> <title> Automatic construction of sparse data flow evaluation graphs. </title> <booktitle> In Symposium on Principles of Programming Languages, </booktitle> <pages> pages 55-66, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: INTERPROCEDURAL PROPAGATION OF REGIONS IN PIPS 183 To reduce this complexity, several sparse representations have been designed for particular classes of problems, such as the program summary graph [36], the ssa form [67, 158], the sparse data flow evaluation graph <ref> [41] </ref>, the system dependence graph [75, 26], : : : The unified interprocedural graph [96] provides a demand-driven unified representation which combines the advantages of the sparse rep resentations without restricting the scope of the possible analyses. * Another issue is the ability to avoid taking into account unrealizable paths [119].
Reference: [42] <author> Micha l Cierniak and Wei Li. </author> <title> Recovering logical structures of data. </title> <booktitle> In Languages and Compilers for Parallel Computing, Lecture Notes in Computer Science, </booktitle> <pages> pages 362-376. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Sophisticated techniques, which are not available in pips, are then necessary. For example, when nonlinear subscripts are due to the hand linearization of a multidimensional array, as in TRFD [25], the data structure may be recovered from the flat array <ref> [42] </ref>. Finally, even in pieces of code where all expressions are perfectly linear, convex polyhedra are not always sufficient to exactly represent array regions. The first reason is that some access patterns intrinsically are non-convex. An example is provided in Figure 8.9, where the loop nest references nine-point stencils.
Reference: [43] <author> Ph. Clauss and V. Loechner. </author> <title> Parametric analysis of polyhedral iteration spaces. </title> <booktitle> In International Conference on Application Specific Array Processors, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: Generating these private copies from array regions represented by convex polyhedra, and converting former accesses to the global array into references to the local array, are themselves not trivial issues (see <ref> [12, 145, 44, 43, 6] </ref>). Handling copy-in and copy-out regions also depends on the target parallel model.
Reference: [44] <author> Philippe Clauss. </author> <title> Couting solutions to linear and nonlinear constraints through Ehrhart polynomials: Applications to analyse and transform scientific programs. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Generating these private copies from array regions represented by convex polyhedra, and converting former accesses to the global array into references to the local array, are themselves not trivial issues (see <ref> [12, 145, 44, 43, 6] </ref>). Handling copy-in and copy-out regions also depends on the target parallel model.
Reference: [45] <author> Fabien Coelho. </author> <title> Experiments with HPF Compilation for a Network of Workstations. </title> <booktitle> In High Performance Computing and Networking Conference, </booktitle> <pages> pages 423-428, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: It is now mainly targeted at generating code for distributed memory machines, using different methods (processor and memory bank code for control distribution [13], cmf, craft polyhedral method [140] or message-passing code from HPF <ref> [45] </ref>). As we see in Section A.3, the translation process is broken into smaller modular operations called phases in Pips. For the user, these phases can be classified into various categories according to their usage. <p> HPF Compiler Hpfc is a prototype HPF compiler implemented as a set of Pips phases. From Fortran 77, HPF static (align distribute processors template), dynamic (realign redistribute dynamic) and parallelism (independent new) directives, it generates portable PVM-based SPMD codes which have run on various parallel architectures (SUN NOW <ref> [45] </ref>, DEC alpha farm, TMC CM5, IBM SP2).
Reference: [46] <author> Fabien Coelho. </author> <title> Compilation of I/O communications for HPF. </title> <booktitle> In Frontiers'95, </booktitle> <pages> pages 102-109, </pages> <month> February </month> <year> 1995. </year> <note> Available via http://www.cri.ensmp.fr/~coelho. </note>
Reference-contexts: On the contrary, the last approach [17, 63] tries to compute exact solutions whenever possible, switching to conservative approximations only when exactness cannot be preserved anymore. However, except for specific applications <ref> [46, 47] </ref> requiring the knowledge of exactness, the advantages of our approach are still an open issue, which is discussed in this chapter. Traditionally, semantic analyses are defined on lattices. <p> This method is very general and not solely limited to array region analyses. It can be used whenever one of the approximate domain is not a lattice, but also whenever exactness is specifically required, as in <ref> [46, 47] </ref>. This chapter is organized as follows. Section 4.1 presents the semantic analysis framework, and shows that some analysis solutions may not belong to a predefined lattice; existing ad-hoc solutions are also presented. <p> It can be useful for every type of analysis where one of the approximation is not defined on a predefined lattice. But also when exact results are required for specific applications <ref> [46, 47] </ref>. Indeed, we show how to obtain an optimal exactness criterion valid for both may and must analyses. <p> It has been applied to I/O communications <ref> [46] </ref> and general remappings [48]. Parallelization The primary parallelization method used for shared-memory machines is based on Allen&Kennedy algorithm and on dependence levels. This algorithm was slightly modified to avoid loop distribution between statements using the same private variable (s).
Reference: [47] <author> Fabien Coelho and Corinne Ancourt. </author> <title> Optimal compilation of HPF remappings. </title> <type> Technical Report A-277-CRI, </type> <institution> CRI, Ecole des Mines de Paris, </institution> <month> October </month> <year> 1995. </year> <note> To appear in JPDC in 1996. </note>
Reference-contexts: On the contrary, the last approach [17, 63] tries to compute exact solutions whenever possible, switching to conservative approximations only when exactness cannot be preserved anymore. However, except for specific applications <ref> [46, 47] </ref> requiring the knowledge of exactness, the advantages of our approach are still an open issue, which is discussed in this chapter. Traditionally, semantic analyses are defined on lattices. <p> This method is very general and not solely limited to array region analyses. It can be used whenever one of the approximate domain is not a lattice, but also whenever exactness is specifically required, as in <ref> [46, 47] </ref>. This chapter is organized as follows. Section 4.1 presents the semantic analysis framework, and shows that some analysis solutions may not belong to a predefined lattice; existing ad-hoc solutions are also presented. <p> It can be useful for every type of analysis where one of the approximation is not defined on a predefined lattice. But also when exact results are required for specific applications <ref> [46, 47] </ref>. Indeed, we show how to obtain an optimal exactness criterion valid for both may and must analyses.
Reference: [48] <author> Fabien Coelho and Corinne Ancourt. </author> <title> Optimal Compilation of HPF Remappings. </title> <type> CRI TR A 277, </type> <institution> CRI, Ecole des Mines de Paris, </institution> <month> October </month> <year> 1995. </year> <note> To appear in JPDC, </note> <year> 1996. </year>
Reference-contexts: It has been applied to I/O communications [46] and general remappings <ref> [48] </ref>. Parallelization The primary parallelization method used for shared-memory machines is based on Allen&Kennedy algorithm and on dependence levels. This algorithm was slightly modified to avoid loop distribution between statements using the same private variable (s).
Reference: [49] <author> Jean-Fran~cois Collard. </author> <title> Space-time transformation of while-loops using speculative execution. </title> <booktitle> In Scalable High Performance Computing Conference, </booktitle> <pages> pages 429-436, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Some of the intra-procedural restrictions have since been partially removed, sometimes at the expense of accuracy: Maslov [127] extends this method to handle, to some extent, if constructs and general variables. Collard <ref> [49, 50] </ref> proposes an extension for do while constructs. Collard et al. [51, 73, 24] remove some linearity limitations, but at the expense of accuracy. collard and Griebl [52] finally extend the framework to explicitly (con trol) parallel programs containing doall and doacross loops.
Reference: [50] <author> Jean-Fran~cois Collard. </author> <title> Automatic parallelization of while-loops using speculative execution. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 23(2) </volume> <pages> 191-219, </pages> <year> 1995. </year>
Reference-contexts: Some of the intra-procedural restrictions have since been partially removed, sometimes at the expense of accuracy: Maslov [127] extends this method to handle, to some extent, if constructs and general variables. Collard <ref> [49, 50] </ref> proposes an extension for do while constructs. Collard et al. [51, 73, 24] remove some linearity limitations, but at the expense of accuracy. collard and Griebl [52] finally extend the framework to explicitly (con trol) parallel programs containing doall and doacross loops.
Reference: [51] <author> Jean-Fran~cois Collard, Denis Barthou, and Paul Feautrier. </author> <title> Fuzzy array dataflow analysis. </title> <booktitle> In Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Some of the intra-procedural restrictions have since been partially removed, sometimes at the expense of accuracy: Maslov [127] extends this method to handle, to some extent, if constructs and general variables. Collard [49, 50] proposes an extension for do while constructs. Collard et al. <ref> [51, 73, 24] </ref> remove some linearity limitations, but at the expense of accuracy. collard and Griebl [52] finally extend the framework to explicitly (con trol) parallel programs containing doall and doacross loops. Interprocedural extensions have been formulated by Leservot: This is described below.
Reference: [52] <author> Jean-Fran~cois Collard and Martin Griebl. </author> <title> Array dataflow analysis for explicitely parallel programs. </title> <booktitle> In Europar'96, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: Collard [49, 50] proposes an extension for do while constructs. Collard et al. [51, 73, 24] remove some linearity limitations, but at the expense of accuracy. collard and Griebl <ref> [52] </ref> finally extend the framework to explicitly (con trol) parallel programs containing doall and doacross loops. Interprocedural extensions have been formulated by Leservot: This is described below.
Reference: [53] <author> K. Cooper, M. W. Hall, and K. Kennedy. </author> <title> Procedure cloning. </title> <booktitle> In IEEE International Conference on Computer Language, </booktitle> <month> April </month> <year> 1992. </year>
Reference-contexts: De plus, l'utilisation systematique de resumes ne permet pas de distinguer les informations specifiques a tel ou tel chemin d'acces, et conduit donc a considerer des combinaisons ne pouvant pas se produire, probleme connu sous le nom d'unrealizable paths [119]. L'utilisation du clonage selectif <ref> [53, 91] </ref>, ou l'utilisation de representations du programme plus generales [134], pourraient en reduire les effets. 9.2 Traduction des Regions Cette section decrit la partie traduction de la propagation interprocedurale. <p> Ces analyses beneficieraient de l'utilisation de techniques comme le clonage selectif <ref> [53, 91] </ref>. Nous avons egalement presente un nouvel algorithme de traduction des regions de tableaux au niveau des appels de procedure. Il peut ^etre vu comme la synthese et l'extension des techniques existantes. <p> Moreover, there is no restriction on the input code. However, much precision may be lost, due to summarization techniques, and translation processes. In between, a recent techniques tries to lessen the drawbacks of interprocedural analysis, while preserving a reasonable complexity. Selective cloning <ref> [91, 53] </ref> duplicates procedures on the basis of calling contexts. A heuristic based on integer variable values has proved useful in subsequent array region analyses, without increasing the program size too dramatically [91]. However, even if this approach alleviates some problem, it still requires interprocedural analysis techniques.
Reference: [54] <author> Keith Cooper, Ken Kennedy, and Nathaniel McIntosh. </author> <title> Cross-loop reuse analysis and its application to cache optimizations. </title> <booktitle> In Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1996. </year> <note> BIBLIOGRAPHIE BIBLIOGRAPHY 305 </note>
Reference-contexts: But since it could not include context information, an extension to gated rsds has also been informally proposed to take if conditions into account. Data access descriptors Lists of dads have been proposed to study inter-loop par allelism in <ref> [54] </ref>. However, they cannot contain context information. Complementary sections have been defined by Manjunathaiah [125]: They contain a simple section to describes the hull of the region, and several simple sections which represent the complementary of the exact region in the hull.
Reference: [55] <author> Patrick Cousot. </author> <title> Methodes Iteratives de Construction et d'Approximation de Points Fixes d'Operateurs Monotones sur un Treillis, Analyse Semantique des Programmes. </title> <type> PhD thesis, </type> <institution> Institut National Polytechnique de Grenoble, </institution> <month> March </month> <year> 1978. </year>
Reference-contexts: Facing these obstacles, the solution is either to restrict the input language (as in [70, 72, 159, 130]), or to perform conservative approximate analyses <ref> [55] </ref> on real-life programs. This last characteristics has played a great role in the popularity of the method [2, 111, 55, 134, 153, 161, 37, 86]. Here, the complexity of the computation directly depends on the accuracy of the analysis. <p> Facing these obstacles, the solution is either to restrict the input language (as in [70, 72, 159, 130]), or to perform conservative approximate analyses [55] on real-life programs. This last characteristics has played a great role in the popularity of the method <ref> [2, 111, 55, 134, 153, 161, 37, 86] </ref>. Here, the complexity of the computation directly depends on the accuracy of the analysis. Up to now, no measurement of this accuracy has been proposed [55]. This section describes some usual characteristics of exact and approximate semantic analysis frameworks. <p> This last characteristics has played a great role in the popularity of the method [2, 111, 55, 134, 153, 161, 37, 86]. Here, the complexity of the computation directly depends on the accuracy of the analysis. Up to now, no measurement of this accuracy has been proposed <ref> [55] </ref>. This section describes some usual characteristics of exact and approximate semantic analysis frameworks. It is then shown that some analyses do not respect these properties. <p> The image of an exact continuous recursive function by ff is then still continuous; its least fixed point is well defined, though its computability is not even decidable. Cousot has shown that least fixed points can then be safely approximated by successive iterations relying on sequences of narrowing operators <ref> [56, 55] </ref>. ff abstraction function approximate solution space exact solution space meaning function fl To handle cases where the approximate solution space is not a lattice or a cpo, but a mere partial order, Bourdoncle [33] generalizes the traditional approach of Galois connections by defining representations, in which ff is not <p> But in the case of a continuous function, its computability is not necessarily decidable <ref> [55] </ref>. Convergence acceleration methods, very similar to those presented in Section 4.1.4 for representations, can nevertheless be used when the cpo is also a complete lattice [55, 33]. <p> But in the case of a continuous function, its computability is not necessarily decidable [55]. Convergence acceleration methods, very similar to those presented in Section 4.1.4 for representations, can nevertheless be used when the cpo is also a complete lattice <ref> [55, 33] </ref>. They are not presented here, because they would provide no useful insights, but their use is assumed whenever necessary. 4.3.3 Composing analyses As will be shown in the following chapters, many analyses rely on the results given by preceding analyses. <p> Indeed, we show how to obtain an optimal exactness criterion valid for both may and must analyses. Furthermore, and from a theoretical point of view, being able to detect the exactness of an analysis gives a partial answer to a still unresolved question from Cousot's thesis <ref> [55] </ref>, about the distance between an approximation and its corresponding exact solution. <p> The domain is used to represent the current state of the program, in fact the current state of the memory: It maps each reference to the value it represents 2 . : R ! V Any statement can thus be seen as a memory store transformer <ref> [55] </ref>: It converts its preceding memory store into another memory store. Each domain is also provided with a greatest element &gt; and a lowest element ? when necessary. <p> SOURCE LANGUAGE AND PRELIMINARY ANALYSES 5.4 Transformers and Inverse Transformers The current section is devoted to the semantics of statements. As stated before, and following a traditional point of view <ref> [55, 132, 108] </ref>, statements can be seen as memory store transformers, that is to say functions mapping stores to stores. <p> The material presented in this chapter is not original, nor optimal, but has been placed here with a regard to correctness and completeness, and with an eye to our target array region analyses. Transformers have already been defined as store transformers by many <ref> [55, 108, 132] </ref>, and their over-approximation is a well-known technique [55, 108]. Transformers and continuation conditions are backward analyses, which were as such broadly studied on a theoretical and practical ground by Cousot [55] and Halb-wachs [90]. <p> Transformers have already been defined as store transformers by many [55, 108, 132], and their over-approximation is a well-known technique <ref> [55, 108] </ref>. Transformers and continuation conditions are backward analyses, which were as such broadly studied on a theoretical and practical ground by Cousot [55] and Halb-wachs [90]. The use of the denotational approach for forward analyses was mostly inspired by Jouvelot [108]. <p> Transformers have already been defined as store transformers by many [55, 108, 132], and their over-approximation is a well-known technique [55, 108]. Transformers and continuation conditions are backward analyses, which were as such broadly studied on a theoretical and practical ground by Cousot <ref> [55] </ref> and Halb-wachs [90]. The use of the denotational approach for forward analyses was mostly inspired by Jouvelot [108].
Reference: [56] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation : a unified lattice model for static analysis of programs by construction or approximation of fix-points. </title> <booktitle> In Symposium on Principles of Programming Languages, </booktitle> <pages> pages 238-252, </pages> <year> 1977. </year>
Reference-contexts: MAY, MUST OR EXACT? 4.1.4 Usual ad-hoc solutions When the approximate solution space A 00 is a lattice or cpo, its relations with the exact solution space A can be described by a Galois connection <ref> [27, 56] </ref>, which defines two monotone functions: An abstraction function ff : A ! A 00 , and a concretization or meaning function fl : A 00 ! A (see Figure 4.2). <p> The image of an exact continuous recursive function by ff is then still continuous; its least fixed point is well defined, though its computability is not even decidable. Cousot has shown that least fixed points can then be safely approximated by successive iterations relying on sequences of narrowing operators <ref> [56, 55] </ref>. ff abstraction function approximate solution space exact solution space meaning function fl To handle cases where the approximate solution space is not a lattice or a cpo, but a mere partial order, Bourdoncle [33] generalizes the traditional approach of Galois connections by defining representations, in which ff is not
Reference: [57] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract interpretation framework. </title> <journal> Journal of Logic and Computation, </journal> <volume> 2(5) </volume> <pages> 511-547, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Les fonctions recursives faisant intervenir cet operateur ne sont donc pas continues ; et l'on ne peut definir leur plus petit point fixe, et donc en donner une meilleure definition. Ce probleme est connu dans le domaine de l'interpretation abstraite <ref> [33, 57] </ref>, et pas seulement pour la sous-approximation des ensembles a coordonnees dans Z. Une solution consiste a changer de domaine d'etude. <p> In fact, this kind of problem is not unfrequent <ref> [57, 33] </ref>. And whereas we restrain our discussion to array region analyses in this section, the same argumentation would hold for other types of analyses.
Reference: [58] <author> Patrick Cousot and Radhia Cousot. </author> <title> Higher-order abstract interpretation (and application to comportment analysis generalizing strictness, termination, projection and PER analysis of functional languages). </title> <booktitle> In International Conference on Computer Languages, </booktitle> <publisher> IEEE Computer Socitey Press, </publisher> <pages> pages 95-112, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Hence the idea to replace A by approximate analyses, comparable to A by a partial order v: A is an over-approximation of A () A v A A is an under-approximation of A () A v A This approximation ordering <ref> [58] </ref> is a logical ordering, and is not necessarily related to a partial ordering between semantic values.
Reference: [59] <author> Patrick Cousot and Nicholas Halbwachs. </author> <title> Automatic discovery of linear restraints among variables of a program. </title> <booktitle> In Symposium on Principles of Programming Languages, </booktitle> <pages> pages 84-97, </pages> <year> 1978. </year>
Reference-contexts: Pour de plus amples details sur la definition de P et de sa sur-approximation P, nous renvoyons le lecteur a la section 5.6. C'est une analyse maintenant classique, fortement inspiree de l'algorithme fournit par Cousot et Halbwachs <ref> [59] </ref>. 3.2.5 Conditions de continuation Nous avons vu au debut de cette section que la presence potentielle d'instruction stop dans un programme necessitait une prise en charge particuliere lors des analyses de regions de tableaux. <p> It is already ensured by Properties 5.1 and 5.2. 1 is not an analysis specific to our out regions. It is also used by others. For instance, it is the transfer function informally used by Cousot and Halbwachs to derive linear relationships between variables in programs <ref> [59] </ref>. <p> P peut ^etre vu comme l'intersection des demi-espaces definis par ses inegalites. Un polyedre peut aussi ^etre represente par son systeme generateur <ref> [9, 59] </ref>. Definition 7.2 Soit P un polyedre convexe. <p> P can be viewed as the intersection of the half-spaces defined by its inequalities. A polyhedron can also be represented by a generating system <ref> [9, 59] </ref>. Definition 8.2 Let P be a convex polyhedron.
Reference: [60] <editor> Beatrice Creusillet. Analyse de flot de donnees : Regions de tableaux IN et OUT. In Rencontres Francophones du Parallelisme, </editor> <month> mai-juin </month> <year> 1995. </year>
Reference-contexts: Seuls Wonnacott et Pugh [171, 170, 176] se sont penches sur ces problemes dans le cas des formules de Presburger. Nous avions nous-m^emes presente nos analyses de regions dans plusieurs rapports et articles <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. Cependant, cette partie apporte de nouvelles contributions. Nous avons ainsi etudie le cadre theorique des analyses de regions de tableaux, independamment de leur type, et avons propose une solution aux problemes poses par les analyses approchees inferieurement. <p> However, no attempt is done to actually represent the conditions under which the break is performed, as we do with continuation conditions (see Page 5.5). And lastly, Wonnacott proposes an interprocedural extension. 6.11 Conclusion We have already presented our array region analyses in several reports or papers <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. However, the present chapter is new in several respects. 122 CHAPTER 6. ARRAY REGION ANALYSES First, array regions are presented using denotational semantics or attributed grammars.
Reference: [61] <author> Beatrice Creusillet. </author> <title> Array regions for interprocedural parallelization and array privatization. </title> <type> Report A-279, </type> <institution> CRI, Ecole des Mines de Paris, </institution> <month> November </month> <year> 1995. </year> <note> Available at http://www.cri.ensmp.fr/~creusil. </note>
Reference-contexts: The idea is to perform corresponding may and must analyses at the same time, and to enhance the results of must analyses with those of may analyses according to an exactness criterion. In our implementation, whose results are already used in pips to privatize array regions <ref> [61] </ref>, must regions are not even computed; instead, may regions are flagged as exact whenever the exactness criterion is true; under-approximations are thus always equal to the empty set, unless they are exact and equal to the corresponding over-approximations. <p> But he does not actually represent the conditions under which it happens. Preconditions have been shown to be unnecessary on a semantic ground, but can be an implementation issue: Adding them may be helpful when using particular representations (see <ref> [103, 61] </ref>), and harmful when computing under-approximate regions of if constructs (see Section 6.10). An open issue is whether it could be possible and interesting to use them only when it is necessary, a criterion which has to be defined. 6.11. <p> The possible applications are numerous. Among others, in and out regions are already used in Pips to privatize array sections <ref> [16, 61] </ref>, and we intend to use them for memory allocation when compiling signal processing specifications based on dynamic single assignments. Another unique feature of Pips array Regions lies in the fact that, although they are over-approximations of the element sets actually referenced, they are flagged as exact whenever possible.
Reference: [62] <author> Beatrice Creusillet. </author> <title> IN and OUT array region analyses. </title> <booktitle> In Fifth International Workshop on Compilers for Parallel Computers, </booktitle> <pages> pages 233-246, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Seuls Wonnacott et Pugh [171, 170, 176] se sont penches sur ces problemes dans le cas des formules de Presburger. Nous avions nous-m^emes presente nos analyses de regions dans plusieurs rapports et articles <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. Cependant, cette partie apporte de nouvelles contributions. Nous avons ainsi etudie le cadre theorique des analyses de regions de tableaux, independamment de leur type, et avons propose une solution aux problemes poses par les analyses approchees inferieurement. <p> However, this approach may fail to compute under-approximations equal to the corresponding exact solutions whereas the computation of the latter is decidable, which is possible as shown in [17, 63]. We thus propose another approach, based on our previous experience of exact array data flow analyses <ref> [63, 62, 65] </ref>: We suggest to perform under- and over-approximate analyses at the same time, and to enhance the results of must analyses with those of may analyses, when the latter can be proved exact according to a computable exactness criterion. <p> However, no attempt is done to actually represent the conditions under which the break is performed, as we do with continuation conditions (see Page 5.5). And lastly, Wonnacott proposes an interprocedural extension. 6.11 Conclusion We have already presented our array region analyses in several reports or papers <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. However, the present chapter is new in several respects. 122 CHAPTER 6. ARRAY REGION ANALYSES First, array regions are presented using denotational semantics or attributed grammars.
Reference: [63] <author> Beatrice Creusillet and Fran~cois Irigoin. </author> <title> Interprocedural array region analyses. </title> <booktitle> In Languages and Compilers for Parallel Computing, number 1033 in Lecture Notes in Computer Science, </booktitle> <pages> pages 46-60. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Detecter ces regions de tableaux privatisables requiert une analyse precise du flot des elements de tableaux. Plusieurs algorithmes de privatisation ou d'expansion 1 on deja ete proposees <ref> [70, 130, 123, 166, 93, 17, 63] </ref>. Ils reposent sur differents types d'analyse du flot des elements de tableaux. La premiere approche [70, 130] effectue une analyse exacte, mais a partir 1 Une technique similaire pour les machines a moire partagee. 21 22 CHAPTER 3. <p> S EMANTIQUE DES R EGIONS DE TABLEAUX d'un langage source restreint, dit langage monoprocedural a controle statique. La plupart des autres methodes utilise des analyses de regions de tableaux approchees, sur-ou sous-estimees selon un ordre predefini. Au contraire, la derniere approche <ref> [17, 63] </ref> consiste a calculer des solutions exactes tant que cela est possible, et a n'effectuer des approximations que lorsque l'exactitude ne peut ^etre conservee. Cette section montre les avantages de cette derniere methode. <p> Seuls Wonnacott et Pugh [171, 170, 176] se sont penches sur ces problemes dans le cas des formules de Presburger. Nous avions nous-m^emes presente nos analyses de regions dans plusieurs rapports et articles <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. Cependant, cette partie apporte de nouvelles contributions. Nous avons ainsi etudie le cadre theorique des analyses de regions de tableaux, independamment de leur type, et avons propose une solution aux problemes poses par les analyses approchees inferieurement. <p> Solving such problems requires a precise intra- and inter-procedural analysis of array data flow. Several algorithms for array privatization or array expansion 2 , based on different types of array data flow analyses, have already been proposed <ref> [70, 130, 123, 166, 93, 17, 63] </ref>, . The first approach [70, 130] performs an exact analysis of array data flow, but for a restricted source language 3 . Most of the other methods use conservative approximations of array element sets, such as MayBeDefined and MustBeDefined sets. <p> Most of the other methods use conservative approximations of array element sets, such as MayBeDefined and MustBeDefined sets. In fact, may sets are over-approximations of exact solutions, while must sets are under-approximations, according to a predefined approximation ordering. On the contrary, the last approach <ref> [17, 63] </ref> tries to compute exact solutions whenever possible, switching to conservative approximations only when exactness cannot be preserved anymore. However, except for specific applications [46, 47] requiring the knowledge of exactness, the advantages of our approach are still an open issue, which is discussed in this chapter. <p> However, this approach may fail to compute under-approximations equal to the corresponding exact solutions whereas the computation of the latter is decidable, which is possible as shown in <ref> [17, 63] </ref>. <p> However, this approach may fail to compute under-approximations equal to the corresponding exact solutions whereas the computation of the latter is decidable, which is possible as shown in [17, 63]. We thus propose another approach, based on our previous experience of exact array data flow analyses <ref> [63, 62, 65] </ref>: We suggest to perform under- and over-approximate analyses at the same time, and to enhance the results of must analyses with those of may analyses, when the latter can be proved exact according to a computable exactness criterion. <p> We show that traditional ad-hoc solutions based on iteration techniques do not give interesting results, even though problems can be lessened by more accurate representations and more complex approximations of fixed points. We thus propose a method based on our previous experience of array region analyses <ref> [63, 65] </ref>. The idea is to perform corresponding may and must analyses at the same time, and to enhance the results of must analyses with those of may analyses according to an exactness criterion. <p> We have therefore introduced in and out regions <ref> [17, 63, 65] </ref> to enable such transformations, but their description was rather informal. This chapter formally describes the flow and context sensitive analysis of read, write, in and out regions. Their exact semantics are defined, as well as their under-and over-approximations. <p> However, no attempt is done to actually represent the conditions under which the break is performed, as we do with continuation conditions (see Page 5.5). And lastly, Wonnacott proposes an interprocedural extension. 6.11 Conclusion We have already presented our array region analyses in several reports or papers <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. However, the present chapter is new in several respects. 122 CHAPTER 6. ARRAY REGION ANALYSES First, array regions are presented using denotational semantics or attributed grammars. <p> PIPS dependence tests compute both dependence levels and dependence cones. Dependence cones can be retrieved to implement advanced tiling and scheduling methods. Regions Array Regions <ref> [63, 65] </ref> are used in Pips to summarize accesses to array elements. read and write Regions represent the effects of statements and procedures on sets of array elements. They are used by the dependence test to disprove interprocedural dependences.
Reference: [64] <author> Beatrice Creusillet and Fran~cois Irigoin. </author> <title> Exact vs. approximate array region analyses. </title> <booktitle> In Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: En utilisant le critere d'exactitude precedant, on peut conclure que cette operation est exacte, et que la region est une sous-approximation valide. Le resultat serait encore exact avec des bornes non-numeriques, mais toujours affines. L'optimalite de cette approche est discutee dans la section 4.2.2 et dans <ref> [64] </ref>. Dans les autres paralleliseurs comme fiat/suif [92], polaris [164] ou panorama [135, 87], les analyses de regions de tableaux sous-estimees sont generalement basees sur un critere d'exactitude implicite qui consiste a eviter les operations inexactes. Ceci necessite bien s^ur une representation a priori infinie.
Reference: [65] <author> Beatrice Creusillet and Fran~cois Irigoin. </author> <title> Interprocedural array region analyses. </title> <journal> International Journal of Parallel Programming (special issue on LCPC), </journal> <volume> 24(6) </volume> <pages> 513-546, </pages> <year> 1996. </year> <note> Extended version of [63]. </note>
Reference-contexts: (Resume des chapitres 4, 5, et 6) Comme nous l'avions annonce dans l'introduction, cette partie est consacree a l'etude du cadre theorique des analyses de regions de tableaux, et a la semantique de quatre types de regions : read, write, in et out, qui ont ete introduites lors d'etudes anterieures <ref> [161, 162, 17, 65] </ref>. En effet, si de nombreuses etudes se sont interessees a de telles analyses, peu se sont penchees sur les problemes theoriques sous-jacents, et jamais d'une fa~con aussi complete et uniforme que nous le proposons ici. <p> Avec une sequence de cinq opera-teurs de retrecissement, on obtiendrait le resultat souhaite. Mais que se passerait-il avec une borne superieure de boucle egale a 10000, ou m^eme symbolique ? Pourtant, dans tous ces cas, les regions exactes sont calculables, et leur exacti tude est decidable <ref> [65] </ref>. Ce sera le point de depart de notre solution. * La deuxieme solution, appelee partitionnement dynamique [32], revient a determiner au vol le treillis adequat. Chaque region exacte est alors approchee in-ferieurement par une liste de sous-regions representables. <p> en temps et en memoire. 3.1.2 Approximation et exactitude Nous avons vu precedemment que, lorsque le domaine choisi n'est pas clos pour l'union ensembliste, les methodes existantes d'approximation des analyses de regions pouvaient donner des resultats decevants, alors m^eme que l'on sait pouvoir calculer la solution exacte sous certaines conditions <ref> [65] </ref>. <p> Seuls Wonnacott et Pugh [171, 170, 176] se sont penches sur ces problemes dans le cas des formules de Presburger. Nous avions nous-m^emes presente nos analyses de regions dans plusieurs rapports et articles <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. Cependant, cette partie apporte de nouvelles contributions. Nous avons ainsi etudie le cadre theorique des analyses de regions de tableaux, independamment de leur type, et avons propose une solution aux problemes poses par les analyses approchees inferieurement. <p> However, this approach may fail to compute under-approximations equal to the corresponding exact solutions whereas the computation of the latter is decidable, which is possible as shown in [17, 63]. We thus propose another approach, based on our previous experience of exact array data flow analyses <ref> [63, 62, 65] </ref>: We suggest to perform under- and over-approximate analyses at the same time, and to enhance the results of must analyses with those of may analyses, when the latter can be proved exact according to a computable exactness criterion. <p> upper bound is so great (do I = 1,10000) that the number of iterations would be overwhelming; or if it is unknown (do I = 1,N)? However, in all these cases, the exact set of array elements referenced within the previous loop nest is computable and known to be computable <ref> [65] </ref>. This is the basis for the solution we propose in the next section. 4.2 Approximations and Exactness The previous section has just shown that existing under-approximate analyses may fail to expose interesting results, when the chosen domain is not closed under set union. <p> This section describes a method to alleviate this problem, based on our previous experience of array region analyses <ref> [65] </ref>. It relies on the use of a computable exactness criterion which is introduced in a first subsection. <p> EXACT? 4.4 Conclusion Due to a considerable amount of efforts over the last ten years, over-approximate array regions analyses are now well-known techniques, even if debates about the choice of the representation are still alive: Time and space complexity versus accuracy is the main issue, but usefulness is widely acknowledged <ref> [163, 29, 101, 92, 65] </ref>. The need for under-approximations appeared only recently [165, 123, 92, 171], mainly for locality analysis or direct dependence analysis. Pugh and Wonnacott have provided extended studies [171, 170, 176] when the underlying semantic analysis framework is the domain of Presburger formulae. <p> We show that traditional ad-hoc solutions based on iteration techniques do not give interesting results, even though problems can be lessened by more accurate representations and more complex approximations of fixed points. We thus propose a method based on our previous experience of array region analyses <ref> [63, 65] </ref>. The idea is to perform corresponding may and must analyses at the same time, and to enhance the results of must analyses with those of may analyses according to an exactness criterion. <p> We have therefore introduced in and out regions <ref> [17, 63, 65] </ref> to enable such transformations, but their description was rather informal. This chapter formally describes the flow and context sensitive analysis of read, write, in and out regions. Their exact semantics are defined, as well as their under-and over-approximations. <p> Other works are much more difficult to compare, because the nature of the computed information is not the same: On one hand, direct dependences provide very precise information about the flow of array data, but on limited subset languages; on the other hand, 6.10. RELATED WORK 119 summarization methods <ref> [87, 93, 65] </ref> do not propagate information about the precise statement in which references are performed, but can be applied on real life programs. The remainder of this section examines in more details the works done in this area. <p> However, no attempt is done to actually represent the conditions under which the break is performed, as we do with continuation conditions (see Page 5.5). And lastly, Wonnacott proposes an interprocedural extension. 6.11 Conclusion We have already presented our array region analyses in several reports or papers <ref> [16, 18, 17, 63, 62, 60, 65] </ref>. However, the present chapter is new in several respects. 122 CHAPTER 6. ARRAY REGION ANALYSES First, array regions are presented using denotational semantics or attributed grammars. <p> In practice, we do not compute the under-approximation, but use a series of criteria the test whether the combination (union, intersection or difference) of an over-approximate region and an exact one can be exact. These criteria were given in <ref> [18, 65] </ref>. do j = 1, m 1 + A (i,j+1) + A (i,j+2) 3 + A (i-1,j) + A (i-2,j) enddo enddo 8.7 Related Work Who would not dream of an ideal representation? It would allow an exact representation of all access patterns found in real life applications, and so <p> The desired result was therefore inherently flow-insensitive. However, because of the need for more advanced program transformations such as array privatization, flow sensitive array region analyses are now commonplace in research parallelizers <ref> [154, 100, 101, 83, 93, 92, 135, 87, 65] </ref>. In particular, the computation of upward exposed used regions, which is performed in all the previously cited parallelizers, requires a backward propagation through the internal control flow graph of individual procedures. <p> Finally, our interprocedural propagation of array regions is supported by a powerful translation algorithm which is presented in the next chapter. Chapter 11 Interprocedural Translation Part of this chapter is reproduced from <ref> [65] </ref> with the kind permission of ijpp. This chapter focuses on the translation part of array region interprocedural analyses. Because the source and target arrays may not have the same declaration (array reshaping), this operation is not straightforward. <p> The algorithm trivially derives from the algorithm given above; but code generation is again the remaining issue. VI CONCLUSION 241 Chapitre 15 Contributions et Perspectives Les analyses de regions de tableaux ont suscite de nombreuses etudes lors de la derniere decennie. Leur utilite n'est plus a demontrer <ref> [163, 29, 101, 92, 65] </ref>, et les debats actuels concernent le choix de la representation des ensembles d'elements de tableaux, ainsi que le type et la quantite d'information symbolique a prendre en compte pour analyser de maniere suffisamment precise des applications reelles, sans pour autant degrader la complexite en temps et <p> C'est l'un de nos projets. 247 248 CHAPITRE 15. CONTRIBUTIONS ET PERSPECTIVES Chapter 16 Contributions and Perspectives Array region analyses have raised a considerable amount of effort over the last decade. Their usefulness is now widely acknowledged <ref> [163, 29, 101, 92, 65] </ref>, and current debates are concerned with the representation of array element sets, and the type and amount of symbolic information required to handle real life programs, time and space complexity versus accuracy being the main issue. <p> PIPS dependence tests compute both dependence levels and dependence cones. Dependence cones can be retrieved to implement advanced tiling and scheduling methods. Regions Array Regions <ref> [63, 65] </ref> are used in Pips to summarize accesses to array elements. read and write Regions represent the effects of statements and procedures on sets of array elements. They are used by the dependence test to disprove interprocedural dependences.
Reference: [66] <author> R. Cytron and J. Ferrante. </author> <title> What's in a name? or the value of renaming for parallelism detection and storage allocation. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages 19-27, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: Plusieurs algorithmes de privatisation de scalaires existent deja <ref> [66, 138] </ref>. Mais il serait trop complexe de les utiliser tels quels pour les tableaux, car cela necessiterait de pouvoir comparer ou combiner des regions de tableaux d'instructions differentes quelconques, tout en tenant compte des valeurs de variables entre les etats memoire les precedant. 214 CHAPTER 12. <p> When parallelizing scientific programs, the purpose is to eliminate spurious dependences between different iterations of a loop in order to parallelize it, as for scalar privatization <ref> [66, 138] </ref>. <p> Several algorithms for scalar privatization have already been designed <ref> [66, 138] </ref>.
Reference: [67] <author> Ron Cytron, Jeanne Ferrante, Barry Rosen, Mark Wegman, and Kenneth Zadeck. </author> <title> Efficiently computing static single assignement form and the control dependence graph. </title> <booktitle> In Symposium on Principles of Programming Languages, </booktitle> <pages> pages 25-35, </pages> <month> January </month> <year> 1989. </year> <note> 306 BIBLIOGRAPHIE BIBLIOGRAPHY </note>
Reference-contexts: INTERPROCEDURAL PROPAGATION OF REGIONS IN PIPS 183 To reduce this complexity, several sparse representations have been designed for particular classes of problems, such as the program summary graph [36], the ssa form <ref> [67, 158] </ref>, the sparse data flow evaluation graph [41], the system dependence graph [75, 26], : : : The unified interprocedural graph [96] provides a demand-driven unified representation which combines the advantages of the sparse rep resentations without restricting the scope of the possible analyses. * Another issue is the ability
Reference: [68] <author> Alain Dumay. </author> <title> Traitement des indexations non lineaires en parallelisation au-tomatique : une methode de linearisation contextuelle. </title> <type> PhD thesis, </type> <institution> Universite Paris VI, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: On the contrary, our method avoids linearization whenever possible by detecting similar dimensions, and partially linearizing the remaining dimensions if possible and necessary. This approach eliminates the linearization versus subscript-by-subscript problem as formulated by Burke and Cytron. Dumay <ref> [68] </ref> Dumay proposes a method (named contextual linearization) to solve systems of non linear constraints. It basically replaces non-linear terms by single dummy variables, which are further constrained by the context provided by other constraints of the system. <p> While this may sometimes allow to disprove dependences, this may also lead to non-linear subscripts, which often prevent subsequent dependence tests. Several studies have been dedicated to solving such problems in the general case <ref> [68, 97, 30, 89, 176] </ref>. By using regions, some dependences may be disproved, whereas other techniques based on linear algebra may fail. Consider for instance the program of Figure 13.3. After induction variable substitution, array subscripts are non-linear, and an advanced dependence test is required.
Reference: [69] <author> R. Eigenmann, J. Hoeflinger, Z. Li, and D. Padua. </author> <title> Experience in the automatic parallelization of four perfect-benchmark programs. </title> <booktitle> In Languages and Compilers for Parallel Computing, number 589 in Lecture Notes in Computer Science, </booktitle> <pages> pages 65-83. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1991. </year>
Reference-contexts: More details on these studies can be found in Chapters 8 and 11. In most parallelizing compilers (petit [176], paraphrase-2 [142], fiat/suif [92], panorama [135], : : : ), induction variables are recognized and substituted <ref> [4, 3, 174, 180, 69] </ref>, and dependence tests do not have to deal with variables modified in loop bodies. While this may sometimes allow to disprove dependences, this may also lead to non-linear subscripts, which often prevent subsequent dependence tests.
Reference: [70] <author> Paul Feautrier. </author> <title> Array expansion. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <pages> pages 429-441, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: Detecter ces regions de tableaux privatisables requiert une analyse precise du flot des elements de tableaux. Plusieurs algorithmes de privatisation ou d'expansion 1 on deja ete proposees <ref> [70, 130, 123, 166, 93, 17, 63] </ref>. Ils reposent sur differents types d'analyse du flot des elements de tableaux. La premiere approche [70, 130] effectue une analyse exacte, mais a partir 1 Une technique similaire pour les machines a moire partagee. 21 22 CHAPTER 3. <p> Detecter ces regions de tableaux privatisables requiert une analyse precise du flot des elements de tableaux. Plusieurs algorithmes de privatisation ou d'expansion 1 on deja ete proposees [70, 130, 123, 166, 93, 17, 63]. Ils reposent sur differents types d'analyse du flot des elements de tableaux. La premiere approche <ref> [70, 130] </ref> effectue une analyse exacte, mais a partir 1 Une technique similaire pour les machines a moire partagee. 21 22 CHAPTER 3. S EMANTIQUE DES R EGIONS DE TABLEAUX d'un langage source restreint, dit langage monoprocedural a controle statique. <p> La meilleure solution est alors donnee par le plus petit point fixe de la fonctionnelle correspondante. Toutefois, ces solutions ne sont generalement pas calculables en un temps fini, et ne sont pas toutes representables en machine. Deux approches permettent d'eviter ces problemes : restreindre le langage source (comme dans <ref> [70, 72, 159, 130] </ref>) ; ou effectuer des analyses approchees sur des programmes reels. Pour les analyses de regions, les solutions exactes appartiennent au treillis (-(Z n ); ?; Z n ; [; "). <p> Solving such problems requires a precise intra- and inter-procedural analysis of array data flow. Several algorithms for array privatization or array expansion 2 , based on different types of array data flow analyses, have already been proposed <ref> [70, 130, 123, 166, 93, 17, 63] </ref>, . The first approach [70, 130] performs an exact analysis of array data flow, but for a restricted source language 3 . Most of the other methods use conservative approximations of array element sets, such as MayBeDefined and MustBeDefined sets. <p> Solving such problems requires a precise intra- and inter-procedural analysis of array data flow. Several algorithms for array privatization or array expansion 2 , based on different types of array data flow analyses, have already been proposed [70, 130, 123, 166, 93, 17, 63], . The first approach <ref> [70, 130] </ref> performs an exact analysis of array data flow, but for a restricted source language 3 . Most of the other methods use conservative approximations of array element sets, such as MayBeDefined and MustBeDefined sets. <p> Facing these obstacles, the solution is either to restrict the input language (as in <ref> [70, 72, 159, 130] </ref>), or to perform conservative approximate analyses [55] on real-life programs. This last characteristics has played a great role in the popularity of the method [2, 111, 55, 134, 153, 161, 37, 86]. Here, the complexity of the computation directly depends on the accuracy of the analysis. <p> The first studies were due to Brandes [34] and Feautrier <ref> [70] </ref>. This approach also encountered a frank success for the quality of information it can provide. However, early implementations only dealt with very limited subset languages. Recent extensions lessen this drawback, some times at the expense of accuracy. <p> Direct or value-based dependence computations are based on the same principle. In addition, the order in which instructions are executed must be taken into account, which is achieved through different methods <ref> [34, 70, 147] </ref>. The differences between this approach and the former one (extensions of standard data flow analyses), are not easy to isolate. <p> The resulting dependences constitute a data flow graph, which can be used for optimizations such as array renaming or expansion (see Chapter 14). No details are given about the way the context of array references is handled. Feautrier <ref> [70, 72] </ref> Feautrier proposes to compute for each use of a scalar or array element its source function, which gives its corresponding definitions as a function of its iteration vector. <p> This enables powerful program optimizations such as array expansion with initialization and finalization (or copy-in and copy-out, see Chapter 14), or more recently the detection of scans and reductions [150]. However, the initial studies <ref> [70, 72] </ref> put overwhelming restrictions on the input language, which has to be a monoprocedural static control program: The only control structures of the language are the sequence, and fortran-like do loops, whose limits are linear expressions in the surrounding loop variables and in the program structure parameters (symbolic constants); array <p> The last approach for enhancing the locality of references is then to privatize or expand array regions, that is to say to replicate data onto several processors when they are used as temporaries. Many work has already been done is this direction <ref> [123, 165, 166, 164, 92, 70, 130, 17] </ref>, 238 CHAPTER 14. ARRAY PRIVATIZATION and the differences with our approach are described below. Notice also that run-time techniques have been recently introduced to privatize arrays in cases which cannot be discovered using static analyses [148, 149]. <p> Instead, when the last iteration of the loop is the last defining iteration for the privatized section, the last iteration of the loop is set apart, and sequentially executed after the loop nest with the privatized array. This alleviates costly analyses, but is less general than our approach. Feautrier <ref> [70] </ref> For shared memory machines, Feautrier proposes to perform another transformation called array expansion which extends arrays to higher dimensions to transform the program into single assignment form. The purpose is the same as array privatization, that is to say to remove spurious dependences. <p> Finally, this approach is restricted to static control programs, that is to say mono-procedural programs with linear loop bounds, test conditions and array subscripts. 14.6. CONCLUSION 239 Maydan et al. [130] Maydan proposes a whole array privatization algorithm based on an efficient implementation of Feautrier's array data flow analysis <ref> [70, 72] </ref>. The input language is very restricted (monoprocedural static control programs), and whole arrays are privatized instead of array sections. This last constraint is lessened by the fact that copy-in and copy-out are handled. This method has two drawbacks.
Reference: [71] <author> Paul Feautrier. </author> <title> Parametric integer programming. </title> <journal> RAIRO Recherche Opera-tionnelle, </journal> <pages> pages 243-268, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: There already exists several libraries to deal with Presburger formulae <ref> [71, 112, 121] </ref>, the most popular ones being the omega and pip libraries. But the results are exact only as long as we deal with linear static control programs. <p> There exists a handful of algorithms to perform this test. The first family computes the coordinates of the elements that are solutions of the inequality system of the polyhedron. Exact methods such as the Gomory's cutting plane method [81] and pip <ref> [71] </ref> belong to them, as well as the simplex method which gives solutions in Q n , and is thus an inexact test. The second family only checks the existence of a solution.
Reference: [72] <author> Paul Feautrier. </author> <title> Dataflow analysis of array and scalar references. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20(1) </volume> <pages> 23-53, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Ces analyses donnent des resultats precis, voire exacts <ref> [72] </ref>. Mal-heureusement les langage d'entree du paralleliseur est generalement tres restreint malgre de recents progres. Et ces analyses sont tres co^uteuses. * Analyse basee sur les regions de tableaux. <p> Two approaches are presently used in research prototypes: * The analysis of direct dependences, or source functions, value dependences, : : : These various terms denote the dependences which cannot be transitively built from other dependences on the same memory cell. These analyses give precise, or even exact results <ref> [72] </ref>. Unfortunately, the source language is generally very restricted despite recent extensions; and these analyses are quite expensive. * Analyses based on array regions. Array region analyses consist in collecting information about the way array elements are used and defined by the program. <p> La meilleure solution est alors donnee par le plus petit point fixe de la fonctionnelle correspondante. Toutefois, ces solutions ne sont generalement pas calculables en un temps fini, et ne sont pas toutes representables en machine. Deux approches permettent d'eviter ces problemes : restreindre le langage source (comme dans <ref> [70, 72, 159, 130] </ref>) ; ou effectuer des analyses approchees sur des programmes reels. Pour les analyses de regions, les solutions exactes appartiennent au treillis (-(Z n ); ?; Z n ; [; "). <p> Facing these obstacles, the solution is either to restrict the input language (as in <ref> [70, 72, 159, 130] </ref>), or to perform conservative approximate analyses [55] on real-life programs. This last characteristics has played a great role in the popularity of the method [2, 111, 55, 134, 153, 161, 37, 86]. Here, the complexity of the computation directly depends on the accuracy of the analysis. <p> The resulting dependences constitute a data flow graph, which can be used for optimizations such as array renaming or expansion (see Chapter 14). No details are given about the way the context of array references is handled. Feautrier <ref> [70, 72] </ref> Feautrier proposes to compute for each use of a scalar or array element its source function, which gives its corresponding definitions as a function of its iteration vector. <p> This enables powerful program optimizations such as array expansion with initialization and finalization (or copy-in and copy-out, see Chapter 14), or more recently the detection of scans and reductions [150]. However, the initial studies <ref> [70, 72] </ref> put overwhelming restrictions on the input language, which has to be a monoprocedural static control program: The only control structures of the language are the sequence, and fortran-like do loops, whose limits are linear expressions in the surrounding loop variables and in the program structure parameters (symbolic constants); array <p> Interprocedural extensions have been formulated by Leservot: This is described below. Leservot [121] Leservot has extended Feautrier's array data flow analysis <ref> [72] </ref> to handle generalized instructions that is to say complex instructions involving definitions and uses of array regions, and such that all uses take place before any definition. <p> We think it may be because their formulae do not separately handle the subscript values of individual array elements and the offset between the first elements of the source and target arrays. 204 CHAPTER 11. INTERPROCEDURAL TRANSLATION Leservot [121] Leservot has extended Feautrier's array data flow analysis <ref> [72] </ref> to handle procedure calls. However, the constraint of the static control program still holds. <p> in et out ont ete introduites pour modeliser le flot des valeurs, la tentation est grande de les utiliser pour construire un graphe de dependance base sur les conflits de valeurs ; et ceci m^eme si les regions in et out fournissent une information moins precise que les fonctions sources <ref> [34, 72, 147] </ref>. La question est donc : que peut-on esperer de l'utilisation des regions in et out pour l'analyse des dependances ? Les regions in d'une instruction representent les elements de tableau qu'elle im-porte, tandis que ces regions out contiennent les elements qu'elle exporte. <p> Les differences portent essentiellement sur le type de representation choisi pour les ensembles d'elements de tableaux, et les tests de dependance utilises, de maniere a obtenir un compromis entre precision et complexite. Une autre tendance actuelle est d'utiliser les dependances directes <ref> [34, 72, 147] </ref> pour generer du code, au lieu des dependances sur la memoire, de maniere a detecter le parallelisme cache par la reutilisation des variables. Ces analyses sont tres precises, mais assez co^uteuses, et imposent souvent des restrictions sur le langage source. <p> Since in and out regions have been introduced to model the flow of values, the temptation is high to use them to build value based dependence graphs. However, in and out regions carry less information than source functions <ref> [34, 72, 147] </ref> for instance, because they do not keep trace of the precise references responsible for the accesses they collectively represent. <p> All the previously cited works deal with memory based dependences. However, these techniques fail to discover parallelism hidden by variable reuse. Several approaches have therefore been designed to study value based dependences <ref> [34, 72, 130, 147] </ref>. They chiefly differ on the algorithms used to compute the dependences, which has an effect on complexity, and the restrictions on the source language (see Sections 6.10 and 14.5). in and out regions were not designed to achieve the same accuracy as these methods. <p> Finally, this approach is restricted to static control programs, that is to say mono-procedural programs with linear loop bounds, test conditions and array subscripts. 14.6. CONCLUSION 239 Maydan et al. [130] Maydan proposes a whole array privatization algorithm based on an efficient implementation of Feautrier's array data flow analysis <ref> [70, 72] </ref>. The input language is very restricted (monoprocedural static control programs), and whole arrays are privatized instead of array sections. This last constraint is lessened by the fact that copy-in and copy-out are handled. This method has two drawbacks.
Reference: [73] <author> Paul Feautrier and Jean-Fran~cois Collard. </author> <title> Fuzzy array dataflow analysis. </title> <type> Research Report 94-21, </type> <institution> ENS-Lyon, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: Some of the intra-procedural restrictions have since been partially removed, sometimes at the expense of accuracy: Maslov [127] extends this method to handle, to some extent, if constructs and general variables. Collard [49, 50] proposes an extension for do while constructs. Collard et al. <ref> [51, 73, 24] </ref> remove some linearity limitations, but at the expense of accuracy. collard and Griebl [52] finally extend the framework to explicitly (con trol) parallel programs containing doall and doacross loops. Interprocedural extensions have been formulated by Leservot: This is described below.
Reference: [74] <author> F. Fernandez and P. </author> <title> Quinton. Extension of Chernikova's algorithm for solving general mixed linear programming problems. </title> <note> Publication Interne 437, IRISA, </note> <year> 1988. </year>
Reference-contexts: -1 ; : : : ; -ff 2 [0; 1] i=1 i= 1 9 1 ; : : : ; ffi 2 Z ff X i v i + i=1 ffi X i l i Ces deux representations sont equivalentes, et des algorithmes permettent de passer de l'une a l'autre <ref> [90, 74] </ref>. Certaines operations comme l'intersection sont plus faciles a realiser sur les systemes d'inegalites, d'autres, comme l'enveloppe convexe, sur les systemes generateurs. <p> = x : fi fi fi fi 9 -1 ; : : : ; -ff 2 [0; 1] i=1 i= 1 9 1 ; : : : ; ffi 2 Z ff X i v i + i=1 ffi X i l i These two representations are equivalent, and algorithms <ref> [90, 74] </ref> have been designed for the conversion between them. This is not a mere mathematical toy: Some operations on convex polyhedra, such as intersection, perform easier on systems of inequalities, while others are less painful on generating systems.
Reference: [75] <author> J. Ferrante, K. Ottenstein, and J. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <year> 1987. </year>
Reference-contexts: INTERPROCEDURAL PROPAGATION OF REGIONS IN PIPS 183 To reduce this complexity, several sparse representations have been designed for particular classes of problems, such as the program summary graph [36], the ssa form [67, 158], the sparse data flow evaluation graph [41], the system dependence graph <ref> [75, 26] </ref>, : : : The unified interprocedural graph [96] provides a demand-driven unified representation which combines the advantages of the sparse rep resentations without restricting the scope of the possible analyses. * Another issue is the ability to avoid taking into account unrealizable paths [119].
Reference: [76] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification. </title> <institution> Rice University, Houston, Texas, </institution> <month> November </month> <year> 1994. </year> <note> Version 1.1. </note>
Reference-contexts: Le probleme pour l'utilisateur final est alors de tirer parti de ces architectures de maniere efficace, simple, et portable, etant donne la vitesse d'obsolescence de ces machines. Il a alors le choix entre deux approches : * Programmer dans un langage explicitement parallele comme occam, cm fortran [160], hpf <ref> [76] </ref>, fortran d [78], vienna fortran [181], : : : L'avantage est que cela permet au programmeur d'implanter des algorithmes intrinseque-ment paralleles, et d'avoir un meilleur controle du parallelisme. <p> Two approaches are available to implement an application: * The first is to program in an explicitly parallel language such as occam, cm fortran [160], hpf <ref> [76] </ref>, fortran d [78], vienna fortran [181], : : : This allows a good control on parallelism, and is the best way to implement intrinsically parallel programs. However, such programs are difficult to build: Synchronization must be added by hand, as well as data placements, and inter-processor communications.
Reference: [77] <institution> J.B.J. Fourier. Analyse des travaux de l'Academie Royale des Sciences pendant l'annee 1823, partie mathematiques. In Histoire de l'Academie Royale des Sciences de l'Institut de France, </institution> <type> volume 7. 1827. </type>
Reference-contexts: The second family only checks the existence of a solution. The Omega test [144] is an exact test in Z n , unlike the Fourier-Motzkin elimination method <ref> [77] </ref> which successively eliminates the variables of the system. In pips, we only use the Fourier-Motzkin and simplex algorithms. All these algorithms have an exponential complexity. However, they perform relatively well on usual cases [9]. <p> Likewise, the computation of the regions of a loop involves the elimination of the loop 8.1. POLYHEDRA: DEFINITIONS AND BASIC OPERATORS 141 index, as described in the next chapter. This is done by projecting the polyhedron representing the region along the variables to eliminate. The Fourier-Motzkin algorithm <ref> [77] </ref> performs this elimination. In fact, it computes the convex hull of the projections of all the single integer points that belong to the initial polyhedron. The result is a convex polyhedron that may contain elements that are not the projection of an integer point.
Reference: [78] <author> Geoffrey C. Fox, Seema Hiranandani, Ken Kennedy, Charles Koelbel, Ulrich Kremer, Chau-Wen Tseng, and M. Wu. </author> <title> The Fortran D Language Specification. </title> <type> TR 90079, CRPC, </type> <month> December </month> <year> 1990. </year>
Reference-contexts: Il a alors le choix entre deux approches : * Programmer dans un langage explicitement parallele comme occam, cm fortran [160], hpf [76], fortran d <ref> [78] </ref>, vienna fortran [181], : : : L'avantage est que cela permet au programmeur d'implanter des algorithmes intrinseque-ment paralleles, et d'avoir un meilleur controle du parallelisme. <p> Two approaches are available to implement an application: * The first is to program in an explicitly parallel language such as occam, cm fortran [160], hpf [76], fortran d <ref> [78] </ref>, vienna fortran [181], : : : This allows a good control on parallelism, and is the best way to implement intrinsically parallel programs. However, such programs are difficult to build: Synchronization must be added by hand, as well as data placements, and inter-processor communications.
Reference: [79] <author> Kyle Gallivan, William Jalby, and Dennis Gannon. </author> <title> On the problem of optimizing data transfers for complex memory systems. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <pages> pages 238-253, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: La section 3.2 presentera ensuite notre langage d'etude et les analyses preliminaires necessaires a la definition de la semantique des regions, qui sera presentee dans la section 3.3. 3.1 Regions Exactes ou Approximations ? Plusieurs etudes <ref> [29, 79] </ref> ont montre la necessite de recourir a des optimisations de programme puissantes pour pouvoir gerer la memoire de maniere efficace lors de la compilation pour des machines a memoire distribuee ou a hierarchie de memoires. <p> Dans la partie suivante, nous presenterons l'implantation effectuee dans pips ; et dans la partie IV, nous montrerons comment effectuer ces analyses en presence d'appels de procedures. 40 CHAPTER 3. S EMANTIQUE DES R EGIONS DE TABLEAUX Chapter 4 May, Must or Exact? Several studies <ref> [79, 29] </ref> have highlighted the need for advanced program optimizations to deal with memory management issues. For instance, Blume and Eigenmann [29] have shown that array privatization could greatly enhance the amount of potential parallelism in sequential programs. <p> Since using in and out regions is equivalent to declare arrays or array sections as local variables, a specific analysis has been preferred in pips. This is the object of the next chapter. Chapter 14 Array Privatization Recent studies <ref> [79, 29] </ref> have highlighted the need for advanced program optimizations to deal with memory management issues when compiling programs for massively parallel machines or hierarchical memory systems. For instance, Blume and Eigenmann [29] have shown that array privatization could greatly enhance the amount of potential parallelism in sequential programs.
Reference: [80] <author> D. Gannon, W. Jalby, and K. Gallivan. </author> <title> Strategies for cache and local memory management by global program transformations. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5(5) </volume> <pages> 587-616, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: The first approach is based on loop transformations (loop reversal, fusion and interchange in [155], compound loop transformation with loop interchange, reversal, skewing, and tiling in [172], loop permutation in [114] and loop interchange and blocking in <ref> [80, 31] </ref>), basically to concentrate near array references in innermost loops, so that processors access compact sets of data (array contraction [155]).
Reference: [81] <author> R.E. Gomory. </author> <title> Solving linear programming problems in integer. </title> <booktitle> In Combinatorial Analysis (proceedings of Symposia in Applied Mathematics), </booktitle> <pages> pages 211-215, </pages> <year> 1960. </year>
Reference-contexts: There exists a handful of algorithms to perform this test. The first family computes the coordinates of the elements that are solutions of the inequality system of the polyhedron. Exact methods such as the Gomory's cutting plane method <ref> [81] </ref> and pip [71] belong to them, as well as the simplex method which gives solutions in Q n , and is thus an inexact test. The second family only checks the existence of a solution.
Reference: [82] <author> S. Graham and M. Wegman. </author> <title> Fast and usually linear algorithm for global flow analysis. </title> <journal> Journal of the ACM, </journal> <volume> 23(1) </volume> <pages> 172-202, </pages> <month> January </month> <year> 1976. </year>
Reference-contexts: This might be rather cumbersome in case of recursive definitions (which are usually needed to handle loops), since the existence of a fixed point is not guaranteed anymore. When the functions meet the weaker condition of monotonicity, Graham and Wegman <ref> [82] </ref> define an acceptable solution. <p> In a commercial compiler where compilation time is a choice criterion, all the previous analyses, except out regions, should be performed simultaneously, to avoid multiple traversals of the program representation. 6.10 Related Work Traditionally, data flow analysis techniques were first devoted to scalar variables <ref> [117, 82, 113, 1, 153] </ref>; accesses to array elements were treated as accesses to the whole array. This was however insufficient to efficiently parallelize many scientific programs dealing with structured data. The first improvement was the introduction of array data dependence analysis [21].
References-found: 82

