URL: ftp://ftp.cs.brown.edu/pub/techreports/92/cs92-25.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-92-25.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [1] <editor> F. et al. Bancilhon. </editor> <title> Magic Sets and Other Strange Ways to Implement Logic Programs. </title> <booktitle> In Proceedings of Fifth ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 1-15, </pages> <address> Cambridge, Massachusetts, </address> <year> 1986. </year>
Reference-contexts: Bottom-up and top-down approaches are both used and have been related by means of rewriting techniques (e.g. magic sets <ref> [1, 27] </ref>). Our algorithm should be related to OLDT-resolution [26]. However, our algorithm is inefficient in this context because elements of A and A 0 denote sets of values (facts) instead of "individual" values. As a consequence, each iteration redoes all computations performed by the previous ones.
Reference: [2] <author> A. Bansam and L. Sterling. </author> <title> An abstract interpretation scheme for logic programs based on type expression. </title> <booktitle> In Proc. Int. Conf. on Fifth Generation Computer Systems, </booktitle> <pages> pages 422-429, </pages> <address> Tokyo, </address> <year> 1988. </year> <month> 15 </month>
Reference-contexts: We stress its usefulness in such a context both from a practical and a methodological point of view. Operational Frameworks The operational approach to abstract interpretation reduces to the idea of executing the program on a non standard (abstract) domain. This leads either to specific algorithms (e.g. <ref> [8, 2, 10] </ref>) or to the so-called operational frameworks [4, 6]. Those approaches are difficult to prove correct, to implement, and to modify, since they mix semantic and algorithmic aspects. A more systematic approach consists in separating both issues.
Reference: [3] <author> G. Berry. </author> <title> Bottom-up Computation of Recursive Programs. </title> <booktitle> In RAIRO-rouge 10(3), </booktitle> <pages> pages 47-82. </pages> <month> March </month> <year> 1976. </year>
Reference-contexts: The previous discussion can also be related to the minimal function graph semantics discussed in the paper and to bottom-up computation of recursive functions (see <ref> [3] </ref>). 12 8.2 Chaotic Iteration Algorithms Chaotic iteration was introduced by P.
Reference: [4] <author> M. Bruynooghe. </author> <title> A Practical Framework for the Abstract Interpretation of Logic Programs. </title> <journal> Journal of Logic Programming, </journal> <volume> 10 </volume> <pages> 91-124, </pages> <year> 1991. </year>
Reference-contexts: Operational Frameworks The operational approach to abstract interpretation reduces to the idea of executing the program on a non standard (abstract) domain. This leads either to specific algorithms (e.g. [8, 2, 10]) or to the so-called operational frameworks <ref> [4, 6] </ref>. Those approaches are difficult to prove correct, to implement, and to modify, since they mix semantic and algorithmic aspects. A more systematic approach consists in separating both issues. <p> Similarly, dynamic granularity is a priori more accurate and costly than static granularity. Usefulness of granularity to compare abstract interpretation frameworks can be illustrated by the works of C. Mellish [20], U. Nilsson [23] and M. Bruynooghe <ref> [4] </ref>, which proposed frameworks for the abstract interpretation of (pure) Prolog. The earlier work is due to Mellish. It has static granularity and only two program points are considered for each procedure: procedure entry and procedure exit.
Reference: [5] <author> F. Bry. </author> <title> Query Evaluation in Recursive Databases. </title> <booktitle> In Proc. First Int. Conf. on Deductive and Object-Oriented Databases, </booktitle> <pages> pages 20-39, </pages> <address> Kyoto, Japan, </address> <year> 1989. </year>
Reference-contexts: However, chaotic iteration seems difficult to generalize to the class of problems considered in this paper. 8.3 Deductive Data Bases Fixpoint computation algorithms have been extensively studied to solve efficiently queries in deductive data bases (e.g. <ref> [5, 27, 28] </ref>). Bottom-up and top-down approaches are both used and have been related by means of rewriting techniques (e.g. magic sets [1, 27]). Our algorithm should be related to OLDT-resolution [26].
Reference: [6] <author> P. Codognet and G. </author> <title> File. Computations, Abstractions and Constraints in Logic Programs. </title> <booktitle> In Proceedings of the fourth International Conference on Programming languages (ICCL'92), </booktitle> <address> Oakland, U.S.A., </address> <month> April </month> <year> 1992. </year>
Reference-contexts: Operational Frameworks The operational approach to abstract interpretation reduces to the idea of executing the program on a non standard (abstract) domain. This leads either to specific algorithms (e.g. [8, 2, 10]) or to the so-called operational frameworks <ref> [4, 6] </ref>. Those approaches are difficult to prove correct, to implement, and to modify, since they mix semantic and algorithmic aspects. A more systematic approach consists in separating both issues.
Reference: [7] <author> P Cousot and R. Cousot. </author> <title> Abstract Interpretation: A unified Lattice Model for Static Analysis of Programs by Construction or Approximation of Fixpoints. </title> <booktitle> In Conf. Record of Fourth ACM Symposium on POPL, </booktitle> <pages> pages 238-252, </pages> <address> Los Angeles, CA, </address> <year> 1977. </year>
Reference-contexts: Its partial correctness and termination are proven and require some additional weak (but rather technical) assumptions. These assumptions are mostly specific monotonicity conditions and they can be relaxed further when the application only requires a postfixpoint. In particular, widening techniques <ref> [7] </ref> allow termination even on infinite domains and the monotonicity conditions imposed for partial correctness can be dropped at the cost of a stronger assumption for termination. As a consequence, the algorithm generalizes and abstracts numerous existing algorithms, removes many restrictions, and provides a versatile alternative to bottom-up algorithms. <p> We now show how to broaden the applicability of the algorithm for these problems. In particular, A can now be infinite and some of the monotonicity conditions can be relaxed. 6.1 Infinite Domains Definition 3 <ref> [7] </ref> Let A be a poset. <p> The previous discussion can also be related to the minimal function graph semantics discussed in the paper and to bottom-up computation of recursive functions (see [3]). 12 8.2 Chaotic Iteration Algorithms Chaotic iteration was introduced by P. Cousot in <ref> [7] </ref> as a very general class of methods for finding the least solution of a set of equations of the form x i = expr i (1 i n): A chaotic iteration strategy for such a set of equations defines a finite sequence i 1 ; . . . ; i <p> We will investigate this idea in future research. 8.4 Abstract Interpretation Abstract interpretation is a general methodology for building static analyses of programs. It was introduced by P. and R. Cousot in <ref> [7] </ref>. The original idea was subsequently adapted, reformulated, and applied to many programming paradigms. (Approximate) computation of fixpoints is a main issue in abstract interpretation. In the following we relate our algorithm to several aspects and approaches in this field.
Reference: [8] <author> S. Debray. </author> <title> Efficient Dataflow Analysis of Logic Programs. </title> <booktitle> In Proc. of 15th Annual Symposium on POPL, </booktitle> <pages> pages 260-273, </pages> <address> San Diego, CA, </address> <year> 1988. </year>
Reference-contexts: We stress its usefulness in such a context both from a practical and a methodological point of view. Operational Frameworks The operational approach to abstract interpretation reduces to the idea of executing the program on a non standard (abstract) domain. This leads either to specific algorithms (e.g. <ref> [8, 2, 10] </ref>) or to the so-called operational frameworks [4, 6]. Those approaches are difficult to prove correct, to implement, and to modify, since they mix semantic and algorithmic aspects. A more systematic approach consists in separating both issues.
Reference: [9] <author> V. Englebert, B. Le Charlier, D. Roland, and P. Van Hentenryck. </author> <title> Generic Abstract Interpretation Algorithms for Prolog: Two Optimization Techniques and Their Experimental Evaluation. </title> <booktitle> In Fourth International Symposium on Programming Language Implementation and Logic Programming (PLILP-92), </booktitle> <address> Leuven (Belgium), </address> <month> August </month> <year> 1992. </year>
Reference-contexts: As a consequence, the algorithm generalizes and abstracts numerous existing algorithms, removes many restrictions, and provides a versatile alternative to bottom-up algorithms. The algorithm has proven useful to derive several abstract interpretation algorithms for Prolog, based on various semantics <ref> [14, 15, 16, 9] </ref>. These algorithms (to our knowledge, the fastest available) are practical both in terms of efficiency and accuracy. The rest of the paper is organized as follows. Section 2 presents some mathematical preliminaries. Section 3 presents the universal top-down fixpoint algorithm.
Reference: [10] <author> M. Hermenegildo, R. Warren, and S. Debray. </author> <title> Global Flow Analysis as a Practical Compilation Tool. </title> <journal> Journal of Logic Programming, </journal> <note> 1991. (To appear). </note>
Reference-contexts: We stress its usefulness in such a context both from a practical and a methodological point of view. Operational Frameworks The operational approach to abstract interpretation reduces to the idea of executing the program on a non standard (abstract) domain. This leads either to specific algorithms (e.g. <ref> [8, 2, 10] </ref>) or to the so-called operational frameworks [4, 6]. Those approaches are difficult to prove correct, to implement, and to modify, since they mix semantic and algorithmic aspects. A more systematic approach consists in separating both issues.
Reference: [11] <author> G Janssens. </author> <title> Deriving Run Time Properties Of Logic Programs By Means of Abstract Interpretation. </title> <type> PhD thesis, </type> <institution> Katholieke Universiteit Leuven, Department Computerwetenschappen, Leuven (Belgium), </institution> <year> 1990. </year>
Reference-contexts: Alternatively, widening techniques are also useful to speed up the algorithm when convergence is slow. 6.2 Non Monotone Transformations In abstract interpretation, it is sometimes difficult, if not almost impossible, to prove monotonicity of transformation t . (See <ref> [11, 21] </ref>.) Fortunately, monotonicity can be dropped since the first part of the partial correctness proof does not use the hypotheses on t; and r.
Reference: [12] <author> N.D. Jones and A. Mycroft. </author> <title> Dataflow Analysis of Applicative Programs using Minimal Function Graphs. </title> <booktitle> In Proceedings of 13th ACM symposium on Principles of Programming Languages, </booktitle> <pages> pages 123-142, </pages> <address> St. Petersburg, Florida, </address> <year> 1986. </year>
Reference-contexts: Minimal Function Graph and Query Directed Semantics To overcome the applicability problem of O'Keefe's algorithm (and more generally of any bottom-up evaluation), many authors design "instrumental" semantics introducing supplementary results needed only by the algorithm for fixpoint computation. They are called minimal function graph semantics in <ref> [12, 29] </ref> and query directed semantics in [18]. The basic idea is that each iteration provides the set of input values for the next iteration in addition to the output values corresponding to the previous inputs.
Reference: [13] <author> N.D. Jones and H. Sondergaard. </author> <title> A Semantics-Based Framework for the Abstract Interpretation of Prolog, </title> <booktitle> volume Abstract Interpretation of Declarative Languages, </booktitle> <pages> pages 123-142. </pages> <publisher> Ellis Horwood, </publisher> <year> 1987. </year>
Reference-contexts: Most optimizations can be handled at the algorithmic level and the semantics can be changed without requiring any substantial modification of the algorithm. 13 Denotational Frameworks The denotational approach to abstract interpretation was first in-troduced by F. Nielson [22]. It was then further developed by many authors including <ref> [13, 19, 29] </ref>. In this approach, the elegant notations of denotational semantics and the mathematical framework of the Cousot's are put together to provide high level descriptions of static analyses. Authors relying on this approach are mostly concerned with semantic issues.
Reference: [14] <author> B. Le Charlier, K. Musumbu, and P. Van Hentenryck. </author> <title> A Generic Abstract Interpretation Algorithm and its Complexity Analysis (Extended Abstract). </title> <booktitle> In Eighth International Conference on Logic Programming (ICLP-91), </booktitle> <address> Paris (France), </address> <month> June </month> <year> 1991. </year>
Reference-contexts: As a consequence, the algorithm generalizes and abstracts numerous existing algorithms, removes many restrictions, and provides a versatile alternative to bottom-up algorithms. The algorithm has proven useful to derive several abstract interpretation algorithms for Prolog, based on various semantics <ref> [14, 15, 16, 9] </ref>. These algorithms (to our knowledge, the fastest available) are practical both in terms of efficiency and accuracy. The rest of the paper is organized as follows. Section 2 presents some mathematical preliminaries. Section 3 presents the universal top-down fixpoint algorithm. <p> The main idea is to avoid restarting simulations of procedure tau that would not produce any information. Dependencies enable to improve the worst case complexity of the algorithm for many instantiations (see <ref> [14] </ref>). <p> The generic algorithm described in <ref> [15, 14, 21] </ref> is an instantiation of the universal algorithm where the transformation t is a simple input/output abstract semantics based on SLD-resolution, the standard operational semantics for Prolog (see [17]). <p> The algorithm of is essentially O'Keefe's one and it is easy to exhibit programs where it gives more precise results than Mellish's algorithm. Bruynooghe's framework uses the same program points as Nilsson but with dynamic granularity. We have presented in <ref> [14] </ref> a generic abstract interpretation algorithm for Prolog wich can be seen as a precise implementation of Bruynooghe's framework. Alternatively it can be seen as an instantiation of the universal algorithm of this paper to a simple input/output semantics for Prolog.
Reference: [15] <author> B. Le Charlier and P. Van Hentenryck. </author> <title> Experimental Evaluation of a Generic Abstract Interpretation Algorithm for Prolog. </title> <booktitle> In Fourth IEEE International Conference on Computer Languages (ICCL'92), </booktitle> <address> San Fransisco, CA, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: It has the property of focusing on the subset of elements necessary to compute the value of ff and explores few, if any, other elements in the practical applications we have considered <ref> [15] </ref>. Its partial correctness and termination are proven and require some additional weak (but rather technical) assumptions. These assumptions are mostly specific monotonicity conditions and they can be relaxed further when the application only requires a postfixpoint. <p> As a consequence, the algorithm generalizes and abstracts numerous existing algorithms, removes many restrictions, and provides a versatile alternative to bottom-up algorithms. The algorithm has proven useful to derive several abstract interpretation algorithms for Prolog, based on various semantics <ref> [14, 15, 16, 9] </ref>. These algorithms (to our knowledge, the fastest available) are practical both in terms of efficiency and accuracy. The rest of the paper is organized as follows. Section 2 presents some mathematical preliminaries. Section 3 presents the universal top-down fixpoint algorithm. <p> The generic algorithm described in <ref> [15, 14, 21] </ref> is an instantiation of the universal algorithm where the transformation t is a simple input/output abstract semantics based on SLD-resolution, the standard operational semantics for Prolog (see [17]).
Reference: [16] <author> B. Le Charlier and P. Van Hentenryck. </author> <title> Reexecution in Abstract Interpretation of Prolog. </title> <type> Technical Report CS-92-12, </type> <institution> CS Department, Brown University, </institution> <year> 1992. </year> <pages> (44 pages). 16 </pages>
Reference-contexts: As a consequence, the algorithm generalizes and abstracts numerous existing algorithms, removes many restrictions, and provides a versatile alternative to bottom-up algorithms. The algorithm has proven useful to derive several abstract interpretation algorithms for Prolog, based on various semantics <ref> [14, 15, 16, 9] </ref>. These algorithms (to our knowledge, the fastest available) are practical both in terms of efficiency and accuracy. The rest of the paper is organized as follows. Section 2 presents some mathematical preliminaries. Section 3 presents the universal top-down fixpoint algorithm. <p> In addition, the algorithm explores at most 15% of unnecessary elements and none for most programs. The reexecution algorithm described in <ref> [16] </ref> is also an instantiation of the universal algorithm for a much more complex semantics exploiting referential transparency to improve accuracy of the analysis. <p> Although the semantics was much more complex, the derivation algorithm and its correctness proof were substantially simplified because of the availability of the universal algorithm. 7.2 Optimizations In <ref> [16] </ref>, we have described two general optimizations for fixpoint algorithms. Both of them produced about 30% improvement on the first instantiation. The second optimization was also integrated in the second instantiations and its effect should be even more important (although no explicit comparison was made).
Reference: [17] <author> J. W. Lloyd. </author> <title> Foundations of Logic Programming. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: The generic algorithm described in [15, 14, 21] is an instantiation of the universal algorithm where the transformation t is a simple input/output abstract semantics based on SLD-resolution, the standard operational semantics for Prolog (see <ref> [17] </ref>). In this instantiation, t is specific to a given program and the cpos A and A 0 are the same. The worst case complexity (i.e. the number of iterations in the repeat loop of procedure repeat computation) was analyzed for several interesting program classes and behavioral assumptions.
Reference: [18] <author> K. Marriott and H. Sondergaard. </author> <title> Semantics-based Dataflow Analysis of Logic Programs. </title> <booktitle> In Information Processing-89, </booktitle> <pages> pages 601-606, </pages> <address> San Fransisco, CA, </address> <year> 1989. </year>
Reference-contexts: They are called minimal function graph semantics in [12, 29] and query directed semantics in <ref> [18] </ref>. The basic idea is that each iteration provides the set of input values for the next iteration in addition to the output values corresponding to the previous inputs. Such an instrumental semantics is no longer needed with our approach (see the comparison with O'Keefe's algorithm).
Reference: [19] <author> K. Marriott and H. Sondergaard. </author> <title> Abstract Interpretation of Logic Programs: the Denotational Approach, </title> <month> June </month> <year> 1990. </year> <note> To appear in ACM Transaction on Programming Languages. </note>
Reference-contexts: Most optimizations can be handled at the algorithmic level and the semantics can be changed without requiring any substantial modification of the algorithm. 13 Denotational Frameworks The denotational approach to abstract interpretation was first in-troduced by F. Nielson [22]. It was then further developed by many authors including <ref> [13, 19, 29] </ref>. In this approach, the elegant notations of denotational semantics and the mathematical framework of the Cousot's are put together to provide high level descriptions of static analyses. Authors relying on this approach are mostly concerned with semantic issues.
Reference: [20] <author> C. Mellish. </author> <title> Abstract Interpretation of Prolog Programs, </title> <booktitle> volume Abstract Interpretation of Declarative Languages, </booktitle> <pages> pages 181-198. </pages> <publisher> Ellis Horwood, </publisher> <year> 1987. </year>
Reference-contexts: Similarly, dynamic granularity is a priori more accurate and costly than static granularity. Usefulness of granularity to compare abstract interpretation frameworks can be illustrated by the works of C. Mellish <ref> [20] </ref>, U. Nilsson [23] and M. Bruynooghe [4], which proposed frameworks for the abstract interpretation of (pure) Prolog. The earlier work is due to Mellish. It has static granularity and only two program points are considered for each procedure: procedure entry and procedure exit.
Reference: [21] <author> K. Musumbu. </author> <title> Interpretation Abstraite de Programmes Prolog. </title> <type> PhD thesis, </type> <institution> University of Namur (Belgium), </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: Alternatively, widening techniques are also useful to speed up the algorithm when convergence is slow. 6.2 Non Monotone Transformations In abstract interpretation, it is sometimes difficult, if not almost impossible, to prove monotonicity of transformation t . (See <ref> [11, 21] </ref>.) Fortunately, monotonicity can be dropped since the first part of the partial correctness proof does not use the hypotheses on t; and r. <p> The generic algorithm described in <ref> [15, 14, 21] </ref> is an instantiation of the universal algorithm where the transformation t is a simple input/output abstract semantics based on SLD-resolution, the standard operational semantics for Prolog (see [17]).
Reference: [22] <author> F. Nielson. </author> <title> A Denotational Framework for Data Flow Analysis. </title> <journal> Acta Informatica, </journal> <volume> 18 </volume> <pages> 265-287, </pages> <year> 1982. </year>
Reference-contexts: The advantages of the approach are twofold. Most optimizations can be handled at the algorithmic level and the semantics can be changed without requiring any substantial modification of the algorithm. 13 Denotational Frameworks The denotational approach to abstract interpretation was first in-troduced by F. Nielson <ref> [22] </ref>. It was then further developed by many authors including [13, 19, 29]. In this approach, the elegant notations of denotational semantics and the mathematical framework of the Cousot's are put together to provide high level descriptions of static analyses.
Reference: [23] <author> U. Nilsson. </author> <title> Systematic Semantic Approximations of Logic Programs. </title> <booktitle> In Proceedings of PLILP 90, </booktitle> <pages> pages 293-306, </pages> <address> Linkoeping, Sweeden, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: Similarly, dynamic granularity is a priori more accurate and costly than static granularity. Usefulness of granularity to compare abstract interpretation frameworks can be illustrated by the works of C. Mellish [20], U. Nilsson <ref> [23] </ref> and M. Bruynooghe [4], which proposed frameworks for the abstract interpretation of (pure) Prolog. The earlier work is due to Mellish. It has static granularity and only two program points are considered for each procedure: procedure entry and procedure exit.
Reference: [24] <author> R.A. O'Keefe. </author> <title> Finite Fixed-Point Problems. </title> <editor> In J-L. Lassez, editor, </editor> <booktitle> Fourth International Conference on Logic Programming, </booktitle> <pages> pages 729-743, </pages> <address> Melbourne, Australia, </address> <year> 1987. </year>
Reference-contexts: This leads to a top-down approach in contrast to the more usual approach inspired by the Kleene's sequence. We now compare our algorithm with a representative bottom-up algorithm proposed by O'Keefe <ref> [24] </ref>. <p> The abstract semantics can be expressed as system of 2n equations with 2n variables where n is the number of procedures. Since this system is small, the naive bottom-up method based on the Kleene's sequence can be used as done in Mellish's algorithm. O' Keefe's paper <ref> [24] </ref> was motivated by Mellish's work and provides a faster method. The framework of Nilsson has static but finer granularity: all program points are considered (clause entry and exit, and any point between two calls).
Reference: [25] <author> J. Stoy. </author> <title> Denotational Semantics: The Scott-Stratchey Approach to Programming Language Theory . MIT Press, </title> <address> Cambridge Mass., </address> <year> 1977. </year>
Reference-contexts: Pascal). Pro 1 cedure tau computes the transformation t (i.e. tau (f,ff)) returns t f ff, calls f finitely often, and terminates when the functional parameter computes a (total) monotone function. The second requirement can be formalized, using denotational semantics <ref> [25] </ref>, by requiring that procedure tau computes a continuous transformation t + : (A 6 ! A 0 ) ! (A 6 ! A 0 ), i.e. 8f 2 (A 7! A 0 ) : t + f = t f .
Reference: [26] <author> H Tamaki and T. Sato. </author> <title> OLD-resolution with Tabulation. </title> <booktitle> In Third International Conference on Logic Programming, </booktitle> <pages> pages 84-98, </pages> <address> London, </address> <month> July </month> <year> 1986. </year>
Reference-contexts: Bottom-up and top-down approaches are both used and have been related by means of rewriting techniques (e.g. magic sets [1, 27]). Our algorithm should be related to OLDT-resolution <ref> [26] </ref>. However, our algorithm is inefficient in this context because elements of A and A 0 denote sets of values (facts) instead of "individual" values. As a consequence, each iteration redoes all computations performed by the previous ones.
Reference: [27] <author> J.D. Ullman. </author> <title> Bottom-up Beats Top-Down for Datalog. </title> <booktitle> In Proc. ACM SIGACT-SIGMOD-SIGART Symp. on Principles of Database Systems, </booktitle> <pages> pages 140-149, </pages> <year> 1989. </year>
Reference-contexts: However, chaotic iteration seems difficult to generalize to the class of problems considered in this paper. 8.3 Deductive Data Bases Fixpoint computation algorithms have been extensively studied to solve efficiently queries in deductive data bases (e.g. <ref> [5, 27, 28] </ref>). Bottom-up and top-down approaches are both used and have been related by means of rewriting techniques (e.g. magic sets [1, 27]). Our algorithm should be related to OLDT-resolution [26]. <p> Bottom-up and top-down approaches are both used and have been related by means of rewriting techniques (e.g. magic sets <ref> [1, 27] </ref>). Our algorithm should be related to OLDT-resolution [26]. However, our algorithm is inefficient in this context because elements of A and A 0 denote sets of values (facts) instead of "individual" values. As a consequence, each iteration redoes all computations performed by the previous ones.
Reference: [28] <author> L. Vieille. </author> <title> Recursive Axioms in Deductive Databases : the Query/Subquery Approach. </title> <booktitle> In Proceedings of the First International Conference on Expert Databases Systems, </booktitle> <pages> pages 179-193, </pages> <address> Charleston, South Carolina, </address> <month> April </month> <year> 1986. </year>
Reference-contexts: However, chaotic iteration seems difficult to generalize to the class of problems considered in this paper. 8.3 Deductive Data Bases Fixpoint computation algorithms have been extensively studied to solve efficiently queries in deductive data bases (e.g. <ref> [5, 27, 28] </ref>). Bottom-up and top-down approaches are both used and have been related by means of rewriting techniques (e.g. magic sets [1, 27]). Our algorithm should be related to OLDT-resolution [26].

References-found: 28

