URL: http://www.cs.dartmouth.edu/~brd/f/s/info-book.ps.gz
Refering-URL: http://www.cs.dartmouth.edu/~brd/www/
Root-URL: http://www.cs.dartmouth.edu
Title: On Information Invariants in Robotics  
Author: Bruce Randall Donald 
Note: c fl1992, 1995  
Date: January 23, 1995  
Address: Ithaca, New York  
Affiliation: Computer Science Department Cornell University  
Abstract-found: 0
Intro-found: 1
Reference: [BK] <author> Blum, M. and D. </author> <title> Kozen On the power of the compass (or, why mazes are easier to search than graphs), </title> <booktitle> Proc. 19 th Symp. Found. Computer Science, </booktitle> <address> Ann Arbor, MI, </address> <pages> pp. </pages> <month> 132-42 </month> <year> (1978). </year>
Reference-contexts: Our work takes as its inspiration the information invariants that Erdmann 2 introduced to the robotics community in 1989 [Erd89], although rigorous examples of information invariants can be found in the theoretical literature from as far back as 1978 (see, for example, <ref> [BK, Koz] </ref>). Part I of this book develops the basic concepts and tools behind information invariants in plain language. Therein, we develop a number of motivating examples. In part II, we provide a fairly detailed analysis. In particular, we admit more sophisticated models of sensors and computation. <p> In part I of this book, we describe two working robots Tommy and Lily, which may be viewed as online robots. We discuss their capabilities, and how they are programmed. We also consider formal models of online robots, foregrounding the situated automata of <ref> [BK] </ref>. The examples in part I link our work to the recent but intense interest in online paradigms for situated autonomous agents. In particular, we discuss what kind of data structures robots can build to represent the environment. <p> Here we note that Xavier, in [Xa, DX3] developed "trade-offs" similar in flavor to Equation (1). Both Erdmann and Xavier obtain "tradeoffs" between information and execution speed. Their methods appear to require a performance measure (eg, the "cost" of a control strategy). One might view our work (and also <ref> [BK] </ref>, below) as investigating information invariants in the absence of a performance measure. In this case, we cannot directly measure absolute information complexity in bit-seconds. Instead, we develop a way to relativize (or reduce) one sensori-computational system to another, in order to quantify their (relative) power. <p> This section (2.2) is devoted to a discussion of their paper, On The Power of the Compass <ref> [BK] </ref>, and we interpret their results in the context of autonomous mobile robots and information invariants. The reader is urged to consult the clear and readable paper [BK] for more details. <p> This section (2.2) is devoted to a discussion of their paper, On The Power of the Compass <ref> [BK] </ref>, and we interpret their results in the context of autonomous mobile robots and information invariants. The reader is urged to consult the clear and readable paper [BK] for more details. In 1990, we posed the following question with Jim Jennings: Question 2.2 [DJ2] "Let us consider a rational reconstruction of mobile robot programming. <p> The proof that a two-counter DFA can simulate a Turing machine was first given by Papert and McNaughton in 1961 [Min] but shorter proofs are now given in many textbooks, for example, see [HU; Thm. 7.9]. 12 See <ref> [BK] </ref> for references. 27 2. There is a two-pebble automaton that can search all mazes. 3. There is a one-counter automaton that can search all mazes. These results are crisp information invariants. <p> Hence side-effecting the environment is equivalent to collaborating with an autonomous co-agent. The equivalence of (1) and (2) to (3) suggests an equivalence (in this case) and a tradeoff (in general) between communication, state, and side-effecting the environment. Hence we may credit <ref> [BK] </ref> with a excellent example of information invariance. 2.2.1 The Power of Randomization Erdmann's PhD thesis is an investigation of the power of randomization in robotic strategies [Erd89]. <p> The idea is similar to that of randomized algorithms|by permitting the robot to randomly perturb initial conditions (the environment), its own internal state, or to randomly choose among actions, one may enhance the performance and capabilities of robots, and derive 13 Here is the idea. First, <ref> [BK] </ref> show how to write a program whereby an unenhanced DFA can traverse the boundary of any single connected component of obstacle squares. Now, suppose the DFA could "remember" the southwesternmost corner (in a lexicographic order) of the obstacle. Next, [BK] show how all the free space can then be systematicically <p> First, <ref> [BK] </ref> show how to write a program whereby an unenhanced DFA can traverse the boundary of any single connected component of obstacle squares. Now, suppose the DFA could "remember" the southwesternmost corner (in a lexicographic order) of the obstacle. Next, [BK] show how all the free space can then be systematicically searched. It suffices for a DFA with a single counter to record the y-coordinate y min of this corner. We now imagine simulating this algorithm (as efficiently as possible) using a Turing machine, and we measure the bit-complexity. <p> We now imagine simulating this algorithm (as efficiently as possible) using a Turing machine, and we measure the bit-complexity. If there are n free squares in the environment then y min n, and the algorithm consumes O (log n) bits of storage. For details, see <ref> [BK] </ref>. 28 probabilistic bounds on expected performance. 14 This lesson should not be lost in the context of the information invariants above. For example, as Erd-mann points out, one finite automaton can search any maze if we permit it to randomly select among the unobstructed directions. <p> How much more "powerful" has Lily become? What tasks can Lily now perform that Tommy cannot? Now, any robot engineer knows compasses are useful. But what we want in answer to question 2.3 is a precise, provable answer. Happily, in the case where the compass is relatively accurate, 15 <ref> [BK] </ref> provide some insight: 14 While the power of randomization has long been known in the context of algorithms for maze exploration, Erdmann was able to lift these results to the robotics domain. <p> The primary difference is that an automaton in a maze has a compass: it can distinguish N,S,E,W. A compass can provide the automaton with valuable information, as shown by the second of our results" <ref> [BK] </ref>. Recall point (1) in Section 2.2. Blum and Kozen show, that in contrast, to (1), no two automata together can search all finite planar cubic graphs (in a cubic graph, all vertices have degree g = 3). They then prove no three automata suffice. <p> See [DJR] for a full discussion. 104 12 Conclusions In this book we suggested a theory of information invariance that includes sensors and computation. Our results generalize the work of <ref> [BK] </ref>; first, we consider fairly detailed yet abstract models of physical autonomous mobile robots; second, we consider generalizations and variations on compasses and orientation sensors; third, we develop a generalized and stratified theory of the "power" of such sensori-computational devices.
Reference: [BKR] <author> Ben-Or M., Kozen D., and Reif J., </author> <title> "The Complexity of Elementary Algebra and Geometry", </title> <journal> J. Comp. and Sys. Sciences, </journal> <volume> Vol. 32, </volume> <year> (1986), </year> <pages> pp. 251-264. </pages>
Reference: [BS] <author> Blum, M. and W. </author> <title> Sakoda On the capability of finite automata in 2 and 3 dimesnional space, </title> <booktitle> Proc. 17 th Symp. Found. Computer Science, </booktitle> <pages> pp. </pages> <month> 147-61 </month> <year> (1977). </year>
Reference-contexts: Later, Kozen showed that four automata do not suffice [Koz]. Moreover, if we relax the planarity assumption but restrict our cubic graphs to be 3D mazes, it is known that no finite set of finite automata can search all such finite 3D mazes <ref> [BS] </ref>. Hence, [BK,Koz] provide a lower bound to the question, "What information does a compass provide?" We close by mentioning that in the flavor of Section 2.2.1, there is a large literature on randomized search algorithms for graphs.
Reference: [Bri] <author> Briggs, Amy. </author> <title> An Efficient Algorithm for One-Step Compliant Motion Planning with Uncertainty, </title> <journal> Algorithmica, </journal> <volume> 8, (2), </volume> <year> 1992. </year> <pages> pp. 195-208. </pages>
Reference-contexts: Also, we note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, [Reif, HSS, Nat, CR]; see, eg, <ref> [Don2, Can, Bri] </ref> for upper bounds). Rosenschein has de 13 veloped a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates.
Reference: [Can] <institution> John Canny On computability of fine motion plans, IEEE ICRA, </institution> <address> Scottsdale, AZ, </address> <year> (1989) </year>
Reference-contexts: Also, we note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, [Reif, HSS, Nat, CR]; see, eg, <ref> [Don2, Can, Bri] </ref> for upper bounds). Rosenschein has de 13 veloped a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates.
Reference: [Cha] <author> Chapman, D. </author> <title> Planning for Conjunctive Goals, </title> <journal> Artificial Intelligence, </journal> <volume> 32 (3), </volume> <pages> pp. </pages> <month> 333-378 (July) </month> <year> (1987). </year>
Reference-contexts: We now have two concepts to define and investigate. First, we show how to specify systems which contain some constant configuration variables. After that, we must find a way to make two free variables codesignate (see <ref> [Cha] </ref>). Two vertices r and u codesignate under an immersion when (r) = (u). More generally, r and u codesignate under different immersions and when (v) = (u). We now proceed with these two tasks. Recall our example of a pointed sensor system S G 0 from Section 8.2 above. <p> Hence, we don't care where R is, save that we wish to colocate r and u. To do this, we make r and u codesignate under the immersions of S and U . We call this a codesignation constraint after <ref> [Cha] </ref>. Here is how we may say this more precisely: Let S G 0 denote sensor system S immersed with vertex v at G 0 (as above). Immerse the rest of S in any consistent manner, and denote this immersion by .
Reference: [CDRX] <author> Canny, J., B. Donald, J. Reif, and P. </author> <title> Xavier On The Complexity of Kinodynamic Planning, </title> <booktitle> 29 th Symposium on the Foundations of Computer Science, </booktitle> <address> White Plains, </address> <pages> NY pp. 306-316. </pages> <year> (1988). </year>
Reference-contexts: Moreover, the methods we describe below typically yield results using "order" notation (big-oh O () or big-theta fi ()) instead of strict equality. One example of provable information invariants is given in the kinody-namic literature <ref> [CDRX, DX1, DX2] </ref>. This work is concerned with provable 24 planning algorithms for robots with dynamics. We give some details in ap-pendix F.1. Here we note that Xavier, in [Xa, DX3] developed "trade-offs" similar in flavor to Equation (1). Both Erdmann and Xavier obtain "tradeoffs" between information and execution speed.
Reference: [CR] <author> Canny, J., and J. Reif, </author> <title> "New Lower Bound Techniques for Robot Motion Planning Problems", </title> <booktitle> FOCS (1987). </booktitle> <pages> 110 </pages>
Reference-contexts: In our quest for a measure of the intrinsic information requirements of a task, we are inspired by Erdmann's monograph on sensor design [Erd91]. Also, we note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, <ref> [Reif, HSS, Nat, CR] </ref>; see, eg, [Don2, Can, Bri] for upper bounds). Rosenschein has de 13 veloped a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates.
Reference: [CLS] <author> Cox, D., Little, J., O'Shea, D. </author> <title> Ideals, Varieties, and Algorithms, Springer-Verlag: Undergraduate Texts in Mathematics: </title> <address> New York (1991). </address>
Reference: [Don1] <author> Donald, B. R. </author> <title> Robot Motion Planning, </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> (8), No. 2. </volume> <year> (1992). </year>
Reference-contexts: In part II, we provide a fairly detailed analysis. In particular, we admit more sophisticated models of sensors and computation. This analysis will call for some machinery whose complexity is best deferred until that time. A central theme to previous work (see the survey article <ref> [Don1] </ref> for a detailed review) has been to determine what information is required to solve a task, and to direct a robot's actions to acquire that information to solve it. Key questions concern: 1. What information is needed by a particular robot to accomplish a par ticular task? 2. <p> He also gives source-to-source transformations on sensori-computational "circuits." In addition to the work discussed here in Section , for a detailed bibliographic essay on previous research on the geometric theory of planning under uncertainty, see, eg., <ref> [Don1] </ref> or [Don3]. The goals outlined here are ambitious and we have only taken a small step towards them. The questions above provide the setting for our inquiry, but we are far from answering them.
Reference: [Don2] <author> Donald, B. R. </author> <title> The Complexity of Planar Compliant Motion Planning with Uncertainty, </title> <journal> Algorithmica, </journal> <volume> 5 (3), </volume> <pages> pp. </pages> <month> 353-382 </month> <year> (1990). </year>
Reference-contexts: Also, we note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, [Reif, HSS, Nat, CR]; see, eg, <ref> [Don2, Can, Bri] </ref> for upper bounds). Rosenschein has de 13 veloped a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates.
Reference: [Don3] <author> Donald, B. R. </author> <title> Error Detection and Recovery in Robotics, </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> Vol. 336, </volume> <publisher> Springer-Verlag, </publisher> <address> New York (1989). </address>
Reference-contexts: He also gives source-to-source transformations on sensori-computational "circuits." In addition to the work discussed here in Section , for a detailed bibliographic essay on previous research on the geometric theory of planning under uncertainty, see, eg., [Don1] or <ref> [Don3] </ref>. The goals outlined here are ambitious and we have only taken a small step towards them. The questions above provide the setting for our inquiry, but we are far from answering them. <p> It is much more restrictive than the tape of a Turing machine. I believe that quantifying communication between collaborating mobile robots is a fundamental information-theoretic question. In manipulation, the ability to structure the environment through the actions of the robot (see, eg, <ref> [Don3] </ref>) or the mechanics of the task (see, eg,. [Mas]) seems a fundamental paradigm. How do these techniques compare in power? We call automata with these extra features enhanced, and we will assume that automata are not enhanced unless noted. Given these assumptions, Blum and Kozen demonstrate the following results.
Reference: [DJ] <author> Donald, B. R. and J. </author> <title> Jennings Constructive Recognizability for Task-Directed Robot Programming, </title> <journal> Jour. Robotics and Autonomous Systems, </journal> <volume> (9), No. 1, </volume> <pages> Elsevier/North-Holland pp. 41-74. </pages> <year> (1992). </year>
Reference-contexts: His theory is set in a logical framework where sensors are logical predicates. Perhaps our theory could be viewed as a geometric attack on a similar problem. This work was inspired by the theoretical attack on perceptual equivalence begun by <ref> [DJ] </ref> and by the experimental studies of [JR]. Horswill [Hors] has developed a semantics for sensory systems that models and quantifies the kinds of assumptions a sensori-computational program makes about its environment. <p> The IR information does not measurably slow down the robot, since the IR processing is distributed and is not done by the Scheme controller. 7 In the language of <ref> [DJ] </ref>, the sonar sensors, plus the IR communication, represent concrete sensors, out of which the virtual sensors shown in fig. 2 can be constructed. The construction essentially involves adding the IR information above to the servo loop for following using sonar given in [RD]. <p> Such a system is called a virtual sensor by <ref> [DJ] </ref>. In a virtual sensor, outputs are computed from the outputs of other sensors in the same device. Given two sensor systems E and H, we would like to be able to quantify the information the sensors provide. <p> L will be the "lighthouse" (beacon) and R will be the "ship." The robots live in the plane. In introducing the lighthouse system, we will informally introduce machinery to describe sensori-computational resources. 17 In the language of <ref> [DJ] </ref>, the perceptual equivalence classes for this sensor are the rays emanating at x. 18 Erdmann emphasizes the special cases where the robot always knows its heading, or, where the robot's heading is always fixed (say, due North, so that h is always identically zero). <p> Clearly the "angle" of the robot|the angle between North and the ray from L to R|can computed as = 2t=t w . (Assuming the ship is moving slowly, relative to t w ). Virtual Sensors. We can implement this as a virtual sensor <ref> [DJ] </ref> called (orientation) shown immediately below. The orientation sensor is specified as a computation that (i) calls concrete sensors, (ii) retains some local state (T0), and (iii) does some computation (*, /, etc). It is easy to measure the time and space requirements of the "circuit" that computes . <p> From this, and claim 6.11 (b), we conclude that E 1 H. t u 7 Information Invariants The relation 1 defines a hierarchy of sensors. Compare the perceptual lattice of <ref> [DJ] </ref>, who propose a geometric program for the analysis and synthesis of sensors based on their perceptual equivalence classes. The relation 1 orders sensor systems on the complexity of their information invariants. 25 At this point it would be useful to review the particular information invariants in our example. <p> Here is a general idea of how we will proceed: Recall the transformation described in Section 5.4.1 and Definition 6.10, where we added output communication to a sensor system. Recalling that 25 It is possible to develop a geometric account of information invariance by pursuing the direction of <ref> [DJ] </ref>. For more on this connection, see appendix C.3. The account we give in section 5.4.1 is also geometric but with a different flavor. Appendix C.3 deals with the geometry of lattices, where an element of the lattice represents (essentially) a knowledge state. <p> There we model the colocation of resources as geometric codesignation constraints. This coloca-tion can be modeled as a quotient map, and in section 8.8 we discuss its relationship to information invariance. 26 In the language of <ref> [DJ] </ref>, communication and permutation permit us to map between the perceptual equivalence classes (PEC's) of E (the rays described in Section 4.1) and the PEC's of H. 8 On The Semantics of Situated Sensor Systems In this section, we formalize our model of sensor systems. <p> By the results of Section 8.10.4, these reductions can be effectively computed. Therefore, in principle, the transformations in [DJR] could be synthesized automatically. We believe that our methods are useful for developing parallel manipulation protocols. We 53 We use the term in the sense of <ref> [DJ] </ref>; others, particularly Henderson have used similar concepts. See Section 4.2.1 for examples of virtual and concrete sensors. 103 specified angular amount.
Reference: [DJ2] <author> Donald, B. R. and J. </author> <title> Jennings Constructive Recognizability for Task-Directed Robot Programming, </title> <booktitle> Proc. IEEE International Conference on Robotics and Automation, </booktitle> <address> Nice, France (1992). </address>
Reference-contexts: The reader is urged to consult the clear and readable paper [BK] for more details. In 1990, we posed the following question with Jim Jennings: Question 2.2 <ref> [DJ2] </ref> "Let us consider a rational reconstruction of mobile robot programming. There is a task we wish the mobile robot to perform, and the task is specified in terms of external (e.g., human-specified) perceptual categories. For example, these terms might be "concepts" like wall, door, hallway, or Professor Hopcroft.
Reference: [DJ3] <author> Donald, B. R. and J. </author> <title> Jennings Sensor Interpretation and Task-Directed Planning Using Perceptual Equivalence Classes, </title> <booktitle> Proc. IEEE International Conference on Robotics and Automation, </booktitle> <address> Sacramento, CA (1991). </address>
Reference: [DJR] <author> Donald, B. R., J. Jennings, and D. </author> <title> Rus Towards a Theory of Information Invariants for Cooperating Autonomous Mobile Robots,, </title> <booktitle> International Symposium on Robotics Research (ISRR). </booktitle> <address> Hidden Valley, PA (October 2). </address> <year> (1993). </year>
Reference-contexts: See <ref> [DJR, Jen94] </ref> for more discussion of actuators. 59 Now, we give Definition 8.16 A situated (or immersed) sensor system S is a sensor system S = (V; E), together with an immersion : V ! C of the vertices. <p> push the block B in a straight line. (do-forever (let ((t (measure-torque))) (cond ((zero? t) (push ^y)) ((negative? t) (move +^x)) ((positive? t) (move ^x))))) gripper). 11 Application and Experiments [This section will be expanded and revised.] We now describe an application of the theory in this book, presented in <ref> [DJR] </ref>. This work is still preliminary, but we describe it here to give some feeling for the potential of our theory. The paper [DJR] relies heavily on the results and methods introduced here. [DJR] quantify a new resource: (f ) How much information is encoded or provided by the task mechanics? <p> (move ^x))))) gripper). 11 Application and Experiments [This section will be expanded and revised.] We now describe an application of the theory in this book, presented in <ref> [DJR] </ref>. This work is still preliminary, but we describe it here to give some feeling for the potential of our theory. The paper [DJR] relies heavily on the results and methods introduced here. [DJR] quantify a new resource: (f ) How much information is encoded or provided by the task mechanics? The theme of exploiting task mechanics is important in previous work. 50 One could define "exploiting task mechanics" for robot manipulation as: taking <p> be expanded and revised.] We now describe an application of the theory in this book, presented in <ref> [DJR] </ref>. This work is still preliminary, but we describe it here to give some feeling for the potential of our theory. The paper [DJR] relies heavily on the results and methods introduced here. [DJR] quantify a new resource: (f ) How much information is encoded or provided by the task mechanics? The theme of exploiting task mechanics is important in previous work. 50 One could define "exploiting task mechanics" for robot manipulation as: taking advantage of the mechanical and physical laws that govern how <p> Currently, in our framework the mechanics are embedded in the geometry of the system. In <ref> [DJR] </ref>, we developed information invariants that explicitly trade-off (f) with resources (a)-(e) from the abstract, in the style of the preceding. Developing such invariants is quite challenging. We close with an example. This example opens up a host of new issues; see [DJR] for details. <p> In <ref> [DJR] </ref>, we developed information invariants that explicitly trade-off (f) with resources (a)-(e) from the abstract, in the style of the preceding. Developing such invariants is quite challenging. We close with an example. This example opens up a host of new issues; see [DJR] for details. Fig. 11a depicts a two-finger planar pushing task. The goal is to push the box B in a straight line (pure translation). The two fingers f 1 and f 2 are rigidly connected; for example, they could be the fingers of a parallel-jaw gripper. <p> Second, if the COF moves outside C, then the fingers can move sideways to capture it again. For example, <ref> [DJR] </ref> implemented following control loop on our Puma: Sense the reaction torque t about the point 0 in fig. 11a. If t = 0, push forward in direction ^y. If t &lt; 0 move the fingers in ^x; else move the fingers in ^x. See fig. 12. <p> applied force by observing the applied power, the position and velocity of the robot, and the contact sensors. 99 Pushing Reorientation Task Task global coordination P1 R1 and control local IR communication, P2 R2 partial synchrony, MPMD uniform (SPMD), P3 R3 asynchronous, no explicit communication of parallel manipulation protocols from <ref> [DJR] </ref>. Now, we ask, how can the system in fig. 11b approximate the pushing strategy (fig. 12), above? We observe the following. Each robot can compute its applied force and contact mode, and communicate these data to the other. <p> In <ref> [DJR] </ref>, we analyze information invariants for manipulation tasks using the formalism presented here. For example, it is clear the surface normal computation requires some internal state, and the compliant align can be viewed as consuming external state or as temporary calibration. <p> Communication appears fundamental to performing the task in fig. 11b. So we ask: what communication is necessary between the robots to accomplish the (2-robot) pushing task? How many messages and what information is required? In <ref> [DJR] </ref> we use the methods introduced here to compare and contrast pushing protocols, and to answer these questions. First, we precisely describe two manipulation tasks for cooperating mobile robots that can push large, heavy objects. One task is shown in fig. 11b, the other in fig. 14. <p> One task is shown in fig. 11b, the other in fig. 14. More specifically, we ask: Can all explicit local and global communication between 100 the agents be removed from a family of pushing protocols for these tasks? 51 <ref> [DJR] </ref> answer in the affirmative|a surprising result|by using the general methods introduced here for analyzing information invariants. 11.1 [DJR] Use Circuits and Reductions to Analyze Information Invariants In [DJR], we develop and analyze synchronous and asynchronous manipulation protocols for a small team of cooperating mobile robots than can push large boxes. <p> More specifically, we ask: Can all explicit local and global communication between 100 the agents be removed from a family of pushing protocols for these tasks? 51 <ref> [DJR] </ref> answer in the affirmative|a surprising result|by using the general methods introduced here for analyzing information invariants. 11.1 [DJR] Use Circuits and Reductions to Analyze Information Invariants In [DJR], we develop and analyze synchronous and asynchronous manipulation protocols for a small team of cooperating mobile robots than can push large boxes. <p> all explicit local and global communication between 100 the agents be removed from a family of pushing protocols for these tasks? 51 <ref> [DJR] </ref> answer in the affirmative|a surprising result|by using the general methods introduced here for analyzing information invariants. 11.1 [DJR] Use Circuits and Reductions to Analyze Information Invariants In [DJR], we develop and analyze synchronous and asynchronous manipulation protocols for a small team of cooperating mobile robots than can push large boxes. <p> Because it is both difficult and important to analyze the information content of this implicit communication and synchronization, we believe that using our theory of information invariants is justified. The manipulation protocols in <ref> [DJR] </ref> are first modeled as circuits, using the formalism developed in Section 5.4.1. Source-to-source transformations on these protocols are then represented as circuit transformations. The circuit transformations are modeled using the reductions described in this book. For the task in fig. 11b, [DJR] consider three pushing protocols P1, P2, and P3, <p> The manipulation protocols in <ref> [DJR] </ref> are first modeled as circuits, using the formalism developed in Section 5.4.1. Source-to-source transformations on these protocols are then represented as circuit transformations. The circuit transformations are modeled using the reductions described in this book. For the task in fig. 11b, [DJR] consider three pushing protocols P1, P2, and P3, and their interreducibility under 1 . In particular, we transform an MPMD pushing protocol P2 with explicit IR communication to an asynchronous SPMD protocol P3 with no explicit communication. <p> Our approach of quantifying the information complexity in the task mechanics involves viewing the world dynamics as a set of mechanically implemented "registers" and "data paths". This permits certain kinds of de facto communication between spatially separated robots. <ref> [DJR] </ref> also consider three protocols R1, R2, and R3, for a reorientation task (see fig. 14). A transformational approach to developing these protocols is viewed as a series of reductions. The final protocol R3 has several advantages over the initial protocols R1 and R2. <p> This methodology helps transform an o*ine, synchronous manipulation strategy (eg., P1 or R1) with global coordination and control, into an online, asynchronous, distributed strategy (P3 or R3) for the same task: Developing Parallel Manipulation Protocols <ref> [DJR] </ref> 1. Start with a sensorless [EM] or near-sensorless [JR, Rus] manipulation protocol requiring global coordination of several "agents" (eg., parallel jaw fingers, or fingers of a dextrous hand). 2. Distribute the protocol over spatially separated agents. Synchronize and coordinate control using explicit local communication. 3. <p> Implement the shared data structures as "mechanical registers." Our circuits model the protocols in the steps above. Our reductions model the transformations between steps. By the results of Section 8.10.4, these reductions can be effectively computed. Therefore, in principle, the transformations in <ref> [DJR] </ref> could be synthesized automatically. We believe that our methods are useful for developing parallel manipulation protocols. We 53 We use the term in the sense of [DJ]; others, particularly Henderson have used similar concepts. See Section 4.2.1 for examples of virtual and concrete sensors. 103 specified angular amount. <p> The arrows illustrate the direction of the applied forces. From <ref> [DJR] </ref>. have implemented and tested our asynchronous, distributed, SPMD manipu lation protocols using Tommy and Lily, and found them robust and efficient. See [DJR] for a full discussion. 104 12 Conclusions In this book we suggested a theory of information invariance that includes sensors and computation. <p> The arrows illustrate the direction of the applied forces. From <ref> [DJR] </ref>. have implemented and tested our asynchronous, distributed, SPMD manipu lation protocols using Tommy and Lily, and found them robust and efficient. See [DJR] for a full discussion. 104 12 Conclusions In this book we suggested a theory of information invariance that includes sensors and computation. <p> there exist better reductions (eg., our "k-wire" reductions in Section 8.10.3) is open; however in our laboratory we are using 1 to design manipulation 54 For example: no algorithm exists to decide the existence of a linear-space (or log-space, polynomial time, Turing-computable, etc.) reduction between two CT problems. 106 protocols <ref> [DJR] </ref> for multiple mobile robots. We also give a "hierarchy" of reductions, ordered on power, so that the strength of our transformations can be quantified. See Appendix A.4 for a discussion of "universal reduction" as per Section 1.1. See Appendices A.4 and C.3 for more on relativized information complexity. <p> However, it is certainly possible during quasi-static manipulation by a single agent. In moving towards multi-agent tasks and at least partially dynamic tasks, we are attempting to investigate this question in both an experimental and theoretical setting. We discuss these issues further in <ref> [DJR] </ref>. By analogy with CT reductions, we may define an equivalence relation = k , such that A = k B when A k B and B k A.
Reference: [DKM] <author> Donald, B., Kapur, D., and Mundy, J. </author> <title> Symbolic and Numerical Computation for Artificial Intelligence, </title> <publisher> Academic Press: </publisher> <address> London (1992). </address>
Reference-contexts: The algebraic simulation function we give now is adequate to decide the relation fl . To construct an algebraic version of H , we use a simple trick from calculus (also used in kinematics; see, for example <ref> [DKM] </ref>). Let be a configuration of sensor system H (fig. 6). <p> Substitute u = tan 2 . Then we have sin = (1 u 2 )=(1 + u 2 ) and cos = 2u=(1 + u 2 ), 91 and our simulation function is a rational function. By clearing denominators we obtain an algebraic function. See <ref> [DKM] </ref> for details. Essentially the graph of 0 H is a s.a. set in correspondence with graph of the non-algebraic map H . The correspondence is given by 7! u. 9.2 Computing the Reductions fl and 1 Now, suppose we have two algebraic sensor systems U and V.
Reference: [DX1] <author> Donald, B. R. and P. </author> <title> Xavier A Provably Good Approximation Algorithm for Optimal-Time Trajectory Planning, </title> <booktitle> Proc. IEEE International Conference on Robotics and Automation, </booktitle> <address> Scottsdale, AZ (1989). </address>
Reference-contexts: In this case, after losing contact with Tommy, Lily will follow the path (or 9 So, p fl is the time-rescaled trajectory from p <ref> [DX1] </ref>. 10 For an explicit use of this constant in an actual servo loop, see, for example, [RD]. 23 plan) p open loop, until Tommy is reacquired. In both these cases, we must allow Lily to retain enough state to store d or p. <p> Moreover, the methods we describe below typically yield results using "order" notation (big-oh O () or big-theta fi ()) instead of strict equality. One example of provable information invariants is given in the kinody-namic literature <ref> [CDRX, DX1, DX2] </ref>. This work is concerned with provable 24 planning algorithms for robots with dynamics. We give some details in ap-pendix F.1. Here we note that Xavier, in [Xa, DX3] developed "trade-offs" similar in flavor to Equation (1). Both Erdmann and Xavier obtain "tradeoffs" between information and execution speed.
Reference: [DX2] <author> Donald, B. R. and P. </author> <title> Xavier Provably Good Approximation Algorithms for Optimal Kinodynamic Planning for Cartesian Robots and Open Chain Manipulators, </title> <booktitle> Proc. 6 th ACM Symposium on Computational Geometry, </booktitle> <address> Berkeley, CA (1990). </address>
Reference-contexts: Moreover, the methods we describe below typically yield results using "order" notation (big-oh O () or big-theta fi ()) instead of strict equality. One example of provable information invariants is given in the kinody-namic literature <ref> [CDRX, DX1, DX2] </ref>. This work is concerned with provable 24 planning algorithms for robots with dynamics. We give some details in ap-pendix F.1. Here we note that Xavier, in [Xa, DX3] developed "trade-offs" similar in flavor to Equation (1). Both Erdmann and Xavier obtain "tradeoffs" between information and execution speed.
Reference: [DX3] <author> Donald, B. R. and P. </author> <title> Xavier Time-Safety Trade-offs and a Bang-Bang Algorithm for Kinodynamic Planning, </title> <booktitle> Proc. IEEE International Conference on Robotics and Automation, </booktitle> <address> Sacramento, CA (1991). </address> <month> 111 </month>
Reference-contexts: One example of provable information invariants is given in the kinody-namic literature [CDRX, DX1, DX2]. This work is concerned with provable 24 planning algorithms for robots with dynamics. We give some details in ap-pendix F.1. Here we note that Xavier, in <ref> [Xa, DX3] </ref> developed "trade-offs" similar in flavor to Equation (1). Both Erdmann and Xavier obtain "tradeoffs" between information and execution speed. Their methods appear to require a performance measure (eg, the "cost" of a control strategy). <p> See appendix F.1 for more details on information invariants with performance measures. To summarize: the ambition of this work is to define the notions in Idea 2.1 so they can be measured directly. Previous work <ref> [Erd91, Xa, DX3] </ref> has required a performance measure in order to obtain a common currency for information invariance. In order not to use this crutch, we first define a set of transformations on sensori-computational systems. <p> Second, such comparisons would require an explicit performance measure. We discussed such measures as speed (or execution time) in Section 2.1.2. In appendix F.1, we argue that such performance measures allow us to apply kinodynamic analysis tools <ref> [DX3, Xa] </ref>. There is no doubt that external performance measures such as "simpler" and "better" and "cheaper" could be used with our framework| but we don't know what exactly these measures are. It appears that efficient algorithms for exploiting these measures will have to take advantage of their structure.
Reference: [Erd] <author> Erdmann, M. </author> <type> Personal Communication, </type> <year> (1992). </year>
Reference-contexts: To calibrate H so that at L is located at the point G clearly adds information. More precisely, note that we have so far considered the radial sensor E at a fixed goal G in the plane. Let 23 This section (5.3) devolves to a suggestion of Mike Erdmann <ref> [Erd] </ref>, for which we are very grateful. 47 us denote this particular installation by E G .
Reference: [Erd86] <author> Erdmann, M. </author> <title> Using Backprojections for Fine Motion Planning with Uncertainty, </title> <journal> IJRR Vol. </journal> <volume> 5 no. </volume> <month> 1 </month> <year> (1986). </year>
Reference-contexts: Finally, we could imagine a scenario where Lily retains some amount of state over time to "track" Tommy. For example, by observing Tommy's trajectory before the break in communication, it may be possible to extrapolate future positions (one could, for example, use forward projections <ref> [Erd86] </ref> or a kalman filter). Based on these extrapolations, Lily could seek Tommy in the region of highest expectation.
Reference: [Erd89] <author> Erdmann, M. </author> <title> On Probabilistic Strategies for Robot Tasks, </title> <type> Ph.D. thesis, </type> <institution> MIT Department of EECS, MIT A.I. Lab, </institution> <address> Cambridge MIT-AI-TR 1155 (1989). </address>
Reference-contexts: Introduction As its title suggests, this book investigates the information requirements for robot tasks. Our work takes as its inspiration the information invariants that Erdmann 2 introduced to the robotics community in 1989 <ref> [Erd89] </ref>, although rigorous examples of information invariants can be found in the theoretical literature from as far back as 1978 (see, for example, [BK, Koz]). Part I of this book develops the basic concepts and tools behind information invariants in plain language. Therein, we develop a number of motivating examples. <p> How may the robot acquire such information? 3. What properties of the world have a great effect on the fragility of a robot plan/program? 2 Erdmann introduced the notion of measuring task complexity in bit-seconds; the example is important but somewhat complicated; the interested reader is referred to <ref> [Erd89] </ref>. 11 4. What are the capabilities of a given robot (in a given environment or class of environments)? These questions can be difficult. <p> Hence we may credit [BK] with a excellent example of information invariance. 2.2.1 The Power of Randomization Erdmann's PhD thesis is an investigation of the power of randomization in robotic strategies <ref> [Erd89] </ref>. The idea is similar to that of randomized algorithms|by permitting the robot to randomly perturb initial conditions (the environment), its own internal state, or to randomly choose among actions, one may enhance the performance and capabilities of robots, and derive 13 Here is the idea. <p> We made a conceptual connection between information invariants and trade-offs. In previous work, tradeoffs arose naturally in kinodynamic situations, in which performance measures, planning complexity, and robustness (in the sense of resistance to control uncertainty) are traded-off. We noted that Erdmann's invariants are of this ilk <ref> [Erd89] </ref>. However, without a performance (cost) measure, it is more difficult to develop information invariants. We believe measures of information complexity are fundamentally different from performance measures. Our interest here is in the former; we will not discuss performance measures again until appendix F.1.
Reference: [Erd91] <author> Erdmann, M. </author> <title> Towards Task-Level Planning: Action-Based Sensor Design, </title> <institution> Carnegie-Mellon School of Computer Science, </institution> <type> Tech. report, </type> <institution> CMU-CS-92-116, </institution> <month> Feb. </month> <year> (1991). </year>
Reference-contexts: In our quest for a measure of the intrinsic information requirements of a task, we are inspired by Erdmann's monograph on sensor design <ref> [Erd91] </ref>. Also, we note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, [Reif, HSS, Nat, CR]; see, eg, [Don2, Can, Bri] for upper bounds). <p> See appendix F.1 for more details on information invariants with performance measures. To summarize: the ambition of this work is to define the notions in Idea 2.1 so they can be measured directly. Previous work <ref> [Erd91, Xa, DX3] </ref> has required a performance measure in order to obtain a common currency for information invariance. In order not to use this crutch, we first define a set of transformations on sensori-computational systems. <p> In particular, one challenge was to consider continuous state spaces (as opposed to graphs). 15 In considering how a very accurate sensor can aid a robot in accomplishing a task, this methodology is closely allied with Erdmann's work on developing "minimal" sensors <ref> [Erd91] </ref>. Consider an automaton (of any kind) in a maze. Such an automaton effectively has a compass, since it can tell N,S,E,W apart. <p> For example, the box could represent some new sensing, or some computation on existing sensory and stored data. In part II we discuss some methods for achieving these goals. To illustrate our techniques, we describe two sensors, the radial sensor <ref> [Erd91] </ref>, and the beacon, or lighthouse sensor. We then develop methods to compare the sensors and their information invariants. These sensors bear some relation to the compass discussed in part I; it is our goal here to quantify this relationship precisely. <p> Sections 4.1-5.4.1 explore this idea through an example. 4.1 The Radial Sensor We begin with a didactic example. In <ref> [Erd91] </ref> Erdmann demonstrates a method for synthesizing sensors from task specifications. The sensors have the property of being "optimal" or "minimal" in the sense that they convey exactly the information required for the control system to perform the task. <p> The robot need only command v r to reduce its distance to the goal. 17 This example easily generalizes to the case where there is uncertainty in the robot's control system (that is, the "aim" of v ) see <ref> [LMT, Erd91] </ref>. It is plausible (and indeed, Erdmann proves) that this sensor is necessary and sufficient to write a feedback loop that provably attains the goal. To summarize: the radial sensor returns information that encodes the relative heading r of the goal G|relative to the robot's current heading h. <p> See fig. 5. We emphasize that the radial sensor does not reveal the configuration (x; h) of the robot beyond this. We will not describe possible physical implementations of the radial sensor, but see <ref> [Erd91] </ref> for a discussion. 18 4.2 Lighthouses, Beacons, Ships, and Airplanes We now describe another sensor. Our goal is to compare this sensor to the radial sensor using information invariants. See fig. 6. We call this a lighthouse sensor system. <p> is encoded or provided by the task mechanics? The theme of exploiting task mechanics is important in previous work. 50 One could define "exploiting task mechanics" for robot manipulation as: taking advantage of the mechanical and physical laws that govern how objects move 50 For example, see the discussion of <ref> [Mas, EM, Erd91] </ref> in part I. 98 and change. Currently, in our framework the mechanics are embedded in the geometry of the system. In [DJR], we developed information invariants that explicitly trade-off (f) with resources (a)-(e) from the abstract, in the style of the preceding.
Reference: [EM] <author> Erdmann, M., and M. Mason, </author> <title> "An Exploration of Sensorless Manipulation", </title> <booktitle> IEEE International Conference on Robotics and Automation, </booktitle> <address> San Francisco, </address> <month> April, </month> <year> 1986. </year>
Reference-contexts: is encoded or provided by the task mechanics? The theme of exploiting task mechanics is important in previous work. 50 One could define "exploiting task mechanics" for robot manipulation as: taking advantage of the mechanical and physical laws that govern how objects move 50 For example, see the discussion of <ref> [Mas, EM, Erd91] </ref> in part I. 98 and change. Currently, in our framework the mechanics are embedded in the geometry of the system. In [DJR], we developed information invariants that explicitly trade-off (f) with resources (a)-(e) from the abstract, in the style of the preceding. <p> The boxes are typically several robot diameters wide, and 1-2 times the mass of a single robot, although the robots have also pushed couches that are heavier (perhaps 2-4 times the mass, and 8 fi 3 robot diameters in size). We build on the ground-breaking work of <ref> [Mason, EM] </ref> and others on planar sensorless manipulation. Our work differs from previous work on pushing in several ways. First, the robots and boxes are on a similar dynamic and spatial scale. <p> This methodology helps transform an o*ine, synchronous manipulation strategy (eg., P1 or R1) with global coordination and control, into an online, asynchronous, distributed strategy (P3 or R3) for the same task: Developing Parallel Manipulation Protocols [DJR] 1. Start with a sensorless <ref> [EM] </ref> or near-sensorless [JR, Rus] manipulation protocol requiring global coordination of several "agents" (eg., parallel jaw fingers, or fingers of a dextrous hand). 2. Distribute the protocol over spatially separated agents. Synchronize and coordinate control using explicit local communication. 3.
Reference: [FLM] <author> Fischer, M., N. Lynch and M. </author> <title> Merritt Easy Impossibility Proofs for Distributed Concensus Problems, </title> <journal> Distributed Computing, </journal> (1):26-39 (1986). 
Reference-contexts: Below, we use the term "sensor system" to mean "sensori-computational system" where it is mellifluous. 8.1 Situated Sensor Systems We formalize our model of sensor systems using a concept similar to the communication graph from distributed systems <ref> [FLM] </ref>. Definition 8.13 A labelled graph G is a directed graph (V; E) with vertices V and edges E, together with a labelling function that assigns a label to each vertex and edge.
Reference: [Fi] <author> Fischer, P. C. </author> <title> Turing Machines with Restricted Memory Access, </title> <journal> Information and Control, </journal> <volume> 9 (4), </volume> <pages> pp. </pages> <month> 364-379 </month> <year> (1966). </year>
Reference-contexts: A DFA with a counter can keep a count in the register, increment or decrement it, and test for zero. A single counter DFA (introduced by <ref> [Fi] </ref> in 1966) can be viewed as a special kind of push-down (stack) automaton (PDA) that has only one stack symbol (except for a top of the stack marker).
Reference: [Gri] <author> Grigoryev D. Yu., </author> <title> "Complexity of Deciding Tarski Algebra" Jour. </title> <journal> Symbolic Computation, </journal> <volume> 5, (1), </volume> <year> (1988), </year> <pages> pp. 65-108. </pages>
Reference: [HSS] <author> Hopcroft, J. E., Schwartz, J. T., and Sharir, M. </author> <title> 1984 On the Complexity of Motion Planning for Multiple Independent Objects; PSPACE-Hardness of the "Warehouseman's Problem." </title> <journal> International Journal of Robotics Research. </journal> <volume> 3(4) </volume> <pages> 76-88. </pages>
Reference-contexts: In our quest for a measure of the intrinsic information requirements of a task, we are inspired by Erdmann's monograph on sensor design [Erd91]. Also, we note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, <ref> [Reif, HSS, Nat, CR] </ref>; see, eg, [Don2, Can, Bri] for upper bounds). Rosenschein has de 13 veloped a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates.
Reference: [HU] <author> Hopcroft, J. E. and J. </author> <title> Ullman Introduction to Automata Theory, Languages, and Computation, </title> <publisher> Addison-Wesley (Reading, </publisher> <address> Mass.) </address> <year> (1979). </year>
Reference-contexts: First, they note a result of Budach that a single automaton cannot search all mazes. 12 Next they prove the following: 1. There are two (unenhanced) automata that together can search all mazes. considerably weaker than a Turing machine (see, eg., <ref> [HU; Ch. 5] </ref>). The proof that a two-counter DFA can simulate a Turing machine was first given by Papert and McNaughton in 1961 [Min] but shorter proofs are now given in many textbooks, for example, see [HU; Thm. 7.9]. 12 See [BK] for references. 27 2. <p> The proof that a two-counter DFA can simulate a Turing machine was first given by Papert and McNaughton in 1961 [Min] but shorter proofs are now given in many textbooks, for example, see <ref> [HU; Thm. 7.9] </ref>. 12 See [BK] for references. 27 2. There is a two-pebble automaton that can search all mazes. 3. There is a one-counter automaton that can search all mazes. These results are crisp information invariants.
Reference: [Hors] <author> Horswill, I. </author> <title> Analysis of Adaptation and Environment, </title> <note> Submitted to Artificial Intelligence (1992). </note>
Reference-contexts: His theory is set in a logical framework where sensors are logical predicates. Perhaps our theory could be viewed as a geometric attack on a similar problem. This work was inspired by the theoretical attack on perceptual equivalence begun by [DJ] and by the experimental studies of [JR]. Horswill <ref> [Hors] </ref> has developed a semantics for sensory systems that models and quantifies the kinds of assumptions a sensori-computational program makes about its environment.
Reference: [JR] <author> Jennings, J. and D. </author> <title> Rus Active Model Acquisition for Near-Sensorless Manipulation With Mobile Robots, </title> <booktitle> International Association of Science and Technology for Development (IASTED) International Conference on Robotics and Manufacturing, </booktitle> <address> (Oxford, England) (September 23-25). </address> <year> (1993). </year> <month> 112 </month>
Reference-contexts: His theory is set in a logical framework where sensors are logical predicates. Perhaps our theory could be viewed as a geometric attack on a similar problem. This work was inspired by the theoretical attack on perceptual equivalence begun by [DJ] and by the experimental studies of <ref> [JR] </ref>. Horswill [Hors] has developed a semantics for sensory systems that models and quantifies the kinds of assumptions a sensori-computational program makes about its environment. <p> Fourth, our protocols assume neither that the robot has a geometric model of the box, nor that the first moment of the friction distribution (the COF) is known. Instead, the robot combines sensorimotor experiments and manipulation strategies to infer the necessary information (the experiments have the flavor of <ref> [JR] </ref>). Finally, the pushing literature generally regards the "pushers" as moving kinematic constraints. In our case, because (i) there are at least two robot pushers and (ii) the robots are less massive than the box, the robots are really "force-appliers" in a system with significant friction. <p> This methodology helps transform an o*ine, synchronous manipulation strategy (eg., P1 or R1) with global coordination and control, into an online, asynchronous, distributed strategy (P3 or R3) for the same task: Developing Parallel Manipulation Protocols [DJR] 1. Start with a sensorless [EM] or near-sensorless <ref> [JR, Rus] </ref> manipulation protocol requiring global coordination of several "agents" (eg., parallel jaw fingers, or fingers of a dextrous hand). 2. Distribute the protocol over spatially separated agents. Synchronize and coordinate control using explicit local communication. 3. Define virtual sensors 53 for the quantities step (2) measures. 4.
Reference: [Jen94] <author> Jennings, J. </author> <title> Sensor Interpretation and Task-Directed Planning for Autonomous Agents, </title> <type> Forthcoming PhD. Thesis, </type> <institution> Computer Science Department, Cornell University, </institution> <address> Ithaca, NY (1994). </address>
Reference-contexts: In this case we need some explicit notion of time and blocking to model the (a)synchronous arrival of data at a component. Such extensions are considered in <ref> [Jen94] </ref>; for now we restrict our attention to trees, which suffice to model our examples. 28 In general our discussion is restricted to consider one clock-tick; however, generalizations are possible to consider the time-varying behavior of the system [Jen94]. <p> Such extensions are considered in <ref> [Jen94] </ref>; for now we restrict our attention to trees, which suffice to model our examples. 28 In general our discussion is restricted to consider one clock-tick; however, generalizations are possible to consider the time-varying behavior of the system [Jen94]. Let us relate these new definitions to the examples from part I. Examples of components are given by the resources described in Section 4.2.1. <p> See <ref> [DJR, Jen94] </ref> for more discussion of actuators. 59 Now, we give Definition 8.16 A situated (or immersed) sensor system S is a sensor system S = (V; E), together with an immersion : V ! C of the vertices.
Reference: [Koz] <author> Kozen, D. </author> <title> Automata and Planar Graphs, </title> <booktitle> Fundamentals of Computing Theory, Proc. Conf. on Algebraic, Arithmetic, and categorical methods in Computation Theory (Berlin) ed. </booktitle> <editor> L. Budach, </editor> <publisher> Akademie Verlag (1979). </publisher>
Reference-contexts: Our work takes as its inspiration the information invariants that Erdmann 2 introduced to the robotics community in 1989 [Erd89], although rigorous examples of information invariants can be found in the theoretical literature from as far back as 1978 (see, for example, <ref> [BK, Koz] </ref>). Part I of this book develops the basic concepts and tools behind information invariants in plain language. Therein, we develop a number of motivating examples. In part II, we provide a fairly detailed analysis. In particular, we admit more sophisticated models of sensors and computation. <p> Blum and Kozen show, that in contrast, to (1), no two automata together can search all finite planar cubic graphs (in a cubic graph, all vertices have degree g = 3). They then prove no three automata suffice. Later, Kozen showed that four automata do not suffice <ref> [Koz] </ref>. Moreover, if we relax the planarity assumption but restrict our cubic graphs to be 3D mazes, it is known that no finite set of finite automata can search all such finite 3D mazes [BS].
Reference: [Lat] <author> Latombe, J.-C. </author> <title> Robot Motion Planning, </title> <publisher> Kluwer: </publisher> <address> New York (1991). </address>
Reference-contexts: The construction essentially involves adding the IR information above to the servo loop for following using sonar given in [RD]. The details are not particularly important to this discussion. 8 See <ref> [Lat] </ref> for a good introduction. 20 w v w v Tommy Lily wall (on his right) at speed v, while Lily (L) follows at speed w. the robot.
Reference: [LoP] <author> Lozano-Perez, T. </author> <title> Spatial Planning: A Configuration Space Approach, </title> <journal> IEEE Trans. on Computers (C-32):108-120 (1983). </journal>
Reference-contexts: Moreover, these "local maps" are updated at each iteration through the servo loop, and so little retained state is necessary. Now, robotics employs the notion of configuration space 8 <ref> [LoP] </ref> to describe control and planning algorithms. The configuration of one of our robots is its position and heading. Configuration space is the set of all configurations. In our case, the configuration space of one robot is the space R 2 fi S 1 .
Reference: [LMT] <author> Lozano-Perez, T., Mason, M. T., and Taylor, R. H. </author> <title> Automatic Synthesis of Fine-Motion Strategies for Robots, </title> <journal> Int. J. of Robotics Research, </journal> <volume> Vol 3, no. </volume> <month> 1 </month> <year> (1984). </year>
Reference-contexts: The robot need only command v r to reduce its distance to the goal. 17 This example easily generalizes to the case where there is uncertainty in the robot's control system (that is, the "aim" of v ) see <ref> [LMT, Erd91] </ref>. It is plausible (and indeed, Erdmann proves) that this sensor is necessary and sufficient to write a feedback loop that provably attains the goal. To summarize: the radial sensor returns information that encodes the relative heading r of the goal G|relative to the robot's current heading h. <p> In particular, the "compass" is an orientation sensor that could in principle be implemented using odometry or dead-reckoning, plus some initial calibration. Moreover, "North" N can be any fixed direction for our purposes, and need not be "true North." In the language of <ref> [LMT] </ref>, the compass senses the projection of a perfect position sensor p fl 2 R 2 fi S 1 onto S 1 . 44 communication only makes sense in a spatially distributed sensor system.
Reference: [LS] <author> V. J. Lumelsky and A. A. </author> <title> Stepanov Path-planning strategies for a point mobile automaton moving amidst unknown obstacles of arbitrary shape, </title> <journal> Algorithmica, </journal> <volume> (2), </volume> <pages> pp. </pages> <month> 403-430 </month> <year> (1987). </year>
Reference-contexts: In particular, even schemes such as <ref> [LS] </ref> require a worst-case linear amount of storage (in the geometric complexity n of the environment). Can one do better? Is there a sufficient representation that is between 0 and O (n)? Blum and Kozen provide precise answers to these questions in the setting of theoretical, situated automata.
Reference: [Mas] <author> Mason, M. T. </author> <year> 1986. </year> <title> Mechanics and Planning of Manipulator Pushing Operations. </title> <journal> International Journal of Robotics Research 5(3). </journal>
Reference-contexts: I believe that quantifying communication between collaborating mobile robots is a fundamental information-theoretic question. In manipulation, the ability to structure the environment through the actions of the robot (see, eg, [Don3]) or the mechanics of the task (see, eg,. <ref> [Mas] </ref>) seems a fundamental paradigm. How do these techniques compare in power? We call automata with these extra features enhanced, and we will assume that automata are not enhanced unless noted. Given these assumptions, Blum and Kozen demonstrate the following results. <p> is encoded or provided by the task mechanics? The theme of exploiting task mechanics is important in previous work. 50 One could define "exploiting task mechanics" for robot manipulation as: taking advantage of the mechanical and physical laws that govern how objects move 50 For example, see the discussion of <ref> [Mas, EM, Erd91] </ref> in part I. 98 and change. Currently, in our framework the mechanics are embedded in the geometry of the system. In [DJR], we developed information invariants that explicitly trade-off (f) with resources (a)-(e) from the abstract, in the style of the preceding.
Reference: [Min] <author> Minsky, M. </author> <title> Recursive Unsolvability of Post's Problem of `Tag' and Other Topics in the Theory of Turing Machines, </title> <journal> Annals of Math, </journal> <volume> 74, (3), </volume> <pages> pp. </pages> <month> 437-455 </month> <year> (1961). </year>
Reference-contexts: There are two (unenhanced) automata that together can search all mazes. considerably weaker than a Turing machine (see, eg., [HU; Ch. 5]). The proof that a two-counter DFA can simulate a Turing machine was first given by Papert and McNaughton in 1961 <ref> [Min] </ref> but shorter proofs are now given in many textbooks, for example, see [HU; Thm. 7.9]. 12 See [BK] for references. 27 2. There is a two-pebble automaton that can search all mazes. 3. There is a one-counter automaton that can search all mazes. These results are crisp information invariants.
Reference: [Nar] <author> Narasimhan, S. </author> <type> Personal Communication, </type> <year> (1993). </year>
Reference: [Nat] <author> B. K. </author> <title> Natarajan On Planning Assemblies, </title> <booktitle> Proc. of the 4th Annual Symposium on Computational Geometry, </booktitle> <address> Urbana, Illinois, </address> <month> June. </month> <pages> pp. 299-308. </pages> <year> (1988). </year>
Reference-contexts: In our quest for a measure of the intrinsic information requirements of a task, we are inspired by Erdmann's monograph on sensor design [Erd91]. Also, we note that many interesting lower bounds (in the complexity-theoretic sense) have been obtained for motion planning questions (see, eg, <ref> [Reif, HSS, Nat, CR] </ref>; see, eg, [Don2, Can, Bri] for upper bounds). Rosenschein has de 13 veloped a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it [Ros]. His theory is set in a logical framework where sensors are logical predicates. <p> For example, (near) reactive systems use (almost) no state, while "map builders" and 31 model-based approaches use a very large (linear) amount. Natarajan <ref> [Nat] </ref> has considered an invariant complexity measure analogous to (b), namely the number of robot "hands" required to perform an assembly task. This quantifies the interference kinematics of the assembly task, and assumes global synchronous control.
Reference: [RD] <author> Rees, J. and B. R. </author> <title> Donald Program Mobile Robots in Scheme, </title> <booktitle> Proc. IEEE International Conference on Robotics and Automation, Nice, France (1992). </booktitle> <editor> Reif J., </editor> <title> "Complexity of the Mover's Problem and Generalizations," </title> <booktitle> Proc. 20th IEEE Symp. FOCS, </booktitle> <year> (1979). </year> <title> Also in "Planning, Geometry and Complexity of Robot Motion", </title> <editor> ed. by J. Schwartz, J. Hopcroft and M. Sharir, </editor> <publisher> Ablex publishing corp. </publisher> <address> New Jersey, </address> <year> (1987), </year> <journal> Ch. </journal> <volume> 11, </volume> <pages> pp. 267-281. 113 </pages>
Reference-contexts: Consider two autonomous mobile robots, such as those described in <ref> [RD] </ref>. The robots we have in mind are the Cornell mobile robots [RD], but the details of their construction are not important. The robots can move about by controlling motors attached to wheels. The robots are autonomous and equipped with a ring of 12 simple Polaroid ultrasonic sonar sensors. <p> Consider two autonomous mobile robots, such as those described in <ref> [RD] </ref>. The robots we have in mind are the Cornell mobile robots [RD], but the details of their construction are not important. The robots can move about by controlling motors attached to wheels. The robots are autonomous and equipped with a ring of 12 simple Polaroid ultrasonic sonar sensors. Each robot has an onboard processor for control and programming. <p> We wish to consider a task in which one robot called Lily must follow another robot called Tommy. It is possible to write such a control loop using only sonar readings and position/force control alone. We now augment the robots described in <ref> [RD] </ref> as follows. (This description characterizes the robots in our lab). We equip each robot with 12 infrared modems/sensors, arrayed in a ring about the robot body. Each modem consists of an emitter-detector pair. <p> Also, using the id a robot can disambiguate other robots' broadcasts from its own IR broadcast (eg, reflections off white walls). 6 This data is noisy, but since an adequate servo loop for following can be constructed using sonars alone <ref> [RD] </ref>, the IR's only add information to the task. <p> The construction essentially involves adding the IR information above to the servo loop for following using sonar given in <ref> [RD] </ref>. The details are not particularly important to this discussion. 8 See [Lat] for a good introduction. 20 w v w v Tommy Lily wall (on his right) at speed v, while Lily (L) follows at speed w. the robot. <p> In this case, after losing contact with Tommy, Lily will follow the path (or 9 So, p fl is the time-rescaled trajectory from p [DX1]. 10 For an explicit use of this constant in an actual servo loop, see, for example, <ref> [RD] </ref>. 23 plan) p open loop, until Tommy is reacquired. In both these cases, we must allow Lily to retain enough state to store d or p. Since Lily already stores some value for d (see [RD]), we need merely replace that. <p> an explicit use of this constant in an actual servo loop, see, for example, <ref> [RD] </ref>. 23 plan) p open loop, until Tommy is reacquired. In both these cases, we must allow Lily to retain enough state to store d or p. Since Lily already stores some value for d (see [RD]), we need merely replace that. However, the storage for the plan (or path) p could be significant, depending on the detail. Finally, we could imagine a scenario where Lily retains some amount of state over time to "track" Tommy. <p> Concrete Sensors. On R, there is is a photo-electric sensor that detects when a white light illuminates R. Another sensor detects green light. There is also a clock on R. Computation. There is a computer on R that we can program in Scheme, following <ref> [RD] </ref>. The concrete sensors above are interfaced to Scheme via library functions (as in [RD]). The functions (white?) and (green?) are of 38 type unit ! bool, and return #t when light is sensed and #f otherwise. <p> Another sensor detects green light. There is also a clock on R. Computation. There is a computer on R that we can program in Scheme, following <ref> [RD] </ref>. The concrete sensors above are interfaced to Scheme via library functions (as in [RD]). The functions (white?) and (green?) are of 38 type unit ! bool, and return #t when light is sensed and #f otherwise. The clock is available as the function (time), which returns the time measured in small units. <p> assume the clock and the processor are very fast relative to the green light (and the ship). 39 ; time between beacons ; event1 and event2 are type unit ! bool. 20 (define (time-beacons event1 event2) (sleep-until event1) (let ((T0 (time))) (sleep-until event2) (- (time) T0))) : utility in scheme48 <ref> [RD] </ref>. ; sleep-until waits until thunk returns #t, ; and then returns. (define (sleep-until thunk) ....) Resources R does not have. Let us contrast our exemplar robot ship R with an enhanced version R 0 that corresponds to a real ship navigating at sea using lighthouse sensors. <p> Now, consider the analogous pushing task in fig. 11b. Each finger is replaced by an autonomous mobile robot with only local communication, configured as described in Section 2.1 of part I. Each robot has a ring of one-bit contact ("bump") sensors. In addition, by examining the servo-loop in <ref> [RD] </ref>, it is clear that we can compute a measure of applied force by observing the applied power, the position and velocity of the robot, and the contact sensors. 99 Pushing Reorientation Task Task global coordination P1 R1 and control local IR communication, P2 R2 partial synchrony, MPMD uniform (SPMD), P3
Reference: [Ros] <author> Rosenschein, S.J. </author> <title> Synthesizing Information-Tracking Automata from Environment Descriptions, </title> <journal> Teleos Research TR No. </journal> <month> 2 </month> <year> (1989). </year>
Reference-contexts: Rosenschein has de 13 veloped a theory of synthetic automata which explore the world and build data-structures that are "faithful" to it <ref> [Ros] </ref>. His theory is set in a logical framework where sensors are logical predicates. Perhaps our theory could be viewed as a geometric attack on a similar problem. This work was inspired by the theoretical attack on perceptual equivalence begun by [DJ] and by the experimental studies of [JR].
Reference: [Rus] <author> Rus, D. </author> <title> "Fine Motion Planning for Dexterous Manipulation", </title> <type> PhD. </type> <note> Thesis available as CU-CS-TR 92-1323 (August) from Comp. </note> <institution> Sci. Dept., Cornell University, </institution> <year> 1992. </year>
Reference-contexts: This methodology helps transform an o*ine, synchronous manipulation strategy (eg., P1 or R1) with global coordination and control, into an online, asynchronous, distributed strategy (P3 or R3) for the same task: Developing Parallel Manipulation Protocols [DJR] 1. Start with a sensorless [EM] or near-sensorless <ref> [JR, Rus] </ref> manipulation protocol requiring global coordination of several "agents" (eg., parallel jaw fingers, or fingers of a dextrous hand). 2. Distribute the protocol over spatially separated agents. Synchronize and coordinate control using explicit local communication. 3. Define virtual sensors 53 for the quantities step (2) measures. 4.
Reference: [Tar] <author> Tarski A., </author> <title> "A Decision Method for Elementary Algebra and Geometry" Univ. of Calif. </title> <publisher> Press, </publisher> <address> Berkeley, </address> <year> (1948), </year> <note> second ed. </note> <year> 1951. </year>

References-found: 46

