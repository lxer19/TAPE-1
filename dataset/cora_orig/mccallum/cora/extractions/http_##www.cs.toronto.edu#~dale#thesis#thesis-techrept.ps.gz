URL: http://www.cs.toronto.edu/~dale/thesis/thesis-techrept.ps.gz
Refering-URL: http://www.cs.toronto.edu/~dale/
Root-URL: 
Title: EFFECTIVE CLASSIFICATION LEARNING  
Author: by Dale Eric Schuurmans 
Degree: A thesis submitted in conformity with the requirements for the degree of Doctor of Philosophy  
Note: c Copyright Dale Schuurmans 1996  
Address: Toronto  
Affiliation: Graduate Department of Computer Science University of  
Abstract-found: 0
Intro-found: 1
Reference: <author> Aha, D. W., Kibler, D., and Albert, M. K. </author> <year> 1991. </year> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6(1) </volume> <pages> 37-66. </pages>
Reference: <author> Albert, M. K. and Aha, D. W. </author> <year> 1991. </year> <title> Analyses of instance-based learning algorithms. </title> <booktitle> In Proceedings of the Ninth American National Conference on Artificial Intelligence (AAAI-91), </booktitle> <pages> pages 553-558. </pages>
Reference: <author> Amari, S., Fujita, N., and Shinomoto, S. </author> <year> 1992. </year> <title> Four types of learning curves. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 605-618. </pages>
Reference: <author> Angluin, D. </author> <year> 1988. </year> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342. </pages>
Reference: <author> Angluin, D. and Laird, P. </author> <year> 1988. </year> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370. </pages>
Reference: <author> Ash, R. B. </author> <year> 1972. </year> <title> Real Analysis and Probability. </title> <publisher> Academic Press, </publisher> <address> San Diego. </address>
Reference: <author> Barnard, E. </author> <year> 1994. </year> <title> A model for nonpolynomial decrease in error rate with increasing sample size. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5(6) </volume> <pages> 994-997. </pages>
Reference: <author> Bartlett, P. L. and Williamson, R. C. </author> <year> 1991. </year> <title> Investigating the distributional assumptions of the pac learning model. </title> <booktitle> In Proceedings of the Fourth Annual Conference on Computational Learning Theory (COLT-91), </booktitle> <pages> pages 24-32. </pages>
Reference: <author> Baum, E. B. </author> <year> 1990. </year> <title> The perceptron algorithm is fast for nonmalicious distributions. </title> <journal> Neural Computation, </journal> <volume> 2 </volume> <pages> 248-260. </pages>
Reference: <author> Baum, E. B. and Haussler, D. </author> <year> 1989. </year> <title> What size net gives valid generalization? Neural Computation, </title> <booktitle> 1 </booktitle> <pages> 151-160. </pages>
Reference: <author> Baum, E. B. and Lyuu, Y.-D. </author> <year> 1991. </year> <title> The transition to perfect generalization in perceptrons. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 386-401. </pages>
Reference: <author> Ben-David, S., Benedek, G. M., and Mansour, Y. </author> <year> 1989. </year> <title> A parameterization scheme for classifying models of learnability. </title> <booktitle> In Proceedings of the Second Annual Conference on Computational Learning Theory (COLT-89), </booktitle> <pages> pages 285-302. </pages>
Reference: <author> Ben-David, S., Cesa-Bianchi, N., and Long, P. M. </author> <year> 1992. </year> <title> Characterizations of learnability for classes of f0; :::; ng-valued functions. </title> <booktitle> In Proceedings of the Fifth Annual Conference on Computational Learning Theory (COLT-92), </booktitle> <pages> pages 333-340. </pages>
Reference: <author> Benedek, G. and Itai, A. </author> <year> 1988a. </year> <title> Learnability by fixed distributions. </title> <booktitle> In Proceedings of the Conference on Computational Learning Theory (COLT-88), </booktitle> <pages> pages 80-90. </pages>
Reference: <author> Benedek, G. and Itai, A. </author> <year> 1988b. </year> <title> Nonuniform learnability. </title> <booktitle> In Proceedings of the Fifteenth International Colloquium on Automata, Languages and Programming (ICALP-88), </booktitle> <pages> pages 82-92. </pages>
Reference: <author> Benedek, G. and Itai, A. </author> <year> 1991. </year> <title> Learnability with respect to fixed distributions. </title> <journal> Theoretical Computer Science, </journal> <volume> 86 </volume> <pages> 377-389. </pages>
Reference: <author> Blumer, A., Ehrenfeucht, A., Haussler, D., and Warmuth, M. K. </author> <year> 1989. </year> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Journal of the ACM, </journal> <volume> 36(4) </volume> <pages> 929-965. </pages> <note> 169 170 BIBLIOGRAPHY Breiman, </note> <author> L., Friedman, J. H., Olshen, R. A., and Stone, C. J. </author> <year> 1984. </year> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont, CA. </address>
Reference: <author> Brualdi, R. A. </author> <year> 1977. </year> <title> Introductory Combinatorics. </title> <publisher> North-Holland, </publisher> <address> New York. </address>
Reference: <author> Buchanan, B. G. and Mitchell, T. M. </author> <year> 1978. </year> <title> Model directed learning of production rules. </title> <editor> In Waterman, D. A. and Hayes-Roth, F., editors, </editor> <title> Pattern Directed Inference Systems. </title> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: <author> Chernoff, H. </author> <year> 1972. </year> <title> Sequential Analysis and Optimal Design. </title> <publisher> SIAM, </publisher> <address> Philadelphia. </address>
Reference: <author> Clancey, W. J. </author> <year> 1985. </year> <title> Heuristic classification. </title> <journal> Artificial Intelligence, </journal> <volume> 27 </volume> <pages> 289-350. </pages>
Reference: <author> Cohn, D. and Tesauro, G. </author> <year> 1990. </year> <title> Can neural networks do better than the Vapnik-Chervonenkis bounds? In Touretzky, </title> <editor> D., editor, </editor> <booktitle> Advances in Neural Information Processing Systems 3. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Cohn, D. and Tesauro, G. </author> <year> 1992. </year> <title> How tight are the Vapnik-Chervonenkis bounds? Neural Computation, </title> <booktitle> 4 </booktitle> <pages> 249-269. </pages>
Reference: <author> Dennis, J. E. and Schnabel, R. B. </author> <year> 1983. </year> <title> Numerical Methods for Unconstrained and Nonlinear Equations. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ. </address>
Reference: <author> Duda, R. O. and Hart, P. </author> <year> 1973. </year> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference: <author> Dudley, R. M., Kulkarni, S., Richardson, T., and Zeitouni, O. </author> <year> 1994. </year> <title> A metric entropy bound is not sufficient for learnability. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 40(3) </volume> <pages> 883-885. </pages>
Reference: <author> Ehrenfeucht, A., Haussler, D., Kearns, M. J., and Valiant, L. </author> <year> 1989. </year> <title> A general lower bound on the number of examples needed for learning. </title> <journal> Information and Computation, </journal> <volume> 82 </volume> <pages> 247-261. </pages>
Reference: <author> Furst, M. L., Jackson, J. C., and Smith, S. W. </author> <year> 1991. </year> <title> Improved learning of AC 0 functions. </title> <booktitle> In Proceedings of the Fourth Annual Conference on Computational Learning Theory (COLT-91), </booktitle> <pages> pages 317-325. </pages>
Reference: <author> Gallant, S. I. </author> <year> 1990. </year> <title> Perceptron-based learning algorithms. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 2(1) </volume> <pages> 179-191. </pages>
Reference: <author> Geman, S., Bienenstock, E., and Doursat, R. </author> <year> 1992. </year> <title> Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4(1) </volume> <pages> 1-58. </pages>
Reference: <author> Gold, E. M. </author> <year> 1967. </year> <title> Language identification in the limit. </title> <journal> Information and Control, </journal> <volume> 10 </volume> <pages> 447-474. </pages>
Reference: <author> Goldman, S., Kearns, M. J., and Schapire, R. </author> <year> 1990. </year> <title> Exact identification of circuits using fixed points of amplification functions. </title> <booktitle> In Proceedings of the Thirty First Annual IEEE Symposium on Foundations of Computer Science (FOCS-90), </booktitle> <pages> pages 193-202. </pages>
Reference: <author> Golea, M. and Marchand, M. </author> <year> 1993. </year> <title> Average case analysis of the clipped Hebb rule for nonoverlapping Perceptron networks. </title> <booktitle> In Proceedings of the Sixth Annual Conference on Computational Learning Theory (COLT-93), </booktitle> <pages> pages 151-157. </pages>
Reference: <author> Hagerup, T. and Rub, C. 1989/90. </author> <title> A guided tour of Chernoff bounds. </title> <journal> Information Processing Letters, </journal> <volume> 33 </volume> <pages> 305-308. </pages>
Reference: <author> Hampson, S. E. and Volper, D. J. </author> <year> 1986. </year> <title> Linear function neurons: Structure and training. </title> <journal> Biological Cybernetics, </journal> <volume> 53 </volume> <pages> 203-217. </pages>
Reference: <author> Hancock, T. and Mansour, Y. </author> <year> 1991. </year> <title> Learning monotone k DNF formulas on product distributions. </title> <booktitle> In Proceedings of the Fourth Annual Conference on Computational Learning Theory (COLT-91), </booktitle> <pages> pages 179-183. </pages>
Reference: <author> Haussler, D. </author> <year> 1988. </year> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 117-221. </pages> <address> BIBLIOGRAPHY 171 Haussler, D. </address> <year> 1992. </year> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications. </title> <journal> Information and Computation, </journal> 100:78-150. 
Reference: <author> Haussler, D., Kearns, M. J., and Schapire, R. </author> <year> 1991. </year> <title> Bounds on the sample complexity of Bayesian learning using information theory and the VC dimension. </title> <booktitle> In Proceedings of the Fourth Annual Conference on Computational Learning Theory (COLT-91), </booktitle> <pages> pages 61-74. </pages>
Reference: <author> Haussler, D., Kearns, M. J., Seung, H. S., and Tishby, N. </author> <year> 1994. </year> <title> Rigorous learning curve bounds from statistical mechanics. </title> <booktitle> In Proceedings of the Seventh Annual Conference on Computational Learning Theory (COLT-94), </booktitle> <pages> pages 76-87. </pages>
Reference: <author> Haussler, D., Littlestone, N., and Warmuth, M. K. </author> <year> 1988. </year> <title> Predicting f0,1g-functions on randomly drawn points. </title> <booktitle> In Proceedings of the Conference on Computational Learning Theory (COLT-88), </booktitle> <pages> pages 280-296. </pages>
Reference: <author> Haussler, D., Littlestone, N., and Warmuth, M. K. </author> <year> 1994. </year> <title> Predicting f0,1g-functions on randomly drawn points. </title> <journal> Information and Computation, </journal> <volume> 115 </volume> <pages> 248-292. </pages>
Reference: <author> Hinton, G. </author> <year> 1989. </year> <note> Unpublished lecture notes. </note>
Reference: <author> Hinton, G. </author> <year> 1995. </year> <type> Personal communication. </type>
Reference: <author> Jackson, J. </author> <year> 1994. </year> <title> An efficient membership-query algorithm for learning DNF with respect to the uniform distribution. </title> <booktitle> In Proceedings of the Thirty Fifth Annual IEEE Symposium on Foundations of Computer Science (FOCS-94), </booktitle> <pages> pages 42-52. </pages>
Reference: <author> Kearns, M. J. </author> <year> 1993. </year> <title> Efficient noise-tolerant learning from statistical queries. </title> <booktitle> In Proceedings of the Twenty Fifth Annual ACM Symposium on Theory of Computing (STOC-93), </booktitle> <pages> pages 392-401. </pages>
Reference: <author> Kearns, M. J. and Li, M. </author> <year> 1988. </year> <title> Learning in the presence of malicious errors. </title> <booktitle> In Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing (STOC-88), </booktitle> <pages> pages 267-280. </pages>
Reference: <author> Kearns, M. J., Li, M., Pitt, L., and Valiant, L. </author> <year> 1987a. </year> <title> On the learnability of boolean formulae. </title> <booktitle> In Proceedings of the Nineteenth Annual ACM Symposium on Theory of Computing (STOC-87), </booktitle> <pages> pages 285-295. </pages>
Reference: <author> Kearns, M. J., Li, M., Pitt, L., and Valiant, L. </author> <year> 1987b. </year> <title> Recent results on boolean concept learning. </title> <booktitle> In Proceedings of the Fourth International Conference on Machine Learning (ML-87), </booktitle> <pages> pages 337-352. </pages>
Reference: <author> Kearns, M. J. and Valiant, L. G. </author> <year> 1989. </year> <title> Cryptographic limitations on learning Boolean formulae and finite automata. </title> <booktitle> In Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing (STOC-89), </booktitle> <pages> pages 433-444. </pages>
Reference: <author> Kharitonov, M. </author> <year> 1993. </year> <title> Cryptographic hardness of distribution-specific learning. </title> <booktitle> In Proceedings of the Twenty Fifth Annual ACM Symposium on Theory of Computing (STOC-93), </booktitle> <pages> pages 372-381. </pages>
Reference: <author> Kolmogorov, A. N. and Tihomirov, V. M. </author> <year> 1961. </year> <title> *-entropy and *-capacity of sets in functional spaces. </title> <journal> Amer. Math. Soc. Transl. Ser. </journal> <volume> 2, 17 </volume> <pages> 277-364. </pages>
Reference: <author> Kulkarni, S. </author> <year> 1991. </year> <title> Problems of Computational and Information Complexity in Machine Vision and Learning. </title> <type> PhD thesis, </type> <institution> MIT, EECS Department. </institution>
Reference: <author> Langley, P., Iba, W., and Thompson, K. </author> <year> 1992. </year> <title> An analysis of Bayesian classifiers. </title> <booktitle> In Proceedings of the Tenth American National Conference on Artificial Intelligence (AAAI-92), </booktitle> <pages> pages 223-228. </pages>
Reference: <author> Larsen, R. J. and Marx, M. L. </author> <year> 1981. </year> <title> An Introduction to Mathematical Statistics and its Applications. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ. </address> <note> le Cun, </note> <author> Y., Boser, B., Denker, J. S., Henderson, D., Howard, D. E., Hubbard, W., and Jackel, L. D. </author> <year> 1989. </year> <title> Backpropagation applied to handwritten zip code recognition. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 541-551. </pages> <note> 172 BIBLIOGRAPHY Linial, </note> <author> N., Mansour, Y., and Nisan, N. </author> <year> 1989. </year> <title> Constant depth circuits, Fourier transform, and learnability. </title> <booktitle> In Proceedings of the Thirtieth Annual IEEE Symposium on Foundations of Computer Science (FOCS-89), </booktitle> <pages> pages 574-579. </pages>
Reference: <author> Linial, N., Mansour, Y., and Rivest, R. L. </author> <year> 1991. </year> <title> Results on learnability and the Vapnik-Chervonenkis dimension. </title> <journal> Information and Computation, </journal> <volume> 90 </volume> <pages> 33-49. </pages>
Reference: <author> Littlestone, N. </author> <year> 1988. </year> <title> Learning quickly when irrelevant attributes abound: A new linear threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 285-318. </pages>
Reference: <author> Littlestone, N. </author> <year> 1989. </year> <title> From online to batch learning. </title> <booktitle> In Proceedings of the Second Annual Conference on Computational Learning Theory (COLT-89), </booktitle> <pages> pages 269-284. </pages>
Reference: <author> Lyuu, Y.-D. and Rivin, I. </author> <year> 1992. </year> <title> Tight bounds on transition to perfect generalization in Perceptrons. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 854-862. </pages>
Reference: <author> Michalski, R. S. </author> <year> 1983. </year> <title> A theory and methodology of inductive learning. </title> <editor> In Michalski, R. S., Carbonell, J. G., and Mitchell, T. M., editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> pages 83-129. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address>
Reference: <author> Minsky, M. L. and Papert, S. A. </author> <year> 1969. </year> <title> Perceptrons. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Mitchell, T. M. </author> <year> 1980. </year> <title> The need for biases in learning generalizations. </title> <type> Technical Report CBM-TR-117, </type> <institution> Rutgers University. </institution>
Reference: <author> Nilsson, N. J. </author> <year> 1965. </year> <title> Learning Machines. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Oblow, E. M. </author> <year> 1992. </year> <title> Implementing Valiant's learnability theory using random sets. </title> <journal> Machine Learning, </journal> <volume> 8(1) </volume> <pages> 45-73. </pages>
Reference: <author> Opper, M. and Haussler, D. </author> <year> 1991. </year> <title> Generalization performance of Bayes optimal classification algorithm for learning a Perceptron. </title> <journal> Physical Review Letters, </journal> <volume> 66(20) </volume> <pages> 2677-2680. </pages>
Reference: <author> Pazzani, M. J. and Sarrett, W. </author> <year> 1990. </year> <title> Average case analysis of conjunctive learning algorithms. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning (ML-90), </booktitle> <pages> pages 339-347. </pages>
Reference: <author> Piatetsky-Shapiro, G. and Frawley, W. J., </author> <title> editors 1991. Knowledge Discovery in Databases. </title> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA. </address>
Reference: <author> Pitt, L. and Valiant, L. G. </author> <year> 1988. </year> <title> Computational limitations on learning from examples. </title> <journal> Journal of the ACM, </journal> <volume> 35(4) </volume> <pages> 965-984. </pages>
Reference: <author> Pollard, D. </author> <year> 1984. </year> <title> Convergence of Stochastic Processes. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference: <author> Purdom, P. W. J. and Brown, C. A. </author> <year> 1985. </year> <title> The Analysis of Algorithms. </title> <publisher> Holt, Rinehart and Winston, </publisher> <address> New York. </address>
Reference: <author> Qian, N. and Sejnowski, T. J. </author> <year> 1988. </year> <title> Predicting the secondary structure of globular proteins using neural network models. </title> <journal> Journal of Molecular Biology, </journal> <volume> 202 </volume> <pages> 865-884. </pages>
Reference: <author> Quinlan, J. R. </author> <year> 1986. </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106. </pages>
Reference: <author> Rivest, R. L. </author> <year> 1987. </year> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2(3) </volume> <pages> 229-246. </pages>
Reference: <author> Rosenstein, J. G. </author> <year> 1982. </year> <title> Linear Orderings. </title> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: <author> Schaffer, C. </author> <year> 1994. </year> <title> A conservation law for generalization performance. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning (ML-94), </booktitle> <pages> pages 259-265. </pages>
Reference: <author> Schapire, R. E. </author> <year> 1992. </year> <title> The Design and Analysis of Efficient Learning Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. BIBLIOGRAPHY 173 Schuurmans, D. </address> <year> 1995. </year> <title> Characterizing rational versus exponential learning curves. </title> <booktitle> In Proceedings of the Second European Conference on Computational Learning Theory (EuroCOLT-95), </booktitle> <pages> pages 272-286. </pages>
Reference: <author> Schuurmans, D. </author> <year> 1996a. </year> <title> Characterizing rational versus exponential learning curves. </title> <journal> Journal of Computer and System Sciences. </journal> <note> Invited submission to special issue. (Under review). </note>
Reference: <author> Schuurmans, D. </author> <year> 1996b. </year> <title> Fast distribution-specific learning. </title> <editor> In Greiner, R., Petsche, T., Hanson, S., and Rivest, R., editors, </editor> <booktitle> Computational Learning Theory and Natural Learning Systems, </booktitle> <volume> volume 4. </volume> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address> <publisher> (In press). </publisher>
Reference: <author> Schuurmans, D. and Greiner, R. </author> <year> 1995a. </year> <title> Practical PAC learning. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (IJCAI-95), </booktitle> <pages> pages 1169-1175. </pages>
Reference: <author> Schuurmans, D. and Greiner, R. </author> <year> 1995b. </year> <title> Sequential PAC learning. </title> <booktitle> In Proceedings of the Eighth Annual Conference on Computational Learning Theory (COLT-95), </booktitle> <pages> pages 377-384. </pages>
Reference: <author> Schwartz, D. B., Samalam, V. K., Solla, S. A., and Denker, J. S. </author> <year> 1990. </year> <title> Exhaustive learning. </title> <journal> Neural Computation, </journal> <volume> 2 </volume> <pages> 374-385. </pages>
Reference: <author> Seung, H. S., Sompolinsky, H., and Tishby, N. </author> <year> 1991. </year> <title> Learning curves in large neural networks. </title> <booktitle> In Proceedings of the Fourth Annual Conference on Computational Learning Theory (COLT-91), </booktitle> <pages> pages 112-127. </pages>
Reference: <author> Shawe-Taylor, J., Anthony, M., and Biggs, N. L. </author> <year> 1993. </year> <title> Bounding sample size with the Vapnik-Chervonenkis dimension. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 42 </volume> <pages> 65-73. </pages>
Reference: <author> Shiryayev, A. N. </author> <year> 1978. </year> <title> Optimal Stopping Rules. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference: <author> Valiant, L. G. </author> <year> 1984. </year> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142. </pages>
Reference: <author> Vapnik, V. N. and Chervonenkis, A. Y. </author> <year> 1971. </year> <title> On the uniform convergence of relative frequencies of events to their probabilities. </title> <journal> Theory of Probability and its Applications, </journal> <volume> 16(2) </volume> <pages> 264-280. </pages>
Reference: <author> Verbeurgt, K. </author> <year> 1990. </year> <title> Learning DNF under the uniform distribution in quasi-polynomial time. </title> <booktitle> In Proceedings of the Third Annual Conference on Computational Learning Theory (COLT-90), </booktitle> <pages> pages 314-326. </pages>
Reference: <author> Wald, A. </author> <year> 1947. </year> <title> Sequential Analysis. </title> <publisher> John Wiley & Sons, </publisher> <address> New York. </address>
Reference: <author> Wantanabe, S. </author> <year> 1987. </year> <title> Inductive ambiguity and the limits of artificial intelligence. </title> <journal> Computational Intelligence, </journal> <volume> 3(4) </volume> <pages> 304-309. </pages>
Reference: <author> Weiss, S. M. and Kulikowski, C. A. </author> <year> 1991. </year> <title> Computer Systems that Learn. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
References-found: 89

