URL: http://www.demo.cs.brandeis.edu/papers/shock_sab98.ps
Refering-URL: http://www.demo.cs.brandeis.edu/papers/long.html
Root-URL: http://www.cs.brandeis.edu
Email: blair@cs.uq.edu.au  sklar@cs.brandeis.edu  
Title: The evolution of subtle manoeuvres in simulated hockey  
Author: Alan D. Blair Elizabeth Sklar 
Address: 4072, Australia  Waltham, MA 02254, USA  
Affiliation: Dept. of Computer Science Electrical Engineering University of Queensland  Dept. of Computer Science Brandeis University  
Abstract: A simulated hockey environment is introduced as a test bed for studying adaptive behavior and evolution of robot controllers. A near-frictionless playing surface is employed, partially mimicking zero gravity conditions. We show how a neural network using a simple evolutionary algorithm can develop nimble strategies for moving about the rink and scoring goals quickly and effectively. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Angeline, P. & Pollack, J. </author> <year> (1992). </year> <title> Evolutionary induction of subroutines. </title> <booktitle> In Proc. 14th Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 236-241. </pages>
Reference-contexts: On the other hand, such adjustments run the risk of introducing artifacts which may distract the player from its main task <ref> (Angeline & Pollack, 1992) </ref>. For example, a player seeking partial credit might push the puck close to the goal without bothering to score, or it might hover close to the puck without touching it, for fear of moving it in the wrong direction.
Reference: <author> Balch, T. </author> <year> (1997). </year> <title> Learning roles: Behavioral diversity in robot teams. </title> <booktitle> AAAI 97 Workshop on Multiagent Learning. </booktitle>
Reference-contexts: One player may be controlled by a human user; all other players are controlled by the simulation software. Shock is similar in style to robot soccer simulators (Kitano et al., 1995; Salustowicz et al., 1998) and has much in common with <ref> (Balch, 1997) </ref>, also being implemented in Java. However, Shock differs from previous systems in some significant ways.
Reference: <author> Beer, R. </author> <year> (1996). </year> <title> Toward the evolution of dynamical neural networks for minimally cognitive behavior. </title> <editor> In (Maes et al., </editor> <year> 1996), </year> <pages> pp. 421-429. </pages>
Reference-contexts: These have included: avoiding obstacles (Xiao et al., 1997; Lee et al., 1996; Brooks, 1986), foraging for "food" (Werger & Mataric, 1996), playing pursuit/evasion games (Miller & Cliff, 1994), discriminating objects <ref> (Beer, 1996) </ref>, fighting for control of a cube (Sims, 1995) and RoboCup soccer (Kitano et al., 1995). Following in these traditions, we have developed a simulated hockey game called Shock which is rather like "table-top" or "air" hockey.
Reference: <author> Brooks, R. </author> <year> (1986). </year> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 2 </volume> <pages> 14-23. </pages>
Reference: <author> Elman, J. </author> <year> (1990). </year> <title> Finding structure in time. </title> <journal> Cognitive Science, </journal> <volume> 14 </volume> <pages> 179-211. </pages>
Reference-contexts: One of our objectives in building the system was to create an environment that could be used for comparing various machine learning techniques. The present work focuses on the following architectures: 1. simple recurrent <ref> (Elman, 1990) </ref> neural networks with 4, 6 and 8 hidden units 2. feed-forward networks with 6 and 8 hidden units 3. linear controller All these architectures use 12 inputs and 4 outputs.
Reference: <author> Funes, P., Sklar, E., Juille, H., & Pollack, J. </author> <year> (1998). </year> <title> Animal-animat coevolution: Using the animal population as fitness function. </title> <booktitle> In Proceedings of SAB-5. </booktitle>
Reference: <author> Haynes, T., Sen, S., Schoenefeld, D., & Wainwright, R. </author> <year> (1995). </year> <title> Evolving a team. </title> <booktitle> In AAAI 1995 Fall Symposium on Genetic Programming. </booktitle>
Reference: <author> Keller, H., Stolz, H., Ziegler, A., & Braunl, T. </author> <year> (1993). </year> <title> Virtual mechanics simulation and animation of rigid body systems. </title> <institution> Rept. Comp. Sci. Dept. </institution> <address> 8/93, U. Stuttgart. </address>
Reference-contexts: Each player has a rectangular body 150mm by 50mm and a mass of 500 grams. The puck is circular in shape with a radius of 25mm and a mass of 100 grams. Collisions between the players, puck and walls are calculated by the "spring" method of collision handling <ref> (Keller et al., 1993) </ref> and are totally elastic. This means that each experiences a restoring force in the normal direction, proportional to the depth of penetration. The puck collides frictionlessly with both players and walls, and therefore never acquires any spin.
Reference: <author> Kitano, H., Asada, M., Kuniyoshi, Y., Noda, I., & Osawa, E. </author> <year> (1995). </year> <title> Robocup: The robot world cup initiative. </title> <booktitle> In IJCAI-95 Workshop on Entertainment and AI/ALife. </booktitle>
Reference-contexts: These have included: avoiding obstacles (Xiao et al., 1997; Lee et al., 1996; Brooks, 1986), foraging for "food" (Werger & Mataric, 1996), playing pursuit/evasion games (Miller & Cliff, 1994), discriminating objects (Beer, 1996), fighting for control of a cube (Sims, 1995) and RoboCup soccer <ref> (Kitano et al., 1995) </ref>. Following in these traditions, we have developed a simulated hockey game called Shock which is rather like "table-top" or "air" hockey. One or more players engage in games with the aim of shooting a puck into the opposing goal during an allocated time period.
Reference: <author> Lee, W.-P., Hallam, J., & Lund, H. </author> <year> (1996). </year> <title> A hybrid gp/ga approach for co-evolving controllers and robot bodies to achieve fitness-specified tasks. </title> <booktitle> In Proc. 1996 IEEE Int'l Conf. Evolutionary Computation, </booktitle> <pages> pp. 384-389. </pages>
Reference: <editor> Maes, P., Mataric, M., Meyer, J.-A., Pollack, J., & Wilson, S. (Eds.) </editor> <booktitle> (1996). From Animals to Animats 4: Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press. </publisher>
Reference: <author> Miller, G. & Cliff, D. </author> <year> (1994). </year> <title> Protean behavior in dynamic games: Arguments for the co-evolution of pursuit-evasion tactics. </title> <booktitle> In Proceedings of the Third International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pp. 411-420. </pages>
Reference-contexts: These have included: avoiding obstacles (Xiao et al., 1997; Lee et al., 1996; Brooks, 1986), foraging for "food" (Werger & Mataric, 1996), playing pursuit/evasion games <ref> (Miller & Cliff, 1994) </ref>, discriminating objects (Beer, 1996), fighting for control of a cube (Sims, 1995) and RoboCup soccer (Kitano et al., 1995). Following in these traditions, we have developed a simulated hockey game called Shock which is rather like "table-top" or "air" hockey.
Reference: <author> Nechyba, M. & Xu, Y. </author> <year> (1994). </year> <title> Sm2 for new space station: autonomous locomotion and teleoperation control. </title> <booktitle> Proc. IEEE Int'l Conf. Robotics and Automation, </booktitle> <volume> 2 </volume> <pages> 1765-1771. </pages>
Reference-contexts: In work at CMU, the Self Mobile Space Manipulator (SM2) is being used to develop basic locomotion and manipulation capabilities for use on the international Space Station Freedom, with the ultimate goal of assisting astronauts during extravehicular activity and replacing astronauts in performing simple, dangerous or routine tasks <ref> (Nechyba & Xu, 1994) </ref>. 2. The Simulated Hockey Domain Shock is played in a rectangular rink, 1m wide by 1.5m long, with a goal at each end 150mm wide (Figure 1). Each player has a rectangular body 150mm by 50mm and a mass of 500 grams.
Reference: <author> Pollack, J. & Blair, A. </author> <year> (1998). </year> <title> Co-evolution in the successful learning of backgammon strategy. </title> <note> Machine Learning (to appear). </note>
Reference-contexts: After the champ's weights have been adjusted, two new GIC's are chosen for the new champ and the process continues. The practice of making only a small adjustment in the direction of the mutant was introduced in previous work on backgammon <ref> (Pollack & Blair, 1998) </ref> on the assumption that most of the strategies of the (well-tested) champion would be preserved, with only limited influence from the mutant since two games are not enough to determine for sure whether the mutant is really better, or just a lucky novice. 1 with standard deviation <p> Due to limited resources, each run was conducted once; ideally we would have executed each run several times and averaged the results. In earlier work on phased learning <ref> (Pollack & Blair, 1998) </ref>, we found that it is better to base the timing of the transition or annealing from one phase to another on internal diagnostics rather than at a pre-determined generation.
Reference: <author> Raibert, M., H.B. Brown, J., Chepponis, M., Hodgins, J., Koechling, J., Dustman, D., Brennan, W. K., Barrett, D., Thompson, C., Hebert, J., Lee, W., & Borvansky, L. </author> <year> (1989). </year> <title> Dynamically stable legged locomotion. </title> <type> AI technical report 1179, </type> <institution> MIT. </institution>
Reference-contexts: We note that the near-frictionless Shock environment mimics to some extent the conditions found in outer space. Lately, hardware designs that will sustain a robot operating in zero gravity have been investigated. The Zero-G robot <ref> (Raibert et al., 1989) </ref> was designed to operate in a weightless environment such as a space station, and relies on a system of parallel rebound surfaces in order to control its movement.
Reference: <author> Salustowicz, R., Wiering, M., & Schmidhuber, J. </author> <year> (1998). </year> <title> Learning team strategies: soccer case studies. </title> <note> Machine Learning (to appear). </note>
Reference: <author> Sims, K. </author> <year> (1995). </year> <title> Evolving 3d morphology and behavior by competition. </title> <booktitle> Proc. Artificial Life 4, </booktitle> <pages> pp. 28-39. </pages>
Reference-contexts: These have included: avoiding obstacles (Xiao et al., 1997; Lee et al., 1996; Brooks, 1986), foraging for "food" (Werger & Mataric, 1996), playing pursuit/evasion games (Miller & Cliff, 1994), discriminating objects (Beer, 1996), fighting for control of a cube <ref> (Sims, 1995) </ref> and RoboCup soccer (Kitano et al., 1995). Following in these traditions, we have developed a simulated hockey game called Shock which is rather like "table-top" or "air" hockey.
Reference: <author> Tesauro, G. </author> <year> (1992). </year> <title> Practical issues in temporal difference learning. </title> <journal> Machine Learning, </journal> <volume> 8 </volume> <pages> 257-277. </pages>
Reference-contexts: Exposing the player to a variety of initial conditions is important for developing robust strategies <ref> (Tesauro, 1992) </ref>. In the first two preliminary runs, the puck was constrained to always start in the middle third of the rink. <p> In subsequent runs, the puck was allowed to start anywhere in the upper two-thirds of the rink, which seems to provide an advantage because it enables players to learn the task "backwards from the end game" as is common in reinforcement learning <ref> (Tesauro, 1992) </ref>. What does it mean to do "better" than the champ? In theory, it should mean that the mutant is more likely to score goals than the champ.
Reference: <author> Werger, B. & Mataric, M. </author> <year> (1996). </year> <title> Robotic "food" chains: Externalization of state and program for minimal-agent foraging. </title> <editor> In (Maes et al., </editor> <year> 1996), </year> <pages> pp. 625-634. </pages>
Reference-contexts: These have included: avoiding obstacles (Xiao et al., 1997; Lee et al., 1996; Brooks, 1986), foraging for "food" <ref> (Werger & Mataric, 1996) </ref>, playing pursuit/evasion games (Miller & Cliff, 1994), discriminating objects (Beer, 1996), fighting for control of a cube (Sims, 1995) and RoboCup soccer (Kitano et al., 1995).
Reference: <author> Xiao, J., Michalewicz, Z., Zhang, L., & Trojanowski, K. </author> <year> (1997). </year> <title> Adaptive evolutionary planner/navigator for mobile robots. </title> <journal> IEEE Trans. Evol. Computation, </journal> <volume> 1(1) </volume> <pages> 18-28. </pages>
References-found: 20

