URL: ftp://ftp.idsia.ch/pub/juergen/bucketbrigade.ps.gz
Refering-URL: http://www.idsia.ch/~juergen/topics.html
Root-URL: 
Title: A Local Learning Algorithm for Dynamic Feedforward and Recurrent Networks  
Author: Jurgen Schmidhuber 
Keyword: recurrent networks, credit assignment, local computations, dissipative systems, internal feedback, external feedback, neural bucket brigade.  
Address: Arcisstr. 21, 8000 Munchen 2, Germany  
Affiliation: Institut fur Informatik Technische Universitat Munchen  
Note: Connection Science, 1(4):403-412, 1989. No figures!  
Email: schmidhu@tumult.informatik.tu-muenchen.de  
Phone: phone (089) 2105 2406  
Abstract: Most known learning algorithms for dynamic neural networks in non-stationary environments need global computations to perform credit assignment. These algorithms either are not local in time or not local in space. Those algorithms which are local in both time and space usually can not deal sensibly with `hidden units'. In contrast, as far as we can judge by now, learning rules in biological systems with many `hidden units' are local in both space and time. In this paper we propose a parallel on-line learning algorithm which performs local computations only, yet still is designed to deal with hidden units and with units whose past activations are `hidden in time'. The approach is inspired by Holland's idea of the bucket brigade for classifier systems, which is transformed to run on a neural network with fixed topology. The result is a feedforward or recurrent `neural' dissipative system which is consuming `weight-substance' and permanently trying to distribute this substance onto its connections in an appropriate way. Simple experiments demonstrating the feasability of the algorithm are reported.
Abstract-found: 1
Intro-found: 1
Reference: <author> Compiani, M., Montanari, D., Serra, R., and Valastro, G. </author> <year> (1989). </year> <title> Classifier systems and neural networks. </title> <editor> In Caianello, E. R., editor, </editor> <booktitle> 1st Workshop on Parallel Architectures and Neural Nets. </booktitle>
Reference-contexts: The justification for this is given by the fact that weights are modifiable, while the `specificity' of a classifier is not. (In <ref> (Compiani et al., 1989) </ref> Compiani, Montanari, Serra and Valastro consider more relationships between classifier systems and neural networks.) We certainly do not want to suggest that the brain uses a weight shifting mechanism for e.g. physically transporting transmitter substance from synapses of outgoing connections to synapses of incoming connections.
Reference: <author> Gherrity, M. </author> <year> (1989). </year> <title> A learning algorithm for analog fully recurrent neural networks. </title> <booktitle> In IEEE/INNS International Joint Conference on Neural Networks, San Diego, </booktitle> <volume> volume 1, </volume> <pages> pages 643-644. </pages>
Reference-contexts: 1 Introduction Various algorithms for supervised learning in recurrent non-equilibrium networks with non-stationary inputs and outputs have been proposed (Robinson and Fallside, 1987) (Williams and Zipser, 1988) (Pearlmutter, 1988) <ref> (Gherrity, 1989) </ref> (Rohwer, 1989). Apart from the fact that these algorithms require explicit teaching signals for the output units, there is a second reason which makes them biologically inplausible: They depend on global computations.
Reference: <author> Grossberg, S. </author> <year> (1976). </year> <title> Adaptive pattern classification and universal recoding, 1: Parallel develop-ment and coding of neural feature detectors. </title> <journal> Biological Cybernetics, </journal> <volume> 23 </volume> <pages> 187-202. </pages>
Reference-contexts: To come closer to asynchronous models from biology we now give up the assumption of predefined competitive subsets and of instant decay. To save the concept of winning units we explicitly introduce fixed inhibitory connections (e.g. a variant of the on-center-off-surround structure (see (Kohonen, 1988) and <ref> (Grossberg, 1976) </ref>). <p> The experiments described above share a rather simple nature. It remains to be seen how well the NBB can deal with more difficult problems, like the learning of motor control for autonomous agents in a changing environment. 5 Conclusion There is an analogy between the NBB and competitive learning <ref> (Grossberg, 1976) </ref>(Kohonen, 1988)(Rumelhart and Zipser, 1986). Competitive learning also can be interpreted as a shifting of weight substance. However, here it is the weakly contributing incoming connections to a unit that have to pay to the strongly contributing incoming connections.
Reference: <author> Holland, J. H. </author> <year> (1985). </year> <title> Properties of the bucket brigade. </title> <booktitle> In Proceedings of an International Conference on Genetic Algorithms. </booktitle> <address> Hillsdale, NJ. </address>
Reference-contexts: Holland <ref> (Holland, 1985) </ref> has proposed the meanwhile well-known bucket brigade algorithm for classifier systems. In this section we shortly review the main idea of this algorithm. Messages in form of bitstrings of size n can be placed on a global message list either by the environment or by entities called classifiers.
Reference: <author> Kohonen, T. </author> <year> (1988). </year> <title> Self-Organization and Associative Memory. </title> <publisher> Springer, second edition. </publisher>
Reference-contexts: To come closer to asynchronous models from biology we now give up the assumption of predefined competitive subsets and of instant decay. To save the concept of winning units we explicitly introduce fixed inhibitory connections (e.g. a variant of the on-center-off-surround structure (see <ref> (Kohonen, 1988) </ref> and (Grossberg, 1976)).
Reference: <author> Pearlmutter, B. A. </author> <year> (1988). </year> <title> Learning state space trajectories in recurrent neural networks. </title> <type> Technical report, </type> <institution> Dept. of Comp. Sci., Carnegie-Mellon Univ., Pittsburgh. </institution>
Reference-contexts: 1 Introduction Various algorithms for supervised learning in recurrent non-equilibrium networks with non-stationary inputs and outputs have been proposed (Robinson and Fallside, 1987) (Williams and Zipser, 1988) <ref> (Pearlmutter, 1988) </ref> (Gherrity, 1989) (Rohwer, 1989). Apart from the fact that these algorithms require explicit teaching signals for the output units, there is a second reason which makes them biologically inplausible: They depend on global computations.
Reference: <author> Robinson, A. J. and Fallside, F. </author> <year> (1987). </year> <title> Static and dynamic error propagation networks with ap-plication to speech coding. </title> <booktitle> Proceedings of Neural Information Processing Systems, American Institute of Physics. </booktitle>
Reference-contexts: 1 Introduction Various algorithms for supervised learning in recurrent non-equilibrium networks with non-stationary inputs and outputs have been proposed <ref> (Robinson and Fallside, 1987) </ref> (Williams and Zipser, 1988) (Pearlmutter, 1988) (Gherrity, 1989) (Rohwer, 1989). Apart from the fact that these algorithms require explicit teaching signals for the output units, there is a second reason which makes them biologically inplausible: They depend on global computations.
Reference: <author> Rohwer, R. </author> <year> (1989). </year> <title> The `moving targets' training method. </title> <editor> In Kindermann, J. and Linden, A., editors, </editor> <booktitle> Proceedings of `Distributed Adaptive Neural Information Processing', </booktitle> <address> St.Augustin, 24.-25.5,. </address> <publisher> Oldenbourg. </publisher>
Reference-contexts: 1 Introduction Various algorithms for supervised learning in recurrent non-equilibrium networks with non-stationary inputs and outputs have been proposed (Robinson and Fallside, 1987) (Williams and Zipser, 1988) (Pearlmutter, 1988) (Gherrity, 1989) <ref> (Rohwer, 1989) </ref>. Apart from the fact that these algorithms require explicit teaching signals for the output units, there is a second reason which makes them biologically inplausible: They depend on global computations.
Reference: <author> Rumelhart, D. E. and Zipser, D. </author> <year> (1986). </year> <title> Feature discovery by competitive learning. </title> <booktitle> In Parallel Distributed Processing, </booktitle> <pages> pages 151-193. </pages> <publisher> MIT Press. </publisher>
Reference: <author> Samuel, A. L. </author> <year> (1959). </year> <title> Some studies in machine learning using the game of checkers. </title> <journal> IBM Journal on Research and Development, </journal> <volume> 3 </volume> <pages> 210-229. </pages>
Reference-contexts: However, Sutton's temporal difference (TD-) methods (Sutton, 1988) (a generalization of both gradient descent methods and an old principle proposed by Samuel <ref> (Samuel, 1959) </ref>) might offer a framework for analyzing the NBB's convergence properties.
Reference: <author> Schmidhuber, J. H. </author> <year> (1989). </year> <title> The neural bucket brigade. </title> <editor> In Pfeifer, R., Schreter, Z., Fogelman, Z., and Steels, L., editors, </editor> <booktitle> Connectionism in Perspective, </booktitle> <pages> pages 439-446. </pages> <address> Amsterdam: </address> <publisher> Elsevier, North-Holland. </publisher>
Reference-contexts: As far as we can judge today, biological systems use completely local computations to accomplish complex spatio-temporal credit assignment tasks. However, the local learning rules proposed so far (like Hebb's rule) make sense only if there are no `hidden units'. In this paper (which is based on <ref> (Schmidhuber, 1989) </ref>) we want to demonstrate that local credit assignment with `hidden units' is no contradiction by itself, by giving a constructive example: We propose a method local in both space and time which is designed to deal with `hidden units' and with units whose past activations are `hidden in time'.
Reference: <author> Schmidhuber, J. H. </author> <year> (1990a). </year> <title> Networks adjusting networks. </title> <editor> In Kindermann, J. and Linden, A., editors, </editor> <booktitle> Proceedings of `Distributed Adaptive Neural Information Processing', </booktitle> <address> St.Augustin, 24.-25.5. </address> <year> 1989, </year> <pages> pages 197-208. </pages> <note> Oldenbourg. In November 1990 a revised and extended ver-sion appeared as FKI-Report FKI-125-90 (revised) at the Institut fur Informatik, </note> <institution> Technische Universitat Munchen. </institution>
Reference-contexts: This is the key feature used for relating present system states to past states. (Recently we have proposed another local learning scheme for recurrent networks where a relation between past and present states is established by a second adaptive network <ref> (Schmidhuber, 1990a) </ref> (Schmidhuber, 1990b).) Due to the local nature of all computations, the discrete time version of the NBB can easily be implemented such that the time complexity of one update cycle (activation changes and weight changes) is O (n) where n is the number of weights in the system.
Reference: <author> Schmidhuber, J. H. </author> <year> (1990b). </year> <title> Recurrent networks adjusted by adaptive critics. </title> <booktitle> In Proc. IEEE/INNS International Joint Conference on Neural Networks, Washington, </booktitle> <editor> D. C., </editor> <volume> volume 1, </volume> <pages> pages 719722. </pages>
Reference-contexts: This is the key feature used for relating present system states to past states. (Recently we have proposed another local learning scheme for recurrent networks where a relation between past and present states is established by a second adaptive network (Schmidhuber, 1990a) <ref> (Schmidhuber, 1990b) </ref>.) Due to the local nature of all computations, the discrete time version of the NBB can easily be implemented such that the time complexity of one update cycle (activation changes and weight changes) is O (n) where n is the number of weights in the system.
Reference: <author> Sutton, R. S. </author> <year> (1988). </year> <title> Learning to predict by the methods of temporal differences. </title> <journal> Machine Learning, </journal> <volume> 3 </volume> <pages> 9-44. </pages>
Reference-contexts: A Local Learning Algorithm 5 3.1 The NBB and Temporal Difference Methods It seems to be unlikely that the NBB performs gradient descent in some sensible global error measure. However, Sutton's temporal difference (TD-) methods <ref> (Sutton, 1988) </ref> (a generalization of both gradient descent methods and an old principle proposed by Samuel (Samuel, 1959)) might offer a framework for analyzing the NBB's convergence properties.
Reference: <author> Williams, R. J. and Zipser, D. </author> <year> (1988). </year> <title> A learning algorithm for continually running fully recurrent networks. </title> <type> Technical Report ICS Report 8805, </type> <institution> Univ. of California, </institution> <address> San Diego, La Jolla. </address>
Reference-contexts: 1 Introduction Various algorithms for supervised learning in recurrent non-equilibrium networks with non-stationary inputs and outputs have been proposed (Robinson and Fallside, 1987) <ref> (Williams and Zipser, 1988) </ref> (Pearlmutter, 1988) (Gherrity, 1989) (Rohwer, 1989). Apart from the fact that these algorithms require explicit teaching signals for the output units, there is a second reason which makes them biologically inplausible: They depend on global computations. <p> The second input unit served to provide stop-signals: Its activation had to be answered by a stationary output of the third output unit. The learning procedure for this problem demonstrates how `teacher forcing' (applied by Williams and Zipser to a similar problem <ref> (Williams and Zipser, 1988) </ref> ) can be incorporated into the NBB in a straight-forward manner: Instead of using the actual activations of the output units at time t for computing the outputs at time t + 1, the desired activations at time t were used.
References-found: 15

