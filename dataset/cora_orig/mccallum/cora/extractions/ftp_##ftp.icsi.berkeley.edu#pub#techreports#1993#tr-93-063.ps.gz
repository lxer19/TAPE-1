URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1993/tr-93-063.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1993.html
Root-URL: http://www.icsi.berkeley.edu
Title: for providing the advice, support and encouragement throughout the years, and for directing me to
Author: my advisors Abhiram Ranade and Jerry Feldman 
Note: iii Acknowledgements I would like to thank  This thesis is dedicated to everyone who has made it possible.  
Abstract: I would like to acknowledgement the financial support from the International Computer Science Institute (ICSI) during the last three years. The pSather research reported here is done on a CM-5 supported under National Science Foundation Infrastructure Grant number CDA-8722788. It has been a privilege and an experience for me to participate in the Sather/pSather project at ICSI. This is especially so because it is not everyday that a graduate student gets to learn from and interact with researchers in a dynamic and stimulating research institution. The congenial environment is more than what a graduate student could hope for and has helped me tremendously. It would be outright blasphemy if this thesis gives an impression that it is solely my work. Therefore, I would like to acknowledge the contributions of the direct participants of the Sather/pSather project | Jeff Bilmes, Ben Gomes, Franco Mazzanti, Stephan Murer, Steve Omo-hundro, Thomas Rauber, Hans Rohnert, Heinz Schmidt, David Stoutamire and Jerry Feldman. I would also like to thank Stephan Murer, Ben Gomes, Jeff Bilmes and David Stoutamire for suffering through early drafts of this thesis. Steve and Heinz has continually provided feedback on various pSather designs. Steve's design of Sather has helped to shape pSather. The revised Sather 1.0 language has also stretched the functionalities of the parallel constructs not previously possible. Furthermore, the various parallel programs described here have made use of his sequential class libraries. And this is not to forget the help of my "big boss" and advisor Jerry Feldman who heads the pSather group. His faith and trust has allowed me to keep my own pace and to enjoy my work. And of course, I have to thank my friends from Stanford and Berkeley | Lubna Alsagoff, Ang Boon Seong, Kinson Ho, Lim Chong Hai, Loh Wei Liem, Poh Hean Lee and Yue Ming Bao, for their support and lunch/dinner reprieves. For those friends who do not find their name here, I haven't forgotten about you but am only trying to protect the privacy of your name. Finally, I would like to thank my parents for their patience and support, and for putting their children's interests before anything else at all times. It has indeed been a long time to be away from home, considering that I was ineligible to vote when I came to the States for my undergrad studies and now I've missed my chance to vote twice. I'm grateful to my brothers for keeping my parents company during this period. The emotional support has remained strong in spite of the physical distance of home (unlike Newton's laws of gravitation). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal, A. K. Chandra, and M. Snir. </author> <title> On Communication Latency in PRAM Computation. </title> <booktitle> In Proceedings of the ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 11-21, </pages> <month> June </month> <year> 1989. </year>
Reference: [2] <author> Gul Agha. </author> <title> Actors: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> The MIT Press, </publisher> <address> Cambridge Massachusetts, </address> <year> 1986. </year>
Reference-contexts: This prevents a subclass from inheriting the body code from its superclass. If there is multiple inheritance, it becomes more complicated as to how body codes from different superclasses should be combined. Actor languages may also have textually distributed next-message-set specification. For example, in Act3 <ref> [2] </ref> each routine uses the become operation to give a replacement behaviour; the new behaviour controls the next set of messages which can be received. 6 Routines therefore have two parts | a computation and a synchronization part (giving the next set of receivable messages). <p> The approach with first-class thread objects is flexible because it does not require any language extensions and allows different thread and synchronization objects, and scheduling strategies to be implemented according to the programmer's needs. The actor approach offers a well-studied theoretical concurrent object-oriented model <ref> [71, 2] </ref>, but is not without its problems (e.g. inheritance anomaly and efficient implementation). PSather follows the model with passive objects and threads as independent loci of control, and has thread creation constructs (Section 2.3). <p> We also did not adopt the actor model <ref> [2] </ref> because of the performance costs of maintaining a message queue for each object, and disallowing parallel operations (e.g. reads) on an object. These costs conflict with pSather's design goal to be suitable for efficient implementations.
Reference: [3] <author> Gul Agha. </author> <title> Concurrent Object-Oriented Programming. </title> <journal> Communications of the ACM, </journal> <volume> 33(9) </volume> <pages> 125-141, </pages> <month> September </month> <year> 1990. </year>
Reference: [4] <author> Gul Agha and Carl Hewitt. </author> <title> Actors: A conceptual foundation for concurrent object-oriented programming. </title> <editor> In Bruce Shriver and Peter Wegner, editors, </editor> <booktitle> Research Directions in Object-Oriented Programming. </booktitle> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1987. </year>
Reference: [5] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques and Tools. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1986. </year>
Reference-contexts: Since our aim is to provide a relatively stable prototype to further experiment with writing parallel applications (in pSather), the compiler is implemented in a relatively straight-forward manner using standard techniques such as those found in <ref> [5, 218] </ref> and is itself not fully optimized. <p> example, a function call fn is marked "in" because its return value may exist before r is called (e.g. the return value may be a pointer to an object stored in some global data structure). 27 This has nothing to do with in/out sets of basic blocks in compiler optimization <ref> [5] </ref>. In our analysis, we are computing a property of a variable. 155 The in/out status of variables and expressions interact as follows. Local variables get their initial in/out status from their initializing expressions. When variables are used, their in/out status are further updated.
Reference: [6] <author> Eugene Albert, Joan D. Lukas, and Guy L. Steele Jr. </author> <title> Data Parallel Computers and the FORALL Statement. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13 </volume> <pages> 185-192, </pages> <year> 1991. </year>
Reference-contexts: There are five characteristics to note for pSather's style of data-parallelism. * The so-called "data" which are operated upon in parallel are actually large-grained chunks (e.g. tree, array) consisting of finer-grained data (e.g. tree nodes, array elements). * Although data-parallelism was previously associated with the execution mode of SIMD machines <ref> [6] </ref>, the dist statement moves away from this association to an SPMD form of data-parallelism in which parallel threads execute the same piece of code on different chunks, but not necessarily in lock-step. * The execution of body code is co-located with the cluster location of the corresponding chunk to ensure
Reference: [7] <author> Pierre America. </author> <title> Inheritance and Subtyping in a Parallel Object-Oriented Language. </title> <booktitle> In ECOOP 1987, European Conference on Object-Oriented Programming LNCS 276, </booktitle> <pages> pages 234-242. </pages> <publisher> Springer-Verlag, </publisher> <month> June 15-17 </month> <year> 1987. </year>
Reference-contexts: The declaration "x:A;" says that x will hold only A objects. After some experience with Sather 0.1, we found that the language would be more expressive if subtyping and code inheritance are treated separately. (Similarly, America <ref> [7] </ref> have argued that inheritance is an implementation mechanism and should not be confused with subtyping, but none of the popular object-oriented languages adopts this separation.) Sather 1.0 introduces abstract classes for subtyping. 5 Abstract classes are used to specify the type of variables.
Reference: [8] <author> Pierre America. </author> <title> Issues in the Design of a Parallel Object-Oriented Language. </title> <institution> Philips Research Laboratories, Eindhoven and University of Amsterdam, </institution> <month> March 1 </month> <year> 1989. </year> <title> Part of POOL2/PTC Distribution Package. </title>
Reference-contexts: There is no way for a programmer to directly manipulate a thread. This is the approach taken by the actor class of languages ([4],[3]). For example, in ABCL [231] and POOL2 (Parallel Object-Oriented Language <ref> [8] </ref>), when an object is created, it also becomes active 4 As we are preparing for a description of pSather in the next sections, we will try to rephrase ideas in our own terminology when appropriate. 16 with a thread acting as a server. <p> In this design, the object-oriented term "message passing" in pSather does not involve communication between threads but has procedure invocation semantics instead; we might view it as message-passing between passive objects rather than between threads. PSather does not need message-passing forms of parallel constructs like actors in POOL2 <ref> [8] </ref>, broadcast in Orca [21], or asynchronous reply in Natasha [78] and ConcurrentSmalltalk [230]. In pSather, sequential routine calls are viewed as the default synchronous mode of message-passing while the thread creation corresponds to asynchronous message-passing. <p> of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette [217], POOL2 <ref> [8, 9, 10] </ref>. We have however described some of their more interesting characteristics earlier. Parallel Versions of Smalltalk We first look at some parallel implementations of Smalltalk. Distributed Smalltalk Bennett [31] describes an implementation of Distributed Smalltalk on a network of Sun 2 workstations.
Reference: [9] <author> Pierre America. </author> <title> Programmer's Guide for POOL2. </title> <institution> Philips Research Laboratories, Eindhoven and University of Amsterdam, </institution> <month> January 10 </month> <year> 1991. </year> <title> Part of POOL2/PTC Distribution Package. </title>
Reference-contexts: of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette [217], POOL2 <ref> [8, 9, 10] </ref>. We have however described some of their more interesting characteristics earlier. Parallel Versions of Smalltalk We first look at some parallel implementations of Smalltalk. Distributed Smalltalk Bennett [31] describes an implementation of Distributed Smalltalk on a network of Sun 2 workstations. <p> This is similar to the strategy adopted by compilers by several other languages such as Standard ML [213], Scheme [26] and POOL2 <ref> [9] </ref>. The advantages of using C are obvious. Because of C's widespread availability, it is relatively easy to port the compiler. We can also take advantage of low-level optimizations (e.g. register allocation) performed by the C compiler.
Reference: [10] <author> Pierre America and Ben Hulshof. </author> <title> Definition of POOL2/PTC, a Parallel Object-Oriented Language. </title> <institution> Philips Research Laboratories, Eindhoven and University of Amsterdam, </institution> <month> March 15 </month> <year> 1991. </year> <title> Part of POOL2/PTC Distribution Package. </title> <type> 295 </type>
Reference-contexts: of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette [217], POOL2 <ref> [8, 9, 10] </ref>. We have however described some of their more interesting characteristics earlier. Parallel Versions of Smalltalk We first look at some parallel implementations of Smalltalk. Distributed Smalltalk Bennett [31] describes an implementation of Distributed Smalltalk on a network of Sun 2 workstations.
Reference: [11] <author> J.P. Anderson, J.A. Hoffman, J. Shifman, and R.J. williams. </author> <title> D825 A Multiple-Computer System for Command and Control. </title> <booktitle> AFIPS Conference Proceedings, </booktitle> <volume> 22 </volume> <pages> 86-96, </pages> <year> 1962. </year>
Reference: [12] <author> Thomas E. Anderson. </author> <title> Fastthreads user's manual. FastThreads software package manual, </title> <month> January </month> <year> 1990. </year>
Reference-contexts: It is hoped that using C will make it easier to port the runtime system to different multiprocessors. We would like to acknowledge that the pSather runtime relies on several sources. These include (a) Sather runtime system, (b) the FastThreads package <ref> [12] </ref>, and in the CM-5 implementation, (c) the CMAM active message package [226]. We describe the functionalities of the major components in the runtime system and how they are inter-related. Active Message Layer.
Reference: [13] <author> Andrew W. Wilson, Jr. and Richard P. LaRowe, Jr. </author> <title> Hiding Shared Memory Reference Latency on the Galactica Net Distributed Shared Memory Architecture. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 15 </volume> <pages> 351-367, </pages> <year> 1992. </year>
Reference-contexts: We feel that the cluster model (distributed memory, shared address space) is a justifiable choice because many parallel architectures are converging to this characterisation, and scalability and programmability considerations have led to many efforts at supporting distributed shared memory (e.g. <ref> [38, 13] </ref>). 40 The first implementation of pSather was on a Sequent Symmetry. 97 Chapter 3 Implementation This chapter describes the implementation of pSather. It is divided into the following sections. Section 3.1 gives an overview of the implementation strategies followed by a rough outline of the compilation process.
Reference: [14] <author> Gregory R. Andrews and Fred B. Schneider. </author> <title> Concepts and Notations for Concurrent Programming. </title> <journal> ACM Computing Surveys, </journal> <volume> 15(1) </volume> <pages> 3-43, </pages> <month> March </month> <year> 1983. </year>
Reference-contexts: An example is the bounded buffer 5 for which we want a thread performing a get (put) routine to wait until the buffer is non-empty (non-full). There are two general approaches to achieving synchronization among threads <ref> [14] </ref> | shared data or message-passing. An example of the shared data approach is the use of monitors ([136, 227]) in Concurrent Pascal ([120, 123]) and Mesa [154].
Reference: [15] <author> A. W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: ABCL/1 does not have class inheritance, but supports delegation using a form of continuation-passing <ref> [15] </ref>. The "continuation-passing" works as follows. When an object O1 receives a message, it also gets an object R (called the reply destination) to which O1 sends its reply. <p> The continuation after E may be in the continuation state (and hence determined at execution time), or statically fixed in E's exit code. Continuation-passing is a well-known compilation technique <ref> [15] </ref>, but to our knowledge, it has not been extensively applied in compiling parallel object-oriented languages. We feel that it may be worthwhile to explore the use of continuation-passing techniques in compiling a parallel object-oriented language such as pSather.
Reference: [16] <author> Ziya Aral, Ilya Gertner, and Greg Shaffer. </author> <title> Efficient Debugging Primitives for Multiprocessors. </title> <booktitle> In Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 87-93, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: For example, 279 setting breakpoints may be to measure the frequency of routine calls (performance monitoring), or to check whether the calls satisfy a certain predicate (debugging). This idea of providing a tool that observes the program behavior is not new, e.g. Parasight <ref> [16] </ref> was a research effort that aims to support "programming for observability". Because performance monitoring and debugging share common aims ("provide information on program behavior"), they also share common research issues such as parallel program visualization [177] (or even auralization).
Reference: [17] <author> Arvind and R.S. Nikhil. </author> <title> Executing a Program on the MIT Tagged-Token Dataflow Architecture. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(3) </volume> <pages> 300-318, </pages> <month> March </month> <year> 1990. </year> <note> Also available as: Computation Structures Group Memo 271, </note> <month> March </month> <year> 1987, </year> <institution> Laboratory for Computer Science, Massachusetts Institute of Technology. </institution>
Reference: [18] <author> Krste Asanovic, James Beck, Tim Callahan, Jerry Feldman, Bertrand Irissou, Brian Kingsbury, Phil Kohn, John Lazzaro, Nelson Morgan, David Stoutamire, and John Wawrzynek. </author> <title> CNS-1 Architecture Specification. </title> <type> Technical Report TR-93-021, </type> <institution> International Computer Science Institute, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: The "loosely synchronous data parallelism" breaks away from SIMD execution and is similar to our approach. dpSather's fine-grain approach is more suitable for vector machines. For distributed-memory multiprocessors with vector units (e.g. CM-5 [76], CNS-1 <ref> [18] </ref>), pSather will have to be extended further and/or borrow ideas from dpSather's fine-grain data-parallelism, so that the user can both distribute data and make use of vector operations. 2.8.5 Target Systems In the design of parallel languages, there are inevitably some implicit assumptions on the characteristics of the ideal target
Reference: [19] <author> Colin Atkinson et al. </author> <title> Object-oriented concurrency and distribution in dragoon. </title> <type> Technical Report Research Report DoC 89/3, </type> <institution> Imperial College, </institution> <month> June </month> <year> 1989. </year>
Reference-contexts: To reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon <ref> [19] </ref>, Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier.
Reference: [20] <author> Henry G. Baker. </author> <title> Inlining Semantics for Subroutines which are Recursive. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 27(12) </volume> <pages> 39-46, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Baker <ref> [20] </ref> notes that an inline pragma for routine r can apply all or selected occurrences of r and argues that the latter case gives the programmer more flexibility. <p> If it is empty, inline expansion is finished. If it is non-empty and the previous loop has not caused at least 26 Baker <ref> [20] </ref>, in pointing out the subtle "semantics" of inlining, describes several straight-forward strategies that might not inline nested routines correctly. 152 one routine to be inlined, then there is a cycle among the inline routines. Otherwise, we repeat the previous step again with a now smaller set S.
Reference: [21] <author> Henri E. Bal, Andrew S. Tanenbaum, and M. Frans Kaashoek. Orca: </author> <title> A language for distributed programming. </title> <journal> SIGPLAN Notices, </journal> <volume> 25(5) </volume> <pages> 17-24, </pages> <year> 1990. </year>
Reference-contexts: PSather does not need message-passing forms of parallel constructs like actors in POOL2 [8], broadcast in Orca <ref> [21] </ref>, or asynchronous reply in Natasha [78] and ConcurrentSmalltalk [230]. In pSather, sequential routine calls are viewed as the default synchronous mode of message-passing while the thread creation corresponds to asynchronous message-passing. <p> This means that the runtime system has to keep track of the activation records of every movable object; this might entail high runtime costs. Jul et al. [146] describes how to reduce such costs and what to update when activation records are moved. Other Languages Orca Orca <ref> [21, 212] </ref> is targeted to deal with network latency in distributed systems. It provides a shared data-object model with passive objects and explicit threads (processes). Processes are created using the fork statement.
Reference: [22] <author> G.H. Barnes, R.M. Brown, M. Kato, D.J. Kuck, D.L. Slotnick, and R.A. </author> <title> Stokes. The ILLIAC IV computer. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-17:746-757, </volume> <year> 1968. </year>
Reference: [23] <author> J.G.P. Barnes. </author> <title> An Overview of Ada. </title> <journal> Software Practice and Experience, </journal> <volume> 10(11) </volume> <pages> 851-887, </pages> <year> 1980. </year> <month> 296 </month>
Reference: [24] <author> Paul S. Barth. </author> <title> Atomic Data Structures for Parallel Computing. </title> <type> PhD thesis, </type> <institution> MIT, MIT Laboratory for Computer Science, </institution> <address> Cambridge, MA 02139, </address> <month> March </month> <year> 1992. </year> <note> Also available as technical report MIT/LCS/TR-532. </note>
Reference-contexts: Since our construct is quite different, using "GATE" avoids any preconceived misconceptions. A unique term also allows us to discuss more clearly the differences and similarities of our construct with other synchronization constructs, such as M-structures <ref> [24, 25] </ref> and monitors [136, 227]. 35 to 2.3.4. Then in Section 2.3.5 we point out the (minor) differences between GATEfTg and GATE0. <p> Section 2.8.5 discusses its implications for suitable target systems for pSather. 2.8.1 GATE Classes vs. Other Synchronization Primitives The GATE classes are the main synchronization mechanisms in pSather. They provide functionalities which closely parallel other synchronization constructs in other languages, such as M-structures <ref> [24] </ref> in Id, and monitors in Mesa and Concurrent Pascal ([154, 120, 123, 136, 227, 50]) Monitors PSather gates were previously called monitors [97] because of their similarity with the monitor concept in Mesa [154] and Concurrent Pascal [123].
Reference: [25] <author> Paul S. Barth, Rishiyur S. Nikhil, and Arvind. M-Structures: </author> <title> Extending a Parallel, Non-Strict, Functional Language with State. </title> <booktitle> In Functional Programming Languages and Computer Architecture, 5th ACM Conference Proceedings, Lecture Notes in Computer Science 523, </booktitle> <pages> pages 538-568, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Since our construct is quite different, using "GATE" avoids any preconceived misconceptions. A unique term also allows us to discuss more clearly the differences and similarities of our construct with other synchronization constructs, such as M-structures <ref> [24, 25] </ref> and monitors [136, 227]. 35 to 2.3.4. Then in Section 2.3.5 we point out the (minor) differences between GATEfTg and GATE0.
Reference: [26] <author> Joel F. Bartlett. </author> <title> SCHEME ! C a Portable Scheme-to-C Compiler. </title> <type> Technical Report 89/1, </type> <institution> Digital Western Research Laboratory, </institution> <address> 100 Hamilton Avenue, Palo Alto, CA 94301, </address> <month> January </month> <year> 1989. </year>
Reference-contexts: This is similar to the strategy adopted by compilers by several other languages such as Standard ML [213], Scheme <ref> [26] </ref> and POOL2 [9]. The advantages of using C are obvious. Because of C's widespread availability, it is relatively easy to port the compiler. We can also take advantage of low-level optimizations (e.g. register allocation) performed by the C compiler.
Reference: [27] <author> Bob Beck. </author> <title> Shared-Memory Parallel Programming in C++. </title> <journal> IEEE Software, </journal> <pages> pages 38-48, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries <ref> [94, 33, 27, 90] </ref>), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier. Parallel Versions of Smalltalk We first look at some parallel implementations of Smalltalk.
Reference: [28] <author> Adam Beguelin, Jack Dongarra, Al Geist, Robert Manchek, and Vaidy Sunderam. </author> <title> A Users' Guide to PVM Parallel Virtual Machine. </title> <type> Technical Report ORNL/TM-11826, </type> <institution> Oak Ridge National Laboratory, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: To ensure portability, one approach is for pSather to implement its user-level threads using a common standard (e.g. POSIX threads [143, 179]) and to use the common message library (e.g. PVM <ref> [28] </ref>) for it runtime messages. 282 However a POSIX thread may still be too expensive (e.g. to implement remote calls). And our prototype suggests that a light-weight, low-latency active message package is more suitable than message libraries such as PVM.
Reference: [29] <author> G. Bell, R. Cady, H. McFarland, B. Delagi, J. O'Laughlin, R. Noonan, and W. Wulf. </author> <title> A New Architecture for Mini-Computers: The DEC PDP-11. </title> <editor> In Daniel P. Siewiorek, C. Gordon Bell, and Allen Newell, editors, </editor> <booktitle> Computer Structures: Principles and Examples, </booktitle> <pages> pages 649-665. </pages> <address> McCraw-Hill, </address> <publisher> Inc., </publisher> <year> 1982. </year>
Reference: [30] <author> M. Ben-Ari. </author> <title> Principles of Concurrent Programming. </title> <publisher> Prentice Hall International, Inc., </publisher> <year> 1982. </year>
Reference-contexts: An example of the shared data approach is the use of monitors ([136, 227]) in Concurrent Pascal ([120, 123]) and Mesa [154]. In this approach, the mechanisms to achieve lock protection include semaphores [88] and protection of critical sections by Dekker's algorithm <ref> [30] </ref>, while a construct which provides conditional wait is the condition variables (originally proposed together with the monitor concept [136]).
Reference: [31] <author> John K. Bennett. </author> <title> The Design and Implementation of Distributed Smalltalk. </title> <booktitle> In OOPSLA '87 Conference Proceedings, </booktitle> <pages> pages 318-330, </pages> <month> October 4-8 </month> <year> 1987. </year> <title> Proceedings also published as: </title> <journal> SIGPLAN Notices, </journal> <volume> Vol 22, No 12, </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: We have however described some of their more interesting characteristics earlier. Parallel Versions of Smalltalk We first look at some parallel implementations of Smalltalk. Distributed Smalltalk Bennett <ref> [31] </ref> describes an implementation of Distributed Smalltalk on a network of Sun 2 workstations. It aims to support a multi-user environment and to allow interaction among multiple processes on different workstations. It does not contain any language extension to Smalltalk.
Reference: [32] <author> John K. Bennett, John B. Carter, and Willy Zwaenepoel. Munin: </author> <title> Shared Memory for Distributed Memory Multiprocessors. </title> <type> Technical Report TR89-91, </type> <institution> Department of Computer Science, Rice University, </institution> <address> P. O. Box 1892, Houston, Texas 77251-1892, </address> <month> April </month> <year> 1989. </year>
Reference-contexts: It is a runtime error to perform two or more simultaneous broadcasts on the same shared feature x. 2.5.5 Discussion In order to support a shared memory programming model, many systems (e.g. Munin <ref> [32, 60] </ref>, Midway [34]) provide a set of common consistency protocols to support distributed shared memory. These consistency protocols are predefined and built into the system. The advantage of an object-oriented system is that users can build their own set of consistency protocols based on the needs of the application. <p> It is also an example of how the programmer can flexibly build a memory consistency protocol based on the needs of the program and not rely on the system to provide a set of predefined protocols (e.g. Munin <ref> [60, 32] </ref>). The hash table can be used as either a map or set abstraction and is useful in the following general situation: The computation has a monotonically increasing global state which consists of the results of different threads. These results are associated with unique integer id's.
Reference: [33] <author> Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy. </author> <title> PRESTO: A System for Object-Oriented Parallel Programming. </title> <journal> Software Practice and Experience, </journal> <volume> 18(8) </volume> <pages> 713-732, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Processes/Threads In order for parallelism to exist, independent processes (or threads 4 of control) must be created to execute concurrently. There are three main views of threads in an object-oriented language. A thread may be treated as a first-class object in the system (e.g. PRESTO <ref> [33] </ref>), just like any other data objects. In this case, routines (or methods in traditional OO terminology) are defined in the threads class to activate, suspend and perform other synchronization operations (e.g. fork-join) on the threads. New types of threads can be defined via class inheritance. <p> reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries <ref> [94, 33, 27, 90] </ref>), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier. Parallel Versions of Smalltalk We first look at some parallel implementations of Smalltalk. <p> After retrieving the result, g.clear is called. A thread that finds that CONFIG::clear request is "true" can then self-abort. 17 We have so far only assumed a uniform shared memory model. In such a model, various runtime systems <ref> [215, 33] </ref> have demonstrated the feasibility of good load balancing techniques. Therefore the deferred assignment statement only provides the functionality of thread creation and leaves load balancing to the runtime system.
Reference: [34] <author> Brian N. Bershad and Matthew J. Zekauskas. Midway: </author> <title> Shared Memory Parallel Programming with Entry Consistency for Distributed Memory Multiprocessors. </title> <type> Technical Report CMU-CS-91-170, </type> <institution> School of Computer Science,Carnegie Mellon University, </institution> <address> Pittsburgh, PA 15213, </address> <month> September </month> <year> 1991. </year> <month> 297 </month>
Reference-contexts: It is a runtime error to perform two or more simultaneous broadcasts on the same shared feature x. 2.5.5 Discussion In order to support a shared memory programming model, many systems (e.g. Munin [32, 60], Midway <ref> [34] </ref>) provide a set of common consistency protocols to support distributed shared memory. These consistency protocols are predefined and built into the system. The advantage of an object-oriented system is that users can build their own set of consistency protocols based on the needs of the application.
Reference: [35] <author> Andrew D. Birrell. </author> <title> An Introduction to Programming with Threads. </title> <type> Technical Report SRC Research Report 35, </type> <institution> DEC Systems Research Center, </institution> <address> 130 Lytton Avenue, Palo Alto, California 94301, </address> <month> January </month> <year> 1989. </year>
Reference-contexts: We are not aware of any parallel language that supports a shared-address model for both shared-memory and distributed-memory multiprocessors, and makes NUMA an integral part of the language design. In addition to the usual control-parallel constructs (e.g. threads <ref> [35] </ref>), pSather also supports a form of data-parallelism [131] (Section 2.6) which is usable for both irregular, dynamic data structures (e.g. trees) and the regular arrays. It decouples the execution model from the execution mode of single-instruction-multiple-data (SIMD) machines.
Reference: [36] <author> Andrew D. Birrell, Roy Levin, Roger M. Needham, and Michael D. Schroder. Grapevine: </author> <title> An Exercise in Distributed Computing. </title> <journal> Communications of the ACM, </journal> <volume> 25(4) </volume> <pages> 260-274, </pages> <month> April </month> <year> 1982. </year>
Reference: [37] <author> Christian H. Bischof and Jack J. Dongarra. </author> <title> A Linear Algebra Library for High-Performance Computers. </title> <editor> In Graham F. Carey, editor, </editor> <booktitle> Parallel Supercomputing: Methods, Algorithms and Applications, </booktitle> <pages> pages 45-55. </pages> <publisher> John Wiley & Sons Ltd., </publisher> <year> 1989. </year>
Reference-contexts: For parallel programs, sofeware reuse is especially relevant because of the difficulty of writing efficient, parallel code. This is why efforts are spent on building libraries (e.g. LAPACK <ref> [37, 91] </ref>, CMSSL [75]). Such efforts however focus mainly on numerical algorithms and not on symbolic algorithms and irregular data structures. One might argue that if a program can be ported to different architectures with relatively little effort, one is already achieving software reuse.
Reference: [38] <author> Roberto Bisiani and Mosur Ravishankar. </author> <title> PLUS: A Distributed Shared-Memory System. </title> <booktitle> In Proc. 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 115-124, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: We feel that the cluster model (distributed memory, shared address space) is a justifiable choice because many parallel architectures are converging to this characterisation, and scalability and programmability considerations have led to many efforts at supporting distributed shared memory (e.g. <ref> [38, 13] </ref>). 40 The first implementation of pSather was on a Sequent Symmetry. 97 Chapter 3 Implementation This chapter describes the implementation of pSather. It is divided into the following sections. Section 3.1 gives an overview of the implementation strategies followed by a rough outline of the compilation process.
Reference: [39] <author> G.A. Blaauw and F.P. Brooks, Jr. </author> <title> The Structure of SYSTEM/360: Part I Outline of the Logical Structure. </title> <editor> In Daniel P. Siewiorek, C. Gordon Bell, and Allen Newell, editors, </editor> <booktitle> Computer Structures: Principles and Examples, </booktitle> <pages> pages 495-710. </pages> <address> McCraw-Hill, </address> <publisher> Inc., </publisher> <year> 1982. </year>
Reference: [40] <author> Andrew Black et al. </author> <title> Object Structure in the Emerald System. </title> <booktitle> In OOPSLA '86 Conference Proceedings, </booktitle> <pages> pages 78-86, </pages> <month> September 29 - October 2 </month> <year> 1986. </year> <title> Proceedings also available as: </title> <journal> Sigplan Notices, </journal> <volume> Vol 21, No 11, </volume> <month> November </month> <year> 1986. </year>
Reference-contexts: If O2 is again unable to service the message, the message can be delegated again to a third object, etc. Eventually when the message is serviced, the reply is sent back to R directly. Languages for Distributed Memory Emerald Emerald <ref> [146, 40] </ref> is an object-based system for writing distributed programs. The main targeted systems are networks with about 100 nodes. Emerald is object-based, rather than object-oriented. There is no mechanism to define a class which will serve as the definition for multiple object instances. <p> A process object is not an actor; its creation simply results in a new thread that can invoke routines on other objects. For synchronization, an object constructor can include a monitor keyword to specify that at most one thread can execute in the object. The references <ref> [146, 40] </ref> however do not describe how more complex synchronization such as barrier and condition-wait can be provided. Because object mobility is a central concept in Emerald, we will describe it in more details.
Reference: [41] <author> H. Boehm and Weiser M. </author> <title> Garbage collection in an uncooperative environment. </title> <journal> Software Practice & Experience pp. </journal> <pages> 807-820, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: and are stored as attributes in dynamically created objects whose links may change during program execution. 5.2.3 Garbage Collection Garbage collection (GC) is a important research area that is not addressed in the current pSather prototype (although Sather 0.2 does use a conservative garbage collector developed by Boehm and Weiser <ref> [41] </ref>). The compiler analysis used to identify short-lived objects (Section 3.5.4) is insufficient for many application programs; hence the importance of a garbage collector so that the user can focus on the high-level program/algorithm design, instead of the implementation details such as identifying unreachable objects.
Reference: [42] <author> A.P.W. Bo hm and R.R. Oldehoeft. </author> <title> SISAL 2.0: Overview and Rationale. </title> <type> Technical Report CS-92-141, </type> <institution> Department of Computer Science, Colorado State University, </institution> <month> November </month> <year> 1992. </year>
Reference: [43] <author> Shahid H. Bokhari. </author> <title> Multiprocessing the sieve of eratosthenes. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 50-58, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: This algorithm uses both the workbag (Section 4.1) and replicated hash table (Section 4.3), and shows how the library classes can be reused in different applications. One algorithm that computes primes is the sieve of Eratosthenes. Bokhari <ref> [43] </ref> described a parallel implementation of the sieve on a Flex/32 multiprocessor. It used a master-worker model, where each time the master program finds a prime p, it asks an idle (worker) process to mark out multiples of p. It was, however, unable to obtain speedup beyond six processors.
Reference: [44] <author> James Boyle et al. </author> <title> Portable Programs for Parallel Processors. </title> <publisher> Holt, Rinehart and Winston, Inc., </publisher> <address> New York, NY, </address> <year> 1987. </year>
Reference-contexts: An example in which this happens is a program with distinct 17 computation phases such that no thread may start a phase before the others. The point where the threads must wait before they can all continue on, is called a barrier <ref> [44] </ref>. Conditional wait. Sometimes we want a thread to suspend and wait for certain conditions to become true before it is allowed to resume execution.
Reference: [45] <author> T. Brandes. </author> <title> Efficient Data Parallel Programming without Explicit Message Passing for Distributed Memory Multiprocessors. GMD Internal Report No. </title> <address> AHR-92-4, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: But porting a parallel program to different multiprocessors is not an easy task. This is why there are tools to help programmers port applications from one class of architectures to another. An example is Adaptor <ref> [45] </ref> which helps to transform data-parallel programs to programs with explicit message passing for distributed-memory MIMD machines. We think that the language must make it easy to reuse code libraries for a wide range of algorithms and data structures.
Reference: [46] <author> Eric A. Brewer, Chrysanthos N. Dellarocas, Adrian Colbrook, and William E. Weihl. PRO-TEUS: </author> <title> A High-Performance Parallel-Architecture Simulator. </title> <type> Technical Report MIT/LCS/TR-516, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: If a simulator can be configured to simulate a wide range of architectures, the programmer also benefits from being able to examine his/her program's performance on different machines (which in turn indicates the program portability). Examples of multiprocessor simulation systems include PRO-TEUS <ref> [46] </ref> and Tango [112]. The systems allow the user to record various low-level events (e.g. lock acquisition/release), but does not support the mapping of such information to high-level program components.
Reference: [47] <author> Jean-Pierre Briot and Akinori Yonezawa. </author> <title> Inheritance and Synchronization in Concurrent OOP. </title> <booktitle> In ECOOP 1987, European Conference on Object-Oriented Programming, </booktitle> <volume> LNCS 276, </volume> <pages> pages 32-40. </pages> <publisher> Springer-Verlag, </publisher> <month> June 15-17 </month> <year> 1987. </year> <month> 298 </month>
Reference-contexts: The ideas also do not overcome the general problems that arise from breaking class encapsulation via inheritance. Taking the earlier QUEUEfTg and DEQUEfTg examples (of which variations appear in various work <ref> [147, 47] </ref>), we note that even in sequential programming, the implementation of new routines in DEQUEfTg requires knowledge about the actual implementation of QUEUEfTg and already breaks the encapsulation in QUEUEfTg.
Reference: [48] <author> B. </author> <title> Buchberger. An Algorithm for Finding a Basis for the Residue Class Ring of a Zero-Dimensional Polynomial Ideal. </title> <type> PhD thesis, </type> <institution> Univ. </institution> <address> Innsbruck, </address> <year> 1965. </year> <note> In German. </note>
Reference-contexts: quiescent) do w bag.get if (w exists) then &lt;Compute with w, and insert new work generated into the bag.&gt; else &lt;No work&gt; end; the distributed workbag is used in the N-queens parallel search problem (Section 4.2), a parallel prime sieve program (Section 4.4) and a parallel variation of Buchberger's algorithm <ref> [48] </ref> for computing Grobner basis (Section 4.7). Queues are common data structures in sequential programming. A sequential program using a queue generally has a structure as in Figure 4.1. <p> comparable to a single CM-5 node) to programming a CM-5 using the current pSather prototype. 4.3 Replicated Hash Table In this section, we look at another library class that is used in two parallel programs: finding primes (Section 4.4) and a parallel variation of Buchberger's algorithm to compute Grobner basis <ref> [48] </ref> (Section 4.7). The class is a replicated hash table (Figures 4.18, 4.19, 4.20). It combines the functionalities of a hash table and a software cache.
Reference: [49] <author> B. </author> <title> Buchberger. Grobner Bases: An Algorithmic Method in Polynomial Ideal Theory. </title> <editor> In N. K. Bose, editor, </editor> <booktitle> Progress, Directions and Open Problems in Multidimensional Systems Theory, </booktitle> <pages> pages 184-232. </pages> <address> D. </address> <publisher> Reidel Publishing Company, </publisher> <year> 1985. </year>
Reference-contexts: A reduced Grobner basis G is a Grobner basis such that every p 2 G is not reducible by any other polynomial in G. Buchberger <ref> [49] </ref> gives an algorithm which computes a reduced Grobner basis. The computation has two phases: the first produces a Grobner basis G and the second produces the reduced basis from G. There have been various attempts at parallelizing Buchberger's algorithm [194, 61, 225], but our aim is slightly different. <p> The second refinement is called Buchberger's criterion 2 <ref> [49] </ref>. For any pair (p; q), if p; q 2 G and lcm (hterm p ; hterm q ) = hterm p fi hterm q , then the S-polynomial of p and q can be expressed in terms of the members of G.
Reference: [50] <author> Peter A. Buhr, Michael H. Coffin, and Michel Fortier. </author> <title> Monitor Classification and Priority-NonBlocking Monitor. Part of C++ Distribution Package. </title>
Reference: [51] <author> Peter A. Buhr and Richard A. Stroobosscher. </author> <title> C++ Annotated Reference Manual Version 3.4.4, </title> <month> August 18 </month> <year> 1992. </year> <title> Part of C++ Distribution Package. </title>
Reference-contexts: A TASK declaration identifies tasks (threads) that share an object y and that are scheduled together to improve cache use. Finally a PROCESSOR declaration schedules a thread on a particular processor p and lets the programmer perform load balancing. C++ C++ <ref> [51] </ref> distinguishes among three concurrency notions that might be associated with an object. They are thread, execution state and implicit lock.
Reference: [52] <author> Michael Burke, Ron Cytron, Jeanne Ferrante, Wilson Hsieh, Vivek Sarkar, and David Shields. </author> <title> Automatic Discovery of Parallelism: A Tool and an Experiment (Extended Abstract). </title> <booktitle> In Proceedings of the ACM/SIGPLAN Parallel Programming Experience with Applications, Languages and Systems (PPEALS) Symposium, </booktitle> <pages> pages 77-84, </pages> <year> 1988. </year> <title> Proceedings also published as: </title> <journal> SIGPLAN Notices, </journal> <volume> Vol. 23, No. 9, </volume> <month> September </month> <year> 1988. </year>
Reference: [53] <author> David Cann. </author> <title> Retire Fortran? A Debate Rekindled. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 81-89, </pages> <month> August </month> <year> 1992. </year>
Reference: [54] <author> Denis Caromel. </author> <title> Service, Asynchrony, </title> <journal> and Wait-by-Necessity. Journal of Object-Oriented Programming, </journal> <volume> 2(4) </volume> <pages> 12-18, </pages> <month> November-December </month> <year> 1989. </year>
Reference-contexts: A message targeted to the enclosed object is sent to the semaphore. The semaphore is acquired and the message is relegated to the enclosed object. This prevents multiple threads from accessing the enclosed object. 28 Eiffel // Eiffel // <ref> [55, 54, 56, 57, 58] </ref> extends the Eiffel language and supports both passive and active objects (actors). A call to a passive object is synchronous, just like any procedure call.
Reference: [55] <author> Denis Caromel. </author> <title> Concurrency: An Object-Oriented Approach. </title> <booktitle> In Proceedings of TOOLS 1990, </booktitle> <pages> pages 183-198, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: A message targeted to the enclosed object is sent to the semaphore. The semaphore is acquired and the message is relegated to the enclosed object. This prevents multiple threads from accessing the enclosed object. 28 Eiffel // Eiffel // <ref> [55, 54, 56, 57, 58] </ref> extends the Eiffel language and supports both passive and active objects (actors). A call to a passive object is synchronous, just like any procedure call.
Reference: [56] <author> Denis Caromel. </author> <title> Concurrency and Reusability: From Sequential to Parallel. </title> <journal> Journal of Object-Oriented Programming, </journal> <volume> 3(3) </volume> <pages> 34-42, </pages> <month> September-October </month> <year> 1990. </year>
Reference-contexts: A message targeted to the enclosed object is sent to the semaphore. The semaphore is acquired and the message is relegated to the enclosed object. This prevents multiple threads from accessing the enclosed object. 28 Eiffel // Eiffel // <ref> [55, 54, 56, 57, 58] </ref> extends the Eiffel language and supports both passive and active objects (actors). A call to a passive object is synchronous, just like any procedure call.
Reference: [57] <author> Denis Caromel. </author> <title> Programmation Parallele asynchrone et imperative: Etudes et Propositions. </title> <type> PhD thesis, </type> <institution> Universite de Nancy 1 (France), Informatique, </institution> <month> February </month> <year> 1991. </year>
Reference-contexts: A message targeted to the enclosed object is sent to the semaphore. The semaphore is acquired and the message is relegated to the enclosed object. This prevents multiple threads from accessing the enclosed object. 28 Eiffel // Eiffel // <ref> [55, 54, 56, 57, 58] </ref> extends the Eiffel language and supports both passive and active objects (actors). A call to a passive object is synchronous, just like any procedure call.
Reference: [58] <author> Denis Caromel. </author> <title> Programming Abstractions for Concurrent Programming: A Solution to the Explicit/Implicit Control Dilemma. </title> <journal> ACM OOPS Messenger, </journal> <volume> 2(2), </volume> <month> April </month> <year> 1991. </year> <note> Journal is collection of articles from Workshop on Object-Based Concurrent Programming, (OOP-SLA/ECOOP 1990), edited by Gul Agha et al. </note>
Reference-contexts: A message targeted to the enclosed object is sent to the semaphore. The semaphore is acquired and the message is relegated to the enclosed object. This prevents multiple threads from accessing the enclosed object. 28 Eiffel // Eiffel // <ref> [55, 54, 56, 57, 58] </ref> extends the Eiffel language and supports both passive and active objects (actors). A call to a passive object is synchronous, just like any procedure call.
Reference: [59] <author> Nicholas Carriero and David Gelernter. </author> <title> How to Write Parallel Programs: A First Course. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: The language must encourage modular structures in parallel programs, making it easier to port to different multiprocessors. Expressiveness of Parallel Constructs In the theoretical literature, certain common paradigms of parallel algorithms (e.g. divide-and-conquer [122, 72], pipeline [121], normal algorithms [221] and master-worker <ref> [59] </ref>) have been recognized in various works to parallelize sequential algorithms or develop new parallel algorithms. One finds that it is more straight-forward to program algorithms in the above paradigms when certain kinds of language constructs are available. <p> Each processor gets all the primes, and uses them to cancel out the multiples in its range. Our implementation follows the algorithm used in Carriero et al. (Chapter 5 of <ref> [59] </ref>) and uses a master-worker model. 11 Each worker thread repeatedly retrieves an odd number v from a distributed workbag and works on the numbers (v, v +2, v +4, : : :, v+range).
Reference: [60] <author> John B. Carter, John K. Bennett, and Willy Zwaenepoel. </author> <title> Implementation and Performance of Munin. </title> <type> Technical Report TR91-150, </type> <institution> Department of Computer Science, Rice University, </institution> <address> P. O. Box 1892, Houston, Texas 77251-1892, </address> <month> March </month> <year> 1991. </year> <month> 299 </month>
Reference-contexts: It is a runtime error to perform two or more simultaneous broadcasts on the same shared feature x. 2.5.5 Discussion In order to support a shared memory programming model, many systems (e.g. Munin <ref> [32, 60] </ref>, Midway [34]) provide a set of common consistency protocols to support distributed shared memory. These consistency protocols are predefined and built into the system. The advantage of an object-oriented system is that users can build their own set of consistency protocols based on the needs of the application. <p> It is also an example of how the programmer can flexibly build a memory consistency protocol based on the needs of the program and not rely on the system to provide a set of predefined protocols (e.g. Munin <ref> [60, 32] </ref>). The hash table can be used as either a map or set abstraction and is useful in the following general situation: The computation has a monotonically increasing global state which consists of the results of different threads. These results are associated with unique integer id's.
Reference: [61] <author> Soumen Chakrabarti. </author> <title> A Distributed Memory Grobner Basis Algorithm. </title> <type> Master's thesis, </type> <institution> University of California at Berkeley, Berkeley, </institution> <address> CA, </address> <year> 1992. </year>
Reference-contexts: Buchberger [49] gives an algorithm which computes a reduced Grobner basis. The computation has two phases: the first produces a Grobner basis G and the second produces the reduced basis from G. There have been various attempts at parallelizing Buchberger's algorithm <ref> [194, 61, 225] </ref>, but our aim is slightly different. We want to produce a reasonably efficient parallel program us ing existing software components. <p> This is the version that has been called pSather/V3 throughout. The main difficulty in measurements is that the program runs to completion too quickly. Table 4.12 shows the pSather/V3 timings for the typical inputs [225]. Even when we tried out the large problems used by <ref> [61] </ref> (which is generated by replicating an input with renamed variables), the 23 The class MPOL PAIRSET OP (used in lines 3, 15) encapsulates the operations that produces S-polynomial and pairs. 24 A pair (p 1 ; q 1 ) is better than (p 2 ; q 2 ) if lcm <p> The field of a particle is the result of interaction between it and each of the other N 1 particles. A brute-force computation takes time O (N 2 ). The Greengard-Rohklin's 25 The reason that our 1-processor times do not take hours (unlike <ref> [61] </ref>) is that the refinements (described in Section 4.7.1) reduce the amount of work generated; the difference may also be due to the different orderings used. 238 Input Lazard fi 15 Robbiano fi 10 Ordering TR TR pSather/V3 422.47 170.27 P = 1 505.86 - 507.36 202.05 - 203.05 P =
Reference: [62] <author> Rohit Chandra, Anoop Gupta, and John L. Hennessy. </author> <title> Integrating Concurrency and Data Abstraction in a Parallel Programming Language. </title> <type> Technical Report CSL-TR-92-511, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: An actor (data object with thread) receives messages from others and processes them. In the third approach, objects are passive entities while threads are loci of execution control independent of objects (e.g. Hybrid [184], COOL <ref> [62] </ref>). The programmer does not have any explicit handle to the thread, so that he cannot perform operations like moving the thread from one scheduler object to another. Most languages in this model allow multiple threads to execute in an object at the same time. Other languages (e.g. <p> In the third model (threads/passive objects), there are separate mechanisms to create threads and objects, so languages with this model have constructs that support explicit thread creation (e.g. the reflex operation in Hybrid [184] or invocation of parallel function in COOL <ref> [62] </ref>). Synchronization/Communication With multiple threads of control, there must be some ways for the threads to communicate and synchronize. We first list several common synchronization patterns found in parallel programs, so that we can later use them to illustrate the synchronization mechanisms in particular parallel object-oriented languages. Lock protection. <p> The difference from the PRESTO-like model is that the synchronization constructs are normally provided via additional language extensions. We consider each of the synchronization patterns (lock protection, barrier and conditional wait) in COOL <ref> [62] </ref>. To achieve locking, attributes and functions can be qualified as mutex at declaration. To do a barrier, there is a predefined binc construct which encloses a block of statements. The current thread suspends until all threads created during the execution of the block terminate. <p> It is interesting to note how different approaches have been adopted with the same sequential language, resulting in languages/systems with widely different characteristics. COOL COOL <ref> [62] </ref> supports parallelism by allowing class routines to be declared as parallel. New threads are created when such routines are invoked (although the caller has the option of making it a serial call). There are constructs for different types of synchronization.
Reference: [63] <author> K. Mani Chandy and Jayadev Misra. </author> <title> Parallel Program Design: A Foundation. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <month> May </month> <year> 1989. </year>
Reference: [64] <author> Jeffrey S. Chase et al. </author> <title> The Amber System: Parallel Programming on a Network of Multiprocessors. </title> <type> Technical Report 89-04-01, </type> <institution> Department of Computer Science, University of Washington, </institution> <year> 1989. </year>
Reference-contexts: The following categorization is not mutually exclusive | a language may suitably fall into more than one category. To reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber <ref> [64] </ref>, Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier.
Reference: [65] <author> Doreen Y. Cheng. </author> <title> A Survey of Parallel Programming Languages and Tools. </title> <type> Technical Report RND-93-005, </type> <institution> NAS Systems Development Branch, NAS Systems Division, NASA Ames Research Center, Mail Stop 258-6, Moffett Field, </institution> <address> CA 94035-1000, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: So the lower-level performance characteristics should be related to the contexts of the program (e.g. which part of the program is generating a large number of remote calls). There are various ongoing research efforts in performance debugging. <ref> [65] </ref> has a summary of various software performance monitoring tools for multiprocessors. For example, Pablo [197, 185] is a high-level instrumentation system for sequential and (distributed-memory) multiprocessors; it requires the programmer to insert trace calls in the program.
Reference: [66] <author> Joseph Cheryian, Torben Hagerup, and Kurt Melhorn. </author> <title> Can a Maximum Flow be Computed in o(nm) Time? In Proceedings of the 17th International Colloquium on Automata, </title> <booktitle> Languages and Programming, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: We think that interesting applications include algorithms for the max-flow problem <ref> [66, 110] </ref>, various kinds of simulators (e.g. ICSIM [205] a neural network simulator), numerical algorithms (e.g. linear programming), and parallel constraint satisfaction systems ([117]). We have mentioned that one of pSather's goals is to provide a platform for building reusable classes.
Reference: [67] <author> Andrew A. Chien and William J. Dally. </author> <title> Concurrent aggregates (ca). </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on the Principles and Practice of Parallel Programming, </booktitle> <year> 1990. </year>
Reference-contexts: Hence the inheritance anomaly problem which is in large part caused by breaking the class encapsulation, should not be over-emphasized. Even in a sequential object-oriented language, a subclass can break the encapsulation of its superclass when it inherits code from the latter as 7 Concurrent Aggregates <ref> [67, 68] </ref> tries to solve this problem by introducing aggregates, such that the objects in an aggregate match the granularity of parallelism. Programming aggregates, however, requires additional programming effort to undo the restriction caused by "one thread per object". 25 described by Snyder [207]. <p> Orca is implemented on top of a reliable broadcasting layer that supports serial updates to objects, but does not guarantee sequential consistency for performance reasons. Object placement is handled by the runtime system. Concurrent Aggregates Concurrent Aggregates (CA) <ref> [67, 68] </ref> adopts an actor model so that invocations are seri-alised. A main concern in its design is that this serialisation leads to bottlenecks and gets worse with more layers of abstractions.
Reference: [68] <author> Andrew Andai Chien. </author> <title> Concurrent Aggregates (CA): An Object-Oriented Language for Fine-Grained Message-Passing Machines. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <month> July </month> <year> 1990. </year> <note> Also available as: </note> <institution> MIT Artificial Intelligence Laboratory, </institution> <type> Technical Report 1248. </type>
Reference-contexts: Hence the inheritance anomaly problem which is in large part caused by breaking the class encapsulation, should not be over-emphasized. Even in a sequential object-oriented language, a subclass can break the encapsulation of its superclass when it inherits code from the latter as 7 Concurrent Aggregates <ref> [67, 68] </ref> tries to solve this problem by introducing aggregates, such that the objects in an aggregate match the granularity of parallelism. Programming aggregates, however, requires additional programming effort to undo the restriction caused by "one thread per object". 25 described by Snyder [207]. <p> Orca is implemented on top of a reliable broadcasting layer that supports serial updates to objects, but does not guarantee sequential consistency for performance reasons. Object placement is handled by the runtime system. Concurrent Aggregates Concurrent Aggregates (CA) <ref> [67, 68] </ref> adopts an actor model so that invocations are seri-alised. A main concern in its design is that this serialisation leads to bottlenecks and gets worse with more layers of abstractions.
Reference: [69] <author> Jong-Deok Choi, Barton P. Miller, and Robert H.B. Netzer. </author> <title> Techniques for Debugging Parallel Programs with Flowback Analysis. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 491-530, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: In addition to software tools, other common approaches in parallel debugging is by static analysis (e.g. [89]), or a combination of logging information during execution with post-mortem analysis (e.g. <ref> [69] </ref>). One dimension of the debugging problem is the methodology (e.g. software tracing vs. static analysis). Another dimension is the nature of the bugs.
Reference: [70] <author> Peter Christy. </author> <title> Software to Support Massively Parallel Computing on the MasPar MP-1. </title> <booktitle> In IEEE COMPCON Proceedings, </booktitle> <pages> pages 29-33, </pages> <year> 1990. </year>
Reference-contexts: This is the case whether they provide virtual (non-uniform) shared-memory in hardware (e.g. KSR1 [201], Dash [161]) or rely on the programmer to write message-passing programs (e.g. on CM-5 [76]) or data-parallel programs (e.g. on MasPar MP-1 <ref> [70] </ref>). This recognition of distributed memory is also found in theoretical research. There are efforts to extend the restrictive PRAM model and come up with more realistic models of parallel computation that take various practical parameters (e.g. communication latency) into account.
Reference: [71] <author> W. D. Clinger. </author> <title> Foundations of Actor Semantics. </title> <type> Technical Report AI-TR-633, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <month> May </month> <year> 1981. </year>
Reference-contexts: The approach with first-class thread objects is flexible because it does not require any language extensions and allows different thread and synchronization objects, and scheduling strategies to be implemented according to the programmer's needs. The actor approach offers a well-studied theoretical concurrent object-oriented model <ref> [71, 2] </ref>, but is not without its problems (e.g. inheritance anomaly and efficient implementation). PSather follows the model with passive objects and threads as independent loci of control, and has thread creation constructs (Section 2.3).
Reference: [72] <author> Murray Cole. </author> <title> Algorithmic Skeletons: Structured Management of Parallel Computation. </title> <booktitle> Research Monographs in Parallel and Distributed Computing. </booktitle> <publisher> The MIT Press, </publisher> <address> Cambridge, Mas-sachusetts, </address> <year> 1989. </year>
Reference-contexts: The language must encourage modular structures in parallel programs, making it easier to port to different multiprocessors. Expressiveness of Parallel Constructs In the theoretical literature, certain common paradigms of parallel algorithms (e.g. divide-and-conquer <ref> [122, 72] </ref>, pipeline [121], normal algorithms [221] and master-worker [59]) have been recognized in various works to parallelize sequential algorithms or develop new parallel algorithms. One finds that it is more straight-forward to program algorithms in the above paradigms when certain kinds of language constructs are available.
Reference: [73] <author> Jean-Francois Colin and Jean-Marc Geib. </author> <title> Eiffel Classes for Concurrent Programming. </title> <booktitle> In TOOLS '91, Technology of Object-Oriented Languages and Systems, </booktitle> <month> 4-8 March </month> <year> 1991. </year> <month> 300 </month>
Reference-contexts: It is therefore possible to build a table that explicitly associates a routine with a function that evaluates the condition for which the routine is blocked. The Live routine of an active object may then use this table to decide which messages to receive. Parallel Eiffel Parallel Eiffel <ref> [113, 73] </ref> has a different approach from Eiffel // as it is more a tool for exploring concurrent object-oriented languages. It therefore only introduces new Eiffel classes to deal with parallelism and does not extend the language.
Reference: [74] <institution> Communications of the ACM: </institution> <note> Concurrent Object-Oriented Programming, </note> <month> September </month> <year> 1993. </year>
Reference-contexts: It does not contain any language extension to Smalltalk. The implementation does not support a shared object space; each program retains a logically distinct 8 Further survey of concurrent object-oriented programming can be found in <ref> [216, 74] </ref>. 26 Language Thread Synchronization Object Placement Inheritance pSather P/DP SD Y I Distributed Smalltalk P SD Y I Multiprocessor Smalltalk P SD N I Concurrent Smalltalk P SD N I Eiffel // A/P SD N I Parallel Eiffel L SD N I CEiffel P SD N I COOL P
Reference: [75] <institution> Thinking Machines Corporation. CMSSL for CM Fortran, Vols. I and II. </institution>
Reference-contexts: For parallel programs, sofeware reuse is especially relevant because of the difficulty of writing efficient, parallel code. This is why efforts are spent on building libraries (e.g. LAPACK [37, 91], CMSSL <ref> [75] </ref>). Such efforts however focus mainly on numerical algorithms and not on symbolic algorithms and irregular data structures. One might argue that if a program can be ported to different architectures with relatively little effort, one is already achieving software reuse.
Reference: [76] <author> Thinking Machines Corporation. </author> <title> The Connection Machine CM-5 Technical Summary. </title> <institution> Thinking Machines Corporation, Cambridge Massachusetts, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: At the systems level, it is generally acknowledged that scalable multiprocessors will have distributed memory [142]. This is the case whether they provide virtual (non-uniform) shared-memory in hardware (e.g. KSR1 [201], Dash [161]) or rely on the programmer to write message-passing programs (e.g. on CM-5 <ref> [76] </ref>) or data-parallel programs (e.g. on MasPar MP-1 [70]). This recognition of distributed memory is also found in theoretical research. There are efforts to extend the restrictive PRAM model and come up with more realistic models of parallel computation that take various practical parameters (e.g. communication latency) into account. <p> The "loosely synchronous data parallelism" breaks away from SIMD execution and is similar to our approach. dpSather's fine-grain approach is more suitable for vector machines. For distributed-memory multiprocessors with vector units (e.g. CM-5 <ref> [76] </ref>, CNS-1 [18]), pSather will have to be extended further and/or borrow ideas from dpSather's fine-grain data-parallelism, so that the user can both distribute data and make use of vector operations. 2.8.5 Target Systems In the design of parallel languages, there are inevitably some implicit assumptions on the characteristics of the
Reference: [77] <institution> Thinking Machines Corporation. Prism User's Guide. Thinking Machines Corporation, Cam-bridge Massachusetts, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: There are various ongoing research efforts in performance debugging. [65] has a summary of various software performance monitoring tools for multiprocessors. For example, Pablo [197, 185] is a high-level instrumentation system for sequential and (distributed-memory) multiprocessors; it requires the programmer to insert trace calls in the program. In Prism <ref> [77] </ref>, the instrumenting code is automatically generated by the tool. 278 Although multiprocessor vendors normally provide a performance tool for their machine, much research still needs to be done.
Reference: [78] <author> Lawrence A. Crowl. </author> <title> Architectural adaptability in parallel programming. </title> <type> PhD thesis, </type> <institution> University of Rochester, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: PSather does not need message-passing forms of parallel constructs like actors in POOL2 [8], broadcast in Orca [21], or asynchronous reply in Natasha <ref> [78] </ref> and ConcurrentSmalltalk [230]. In pSather, sequential routine calls are viewed as the default synchronous mode of message-passing while the thread creation corresponds to asynchronous message-passing. <p> The following categorization is not mutually exclusive | a language may suitably fall into more than one category. To reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha <ref> [78] </ref>, Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10].
Reference: [79] <author> Lawrence A. Crowl, Mark E. Crovella, Thomas J. LeBlanc, and Michael L. Scott. </author> <title> Beyond Data Parallelism: The Advantages of Multiple Parallelizations in Combinatorial Search. </title> <type> Technical Report Technical Report 451, </type> <institution> The University of Rochester, Computer Science Department, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: Thus, pSather supports a distributed-memory shared-address model and has constructs that allow programmers to take data locality into account. Another characteristic of pSather is its combination of various parallel paradigms in one consistent framework. This will be useful for supporting research on multiple parallelizations within an algorithm <ref> [79] </ref>. The current protoype supports all the parallel constructs. Our implementation demonstrates that even if a distributed-memory machine does not support a shared-address space at the hardware/operating system level, the compiler can still provide the shared-address abstraction relatively well.
Reference: [80] <author> W. Crowther, J. Goodhue, R. Gurwitz, R. Rettberg, and R. Thomas. </author> <title> The Butterfly (TM) Parallel Processor. </title> <journal> IEEE Computer Architecture Technical Committee Newsletter, </journal> <pages> pages 18-45, </pages> <month> September-December </month> <year> 1985. </year>
Reference: [81] <author> David Culler et al. </author> <title> LogP: Towards a Realistic Model of Parallel Computation. </title> <type> Technical Report UCB/CSD 92/713, </type> <institution> Computer Science Division (EECS), University of California, Berkeley, </institution> <address> CA 94720, </address> <year> 1992. </year>
Reference: [82] <author> Ole-Johan Dahl and Kristen Nygaard. </author> <title> Simula an ALGOL-based simulation language. </title> <journal> Communications of the ACM, </journal> <volume> 9(9) </volume> <pages> 671-678, </pages> <month> September </month> <year> 1966. </year>
Reference: [83] <author> Jack W. Davidson and Anne M. Holler. </author> <title> A Study of a C Function Inliner. </title> <journal> Software Practice and Experience, </journal> <volume> 18(8) </volume> <pages> 775-790, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: In addition to reducing procedure call overheads, inlining also allows the body of an inlined procedure to be analyzed and optimized specific to its called context [200]. One disadvantage of inlining is that it increases the size of the executable although a study in <ref> [83] </ref> concludes that this size increase is not a problem in practice. [84] is another reference that discusses various factors that influence the speedup of inlined code. Inlining is a useful optimization technique in an object-oriented language because there often exist short but often-called routines in classes.
Reference: [84] <author> Jack W. Davidson and Anne M. Holler. </author> <title> Subprogram Inlining: A Study of its Effects on Program Execution Time. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(2) </volume> <pages> 89-102, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: One disadvantage of inlining is that it increases the size of the executable although a study in [83] concludes that this size increase is not a problem in practice. <ref> [84] </ref> is another reference that discusses various factors that influence the speedup of inlined code. Inlining is a useful optimization technique in an object-oriented language because there often exist short but often-called routines in classes. We therefore added a phase in the compiler to perform inlining.
Reference: [85] <author> D. Decouchant et al. </author> <title> A synchronization mechanism for typed objects in a distributed system. </title> <booktitle> In Proceedings of the ACM SIGPLAN Workshop on Object-Based Concurrent Programming, </booktitle> <pages> pages 105-107, </pages> <month> September 26-27 </month> <year> 1988. </year> <title> Workshop proceedings available as: </title> <journal> SIGPLAN Notices, </journal> <volume> Vol 24, No 4, </volume> <month> April </month> <year> 1989. </year>
Reference-contexts: Tomlinson et al. [217] propose a similar augmentation to the next-message-set approach. The inheritance anomaly in the QUEUEfTg/DEQUEfTg example however does not arise in approaches which associate a condition with each routine. Decouchant et al. <ref> [85] </ref> describes how a boolean activation condition is specified for each routine. Only when the boolean condition is true, is the corresponding routine enabled and a message for that routine receivable.
Reference: [86] <author> Jack B. Dennis and Earl C. Van Horn. </author> <title> Programming Semantics for Multiprogrammed Computations. </title> <journal> Communications of the ACM, </journal> <volume> 9(3) </volume> <pages> 143-155, </pages> <month> March </month> <year> 1966. </year> <month> 301 </month>
Reference-contexts: Message-passing is not the only way to achieve synchronization in parallel object-oriented languages. The model with explicit thread objects (e.g. PRESTO) uses the shared data approach. The synchronization mechanisms are more in the tradition of constructs used in concurrent programming, such as fork-join <ref> [86] </ref> and semaphores [88], except that these mechanisms are defined 5 The bounded buffer has been a traditional example used in the discussion of various high-level parallel programming constructs and can be found in many references e.g. [136]. 18 as in classes and are not embodied as fixed language constructs.
Reference: [87] <author> Keith Diefendorff and Michael Allen. </author> <title> Orgnization of the Motorola 88110 Superscalar RISC Microprocessor. </title> <booktitle> IEEE Micro, </booktitle> <pages> pages 40-63, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: In terms of expressiveness, pSather has both control-parallel (Section 2.3) and data-parallel constructs (Section 2.6). They have orthogonal semantics, and therefore a data-parallel execution 3 Hennessy and Jouppi [129] give a description of superscalar and superpipelining techniques which are used in the Motorola 88110 <ref> [87] </ref> and MIPS R4000 [178] processors respectively. 15 may contain thread-based parallelism and vice versa. Last but not least, our design is based on Sather because we want pSather to leverage off Sather's efficient implementation.
Reference: [88] <author> E. W. Dijkstra. </author> <title> The structure of the 'THE' multiprogramming system. </title> <journal> Communications of the ACM, </journal> <volume> 11(5) </volume> <pages> 341-346, </pages> <month> May </month> <year> 1968. </year>
Reference-contexts: There are two general approaches to achieving synchronization among threads [14] | shared data or message-passing. An example of the shared data approach is the use of monitors ([136, 227]) in Concurrent Pascal ([120, 123]) and Mesa [154]. In this approach, the mechanisms to achieve lock protection include semaphores <ref> [88] </ref> and protection of critical sections by Dekker's algorithm [30], while a construct which provides conditional wait is the condition variables (originally proposed together with the monitor concept [136]). <p> Message-passing is not the only way to achieve synchronization in parallel object-oriented languages. The model with explicit thread objects (e.g. PRESTO) uses the shared data approach. The synchronization mechanisms are more in the tradition of constructs used in concurrent programming, such as fork-join [86] and semaphores <ref> [88] </ref>, except that these mechanisms are defined 5 The bounded buffer has been a traditional example used in the discussion of various high-level parallel programming constructs and can be found in many references e.g. [136]. 18 as in classes and are not embodied as fixed language constructs.
Reference: [89] <author> Anne Dinning and Edith Schonberg. </author> <title> Detecting access anomalies in programs with critical sections. </title> <booktitle> In Proceedings of the ACM/ONR Workshop on Parallel and Distributed Debugging, </booktitle> <pages> pages 85-96, </pages> <year> 1991. </year> <note> Proceedings also available as SIGPLAN Notices 26(12), </note> <month> December, </month> <year> 1991. </year>
Reference-contexts: Because performance monitoring and debugging share common aims ("provide information on program behavior"), they also share common research issues such as parallel program visualization [177] (or even auralization). In addition to software tools, other common approaches in parallel debugging is by static analysis (e.g. <ref> [89] </ref>), or a combination of logging information during execution with post-mortem analysis (e.g. [69]). One dimension of the debugging problem is the methodology (e.g. software tracing vs. static analysis). Another dimension is the nature of the bugs.
Reference: [90] <author> Thomas W. Doeppner, Jr. and Alan J. Gebele. </author> <title> C++ on a parallel machine. </title> <type> Technical Report CS-87-26, </type> <institution> Brown University, Department of Computer Science, Brown University, </institution> <address> Providence, RI 02912, </address> <month> November 17 </month> <year> 1987. </year>
Reference-contexts: reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries <ref> [94, 33, 27, 90] </ref>), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier. Parallel Versions of Smalltalk We first look at some parallel implementations of Smalltalk.
Reference: [91] <author> Jack J. Dongarra, Jeremy du Croz, Sven Hammarling, and Iain Duff. </author> <title> A Set of Level 3 Basic Linear Algebra Subprograms. </title> <journal> ACM Transactions on Mathmatical Software, </journal> <volume> 16(1) </volume> <pages> 1-17, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: For parallel programs, sofeware reuse is especially relevant because of the difficulty of writing efficient, parallel code. This is why efforts are spent on building libraries (e.g. LAPACK <ref> [37, 91] </ref>, CMSSL [75]). Such efforts however focus mainly on numerical algorithms and not on symbolic algorithms and irregular data structures. One might argue that if a program can be ported to different architectures with relatively little effort, one is already achieving software reuse.
Reference: [92] <author> A. Dubruille, R.G. Scarborough, and H. Kolsky. </author> <title> How to write good vectorizable Fortran. </title> <type> Technical Report G320-3478, </type> <institution> Palo Alto Scientific Center, </institution> <year> 1985. </year>
Reference: [93] <author> Anant Agarwal et al. Sparcle: </author> <title> An Evolutionary Processor Design for Large-Scale Multiprocessors. </title> <journal> IEEE Micro, </journal> <volume> 13(3) </volume> <pages> 48-61, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: We think that if a machine like CM-5 were to use MIPS R4000 [178] instead of a Sparc, the overheads of our implementation would be much less. Otherwise, a processor design targeted for multiprocessor also holds better promise. One such example is Sparcle <ref> [93] </ref> which supports fast context-switching by partitioning the set of register windows among multiple threads. 43 Altering a C compiler was beyond the scope of our work and we could not find any reliable C compiler that does not use the Sparc register windows. 182 Chapter 4 Abstractions and Applications This
Reference: [94] <author> John E. Faust and Henry M. Levy. </author> <title> The Performance of an Object-Oriented Threads Package. </title> <booktitle> In ECOOP/OOPSLA Proceedings, </booktitle> <pages> pages 278-288, </pages> <month> October </month> <year> 1990. </year> <title> Proceedings available as: </title> <journal> SIGPLAN Notices, </journal> <volume> Vol 25, No 10, </volume> <month> October </month> <year> 1990. </year>
Reference-contexts: reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries <ref> [94, 33, 27, 90] </ref>), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier. Parallel Versions of Smalltalk We first look at some parallel implementations of Smalltalk. <p> On the other hand, for intra-cluster load balancing, there are various runtime systems (e.g. Uniform [215], Presto <ref> [94] </ref>, and any state-of-the-art operating system for symmetric multiprocessors e.g. Solaris, Mach) which perform well for shared-memory machines. In a machine with &gt; 1 processor per cluster, such systems can be used to provide automatic load balancing within a cluster.
Reference: [95] <author> Michael J. Feeley and Henry M. Levy. </author> <title> Distributed Shared Memory with Versioned Objects. </title> <booktitle> In Proceedings of the Conference on Object-Oriented Programming Systems, Languages and Applications (OOPSLA), </booktitle> <pages> pages 247-263, </pages> <month> Oct 18 - Oct 22 </month> <year> 1992. </year>
Reference: [96] <author> Jerome A. Feldman. </author> <title> High level programming for distributed computing. </title> <journal> Communications of the ACM, </journal> <volume> 22(6) </volume> <pages> 353-368, </pages> <month> June </month> <year> 1979. </year>
Reference-contexts: On the other hand, the message-passing approach is characterized by the rendezvous in Ada ([23, 223]), channels in CSP (Communicating Sequential Processes [137], of which OCCAM [195] is an implementation) and the send/receive constructs in PLITS <ref> [96] </ref>. In an object-oriented language, conceptually, objects interact among themselves by message passing. An object invokes a routine (or method) of another object or itself by sending a message to the destination object. It would therefore seem natural that object-oriented languages should adopt a message-passing approach for synchronization.
Reference: [97] <author> Jerome A. Feldman, Chu-Cheow Lim, and Franco Mazzanti. </author> <title> pSather monitors: Design, Tutorial, Rationale and Implementation. </title> <type> Technical Report TR-91-031, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> Ca., </address> <year> 1991. </year>
Reference-contexts: In this section, we start with a simplified machine model with uniform shared memory. This allows us to focus on the language constructs that provide threads and synchronization. Then 12 This is joint work with Jerry Feldman, Franco Mazzanti and Stephan Murer, also described in <ref> [97] </ref> (pSather 0.1) and [181] (pSather 1.0). 34 in Section 2.4, we generalize the machine model to a cluster model that is applicable to both shared and distributed memory machines. Section 2.5 describes language constructs for programming in the cluster model's non-uniform shared address space. <p> There were many other design alternatives which we have considered. Discussions of the design process and rationale is given in <ref> [97] </ref>. There are two ways to use a GATE (ie. GATEfTg or GATE0) class. A class can be a descendent of a GATE class and inherit the predefined routines. <p> In the code, a philosopher (thread) can grab two chopsticks atomically using multiple-locking facility in the lock statement. The statement semantics prevent any deadlock, which might otherwise result if the programmer uses a nested locking schema instead <ref> [97] </ref>. Another use of the lock statement is illustrated by a join routine (Figure 2.7) defined within the GATE classes. To express a fork-join computation, forked threads are attached to a gate g. When the parent thread is ready to wait for the termination of child threads, it calls "g.join". <p> They provide functionalities which closely parallel other synchronization constructs in other languages, such as M-structures [24] in Id, and monitors in Mesa and Concurrent Pascal ([154, 120, 123, 136, 227, 50]) Monitors PSather gates were previously called monitors <ref> [97] </ref> because of their similarity with the monitor concept in Mesa [154] and Concurrent Pascal [123]. Firstly a gate operation (monitor entry procedure) guarantees a thread (process) exclusive access to the object (Mesa module). But in pSather, the gate operations are predefined since GATEfTg and GATE0 are predefined classes.
Reference: [98] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification, </title> <note> version 1.0 final, May 24 1993. 302 </note>
Reference-contexts: In addition to supporting a data-parallel model of computation with object, PC++ has constructs to partition a collection among the processors. The distribution construct is similar to the alignment constructs in Fortran D [99] and High Performance Fortran <ref> [98] </ref>. For example, the declaration: DistributedList&lt;element&gt; G ([MAXPROC], [M], [Block]); 31 allocates a collection with M elements and distributes them in a block fashion among a logical 1-D array of MAXPROC processors. Thus processor 0 gets the 0,: : :,(M/MAXPROC)-1 elements, processor 1 gets the (M/MAXPROC),: : :,2*(M/MAXPROC)-1 elements etc. <p> Fortran D [99], High Performance Fortran <ref> [98] </ref>, PC++ [103]) provide additional keywords/declarations so that the programmer can declare how a statically declared array can be partitioned on a distributed memory machine. For example, Fortran D has a DISTRIBUTE statement that assigns an attribute to each dimension of an array to describe how it is distributed.
Reference: [99] <author> Geoffrey Fox, Seema Hiranandani, Ken Kennedy, Charles Koelbel, Uli Kremer, Chau-Wen Tseng, and Min-You Wu. </author> <title> Fortran D Language Specification. </title> <type> Technical Report COMP TR90-141, </type> <institution> Department of Computer Science, Rice University, </institution> <address> Houston, TX 77251-1892, </address> <month> December </month> <year> 1990. </year> <note> Revised April, </note> <year> 1991. </year>
Reference-contexts: In addition to supporting a data-parallel model of computation with object, PC++ has constructs to partition a collection among the processors. The distribution construct is similar to the alignment constructs in Fortran D <ref> [99] </ref> and High Performance Fortran [98]. For example, the declaration: DistributedList&lt;element&gt; G ([MAXPROC], [M], [Block]); 31 allocates a collection with M elements and distributes them in a block fashion among a logical 1-D array of MAXPROC processors. <p> Fortran D <ref> [99] </ref>, High Performance Fortran [98], PC++ [103]) provide additional keywords/declarations so that the programmer can declare how a statically declared array can be partitioned on a distributed memory machine.
Reference: [100] <author> Curt Freeland. </author> <title> Sun Machines Set the Standards: </title> <journal> SPARCstation 2, ELC, IPX, and IPC. SunWorld, </journal> <volume> 5(1) </volume> <pages> 62-73, </pages> <month> January </month> <year> 1992. </year>
Reference: [101] <author> Svend Frtlund. </author> <title> Inheritance of Synchronization Constraints in Concurrent Object-Oriented Programming Languages. </title> <type> Technical Report UIUCDCS-R-92-1742, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, </institution> <address> IL 61801-2987, </address> <month> April </month> <year> 1992. </year> <note> Also in: Proceedings of ECOOP '92, </note> <year> 1992. </year>
Reference-contexts: Variations of this approach to decouple the synchronization constraints from computation have been suggested to solve the inheritance anomaly problem. For example Frtlund <ref> [101] </ref> argues that synchronization constraints should disable rather than enable routines for incremental specification. An exhaustive study of inheritance anomaly is beyond our scope, but such a study for actor languages is given by Matsuoka [171].
Reference: [102] <author> Dennis Gannon, Vincent A. Guarna Jr., and Jenq Kuen Lee. </author> <title> Static Analysis and Runtime Support for Parallel Execution of C. </title> <type> Technical Report CSRD-918, </type> <institution> Center for Supercomputing Research and Development, University of Illinois, Urbana, </institution> <address> IL 61801-2932, </address> <month> August </month> <year> 1989. </year>
Reference: [103] <author> Dennis Gannon, Jenq Kuen Lee, and Srinivas Narayana. </author> <title> On Using Object Oriented Parallel Programming to Build Distributed Algebraic Abstractions. </title> <booktitle> In Proceedings of CONPAR 92 - LNCS 634. </booktitle> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1992. </year>
Reference-contexts: Hybrid [184]) group objects into protection domains such that at most one thread can be active in a domain. Other than the three main approaches above, a combination of the approaches is possible and used in some languages. For example, Rosette has both actors and passive objects [217]. PC++ <ref> [103] </ref> presents another variation by supporting the creation of multiple parallel threads, each working on a passive object, resulting in a data-parallel model of computation. Each approach leads to a different programmer's view of how threads are created and executed. <p> There is also a uCondition class on which threads can be suspended and resumed. Unlike COOL, C++ does not have any language constructs for doing thread or object placement. PC++ A major concern of PC++ <ref> [103, 159] </ref> is to be able to build complex distributed data structures (e.g. arrays, lists, sets) in distributed-memory machines. PC++ extends C++ by introducing the notion of a collection which is a homogeneous group of elements. <p> Fortran D [99], High Performance Fortran [98], PC++ <ref> [103] </ref>) provide additional keywords/declarations so that the programmer can declare how a statically declared array can be partitioned on a distributed memory machine. For example, Fortran D has a DISTRIBUTE statement that assigns an attribute to each dimension of an array to describe how it is distributed.
Reference: [104] <author> R. Gebauer and M. Moller. </author> <title> On an installation of buchberger's algorithm. </title> <journal> Journal of Symbolic Computation, </journal> <volume> 6:275 - 286, </volume> <year> 1988. </year>
Reference-contexts: So (p; q) need not be added to P P . [225] demonstrates how these two refinements greatly reduce the number of S-polynomials. We therefore use these two refinements in our parallel implementation which is described next. 19 This is referred to as Buchberger's criterion 1 <ref> [104, 225] </ref>. 20 This implies that lcm (hterm p ; hterm q 1 ; hterm q 2 ) = lcm (hterm p ; hterm q 1 ). 232 4.7.2 Parallel Implementation in pSather Our implementation of Buchberger algorithm computes and reduces the S-polynomials in parallel (i.e. phase 1 of Figure 4.35).
Reference: [105] <author> Kouroush Gharachorloo, Anoop Gupta, and John Hennessy. </author> <title> Performance Evaluation of Memory Consistency Models for Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of the 18th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 245-257, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: The following pSather operations are consistency-ensuring: the forking of a child thread, the termination of a thread, and any gate operation. The inter-thread consistency rule states that all writes executed by T1 before an ensuring operation will be seen by other threads. For example: 24 <ref> [105] </ref> gives performance measurements for several levels of relaxed consistency. 58 [Thread T1] [Thread T2] -- "flag" has value false. if (flag = true) then x := 3; -- "x" must be 3 g.set; end; flag := true; * Consider Figure 2.16.
Reference: [106] <author> Kouroush Gharachorloo, Daniel Lenoski, James Laudon, Phillip Gibbons, Anoop Gupta, and John Hennessy. </author> <title> Memory Consistency and Event Ordering in Scalable Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: If every processor cache in a shared-memory machine needs to be synchronized on each write instruction, performance can be greatly reduced. 24 Various levels of consistency among processors have been defined and studied <ref> [106] </ref>. The strongest of these is sequential consistency [153] which guarantees that every read operation sees the most recent write to the same location.
Reference: [107] <author> Phillip B. Gibbons. </author> <title> A More Practical PRAM Model. </title> <type> Technical Report TR-89-019, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> Ca., </address> <month> April </month> <year> 1989. </year>
Reference: [108] <author> Aaron J. Goldberg. </author> <title> Multiprocessor Performance Debugging and Memory Bottlenecks. </title> <type> Technical Report CSL-TR-92-542, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <month> August </month> <year> 1992. </year>
Reference-contexts: Thus, in addition to compute time, parallel programs need other statistics e.g. synchronization and memory overheads. While there are research efforts that addresses such issues (reducing the monitoring overheads and measuring the memory overheads) in shared-memory multiprocessors (e.g. <ref> [108] </ref>), the research in examining such problems for distributed-memory machine remains even more open.
Reference: [109] <author> Adele Goldberg and David Robson. </author> <title> Multiple Independent Processes, </title> <booktitle> chapter 15, </booktitle> <pages> pages 249-266. </pages> <publisher> Addison-Wesley, </publisher> <year> 1983. </year>
Reference-contexts: Because of the variety of languages, this survey is by no means exhaustive. 8 We focus our attention on languages which (1) are parallel extensions of major sequential object-oriented languages (e.g. C++ [210], Smalltalk <ref> [109] </ref>, Eiffel [175]), (2) or embody a unique model or concept. The following categorization is not mutually exclusive | a language may suitably fall into more than one category.
Reference: [110] <author> Andrew V. Goldberg and Robert E. Tarjan. </author> <title> A new approach to the maximum-flow problem. </title> <journal> Journal of the ACM, </journal> <volume> 35(4) </volume> <pages> 921-940, </pages> <month> October </month> <year> 1988. </year> <month> 303 </month>
Reference-contexts: Queues are common data structures in sequential programming. A sequential program using a queue generally has a structure as in Figure 4.1. In many cases, the ordering of elements in the queue is irrelevant to the algorithms' correctness, e.g. algorithms such as graph problems (Goldberg-Tarjan's max-flow algorithm <ref> [110] </ref>), combinatorial search problems (traveling salesman problem using "2-opting", searching all solutions for an n-queens problem). These algorithms are especially amenable to parallelization, because several threads can then dequeue elements in parallel, and work independently (Figure 4.2). <p> We think that interesting applications include algorithms for the max-flow problem <ref> [66, 110] </ref>, various kinds of simulators (e.g. ICSIM [205] a neural network simulator), numerical algorithms (e.g. linear programming), and parallel constraint satisfaction systems ([117]). We have mentioned that one of pSather's goals is to provide a platform for building reusable classes.
Reference: [111] <author> B. Goldberg and P. Hudak. </author> <title> ALFALFA | Distributed Graph Reduction on a Hypercube Multiprocessor. In Workshop on Graph Reduction, </title> <booktitle> Lecture Notes in Computer Science 279. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1986. </year>
Reference-contexts: There are more memory-efficient stack techniques used in parallel functional language e.g. cactus stack <ref> [111] </ref> (which maintains the activation records in a tree of linked lists) and meshed stack [138] (which keeps activation records of multiple threads on a processor on the same stack), but our choice of stack technique is restricted by C as an intermediate language.
Reference: [112] <author> Stephen R. Goldschmidt and Helen Davis. </author> <title> Tango introduction and tutorial. </title> <type> Technical Report CSL-TR-90-410, </type> <institution> Stanford University, Computer Systems Laboratory, </institution> <month> January </month> <year> 1990. </year>
Reference-contexts: If a simulator can be configured to simulate a wide range of architectures, the programmer also benefits from being able to examine his/her program's performance on different machines (which in turn indicates the program portability). Examples of multiprocessor simulation systems include PRO-TEUS [46] and Tango <ref> [112] </ref>. The systems allow the user to record various low-level events (e.g. lock acquisition/release), but does not support the mapping of such information to high-level program components.
Reference: [113] <author> Christophe Gransart and Jean-Marc Geib. </author> <title> Reusability and Concurrency in Parallel Eiffel. </title> <booktitle> In 10th International Eiffel User Conference, </booktitle> <month> April 3 </month> <year> 1992. </year> <note> Also available as: </note> <institution> Laboratoire D'Informatique Fondamentale De Lille Publication no. </institution> <month> 112, March </month> <year> 1992. </year>
Reference-contexts: It is therefore possible to build a table that explicitly associates a routine with a function that evaluates the condition for which the routine is blocked. The Live routine of an active object may then use this table to decide which messages to receive. Parallel Eiffel Parallel Eiffel <ref> [113, 73] </ref> has a different approach from Eiffel // as it is more a tool for exploring concurrent object-oriented languages. It therefore only introduces new Eiffel classes to deal with parallelism and does not extend the language.
Reference: [114] <author> Leslie Greengard. </author> <title> The Rapid Evaluation of Potential Fields in Particle Systems. </title> <publisher> ACM Distinguished Dissertations. The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1988. </year>
Reference-contexts: P = Number of processors. &lt;Name&gt; fi &lt;n&gt; = &lt;n&gt; copies of &lt;Name&gt;, with renamed variables. 239 240 algorithm <ref> [114] </ref> takes time O (N ). We implemented two versions of the algorithm, for when the particles are evenly or unevenly distributed throughout the region. A non-adaptive algorithm is used when the particles are evenly distributed and an adaptive algorithm when they are unevenly distributed. <p> A non-adaptive algorithm is used when the particles are evenly distributed and an adaptive algorithm when they are unevenly distributed. Section 4.8.1 describes the general outline of the algorithm, but does not go into the detailed mathematics described in <ref> [114] </ref>. Section 4.8.2 describes our parallel implementation and data structures used. <p> Each region R maintains four lists of regions, simply called u-, v-, wand x-lists. The u-, v-, wand x-lists of a region R are denoted by U R , V R , W R and X R respectively. We use Figure 4.42 (from <ref> [114] </ref>) to explain their meaning. 243 244 * If R is a parent (i.e. internal) node, U R is empty. If R is a leaf node, U R consists of R and all leaf nodes adjacent to R.
Reference: [115] <author> Andrew S. Grimshaw. </author> <title> An Introduction to the Parallel Object-Oriented Programming with Mentat. </title> <type> Technical Report TR-91-07, </type> <institution> Department of Computer Science, University of Virginia, </institution> <address> Charlottesville, Virginia 22903, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The following categorization is not mutually exclusive | a language may suitably fall into more than one category. To reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat <ref> [115, 116, 183] </ref>, PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier.
Reference: [116] <author> Andrew S. Grimshaw. </author> <title> A Software Environment for High-Performance Parallel Computing. </title> <booktitle> In Proceedings of the 1991 Minnowbrook Workshop on Software Engineering for Parallel Computing, </booktitle> <month> July 16-19 </month> <year> 1991. </year>
Reference-contexts: The following categorization is not mutually exclusive | a language may suitably fall into more than one category. To reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat <ref> [115, 116, 183] </ref>, PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier.
Reference: [117] <author> Hans W. Guesgen, Kinson Ho, and Paul N. Hilfinger. </author> <title> A Tagging Method for Parallel Constraint Satisfaction. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 16 </volume> <pages> 72-75, </pages> <year> 1992. </year>
Reference: [118] <author> L. Gunaseelan and R.J. LeBlanc. </author> <title> Distributed Eiffel: A Language for Programming Multi-granular Distributed Objects on the Clouds Operating System. </title> <type> Technical Report 91/50, </type> <institution> Georgia Institute of Technology, College of Computing, </institution> <year> 1991. </year>
Reference-contexts: Parallel Versions of Eiffel Since Eiffel is one of the more well-known object-oriented languages and Sather was derived originally from Eiffel, it is therefore instructive to survey various efforts in extending Eiffel for parallel execution. We have omitted the works in <ref> [118, 148, 176] </ref> and focus on three efforts that illustrate quite different approaches. 9 This is done by "wrapping" a semaphore object around the object which is to be the actor. A message targeted to the enclosed object is sent to the semaphore.
Reference: [119] <author> R. H. Halstead, Jr. </author> <title> Multilisp: A language for concurrent symbolic computation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(4) </volume> <pages> 501-538, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: On the other hand, the data-parallel model has also commonly served as a basis for description of algorithms (such as those for graph and matrix problems [192]). While some parallel languages (e.g. Multilisp <ref> [119] </ref>, Spur Lisp [234]) have focused on providing control-parallel constructs, others (e.g. C* [127], Fortran D [132]) have concentrated on supporting data-parallel constructs. It is unnatural, if not difficult, to express data-parallel algorithms in control-parallel languages and vice-versa. <p> The caller does not wait for the result. Instead it gets a CBox object which acts as a future <ref> [119] </ref>; the result computed by the receiver is deposited in the CBox object. The receiver may return the result asynchronously, thus allowing its thread to continue execution. There is no language construct to distinguish between local and remote objects. <p> When the thread terminates, the result is enqueued in the queue of values and the thread is removed from the set of associated threads. This association of a forked thread to a gate allows us to use gates as futures <ref> [119] </ref>. g:GATEfINTg := GATEfINTg::new; -- Create a gate with queue of INT's. : : : g :- compute; : : : result := g.read; : : : 15 A runtime error due to a void gate can be caught if the program has been compiled with a runtime-check option.
Reference: [120] <author> Per Brinch Hansen. </author> <title> The programming language Concurrent Pascal. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-1(2):199-206, </volume> <month> June </month> <year> 1975. </year>
Reference: [121] <author> Per Brinch Hansen. </author> <title> The n-body pipeline. </title> <type> Technical Report SU-CIS-91-09, </type> <institution> School of Computer and Information Science, Suite 4-116, Center for Science and Technology, Syracuse, </institution> <address> New York 13244-4100, </address> <month> March </month> <year> 1991. </year>
Reference-contexts: The language must encourage modular structures in parallel programs, making it easier to port to different multiprocessors. Expressiveness of Parallel Constructs In the theoretical literature, certain common paradigms of parallel algorithms (e.g. divide-and-conquer [122, 72], pipeline <ref> [121] </ref>, normal algorithms [221] and master-worker [59]) have been recognized in various works to parallelize sequential algorithms or develop new parallel algorithms. One finds that it is more straight-forward to program algorithms in the above paradigms when certain kinds of language constructs are available.
Reference: [122] <author> Per Brinch Hansen. </author> <title> Parallel Divide and Conquer. </title> <type> Technical Report SU-CIS-91-45, </type> <institution> School of Computer and Information Science, Suite 4-116, Center for Science and Technology, Syracuse, </institution> <address> New York 13244-4100, </address> <month> December </month> <year> 1991. </year> <month> 304 </month>
Reference-contexts: The language must encourage modular structures in parallel programs, making it easier to port to different multiprocessors. Expressiveness of Parallel Constructs In the theoretical literature, certain common paradigms of parallel algorithms (e.g. divide-and-conquer <ref> [122, 72] </ref>, pipeline [121], normal algorithms [221] and master-worker [59]) have been recognized in various works to parallelize sequential algorithms or develop new parallel algorithms. One finds that it is more straight-forward to program algorithms in the above paradigms when certain kinds of language constructs are available.
Reference: [123] <author> Per Brinch Hansen. </author> <title> Monitors and Concurrent Pascal: A Personal History. </title> <booktitle> In Second ACM SIG-PLAN History of Programming Languages Conference (HOPL-II), </booktitle> <address> Cambridge, Massachusetts, USA, </address> <month> April 20-23 </month> <year> 1993. </year>
Reference-contexts: which closely parallel other synchronization constructs in other languages, such as M-structures [24] in Id, and monitors in Mesa and Concurrent Pascal ([154, 120, 123, 136, 227, 50]) Monitors PSather gates were previously called monitors [97] because of their similarity with the monitor concept in Mesa [154] and Concurrent Pascal <ref> [123] </ref>. Firstly a gate operation (monitor entry procedure) guarantees a thread (process) exclusive access to the object (Mesa module). But in pSather, the gate operations are predefined since GATEfTg and GATE0 are predefined classes.
Reference: [124] <author> Samuel P. Harbison and Guy L. Steele, Jr. </author> <title> C, A Reference Manual. </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1991. </year>
Reference-contexts: We use two general strategies to incorporate extra code that does runtime error checking. The first is for the compiler to generate code that performs specific checks. The second strategy is to define sections of code that do runtime checks within the C preprocessor #ifdef command <ref> [124] </ref> in the runtime system. When the runtime-check option is on, the compiler generates a -DRT CODE CHECK 172 flag that is fed to the C compiler and causes the #ifdef'd (or conditionally compiled) code to be included.
Reference: [125] <author> Bryan Hastings and Dan Miller. </author> <title> Fastest Number-Crunching PCs for $3000. </title> <booktitle> PC World, </booktitle> <pages> pages 132-165, </pages> <month> May </month> <year> 1993. </year>
Reference: [126] <author> Philip J. Hatcher, Anthony J. Lapadula, Robert R. Jones, Michael J. Quinn, and Ray J. Anderson. </author> <title> A Production-Quality C* Compiler for a Hypercube Multicomputer. </title> <type> Technical Report TR 90-80-3, </type> <institution> Oregon State University, Computer Science Department, </institution> <year> 1990. </year>
Reference-contexts: For example, it is possible to perform the usual object operations (e.g. routine calls, iterator calls) on distributed objects, just like ordinary objects. In C* <ref> [126, 127] </ref>, the user can declare a domain data type (just like a C struct) and then use this data type to declare domain arrays.
Reference: [127] <author> Philip J. Hatcher and Michael J. Quinn. </author> <title> Data-Parallel Programming on MIMD Computers. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1991. </year>
Reference-contexts: On the other hand, the data-parallel model has also commonly served as a basis for description of algorithms (such as those for graph and matrix problems [192]). While some parallel languages (e.g. Multilisp [119], Spur Lisp [234]) have focused on providing control-parallel constructs, others (e.g. C* <ref> [127] </ref>, Fortran D [132]) have concentrated on supporting data-parallel constructs. It is unnatural, if not difficult, to express data-parallel algorithms in control-parallel languages and vice-versa. We would like to support both these styles of computation in a coherent framework. <p> For example, it is possible to perform the usual object operations (e.g. routine calls, iterator calls) on distributed objects, just like ordinary objects. In C* <ref> [126, 127] </ref>, the user can declare a domain data type (just like a C struct) and then use this data type to declare domain arrays.
Reference: [128] <author> John Hennessy and David Patterson. </author> <title> Computer Architecture, a Quantitative Approach. </title> <publisher> Mor-gan Kaufmann Publishers, Inc., </publisher> <year> 1990. </year>
Reference-contexts: Another independent question concerns when various threads reading a variable will see the newly written value. This problem arises in modern cache-based processors and is called the memory consistency problem (for which a concise introduction is given in <ref> [128] </ref>). If every processor cache in a shared-memory machine needs to be synchronized on each write instruction, performance can be greatly reduced. 24 Various levels of consistency among processors have been defined and studied [106].
Reference: [129] <author> John L. Hennessy and Norman P. Jouppi. </author> <title> Computer Technology and Architecture: An Evolving Interaction. </title> <journal> IEEE Computer, </journal> <volume> 24(9) </volume> <pages> 18-29, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: In terms of expressiveness, pSather has both control-parallel (Section 2.3) and data-parallel constructs (Section 2.6). They have orthogonal semantics, and therefore a data-parallel execution 3 Hennessy and Jouppi <ref> [129] </ref> give a description of superscalar and superpipelining techniques which are used in the Motorola 88110 [87] and MIPS R4000 [178] processors respectively. 15 may contain thread-based parallelism and vice versa.
Reference: [130] <author> Mark D. Hill et al. </author> <title> Cooperative Shared Memory: Software and Hardware for Scalable Multiprocessors. </title> <booktitle> In Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS-V Proceedings, </booktitle> <pages> pages 262-273, </pages> <address> Boston, Mas-sachusetts, </address> <month> Oct 12 - Oct 15 </month> <year> 1992. </year>
Reference: [131] <author> W. Daniel Hillis and Guy L. Steele, Jr. </author> <title> Data Parallel Algorithms. </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1170-1183, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: We are not aware of any parallel language that supports a shared-address model for both shared-memory and distributed-memory multiprocessors, and makes NUMA an integral part of the language design. In addition to the usual control-parallel constructs (e.g. threads [35]), pSather also supports a form of data-parallelism <ref> [131] </ref> (Section 2.6) which is usable for both irregular, dynamic data structures (e.g. trees) and the regular arrays. It decouples the execution model from the execution mode of single-instruction-multiple-data (SIMD) machines. The semantics of data-parallel and control-parallel constructs are orthogonal to each other, and they co-exist within a single framework.
Reference: [132] <author> Seema Hiranandani et al. </author> <title> An Overview of the Fortran D Programming System. </title> <type> Technical Report COMP TR91-154, </type> <institution> Rice University, </institution> <address> Houston, TX 77251-1892, </address> <month> March </month> <year> 1991. </year>
Reference-contexts: On the other hand, the data-parallel model has also commonly served as a basis for description of algorithms (such as those for graph and matrix problems [192]). While some parallel languages (e.g. Multilisp [119], Spur Lisp [234]) have focused on providing control-parallel constructs, others (e.g. C* [127], Fortran D <ref> [132] </ref>) have concentrated on supporting data-parallel constructs. It is unnatural, if not difficult, to express data-parallel algorithms in control-parallel languages and vice-versa. We would like to support both these styles of computation in a coherent framework. <p> The consequence is that the location of threads are independent of the objects' location. This is in contrast to the approaches in some languages, e.g. Emerald [146] always executes the routine at the object's processor, and Fortran D <ref> [132] </ref> is implemented using an owner computes rule so that a processor computes the results of its own array elements. A possible alternative semantics of an invocation without @-operator would be that the routine is executed on the reference object's cluster.
Reference: [133] <author> Kinson Ho. </author> <title> High-level Abstractions for Symbolic Parallel Programming. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, Berkeley, </institution> <address> CA, </address> <year> 1993. </year> <note> To appear. </note>
Reference: [134] <author> Kinson Ho, Paul N. Hilfinger, and Hans W. Guesgen. </author> <title> Optimistic discrete parallel relaxation. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <address> Chambery, Savoie, France, </address> <month> Aug </month> <year> 1993. </year>
Reference: [135] <author> W. Wilson Ho. Dld, </author> <title> A Dynamic Link/Unlink Editor, Version 3.2.3. Dld package, </title> <year> 1991. </year>
Reference-contexts: Dld <ref> [135] </ref>) to add/remove object code based on program needs during execution, but this research (dynamic linking on distributed-memory multiprocessors) is beyond the scope of this work. We measure the code sizes of several programs (which will be described in Chapter 4) by adding each additional heuristic to the compilation process.
Reference: [136] <author> C. A. R. Hoare. </author> <title> Monitors: an operating system structuring concept. </title> <journal> Communications of the ACM, </journal> <volume> 17 </volume> <pages> 549-557, </pages> <month> October </month> <year> 1974. </year> <month> 305 </month>
Reference-contexts: In this approach, the mechanisms to achieve lock protection include semaphores [88] and protection of critical sections by Dekker's algorithm [30], while a construct which provides conditional wait is the condition variables (originally proposed together with the monitor concept <ref> [136] </ref>). On the other hand, the message-passing approach is characterized by the rendezvous in Ada ([23, 223]), channels in CSP (Communicating Sequential Processes [137], of which OCCAM [195] is an implementation) and the send/receive constructs in PLITS [96]. In an object-oriented language, conceptually, objects interact among themselves by message passing. <p> more in the tradition of constructs used in concurrent programming, such as fork-join [86] and semaphores [88], except that these mechanisms are defined 5 The bounded buffer has been a traditional example used in the discussion of various high-level parallel programming constructs and can be found in many references e.g. <ref> [136] </ref>. 18 as in classes and are not embodied as fixed language constructs. <p> Since our construct is quite different, using "GATE" avoids any preconceived misconceptions. A unique term also allows us to discuss more clearly the differences and similarities of our construct with other synchronization constructs, such as M-structures [24, 25] and monitors <ref> [136, 227] </ref>. 35 to 2.3.4. Then in Section 2.3.5 we point out the (minor) differences between GATEfTg and GATE0.
Reference: [137] <editor> C.A.R. </editor> <booktitle> Hoare. Communicating Sequential Processes, </booktitle> <pages> pages 136-148. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1989. </year> <note> Also published in Communications of the ACM, </note> <month> August </month> <year> 1978, </year> <pages> pp 666-677. </pages>
Reference-contexts: On the other hand, the message-passing approach is characterized by the rendezvous in Ada ([23, 223]), channels in CSP (Communicating Sequential Processes <ref> [137] </ref>, of which OCCAM [195] is an implementation) and the send/receive constructs in PLITS [96]. In an object-oriented language, conceptually, objects interact among themselves by message passing. An object invokes a routine (or method) of another object or itself by sending a message to the destination object. <p> A uTask class defines actor objects (like those of POOL2, Eiffel //) which have their own thread and execution state; the thread starts executing a distinguished routine main after the object is created and initialised. There is a uAccept statement that acts like the guarded alternatives in CSP <ref> [137] </ref>. This allows a uMutex object to select the routines to be executed based on the results of the guard expressions. There is also a uCondition class on which threads can be suspended and resumed. Unlike COOL, C++ does not have any language constructs for doing thread or object placement.
Reference: [138] <author> Guido Hogen and Rita Loogen. </author> <title> A New Stack Technique for the Management of Runtime Structures in Distributed Implementations. </title> <type> Technical Report 93-03, </type> <institution> Department of Computer Science, Aachen University of Technology, RWTH Aachen, Lehrstuhl fur Informatik II, </institution> <address> Ahornstrafie 55, W-5100 Aachen, Germany, </address> <year> 1993. </year>
Reference-contexts: There are more memory-efficient stack techniques used in parallel functional language e.g. cactus stack [111] (which maintains the activation records in a tree of linked lists) and meshed stack <ref> [138] </ref> (which keeps activation records of multiple threads on a processor on the same stack), but our choice of stack technique is restricted by C as an intermediate language.
Reference: [139] <author> Urs Holzle, Craig Chambers, and David Ungar. </author> <title> Optimizing Dynamically-Typed Object-Oriented Languages with Polymorphic Inline Caches. </title> <booktitle> In ECOOP '91 Proceedings, Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: We have, therefore, avoided elaborate techniques such as inline expansion for dispatched variables which is a technique adopted in the SELF compiler <ref> [139] </ref>. This tradeoff does not have a major impact on the applications because situations in which the optimizations are applicable do not normally use dispatched variables.
Reference: [140] <author> Chris Houck and Gul Agha. HAL: </author> <title> A High-Level Actor Languages and its Distributed Implementation. </title> <type> Technical Report UIUCDCS-R-92-1728, </type> <institution> Department of Computer Science, Uni-veristy of Illinois at Urbana-Champaign, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: One clean approach to improving the inheritability of synchronization code is to separate the synchronization of a routine from the routine's computation. An example is given by use of constraints in HAL <ref> [140] </ref>. Each routine may have an associated constraint, such that the routine is executed only when the constraint is true.
Reference: [141] <author> Jin H. Hur and Kilnam Chon. </author> <title> Overview of a parallel object-oriented language clix. </title> <type> Technical Report CS-TR-87-25, </type> <institution> Computer Science Department, Korea Advanced Institute of Science and Technology, Seoul, Republic of Korea, </institution> <year> 1987. </year>
Reference-contexts: To reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX <ref> [141] </ref>, Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier.
Reference: [142] <institution> IEEE Spectrum Special Issue: Supercomputers, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: A uniform shared-memory model therefore is too restrictive. At the systems level, it is generally acknowledged that scalable multiprocessors will have distributed memory <ref> [142] </ref>. This is the case whether they provide virtual (non-uniform) shared-memory in hardware (e.g. KSR1 [201], Dash [161]) or rely on the programmer to write message-passing programs (e.g. on CM-5 [76]) or data-parallel programs (e.g. on MasPar MP-1 [70]). This recognition of distributed memory is also found in theoretical research.
Reference: [143] <author> IEEE. </author> <title> Threads Extension for Portable Operating Systems (Draft 6), </title> <month> February </month> <year> 1992. </year> <month> P1003.4a/D6. </month>
Reference-contexts: Runtime Support The other aspect of portability is pSather's runtime of which the threads and remote operations appear to be the most system-dependent. To ensure portability, one approach is for pSather to implement its user-level threads using a common standard (e.g. POSIX threads <ref> [143, 179] </ref>) and to use the common message library (e.g. PVM [28]) for it runtime messages. 282 However a POSIX thread may still be too expensive (e.g. to implement remote calls).
Reference: [144] <institution> International Computer Science Institute. Sather 0.2i programming language and environment, </institution> <year> 1992. </year>
Reference-contexts: Another disadvantage is that the pSather compiler does not have fine-grained control of runtime resources (e.g. allocation of stack frames) which might improve system performance. The compilation environment is similar to that in Sather 0.2i <ref> [144] </ref> (a public domain Sather implementation). Since our aim is to provide a relatively stable prototype to further experiment with writing parallel applications (in pSather), the compiler is implemented in a relatively straight-forward manner using standard techniques such as those found in [5, 218] and is itself not fully optimized.
Reference: [145] <author> David R. Jefferson. </author> <title> Virtual Time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(3) </volume> <pages> 404-425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: Our prototype has been used by other researchers to implement other non-trivial applications (e.g. a multiprocessor architecture simulator using the time-warp mechanism <ref> [145] </ref>). The main 277 shortcoming of the system is the absence of debugging support and performance monitoring; we briefly discuss these possible areas of future research in Section 5.2. We have implemented a few abstractions which turn out to be reusable by applications with very different characteristics (Chapter 4).
Reference: [146] <author> Eric Jul et al. </author> <title> Fine-grained mobility in the emerald system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 109-133, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Sloop objects are allocated without any location information. The placement of an object is given indirectly via its "spatial" relationships relative to other objects. An object's location may be linked to other objects' locations, but never to specific processors. Emerald <ref> [146] </ref> is another example which supports non-uniform treatment of objects and will be discussed later (in Section 2.2.2) when we survey specific languages. Inheritance The class inheritance relationship is an important aspect of object-oriented programming. <p> If O2 is again unable to service the message, the message can be delegated again to a third object, etc. Eventually when the message is serviced, the reply is sent back to R directly. Languages for Distributed Memory Emerald Emerald <ref> [146, 40] </ref> is an object-based system for writing distributed programs. The main targeted systems are networks with about 100 nodes. Emerald is object-based, rather than object-oriented. There is no mechanism to define a class which will serve as the definition for multiple object instances. <p> A process object is not an actor; its creation simply results in a new thread that can invoke routines on other objects. For synchronization, an object constructor can include a monitor keyword to specify that at most one thread can execute in the object. The references <ref> [146, 40] </ref> however do not describe how more complex synchronization such as barrier and condition-wait can be provided. Because object mobility is a central concept in Emerald, we will describe it in more details. <p> Therefore when an object moves, activation records of its routines have to be relocated as well. This means that the runtime system has to keep track of the activation records of every movable object; this might entail high runtime costs. Jul et al. <ref> [146] </ref> describes how to reduce such costs and what to update when activation records are moved. Other Languages Orca Orca [21, 212] is targeted to deal with network latency in distributed systems. It provides a shared data-object model with passive objects and explicit threads (processes). <p> The consequence is that the location of threads are independent of the objects' location. This is in contrast to the approaches in some languages, e.g. Emerald <ref> [146] </ref> always executes the routine at the object's processor, and Fortran D [132] is implemented using an owner computes rule so that a processor computes the results of its own array elements. <p> Emerald <ref> [146] </ref>) does not support migrating objects which retain their identity, because the identity of an object is its address (including the cluster location) in our simple yet efficient model. <p> The examine operation (similar to GATE's read) is built on top of the take and put: def examine c = f v = take c ; = put c v; 2.8.2 Object Placement / NUMA Programming Model Emerald <ref> [146] </ref>, like pSather, incorporates object placement in its language semantics. In fact, object mobility is a major design goal of Emerald and affects its design (e.g. parameter passing semantics). <p> Therefore when an object moves, activation records of its routines have to be relocated as well. This means that the runtime system has to keep track of the activation records of every movable object; this might entail high runtime costs. Jul et al <ref> [146] </ref> describes how to reduce such costs and what to update when activation records are moved. In pSather, where a routine executes is independent of the object's location and is determined by the @-operator (executed in the caller). The @-operator simply specifies where a subthread executes.
Reference: [147] <author> Dennis G. Kafura and Keung Hae Lee. </author> <title> Inheritance in Actor Based Concurrent Object-Oriented Languages. </title> <booktitle> In Proceedings of the 1989 European Conference on Object-Oriented Programming, </booktitle> <pages> pages 131-145, </pages> <month> 10-14 July </month> <year> 1989. </year>
Reference-contexts: The inherited routines can be reused without change. But in an actor language with textually distributed next-message-set specification, both inherited routines have to be redefined, e.g. when insert back specifies the next set of receivable messages, it has to include the new routines. Kafura et al. <ref> [147] </ref> suggests a solution that treats the next set of receivable messages as an abstract entity. Descendent classes only need to redefine these abstract entities and not the computation parts of inherited routines. Tomlinson et al. [217] propose a similar augmentation to the next-message-set approach. <p> The ideas also do not overcome the general problems that arise from breaking class encapsulation via inheritance. Taking the earlier QUEUEfTg and DEQUEfTg examples (of which variations appear in various work <ref> [147, 47] </ref>), we note that even in sequential programming, the implementation of new routines in DEQUEfTg requires knowledge about the actual implementation of QUEUEfTg and already breaks the encapsulation in QUEUEfTg. <p> We now show how the $GATE classes can be used to deal with inheritance anomaly explicitly in a relatively clear and succinct manner. We use a bounded queue example QUEUEfTg found in various papers (e.g. <ref> [147, 173] </ref>), and show how two different descendent classes can be introduced without altering the synchronization conditions in the ancestor class. One clean approach to improving the inheritability of synchronization code is to separate the synchronization of a routine from the routine's computation.
Reference: [148] <author> M. Karaorman and J. Bruno. </author> <title> Concurrent programming with Eiffel. </title> <type> Technical Report TRCS 91-12, </type> <institution> University of California, Santa Barbara. Department of Computer Science, </institution> <year> 1991. </year>
Reference-contexts: Parallel Versions of Eiffel Since Eiffel is one of the more well-known object-oriented languages and Sather was derived originally from Eiffel, it is therefore instructive to survey various efforts in extending Eiffel for parallel execution. We have omitted the works in <ref> [118, 148, 176] </ref> and focus on three efforts that illustrate quite different approaches. 9 This is done by "wrapping" a semaphore object around the object which is to be the actor. A message targeted to the enclosed object is sent to the semaphore.
Reference: [149] <author> R. M. Karp, M. Luby, and F. Meyer auf der Heide. </author> <title> Efficient PRAM Simulation on a Distributed Memory Machine. </title> <booktitle> In Proceedings of the Twenty-Fourth Annual ACM Symposium of the Theory of Computing, </booktitle> <pages> pages 318-326, </pages> <month> May </month> <year> 1992. </year> <month> 306 </month>
Reference: [150] <author> David Keppel. </author> <title> Fast Data Breakpoints. </title> <type> Technical Report 93-04-06, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: There are two ways to look their possible link. First, many common implementation mechanisms may appear in both tools, e.g. fast data break points <ref> [150] </ref>. Another link is that they are both trying to help the programmer visualize program behavior.
Reference: [151] <author> Tim Korson and John D. McGregor. </author> <title> Understanding Object-Oriented: A Unifying Paradigm. </title> <journal> Communications of the ACM, </journal> <volume> 33(9) </volume> <pages> 40-60, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: To summarize, an architecture-independent model should be easy to use (like shared-memory) and reflects realistic memory latencies (like distributed-memory). Support Software Reuse For sequential programming, various software engineering techniques, including the object-oriented paradigm <ref> [151] </ref>, have evolved to develop and maintain complex systems. One of the goals in software engineering techniques is to make software development more productive with reuse, i.e. by having software components which can be reused in various applications.
Reference: [152] <author> Monica S. Lam. </author> <title> A Systolic Array Optimizing Compiler. </title> <booktitle> The Kluwer International Series in Engineering and Computer Science. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <year> 1989. </year>
Reference-contexts: One of the goals in software engineering techniques is to make software development more productive with reuse, i.e. by having software components which can be reused in various applications. Software reuse is well 2 The W2 language on the Warp machine <ref> [152] </ref> built in the mid 1980's at Carnegie Mellon University is an example of a language with a machine-dependent model. The model is a pipeline (or systolic) form of message passing on a fixed processor lattice. As a result, although the W2 compiler [152] implemented various optimization techniques (such as software <p> The W2 language on the Warp machine <ref> [152] </ref> built in the mid 1980's at Carnegie Mellon University is an example of a language with a machine-dependent model. The model is a pipeline (or systolic) form of message passing on a fixed processor lattice. As a result, although the W2 compiler [152] implemented various optimization techniques (such as software pipelining) to generate efficient code, W2 exposes the underlying array architecture to the programmer and is difficult to use.
Reference: [153] <author> Leslie Lamport. </author> <title> How to Make a Multiprocessor Computer that Correctly Executes Multipro-cess Programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9):241-248, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: If every processor cache in a shared-memory machine needs to be synchronized on each write instruction, performance can be greatly reduced. 24 Various levels of consistency among processors have been defined and studied [106]. The strongest of these is sequential consistency <ref> [153] </ref> which guarantees that every read operation sees the most recent write to the same location.
Reference: [154] <author> Butler W. Lampson and David D. Redell. </author> <title> Experience with Processes and Monitors in Mesa. </title> <journal> Communications of the ACM, </journal> <volume> 23(2) </volume> <pages> 105-117, </pages> <month> February </month> <year> 1980. </year>
Reference-contexts: There are two general approaches to achieving synchronization among threads [14] | shared data or message-passing. An example of the shared data approach is the use of monitors ([136, 227]) in Concurrent Pascal ([120, 123]) and Mesa <ref> [154] </ref>. In this approach, the mechanisms to achieve lock protection include semaphores [88] and protection of critical sections by Dekker's algorithm [30], while a construct which provides conditional wait is the condition variables (originally proposed together with the monitor concept [136]). <p> A third reason is that programmers often combine low level mechanisms to get high level synchronizations (e.g. using semaphores to build barriers). Sometimes the low level mechanisms may not be at the right level of abstraction. For example, if only condition variables <ref> [154] </ref> and locks are provided, the programmer will find it difficult to atomically wait on a conditional variable and release a lock. The main disadvantage of the integrated functionalities in GATE is that some efficiency may be lost. <p> They provide functionalities which closely parallel other synchronization constructs in other languages, such as M-structures [24] in Id, and monitors in Mesa and Concurrent Pascal ([154, 120, 123, 136, 227, 50]) Monitors PSather gates were previously called monitors [97] because of their similarity with the monitor concept in Mesa <ref> [154] </ref> and Concurrent Pascal [123]. Firstly a gate operation (monitor entry procedure) guarantees a thread (process) exclusive access to the object (Mesa module). But in pSather, the gate operations are predefined since GATEfTg and GATE0 are predefined classes. <p> After getting a gate G associated with k, we unlock the shared gate and suspend the executing thread: unlock g; wait gate.read; Even though the unlocking and thread suspension does not execute atomically (unlike the wait operation on condition variable in Mesa's monitor <ref> [154] </ref>), the code works correctly because we maintain the following invariant: G is bound iff there exists an object O1 such that (k, O1) is in the shared hash table. 9 Two or more threads may simultaneously try to insert copies for the same key into the same local table.
Reference: [155] <author> Bernard Lang, Christian Queinnec, and Jose Piquer. </author> <title> Garbage Collecting the World. </title> <booktitle> In Nineteenth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 39-50, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: Whatever the case, the GC scheme probably has to be tightly integrated with the runtime support system for good performance. 280 <ref> [155, 172] </ref> are examples of research efforts on design and implementation of distributed GC. 5.2.4 Better Compilation Strategies There are two issues in the compiler's intermediate representation (IR) which we have not examined so far.
Reference: [156] <institution> Sather language mailing list. </institution> <note> Discussions on sather language, 1991-current. Notes available by anonymous ftp from icsi-ftp.berkeley.edu. </note>
Reference-contexts: further complicates the semantics of the deferred-assignment statement without any benefit to expressiveness. (Although iterators do not work with deferred-assignment, they work well with dist statement to support data-parallel execution (Section 2.7.3).) 38 An analogy is that an iterator is to structured coroutine, as a loop is to structured goto <ref> [156] </ref>. 83 Another Detail In pSather 0.1's deferred assignment statement, when the left-hand-side is a GATE0 object, the right-hand-side may or may not have any return value. This is in accordance with the semantics in Sather 0.1 which allows the result of any routine call to be discarded. <p> The Sather compiler implemented at Karlsruhe demonstrates an alternative dispatch implementation <ref> [156] </ref> that is both efficient and theoretically will not rely on the protection given by non-polling during dispatching. * (+) The runtime can avoid locking runtime data structures (e.g. ready queue) because the absence of polling guarantees that the data structure is protected during update (Section 3.2).
Reference: [157] <author> Steven T. Lansdowne, Robert E. Cousins, and D. Clark Wilkinson. </author> <title> Reprogramming the sieve of eratosthenes. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 90-91, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: It used a master-worker model, where each time the master program finds a prime p, it asks an idle (worker) process to mark out multiples of p. It was, however, unable to obtain speedup beyond six processors. Lansdowne et al. <ref> [157] </ref> describes a better parallel implementation with better speedup (speedup of about 18.4 on a 20-processor CSI-150 system). Their approach was to find all primes from 2 and p N sequentially, and divide the range p N + 1 to N among the processors.
Reference: [158] <author> James R. Larus. </author> <title> Restructuring Symbolic Programs for Concurrent Exectuion on Multiprocessors. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <year> 1989. </year> <note> Also available as: Report No. UCB/CSD 89/502, </note> <month> May </month> <year> 1989, </year> <institution> Cmputer Division (EECS), Berkeley, California 94720. </institution>
Reference: [159] <author> Jenq Kuen Lee and Dennis Gannon. </author> <title> Object Oriented Parallel Programming Experiments and Results. </title> <booktitle> In Proceedings of Supercomputing '91. </booktitle> <publisher> IEEE Computer Society Press and ACM SIGARCH, </publisher> <month> November </month> <year> 1991. </year>
Reference-contexts: There is also a uCondition class on which threads can be suspended and resumed. Unlike COOL, C++ does not have any language constructs for doing thread or object placement. PC++ A major concern of PC++ <ref> [103, 159] </ref> is to be able to build complex distributed data structures (e.g. arrays, lists, sets) in distributed-memory machines. PC++ extends C++ by introducing the notion of a collection which is a homogeneous group of elements. <p> There is no such restriction in pSather. * Because the idea of domain is closely associated with the data-parallel construct (domain select statement), it is not obvious that a domain object can exist independent of a domain array. In PC++ <ref> [159] </ref>, there is the concept of a homogeneous collection of objects which is analogous to the domain array in C*. The data-parallel construct is also similar to that in C*.
Reference: [160] <author> A.L. Leiner, W.A. Notz, J.L. Smith, and A. Weinberger. </author> <title> PILOT ANew Multiple Computer System. </title> <journal> Journal of the ACM, </journal> <volume> 6 </volume> <pages> 313-335, </pages> <year> 1959. </year>
Reference: [161] <author> Daniel Lenoski et al. </author> <title> The Stanford Dash Multiprocessor. </title> <journal> IEEE Computer, </journal> <volume> 25(3) </volume> <pages> 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: A uniform shared-memory model therefore is too restrictive. At the systems level, it is generally acknowledged that scalable multiprocessors will have distributed memory [142]. This is the case whether they provide virtual (non-uniform) shared-memory in hardware (e.g. KSR1 [201], Dash <ref> [161] </ref>) or rely on the programmer to write message-passing programs (e.g. on CM-5 [76]) or data-parallel programs (e.g. on MasPar MP-1 [70]). This recognition of distributed memory is also found in theoretical research. <p> framework. * We want the long latencies of remote operations on large-scale multiprocessors to be made visible to the programmer, so that these costs can be taken into account when writing programs. * We want pSather programs to continue to be compatible with the forseeable new multiprocessor architectures like Dash <ref> [161] </ref> and other cluster-based systems like Cray T3D. The abstract machine model has P asynchronous processors grouped in C clusters. The model presents a shared logical address-space to the programmers, but divides the address space such that each cluster has its own physical address-space.
Reference: [162] <author> Zhiyuan Li and Pen-Chung Yew. </author> <title> Efficient Interprocedural Analysis for Program Parallelization and Restructuring. </title> <booktitle> In Proceedings of the ACM/SIGPLAN Parallel Programming Experience with Applications, Languages and Systems (PPEALS) Symposium, </booktitle> <pages> pages 85-99, </pages> <year> 1988. </year> <title> Proceedings also published as: </title> <journal> SIGPLAN Notices, </journal> <volume> Vol. 23, No. 9, </volume> <month> September </month> <year> 1988. </year> <month> 307 </month>
Reference: [163] <author> Chu-Cheow Lim, Jerome A. Feldman, and Stephan Murer. </author> <title> Unifying Control- and Data-parallelism in an Object-Oriented Language. </title> <booktitle> In Joint Symposium on Parallel Processing, </booktitle> <address> Tokyo, Japan 1993, </address> <month> May 17 - 19 </month> <year> 1993. </year>
Reference-contexts: We expect the library designers to take advantage of such optimizations in commonly used library routines; an example is a distributed matrix multiplication routine described in <ref> [163] </ref>. 3.6.2 Invoking Routines. Another set of important operations is the invocation of routines. Section 3.3 describes how the compiler distinguishes between suspendable and non-suspendable routines in order to generate more efficient code for non-suspendable remote calls.
Reference: [164] <author> Chu-Cheow Lim and Andreas Stolcke. </author> <title> Sather Language design and performance evaluation. </title> <type> Technical Report TR-91-034, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> Ca., </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Last but not least, our design is based on Sather because we want pSather to leverage off Sather's efficient implementation. Performance measurements on Sather <ref> [164] </ref> have shown that a Sather program incurs small overhead (in the range of 10%) relative to a corresponding C program. <p> The code for these classes are eliminated in V2. 3.5.2 Integrating Dispatch and Access One interesting aspect of Sather/pSather implementation was a compiler-generated software cache for dispatching <ref> [164] </ref>. Given a dispatched call "&lt;obj&gt;.&lt;feature&gt;" where &lt;obj&gt; has an abstract type, the Sather compiler generates the code sequence in Figure 3.25. <p> Before we discuss the speedups of the parallel programs, we make some observations about the program's overhead costs in a parallel environment. A sequential Sather/pSather program on CM-5 (pSather/V1) is about 15% to 20% slower than a corresponding C program. This is consistent with the 10% penalty reported in <ref> [164] </ref>. The additional penalty is incurred by having long pointers on CM-5.
Reference: [165] <author> Klaus-Peter Lohr. </author> <title> Concurrency Annotations. </title> <booktitle> In OOPSLA Conference Proceedings, </booktitle> <pages> pages 327-340, </pages> <month> October </month> <year> 1992. </year> <title> Proceedings available as: </title> <journal> SIGPLAN Notices, </journal> <volume> Vol 27, No 10, </volume> <month> October </month> <year> 1992. </year>
Reference-contexts: The approach of CEiffel <ref> [165] </ref> is to add annotations that would be used by a compiler for parallel machines but otherwise ignored. For example, annotating a routine definition with "-v-" indicates that a new thread is forked when this routine is called.
Reference: [166] <author> Tom Lovett and Shreekant Thakkar. </author> <title> The Symmetry Multiprocessor System. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <pages> pages 303-310. </pages> <institution> Pennsylvania State University Press, University Park, </institution> <address> PA., </address> <year> 1988. </year>
Reference: [167] <author> Steven E. Lucco. </author> <title> Parallel Programming in a Virtual Object Space. </title> <booktitle> In Proceedings OOPSLA '87, </booktitle> <pages> pages 26-34. </pages> <publisher> ACM, </publisher> <month> December </month> <year> 1987. </year> <title> Proceedings available as: </title> <booktitle> SIGPLAN Notice Vol 22, </booktitle> <volume> No. 12, </volume> <month> Dec </month> <year> 1987. </year>
Reference-contexts: Tarmac [168]) that automatically performs load balancing and maps allocated objects on different processors is needed. There are however parallel object-oriented languages which support a non-uniform shared-address space in a high-level manner. For example, Sloop <ref> [167] </ref> lets the programmer specify alignment relationships among objects via calls to an align routine. <p> To reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop <ref> [167] </ref>, Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier. Parallel Versions of Smalltalk We first look at some parallel implementations of Smalltalk.
Reference: [168] <author> Steven E. Lucco and David P. Anderson. Tarmac: </author> <title> a language system substrate based on mobile memory. </title> <type> Technical Report UCB/CSD 89/525, </type> <institution> Computer Science Division (EECS), University of California, Berkeley, </institution> <address> CA 94720, </address> <month> November </month> <year> 1989. </year>
Reference-contexts: BODY WHILE &lt;condition satisfied&gt; DO IF empty THEN ANSWER (insert back) ELSE ANSWER (insert back, get front) OD; YDOB access (NUMA) or distributed-memory multiprocessor, a runtime system (e.g. Tarmac <ref> [168] </ref>) that automatically performs load balancing and maps allocated objects on different processors is needed. There are however parallel object-oriented languages which support a non-uniform shared-address space in a high-level manner. For example, Sloop [167] lets the programmer specify alignment relationships among objects via calls to an align routine.
Reference: [169] <editor> Mesaac Makpangou et al. </editor> <title> Structuring distributed applications as fragmented objects. </title> <type> Technical Report 1404, </type> <institution> INRIA, France, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS <ref> [206, 169] </ref>, Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier. Parallel Versions of Smalltalk We first look at some parallel implementations of Smalltalk. Distributed Smalltalk Bennett [31] describes an implementation of Distributed Smalltalk on a network of Sun 2 workstations.
Reference: [170] <author> Evangelos P. Markatos and Thomas J. LeBlanc. </author> <title> Load Balancing vs. Locality Management in Shared-Memory Multiprocessors. </title> <type> Technical Report 399, </type> <institution> The University of Rochester, Computer Science Department, Rochester, </institution> <address> New York 14627, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: the local sub-bag before looking in the remote sub-bags. (Section 4.1.5 will describe the insertion and retrieval routines in more details.) Our setup pays more attention to data locality than load balancing, because with non-uniform memory accesses, it is generally important to reduce remote communication between processors in different clusters <ref> [170] </ref>. A complication with a parallel workbag is termination detection. We want to terminate the program when the bag/queue becomes empty permanently. In the sequential case (Figure 4.1), because there is only one thread of control, when the queue becomes empty, it stays empty.
Reference: [171] <author> Satoshi Matsuoka. </author> <title> Language Features for Extensibility and Re-use in Concurrent Object-Oriented Languages. </title> <type> PhD thesis, </type> <institution> University of Tokyo, </institution> <year> 1993. </year> <note> In preparation. </note>
Reference-contexts: For example Frtlund [101] argues that synchronization constraints should disable rather than enable routines for incremental specification. An exhaustive study of inheritance anomaly is beyond our scope, but such a study for actor languages is given by Matsuoka <ref> [171] </ref>. His thesis describes the problem in detail, discusses various proposals in the literature and the situations when they would fail, and presents language constructs in actor languages to overcome this problem.
Reference: [172] <author> Satoshi Matsuoka, Shin'ichi Furuso, and Akinori Yonezawa. </author> <title> A Fast Parallel Conservative Garbage Collector for Concurrent Object-Oriented Systems. </title> <booktitle> In Proceedings of IEEE International Workshop on Object Orientation in Operating Systems, </booktitle> <pages> pages 87-93, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Whatever the case, the GC scheme probably has to be tightly integrated with the runtime support system for good performance. 280 <ref> [155, 172] </ref> are examples of research efforts on design and implementation of distributed GC. 5.2.4 Better Compilation Strategies There are two issues in the compiler's intermediate representation (IR) which we have not examined so far.
Reference: [173] <author> Satoshi Matsuoka, Ken Wakita, and Akinori Yonezawa. </author> <title> Analysis of Inheritance Anomaly in Concurrent Object-Oriented Languages, </title> <month> October </month> <year> 1990. </year> <note> (Proceedings unpublished). </note>
Reference-contexts: We now show how the $GATE classes can be used to deal with inheritance anomaly explicitly in a relatively clear and succinct manner. We use a bounded queue example QUEUEfTg found in various papers (e.g. <ref> [147, 173] </ref>), and show how two different descendent classes can be introduced without altering the synchronization conditions in the ancestor class. One clean approach to improving the inheritability of synchronization code is to separate the synchronization of a routine from the routine's computation.
Reference: [174] <author> Bertrand Meyer. </author> <title> Applying "Design by Contract". </title> <journal> IEEE Computer, </journal> <volume> 25(10) </volume> <pages> 40-51, </pages> <month> October </month> <year> 1992. </year> <month> 308 </month>
Reference-contexts: But the user programs should remain unchanged. Any rewrite of the code libraries should, however, still be relatively straight-forward using the language facilities. We adopt a "design by contract" philosophy, similar to Eiffel <ref> [174] </ref>. The interface of a class will specify what it provides in terms of efficiency, safety and functionality. There are tradeoffs between efficiency and safety in parallel programming; for example, data structures which are not shared by parallel threads can be more efficient because there is no synchronization overhead.
Reference: [175] <author> Bertrand Meyer. </author> <title> Eiffel: The Language. </title> <publisher> Prentice Hall, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Because of the variety of languages, this survey is by no means exhaustive. 8 We focus our attention on languages which (1) are parallel extensions of major sequential object-oriented languages (e.g. C++ [210], Smalltalk [109], Eiffel <ref> [175] </ref>), (2) or embody a unique model or concept. The following categorization is not mutually exclusive | a language may suitably fall into more than one category.
Reference: [176] <author> Betrand Meyer. </author> <title> Sequential and concurrent object-oriented programming. </title> <booktitle> In Proceedings of TOOLS '90, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: Parallel Versions of Eiffel Since Eiffel is one of the more well-known object-oriented languages and Sather was derived originally from Eiffel, it is therefore instructive to survey various efforts in extending Eiffel for parallel execution. We have omitted the works in <ref> [118, 148, 176] </ref> and focus on three efforts that illustrate quite different approaches. 9 This is done by "wrapping" a semaphore object around the object which is to be the actor. A message targeted to the enclosed object is sent to the semaphore.
Reference: [177] <author> Barton P. Miller. </author> <title> What to Draw? When to Draw? An essay on Parallel Program Visualization. </title> <type> Technical Report 1103, </type> <institution> Computer Sciences Department, University of Wisconsin - Madison, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: Parasight [16] was a research effort that aims to support "programming for observability". Because performance monitoring and debugging share common aims ("provide information on program behavior"), they also share common research issues such as parallel program visualization <ref> [177] </ref> (or even auralization). In addition to software tools, other common approaches in parallel debugging is by static analysis (e.g. [89]), or a combination of logging information during execution with post-mortem analysis (e.g. [69]). One dimension of the debugging problem is the methodology (e.g. software tracing vs. static analysis).
Reference: [178] <author> Sunil Mirapuri, Michael Woodacre, and Nader Vasseghi. </author> <title> The MIPS R4000 Processor. </title> <booktitle> IEEE Micro, </booktitle> <pages> pages 10-22, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: In terms of expressiveness, pSather has both control-parallel (Section 2.3) and data-parallel constructs (Section 2.6). They have orthogonal semantics, and therefore a data-parallel execution 3 Hennessy and Jouppi [129] give a description of superscalar and superpipelining techniques which are used in the Motorola 88110 [87] and MIPS R4000 <ref> [178] </ref> processors respectively. 15 may contain thread-based parallelism and vice versa. Last but not least, our design is based on Sather because we want pSather to leverage off Sather's efficient implementation. <p> We think that if a machine like CM-5 were to use MIPS R4000 <ref> [178] </ref> instead of a Sparc, the overheads of our implementation would be much less. Otherwise, a processor design targeted for multiprocessor also holds better promise.
Reference: [179] <author> Frank Mueller. </author> <title> A Library Implementation of POSIX Threads under Unix. </title> <booktitle> In 1993 Winter USENIX, </booktitle> <pages> pages 29-41, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Runtime Support The other aspect of portability is pSather's runtime of which the threads and remote operations appear to be the most system-dependent. To ensure portability, one approach is for pSather to implement its user-level threads using a common standard (e.g. POSIX threads <ref> [143, 179] </ref>) and to use the common message library (e.g. PVM [28]) for it runtime messages. 282 However a POSIX thread may still be too expensive (e.g. to implement remote calls).
Reference: [180] <author> Stephan Murer and Philipp Farber. </author> <title> A Scalable Distributed Shared Memory. </title> <booktitle> In Proceedings of CONPAR 92-VAPP V - Lyon, </booktitle> <address> France, </address> <publisher> LNCS 634. Springer-Verlag, </publisher> <month> September </month> <year> 1992. </year>
Reference: [181] <author> Stephan Murer, Jerome A. Feldman, and Chu-Cheow Lim. pSather: </author> <title> Layered Extensions to an Object-Oriented Language for Efficient Parallel Computation. </title> <type> Technical Report TR 93-028, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> Ca., </address> <month> June </month> <year> 1993. </year>
Reference-contexts: In this section, we start with a simplified machine model with uniform shared memory. This allows us to focus on the language constructs that provide threads and synchronization. Then 12 This is joint work with Jerry Feldman, Franco Mazzanti and Stephan Murer, also described in [97] (pSather 0.1) and <ref> [181] </ref> (pSather 1.0). 34 in Section 2.4, we generalize the machine model to a cluster model that is applicable to both shared and distributed memory machines. Section 2.5 describes language constructs for programming in the cluster model's non-uniform shared address space. <p> The routines init dist, is done, curr chunk, curr c index and next dist serve as a way to index through the array of chunks. They are used by the dist statement (next Section) and their functionalities are replaced by a single iterator in pSather 1.0 <ref> [182, 181] </ref>. 2.6.2 dist statement PSather has a dist-statement for data-parallel computation on objects inheriting from DISTfTg. We introduce the syntax and the semantics of the dist-statement and in the next section, show examples for the dist-statement. <p> The routine computes the square of the Euclidean distance between self and the first parameter a. The return value is the square of the Euclidean distance iff it is less than or equal to a 35 A dot product example in Section 7.3 of <ref> [181] </ref> shows how this is used. 36 This obviously assumes that an n-chunk distributed structure numbers them 0; : : : ; n. 77 1 : scale by (a:DOUBLE) is 2 : -- Scale "self" by "a". 3 : dist self as c do 4 : i:INT; until i&gt;=c.size loop c
Reference: [182] <author> Stephan Murer, Stephen Omohundro, and Clemens Szyperski. Sather Iters: </author> <title> Object-oriented Iteration Abstraction, </title> <year> 1993. </year>
Reference-contexts: to be done for parallel programming environments to be as easily usable as commercial sequential environments. 6 Sather 1.0 allows overloading and hence features of the same name as long as they can be disambiguated by their type signatures. 7 Sather 1.0 also introduces new powerful encapsulation mechanisms, e.g. iters <ref> [182] </ref>, but these are not part of the thesis 9 Language PSather has a cluster machine model (Section 2.4) which includes non-uniform memory access (NUMA) as part of the shared-address space model. The cluster model applies to both shared-memory and distributed-memory multiprocessors, and is supported by several parallel constructs. <p> The routines init dist, is done, curr chunk, curr c index and next dist serve as a way to index through the array of chunks. They are used by the dist statement (next Section) and their functionalities are replaced by a single iterator in pSather 1.0 <ref> [182, 181] </ref>. 2.6.2 dist statement PSather has a dist-statement for data-parallel computation on objects inheriting from DISTfTg. We introduce the syntax and the semantics of the dist-statement and in the next section, show examples for the dist-statement. <p> This analysis to detect intermediate objects is also 154 useful for other kinds of objects such as CURSOR [187]. With the language extensions in 1.0, COMPLEX can be implemented as a value class, and the functionalities are cursors are handled by iterators <ref> [182] </ref>. These extensions would probably reduce the usefulness of this analysis. This analysis however is relevant in application program written in pSather 0.1 (e.g. fast multipole N-body algorithm) and also demonstrates how inlining impacts interprocedural analysis. We now describe the technique used.
Reference: [183] <author> Padmini Narayan, Sherry Smoot, Ambar Sarkar, Emily West, Andrew Grimshaw, and Timothy Strayer. </author> <title> Portability and Performance: Mentat Applications on Diverse Applications. </title> <type> Technical Report TR-92-22, </type> <institution> Department of Computer Science, University of Virginia, </institution> <address> Charlottesville, Virginia 22903, </address> <month> July 22 </month> <year> 1992. </year>
Reference-contexts: The following categorization is not mutually exclusive | a language may suitably fall into more than one category. To reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat <ref> [115, 116, 183] </ref>, PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier.
Reference: [184] <author> O.M. Nierstrasz. </author> <title> Active Objects in Hybrid. </title> <booktitle> In OOPSLA 1987 Conference Proceedings, </booktitle> <pages> pages 243-253, </pages> <month> Oct 4 - Oct 8 </month> <year> 1987. </year>
Reference-contexts: An actor (data object with thread) receives messages from others and processes them. In the third approach, objects are passive entities while threads are loci of execution control independent of objects (e.g. Hybrid <ref> [184] </ref>, COOL [62]). The programmer does not have any explicit handle to the thread, so that he cannot perform operations like moving the thread from one scheduler object to another. Most languages in this model allow multiple threads to execute in an object at the same time. Other languages (e.g. <p> The programmer does not have any explicit handle to the thread, so that he cannot perform operations like moving the thread from one scheduler object to another. Most languages in this model allow multiple threads to execute in an object at the same time. Other languages (e.g. Hybrid <ref> [184] </ref>) group objects into protection domains such that at most one thread can be active in a domain. Other than the three main approaches above, a combination of the approaches is possible and used in some languages. For example, Rosette has both actors and passive objects [217]. <p> In the third model (threads/passive objects), there are separate mechanisms to create threads and objects, so languages with this model have constructs that support explicit thread creation (e.g. the reflex operation in Hybrid <ref> [184] </ref> or invocation of parallel function in COOL [62]). Synchronization/Communication With multiple threads of control, there must be some ways for the threads to communicate and synchronize. <p> To reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid <ref> [184] </ref>, PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier. Parallel Versions of Smalltalk We first look at some parallel implementations of Smalltalk.
Reference: [185] <author> Roger J. Noe. </author> <title> Pablo Instrumentation Environment User's Guide (Final Draft Version), </title> <month> June </month> <year> 1992. </year> <title> Part of Pablo Performance Analysis Environment (Release 1.0). </title>
Reference-contexts: There are various ongoing research efforts in performance debugging. [65] has a summary of various software performance monitoring tools for multiprocessors. For example, Pablo <ref> [197, 185] </ref> is a high-level instrumentation system for sequential and (distributed-memory) multiprocessors; it requires the programmer to insert trace calls in the program.
Reference: [186] <author> R.R. Oldehoeft et al. </author> <title> The SISAL 2.0 reference manual. </title> <type> Technical Report UCRL-MA-109098, </type> <institution> Lawrence Livermore National Laboratory, Livermore, </institution> <address> CA., </address> <month> December </month> <year> 1991. </year>
Reference: [187] <author> Stephen Omohundro and Chu-Cheow Lim. </author> <title> The Sather Language and Libraries. </title> <type> Technical Report TR-92-017, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> Ca., </address> <month> March </month> <year> 1992. </year>
Reference-contexts: We rely on the compiler (with a little user help) to detect intermediate short-lived objects whose memory allocation is then managed runtime user help) via a simple data-flow analysis on variables. This analysis to detect intermediate objects is also 154 useful for other kinds of objects such as CURSOR <ref> [187] </ref>. With the language extensions in 1.0, COMPLEX can be implemented as a value class, and the functionalities are cursors are handled by iterators [182]. These extensions would probably reduce the usefulness of this analysis.
Reference: [188] <author> Stephen M. Omohundro. </author> <title> The Sather Language. </title> <type> Technical report, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> Ca., </address> <year> 1991. </year> <month> 309 </month>
Reference-contexts: The type systems in 0.1 and 1.0 are described in detail in <ref> [188] </ref> and [189] respectively. 0.1 has only value and reference objects: a value object has a value class as its type while a reference object has a reference class as its type. 1.0 further introduces bound objects which have predefined bound types (not associated with any class). <p> It also supports data-parallel computation with a dist-statement (Section 2.6) which implicitly creates parallel threads for distributed data structures. PSather does not treat threads as first-class objects because the initial version of Sather <ref> [188] </ref> does not support any form of closure or routine as first-class objects. The new language specification has a form of closure called bound routines (Section 1.2). As pSather evolves, one might imagine eliminating the thread-related constructs and having a predefined THREADfTg class instead (Figure 2.4).
Reference: [189] <author> Stephen M. Omohundro. </author> <title> The Sather 1.0 Specification. </title> <type> Technical report, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> Ca., </address> <year> 1993. </year>
Reference-contexts: The type systems in 0.1 and 1.0 are described in detail in [188] and <ref> [189] </ref> respectively. 0.1 has only value and reference objects: a value object has a value class as its type while a reference object has a reference class as its type. 1.0 further introduces bound objects which have predefined bound types (not associated with any class). <p> This version is implemented in the current prototype (Chapter 3). In the following sections, we further clarify the semantics of the pSather extensions in the context of Sather 1.0 37 <ref> [189] </ref>. The overall semantics remain unchanged. <p> Table B.1 shows the sugar expressions in Sather 1.0 <ref> [189] </ref>. 286 Appendix C Sequential SOR Programs for (i = 1; i &lt; s; i++) f matrix [i*ncols+j] = (omega1 * matrix [i*ncols+j]) + omega * (matrix [i*ncols+(j-1)] + matrix [i*ncols+(j+1)] + matrix [(i-1)*ncols+j] + matrix [(i+1)*ncols+j]); g Figure C.1: C code in SOR (which updates the variables in each iteration),
Reference: [190] <author> Joseph Pallas and David Ungar. </author> <title> Multiprocessor Smalltalk: A Case Study of a Multiprocessor-Based Programming Environment. </title> <booktitle> In Proceedings of the SIGPLAN 1988 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 268-277, </pages> <address> Atlanta, Georgia, </address> <month> June 22-24 </month> <year> 1988. </year>
Reference-contexts: Because it follows a traditional remote operation model, it is possible to invoke routines on remote objects in a transparent manner. Synchronization is provided by Smalltalk classes (i.e. shared data approach) and there is support to move and copy objects to different processors. Multiprocessor Smalltalk MP Smalltalk <ref> [191, 190] </ref> is an implementation of Smalltalk-80 on a multiprocessor without any language extensions. Unlike Distributed Smalltalk, it presents a shared-address space to the programmer. Parallelism and synchronization are derived from the Process and Semaphore classes. The system therefore treats Processes (threads) like any first-class objects.
Reference: [191] <author> Joseph Ira Pallas. </author> <title> Multiprocessor Smalltalk: Implementation, Performance and Analysis. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> June </month> <year> 1990. </year> <note> Also available as technical report CSL-TR-90-429. </note>
Reference-contexts: Because it follows a traditional remote operation model, it is possible to invoke routines on remote objects in a transparent manner. Synchronization is provided by Smalltalk classes (i.e. shared data approach) and there is support to move and copy objects to different processors. Multiprocessor Smalltalk MP Smalltalk <ref> [191, 190] </ref> is an implementation of Smalltalk-80 on a multiprocessor without any language extensions. Unlike Distributed Smalltalk, it presents a shared-address space to the programmer. Parallelism and synchronization are derived from the Process and Semaphore classes. The system therefore treats Processes (threads) like any first-class objects. <p> For example, multiprocessor Smalltalk <ref> [191] </ref> has a Collection class which supports this notion of data-parallelism. When a collection object receives a parallelDo: message, it invokes a block in parallel for all the objects in the collection.
Reference: [192] <author> Cynthia A. Phillips. </author> <title> Theoretical and Experimental Analysis of Parallel Combinatorial Algorithms. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <month> October </month> <year> 1989. </year> <note> Also available as: MIT VLSI Publications, VLSI Memo No. 90-577, </note> <month> June </month> <year> 1990. </year>
Reference-contexts: Examples of such control-parallel language constructs include the ability to create parallel threads of control and synchronization mechanisms such as lock, barrier etc. On the other hand, the data-parallel model has also commonly served as a basis for description of algorithms (such as those for graph and matrix problems <ref> [192] </ref>). While some parallel languages (e.g. Multilisp [119], Spur Lisp [234]) have focused on providing control-parallel constructs, others (e.g. C* [127], Fortran D [132]) have concentrated on supporting data-parallel constructs. It is unnatural, if not difficult, to express data-parallel algorithms in control-parallel languages and vice-versa.
Reference: [193] <author> Maria Cristina Pinotti and Geppino Pucci. </author> <title> Parallel Priority Queues. </title> <type> Technical Report TR-91-016, </type> <institution> International Computer Science Institute, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: We have mentioned that one of pSather's goals is to provide a platform for building reusable classes. In Chapter 4, we have discussed some abstractions, but there are other data structures (e.g. parallel priority queues <ref> [193] </ref>) which we did not look at.
Reference: [194] <author> Carl Glen Ponder. </author> <title> Evaluation of "Performance Enhancements" in Algebraic Manipulation Systems. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <year> 1988. </year> <note> Also available as Report No. UCB/CSD 88/438, </note> <month> August, </month> <year> 1988, </year> <institution> Computer Science Division (EECS), University of California, Berkeley, </institution> <address> CA 94720. </address>
Reference-contexts: Buchberger [49] gives an algorithm which computes a reduced Grobner basis. The computation has two phases: the first produces a Grobner basis G and the second produces the reduced basis from G. There have been various attempts at parallelizing Buchberger's algorithm <ref> [194, 61, 225] </ref>, but our aim is slightly different. We want to produce a reasonably efficient parallel program us ing existing software components.
Reference: [195] <author> Dick Pountain. </author> <title> A tutorial introduction to OCCAM programming. Inmos Occam Manual. </title>
Reference-contexts: On the other hand, the message-passing approach is characterized by the rendezvous in Ada ([23, 223]), channels in CSP (Communicating Sequential Processes [137], of which OCCAM <ref> [195] </ref> is an implementation) and the send/receive constructs in PLITS [96]. In an object-oriented language, conceptually, objects interact among themselves by message passing. An object invokes a routine (or method) of another object or itself by sending a message to the destination object.
Reference: [196] <author> Umakishore Ramachandran and M. Yousef A. Khalidi. </author> <title> An Implementation of Distributed Shared Memory. </title> <type> Technical Report GIT-ICS-88/50, </type> <institution> School of Information and Computer Science, Georgia Institute of Technology, </institution> <address> Atlanta, Ga 30332-0280 USA, </address> <month> December </month> <year> 1988. </year>
Reference: [197] <author> Daniel A. Reed, Ruth A. Aydt, Tara M. Madhyastha, Roger J. Noe, Keith A. Shields, and Bradley W. Schwartz. </author> <title> The Pablo Performance Analysis Environment, 1992. Part of Pablo Performance Analysis Environment (Release 1.0). </title>
Reference-contexts: There are various ongoing research efforts in performance debugging. [65] has a summary of various software performance monitoring tools for multiprocessors. For example, Pablo <ref> [197, 185] </ref> is a high-level instrumentation system for sequential and (distributed-memory) multiprocessors; it requires the programmer to insert trace calls in the program.
Reference: [198] <author> Steven K. Reinhardt, Mark D. Hill, James R. Larus, Alvin R. Lebeck, James C. Lewis, and David A. Wood. </author> <title> The Wisconsin Wind Tunnel: Virtual Prototyping of Parallel Computers. </title> <booktitle> In Proceedings of the 1993 ACM SIGMETRICS Conference, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: One possible approach is to alter the operating system, like Wisconsin Wind Tunnel <ref> [198] </ref> (WWT). WWT effectively simulates shared virtual memory by treating a CM-5 node's memory pages as caches for a virtual target machine.
Reference: [199] <institution> Kendall Square Research. Kendall Square Research: </institution> <type> Technical Summary. </type>
Reference: [200] <author> Stephen Richardson and Mahadevan Ganapathi. </author> <title> Interprocedural analysis vs. procedure integration. </title> <journal> Information Processing Letters, </journal> <volume> 32 </volume> <pages> 137-142, </pages> <year> 1989. </year>
Reference-contexts: In addition to reducing procedure call overheads, inlining also allows the body of an inlined procedure to be analyzed and optimized specific to its called context <ref> [200] </ref>. One disadvantage of inlining is that it increases the size of the executable although a study in [83] concludes that this size increase is not a problem in practice. [84] is another reference that discusses various factors that influence the speedup of inlined code.
Reference: [201] <author> James Rothnie. </author> <title> Overview of the KSR1 Computer System. </title> <type> Kendall Square Research Report TR 9202001, </type> <month> March </month> <year> 1992. </year> <month> 310 </month>
Reference-contexts: A uniform shared-memory model therefore is too restrictive. At the systems level, it is generally acknowledged that scalable multiprocessors will have distributed memory [142]. This is the case whether they provide virtual (non-uniform) shared-memory in hardware (e.g. KSR1 <ref> [201] </ref>, Dash [161]) or rely on the programmer to write message-passing programs (e.g. on CM-5 [76]) or data-parallel programs (e.g. on MasPar MP-1 [70]). This recognition of distributed memory is also found in theoretical research.
Reference: [202] <author> M. Sakkinen. </author> <title> Disciplined Inheritance. </title> <booktitle> In Proceedings of the 1989 European Conference on Object-Oriented Programming, </booktitle> <pages> pages 39-56, </pages> <month> 10-14 July </month> <year> 1989. </year>
Reference-contexts: The pitfalls in inheriting (computation and synchronization) code may be better circumvented by following certain disciplines in programming (such as suggested by Sakkinen <ref> [202] </ref>), and designing flexible encapsulation mechanisms that work well in general and not just in parallel programming.
Reference: [203] <author> M. Satyanarayanan. </author> <title> Distributed File Systems. </title> <editor> In Sape Mullender, editor, </editor> <booktitle> Distributed Systems, </booktitle> <pages> pages 149-188. </pages> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference: [204] <author> H. W. Schmidt. </author> <title> Data-Parallel Object-Oriented Programming. </title> <booktitle> In Proc. of the Fifth Australian Supercomputer Conference, </booktitle> <institution> Melbourne (AUS): Univ. Melbourne, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: Thus any element type which satisfies the interface can be used in the collection. This allows the code in a collection to be reused; there is no similar facility for code reuse in C*. There is also a research effort on dpSather <ref> [204] </ref> to add only "loosely synchronous data parallelism" to sequential Sather, without the notions of threads, synchronization etc. dpSather has bulk types; the elements in a bulk type is finer-grained than chunks.
Reference: [205] <author> Heinz W. Schmidt and Ben Gomes. ICSIM: </author> <title> An Object-Oriented Connectionist Simulator. </title> <type> Technical Report TR-91-048, </type> <institution> International Computer Science Institute, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: We think that interesting applications include algorithms for the max-flow problem [66, 110], various kinds of simulators (e.g. ICSIM <ref> [205] </ref> a neural network simulator), numerical algorithms (e.g. linear programming), and parallel constraint satisfaction systems ([117]). We have mentioned that one of pSather's goals is to provide a platform for building reusable classes.
Reference: [206] <author> Marc Shapiro, Philippe Gautron, and Laurence Mosseri. </author> <title> Persistence and Migration for C++ Objects. </title> <booktitle> In Proceedings of the 1989 European Conference on Object-Oriented Programming, </booktitle> <pages> pages 191-204, </pages> <month> 10-14 July </month> <year> 1989. </year>
Reference-contexts: we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS <ref> [206, 169] </ref>, Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier. Parallel Versions of Smalltalk We first look at some parallel implementations of Smalltalk. Distributed Smalltalk Bennett [31] describes an implementation of Distributed Smalltalk on a network of Sun 2 workstations.
Reference: [207] <author> Alan Snyder. </author> <title> Encapsulation and Inheritance in Object-Oriented Programming Languages. </title> <booktitle> In OOPSLA '86 Conference Proceedings, </booktitle> <pages> pages 38-45, </pages> <month> September 29 - October 2 </month> <year> 1986. </year> <title> Proceedings also available as: </title> <journal> SIGPLAN Notices, </journal> <volume> Vol 21, No 11, </volume> <month> November </month> <year> 1986. </year>
Reference-contexts: Programming aggregates, however, requires additional programming effort to undo the restriction caused by "one thread per object". 25 described by Snyder <ref> [207] </ref>. Although the ideas to decouple synchronization and computation codes are useful, when such a general mechanism is implemented for all classes, the runtime costs are high. The ideas also do not overcome the general problems that arise from breaking class encapsulation via inheritance.
Reference: [208] <author> W. Y. Stevens. </author> <title> The Structure of SYSTEM/360: Part II System Implementations. </title> <editor> In Daniel P. Siewiorek, C. Gordon Bell, and Allen Newell, editors, </editor> <booktitle> Computer Structures: Principles and Examples, </booktitle> <pages> pages 710-715. </pages> <address> McCraw-Hill, </address> <publisher> Inc., </publisher> <year> 1982. </year>
Reference: [209] <author> J. Stoer and R. </author> <title> Bulirsch. Introduction to Numerical Analysis. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: I N T N C C C T N = B B B 4 1 . . . 1 4 C C C We can in turn use various iterative algorithms <ref> [209] </ref> to find solutions for u i;j . Our program implements an iterative successive overrelaxation (SOR) algorithm for this problem.
Reference: [210] <author> Bjarne Stroustrup. </author> <title> The C++ Programming Language, Second Edition. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <month> September </month> <year> 1991. </year>
Reference-contexts: Because of the variety of languages, this survey is by no means exhaustive. 8 We focus our attention on languages which (1) are parallel extensions of major sequential object-oriented languages (e.g. C++ <ref> [210] </ref>, Smalltalk [109], Eiffel [175]), (2) or embody a unique model or concept. The following categorization is not mutually exclusive | a language may suitably fall into more than one category.
Reference: [211] <author> R.J. Swan, S.H. Fuller, </author> <title> and D.P. Siewiorek. Cm* a modular, multi-microprocessor. </title> <booktitle> In Proceedings of the National Computer Conference, </booktitle> <volume> volume 46, </volume> <year> 1977. </year>
Reference: [212] <author> Andrew S. Tanenbaum, M. Frans Kaashoek, and Henri E. Bal. </author> <title> Parallel Programming Using Shared Objects and Broadcasting. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 10-19, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: This means that the runtime system has to keep track of the activation records of every movable object; this might entail high runtime costs. Jul et al. [146] describes how to reduce such costs and what to update when activation records are moved. Other Languages Orca Orca <ref> [21, 212] </ref> is targeted to deal with network latency in distributed systems. It provides a shared data-object model with passive objects and explicit threads (processes). Processes are created using the fork statement.
Reference: [213] <author> David Tarditi, Peter Lee, and Anurag Acharya. </author> <title> No Assembly Required: Compiling Standard ML to C. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1(2) </volume> <pages> 161-177, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: This is similar to the strategy adopted by compilers by several other languages such as Standard ML <ref> [213] </ref>, Scheme [26] and POOL2 [9]. The advantages of using C are obvious. Because of C's widespread availability, it is relatively easy to port the compiler. We can also take advantage of low-level optimizations (e.g. register allocation) performed by the C compiler.
Reference: [214] <author> Chandramohan A. Thekkath, Henry M. Levy, and Edward D. Lazowska. </author> <title> Efficient Support for Multicomputing on ATM Networks. </title> <type> Technical Report 93-04-03, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <address> Seattle, WA 98195, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: It also suggests that pSather's model can also be realized on networks of workstations if the network latencies are 2 orders of magnitude slower than the fastest local access. (e.g. <ref> [214] </ref>). Although active messages were developed as support for dataflow languages, we find that they are also useful as part of the runtime support for pSather, a high-level object-oriented language with a completely different paradigm.
Reference: [215] <author> Robert H. Thomas and Will Crowther. </author> <title> The Uniform System: An Approach to Runtime Support for Large Scaled Shared Memory Parallel Processors. </title> <booktitle> In Proceedings of the 1988 International Conference on Parallel Processing, </booktitle> <pages> pages 245-254, </pages> <month> August </month> <year> 1988. </year> <month> 311 </month>
Reference-contexts: After retrieving the result, g.clear is called. A thread that finds that CONFIG::clear request is "true" can then self-abort. 17 We have so far only assumed a uniform shared memory model. In such a model, various runtime systems <ref> [215, 33] </ref> have demonstrated the feasibility of good load balancing techniques. Therefore the deferred assignment statement only provides the functionality of thread creation and leaves load balancing to the runtime system. <p> On the other hand, for intra-cluster load balancing, there are various runtime systems (e.g. Uniform <ref> [215] </ref>, Presto [94], and any state-of-the-art operating system for symmetric multiprocessors e.g. Solaris, Mach) which perform well for shared-memory machines. In a machine with &gt; 1 processor per cluster, such systems can be used to provide automatic load balancing within a cluster.
Reference: [216] <author> Chris Tomlinson and Mark Sheeval. </author> <title> Concurrent Object-Oriented Programming Languages. </title> <editor> In Won Ki and Frederick H. Lochovsky, editors, </editor> <booktitle> Object-oriented concepts, databases, and applications, chapter 5, </booktitle> <pages> pages 79-124. </pages> <publisher> ACM Press, </publisher> <year> 1989. </year>
Reference-contexts: It does not contain any language extension to Smalltalk. The implementation does not support a shared object space; each program retains a logically distinct 8 Further survey of concurrent object-oriented programming can be found in <ref> [216, 74] </ref>. 26 Language Thread Synchronization Object Placement Inheritance pSather P/DP SD Y I Distributed Smalltalk P SD Y I Multiprocessor Smalltalk P SD N I Concurrent Smalltalk P SD N I Eiffel // A/P SD N I Parallel Eiffel L SD N I CEiffel P SD N I COOL P
Reference: [217] <author> Chris Tomlinson and Vineet Singh. </author> <title> Inheritance and Synchronization with Enabled-Sets. </title> <booktitle> In OOPSLA 1989 Conference Proceedings, </booktitle> <pages> pages 103-112, </pages> <month> October 1-6 </month> <year> 1989. </year> <note> Proceedings also as: SIGPLAN Notices 24(10), </note> <month> October, </month> <year> 1989. </year>
Reference-contexts: Hybrid [184]) group objects into protection domains such that at most one thread can be active in a domain. Other than the three main approaches above, a combination of the approaches is possible and used in some languages. For example, Rosette has both actors and passive objects <ref> [217] </ref>. PC++ [103] presents another variation by supporting the creation of multiple parallel threads, each working on a passive object, resulting in a data-parallel model of computation. Each approach leads to a different programmer's view of how threads are created and executed. <p> Kafura et al. [147] suggests a solution that treats the next set of receivable messages as an abstract entity. Descendent classes only need to redefine these abstract entities and not the computation parts of inherited routines. Tomlinson et al. <ref> [217] </ref> propose a similar augmentation to the next-message-set approach. The inheritance anomaly in the QUEUEfTg/DEQUEfTg example however does not arise in approaches which associate a condition with each routine. Decouchant et al. [85] describes how a boolean activation condition is specified for each routine. <p> design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL [224], CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette <ref> [217] </ref>, POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier. Parallel Versions of Smalltalk We first look at some parallel implementations of Smalltalk. Distributed Smalltalk Bennett [31] describes an implementation of Distributed Smalltalk on a network of Sun 2 workstations.
Reference: [218] <author> Jean-Paul Tremblay and Paul G. Sorenson. </author> <title> The Theory and Practice of Compiler Writing. </title> <publisher> McGraw-Hill, Inc., </publisher> <year> 1989. </year>
Reference-contexts: Since our aim is to provide a relatively stable prototype to further experiment with writing parallel applications (in pSather), the compiler is implemented in a relatively straight-forward manner using standard techniques such as those found in <ref> [5, 218] </ref> and is itself not fully optimized. <p> But because we want to demonstrate that it is possible to have a pSather implementation with reasonable performance, the later sections of this chapter describe some optimization strategies used in the compiler. 3.1.1 Compilation The main data structure during compilation is the abstract syntax trees (AST's <ref> [218, Chapter 10] </ref>) for the classes being compiled. We make use of the Sather class hierarchy to represent different language constructs, so e.g. all AST nodes for lock-statement are Sather objects from the LOCK STMTOB S class.
Reference: [219] <author> Ping-Sheng Tseng. </author> <title> A Systolic Array Parallelizing Compiler. </title> <booktitle> The Kluwer International Series in Engineering and Computer Science. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <year> 1990. </year>
Reference-contexts: This led to AL, a high-level shared-memory language on Warp, and to the work on a parallelizing compiler for systolic array <ref> [219, 220] </ref>. 13 supported in the object-oriented approach because central object-oriented concepts like the ideas of classes and class inheritance relations encourage encapsulation and abstraction. For parallel programs, sofeware reuse is especially relevant because of the difficulty of writing efficient, parallel code.
Reference: [220] <author> Ping-Sheng Tseng. </author> <title> A Systolic Array Parallelizing Compiler. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 9 </volume> <pages> 116-127, </pages> <year> 1990. </year>
Reference-contexts: This led to AL, a high-level shared-memory language on Warp, and to the work on a parallelizing compiler for systolic array <ref> [219, 220] </ref>. 13 supported in the object-oriented approach because central object-oriented concepts like the ideas of classes and class inheritance relations encourage encapsulation and abstraction. For parallel programs, sofeware reuse is especially relevant because of the difficulty of writing efficient, parallel code.
Reference: [221] <author> Jeffrey D. Ullman. </author> <title> Computational aspects of VLSI. </title> <booktitle> Principles of computer science series. </booktitle> <publisher> Computer Science Press, </publisher> <year> 1984. </year>
Reference-contexts: The language must encourage modular structures in parallel programs, making it easier to port to different multiprocessors. Expressiveness of Parallel Constructs In the theoretical literature, certain common paradigms of parallel algorithms (e.g. divide-and-conquer [122, 72], pipeline [121], normal algorithms <ref> [221] </ref> and master-worker [59]) have been recognized in various works to parallelize sequential algorithms or develop new parallel algorithms. One finds that it is more straight-forward to program algorithms in the above paradigms when certain kinds of language constructs are available.
Reference: [222] <author> David Ungar and Randall B. Smith. </author> <title> SELF: The Power of Simplicity. </title> <booktitle> In OOPSLA 1987 Conference Proceedings, </booktitle> <pages> pages 227-241, </pages> <year> 1987. </year> <note> Proceedings also available as SIGPLAN Notices 22(12), </note> <month> December, </month> <year> 1987. </year>
Reference: [223] <institution> Reference Manual for the Ada Programming Language. United States Department of Defense, </institution> <month> July </month> <year> 1982. </year>
Reference: [224] <author> Jan van den Bos and Chris Laffra. </author> <title> PROCOL: A Concurrent Object-Oriented Language with Protocols Delegation and Constraints. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Leiden, </institution> <month> December 6 </month> <year> 1990. </year>
Reference-contexts: To reduce the amount of survey, we give the design characteristics of the following languages in Table 2.1, but omit any description | Natasha [78], Amber [64], Mentat [115, 116, 183], PROCOL <ref> [224] </ref>, CLIX [141], Dragoon [19], Sloop [167], Hybrid [184], PRESTO (and other systems which provides threads and synchronization libraries [94, 33, 27, 90]), SOS [206, 169], Rosette [217], POOL2 [8, 9, 10]. We have however described some of their more interesting characteristics earlier.
Reference: [225] <author> Jean-Philippe Vidal. </author> <title> The Computation of Grobner Bases on a Shared Memory Multiprocessor. </title> <type> Technical Report CMU-CS-90-163, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA 15213, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: Buchberger [49] gives an algorithm which computes a reduced Grobner basis. The computation has two phases: the first produces a Grobner basis G and the second produces the reduced basis from G. There have been various attempts at parallelizing Buchberger's algorithm <ref> [194, 61, 225] </ref>, but our aim is slightly different. We want to produce a reasonably efficient parallel program us ing existing software components. <p> There are two improvements to phase 1 which are essential to the efficiency of the computation. The idea is that not all pairs need to be added into the set P P (line 9). The algebraic arguments are summarized in <ref> [225] </ref> (which gives further references). We describe the algorithm refinements. <p> So (p; q) need not be added to P P . <ref> [225] </ref> demonstrates how these two refinements greatly reduce the number of S-polynomials. <p> So (p; q) need not be added to P P . [225] demonstrates how these two refinements greatly reduce the number of S-polynomials. We therefore use these two refinements in our parallel implementation which is described next. 19 This is referred to as Buchberger's criterion 1 <ref> [104, 225] </ref>. 20 This implies that lcm (hterm p ; hterm q 1 ; hterm q 2 ) = lcm (hterm p ; hterm q 1 ). 232 4.7.2 Parallel Implementation in pSather Our implementation of Buchberger algorithm computes and reduces the S-polynomials in parallel (i.e. phase 1 of Figure 4.35). <p> This is the version that has been called pSather/V3 throughout. The main difficulty in measurements is that the program runs to completion too quickly. Table 4.12 shows the pSather/V3 timings for the typical inputs <ref> [225] </ref>.
Reference: [226] <author> Thorsten von Eicken, David E. Culler, Seth Copen Goldstein, and Klaus Erik Schauser. </author> <title> Active Messages: A Mechanism for Integrated Communication and Computation. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture. </booktitle> <publisher> ACM Press, </publisher> <month> May </month> <year> 1992. </year> <note> Also available as technical report from University of California at Berkeley, CS Division, UCB/CSD 92/675, </note> <month> March </month> <year> 1992. </year>
Reference-contexts: We would like to acknowledge that the pSather runtime relies on several sources. These include (a) Sather runtime system, (b) the FastThreads package [12], and in the CM-5 implementation, (c) the CMAM active message package <ref> [226] </ref>. We describe the functionalities of the major components in the runtime system and how they are inter-related. Active Message Layer. In the CM-5 implementation, one of the most fundamental layers on which most other components depend is the active message library built by von Eicken et al. [226] at University <p> message package <ref> [226] </ref>. We describe the functionalities of the major components in the runtime system and how they are inter-related. Active Message Layer. In the CM-5 implementation, one of the most fundamental layers on which most other components depend is the active message library built by von Eicken et al. [226] at University of California at Berkeley. This layer is not necessary in a shared memory implementation (e.g. Sequent). The active message layer is used to build remote operations, including remote reads/writes, remote routine calls etc. Basic Thread/Synchronization Support. <p> The issues discussed will also be relevant for languages that share similarities to pSather's model and semantics. 7 On the CM-5, all pSather remote operations are implemented by using the CM-5 Active Message (CMAM) library that has been built by von Eicken et al. <ref> [226] </ref> at University of California at Berkeley. CMAM supports active messages each of which serves as a request to start a routine on a remote processor. In CMAM a remote processor must poll the network to recognize requests. <p> Message Library We have found that an active message library such as that by von Eicken et al. <ref> [226] </ref> is a suitable substrate on which to build the pSather runtime. The ability to access the network interface directly is important for reducing remote latencies, and making the shared address space model feasible (even though CM-5 is a message-passing machine).
Reference: [227] <author> Peter Wegner and Scott A. Smolka. </author> <title> Processes, Tasks, and Monitors: A Comparative Study of Concurrent Programming Primitives. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-9(4):446-462, </volume> <month> July </month> <year> 1983. </year> <month> 312 </month>
Reference-contexts: Since our construct is quite different, using "GATE" avoids any preconceived misconceptions. A unique term also allows us to discuss more clearly the differences and similarities of our construct with other synchronization constructs, such as M-structures [24, 25] and monitors <ref> [136, 227] </ref>. 35 to 2.3.4. Then in Section 2.3.5 we point out the (minor) differences between GATEfTg and GATE0.
Reference: [228] <author> L. Curtis Widdoes, Jr. and Steven Correll. </author> <title> The S-1 Project: Developing High-Performance Digital Computers. </title> <editor> In Robert H. Kuhn and David A. Padua, editors, </editor> <booktitle> Tutorial on Parallel Processing. IEEE Computer Society, </booktitle> <year> 1981. </year>
Reference: [229] <author> Katherine Anne Yelick. </author> <title> Using Abstraction in Explicitly Parallel Programs. </title> <type> PhD thesis, </type> <institution> MIT, MIT Laboratory for Computer Science, </institution> <address> Cambridge, MA 02139, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: We prevent this inefficiency 3 by requiring each thread to make a local copy of the directory. Each local directory can be thought of as a thread's local port <ref> [229] </ref> to the workbag abstraction, and is represented by a dashed box in Figure 4.3. Each directory has additional attributes. The local id attribute gives the cluster id in which the directory is located and is used to find the local sub-bag.
Reference: [230] <author> Y. Yokote and M. Tokoro. </author> <title> Experience and evolution of concurrentsmalltalk. </title> <booktitle> In Proceedings of OOPSLA, </booktitle> <pages> pages 406-415, </pages> <address> Orlando, Florida, </address> <month> December </month> <year> 1987. </year> <note> ACM. </note>
Reference-contexts: PSather does not need message-passing forms of parallel constructs like actors in POOL2 [8], broadcast in Orca [21], or asynchronous reply in Natasha [78] and ConcurrentSmalltalk <ref> [230] </ref>. In pSather, sequential routine calls are viewed as the default synchronous mode of message-passing while the thread creation corresponds to asynchronous message-passing. <p> Since the runtime environment (such as a scheduler) is visible, a programmer can also explicitly manage process priorities. A parallel implementation of Smalltalk, however, requires modifications to the system because some design and implementation aspects of Smalltalk inherently assume a concurrent but not truly parallel environment. ConcurrentSmalltalk ConcurrentSmalltalk <ref> [230] </ref> extends Smalltalk-80 by introducing asynchronous calls and CBox objects. (This approach is unlike MP Smalltalk which does not extend Smalltalk-80.) An asynchronous call starts a new thread of execution for the receiver object. The caller does not wait for the result.
Reference: [231] <editor> Akinori Yonezawa, editor. </editor> <title> ABCL An object-oriented concurrent system. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: In this case, a thread is not a first-class object and is only associated with an object in the system. There is no way for a programmer to directly manipulate a thread. This is the approach taken by the actor class of languages ([4],[3]). For example, in ABCL <ref> [231] </ref> and POOL2 (Parallel Object-Oriented Language [8]), when an object is created, it also becomes active 4 As we are preparing for a description of pSather in the next sections, we will try to rephrase ideas in our own terminology when appropriate. 16 with a thread acting as a server. <p> Thus processor 0 gets the 0,: : :,(M/MAXPROC)-1 elements, processor 1 gets the (M/MAXPROC),: : :,2*(M/MAXPROC)-1 elements etc. PC++ builds irregular data structures (e.g. binary tree) on top of C static arrays and thus the data structures are not dynamic. An Actor Language ABCL/1 ABCL/1 <ref> [231, 232] </ref> is an actor language. Every object (actor) in ABCL/1 has its own thread of control, and is always in one of three modes: dormant, active or waiting.
Reference: [232] <author> Akinori Yonezawa, Jean-Pierre Briot, and Etsuya Shibayama. </author> <booktitle> Object-Oriented Concurrent Programming in ABCL/1. In OOPSLA 1986 Proceedings, </booktitle> <pages> pages 258-268, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: Thus processor 0 gets the 0,: : :,(M/MAXPROC)-1 elements, processor 1 gets the (M/MAXPROC),: : :,2*(M/MAXPROC)-1 elements etc. PC++ builds irregular data structures (e.g. binary tree) on top of C static arrays and thus the data structures are not dynamic. An Actor Language ABCL/1 ABCL/1 <ref> [231, 232] </ref> is an actor language. Every object (actor) in ABCL/1 has its own thread of control, and is always in one of three modes: dormant, active or waiting.
Reference: [233] <author> Akinori Yonezawa, Satoshi Matsuoka, Masahiro Yasugi, and Kenjiro Taura. </author> <title> Implementing Concurrent Object-Oriented Languages on Multicomputers. </title> <journal> IEEE Parallel & Distributed Technology, Systems & Applications, </journal> <volume> 1(2) </volume> <pages> 49-61, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: This construct specifies the patterns and constraints of messages that will reactivate the object, and is similar to the guarded alternatives in CSP, Although ABCL/1 does not have a machine model with distributed memory, the language has been implemented on distributed memory machines <ref> [233] </ref>. ABCL/1 does not have class inheritance, but supports delegation using a form of continuation-passing [15]. The "continuation-passing" works as follows. When an object O1 receives a message, it also gets an object R (called the reply destination) to which O1 sends its reply.
Reference: [234] <author> Benjamin Zorn et al. </author> <title> Multiprocessing Extensions in Spur Lisp. </title> <journal> IEEE Software, </journal> <pages> pages 41-49, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: On the other hand, the data-parallel model has also commonly served as a basis for description of algorithms (such as those for graph and matrix problems [192]). While some parallel languages (e.g. Multilisp [119], Spur Lisp <ref> [234] </ref>) have focused on providing control-parallel constructs, others (e.g. C* [127], Fortran D [132]) have concentrated on supporting data-parallel constructs. It is unnatural, if not difficult, to express data-parallel algorithms in control-parallel languages and vice-versa. We would like to support both these styles of computation in a coherent framework.
References-found: 234

