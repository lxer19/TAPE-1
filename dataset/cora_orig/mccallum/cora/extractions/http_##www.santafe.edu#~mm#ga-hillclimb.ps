URL: http://www.santafe.edu/~mm/ga-hillclimb.ps
Refering-URL: http://www.santafe.edu/~mm/paper-abstracts.html
Root-URL: 
Title: When Will a Genetic Algorithm Outperform Hill Climbing?  
Author: Melanie Mitchell John H. Holland Stephanie Forrest J. D. Cowan, G. Tesauro, and J. 
Note: To appear in  Alspector (editors), Advances in Neural Information Processing Systems 6. San Mateo, CA: Morgan Kaufmann.  
Address: 1660 Old Pecos Trail, Suite A Santa Fe, NM 87501  Ann Arbor, MI 48109  Albuquerque, NM 87131  
Affiliation: Santa Fe Institute  Dept. of Psychology University of Michigan  Dept. of Computer Science University of New Mexico  
Abstract: We analyze a simple hill-climbing algorithm (RMHC) that was previously shown to outperform a genetic algorithm (GA) on a simple "Royal Road" function. We then analyze an "idealized" genetic algorithm (IGA) that is significantly faster than RMHC and that gives a lower bound for GA speed. We identify the features of the IGA that give rise to this speedup, and discuss how these features can be incorporated into a real GA. 
Abstract-found: 1
Intro-found: 1
Reference: <author> L. D. </author> <title> Davis (1991). Bit-climbing, representational bias, and test suite design. </title> <booktitle> In R. </booktitle>
Reference-contexts: 1 INTRODUCTION Our goal is to understand the class of problems for which genetic algorithms (GA) are most suited, and in particular, for which they will outperform other search algorithms. Several studies have empirically compared GAs with other search and optimization methods such as simple hill-climbing <ref> (e.g., Davis, 1991) </ref>, simulated annealing (e.g., Ingber & Rosen, 1992), linear, nonlinear, and integer programming techniques, and other traditional optimization techniques (e.g., De Jong, 1975).
Reference: <editor> K. Belew and L. B. Booker (eds.), </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> 18-23. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> K. A. </author> <title> De Jong (1975). An Analysis of the Behavior of a Class of Genetic Adaptive Systems. </title> <type> Unpublished doctoral dissertation. </type> <institution> University of Michigan, </institution> <address> Ann Arbor, MI. </address>
Reference-contexts: Several studies have empirically compared GAs with other search and optimization methods such as simple hill-climbing (e.g., Davis, 1991), simulated annealing (e.g., Ingber & Rosen, 1992), linear, nonlinear, and integer programming techniques, and other traditional optimization techniques <ref> (e.g., De Jong, 1975) </ref>. However, such comparisons typically compare one version of the GA with a second algorithm on a single problem or set of problems, often using performance criteria which may not be appropriate.
Reference: <author> S. Forrest and M. </author> <title> Mitchell (1993). Relative building-block fitness and the building-block hypothesis. </title> <editor> In D. Whitley (ed.), </editor> <booktitle> Foundations of Genetic Algorithms 2, </booktitle> <pages> 109-126. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However both these expectations were overturned <ref> (Forrest & Mitchell, 1993) </ref>. <p> Second, fitness-proportionate reproduction under the GA should conserve instances of such schemas. Third, a high crossover rate should quickly combine instances of low-order schemas on different strings to create instances of longer schemas that confer even higher fitness. Our previous experiments <ref> (Forrest & Mitchell, 1993) </ref> showed that the simple GA departed from this "in principle" behavior. One major impediment was hitchhiking, which limited implicit parallelism by fixing certain schema regions suboptimally. <p> A discussion of how such a balance might be achieved is given in Holland (1993). 3 RESULTS OF EXPERIMENTS As a first step in exploring these balances, we designed R3, a variant of our previous function R 2 <ref> (Forrest & Mitchell, 1993) </ref>, based on some of the features described above. In R3 the desired schemas are s 1 -s 8 (shown in Fig. 1) and combinations of them, just as in R2.
Reference: <author> J. H. Holland (1975/1992). </author> <booktitle> Adaptation in Natural and Artificial Systems. </booktitle> <address> Cam-bridge, MA: </address> <publisher> MIT Press. </publisher> <address> (First edition 1975, Ann Arbor: </address> <publisher> University of Michigan Press.) </publisher> <editor> J. H. </editor> <title> Holland (1993). Innovation in complex adaptive systems: </title> <note> Some mathematical sketches. Working Paper 93-10-062, </note> <institution> Santa Fe Institute, </institution> <address> Santa Fe, NM. </address>
Reference: <author> L. Ingber and B. </author> <title> Rosen (1992). Genetic algorithms and very fast simulated rean-nealing: A comparison. </title> <journal> Mathematical Computer Modelling, </journal> <volume> 16 (11), </volume> <pages> 87-100. </pages>
Reference-contexts: Several studies have empirically compared GAs with other search and optimization methods such as simple hill-climbing (e.g., Davis, 1991), simulated annealing <ref> (e.g., Ingber & Rosen, 1992) </ref>, linear, nonlinear, and integer programming techniques, and other traditional optimization techniques (e.g., De Jong, 1975).
Reference: <author> J. R. </author> <title> Levenick (1991). Inserting introns improves genetic algorithm success rate: Taking a cue from biology. </title> <editor> In R. K. Belew and L. B. Booker (eds.), </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> 123-127. </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> M. Mitchell, S. Forrest, and J. H. </author> <title> Holland (1992). The royal road for genetic algorithms: Fitness landscapes and GA performance. </title> <editor> In F. J. Varela and P. Bourgine (eds.), </editor> <booktitle> Proceedings of the First European Conference on Artificial Life, </booktitle> <pages> 245-254. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
References-found: 8

