URL: file://ftp.cs.utexas.edu/pub/neural-nets/papers/leow.rep-learn.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/nn/pages/publications/abstracts.html
Root-URL: http://www.cs.utexas.edu
Email: Email leow,risto@cs.utexas.edu  
Title: Representing and Learning Visual Schemas in Neural Networks for Scene Analysis  
Author: Wee Kheng Leow and Risto Miikkulainen 
Address: Austin, Texas 78712 USA  
Affiliation: Department of Computer Sciences The University of Texas at Austin  
Abstract: Using scene analysis as the task, this research focuses on three fundamental problems in neural network systems: (1) limited processing resources, (2) representing schemas, and (3) learning schemas. The first problem arises because no practical neural network can process all the visual input simultaneously and efficiently. The solution is to process a small amount of the input in parallel, and successively focus on the other parts of the input. This strategy requires that the system maintains structured knowledge for describing and interpreting the gathered information. The system should also learn to represent structured knowledge from examples of objects and scenes. VISOR, the system described in this paper, consists of three main components. The Low-Level Visual Module (simulated using procedural programs) extracts featural and positional information from the visual input. The Schema Module encodes structured knowledge about possible objects, and provides top-down information for the Low-Level Visual Module to focus attention at different parts of the scene. The Response Module learns to associate the schema activation patterns with external responses. It enables the external environment to provide reinforcement feedback for the learning of schematic structures. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Antes, J. R., and Penland, J. G. </author> <year> (1981). </year> <title> Picture context effects on eye movement patterns. </title> <editor> In Fisher, D. F., Monty, R. A., and Senders, J. W., editors, </editor> <title> Eye Movements: Cognition and Visual Perception. </title> <publisher> Erlbaum. </publisher>
Reference-contexts: It continues processing other parts of the scene until it has gathered sufficient information to build a consistent, complete interpretation. A system that adopts this strategy requires an internal model, generally known as a schema in psychological research, for making the interpretations <ref> [1; 3; 8; 12] </ref>. Thus, the solution to the first problem requires addressing the second problem: the network needs to be able to represent structures in the input, including the spatial layout of the objects and the entire scene.
Reference: [2] <author> Arbib, M. A. </author> <year> (1989). </year> <title> The Metaphorical Brain 2: Neural Networks and Beyond. </title> <address> New York: </address> <publisher> Wiley. </publisher>
Reference-contexts: Although visual schemas have been extensively studied in the symbolic framework [5; 10], there has been very little work in neural networks in this area (see <ref> [2; 6; 16] </ref> for related approaches). Neural networks are not very good at manipulating symbolic structures explicitly. Instead, they are good at feature extraction, association, constraint satisfaction, pattern classification, and making other fuzzy decisions, based on cooperation and competition among units and networks.
Reference: [3] <author> Biederman, I. </author> <year> (1972). </year> <title> Perceiving real-world scenes. </title> <journal> Science, </journal> <volume> 177 </volume> <pages> 77-80. </pages>
Reference-contexts: It continues processing other parts of the scene until it has gathered sufficient information to build a consistent, complete interpretation. A system that adopts this strategy requires an internal model, generally known as a schema in psychological research, for making the interpretations <ref> [1; 3; 8; 12] </ref>. Thus, the solution to the first problem requires addressing the second problem: the network needs to be able to represent structures in the input, including the spatial layout of the objects and the entire scene.
Reference: [4] <author> Carpenter, G. A., and Grossberg, S. </author> <year> (1987). </year> <title> A massively parallel architecture for a self-organizing neural pattern recognition machine. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 37 </volume> <pages> 54-115. </pages>
Reference-contexts: After receiving the punishment signal, the Schema Module suppresses the activity of the arch schema-net so that a different schema-net can become most active and correct learning can proceed as in the single-schema case. The punishment signal is very similar to the mismatch-reset signal in the ART network <ref> [4] </ref>. It tells the Schema Module to find a different schema-net to encode the house without specifying which one. Learning begins with a number of schema-nets connected in a hierarchy, each with small random weights, and therefore encoding no spatial structure.
Reference: [5] <author> Draper, B. A., Collins, R. T., Brolio, J., Hanson, A. R., and Riseman, E. M. </author> <year> (1989). </year> <title> The schema system. </title> <journal> International Journal of Computer Vision, </journal> <volume> 2 </volume> <pages> 209-250. </pages>
Reference-contexts: Thus, the solution to the first problem requires addressing the second problem: the network needs to be able to represent structures in the input, including the spatial layout of the objects and the entire scene. Although visual schemas have been extensively studied in the symbolic framework <ref> [5; 10] </ref>, there has been very little work in neural networks in this area (see [2; 6; 16] for related approaches). Neural networks are not very good at manipulating symbolic structures explicitly.
Reference: [6] <author> Feldman, J. A. </author> <year> (1986). </year> <title> Connectionist models and parallelism in high level vision. </title> <editor> In Rosenfeld, A., editor, </editor> <booktitle> Human and Machine Vision II. </booktitle> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference-contexts: Although visual schemas have been extensively studied in the symbolic framework [5; 10], there has been very little work in neural networks in this area (see <ref> [2; 6; 16] </ref> for related approaches). Neural networks are not very good at manipulating symbolic structures explicitly. Instead, they are good at feature extraction, association, constraint satisfaction, pattern classification, and making other fuzzy decisions, based on cooperation and competition among units and networks.
Reference: [7] <author> Feldman, J. A., and Ballard, D. H. </author> <year> (1982). </year> <title> Connectionist models and their properties. </title> <journal> Cognitive Science, </journal> <volume> 6 </volume> <pages> 205-254. </pages>
Reference-contexts: Even if such a network can capture a large part of the scene at once, it may not be able to process all the information in parallel unless it has an exponential number of units and connections <ref> [7; 17] </ref>. The only viable option is to process a small amount of visual input in parallel, and successively focus on different parts of the scene. This strategy also seems to be in use in biological visual systems [12].
Reference: [8] <author> Friedman, A. </author> <year> (1979). </year> <title> Framing pictures: The role of knowledge in automatized encoding of memory for gist. </title> <journal> Journal of Experimental Psychology: General, </journal> <volume> 108 </volume> <pages> 316-355. </pages>
Reference-contexts: It continues processing other parts of the scene until it has gathered sufficient information to build a consistent, complete interpretation. A system that adopts this strategy requires an internal model, generally known as a schema in psychological research, for making the interpretations <ref> [1; 3; 8; 12] </ref>. Thus, the solution to the first problem requires addressing the second problem: the network needs to be able to represent structures in the input, including the spatial layout of the objects and the entire scene.
Reference: [9] <author> Grossberg, S., and Kuperstein, M. </author> <year> (1989). </year> <title> Neural Dynamics of Adaptive Sensory-Motor Control. </title> <address> New York: </address> <publisher> Pergamon Press. </publisher>
Reference-contexts: After presentations of several different instances, the weights of the schema-net will gradually 2 Multi-modular learning schemes have also been proposed by Grossberg and Kuperstein <ref> [9] </ref>, and Miikku-lainen [15]. converge to stable values that encode the essential structure of the object, and allow it to recognize further instances with minor variation. At the same time, the Response Module learns to associate the target response with the activation of this particular schema-net.
Reference: [10] <author> Hanson, A. R., and Riseman, E. M. </author> <year> (1978). </year> <title> VISIONS: A computer system for interpreting scenes. </title> <editor> In Hanson, A. R., and Riseman, E. M., editors, </editor> <booktitle> Computer Vision Systems. </booktitle> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference-contexts: Thus, the solution to the first problem requires addressing the second problem: the network needs to be able to represent structures in the input, including the spatial layout of the objects and the entire scene. Although visual schemas have been extensively studied in the symbolic framework <ref> [5; 10] </ref>, there has been very little work in neural networks in this area (see [2; 6; 16] for related approaches). Neural networks are not very good at manipulating symbolic structures explicitly.
Reference: [11] <author> Hinton, G. E. </author> <year> (1988). </year> <title> Representing part-whole hierarchies in connectionist networks. </title> <booktitle> In Proceedings of the 10th Annual Conference of the Cognitive Science Society. </booktitle> <address> Hillsdale, NJ: </address> <publisher> Erlbaum. </publisher>
Reference-contexts: The Schema Module performs scene analysis and the Response Module produces responses expected by the environment. Figures (e) and (f) indicate the activities of fine-scaled and coarse-scaled Relative Position Maps (RPMs) when attention is focused at the position marked with "+". similar to that of Hinton's part-whole hierarchies <ref> [11] </ref>. VISOR consists of three main components: the Low-Level Visual Module (simulated using procedural programs), the Schema Module, and the Response Module. The architecture and operation of the first two modules will be described below. The Response Module will be discussed with schema learning (Section 4).
Reference: [12] <author> Hochberg, J. E. </author> <year> (1978). </year> <title> Perception. </title> <address> Englewood Cliffs, NJ: </address> <note> Prentice-Hall. Second edition. </note>
Reference-contexts: The only viable option is to process a small amount of visual input in parallel, and successively focus on different parts of the scene. This strategy also seems to be in use in biological visual systems <ref> [12] </ref>. Since the network is fixed and finite, it may not have enough storage space for the input information. It will have to build and maintain a partial interpretation of the input gathered so far. <p> It continues processing other parts of the scene until it has gathered sufficient information to build a consistent, complete interpretation. A system that adopts this strategy requires an internal model, generally known as a schema in psychological research, for making the interpretations <ref> [1; 3; 8; 12] </ref>. Thus, the solution to the first problem requires addressing the second problem: the network needs to be able to represent structures in the input, including the spatial layout of the objects and the entire scene.
Reference: [13] <author> Leow, W. K. </author> <year> (1994). </year> <title> VISOR: Learning Visual Schemas in Neural Networks for Object Recognition and Scene Analysis. </title> <type> PhD thesis, </type> <institution> Department of Computer Sciences, The University of Texas at Austin. </institution>
Reference-contexts: Learning simplifies the process. The same system can be used in different applications after the domain-specific knowledge has been acquired. Such a system can also adapt to environmental changes. The VISOR system (VIsual Schemas for Object Representation; <ref> [13; 14] </ref>) is designed to address the three fundamental problems in the domain of scene analysis.
Reference: [14] <author> Leow, W. K., and Miikkulainen, R. </author> <year> (1993). </year> <title> Representing visual schemas in neural networks for object recognition. </title> <booktitle> In Proceedings of the IEEE International Conference on Neural Networks (San Francisco, </booktitle> <address> CA). </address> <publisher> IEEE. </publisher>
Reference-contexts: Learning simplifies the process. The same system can be used in different applications after the domain-specific knowledge has been acquired. Such a system can also adapt to environmental changes. The VISOR system (VIsual Schemas for Object Representation; <ref> [13; 14] </ref>) is designed to address the three fundamental problems in the domain of scene analysis.
Reference: [15] <author> Miikkulainen, R. </author> <year> (1993). </year> <title> Subsymbolic Natural Language Processing: An Integrated Model of Scripts, Lexicon, and Memory. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: After presentations of several different instances, the weights of the schema-net will gradually 2 Multi-modular learning schemes have also been proposed by Grossberg and Kuperstein [9], and Miikku-lainen <ref> [15] </ref>. converge to stable values that encode the essential structure of the object, and allow it to recognize further instances with minor variation. At the same time, the Response Module learns to associate the target response with the activation of this particular schema-net.
Reference: [16] <author> Rumelhart, D. E., Smolensky, P., McClelland, J. L., and Hinton, G. E. </author> <year> (1986). </year> <title> Schemata and sequential thought processes in PDP models. </title> <editor> In McClelland, J. L., and Rumelhart, D. E., editors, </editor> <booktitle> Parallel Distributed Processing, Volume 2: Psychological and Biological Models, </booktitle> <pages> 7-57. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Although visual schemas have been extensively studied in the symbolic framework [5; 10], there has been very little work in neural networks in this area (see <ref> [2; 6; 16] </ref> for related approaches). Neural networks are not very good at manipulating symbolic structures explicitly. Instead, they are good at feature extraction, association, constraint satisfaction, pattern classification, and making other fuzzy decisions, based on cooperation and competition among units and networks.
Reference: [17] <author> Tsotsos, J. K. </author> <year> (1988). </year> <title> How does human vision beat the computational complexity of visual perception? In Pylyshyn, </title> <editor> Z. W., editor, </editor> <booktitle> Computational Processes in Human Vision. </booktitle> <address> Norwood, NJ: </address> <publisher> Ablex. </publisher>
Reference-contexts: Even if such a network can capture a large part of the scene at once, it may not be able to process all the information in parallel unless it has an exponential number of units and connections <ref> [7; 17] </ref>. The only viable option is to process a small amount of visual input in parallel, and successively focus on different parts of the scene. This strategy also seems to be in use in biological visual systems [12].
Reference: [18] <author> Van Essen, D. C., and Anderson, C. H. </author> <year> (1990). </year> <title> Information processing strategies and pathways in the primate retina and visual cortex. </title> <editor> In Zornetzer, S. F., Davis, J. L., and Lau, C., editors, </editor> <title> An Introduction to Neural and Electronic Networks. </title> <address> New York: </address> <publisher> Academic Press. </publisher>
References-found: 18

