URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-433.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: sandy@media.mit.edu andy@pathfinder.cbr.com  
Title: Modeling and Prediction of Human Behavior  
Author: Alex Pentland Andrew Liu 
Affiliation: Massachusetts Institute of Technology Nissan Cambridge Basic Research  
Date: Sept. 25-26, 1995  
Address: 350-355, Detroit MI,  Room E15-387, 20 Ames Street 4 Cambridge Center Cambridge, MA 02139, USA Cambridge, MA, 02142  
Note: Originally published as: Towards Augmented Control Systems, in IEEE Intelligent Vehicles 95, pp.  
Abstract: M.I.T. Media Lab Perceptual Computing Technical Report No. 433 Abstract We describe our research toward building systems that include a complex, multi-state model of human dynamic behavior. This can allow us to predict human behavior over short periods of time, in order to create control systems that intelligently complement the human's action. To accomplish this requires inferring the internal state of the human, and then correctly adapting the remainder of the system to achieve optimal performance. We describe methods for achieving this goal, and report an initial experiment in which we were able to achieve 95% accuracy at predicting automobile driver's actions from their initial preparatory movements. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Land. </author> <title> Predictable eye-head coordination during driving, </title> <journal> Nature, </journal> <volume> Vol. 359, </volume> <pages> pp. 318-320, </pages> <year> 1992. </year> <title> (a) (b) subjects. </title>
Reference: [2] <author> Boer, E., Fernandez, M., Pentland, A., and Liu, A., </author> <title> (1996) "Method for Evaluating Human and Simulated Drivers in Real Traffic Situations," </title> <booktitle> IEEE Vehicular Tech. Conf., </booktitle> <address> Atlanta, GA. </address>
Reference-contexts: If heading and acceleration is monitored externally via video cameras, as in Figures 2 and 3 (the `blob' processing algorithm that extracts the vehicle parameters from video is described in Boer, Fernan-dez, Pentland, and Liu 1996 <ref> [2] </ref>), then we can more intelligently control the traffic flow. 5.1 Experimental Design The goal is to test the ability of our framework to characterize driver's steering and acceleration/braking patterns in order to classify the driver's intended action.
Reference: [3] <author> M. Friedmann, T. Starner, and A. Pentland. </author> <title> Device Synchronization using an Optimal Linear Filter, </title> <booktitle> Proc. ACM 1992 Symposium on Interactive 3D Graphics, </booktitle> <address> Boston, MA, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: kt + f (i) ( ^ X kt ; t)t; t)) by substituting Equation 6. 3.1 Results Using Multiple Dynamic Models We have used this method to accurately remove lag in a high-speed telemanipulation task by continuously re-estimating the user's arm dynamics (e.g., tense and stiff, versus relaxed and inertia-dominated) <ref> [3] </ref>. In this case, the state vector X k consists of the true position, velocity, and acceleration of the hand in each of the x, y, and z coordinates, and the observation vector Y k consists of the position readings for the x, y, and z coordinates.
Reference: [4] <author> T. Starner, and A. Pentland. </author> <title> Visual Recognition of American Sign Language Using Hidden Markov Models, </title> <booktitle> Proc. Int'l Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <address> Zurich, Switzerland, </address> <month> June 26-28, </month> <year> 1995. </year>
Reference-contexts: Fine tuning this topology can be performed empirically. Figure 1, for instance, shows a four state HMM with skip transitions that we have used to classify complex hand motions. from <ref> [4] </ref>. There are three key problems in HMM use. These are the evaluation, estimation, and the decoding problems.
Reference: [5] <author> L. Baum. </author> <title> An inequality and associated maximization technique in statistical estimation of probabilistic functions of markov processes. </title> <journal> Inequalities, </journal> <volume> 3 </volume> <pages> 1-8, </pages> <year> 1972. </year>
Reference-contexts: While a substantial body of literature exists on HMM technology <ref> [5, 6, 8, 11] </ref>, we will first briefly outline a traditional discussion of the algorithms. After outlining the fundamental theory in training and testing of a discrete HMM, we will generalize these results to the continuous density case applicable to switching between dynamic models.
Reference: [6] <author> X. Huang, Y. Ariki, and M. Jack. </author> <title> Hidden Markov Models for Speech Recognition. </title> <publisher> Edin-burgh Univ. Press, Edinburgh, </publisher> <year> 1990. </year>
Reference-contexts: While a substantial body of literature exists on HMM technology <ref> [5, 6, 8, 11] </ref>, we will first briefly outline a traditional discussion of the algorithms. After outlining the fundamental theory in training and testing of a discrete HMM, we will generalize these results to the continuous density case applicable to switching between dynamic models. <p> After outlining the fundamental theory in training and testing of a discrete HMM, we will generalize these results to the continuous density case applicable to switching between dynamic models. For broader discussion of the topic, <ref> [6, 9] </ref> are recommended. A time domain process demonstrates a Markov property if the conditional probability density of the current event, given all present and past events, de- pends only on the j th most recent events. <p> There are three key problems in HMM use. These are the evaluation, estimation, and the decoding problems. The evaluation problem is that given an observation sequence and a model, what is the probability that the observed sequence was generated by the model (P r (Yj)) (notational style adapted from <ref> [6] </ref>)? If this can be evaluated for all competing models for an observation sequence, then the model with the highest probability can be chosen for recognition.
Reference: [7] <author> B. Juang. </author> <title> Maximum likelihood estimation for mixture multivariate observations of markov chains. </title> <journal> AT&T Technical Journal, </journal> <volume> 64 </volume> <pages> 1235-1249, </pages> <year> 1985. </year>
Reference-contexts: Consequently, instead of using vector quantization, we must employ the actual probability densities for the innovations processes. Fortunately, Baum-Welch parameter estimation, the Viterbi algorithm, and the forward-backward algorithms can be modified to handle a variety of characteristic densities <ref> [7] </ref>. In this paper, however, the densities will be assumed to be Gaussian.
Reference: [8] <author> L. Rabiner and B. Juang. </author> <title> An introduction to hidden markov models. </title> <journal> IEEE ASSP Magazine, </journal> <volume> p. </volume> <pages> 4-16, </pages> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: While a substantial body of literature exists on HMM technology <ref> [5, 6, 8, 11] </ref>, we will first briefly outline a traditional discussion of the algorithms. After outlining the fundamental theory in training and testing of a discrete HMM, we will generalize these results to the continuous density case applicable to switching between dynamic models. <p> However, <ref> [8] </ref> shows that this is often sufficient. 4.1 The Continuous Case So far this discussion of HMMs has assumed some sort of quantization of feature vectors into classes, whereas the innovations processes that will drive our inter-state transitions are continuous.
Reference: [9] <author> T. Starner. </author> <title> Visual Recognition of American Sign Language Using Hidden Markov Models. </title> <type> Master's thesis, </type> <institution> MIT Media Laboratory, </institution> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: After outlining the fundamental theory in training and testing of a discrete HMM, we will generalize these results to the continuous density case applicable to switching between dynamic models. For broader discussion of the topic, <ref> [6, 9] </ref> are recommended. A time domain process demonstrates a Markov property if the conditional probability density of the current event, given all present and past events, de- pends only on the j th most recent events.
Reference: [10] <author> T. Starner, J. Makhoul, R. Schwartz, and G. Chou. </author> <title> On-line cursive handwriting recognition using speech recognition methods. </title> <booktitle> In ICASSP, </booktitle> <year> 1994. </year>
Reference: [11] <author> S. Young. </author> <title> HTK: Hidden Markov Model Toolkit V1.5. </title> <institution> Cambridge Univ. Eng. Dept. Speech Group and Entropic Research Lab. Inc., </institution> <address> Wash-ington DC, </address> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: While a substantial body of literature exists on HMM technology <ref> [5, 6, 8, 11] </ref>, we will first briefly outline a traditional discussion of the algorithms. After outlining the fundamental theory in training and testing of a discrete HMM, we will generalize these results to the continuous density case applicable to switching between dynamic models. <p> Using the steering and acceleration data recorded while subjects carried out these commands, we built three-state models of each type of driver action (stopping, turn left, turn right, lane change, car passing, and drive-normal) using the estimation tools provided by the Entropic's HTK computer software <ref> [11] </ref>. To assess the classification accuracy of these models we combined them with the Viterbi recognition algorithm, and examined the stream of drivers' steering and acceleration innovations in order to detect and classify the driver's actions.
Reference: [12] <author> R.E. </author> <title> Kalman and R.S. Bucy. New results in linear filtering and prediction theory. </title> <journal> In Transaction ASME (Journal of basic engineering), </journal> <volume> 83D, </volume> <pages> 95-108, </pages> <year> 1961. </year>
Reference-contexts: Using Kalman's result, we can then obtain the optimal linear estimate ^ X k of the state vector X k by use of the following Kalman filter: ^ X k = X fl k ; t)) (3) provided that the Kalman gain matrix K k is chosen correctly <ref> [12] </ref>.

References-found: 12

