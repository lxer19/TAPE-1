URL: http://www.eecs.umich.edu/~zaher/rtss95.ps
Refering-URL: http://www.eecs.umich.edu/~zaher/publications.html
Root-URL: http://www.eecs.umich.edu
Email: fzaher,kgshing@eecs.umich.edu  
Phone: 734-763-0391 (voice); 734-963-4617 (fax)  
Title: Optimal Combined Task and Message Scheduling in Distributed Real-Time Systems  
Author: Tarek F. Abdelzaher and Kang G. Shin 
Keyword: Key Words Real-time scheduling, combined task and message scheduling, distributed hard real-time systems, resource constraints, deadlock.  
Address: Ann Arbor, Michigan 48109-2122  
Affiliation: Real-time Computing Laboratory Department of Electrical Engineering and Computer Science The University of Michigan  
Abstract: This paper presents an algorithm for off-line scheduling of communicating tasks with precedence and exclusion constraints in distributed hard real-time systems. Tasks are assumed to communicate via message passing based on a time-bounded communication paradigm such as the real-time channel [1]. The algorithm uses a branch-and-bound (B&B) technique to search for an optimal task schedule by minimizing maximum task lateness (defined as the difference between task completion time and task deadline), and exploits the interplay between task and message scheduling to improve the quality of solution. It has the property of generating a complete schedule at each vertex in the search tree, and can be made to yield a feasible solution (found before reaching an optimal solution), or proceed until an optimal solution is found. We have conducted an extensive simulation study evaluating the performance of the proposed algorithm. The algorithm is shown to scale well with respect to system size, and degree of intertask interactions. It also offers good performance for workloads with a wide range of CPU utilizations and application concurrency. For larger systems and higher loads, we introduce a greedy heuristic that is faster but does not guarantee optimality. We have also extended the algorithm to a more general resource-constraint model thus widening its application domain. An earlier version of this paper was presented at the 1995 IEEE Real-Time Systems Symposium. The work reported in this paper was supported in part by the Advanced Research Project Agency unde grant F30602-95-1-0044 and the National Science Foundation under grant MIP-9203895. Any opinions, findngs, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of funding agencies. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. D. Kandlur, K. G. Shin, and D. Ferrari, </author> <title> "Real-time communication in multi-hop networks," </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> vol. 5, no. 10, </volume> <pages> pp. 1044-1056, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: In distributed hard real-time systems, inter-machine message communication affects task schedu-lability, and thus, has to be accounted for. One way to solve this problem is to separate message communication from task scheduling. A communication paradigm such as the real-time channel <ref> [1] </ref> is first assumed where the communication subsystem guarantees bounded message delays (specified as message deadlines), then the task scheduling problem is solved on top of that paradigm, assuming fixed and known message delay bounds. <p> An algorithm combining this problem with that of task allocation was presented in [11]. In contrast, we propose an optimal algorithm for scheduling tasks in a distributed real-time system which interacts with the problem of message scheduling, thereby improving the quality of solution. Assuming that the real-time channel paradigm <ref> [1] </ref> is used for message communication, the problem of message scheduling reduces to that of an appropriate choice of message deadlines. Let's define the message priority space in which each point corresponds to a different message priority assignment. <p> The resulting set of synchronization constraints Sync init is shown in Table 2. This example task set will be used throughout the paper to illustrate the algorithm. 4 Invocation Module a k c k d k T 1 <ref> [1] </ref> M 1 0 1 3 T 1 [3] M 3 6 1 9 T 2 [1] M 5 0 2 5.5 T 3 [1] M 7 0 1 11 T 4 [1] M 9 0 3 4 T 5 [1] M 11 0 1 9 T 6 [2] M [ <p> This example task set will be used throughout the paper to illustrate the algorithm. 4 Invocation Module a k c k d k T 1 <ref> [1] </ref> M 1 0 1 3 T 1 [3] M 3 6 1 9 T 2 [1] M 5 0 2 5.5 T 3 [1] M 7 0 1 11 T 4 [1] M 9 0 3 4 T 5 [1] M 11 0 1 9 T 6 [2] M [ 13] 6 0.5 9.5 Messages: m 7;11 ; m 9;4 Sync init = fM 7 precedes <p> This example task set will be used throughout the paper to illustrate the algorithm. 4 Invocation Module a k c k d k T 1 <ref> [1] </ref> M 1 0 1 3 T 1 [3] M 3 6 1 9 T 2 [1] M 5 0 2 5.5 T 3 [1] M 7 0 1 11 T 4 [1] M 9 0 3 4 T 5 [1] M 11 0 1 9 T 6 [2] M [ 13] 6 0.5 9.5 Messages: m 7;11 ; m 9;4 Sync init = fM 7 precedes M 11 ; M 7 precedes M 8 <p> throughout the paper to illustrate the algorithm. 4 Invocation Module a k c k d k T 1 <ref> [1] </ref> M 1 0 1 3 T 1 [3] M 3 6 1 9 T 2 [1] M 5 0 2 5.5 T 3 [1] M 7 0 1 11 T 4 [1] M 9 0 3 4 T 5 [1] M 11 0 1 9 T 6 [2] M [ 13] 6 0.5 9.5 Messages: m 7;11 ; m 9;4 Sync init = fM 7 precedes M 11 ; M 7 precedes M 8 ; M 9 precedes M 4 ; M <p> Invocation Module a k c k d k T 1 <ref> [1] </ref> M 1 0 1 3 T 1 [3] M 3 6 1 9 T 2 [1] M 5 0 2 5.5 T 3 [1] M 7 0 1 11 T 4 [1] M 9 0 3 4 T 5 [1] M 11 0 1 9 T 6 [2] M [ 13] 6 0.5 9.5 Messages: m 7;11 ; m 9;4 Sync init = fM 7 precedes M 11 ; M 7 precedes M 8 ; M 9 precedes M 4 ; M 9 excludes M 11 ; M 10 excludes <p> We compute (i) a message priority order using some heuristic C3 that attempts to reduce task lateness, (ii) message delay bounds using paradigm C1, and (iii) an optimal schedule using the optimal task scheduling algorithm C2 that minimizes task lateness for given message delays. The real-time channels presented in <ref> [1] </ref> guarantee bounded communication delays and thus will be used as an example for the paradigm C1. 5 A B&B technique is used to implement the above-mentioned approach. It can be viewed as a search, by implicit enumeration, through the entire valid solution space.
Reference: [2] <author> J. Xu and D. L. Parnas, </author> <title> "Scheduling processes with release times, deadlines, precedence, and exclusion relations," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. SE-16, no. 3, </volume> <pages> pp. 360-369, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: If the optimal schedule has positive lateness, then we know that no feasible schedule exists. Thus, the problem is to find the optimal 1 pre-runtime schedule for hard real-time tasks with known arrival times, precedence constraints and resource requirements. Such a problem was solved by Xu and Parnas <ref> [2] </ref> for uniprocessor systems. An attempt to extend their approach to several processors was made by Shepard and Gagne [3], but their algorithm occasionally fails to find existing feasible schedules as we pointed out in [4]. Xu [5] remedied this shortcoming and optimally solved the problem for multiprocessor systems. <p> T 1 [1] M 1 0 1 3 T 1 [3] M 3 6 1 9 T 2 [1] M 5 0 2 5.5 T 3 [1] M 7 0 1 11 T 4 [1] M 9 0 3 4 T 5 [1] M 11 0 1 9 T 6 <ref> [2] </ref> M [ 13] 6 0.5 9.5 Messages: m 7;11 ; m 9;4 Sync init = fM 7 precedes M 11 ; M 7 precedes M 8 ; M 9 precedes M 4 ; M 9 excludes M 11 ; M 10 excludes M 11 g Table 2: The module set.
Reference: [3] <author> T. Shepard and M. Gagne, </author> <title> "A pre-run-time scheduling algorithm for hard real-time systems," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 17, no. 7, </volume> <pages> pp. 669-677, </pages> <month> Jul </month> <year> 1991. </year>
Reference-contexts: Such a problem was solved by Xu and Parnas [2] for uniprocessor systems. An attempt to extend their approach to several processors was made by Shepard and Gagne <ref> [3] </ref>, but their algorithm occasionally fails to find existing feasible schedules as we pointed out in [4]. Xu [5] remedied this shortcoming and optimally solved the problem for multiprocessor systems. <p> The resulting set of synchronization constraints Sync init is shown in Table 2. This example task set will be used throughout the paper to illustrate the algorithm. 4 Invocation Module a k c k d k T 1 [1] M 1 0 1 3 T 1 <ref> [3] </ref> M 3 6 1 9 T 2 [1] M 5 0 2 5.5 T 3 [1] M 7 0 1 11 T 4 [1] M 9 0 3 4 T 5 [1] M 11 0 1 9 T 6 [2] M [ 13] 6 0.5 9.5 Messages: m 7;11 ; <p> In general, for a wide range of workloads the algorithm generates an optimal solution at or near the root of the search tree. A similar observation was reported in <ref> [3] </ref>. This is due to the nature of the performance measure being optimized. Schedule lateness refers to the lateness of only one module.
Reference: [4] <author> T. F. Abdelzaher and K. G. Shin, </author> <title> "Comment on `a pre-run-time scheduling algorithm for hard real-time systems," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 23, no. 9, </volume> <pages> pp. 599-600, </pages> <month> September </month> <year> 1997. </year>
Reference-contexts: Such a problem was solved by Xu and Parnas [2] for uniprocessor systems. An attempt to extend their approach to several processors was made by Shepard and Gagne [3], but their algorithm occasionally fails to find existing feasible schedules as we pointed out in <ref> [4] </ref>. Xu [5] remedied this shortcoming and optimally solved the problem for multiprocessor systems.
Reference: [5] <author> J. Xu, </author> <title> "Multiprocessor scheduling of processes with release times, deadlines, precedence, and exclusion relations," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 19, no. 2, </volume> <pages> pp. 139-154, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Such a problem was solved by Xu and Parnas [2] for uniprocessor systems. An attempt to extend their approach to several processors was made by Shepard and Gagne [3], but their algorithm occasionally fails to find existing feasible schedules as we pointed out in [4]. Xu <ref> [5] </ref> remedied this shortcoming and optimally solved the problem for multiprocessor systems.
Reference: [6] <author> D.-T. Peng and K. G. Shin, </author> <title> "Optimal scheduling of cooperative tasks in a distributed system using an enumerative method," </title> <journal> IEEE Trans. Software Engineering, </journal> <volume> vol. 19, no. 3, </volume> <pages> pp. 253-267, </pages> <month> Mar </month> <year> 1993. </year>
Reference-contexts: An optimal algorithm for solving the latter problem is presented in <ref> [6] </ref>, but it does not consider resource requirements. In general, a disadvantage of separating message scheduling from task scheduling is that the bounded message delays guaranteed by solving the former are a function of the specified message deadlines. <p> For example, in the root schedule shown in Figure 2 the busy period of the latest module M 11 is B 11 = <ref> [6; 10:5] </ref>. Formally, the busy period B i of module M i is defined recursively as follows: 1. M i 2 B i , 2.
Reference: [7] <author> R. Agne, </author> <title> "A distributed o*ine scheduler for distributed hard real-time systems," </title> <booktitle> in Distributed Computer Control Systems. Proceedings of the 10th IFAC Workshop, </booktitle> <pages> pp. 35-40, </pages> <address> Summering, Aus-tria, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: We must therefore develop a combined approach to schedulability analysis that takes into consideration both tasks and intertask messages. Several heuristics have been proposed to solve the combined problem, e.g., <ref> [7] </ref> and [8]. A flexible scheme which combines off-line analysis with on-line guarantees is suggested in [9] for uniprocessors. In [10], a rather similar scheme is described for distributed systems.
Reference: [8] <author> K. Jeffay, </author> <title> "On latency management in time-shared operating systems," </title> <booktitle> in Real-Time Operating Systems and Software, </booktitle> <pages> pp. 86-90, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: We must therefore develop a combined approach to schedulability analysis that takes into consideration both tasks and intertask messages. Several heuristics have been proposed to solve the combined problem, e.g., [7] and <ref> [8] </ref>. A flexible scheme which combines off-line analysis with on-line guarantees is suggested in [9] for uniprocessors. In [10], a rather similar scheme is described for distributed systems.
Reference: [9] <author> H. Chetto, M. Silly, and T. Bouchentouf, </author> <title> "Dynamic scheduling of real-time tasks under precedence constraints," </title> <journal> Journal of Real-Time Systems, </journal> <volume> vol. 2, no. 3, </volume> <pages> pp. 181-194, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: We must therefore develop a combined approach to schedulability analysis that takes into consideration both tasks and intertask messages. Several heuristics have been proposed to solve the combined problem, e.g., [7] and [8]. A flexible scheme which combines off-line analysis with on-line guarantees is suggested in <ref> [9] </ref> for uniprocessors. In [10], a rather similar scheme is described for distributed systems.
Reference: [10] <author> M. D. Natale and J. A. Stankovic, </author> <title> "Dynamic end-to-end guarantees in distributed real-time systems," </title> <booktitle> in Proc. Real-Time Systems Symposium, </booktitle> <pages> pp. 216-227, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: Several heuristics have been proposed to solve the combined problem, e.g., [7] and [8]. A flexible scheme which combines off-line analysis with on-line guarantees is suggested in [9] for uniprocessors. In <ref> [10] </ref>, a rather similar scheme is described for distributed systems. It uses off-line analysis to convert task precedence and communication constraints into pseudo deadlines of tasks and messages, then employs an on-line guarantee routine to find a run-time task and message schedule that minimizes the number of tasks missing deadlines.
Reference: [11] <author> K. Ramamritham, </author> <title> "Allocation and scheduling of complex periodic tasks," </title> <booktitle> in Proc. Int'l Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 108-115, </pages> <year> 1990. </year>
Reference-contexts: An algorithm combining this problem with that of task allocation was presented in <ref> [11] </ref>. In contrast, we propose an optimal algorithm for scheduling tasks in a distributed real-time system which interacts with the problem of message scheduling, thereby improving the quality of solution.
Reference: [12] <author> D.-T. Peng, K. G. Shin, and T. F. Abdelzaher, </author> <title> "Assignment and scheduling of communicating periodic tasks in distributed real-time systems," </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> vol. 8, no. 12, </volume> <pages> pp. 745-758, </pages> <month> December </month> <year> 1997. </year> <month> 23 </month>
Reference-contexts: PNs run a set T of n hard real-time tasks, T 1 ; ; T n . Each task is assumed to reside permanently on one processor. How to assign tasks to processors is beyond the scope of this paper. See <ref> [12] </ref> for a suitable task assignment algorithm. Each task T k in the distributed system has a known arrival time a k , total execution time c k , and deadline d k . In the case of periodic tasks, each task also has a period P k .
Reference: [13] <author> W. H. Kohler and K. Steiglitz, </author> <title> "Enumerative and iterative computational approach," </title> <journal> Computer and Job-Shop Scheduling Theory, </journal> <pages> pp. 229-287, </pages> <year> 1976. </year>
Reference-contexts: [1] M 1 0 1 3 T 1 [3] M 3 6 1 9 T 2 [1] M 5 0 2 5.5 T 3 [1] M 7 0 1 11 T 4 [1] M 9 0 3 4 T 5 [1] M 11 0 1 9 T 6 [2] M <ref> [ 13] </ref> 6 0.5 9.5 Messages: m 7;11 ; m 9;4 Sync init = fM 7 precedes M 11 ; M 7 precedes M 8 ; M 9 precedes M 4 ; M 9 excludes M 11 ; M 10 excludes M 11 g Table 2: The module set. 2.2 The <p> As with any B&B algorithm, its optimality is guaranteed as long as (i) branching does not leave any part of the solution space unreachable, and (ii) bounding computes a true lower bound of the performance measure for each vertex <ref> [13] </ref>. These properties are proved when discussing branching and bounding in Section 2.2.3 and Section 2.2.4, respectively. 2.2.1 Setting up the Root Vertex The root vertex represents the entire space of all valid solutions.
Reference: [14] <author> M.-I. Chen and K.-J. Lin, </author> <title> "Dynamic priority ceilings: A concurrency control protocol for real-time systems," </title> <journal> Journal of Real Time Systems, </journal> <volume> vol. 2, no. 4, </volume> <pages> pp. 325-346, </pages> <year> 1990. </year> <month> 24 </month>
Reference-contexts: To prevent unbounded (dynamic) priority inversion, a module which blocks others with earlier deadlines inherits the earliest of these deadlines. We call this policy EDF with Deadline Inheritance (EDF-DI). Note that we do not use dynamic priority ceilings <ref> [14] </ref>, because deadlocks cannot occur in our simplified model. Figure 2 shows the schedule computed by solution (V ) at the root vertex for the task set in Table 2.
References-found: 14

