URL: http://foxnet.cs.cmu.edu/papers/necula-pldi98.ps
Refering-URL: http://foxnet.cs.cmu.edu/papers.html
Root-URL: 
Email: fnecula,petelg@cs.cmu.edu  
Title: The Design and Implementation of a Certifying Compiler  
Author: George C. Necula Peter Lee 
Address: Pittsburgh, Pennsylvania 15213-3891  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: This paper presents the design and implementation of a compiler that translates programs written in a type-safe subset of the C programming language into highly optimized DEC Alpha assembly language programs, and a certifier that automatically checks the type safety and memory safety of any assembly language program produced by the compiler. The result of the certifier is either a formal proof of type safety or a counterexample pointing to a potential violation of the type system by the assembly-language target program. The ensemble of the compiler and the certifier is called a certifying compiler. Several advantages of certifying compilation over previous approaches can be claimed. The notion of a certifying compiler is significantly easier to employ than a formal compiler verification, in part because it is generally easier to verify the correctness of the result of a computation than to prove the correctness of the computation itself. Also, the approach can be applied even to highly optimizing compilers, as demonstrated by the fact that our compiler generates target code, for a range of realistic C programs, which is competitive with both the cc and gcc compilers with all optimizations enabled. The certifier also drastically improves the effectiveness of compiler testing because, for each test case, it statically signals compilation errors that might otherwise require many executions to detect. Finally, this approach is a practical way to produce the safety proofs for a Proof-Carrying Code system, and thus may be useful in a system for safe mobile code. This research was sponsored in part by the Advanced Research Projects Agency CSTO under the title "The Fox Project: Advanced Languages for Systems Software," ARPA Order No. C533, issued by ESC/ENS under Contract No. F19628-95-C-0050. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Advanced Research Projects Agency or the U.S. Government. Submitted to PLDI'98. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Boyer, R., and Moore, J. S. </author> <title> A Computational Logic. </title> <publisher> Academic Press, </publisher> <year> 1979. </year>
Reference-contexts: Many of the existing theorem provers <ref> [1, 4, 6, 18] </ref> can be used for this purpose, although they do not produce proofs that can be checked independently.
Reference: [2] <author> Cimatti, A., et al. </author> <title> A provably correct embed ded verifier for the certification of safety critical software. </title> <booktitle> In Computer Aided Verification. 9th International Conference. Proceedings (June 1997), </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pp. 202-213. 11 </pages>
Reference-contexts: These rather large differences are partly due to the fact that the certifying compiler is an early prototype.] 10 8 Related Work The idea of checking individual compilations instead of verifying the compiler also appears in the work of Cimatti et al. <ref> [2] </ref>, though in the much simpler instance of a non-optimizing compiler from an expression language without loops or function calls to an RTL-like language. On the other hand they have the more ambitious goal of verifying full equivalence of the source expression and the target program.
Reference: [3] <author> D.C. Luckham, e. </author> <title> Stanford pascal verifier user manual. </title> <type> Tech. Rep. </type> <institution> STAN-CS-79-731, Dept. of Computer Science, Stanford Univ., </institution> <month> Mar. </month> <year> 1979. </year>
Reference-contexts: However, we feel that these are important properties, and thus, to retain them we have implemented a theorem prover that emits proofs. The theorem prover is based on the Nelson-Oppen architecture for cooperating decision procedures [16], also implemented in the Stanford Pascal Verifier <ref> [3] </ref> and the Extended Static Checking [4] systems. Theorem provers are traditionally viewed as logically-incomplete systems that require human intervention in many instances.
Reference: [4] <author> Detlefs, D. </author> <title> An overview of the Extended Static Checking system. </title> <booktitle> In Proceedings of the First Formal Methods in Software Practice Workshop (1996). </booktitle>
Reference-contexts: Many of the existing theorem provers <ref> [1, 4, 6, 18] </ref> can be used for this purpose, although they do not produce proofs that can be checked independently. <p> However, we feel that these are important properties, and thus, to retain them we have implemented a theorem prover that emits proofs. The theorem prover is based on the Nelson-Oppen architecture for cooperating decision procedures [16], also implemented in the Stanford Pascal Verifier [3] and the Extended Static Checking <ref> [4] </ref> systems. Theorem provers are traditionally viewed as logically-incomplete systems that require human intervention in many instances. In our system, however, the theorem prover is guaranteed to be able to prove the safety predicates automatically because these predicates are implicitly proved by the compiler itself during compilation.
Reference: [5] <author> Dybjer, P. </author> <title> Using domain algebras to prove the correctness of a compiler. </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <month> 182 </month> <year> (1986). </year>
Reference-contexts: In a paper published in 1963, John McCarthy refers to this problem as "one of the most interesting and useful goals for the mathematical science of computation" [9]. However, despite a large body of work in the area <ref> [5, 7, 10, 11, 17, 23, 24] </ref>, we still lack the technology to prove automatically the correctness of an optimizing compiler. Even manual proofs are rare, and they tend to verify only the algorithms rather than the implementations.
Reference: [6] <author> Gordon, M. </author> <title> HOL: A machine oriented formula tion of higher-order logic. </title> <type> Tech. Rep. 85, </type> <institution> University of Cambridge, Computer Laboratory, </institution> <month> July </month> <year> 1985. </year>
Reference-contexts: Many of the existing theorem provers <ref> [1, 4, 6, 18] </ref> can be used for this purpose, although they do not produce proofs that can be checked independently.
Reference: [7] <author> Guttman, J. D., Ramsdell, J. D., and Wand, M. VLISP: </author> <title> a verified implementation of Scheme. </title> <booktitle> Lisp and Symbolic Computation, 8 (1995), </booktitle> <pages> 5-32. </pages>
Reference-contexts: In a paper published in 1963, John McCarthy refers to this problem as "one of the most interesting and useful goals for the mathematical science of computation" [9]. However, despite a large body of work in the area <ref> [5, 7, 10, 11, 17, 23, 24] </ref>, we still lack the technology to prove automatically the correctness of an optimizing compiler. Even manual proofs are rare, and they tend to verify only the algorithms rather than the implementations.
Reference: [8] <author> Harper, R., Honsell, F., and Plotkin, G. </author> <title> A framework for defining logics. </title> <journal> Journal of the Association for Computing Machinery 40, </journal> <month> 1 (Jan. </month> <year> 1993), </year> <pages> 143-184. </pages>
Reference-contexts: To use it, we encode the proof as an LF expression and the safety predicate as an LF type. Then LF type-checking is enough to validate the proof. (The fact that this approach is sound is established in <ref> [8] </ref>.
Reference: [9] <author> McCarthy, J. </author> <title> Towards a mathematical theory of computation. </title> <booktitle> In Proceedings of the International Congress on Information Processing (1963), </booktitle> <editor> C. M. Popplewell, Ed., </editor> <publisher> North-Holland, </publisher> <pages> pp. 21-28. </pages>
Reference-contexts: 1 Introduction The question of compiler correctness is as old as the first compiler implementations. In a paper published in 1963, John McCarthy refers to this problem as "one of the most interesting and useful goals for the mathematical science of computation" <ref> [9] </ref>. However, despite a large body of work in the area [5, 7, 10, 11, 17, 23, 24], we still lack the technology to prove automatically the correctness of an optimizing compiler. Even manual proofs are rare, and they tend to verify only the algorithms rather than the implementations.
Reference: [10] <author> Moore, J. S. </author> <title> A mechanically verified language implementation. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 5 (1989), </volume> <pages> 461-492. </pages>
Reference-contexts: In a paper published in 1963, John McCarthy refers to this problem as "one of the most interesting and useful goals for the mathematical science of computation" [9]. However, despite a large body of work in the area <ref> [5, 7, 10, 11, 17, 23, 24] </ref>, we still lack the technology to prove automatically the correctness of an optimizing compiler. Even manual proofs are rare, and they tend to verify only the algorithms rather than the implementations.
Reference: [11] <author> Morris, F. L. </author> <title> Advice on structuring compilers and proving them correct. </title> <booktitle> In Proceedings of the First ACM Symposium on Principles of Programming Languages (1973), </booktitle> <pages> pp. 144-152. </pages>
Reference-contexts: In a paper published in 1963, John McCarthy refers to this problem as "one of the most interesting and useful goals for the mathematical science of computation" [9]. However, despite a large body of work in the area <ref> [5, 7, 10, 11, 17, 23, 24] </ref>, we still lack the technology to prove automatically the correctness of an optimizing compiler. Even manual proofs are rare, and they tend to verify only the algorithms rather than the implementations.
Reference: [12] <author> Morrisett, G., Walker, D., and Crary, K. </author> <title> From system F to typed assembly language. </title> <booktitle> In The 25th Annual ACM Symposium on Principles of Programming Languages (Jan. </booktitle> <year> 1998), </year> <note> ACM. To appear. </note>
Reference-contexts: For this reason, types are dropped in TIL before the register allocation phase and thus, no type-checking is possible at the level of the compiler output. The problems related to register allocation are solved by Morrisett et al. <ref> [12] </ref> by choosing a more expressive type system, but the issue of memory-safety in the presence of optimizations such as array bounds-checking elimination still remains a problem. The purpose and the design of our certifying compiler are also related to the Java [20] compiler and byte-code verifier [21] systems. <p> since these checks are built in to the definition of the byte codes. 9 Discussion and Future Work [In the full paper, this section discusses variations of the certifying compiler scheme presented here, especially as they relate to Java bytecode verification and type-checking in the type-system of Morrisett et al. <ref> [12] </ref>.
Reference: [13] <author> Necula, G. C. </author> <title> Proof-carrying code. </title> <booktitle> In The 24th Annual ACM Symposium on Principles of Programming Languages (Jan. 1997), ACM, </booktitle> <pages> pp. 106-119. </pages>
Reference-contexts: benefit of our design is that it requires relatively few modifications to the traditional compiler design, and hence it should be possible to adapt existing compilers to this technique. * This method is a practical method for produc ing, in an automatic manner, the safety proofs for a Proof-Carrying Code <ref> [13, 14] </ref> system for type safety.
Reference: [14] <author> Necula, G. C., and Lee, P. </author> <title> Safe kernel exten sions without run-time checking. </title> <booktitle> In Second Symposium on Operating Systems Design and Implementations (Oct. 1996), Usenix, </booktitle> <pages> pp. 229-243. </pages>
Reference-contexts: benefit of our design is that it requires relatively few modifications to the traditional compiler design, and hence it should be possible to adapt existing compilers to this technique. * This method is a practical method for produc ing, in an automatic manner, the safety proofs for a Proof-Carrying Code <ref> [13, 14] </ref> system for type safety. <p> This is a significant advantage, since the VCGen and proof checker are significantly simpler than the compiler and the prover. Our confidence in VCGen and the proof checker is further enhanced by the fact that they are borrowed unchanged from our Proof-Carrying Code system, <ref> [14] </ref> which has been in use since September 1996. 3 The Source Language The concept of the certifying compiler, and in fact most of the implementation of the certifier subsystem are independent of the particular typed language being compiled.
Reference: [15] <author> Necula, G. C., and Lee, P. </author> <title> Efficient representa tion and validation of logical proofs. </title> <type> Technical Report CMU-CS-97-172, </type> <institution> Computer Science Department, Carnegie Mellon University, </institution> <month> Oct. </month> <year> 1997. </year>
Reference-contexts: Then LF type-checking is enough to validate the proof. (The fact that this approach is sound is established in [8]. We have made some modifications that are described and proved to be sound in <ref> [15] </ref>.) The advantage of this arrangement is that the LF type-checker is independent of the logic and thus we are able to reuse its implementation for checking proofs in many logics, including the memory-safety and type-safety logic presented here.
Reference: [16] <author> Nelson, G., and Oppen, D. </author> <title> Simplification by cooperating decision procedures. </title> <journal> ACM Transactions on Programming Languages and Systems 1, </journal> <month> 2 (Oct. </month> <year> 1979), </year> <pages> 245-257. </pages>
Reference-contexts: However, we feel that these are important properties, and thus, to retain them we have implemented a theorem prover that emits proofs. The theorem prover is based on the Nelson-Oppen architecture for cooperating decision procedures <ref> [16] </ref>, also implemented in the Stanford Pascal Verifier [3] and the Extended Static Checking [4] systems. Theorem provers are traditionally viewed as logically-incomplete systems that require human intervention in many instances.
Reference: [17] <author> Oliva, D. P., Ramsdell, J. D., and Wand, M. </author> <title> The VLISP verified PreScheme compiler. </title> <booktitle> Lisp and Symbolic Computation, 8 (1995), </booktitle> <pages> 111-182. </pages>
Reference-contexts: In a paper published in 1963, John McCarthy refers to this problem as "one of the most interesting and useful goals for the mathematical science of computation" [9]. However, despite a large body of work in the area <ref> [5, 7, 10, 11, 17, 23, 24] </ref>, we still lack the technology to prove automatically the correctness of an optimizing compiler. Even manual proofs are rare, and they tend to verify only the algorithms rather than the implementations.
Reference: [18] <author> Owre, S., Rushby, J. M., and Shankar, N. PVS: </author> <title> A prototype verification system. </title> <booktitle> In 11th International Conference on Automated Deduction (CADE) (Saratoga, </booktitle> <address> NY, </address> <month> June </month> <year> 1992), </year> <editor> D. Kapur, Ed., </editor> <volume> vol. </volume> <booktitle> 607 of Lecture Notes in Artificial Intelligence, </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pp. 748-752. </pages>
Reference-contexts: Many of the existing theorem provers <ref> [1, 4, 6, 18] </ref> can be used for this purpose, although they do not produce proofs that can be checked independently.
Reference: [19] <author> Shostak, R. </author> <title> Deciding linear inequalities by com puting loop residues. </title> <journal> Journal of the ACM 28, </journal> <month> 4 (Oct. </month> <year> 1981), </year> <pages> 769-779. </pages>
Reference-contexts: The proof is attempted using a simple decision procedure for linear arithmetic based on computing loop residues <ref> [19] </ref>. The conditional elimination analysis is implemented as one pass through the intermediate representation. When a bounds-checking conditional is encountered, its boolean expression is converted to the form xy+c 0, where x and y are arbitrary expressions (usually variables) and c is a constant.
Reference: [20] <author> Sun Microsystems. </author> <title> The Java language specifi cation. </title> <note> Available as ftp://ftp.javasoft.com/docs/javaspec.ps.zip, </note> <year> 1995. </year>
Reference-contexts: The purpose and the design of our certifying compiler are also related to the Java <ref> [20] </ref> compiler and byte-code verifier [21] systems. The similarity is that both systems produce code that is annotated for the purpose of enabling a certification system (the bytecode verifier, in the Java case) to verify the type safety.
Reference: [21] <author> Sun Microsystems. </author> <title> The Java Virtual Machine specification. </title> <note> Available as ftp://ftp.javasoft.com/docs/vmspec.ps.zip, </note> <year> 1995. </year>
Reference-contexts: The purpose and the design of our certifying compiler are also related to the Java [20] compiler and byte-code verifier <ref> [21] </ref> systems. The similarity is that both systems produce code that is annotated for the purpose of enabling a certification system (the bytecode verifier, in the Java case) to verify the type safety.
Reference: [22] <author> Tarditi, D., Morrisett, J. G., Cheng, P., Stone, C., Harper, R., and Lee, P. </author> <title> TIL: A type-directed optimizing compiler for ML. </title> <booktitle> In PLDI'96 Conference on Programming Language Design and Implementation (May 1996), </booktitle> <pages> pp. 181-192. </pages>
Reference-contexts: On the other hand they have the more ambitious goal of verifying full equivalence of the source expression and the target program. The compilation approach presented here resembles in many respects the compilation strategy of the TIL <ref> [22] </ref> compiler for Standard ML, which uses a typed intermediate language that can be easily type-checked to achieve an independent validation of optimizations.
Reference: [23] <author> Thatcher, J. W., Wagner, E. G., and Wright, J. B. </author> <title> More on advice on structuring compilers and proving them correct. </title> <booktitle> LNCS'94: Proceedings of a Workshop on Semantics-Directed Compiler Generation, 94 (1980), </booktitle> <pages> 165-188. </pages>
Reference-contexts: In a paper published in 1963, John McCarthy refers to this problem as "one of the most interesting and useful goals for the mathematical science of computation" [9]. However, despite a large body of work in the area <ref> [5, 7, 10, 11, 17, 23, 24] </ref>, we still lack the technology to prove automatically the correctness of an optimizing compiler. Even manual proofs are rare, and they tend to verify only the algorithms rather than the implementations.
Reference: [24] <author> Young, W. D. </author> <title> A mechanically verified code gen erator. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 5 (1989), </volume> <pages> 493-518. </pages>
Reference-contexts: In a paper published in 1963, John McCarthy refers to this problem as "one of the most interesting and useful goals for the mathematical science of computation" [9]. However, despite a large body of work in the area <ref> [5, 7, 10, 11, 17, 23, 24] </ref>, we still lack the technology to prove automatically the correctness of an optimizing compiler. Even manual proofs are rare, and they tend to verify only the algorithms rather than the implementations.
References-found: 24

