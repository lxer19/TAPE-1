URL: http://www.cs.huji.ac.il/papers/IP/enhancement.ps.gz
Refering-URL: http://www.cs.huji.ac.il/papers/IP/index.html
Root-URL: 
Title: Motion Analysis for Image Enhancement: Resolution, Occlusion, and Transparency  
Author: Michal Irani Shmuel Peleg 
Address: 91904 Jerusalem, ISRAEL  
Affiliation: Institute of Computer Science The Hebrew University of Jerusalem  
Abstract: After computing the motion for the different image regions, these regions can be enhanced by fusing several successive frames covering the same region. Enhancements treated here include improvement of image resolution, filling-in occluded regions, and reconstruction of transparent objects. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Adiv. </author> <title> Determining three-dimensional motion and structure from optical flow generated by several moving objects. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 7(4) </volume> <pages> 384-401, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: Deriving Err (t) (p; q) with respect to the motion parameters and setting to zero yields six linear equations in the six unknowns: a, b, c, d, e, f [4, 5]. 3 3. Moving planar surface (a pseudo projective transformation): 8 parameters <ref> [1, 4] </ref>, p (x; y; t) = a + bx + cy + gx 2 + hxy, q (x; y; t) = d + ex + f y + gxy + hy 2 .
Reference: [2] <author> H.C. Andrews and B.R. Hunt, </author> <title> editors. Digital Image Restoration. </title> <publisher> Prentice Hall, </publisher> <year> 1977. </year>
Reference-contexts: Restoration of degraded images when a model of the degradation process is given is an ill-conditioned problem <ref> [2, 9, 11, 13, 19, 24] </ref>. The resolution of an image is determined by the physical characteristics of the sensor: the optics, the density of the detector elements, and their spatial response. Resolution improvement by modifying the sensor can be prohibitive.
Reference: [3] <author> J.R. Bergen and E.H. Adelson. </author> <title> Hierarchical, computationally efficient motion estimation algorithm. </title> <journal> J. Opt. Soc. Am. A., </journal> <volume> 4:35, </volume> <year> 1987. </year>
Reference-contexts: setting to zero, yields eight linear equations in the eight unknowns: a, b, c, d, e, f , g, h. 2.2 Detecting the First Object When the region of support of a single object in the image is known, its motion parameters can be computed using a multiresolution iterative framework <ref> [3, 4, 5, 6, 16, 17] </ref>. Motion estimation is more difficult in the common case when the scene includes several moving objects, and the region of support of each object in the image is not known.
Reference: [4] <author> J.R. Bergen, P. Anandan, K.J. Hanna, and R. Hingorani. </author> <title> Hierarchical model-based motion estimation. </title> <booktitle> In European Conference on Computer Vision, </booktitle> <pages> pages 237-252, </pages> <address> Santa Margarita Ligure, </address> <month> May </month> <year> 1992. </year> <month> 22 </month>
Reference-contexts: In order to minimize Err (t) (p; q), its derivatives with respect to a and d are set to zero. This yields two linear equations in the two unknowns, a and d. Those are the two well-known optical flow equations <ref> [4, 20] </ref>, where every small window is assumed to have a single translation. In this translation model, the entire object is assumed to have a single translation. 2. <p> Deriving Err (t) (p; q) with respect to the motion parameters and setting to zero yields six linear equations in the six unknowns: a, b, c, d, e, f <ref> [4, 5] </ref>. 3 3. Moving planar surface (a pseudo projective transformation): 8 parameters [1, 4], p (x; y; t) = a + bx + cy + gx 2 + hxy, q (x; y; t) = d + ex + f y + gxy + hy 2 . <p> Deriving Err (t) (p; q) with respect to the motion parameters and setting to zero yields six linear equations in the six unknowns: a, b, c, d, e, f [4, 5]. 3 3. Moving planar surface (a pseudo projective transformation): 8 parameters <ref> [1, 4] </ref>, p (x; y; t) = a + bx + cy + gx 2 + hxy, q (x; y; t) = d + ex + f y + gxy + hy 2 . <p> setting to zero, yields eight linear equations in the eight unknowns: a, b, c, d, e, f , g, h. 2.2 Detecting the First Object When the region of support of a single object in the image is known, its motion parameters can be computed using a multiresolution iterative framework <ref> [3, 4, 5, 6, 16, 17] </ref>. Motion estimation is more difficult in the common case when the scene includes several moving objects, and the region of support of each object in the image is not known.
Reference: [5] <author> J.R. Bergen, P.J. Burt, K. Hanna, R. Hingorani, P. Jeanne, and S. Peleg. </author> <title> Dynamic multiple--motion computation. In Y.A. </title> <editor> Feldman and A. Bruckstein, editors, </editor> <booktitle> Artificial Intelligence and Computer Vision: Proceedings of the Israeli Conference, </booktitle> <pages> pages 147-156. </pages> <publisher> Elsevier, </publisher> <year> 1991. </year>
Reference-contexts: Deriving Err (t) (p; q) with respect to the motion parameters and setting to zero yields six linear equations in the six unknowns: a, b, c, d, e, f <ref> [4, 5] </ref>. 3 3. Moving planar surface (a pseudo projective transformation): 8 parameters [1, 4], p (x; y; t) = a + bx + cy + gx 2 + hxy, q (x; y; t) = d + ex + f y + gxy + hy 2 . <p> setting to zero, yields eight linear equations in the eight unknowns: a, b, c, d, e, f , g, h. 2.2 Detecting the First Object When the region of support of a single object in the image is known, its motion parameters can be computed using a multiresolution iterative framework <ref> [3, 4, 5, 6, 16, 17] </ref>. Motion estimation is more difficult in the common case when the scene includes several moving objects, and the region of support of each object in the image is not known.
Reference: [6] <author> J.R. Bergen, P.J. Burt, R. Hingorani, and S. Peleg. </author> <title> Computing two motions from three frames. </title> <booktitle> In International Conference on Computer Vision, </booktitle> <pages> pages 27-32, </pages> <address> Osaka, Japan, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: setting to zero, yields eight linear equations in the eight unknowns: a, b, c, d, e, f , g, h. 2.2 Detecting the First Object When the region of support of a single object in the image is known, its motion parameters can be computed using a multiresolution iterative framework <ref> [3, 4, 5, 6, 16, 17] </ref>. Motion estimation is more difficult in the common case when the scene includes several moving objects, and the region of support of each object in the image is not known. <p> Taking the logarithm of the input images changes the multiplicative effects into additive effects, and once the tracking is done, the exponent is taken to return to the original scale. Previous analysis of transparency <ref> [6, 8, 21, 22, 23] </ref> assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods [6, 21, 23] elegantly avoid the segmentation problem. <p> Previous analysis of transparency [6, 8, 21, 22, 23] assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods <ref> [6, 21, 23] </ref> elegantly avoid the segmentation problem. They require, however, high order derivatives (the order increases with the number of objects), which make them sensitive to noisy data. In our work we do not assume any motion constancy. We temporally integrate the image frames rather than use temporal derivatives. <p> Therefore, we use the values of the absolute difference image as an initial mask for the search of the next dominant object in the temporal integration algorithm from Section 2.3. The tracking algorithm is applied once again to the original image sequence, and not to frame differences as in <ref> [6] </ref>. Now that the algorithm tracks the second dominant object, the new internal representation image Av 2 (t) restores the second dominant transparent object, and blurs out the other transparent objects, including the first dominant object. 15 a) b) a-b) The first and last frames in a sequence.
Reference: [7] <author> P.J. Burt, R. Hingorani, and R.J. Kolczynski. </author> <title> Mechanisms for isolating component patterns in the sequential analysis of multiple motion. </title> <booktitle> In IEEE Workshop on Visual Motion, </booktitle> <pages> pages 187-193, </pages> <address> Princeton, New Jersey, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Motion estimation is more difficult in the common case when the scene includes several moving objects, and the region of support of each object in the image is not known. It was shown in <ref> [7, 16, 17] </ref> that in this case the motion parameters of a single object can be recovered accurately by applying the same motion computation framework (with some iterative extensions [16, 17]) to the entire region of analysis. This procedure computes a single motion (the dominant motion) between two images.
Reference: [8] <author> T. Darrell and A. Pentland. </author> <title> Robust estimation of a multi-layered motion representation. </title> <booktitle> In IEEE Workshop on Visual Motion, </booktitle> <pages> pages 173-178, </pages> <address> Princeton, New Jersey, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Taking the logarithm of the input images changes the multiplicative effects into additive effects, and once the tracking is done, the exponent is taken to return to the original scale. Previous analysis of transparency <ref> [6, 8, 21, 22, 23] </ref> assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods [6, 21, 23] elegantly avoid the segmentation problem.
Reference: [9] <author> R.C. Gonzalez. </author> <title> Image enhancement and restoration. In T.Y. Young and K.S. Fu, </title> <editor> editors, </editor> <booktitle> Handbook of Pattern Recognition and Image Processing, </booktitle> <pages> pages 191-213. </pages> <publisher> Academic Press, </publisher> <year> 1986. </year>
Reference-contexts: Restoration of degraded images when a model of the degradation process is given is an ill-conditioned problem <ref> [2, 9, 11, 13, 19, 24] </ref>. The resolution of an image is determined by the physical characteristics of the sensor: the optics, the density of the detector elements, and their spatial response. Resolution improvement by modifying the sensor can be prohibitive.
Reference: [10] <author> B.K.P. Horn and B.G. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: It can be shown <ref> [10] </ref> that the desired motion (p; q) minimizes the following error function at Frame t in the region of analysis R: Err (t) (p; q) = (x;y)2R We perform the error minimization over the parameters of one of the following motion models: 1.
Reference: [11] <author> T.S. Huang, </author> <title> editor. Image Enhancement and Restoration. </title> <publisher> JAI Press, </publisher> <year> 1986. </year>
Reference-contexts: Restoration of degraded images when a model of the degradation process is given is an ill-conditioned problem <ref> [2, 9, 11, 13, 19, 24] </ref>. The resolution of an image is determined by the physical characteristics of the sensor: the optics, the density of the detector elements, and their spatial response. Resolution improvement by modifying the sensor can be prohibitive.
Reference: [12] <author> T.S. Huang and R.Y. Tsai. </author> <title> Multi-frame image restoration and registration. In T.S. </title> <editor> Huang, editor, </editor> <booktitle> Advances in Computer Vision and Image Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 317-339. </pages> <publisher> JAI Press Inc., </publisher> <year> 1984. </year>
Reference-contexts: In this section we present an algorithm for processing image sequences to obtain improved resolution of differently moving objects. This is an extension of our earlier method, which was presented in [14]. While earlier research on super-resolution <ref> [12, 14, 18, 25] </ref> treated only static scenes and pure translational motion in the image plane, we treat dynamic scenes and more complex motions.
Reference: [13] <author> R.A. Hummel, B. Kimia, </author> <title> and S.W. Zucker. Deblurring gaussian blur. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 38 </volume> <pages> 66-80, </pages> <year> 1986. </year>
Reference-contexts: Restoration of degraded images when a model of the degradation process is given is an ill-conditioned problem <ref> [2, 9, 11, 13, 19, 24] </ref>. The resolution of an image is determined by the physical characteristics of the sensor: the optics, the density of the detector elements, and their spatial response. Resolution improvement by modifying the sensor can be prohibitive.
Reference: [14] <author> M. Irani and S. Peleg. </author> <title> Improving resolution by image registration. CVGIP: Graphical Models and Image Processing, </title> <booktitle> 53 </booktitle> <pages> 231-239, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: In this section we present an algorithm for processing image sequences to obtain improved resolution of differently moving objects. This is an extension of our earlier method, which was presented in <ref> [14] </ref>. While earlier research on super-resolution [12, 14, 18, 25] treated only static scenes and pure translational motion in the image plane, we treat dynamic scenes and more complex motions. <p> In this section we present an algorithm for processing image sequences to obtain improved resolution of differently moving objects. This is an extension of our earlier method, which was presented in [14]. While earlier research on super-resolution <ref> [12, 14, 18, 25] </ref> treated only static scenes and pure translational motion in the image plane, we treat dynamic scenes and more complex motions.
Reference: [15] <author> M. Irani and S. Peleg. </author> <title> Image sequence enhancement using multiple motions analysis. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Champaign, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: An initial version of this paper appeared in <ref> [15] </ref>. 2 2 Detecting and Tracking Multiple Moving Objects In this section we describe briefly a method for detecting and tracking multiple moving objects in image sequences, which is presented in detail in [17]. Any other good motion computation method can be used as well. <p> in real-time, as only simple arithmetic operations are involved in the computation. 12 4 Reconstruction of Occlusions When parts of a tracked object are occluded in some frames by another moving object, but these parts appear in other frames, a more complete view of the occluded object can be reconstructed <ref> [15, 26] </ref>. The image frames are registered using the computed motion parameters of the tracked object, and the occluded parts of that object are then reconstructed by temporally averaging gray levels of all pixels which were classified as object pixels in the corresponding segmentation masks.
Reference: [16] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Detecting and tracking multiple moving objects using temporal integration. </title> <booktitle> In European Conference on Computer Vision, </booktitle> <pages> pages 282-287, </pages> <address> Santa Margarita Ligure, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: The motion models used to approximate the motions of the objects are 2-D parametric motions in the image plane, such as affine and projective transformations. The motion analysis is presented in a previous paper <ref> [16, 17] </ref>, and will only be briefly described here. Once an object has been tracked and segmented, it can be enhanced using information from several frames. Tracked objects can be enhanced by filling-in occluded regions, and by improving the spatial resolution of their images. <p> setting to zero, yields eight linear equations in the eight unknowns: a, b, c, d, e, f , g, h. 2.2 Detecting the First Object When the region of support of a single object in the image is known, its motion parameters can be computed using a multiresolution iterative framework <ref> [3, 4, 5, 6, 16, 17] </ref>. Motion estimation is more difficult in the common case when the scene includes several moving objects, and the region of support of each object in the image is not known. <p> Motion estimation is more difficult in the common case when the scene includes several moving objects, and the region of support of each object in the image is not known. It was shown in <ref> [7, 16, 17] </ref> that in this case the motion parameters of a single object can be recovered accurately by applying the same motion computation framework (with some iterative extensions [16, 17]) to the entire region of analysis. This procedure computes a single motion (the dominant motion) between two images. <p> It was shown in [7, 16, 17] that in this case the motion parameters of a single object can be recovered accurately by applying the same motion computation framework (with some iterative extensions <ref> [16, 17] </ref>) to the entire region of analysis. This procedure computes a single motion (the dominant motion) between two images. A segmentation procedure is then used (see Section 2.5) in order to detect the corresponding object (the dominant object) in the image. <p> This image contains, after a few frames, a sharp image of the tracked object, and a blurred image of all the other objects. Each new frame in the sequence is compared to the internal representation image of the tracked object rather than to the previous frame <ref> [16, 17] </ref>. Following is a summary of the algorithm for detecting and tracking an object in an image sequence: For each frame in the sequence (starting at t = 0) do: 1.
Reference: [17] <author> M. Irani, B. Rousso, and S. Peleg. </author> <note> Computing occluding and transparent motions. To appear in International Journal of Computer Vision, </note> <year> 1993. </year>
Reference-contexts: The motion models used to approximate the motions of the objects are 2-D parametric motions in the image plane, such as affine and projective transformations. The motion analysis is presented in a previous paper <ref> [16, 17] </ref>, and will only be briefly described here. Once an object has been tracked and segmented, it can be enhanced using information from several frames. Tracked objects can be enhanced by filling-in occluded regions, and by improving the spatial resolution of their images. <p> An initial version of this paper appeared in [15]. 2 2 Detecting and Tracking Multiple Moving Objects In this section we describe briefly a method for detecting and tracking multiple moving objects in image sequences, which is presented in detail in <ref> [17] </ref>. Any other good motion computation method can be used as well. In this approach for detecting differently moving objects, a single motion is first computed, and a single object which corresponds to this motion is identified and tracked. <p> setting to zero, yields eight linear equations in the eight unknowns: a, b, c, d, e, f , g, h. 2.2 Detecting the First Object When the region of support of a single object in the image is known, its motion parameters can be computed using a multiresolution iterative framework <ref> [3, 4, 5, 6, 16, 17] </ref>. Motion estimation is more difficult in the common case when the scene includes several moving objects, and the region of support of each object in the image is not known. <p> Motion estimation is more difficult in the common case when the scene includes several moving objects, and the region of support of each object in the image is not known. It was shown in <ref> [7, 16, 17] </ref> that in this case the motion parameters of a single object can be recovered accurately by applying the same motion computation framework (with some iterative extensions [16, 17]) to the entire region of analysis. This procedure computes a single motion (the dominant motion) between two images. <p> It was shown in [7, 16, 17] that in this case the motion parameters of a single object can be recovered accurately by applying the same motion computation framework (with some iterative extensions <ref> [16, 17] </ref>) to the entire region of analysis. This procedure computes a single motion (the dominant motion) between two images. A segmentation procedure is then used (see Section 2.5) in order to detect the corresponding object (the dominant object) in the image. <p> This image contains, after a few frames, a sharp image of the tracked object, and a blurred image of all the other objects. Each new frame in the sequence is compared to the internal representation image of the tracked object rather than to the previous frame <ref> [16, 17] </ref>. Following is a summary of the algorithm for detecting and tracking an object in an image sequence: For each frame in the sequence (starting at t = 0) do: 1.
Reference: [18] <author> S.P. Kim, N.K. Bose, and H.M. valenzuela. </author> <title> Recursive reconstruction of high resolution image from noisy undersampled multiframes. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> 38(6) </volume> <pages> 1013-1027, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: In this section we present an algorithm for processing image sequences to obtain improved resolution of differently moving objects. This is an extension of our earlier method, which was presented in [14]. While earlier research on super-resolution <ref> [12, 14, 18, 25] </ref> treated only static scenes and pure translational motion in the image plane, we treat dynamic scenes and more complex motions.
Reference: [19] <author> R.L. Lagendijk and J. Biemond. </author> <title> Iterative Identification and Restoration of Images. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston/Dordrecht/London, </address> <year> 1991. </year> <month> 23 </month>
Reference-contexts: Restoration of degraded images when a model of the degradation process is given is an ill-conditioned problem <ref> [2, 9, 11, 13, 19, 24] </ref>. The resolution of an image is determined by the physical characteristics of the sensor: the optics, the density of the detector elements, and their spatial response. Resolution improvement by modifying the sensor can be prohibitive. <p> The average taking in Equation (4) reduces additive noise. The algorithm is numerically similar to common iterative methods for solving sets of linear equations <ref> [19] </ref>, and therefore has similar properties, such as rapid convergence (see next paragraph). In Figure 6, the resolution of a car's license plate was improved from 15 frames. Analysis and Discussion.
Reference: [20] <author> B.D. Lucas and T. Kanade. </author> <title> An iterative image registration technique with an application to stereo vision. </title> <booktitle> In Image Understanding Workshop, </booktitle> <pages> pages 121-130, </pages> <year> 1981. </year>
Reference-contexts: In order to minimize Err (t) (p; q), its derivatives with respect to a and d are set to zero. This yields two linear equations in the two unknowns, a and d. Those are the two well-known optical flow equations <ref> [4, 20] </ref>, where every small window is assumed to have a single translation. In this translation model, the entire object is assumed to have a single translation. 2.
Reference: [21] <author> M. Shizawa. </author> <title> On visual ambiguities due to transparency in motion and stereo. </title> <booktitle> In European Conference on Computer Vision, </booktitle> <pages> pages 411-419, </pages> <address> Santa Margarita Ligure, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Taking the logarithm of the input images changes the multiplicative effects into additive effects, and once the tracking is done, the exponent is taken to return to the original scale. Previous analysis of transparency <ref> [6, 8, 21, 22, 23] </ref> assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods [6, 21, 23] elegantly avoid the segmentation problem. <p> Previous analysis of transparency [6, 8, 21, 22, 23] assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods <ref> [6, 21, 23] </ref> elegantly avoid the segmentation problem. They require, however, high order derivatives (the order increases with the number of objects), which make them sensitive to noisy data. In our work we do not assume any motion constancy. We temporally integrate the image frames rather than use temporal derivatives.
Reference: [22] <author> M. Shizawa and K. Mase. </author> <title> Simultaneous multiple optical flow estimation. </title> <booktitle> In International Conference on Pattern Recognition, </booktitle> <pages> pages 274-278, </pages> <address> Atlantic City, New Jersey, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Taking the logarithm of the input images changes the multiplicative effects into additive effects, and once the tracking is done, the exponent is taken to return to the original scale. Previous analysis of transparency <ref> [6, 8, 21, 22, 23] </ref> assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods [6, 21, 23] elegantly avoid the segmentation problem.
Reference: [23] <author> M. Shizawa and K. Mase. </author> <title> Principle of superposition: A common computational framework for analysis of multiple motion. </title> <booktitle> In IEEE Workshop on Visual Motion, </booktitle> <pages> pages 164-172, </pages> <address> Princeton, New Jersey, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Taking the logarithm of the input images changes the multiplicative effects into additive effects, and once the tracking is done, the exponent is taken to return to the original scale. Previous analysis of transparency <ref> [6, 8, 21, 22, 23] </ref> assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods [6, 21, 23] elegantly avoid the segmentation problem. <p> Previous analysis of transparency [6, 8, 21, 22, 23] assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods <ref> [6, 21, 23] </ref> elegantly avoid the segmentation problem. They require, however, high order derivatives (the order increases with the number of objects), which make them sensitive to noisy data. In our work we do not assume any motion constancy. We temporally integrate the image frames rather than use temporal derivatives.
Reference: [24] <author> H. Shvayster and S. Peleg. </author> <title> Inversion of picture operators. </title> <journal> Pattern Recognition Letters, </journal> <volume> 5 </volume> <pages> 49-61, </pages> <year> 1985. </year>
Reference-contexts: Restoration of degraded images when a model of the degradation process is given is an ill-conditioned problem <ref> [2, 9, 11, 13, 19, 24] </ref>. The resolution of an image is determined by the physical characteristics of the sensor: the optics, the density of the detector elements, and their spatial response. Resolution improvement by modifying the sensor can be prohibitive.
Reference: [25] <author> H. Ur and Gross D. </author> <title> Improved resolution from subpixel shifted pictures. CVGIP: Graphical Models and Image Processing, </title> <booktitle> 54 </booktitle> <pages> 181-186, </pages> <year> 1992. </year>
Reference-contexts: In this section we present an algorithm for processing image sequences to obtain improved resolution of differently moving objects. This is an extension of our earlier method, which was presented in [14]. While earlier research on super-resolution <ref> [12, 14, 18, 25] </ref> treated only static scenes and pure translational motion in the image plane, we treat dynamic scenes and more complex motions.
Reference: [26] <author> J. Wang and E. Adelson. </author> <title> Layered representation for motion analysis. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 361-366, </pages> <address> New York, </address> <month> June </month> <year> 1993. </year> <month> 24 </month>
Reference-contexts: in real-time, as only simple arithmetic operations are involved in the computation. 12 4 Reconstruction of Occlusions When parts of a tracked object are occluded in some frames by another moving object, but these parts appear in other frames, a more complete view of the occluded object can be reconstructed <ref> [15, 26] </ref>. The image frames are registered using the computed motion parameters of the tracked object, and the occluded parts of that object are then reconstructed by temporally averaging gray levels of all pixels which were classified as object pixels in the corresponding segmentation masks.
References-found: 26

