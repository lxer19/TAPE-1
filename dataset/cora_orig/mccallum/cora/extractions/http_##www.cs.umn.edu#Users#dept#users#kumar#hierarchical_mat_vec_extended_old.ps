URL: http://www.cs.umn.edu/Users/dept/users/kumar/hierarchical_mat_vec_extended_old.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Email: samehg@cs.umn.edu  
Title: Parallel Matrix-Vector Product Using Approximate Hierarchical Methods  
Author: Ananth Grama, Vipin Kumar, Ahmed Sameh fananth, kumar, 
Address: Minneapolis, MN 55455  
Affiliation: Department of Computer Science, University of Minnesota  
Abstract: Matrix-vector products (mat-vecs) form the core of iterative methods used for solving dense linear systems. Often, these systems arise in the solution of integral equations used in electro-magnetics, heat transfer, and wave propagation. In this paper, we present a parallel approximate method for computing mat-vecs used in the solution of integral equations. We use this method to compute dense mat-vecs of hundreds of thousands of elements. The combined speedups obtained from the use of approximate methods and parallel processing represent an improvement of several orders of magnitude over exact mat-vecs on uniprocessors. We demonstrate that our parallel formulation incurs minimal parallel processing overhead and scales up to a large number of processors. We study the impact of varying the accuracy of the approximate mat-vec on overall time and on parallel efficiency. Experimental results are presented for a 256 processor CM5 parallel computer. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. W. Appel. </author> <title> An efficient program for many-body simulation. </title> <journal> SIAM Journal of Computing, </journal> <volume> 6, </volume> <year> 1985. </year>
Reference-contexts: This forms the basis of hierarchical methods. These methods provide systematic ways of aggregating entities and computing interactions while controlling the overall error in modeling. Algorithms based on hierarchical techniques include Barnes-Hut [2], Fast Multipole [8], and Appel's <ref> [1] </ref> algorithms. Approximating long range interactions in this manner reduces the sequential complexity of typical simulations involving n particles from O (n 2 ) to O (n log n) or O (n).
Reference: [2] <author> J. Barnes and P. Hut. </author> <title> A hierarchical o(n log n) force calculation algorithm. </title> <journal> Nature, </journal> <volume> 324, </volume> <year> 1986. </year>
Reference-contexts: Using this approach, the total number of interactions in the system can be reduced significantly. This forms the basis of hierarchical methods. These methods provide systematic ways of aggregating entities and computing interactions while controlling the overall error in modeling. Algorithms based on hierarchical techniques include Barnes-Hut <ref> [2] </ref>, Fast Multipole [8], and Appel's [1] algorithms. Approximating long range interactions in this manner reduces the sequential complexity of typical simulations involving n particles from O (n 2 ) to O (n log n) or O (n).
Reference: [3] <author> J. A. Board, J. W. Causey, J. F. Leathrum, A. Windemuth, and K. Schulten. </author> <title> Accelerated molecular dynamics with the fast multipole algorithm. </title> <institution> Chem. Phys. Let., 198:89, </institution> <year> 1992. </year>
Reference-contexts: Parallel formulations of hierarchical methods involve partitioning the domain among various processors with the combined objectives of optimizing communication and balancing load. If particle densities are uniform across the domain, these objectives are easily met <ref> [3, 17, 10, 12, 7] </ref>. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [13] and Warren and Salmon [16, 15] present schemes for irregular distributions that try to meet these objectives. <p> This is usually the case and we use significantly smaller values of ff ensuring greater accuracy. 3.1 Overview of Existing Parallel Formulations of Hierarchical Methods A number of researchers have explored parallel formulations of hierarchical techniques. Whereas most of the research addresses uniform particle distributions <ref> [3, 17, 10, 12, 7] </ref>, work has also been done for highly non-uniform distributions [16, 15, 13, 4, 5]. The scheme proposed by Singh et al. [13] (referred to as Costzones) was designed and presented for shared address space computers such as the DASH and KSR.
Reference: [4] <author> Ananth Grama, Vipin Kumar, and Ahmad Sameh. </author> <title> Scalable parallel formulations of the barnes-hut method for n-body simulations. </title> <booktitle> In Supercomputing '94 Proceedings, </booktitle> <year> 1994. </year>
Reference-contexts: For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [13] and Warren and Salmon [16, 15] present schemes for irregular distributions that try to meet these objectives. In <ref> [4, 5] </ref> we present alternate schemes for irregular distributions that improve on the performance of the earlier schemes. <p> Whereas most of the research addresses uniform particle distributions [3, 17, 10, 12, 7], work has also been done for highly non-uniform distributions <ref> [16, 15, 13, 4, 5] </ref>. The scheme proposed by Singh et al. [13] (referred to as Costzones) was designed and presented for shared address space computers such as the DASH and KSR. <p> In both of the schemes discussed above, all force computations for a particle are performed by the processor to which the particle is assigned. This implies that if a tree node is not available locally, it must be fetched. This paradigm of is called data shipping. In <ref> [4, 5] </ref>, we noted several drawbacks of data shipping schemes. We propose two other schemes that are based on the function shipping paradigm. <p> The schemes of Singh et. al. and Warren and Salmon are data shipping schemes. We had demonstrated the equivalence of these schemes in <ref> [4] </ref>. Data shipping schemes incur the following overheads: * Since a point may interact with any node in a tree, it must be possible to address a node inside a tree quickly. This is done using a hash function in the WS scheme. Collisions are handled using chaining. <p> The function shipping schemes presented in <ref> [4] </ref> are based on a static decomposition of the domain into a large number of clusters. These clusters are then assigned to processors using a Morton ordering of the clusters. This formulation has been shown to have good performance for moderately irregular particle distributions. <p> Singh et. al. [13] show that by ordering the sons of a node in a specific manner while constructing 9 the tree, it is possible to ensure that the partitions assigned to processors are contiguous in space. We have shown <ref> [4] </ref> that this ordering is identical to constructing a Peano-Hilbert ordering of the nodes. 4.3 Performance of the New Formulation The parallel formulation presented in this section offers several enhancements over the existing formulations.
Reference: [5] <author> Ananth Grama, Vipin Kumar, and Ahmed Sameh. </author> <title> On n-body simulations using message passing parallel computers. </title> <booktitle> In Proceedings of the SIAM Conference on Parallel Processing, </booktitle> <address> San Francisco, </address> <year> 1995. </year>
Reference-contexts: For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [13] and Warren and Salmon [16, 15] present schemes for irregular distributions that try to meet these objectives. In <ref> [4, 5] </ref> we present alternate schemes for irregular distributions that improve on the performance of the earlier schemes. <p> Whereas most of the research addresses uniform particle distributions [3, 17, 10, 12, 7], work has also been done for highly non-uniform distributions <ref> [16, 15, 13, 4, 5] </ref>. The scheme proposed by Singh et al. [13] (referred to as Costzones) was designed and presented for shared address space computers such as the DASH and KSR. <p> In both of the schemes discussed above, all force computations for a particle are performed by the processor to which the particle is assigned. This implies that if a tree node is not available locally, it must be fetched. This paradigm of is called data shipping. In <ref> [4, 5] </ref>, we noted several drawbacks of data shipping schemes. We propose two other schemes that are based on the function shipping paradigm.
Reference: [6] <author> L. Greengard. </author> <title> The Rapid Evaluation of Potential Fields in Particle Systems. </title> <publisher> ACM Press, </publisher> <year> 1987. </year>
Reference-contexts: This is done in the context of evaluating the charge density in a given conductor <ref> [11, 6] </ref>. <p> In our code, we use the expansion 11 corresponding to Equation 3, although, as can be seen, it is easy to incorporate other expansions. The translation of a multipole series centered at point x 0 to point x can be derived similarly <ref> [6] </ref>. We now discuss the specific results of our experimental study. 5.1 Parallel Efficiency and Overheads We present the parallel runtime and efficiency of four different problem instances. It is impossible to run these instances on a single processor because of their memory requirements.
Reference: [7] <author> L. Greengard and W. Gropp. </author> <title> A parallel version of the fast multipole method. </title> <booktitle> Parallel Processing for Scientific Computing, </booktitle> <pages> pages 213-222, </pages> <year> 1987. </year>
Reference-contexts: Parallel formulations of hierarchical methods involve partitioning the domain among various processors with the combined objectives of optimizing communication and balancing load. If particle densities are uniform across the domain, these objectives are easily met <ref> [3, 17, 10, 12, 7] </ref>. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [13] and Warren and Salmon [16, 15] present schemes for irregular distributions that try to meet these objectives. <p> This is usually the case and we use significantly smaller values of ff ensuring greater accuracy. 3.1 Overview of Existing Parallel Formulations of Hierarchical Methods A number of researchers have explored parallel formulations of hierarchical techniques. Whereas most of the research addresses uniform particle distributions <ref> [3, 17, 10, 12, 7] </ref>, work has also been done for highly non-uniform distributions [16, 15, 13, 4, 5]. The scheme proposed by Singh et al. [13] (referred to as Costzones) was designed and presented for shared address space computers such as the DASH and KSR.
Reference: [8] <author> L. Greengard and V. Rokhlin. </author> <title> A fast algorithm for particle simulations. </title> <journal> J. Comp. Physics, </journal> <volume> 73 </volume> <pages> 325-348, </pages> <year> 1987. </year>
Reference-contexts: This forms the basis of hierarchical methods. These methods provide systematic ways of aggregating entities and computing interactions while controlling the overall error in modeling. Algorithms based on hierarchical techniques include Barnes-Hut [2], Fast Multipole <ref> [8] </ref>, and Appel's [1] algorithms. Approximating long range interactions in this manner reduces the sequential complexity of typical simulations involving n particles from O (n 2 ) to O (n log n) or O (n).
Reference: [9] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Algorithm Design and Analysis. </title> <address> Benjamin/Cummings, Redwod City, </address> <year> 1994. </year>
Reference-contexts: It is easy to see that the subtree rooted at the branch node is an accurate representation of the Barnes-Hut tree. After constructing 7 the local trees, the branch nodes are collected and broadcast to all the processors using a single all-to-all broadcast operation <ref> [9] </ref>. The non-local branch nodes thus received by each processor are inserted into their respective trees and the top levels of the tree are reconstructed by all processors independently. <p> All particles lying in the tree between load boundaries iW=p and (i + 1)W=p are collected in a bin for processor i. After each processor goes through its local tree, the points are communicated to the designated processors using a single all-to-all personalized communication <ref> [9] </ref>. In this load balancing technique, the tree is traversed in a left to right manner. If the sons of a node are ordered arbitrarily, the resulting partitions are not guaranteed to be physically contiguous. <p> This implies that as the accuracy is increased, the efficiency of our formulation increases. 10 5 Experimental Results In this section, we report on the implementation of our parallel formulation. The objectives of this experimental study are as follows: * Accurate methods for computing mat-vecs parallelize very well <ref> [9] </ref>. Approximate methods for computing mat-vecs are considerably faster in the serial context. However, their paralleliz-ability has not been explored.
Reference: [10] <author> J. F. Leathrum and J. A. </author> <title> Board. Mapping the adaptive fast multipole algorithm into mimd systems. </title> <editor> In P. Mehrotra and J. Saltz, editors, </editor> <title> Unstructured Scientific Computation on Scalable Multiprocessors. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: Parallel formulations of hierarchical methods involve partitioning the domain among various processors with the combined objectives of optimizing communication and balancing load. If particle densities are uniform across the domain, these objectives are easily met <ref> [3, 17, 10, 12, 7] </ref>. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [13] and Warren and Salmon [16, 15] present schemes for irregular distributions that try to meet these objectives. <p> This is usually the case and we use significantly smaller values of ff ensuring greater accuracy. 3.1 Overview of Existing Parallel Formulations of Hierarchical Methods A number of researchers have explored parallel formulations of hierarchical techniques. Whereas most of the research addresses uniform particle distributions <ref> [3, 17, 10, 12, 7] </ref>, work has also been done for highly non-uniform distributions [16, 15, 13, 4, 5]. The scheme proposed by Singh et al. [13] (referred to as Costzones) was designed and presented for shared address space computers such as the DASH and KSR.
Reference: [11] <author> Keith Nabors and Jacob White. Fastcap: </author> <title> A multipole accelerated 3-d capacitance extraction program. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 10(11) </volume> <pages> 1447-1459, </pages> <month> Nov </month> <year> 1991. </year>
Reference-contexts: This is done in the context of evaluating the charge density in a given conductor <ref> [11, 6] </ref>.
Reference: [12] <author> K. E. Schmidt and M. A. Lee. </author> <title> Implementing the fast multipole method in three dimensions. </title> <journal> J. Stat. Phys., </journal> <volume> 63:1120, </volume> <year> 1991. </year>
Reference-contexts: Parallel formulations of hierarchical methods involve partitioning the domain among various processors with the combined objectives of optimizing communication and balancing load. If particle densities are uniform across the domain, these objectives are easily met <ref> [3, 17, 10, 12, 7] </ref>. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [13] and Warren and Salmon [16, 15] present schemes for irregular distributions that try to meet these objectives. <p> This is usually the case and we use significantly smaller values of ff ensuring greater accuracy. 3.1 Overview of Existing Parallel Formulations of Hierarchical Methods A number of researchers have explored parallel formulations of hierarchical techniques. Whereas most of the research addresses uniform particle distributions <ref> [3, 17, 10, 12, 7] </ref>, work has also been done for highly non-uniform distributions [16, 15, 13, 4, 5]. The scheme proposed by Singh et al. [13] (referred to as Costzones) was designed and presented for shared address space computers such as the DASH and KSR.
Reference: [13] <author> J. Singh, C. Holt, T. Totsuka, A. Gupta, and J. Hennessy. </author> <title> Load balancing and data locality in hierarchical n-body methods. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> 1994 (to appear). </note>
Reference-contexts: If particle densities are uniform across the domain, these objectives are easily met [3, 17, 10, 12, 7]. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. <ref> [13] </ref> and Warren and Salmon [16, 15] present schemes for irregular distributions that try to meet these objectives. In [4, 5] we present alternate schemes for irregular distributions that improve on the performance of the earlier schemes. <p> Whereas most of the research addresses uniform particle distributions [3, 17, 10, 12, 7], work has also been done for highly non-uniform distributions <ref> [16, 15, 13, 4, 5] </ref>. The scheme proposed by Singh et al. [13] (referred to as Costzones) was designed and presented for shared address space computers such as the DASH and KSR. <p> Whereas most of the research addresses uniform particle distributions [3, 17, 10, 12, 7], work has also been done for highly non-uniform distributions [16, 15, 13, 4, 5]. The scheme proposed by Singh et al. <ref> [13] </ref> (referred to as Costzones) was designed and presented for shared address space computers such as the DASH and KSR. <p> It is possible to view a particle as a computational entity. Since each particle requires traversing a different number of nodes in the tree, the computational load associated with each particle is not the same. However, as noted in <ref> [13, 16] </ref>, since the particles are not expected to move significantly between two time-steps, it is possible to use the number of interactions during the current time-step as an estimate of its load in the next time-step. First, assume that the whole Barnes-Hut tree is available to all the processors. <p> In this load balancing technique, the tree is traversed in a left to right manner. If the sons of a node are ordered arbitrarily, the resulting partitions are not guaranteed to be physically contiguous. Singh et. al. <ref> [13] </ref> show that by ordering the sons of a node in a specific manner while constructing 9 the tree, it is possible to ensure that the partitions assigned to processors are contiguous in space.
Reference: [14] <author> J. P. Singh, J. L. Hennessy, and A. Gupta. </author> <title> Implications of hierarchical n-body techniques for multicomputer architectures. </title> <type> Technical Report CSL-TR-92-506, </type> <institution> Stanford University, </institution> <year> 1992. </year> <month> 16 </month>
Reference-contexts: present an efficient 6 implementation of the partitioning technique for message passing machines that avoids the sorting overhead. * The communication overhead increases as the degree of multipole expansion is increased. * One of the primary deterrents to porting n-body codes to message passing computers identified by Singh et al. <ref> [14] </ref> is the fact that receiver initiated data transfer of small messages over long distances is very expensive. The function shipping schemes presented in [4] are based on a static decomposition of the domain into a large number of clusters.
Reference: [15] <author> M. Warren and J. Salmon. </author> <title> Astrophysical n-body simulations using hierarchical tree data structures. </title> <booktitle> In Proceedings of Supercomputing Conference, </booktitle> <year> 1992. </year>
Reference-contexts: If particle densities are uniform across the domain, these objectives are easily met [3, 17, 10, 12, 7]. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [13] and Warren and Salmon <ref> [16, 15] </ref> present schemes for irregular distributions that try to meet these objectives. In [4, 5] we present alternate schemes for irregular distributions that improve on the performance of the earlier schemes. <p> Whereas most of the research addresses uniform particle distributions [3, 17, 10, 12, 7], work has also been done for highly non-uniform distributions <ref> [16, 15, 13, 4, 5] </ref>. The scheme proposed by Singh et al. [13] (referred to as Costzones) was designed and presented for shared address space computers such as the DASH and KSR.
Reference: [16] <author> M. Warren and J. Salmon. </author> <title> A parallel hashed oct tree n-body algorithm. </title> <booktitle> In Proceedings of Supercomputing Conference, </booktitle> <year> 1993. </year>
Reference-contexts: If particle densities are uniform across the domain, these objectives are easily met [3, 17, 10, 12, 7]. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [13] and Warren and Salmon <ref> [16, 15] </ref> present schemes for irregular distributions that try to meet these objectives. In [4, 5] we present alternate schemes for irregular distributions that improve on the performance of the earlier schemes. <p> Whereas most of the research addresses uniform particle distributions [3, 17, 10, 12, 7], work has also been done for highly non-uniform distributions <ref> [16, 15, 13, 4, 5] </ref>. The scheme proposed by Singh et al. [13] (referred to as Costzones) was designed and presented for shared address space computers such as the DASH and KSR. <p> But as the authors note, the same scheme works for the Barnes-Hut algorithm too. In this paper, we discuss it only in the context of the Barnes-Hut algorithm. 5 The scheme proposed by Warren and Salmon <ref> [16] </ref> (henceforth referred to as WS) was originally designed for a message passing computer. In the WS scheme, a key is computed for each particle by interleaving the bits of the x and the y coordinates. This key is referred to as the Morton index. <p> It is possible to view a particle as a computational entity. Since each particle requires traversing a different number of nodes in the tree, the computational load associated with each particle is not the same. However, as noted in <ref> [13, 16] </ref>, since the particles are not expected to move significantly between two time-steps, it is possible to use the number of interactions during the current time-step as an estimate of its load in the next time-step. First, assume that the whole Barnes-Hut tree is available to all the processors. <p> After this phase, each processor has the top few levels of the tree enveloped by the branch nodes, and the complete subtrees rooted at its branch nodes. This phase of the algorithm is identical to the tree construction phase of Warren and Salmon <ref> [16] </ref>. 4.2.2 Force Computation In this phase, each particle traverses the tree and computes required interactions. For each particle assigned to a processor, it starts at the root node of the tree (which is locally available). It traverses the tree until it reaches a node that is not locally available.
Reference: [17] <author> F. Zhao and S. L. Johnsson. </author> <title> The parallel multipole method on the connection machine. </title> <journal> SIAM J. of Sci. Stat. Comp., </journal> <volume> 12 </volume> <pages> 1420-1437, </pages> <year> 1991. </year> <month> 17 </month>
Reference-contexts: Parallel formulations of hierarchical methods involve partitioning the domain among various processors with the combined objectives of optimizing communication and balancing load. If particle densities are uniform across the domain, these objectives are easily met <ref> [3, 17, 10, 12, 7] </ref>. For irregular distributions, these objectives are hard to achieve because of the highly unstructured nature of both computation and communication. Singh et al. [13] and Warren and Salmon [16, 15] present schemes for irregular distributions that try to meet these objectives. <p> This is usually the case and we use significantly smaller values of ff ensuring greater accuracy. 3.1 Overview of Existing Parallel Formulations of Hierarchical Methods A number of researchers have explored parallel formulations of hierarchical techniques. Whereas most of the research addresses uniform particle distributions <ref> [3, 17, 10, 12, 7] </ref>, work has also been done for highly non-uniform distributions [16, 15, 13, 4, 5]. The scheme proposed by Singh et al. [13] (referred to as Costzones) was designed and presented for shared address space computers such as the DASH and KSR.
References-found: 17

