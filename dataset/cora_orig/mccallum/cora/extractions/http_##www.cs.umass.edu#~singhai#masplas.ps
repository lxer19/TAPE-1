URL: http://www.cs.umass.edu/~singhai/masplas.ps
Refering-URL: http://www.cs.umass.edu/~singhai/publications.html
Root-URL: 
Email: (singhai@cs.umass.edu)  
Title: Loop Fusion for Data Locality and Parallelism  heuristic solution.  
Author: Sharad Singhai and Kathryn McKinley 
Date: April 27, 1996  
Address: New Paltz  
Note: Proceedings of MASPLAS'96, The Mid-Atlantic Student Workshop on Programming Languages and  
Affiliation: Dept. of Computer Science University of Massachusetts  Systems, SUNY at  
Abstract: Loop fusion is a reordering transformation that merges multiple loops into a single loop. It can increase data locality thereby exploiting better cache locality; it can also increase the granularity of parallel loops, thereby decreasing barrier synchronization overhead and improving program performance. However, very large granularity loops are undesirable, if they introduce register spills inside the loop. Previous approaches to the fusion problem have considered all these factors in isolation. In this work, we present a new model which considers data locality and parallelism together subject to the register pressure. We build a weighted directed acyclic graph, called the fusion graph, in which the nodes represent loops and the weights on edges represent amount of locality and parallelism present. The direction of an edge represents an execution order constraint. We partition the graph into components such that the sum of the weights on the edges cut is minimized subject to the constraint that the nodes in the same partition can be safely fused together and the resultant loops do not exceed the maximum allowable register pressure. Previous research has demonstrated that the general problem of finding optimal partitioning is NP-hard. However, we show that in restricted cases it is possible to arrive at the optimal solution and for the general case we propose a This work is being implemented for fortran programs in ParaScope parallel programming environment. In this paper we present preliminary results and demonstrate that our approach is more general and significant performance improvements are achived. 
Abstract-found: 1
Intro-found: 1
Reference: [AS79] <author> W. Abu-Sufah. </author> <title> Improving the Performance of Virtual Memory Computers. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1979. </year>
Reference-contexts: In the first two cases, fusion is legal since the direction of the dependence is preserved. Fusion is illegal when a loop-independent dependence becomes a backward loop-carried dependence after fusion. Such dependences are called fusionpreventing dependences <ref> [AS79] </ref>. A simple test for this case is dependence testing on the two loop bodies as if they were in a single loop [Wol89].
Reference: [Cal87] <author> D. Callahan. </author> <title> A Global Approach to Detection of Parallelism. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> March </month> <year> 1987. </year>
Reference-contexts: Kennedy and McKinley proved that fusion for optimal reuse is NP-hard [KM93a]. In his thesis, Callahan proved that loop fusion to minimize the number of loops is NP-hard when we are allowed to permute the loop nests <ref> [Cal87] </ref>. The problem is compounded by the fact that there are several loop transformations which interact with loop fusion and loop fusion itself can have several objectives like maximizing reuse, maximizing parallelism and not exceeding number of available registers within a fused loop.
Reference: [GJ79] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman and Company, </publisher> <address> San Francisco, CA, </address> <year> 1979. </year>
Reference-contexts: There is a restriction on the maximum size of an individual subsets. This problem is known to be NP-complete <ref> [GJ79] </ref>. The vertex weight corresponds to the register requirements of individual loop and edge weight corresponds to the amount of reuse between different loops. In addition, we have the constraint that certain given pairs of vertices can never be put in the same partition (these pairs represent fusion preventing edges).
Reference: [GOST92] <author> G. Gao, R. Olsen, V. Sarkar, and R. Thekkath. </author> <title> Collective loop fusion for 5.10 array contraction. </title> <booktitle> In Proceedings of the Fifth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> New Haven, CT, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: The problem is compounded by the fact that there are several loop transformations which interact with loop fusion and loop fusion itself can have several objectives like maximizing reuse, maximizing parallelism and not exceeding number of available registers within a fused loop. Previous fusion approaches <ref> [KM93a, KM93b, GOST92] </ref> have considered the fusion problem in isolation. Kennedy and McKinley considered the two objectives of maximizing parallelism and in creasing data locality separately which may not give 5.8 optimal results [KM93b]. Also, they restricted their attention to fusing only adjacent loops.
Reference: [HKM91] <author> M. W. Hall, K. Kennedy, and K. S. McKinley. </author> <title> Interprocedural transformations for parallel code generation. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <address> Al-buquerque, NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: all of the following properties * If vertex i and j are in the same partition then all the vertices on the directed paths in G from i to j are also in the same partition. 3 2 Fusion works across procedures too if good inter procedural analysis is available <ref> [HKM91] </ref>. 3 This constraint is also referred to as convexity constraint. 5.5 * Two nodes connected by a fusion preventing dependence may not be in the same partition. * Any two nodes are in the same partition only if they have a path (without any fusion preventing edges) in the fusion
Reference: [KM93a] <author> K. Kennedy and K. S. McKinley. </author> <title> Maximizing loop parallelism and improving data locality via loop fusion and distribution. </title> <booktitle> In Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: This problem arises in practical situations like in an optimizing compiler which restructures the program to generate efficient code for a parallel architecture. The general fusion problem has already been known to be NP-hard <ref> [KM93a] </ref>. Here we present an optimal solution in the restricted case when data dependences among loops form a tree. This solution is obtained by dynamic programming which runs in linear time with respect to the number of loops and square in number of registers available. <p> arises because if these two loops were to be fused, the dependence direction of T OT (I; J ) would be reversed and the program meaning would be changed. 6 Algorithm To set up the fusion problem, we first perform maximal distribution on the loops of the program as in <ref> [KM93a] </ref>. Maximal distribution means that the maximum number of loops are created but all statements within a recurrence relation remain in the same loop. Thus any dependence cycle is wholly contained within a loop. <p> Any optimal solution must satisfy all of the above constraints and must have the minimum weight on edges having two endpoints in different partitions. This problem is NP-complete <ref> [KM93a] </ref>. <p> Kennedy and McKinley proved that fusion for optimal reuse is NP-hard <ref> [KM93a] </ref>. In his thesis, Callahan proved that loop fusion to minimize the number of loops is NP-hard when we are allowed to permute the loop nests [Cal87]. <p> The problem is compounded by the fact that there are several loop transformations which interact with loop fusion and loop fusion itself can have several objectives like maximizing reuse, maximizing parallelism and not exceeding number of available registers within a fused loop. Previous fusion approaches <ref> [KM93a, KM93b, GOST92] </ref> have considered the fusion problem in isolation. Kennedy and McKinley considered the two objectives of maximizing parallelism and in creasing data locality separately which may not give 5.8 optimal results [KM93b]. Also, they restricted their attention to fusing only adjacent loops.
Reference: [KM93b] <author> K. Kennedy and K.S. McKinley. </author> <title> Typed fusion with applications to parallel and sequential code generation. </title> <type> Technical Report TR93-208, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: The problem is compounded by the fact that there are several loop transformations which interact with loop fusion and loop fusion itself can have several objectives like maximizing reuse, maximizing parallelism and not exceeding number of available registers within a fused loop. Previous fusion approaches <ref> [KM93a, KM93b, GOST92] </ref> have considered the fusion problem in isolation. Kennedy and McKinley considered the two objectives of maximizing parallelism and in creasing data locality separately which may not give 5.8 optimal results [KM93b]. Also, they restricted their attention to fusing only adjacent loops. <p> Previous fusion approaches [KM93a, KM93b, GOST92] have considered the fusion problem in isolation. Kennedy and McKinley considered the two objectives of maximizing parallelism and in creasing data locality separately which may not give 5.8 optimal results <ref> [KM93b] </ref>. Also, they restricted their attention to fusing only adjacent loops. In many practical situations, two loops differ by only a small number of iterations. Loop peeling by an appropriate amount could make these two loops conformable and candidates for fusion.
Reference: [Kuc78] <author> D. Kuck. </author> <title> The Structure of Computers and Computations, Volume 1. </title> <publisher> John Wi-ley and Sons, </publisher> <address> New York, NY, </address> <year> 1978. </year>
Reference-contexts: A dependence exists between two statements in a program if there exists a control-flow path from the first statement to the second and both statements reference the same memory location <ref> [Kuc78] </ref>.
Reference: [Luk74] <author> J. A. Lukes. </author> <title> Efficient algorithm for the partitioning of trees. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 18:217224, </volume> <year> 1974. </year>
Reference-contexts: Here we develop a solution to a restricted version, in which the dependence edges (input, true and anti) form a tree in the fusion graph and all fusion preventing dependences are forward edges in the fusion graph. 6.1 Partitioning of Trees Lukes gives an optimal algorithm for partitioning of trees <ref> [Luk74] </ref>. <p> Node weights are not shown but each node weight is one. We do not show the dynamic programming table for lack of space here. The final partitions are shown in Figure 4. 6.4 Optimality and Complexity The optimality proof from <ref> [Luk74] </ref> applies as we always form connected partitions as we traverse the tree bottom-up. The complexity of simple tree partitioning is linear in number of nodes in the graph.
Reference: [MA95] <author> N. Manjikian and T. Abdelrahman. </author> <title> Fusion of loops for parallelism and locality. </title> <booktitle> In Proceedings of the 24th International Conference on Parallel Processing, pages II:1928, </booktitle> <address> Oconomowoc, WI, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Also, they do not try to optimize both for uniprocessors and multiprocessors. Manjikian and Abdelrahman consider fusion for parallelism and locality but not together <ref> [MA95] </ref>. Moreover, they do not get optimal solution. 9 Future Work Our fusion alogorithm can be extended to handle general problem of reordering statements within a program for various optimizations. Instruction scheduling is an important example.
Reference: [Sar89] <author> V. Sarkar. </author> <title> Partition and Scheduling Parallel Programs for Multiprocessors. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference-contexts: A heuristic for clustering has been successfully used by Sih and Lee for multiprocessor scheduling [SL93]. The internalization approach, proposed by Sarkar clusters nodes together to minimize the schedule length on an unbounded number of processors <ref> [Sar89] </ref>. The algorithm initially places each task in a separate cluster and considers the arcs in descending order according to the amount of data transferred over each arc.
Reference: [SL93] <author> G.C. Sih and E.A. Lee. </author> <title> Declustering: A new multiprocessor scheduling technique. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(6):625637, </volume> <month> June </month> <year> 1993. </year>
Reference-contexts: The edge weights denote the closeness of one node to another. The problem is to break the graph into clusters so that the nodes with higher closeness are grouped together in the same cluster. A heuristic for clustering has been successfully used by Sih and Lee for multiprocessor scheduling <ref> [SL93] </ref>. The internalization approach, proposed by Sarkar clusters nodes together to minimize the schedule length on an unbounded number of processors [Sar89]. The algorithm initially places each task in a separate cluster and considers the arcs in descending order according to the amount of data transferred over each arc.
Reference: [Wol89] <author> M. J. Wolfe. </author> <title> Optimizing Supercompil-ers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year> <month> 5.11 </month>
Reference-contexts: Fusion is illegal when a loop-independent dependence becomes a backward loop-carried dependence after fusion. Such dependences are called fusionpreventing dependences [AS79]. A simple test for this case is dependence testing on the two loop bodies as if they were in a single loop <ref> [Wol89] </ref>.
References-found: 13

