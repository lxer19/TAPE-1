URL: http://www.geo.fmi.fi/~jtammine/ampure.ps.gz
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: An Adaptive Metropolis algorithm  
Author: Heikki Haario, Eero Saksman and Johanna Tamminen 
Keyword: Monte Carlo, Metropolis-Hastings algorithm  
Abstract: A proper choice of a proposal distribution for MCMC methods, e.g. for the Metropolis-Hastings algorithm, is well known to be a crucial factor for the convergence of the algorithm. In this paper we introduce an adaptive Metropolis Algorithm (AM), where the Gaussian proposal distribution is updated along the process using the full information cumulated so far. Due to the adaptive nature of the process, the AM algorithm is non-Markovian, but we establish here that it has the correct ergodic properties. We also include the results of our numerical tests, which indicate that the AM algorithm competes well with traditional Metropolis-Hastings algorithms, and demonstrate that AM provides an easy to use algorithm for practical computation. 1991 Mathematics Subject Classification: 65C05, 65U05. Keywords: adaptive MCMC, comparison, convergence, ergodicity, Markov Chain 
Abstract-found: 1
Intro-found: 1
Reference: [Davidson and Jong 1997] <author> J. Davidson and R. de Jong: </author> <title> Strong laws of large numbers for dependent heterogeneous processes: a synthesis of recent and new results, </title> <journal> Econometric Rev. </journal> <volume> 16 (1997), </volume> <pages> 251-279. </pages>
Reference-contexts: Remark 6 We refer to the original article [McLeish 1975] or to the recent review article <ref> [Davidson and Jong 1997] </ref> for basic properties of mixingales.
Reference: [Dobrushin 1956] <author> R. Dobrushin: </author> <title> Central limit theorems for non-stationary Markov chains II, </title> <journal> Theory Prob. Appl. </journal> <volume> 1 (1956), </volume> <pages> 329-383. </pages>
Reference-contexts: In order to be able to proceed we give some definitions. Recall first the definition of the coefficient of ergodicity <ref> [Dobrushin 1956] </ref>.
Reference: [Evans 1991] <author> M. Evans: </author> <title> Chaining via annealing, Ann. </title> <booktitle> Statistics 19 (1991), </booktitle> <pages> 382-393. </pages>
Reference-contexts: For other versions of adaptive MCMC and related work we refer to e.g. <ref> [Evans 1991] </ref>, [Fishman 1996] [Gelfand and Sahu 1994], and [Marinari and Parisi 1992] together with the references therein. We introduce here an adaptive Metropolis algorithm (AM), which adapts continuously to the target distribution. What is important, the adaptation affects both the size and the spatial orientation of the proposal distribution.
Reference: [Fishman 1996] <author> G. S. Fishman: </author> <title> Monte Carlo. Concepts, algorithms and applications. </title> <publisher> Springer (1996). </publisher> <pages> 15 </pages>
Reference-contexts: For other versions of adaptive MCMC and related work we refer to e.g. [Evans 1991], <ref> [Fishman 1996] </ref> [Gelfand and Sahu 1994], and [Marinari and Parisi 1992] together with the references therein. We introduce here an adaptive Metropolis algorithm (AM), which adapts continuously to the target distribution. What is important, the adaptation affects both the size and the spatial orientation of the proposal distribution.
Reference: [Gelfand and Sahu 1994] <author> A. E. Gelfand and S. K. Sahu: </author> <title> On Markov chain Monte Carlo acceleration, </title> <journal> J. Computational and Graphical Stat. </journal> <volume> 3 (1994), </volume> <pages> 261-276. </pages>
Reference-contexts: For other versions of adaptive MCMC and related work we refer to e.g. [Evans 1991], [Fishman 1996] <ref> [Gelfand and Sahu 1994] </ref>, and [Marinari and Parisi 1992] together with the references therein. We introduce here an adaptive Metropolis algorithm (AM), which adapts continuously to the target distribution. What is important, the adaptation affects both the size and the spatial orientation of the proposal distribution.
Reference: [Gelman et al. 1996] <author> A. G. Gelman, G. O. Roberts and W. R. Gilks: </author> <title> Efficient Metropolis jumping rules, Bayesian Statistics V pp. </title> <editor> 599-608 (eds J.M. Bernardo, J.O. Berger, A.F. David and A.F.M. Smith). </editor> <publisher> Oxford University press, </publisher> <year> 1996. </year>
Reference-contexts: This concerns both the size and the spatial orientation of the proposal distribution, which are often very difficult to choose well since the target density is unknown (see e.g. <ref> [Gelman et al. 1996] </ref>, [Gilks et al. 1995], [Gilks et al. 1998],[Haario et al. 1998], and [Roberts et al. 1994]). A possible remedy is provided by adaptive algorithms, which use the history of the process in order to 'tune' the proposal distribution suitably. <p> The role of the parameter " is just to ensure that C t will not become singular (see Remark 1 below). As a basic choice for the scaling parameter we have adopted the value s d = (2:4) 2 =d from <ref> [Gelman et al. 1996] </ref>, where it was shown that in a certain sense this choice optimizes the mixing properties of the Metropolis search in the case of Gaussian targets and Gaussian proposals. Remark 1 In our test runs the covariance C t has not had the tendency to degenerate. <p> We have tried to be fair in choosing the proposal distributions for the random walk Metropolis and the single component Metropolis algorithms. For example, in the case of the Gaussian target distributions we used covariances corresponding to the targets and normalized them with the heuristic optimal scaling from <ref> [Gelman et al. 1996] </ref>. In Figure 1 the test results in dimension 8 are summarized in a graphical form. In the top picture we present the mean and the error bars given by the standard deviations for the 68.3% confidence region.
Reference: [Gilks et al. 1994] <author> W. R. Gilks, G.O. Roberts, E.I. George: </author> <title> Adaptive direction sampling, </title> <journal> The Statistician, </journal> <volume> 43, </volume> <pages> 179-189. </pages>
Reference: [Gilks et al. 1995] <author> W. R. Gilks, S. Richardson, and D. J. Spiegelhalter: </author> <title> Introducing markov chain Monte Carlo. pp. 1-19. In Markov Chain Monte Carlo in practice. </title> <editor> (eds W.R. Gilks, S. Richardson and D.J. Spiegelhalter). </editor> <publisher> Chapman & Hall, </publisher> <year> 1995. </year>
Reference-contexts: This concerns both the size and the spatial orientation of the proposal distribution, which are often very difficult to choose well since the target density is unknown (see e.g. [Gelman et al. 1996], <ref> [Gilks et al. 1995] </ref>, [Gilks et al. 1998],[Haario et al. 1998], and [Roberts et al. 1994]). A possible remedy is provided by adaptive algorithms, which use the history of the process in order to 'tune' the proposal distribution suitably.
Reference: [Gilks and Roberts 1995] <author> W.R. Gilks and G. O. Roberts: </author> <title> Strategies for improving MCMC, pp. 75-88. In Markov Chain Monte Carlo in practice. </title> <editor> (eds W.R. Gilks, S. Richardson and D.J. Spiegelhalter). </editor> <publisher> Chapman & Hall, </publisher> <year> 1995. </year>
Reference: [Gilks et al. 1998] <author> W. R. Gilks, G.O. Roberts and S.K. Sahu: </author> <title> Adaptive Markov Chain Monte Carlo, </title> <journal> J. Amer. Statist. Assoc. </journal> <note> (to appear). </note>
Reference-contexts: This concerns both the size and the spatial orientation of the proposal distribution, which are often very difficult to choose well since the target density is unknown (see e.g. [Gelman et al. 1996], [Gilks et al. 1995], <ref> [Gilks et al. 1998] </ref>,[Haario et al. 1998], and [Roberts et al. 1994]). A possible remedy is provided by adaptive algorithms, which use the history of the process in order to 'tune' the proposal distribution suitably. <p> This has previously been done (for instance) by assuming that the state space contains an atom. The adaptation is performed only at the recurrence times to the atom in order to preserve the right ergodic properties <ref> [Gilks et al. 1998] </ref>. The adaptation criteria are then obtained by monitoring the acceptance rate.
Reference: [Haario and Saksman 1991] <author> H. Haario and E. Saksman: </author> <title> Simulated annealing process in general state space, </title> <journal> Adv. Appl. Prob. </journal> <volume> 23 (1991), </volume> <pages> 866-893. </pages>
Reference-contexts: T C 1 x): (6) The Gaussian proposal transition probability corresponding to the covariance C satisfies Q C (x; A) = A where A IR d is a Borel set and dy is the standard Lebesgue measure on IR d : It follows that Q C is m-symmetric (see e.g. <ref> [Haario and Saksman 1991, Definition 2.2] </ref>). <p> Naturally, here one has to make the necessary assumption that the set fx : (x) &gt; 0g does not contain components that are too much separated. In this connection the estimates provided by <ref> [Haario and Saksman 1991, Theorem 6.5.(b)] </ref> are relevant.
Reference: [Haario et al. 1998] <author> H. Haario, E. Saksman and J. Tamminen: </author> <title> Adaptive proposal distribution for random walk Metropolis algorithm, </title> <institution> Reports of the Department of Mathematics, University of Helsinki. </institution> <note> Preprint 176 (1998). </note>
Reference-contexts: Moreover, the new algorithm is straightforward to implement and use in practice. The definition of the AM algorithm is based on the classical random walk Metropolis algorithm [Metropolis et al. 1953] and its modification, the AP algorithm (introduced in <ref> [Haario et al. 1998] </ref>). In the AP algorithm the proposal distribution is a Gaussian distribution centered at the current state, and the covariance is calculated from a fixed finite number of the previous states. <p> A more detailed description of the algorithm is given in section 2 below. One of the difficulties in constructing adaptive MCMC algorithms is to ensure that the algorithm maintains the correct ergodicity properties. We observe here (see also <ref> [Haario et al. 1998] </ref>) that the AP algorithm fails this property. Our main result, Theorem 1 below, verifies that the AM process indeed has the correct ergodicity properties. <p> From the practical point of view, it is important to know how accurate simulations of the target distribution one can expect to get from finite MCMC runs. In <ref> [Haario et al. 1998] </ref> we compared three different methods: random walk Metropolis algorithm (M), single component Metropolis algorithm (SC), and the adaptive proposal algorithm (AP) (see the introduction or [Haario et al. 1998] for the exact definition and more detailes). <p> In <ref> [Haario et al. 1998] </ref> we compared three different methods: random walk Metropolis algorithm (M), single component Metropolis algorithm (SC), and the adaptive proposal algorithm (AP) (see the introduction or [Haario et al. 1998] for the exact definition and more detailes). Recall again that the difference between AP and AM algorithms was simply that in AP the covariance for the proposal distribution was computed only from a fixed number of previous states. <p> <ref> [Haario et al. 1998] </ref> for the exact definition and more detailes). Recall again that the difference between AP and AM algorithms was simply that in AP the covariance for the proposal distribution was computed only from a fixed number of previous states. Here we have made similar tests as in [Haario et al. 1998] and included the AM algorithm in the comparison. We have applied the AM algorithm succesfully in various dimensions up to d = 200. Here we present the results of extensive tests in dimension d = 8. <p> The burn in period was chosen to be half of the chain length. Each test case was run 100 times in order to retrieve statistically relevant information. Hence, each accuracy criterion number is an average value over 100 repetitions. We refer to <ref> [Haario et al. 1998] </ref> for a more detailed explanation of the test procedure. We have tried to be fair in choosing the proposal distributions for the random walk Metropolis and the single component Metropolis algorithms.
Reference: [Hall and Heyde 1980] <author> P. Hall and C.C. Heyde: </author> <title> Martingale limit theory and its application. </title> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: for k k 1 ( 0 ): At this stage the estimate (26) for the asymptotic independence together with the definition of the sigma-algebra F n make it clear that f (X n ) R S f (y)(dy) is a mixingale in the sense of McLeish (see [McLeish 1975] or <ref> [Hall and Heyde 1980, p. 19] </ref>). <p> Moreover, (k) C (")k "1 for every " &gt; 0: Hence we may apply directly the well-known laws of large numbers for mixingales in the form of <ref> [Hall and Heyde 1980, Theorem 2.21, p. 41] </ref> to the sequence f (X n ) in order to obtain the desired conclusion. Remark 6 We refer to the original article [McLeish 1975] or to the recent review article [Davidson and Jong 1997] for basic properties of mixingales.
Reference: [Hastings 1970] <author> W. K. Hastings: </author> <title> Monte Carlo sampling methods using Markov chains and their applications, </title> <booktitle> Biometrica 57 (1970), </booktitle> <pages> 97-109. </pages>
Reference: [Marinari and Parisi 1992] <author> E. Marinari and G. Parisi: </author> <title> Simulated tempering: a new Monte Carlo Scheme, </title> <journal> Europhys. Lett. </journal> <volume> 19 (1992), </volume> <pages> 451-458. </pages>
Reference-contexts: For other versions of adaptive MCMC and related work we refer to e.g. [Evans 1991], [Fishman 1996] [Gelfand and Sahu 1994], and <ref> [Marinari and Parisi 1992] </ref> together with the references therein. We introduce here an adaptive Metropolis algorithm (AM), which adapts continuously to the target distribution. What is important, the adaptation affects both the size and the spatial orientation of the proposal distribution.
Reference: [McLeish 1975] <author> D. L. McLeish: </author> <title> A maximal inequality and dependent strong laws, </title> <journal> Ann. Prob. </journal> <volume> 3 (1975), </volume> <pages> 829-839. </pages>
Reference-contexts: this paper we have left open the question whether the convergence of the algorithm (as established in Theorem 1) satisfies a central limit theorem. 4 Proof of Theorem 2 In this section we will prove Theorem 2 by showing that a related process is a mixingale (in the sense of <ref> [McLeish 1975] </ref>) that satisfies an appropriate law of large numbers. The conditions of the theorem were tailored to apply to the AM chain on bounded subsets of IR n , but they are stated in the language of a general state space. <p> (1= 0 ) for k k 1 ( 0 ): At this stage the estimate (26) for the asymptotic independence together with the definition of the sigma-algebra F n make it clear that f (X n ) R S f (y)(dy) is a mixingale in the sense of McLeish (see <ref> [McLeish 1975] </ref> or [Hall and Heyde 1980, p. 19]). <p> Remark 6 We refer to the original article <ref> [McLeish 1975] </ref> or to the recent review article [Davidson and Jong 1997] for basic properties of mixingales.
Reference: [Metropolis et al. 1953] <author> N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and E. Teller: </author> <title> Equations of state calculations by fast computing machines, </title> <journal> J. Chem. Phys. </journal> <volume> 21 (1953), </volume> <pages> 1087-1091. </pages>
Reference-contexts: What is important, the adaptation affects both the size and the spatial orientation of the proposal distribution. Moreover, the new algorithm is straightforward to implement and use in practice. The definition of the AM algorithm is based on the classical random walk Metropolis algorithm <ref> [Metropolis et al. 1953] </ref> and its modification, the AP algorithm (introduced in [Haario et al. 1998]). In the AP algorithm the proposal distribution is a Gaussian distribution centered at the current state, and the covariance is calculated from a fixed finite number of the previous states.
Reference: [Neveu 1965] <author> J. Neveu: </author> <title> Mathematical foundations of the calculus of probability. </title> <booktitle> Holden-Day 1965. </booktitle> <pages> 16 </pages>
Reference-contexts: Proposition V.1.1 of <ref> [Neveu 1965] </ref>) yields the existence of the chain (X n ) on S satisfying (4). We shall now turn to the exact definition of the AM chain as a discrete time stochastic process.
Reference: [Nummelin 1984] <author> E. Nummelin: </author> <title> General irreducible Markov chains and non-negative operators. </title> <publisher> Cambridge University Press, </publisher> <year> 1984. </year>
Reference-contexts: From the definition it easily follows that ffi (T 1 T 2 :::T n ) i=1 The condition ffi (T k 0 ) &lt; 1 for some k 0 1 is well known to be equivalent to the uniform ergodicity (compare <ref> [Nummelin 1984, Section 6.6.] </ref>) of the Markov chain having the transition probability T: For our purposes it is useful to define the transition probability that is obtained from a generalized transition probability by 'freezing' the n 1 first variables. <p> This easily yields (compare e.g. <ref> [Nummelin 1984, pp. 122-123] </ref>) that ffi (K n;ey n2 ) 1 c 3 , which proves (i) with k 0 = 1: We next verify condition (iii).
Reference: [Roberts et al. 1994] <author> G. O. Roberts, A. Gelman and W. R. Gilks: </author> <title> Weak convergence and optimal scaling of random walk metropolis algorithms. </title> <type> Preprint. </type> <note> (http://www.stats.bris.ac.uk/MCMC/) </note>
Reference-contexts: This concerns both the size and the spatial orientation of the proposal distribution, which are often very difficult to choose well since the target density is unknown (see e.g. [Gelman et al. 1996], [Gilks et al. 1995], [Gilks et al. 1998],[Haario et al. 1998], and <ref> [Roberts et al. 1994] </ref>). A possible remedy is provided by adaptive algorithms, which use the history of the process in order to 'tune' the proposal distribution suitably. This has previously been done (for instance) by assuming that the state space contains an atom.
Reference: [Sahu and Zhigljavsky 1998a] <author> S. K. Sahu and A. A. Zhigljavsky: </author> <title> Self regenerative Markov chain Monte Carlo. </title> <type> Preprint. </type> <note> (http://www.stats.bris.ac.uk/MCMC/) </note>
Reference-contexts: The adaptation criteria are then obtained by monitoring the acceptance rate. A related interesting self regenerative version of adaptive MCMC, based on introducing an auxiliary chain, is contained in the fl Supported by the Academy of Finland, Project 32837 1 recent preprints <ref> [Sahu and Zhigljavsky 1998a] </ref> and [Sahu and Zhigljavsky 1998b]. For other versions of adaptive MCMC and related work we refer to e.g. [Evans 1991], [Fishman 1996] [Gelfand and Sahu 1994], and [Marinari and Parisi 1992] together with the references therein.
Reference: [Sahu and Zhigljavsky 1998b] <author> S. K. Sahu and A. A. Zhigljavsky: </author> <title> Adaption for self regenerative MCMC, </title> <type> Preprint. </type> <note> (http://www.stats.bris.ac.uk/MCMC/) </note>
Reference-contexts: The adaptation criteria are then obtained by monitoring the acceptance rate. A related interesting self regenerative version of adaptive MCMC, based on introducing an auxiliary chain, is contained in the fl Supported by the Academy of Finland, Project 32837 1 recent preprints [Sahu and Zhigljavsky 1998a] and <ref> [Sahu and Zhigljavsky 1998b] </ref>. For other versions of adaptive MCMC and related work we refer to e.g. [Evans 1991], [Fishman 1996] [Gelfand and Sahu 1994], and [Marinari and Parisi 1992] together with the references therein. We introduce here an adaptive Metropolis algorithm (AM), which adapts continuously to the target distribution.
Reference: [Tierney 1994] <author> L. Tierney: </author> <title> Markov chains for exploring posterior distributions, with discussion, </title> <journal> Ann. Statistics (1994), </journal> <pages> 1701-1762. </pages>
Reference-contexts: c 5 =n; where c 5 does not depend on y 2 S: We may hence estimate as before that kK n;ey n2 M C fl k M (S)!M (S) n Since M C fl is a Metropolis transition probability we have that M C fl = ; see e.g. <ref> [Tierney 1994, p. 1705] </ref>), and we obtain k K n;ey n2 k = k (M C fl K n;ey n2 )k n which completes the proof of Theorem 1. Let us record an expected result on the behaviour of the AM chain.
References-found: 23

