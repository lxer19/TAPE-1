URL: http://www.cs.toronto.edu/~parodi/ICPR-1996.ps.gz
Refering-URL: http://www.cs.toronto.edu/~parodi/abstract_icpr96.html
Root-URL: 
Title: An efficient pre-processing of mixed-content document images for OCR systems  
Author: Pietro Parodi Giulia Piccioli 
Address: 6 King's College Rd, Room 265 C Via Dodecaneso 33 Toronto (ON), Canada M5S 3H5 Genova, Italy 16146  
Affiliation: Department of Computer Science Dipartimento di Fisica University of Toronto University of Genova  
Abstract: An efficient, novel technique for segmenting document pages of mixed content into text and non-text regions is herein presented. The aim of the technique is to provide a pre-processing for an OCR system, so that large amounts of documents of unknown layout can be examined and the written content of such documents can be put into digital format without human intervention. The user fixes two parameters, the minimum width w of the text to be detected, and the precision * needed (both expressed as a percentage of the image width), according to the implementation needs (default values that yield good results for widely varying kinds of documents are * = 2%, w = 4*). The method works by detecting pieces of text lines in small overlapping columns of width w 2*, shifted with respect to each other by * and by merging such pieces in a bottom-up fashion to form complete text lines and blocks of text lines. The algorithm is very fast and is able to work on low-resolution document pages. The algorithm is also very flexible, no assumptions being made on the layout of the document, the shape of the text regions, and the font size and style; the main assumptions are that the background is uniform and the text is horizontal (apart from the skew, which can be up to about 6-7 degrees). Experimental results are shown which demonstrate the effectiveness of the method on several different kinds of documents. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L.A. Fletcher and R. Kasturi. </author> <title> A robust algorithm for text string separation from mixed text/graphics images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 10(6) </volume> <pages> 910-918, </pages> <year> 1988. </year>
Reference-contexts: The techniques developed for this purpose are commonly subdivided into top-down, bottom-up and hybrid techniques. Bottom-up techniques <ref> [1] </ref> progressively merge evidence at increasing scales to form, e.g., words from characters, lines from words, columns from text lines.
Reference: [2] <author> D. Wang and S.N. Srihari. </author> <title> Classification of newspaper image blocks using texture analysis. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 47 </volume> <pages> 327-352, </pages> <year> 1989. </year>
Reference-contexts: They do not usually make assumptions on font style and size, and about page layout, but they usually rely on the use of a number of appropriate thresholds and may suffer from the accumulation of mistakes from the lowest detail up. Top-down techniques <ref> [2, 3, 4] </ref> use a priori assumptions about the layout of the page in order to segment it.
Reference: [3] <author> F.M. Wahl, K.Y. Wong, and R.G. Casey. </author> <title> Block segmentation and text extraction in mixed text/image documents. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 20 </volume> <pages> 375-390, </pages> <year> 1982. </year>
Reference-contexts: They do not usually make assumptions on font style and size, and about page layout, but they usually rely on the use of a number of appropriate thresholds and may suffer from the accumulation of mistakes from the lowest detail up. Top-down techniques <ref> [2, 3, 4] </ref> use a priori assumptions about the layout of the page in order to segment it.
Reference: [4] <author> G. Nagy and S.C.Seth. </author> <title> Hierarchical representation of optical scanned documents. </title> <booktitle> In Proceedings of the International Conference on Pattern Recognition, </booktitle> <pages> pages 347-349. </pages> <publisher> IEEE, </publisher> <address> Montreal, Canada, </address> <year> 1984. </year>
Reference-contexts: They do not usually make assumptions on font style and size, and about page layout, but they usually rely on the use of a number of appropriate thresholds and may suffer from the accumulation of mistakes from the lowest detail up. Top-down techniques <ref> [2, 3, 4] </ref> use a priori assumptions about the layout of the page in order to segment it.
Reference: [5] <author> H. S. Baird, S. E. Jones, and S. J. Fortune. </author> <title> Image segmentation by shape-directed covers. </title> <booktitle> In Proceedings of the International Conference on Pattern Recognition, </booktitle> <pages> pages 820-825, </pages> <year> 1990. </year>
Reference-contexts: Most methods do not really fit into any of the two categories above and they have therefore been called hybrid. It is impossible to give an overview of these methods here, so we will only cite three works based on background analysis <ref> [5, 6, 7] </ref> and two very general methods for segmentation based on texture analysis [8, 9]. Despite the many efforts spent on the subject, document segmentation cannot be considered as a completely solved problem. Fast segmentation methods are needed which do not rely on heavy prior assumptions about the document.
Reference: [6] <author> T. Pavlidis and J. Zhou. </author> <title> Page segmentation by white streams. </title> <booktitle> In Proceedings of the International Conference on Document Analysis and Recognition, </booktitle> <pages> pages 945-953, </pages> <year> 1991. </year>
Reference-contexts: Most methods do not really fit into any of the two categories above and they have therefore been called hybrid. It is impossible to give an overview of these methods here, so we will only cite three works based on background analysis <ref> [5, 6, 7] </ref> and two very general methods for segmentation based on texture analysis [8, 9]. Despite the many efforts spent on the subject, document segmentation cannot be considered as a completely solved problem. Fast segmentation methods are needed which do not rely on heavy prior assumptions about the document.
Reference: [7] <author> A. Antonacopoulos and R. T. Ritchings. </author> <title> Flexible page segmentation using the background. </title> <booktitle> In Proceedings of the International Conference on Pattern Recognition. IEEE, </booktitle> <address> Jerusalem, Israel, </address> <year> 1994. </year>
Reference-contexts: Most methods do not really fit into any of the two categories above and they have therefore been called hybrid. It is impossible to give an overview of these methods here, so we will only cite three works based on background analysis <ref> [5, 6, 7] </ref> and two very general methods for segmentation based on texture analysis [8, 9]. Despite the many efforts spent on the subject, document segmentation cannot be considered as a completely solved problem. Fast segmentation methods are needed which do not rely on heavy prior assumptions about the document.
Reference: [8] <author> A.K. Jain and S. Bhattacharjee. </author> <title> Text segmentation using Gabor filters for automatic document processing. </title> <journal> Machine Vision and Applications, </journal> <volume> 5 </volume> <pages> 169-184, </pages> <year> 1992. </year>
Reference-contexts: It is impossible to give an overview of these methods here, so we will only cite three works based on background analysis [5, 6, 7] and two very general methods for segmentation based on texture analysis <ref> [8, 9] </ref>. Despite the many efforts spent on the subject, document segmentation cannot be considered as a completely solved problem. Fast segmentation methods are needed which do not rely on heavy prior assumptions about the document.
Reference: [9] <author> K.Etemad, R. Chellappa, and D. Doermann. </author> <title> Document page segmentation by integrating distributed soft decisions. </title> <booktitle> In Proceedings of the International Conference on Neural Networks, </booktitle> <pages> pages 4022 - 4027, </pages> <year> 1994. </year>
Reference-contexts: It is impossible to give an overview of these methods here, so we will only cite three works based on background analysis [5, 6, 7] and two very general methods for segmentation based on texture analysis <ref> [8, 9] </ref>. Despite the many efforts spent on the subject, document segmentation cannot be considered as a completely solved problem. Fast segmentation methods are needed which do not rely on heavy prior assumptions about the document.
Reference: [10] <author> P. Parodi and G. Piccioli. </author> <title> A fast and flexible statistical method for text extraction in document pages. </title> <booktitle> In Proceedings of Computer Vision and Pattern Recognition, </booktitle> <year> 1996. </year>
Reference-contexts: i and j if-f 1 The model of computation adopted here is the common PRAM: parallel random access machine with shared memory, with exclusive-read, exclusive-write access priority. 2 Here we skip over the matter of white space extraction inside the line elements; some details on this can be found in <ref> [10] </ref>. (i) i and j have comparable font size: a rather conservative criterion that can be used is to require that the ratio between the height of the two line pieces belongs to the range 3 (1=2; 2). <p> An alternative approach, in which a histogram-based classification of font sizes is performed, is described in <ref> [10] </ref>; (ii) i and j belong to adjacent, successive columns (such condition can be relaxed); (iii) i and j partially overlap. Observe that such a graph must be of degree at most two. <p> Depending on the application, it may be useful to group related text lines into blocks. A description of this feature, which is provided for in the system, can be found in <ref> [10] </ref>. Output. The output is a set of text lines (or of blocks of related text lines) which are given as an input to the OCR system which will investigate the content of the single lines. the right, the text lines extracted. The skew is negligible.
References-found: 10

