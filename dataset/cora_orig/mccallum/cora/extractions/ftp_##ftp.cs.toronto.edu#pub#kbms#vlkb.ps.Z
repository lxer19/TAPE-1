URL: ftp://ftp.cs.toronto.edu/pub/kbms/vlkb.ps.Z
Refering-URL: ftp://ftp.cs.toronto.edu/pub/kbms/readme.html
Root-URL: http://www.cs.toronto.edu
Title: ADAPTING DATABASE IMPLEMENTATION TECHNIQUES TO MANAGE VERY LARGE KNOWLEDGE BASES  
Author: John Mylopoulos, Vinay K. Chaudhri, Dimitris Plexousakis and Thodoros Topaloglou 
Address: 6 King's College Road, Toronto, Canada M5S 1A4  
Affiliation: Department of Computer Science, University of Toronto  
Abstract: The management of very large knowledge bases presupposes efficient and robust implementation techniques, sophisticated user interfaces and tools to support knowledge acquisition, validation and evolution. This paper examines the problem of efficiently implementing a knowledge base management system by adopting database techniques. In particular, the paper describes algorithms for designing logical and physical storage schemes and for processing efficiently queries with respect to a given knowledge base. In addition, the paper offers an overview of a new concurrency control algorithm which exploits knowledge base structure to support efficient multiuser access. Finally, rule and constraint management is discussed and a comprehensive scheme for compiling and processing them is presented. Throughout, the paper sketches algorithms, presents some formally proven properties of these algorithms and discusses performance results. The research presented in this paper was conducted at the University of Toronto for a project titled "The Telos Knowledge Base Management System". 1 
Abstract-found: 1
Intro-found: 1
Reference: [Allen83] <author> J. Allen, </author> <title> "Maintaining Knowledge about Temporal Intervals", </title> <journal> Communications of the ACM, </journal> <volume> 26(11) </volume> <pages> 832-843, </pages> <year> 1983. </year>
Reference: [Bry88] <author> F. Bry, H. Decker and R. Manthey, </author> <title> "A Uniform Approach to Constraint Satisfaction and Constraint Satisfiability in Deductive Databases", </title> <booktitle> Proceedings of EDBT-88 , pages 488-505, </booktitle> <year> 1988. </year>
Reference-contexts: This section describes this KBMS component, focusing on extensions to existng techniques for rule and constraint management and enforcement. In particular, we describe a novel approach to the efficient enforcement of declarative temporal integrity constraints [Plexousakis93b] based on a compile-time simplification method initially proposed in <ref> [Bry88] </ref> and later adapted to an objectoriented setting in [Jeusfeld90]. Our approach extends this work by offering special treatment for temporal knowledge also by generalizing the compilation phase. In general, the problem of constraint enforcement in the presence of deductive rules, historical and belief time is decomposed in two phases. <p> The twofold presence of time in Telos (history/belief time) allows for the expression of constraints that can't be handled by other formalisms that support a single dimension of time, e.g. <ref> [Bry88] </ref>, [Hulsmann90].
Reference: [Bernst ein87] <author> P. Bernstein, V. Hadzilacos and N. Goodman, </author> <title> Concurrency Control and Recovery in Database Systems., </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference: [B e r t i n o 8 9 ] <author> E. Bertino and W. Kim, </author> <title> "Indexing Techniques for Queries on Nested Objects", </title> <journal> I E E E Transactions on Knowledge and Data Engineering, </journal> <volume> 1(2) </volume> <pages> 196-214, </pages> <year> 1989. </year>
Reference: [C h a u d h r i 9 2 ] <author> V. Chaudhri, V. Hadzilacos and J. Mylopoulos, </author> <title> "Concurrency Control for Knowledge Bases", </title> <booktitle> Proceedings 3rd International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <year> 1992. </year>
Reference: [ C h a u d h r i 9 4 ] <author> V. K. Chaudhri, </author> <title> "Tr a n s a c t i o n Synchronization in Knowledge Bases: Concepts, Realization and Quantitative Evaluation, </title> <type> PhD Thesis, </type> <institution> Universtiy of Toronto, Forthcoming. </institution>
Reference: [Copeland85] <author> G.P. Copeland and S.N. Khoshafian, </author> <title> "A Decomposition Storage Model", </title> <booktitle> Proceedings A C M SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 268-279, </pages> <year> 1985. </year>
Reference-contexts: In this paper we are mainly concerned about the second step. The controlled decomposition algorithm is based on the controlled decomposition model (hereafter CDM), a flexible combination of the nary (direct) storage model (or NSM) and the decomposition storage model (or DSM) <ref> [Copeland85] </ref>, [Valduriez86]. The NSM stores a complex object in one relation which includes one column for each complex object component or attribute. The DSM, on the other hand, defines one storage relation for each object component or attribute.
Reference: [Eswaran76] <author> K.P. Eswaran, J. N. Gray, R. A. Lorie and I. L. Traiger, </author> <title> "The Notions of Consistency and Predicate Locks in Database Systems", </title> <journal> Communications of the ACM , 19(9) </journal> <pages> 624-633, </pages> <year> 1976. </year>
Reference-contexts: Although several approaches have been proposed in the literature for achieving serializable concurrency control policies for databases, locking-based algorithms have been most successful for commercial systems. The best known locking algorithm, two phase locking (affectionately referred to as 2PL) <ref> [Eswaran76] </ref>, works along the following lines. Associated with each data item is a distinct "lock''. A transaction must acquire a lock on a data item before accessing it. While a transaction holds a lock on a data item no other transaction may access that item.
Reference: [G r a y 9 3 ] <author> J. N. Gray and A. Reuter, </author> <title> T r a n s a c t i o n Processing: Concepts and Techniques, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1993. </year>
Reference: [Guttman84] <author> A. Guttman, "R-Trees: </author> <title> A Dynamic Index Structure For Spatial Searching", </title> <booktitle> Proceedings , A C M SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 47-57, </pages> <year> 1984. </year>
Reference-contexts: As with the join index [Valduriez87], two copies of the TJI are stored (see figure 4): one clustered on source identifiers and one on destination ones, thereby making bidirectional access possible. Each copy of the TJI is implemented in terms of an R-tree-like data structure <ref> [Guttman84] </ref>. The reason for choosing a spatial data structure, such as R-trees, is that identifiers are not just points on a one dimensional value space, but line segments on a two-dimensional space where the time component specifies the lifetime of the relationship between the joined identifiers.
Reference: [ H u l s m a n n 9 0 ] <author> K. Hulsmann and G. Saake, </author> <title> "Representation of the Historical Information Necessary for Temporal Integrity Monitoring, </title> <booktitle> Proceedings EDBT-90, </booktitle> <pages> pages 378-392, </pages> <year> 1990. </year>
Reference: [Jeusfeld90] <author> M. Jeusfeld and E. Kruger, </author> <title> "Deductive Integrity Maintenance in an ObjectOriented Setting", </title> <note> Technical Report MIP-9013 , Universitat Passau , 1990 [Kim89]W. </note> <author> Kim, K.-C. Kim and A. Dale, </author> <title> "Indexing Techniques for ObjectOriented Databases", In Object-Oriented Concepts, </title> <note> Databases and Applications , ACM Press, </note> <year> 1989. </year>
Reference-contexts: In particular, we describe a novel approach to the efficient enforcement of declarative temporal integrity constraints [Plexousakis93b] based on a compile-time simplification method initially proposed in [Bry88] and later adapted to an objectoriented setting in <ref> [Jeusfeld90] </ref>. Our approach extends this work by offering special treatment for temporal knowledge also by generalizing the compilation phase. In general, the problem of constraint enforcement in the presence of deductive rules, historical and belief time is decomposed in two phases.
Reference: [Kim90] <author> W. Kim, J.F. Garza, N. Ballou and D. Woelk, </author> <title> "Architecture of the ORION Next-Generation Database System", </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 109-124, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: The modules linking the logical and the physical layer manage rules (both their compilation and evaluation), support concurrency control (through the transaction manager) and perform temporal and possibly other types of specialized reasoning. The proposed architecture is similar to that of the ORION objectoriented database system <ref> [Kim90] </ref>. The main difference is that the Telos KBMS supports inference mechanisms for deductive rules and integrity constraints as well as temporal knowledge, thereby increasing the complexity of the overall design. 4.
Reference: [Kuchenhoff91] <author> V. Kuchenhoff, </author> <title> "On the Efficient Computation of the Difference Between Consecutive Database States", </title> <booktitle> Proceedings Int. Conference on Deductive and ObjectOriented Databases , pages 478-502, </booktitle> <year> 1991. </year>
Reference: [Livny86] <author> M. Livny, </author> <title> "DeNeT User's Guide (Version 1.5)", </title> <type> Technical Report, </type> <institution> University of Wisconsin, </institution> <year> 1986. </year>
Reference-contexts: The proportion of the transactions in the first class is 73% with the remaining 27% in the second class. The DDG policy has been implemented in the DeNet simulation environment <ref> [Livny86] </ref>. This implementation has been used to measure the relative running costs of 2PL and DDG policies , which in turn, have been used in our simulation to reflect the overhead of using the DDG policy.
Reference: [Lockemann91] <author> P. Lockemann, H. Nagel and I. Walter, </author> <title> "Databases for Knowledge Bases: Empirical Study of a Knowledge Base Management System for a Semantic Network", </title> <journal> Data and Knowledge Engineering, </journal> <volume> 7(2) </volume> <pages> 115-154, </pages> <year> 1991. </year>
Reference: [Manthey90] <author> R. Manthey. </author> <title> "Satisfiability of Integrity Constraints: Reflections on a Neglected Problem", </title> <booktitle> Proceedings 2nd Int.Workshop on Foundations of Models and Languages for Data and Objects, </booktitle> <year> 1990. </year>
Reference: [Mylopoulos90] <author> J. Mylopoulos, A. Borgida, M. Jarke and M. Koubarakis, </author> <title> "Telos: Representing Knowledge about Information Systems", </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 8(4) </volume> <pages> 325-362, </pages> <year> 1990. </year>
Reference-contexts: Throughout, the paper sketches algorithms, presents some formally proven properties of these algorithms and discusses performance results, where available. A more detailed description of the proposed architecture can be found in [Mylopoulos93]. The KBMS prototype under design adopts the language Telos <ref> [Mylopoulos90] </ref>, an object-centered knowledge representation language supporting a number of structuring mechanisms, a declarative sublanguage for representing deductive rules and integrity constraints as well as facilities for representing and reasoning with temporal knowledge. <p> Finally, section 7 summarizes the results of this paper and points to directions for further research. 2. A BRIEF OVERVIEW OF TELOS Telos <ref> [Mylopoulos90] </ref> is an object-centered knowledge representation language offering structuring mechanisms analogous to those supported by semantic networks and semantic data models as well as an assertional sublanguage for the expression of deductive rules and integrity constraints.
Reference: [M y l o p o u l o s 9 2 ] <author> J. Mylopoulos, V. Chaudhri, D. Plexousakis and T. Topaloglou, </author> <title> "A Performance Oriented Approach to Knowledge Base Management", </title> <booktitle> Proceedings 1st International Conference on Information and Knowledge Management, </booktitle> <year> 1992. </year>
Reference: [M y l o p o u l o s 9 3 ] <author> J. Mylopoulos, V. Chaudhri, D. Plexousakis and T. Topaloglou, </author> <title> "The Design of a Prototype Knowledge Base Management System", </title> <month> forthcoming , </month> <year> 1993. </year>
Reference: [ M i l l e r 9 0 ] <author> S. Miller and L. Schubert, </author> <title> "Time Revisited", </title> <journal> Computational Intelligence, </journal> <volume> 6 </volume> <pages> 108-118, </pages> <year> 1990. </year>
Reference: [Neches91] <author> R. Neches, R. Fikes, T. Finin, T. Gruber, R. Patil, T. Senator and W. Swartout, </author> <title> "Enabling Technology for Knowledge Sharing", </title> <journal> AI Magazine, </journal> <volume> 12(3) </volume> <pages> 36-56, </pages> <year> 1991. </year>
Reference: [N i c o l a s8 2 ] <author> J.-M. Nicolas, </author> <title> "Logic for Improving Integrity Checking in Relational Databases, </title> <journal> A c t a Informatica, </journal> <volume> 18 </volume> <pages> 227-253, </pages> <year> 1982. </year>
Reference: [Papadimitriou86] <author> C. Papadimitriou, </author> <title> The Theory of Database Concurrency Control., </title> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1986. </year>
Reference-contexts: To avoid such situations, Database research has studied the notion of correctness of interleaved execution through the concept of serializability <ref> [Bernstein87, Papadimitriou86, Gray93] </ref>. Serializability requires that the interleaved execution of transactions should be equivalent to some serial execution of the same collection of transactions (in terms of the final state of the knowledge base and the values returned by each transaction).
Reference: [Plexousakis93a] <author> D. Plexousakis, </author> <title> "Semantical and Ontological Considerations in Telos: </title> <booktitle> a Language for Knowledge Representation ", Computational Intelligence, </booktitle> <volume> 9 (1), </volume> <pages> 41-72, </pages> <year> 1993. </year>
Reference-contexts: To support the representation of temporal knowledge, Telos adopts Allen's [Allen81] interval-based temporal representation framework. Telos has a well-defined semantics based on a possible-worlds model <ref> [Plexousakis93a] </ref>. An example knowledge base is shown in figure 1 in the form of a semantic network. Dashed lines represent generalization (is-a) relationships between generic entities (classes), shown in bold font, whereas solid lines represent binary relationships among entities (attributes).
Reference: [ P l e x o u s a k i s 9 3 b ] <author> D. Plexousakis, </author> <title> "Integrity Constraint and Rule Maintenance in Temporal Deductive Knowledge Bases", </title> <booktitle> Proceedings 19th International Conference on Very Large Data Bases, </booktitle> <pages> pp 146-155, </pages> <year> 1993 </year>
Reference: [Selinger79] <author> G. Selinger, M. Astrahan, D. Chamberlin, R. Lorie and T. Price, </author> <title> "Access Path Selection in a Relational Database Management System", </title> <booktitle> Proceedings ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 23-34, </pages> <year> 1979. </year>
Reference-contexts: The second phase is the physical query processing phase where optimization is accomplished in terms of bulk operations called access paths which are supported directly by the underlying storage model. The selection of optimal access paths is an intriguing problem referred to as access planning <ref> [Selinger79] </ref>. Before planning a query execution scenario by choosing among alternative access plans, the access planner needs to estimate the execution cost of specific access operations, such as the cost of accessing an index, the cost of scanning a relation, etc [Mylopoulos93]. <p> Selectivities of comparison operators and access costs have been reconsidered by taking into account parameters which depend on the distribution of data / knowledge over time. For instance, the selectivity of a selection operation such as employee.salary=50000 ON 92..94 will be the selectivity of the operation as in <ref> [Selinger79] </ref> (i.e., 1/cardinality (salary)) multiplied by the temporal selectivity factor . For the KBMS, this has been defined as: = [(query specified time) / (max length of temporal domain's history] * (temporal distribution factor).
Reference: [Silberschatz80] <author> A. Silberschatz and Z. M. Kedem, </author> <title> "Consistency in Hierarchical Database Systems", </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 27(1) </volume> <pages> 72-80, </pages> <year> 1980. </year>
Reference: [Topaloglou92] <author> T. Topaloglou, A. Illarramendi and L. </author> <title> Sbattella "Query Optimization for KBMSs: Temporal, Syntactic and Semantic Transformation", </title> <booktitle> Proceedings 8th Int. Conference on Data Engineering, pages 310--319, 1992. [Topaloglou93]T. Topaloglou, "Storage Management for Knowledge Bases", Proceedings 2nd International Conference on Information and Knowledge Management, 1993. </booktitle> <address> [Va ldur iez 86]P. </address> <note> Valduriez, </note> <author> S. Khoshafian and G. Copeland, </author> <title> "Implementation Techniques of Complex Objects", </title> <booktitle> Proceedings 12th International Conference on Very Large Data Bases, </booktitle> <pages> pages 101-109, </pages> <year> 1986. </year>
Reference-contexts: The query processing cycle of the proposed KBMS consists of two phases. The first phase is the semantic query optimization phase which involves generation of an equivalent query expression that can be processed more efficiently than the input query. This phase is discussed in detail in <ref> [Topaloglou92] </ref>. The second phase is the physical query processing phase where optimization is accomplished in terms of bulk operations called access paths which are supported directly by the underlying storage model. The selection of optimal access paths is an intriguing problem referred to as access planning [Selinger79].
Reference: [V al duri e z8 7] <author> P. Valduriez, </author> <title> "Join Indices", </title> <journal> A C M Transactions on Database Systems, </journal> <volume> 12(2) </volume> <pages> 218-246, </pages> <month> June </month> <year> 1987. </year>
Reference: [Yannakakis82a] <author> M. Yannakakis, </author> <title> "A Theory of Safe Locking Policies in Database Systems", </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 29(3) </volume> <pages> 718-740, </pages> <month> July </month> <year> 1982. </year>
Reference: [Yannakakis82b] <author> M. Yannakakis, </author> <title> "Freedom from Deadlock of Safe Locking Policies", </title> <journal> SIAM Journal of Computing, </journal> <volume> 11(2) </volume> <pages> 391-408, </pages> <month> May </month> <year> 1982. </year>
References-found: 32

