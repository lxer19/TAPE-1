URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-403.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: (intille j jdavis j bobick@media.mit.edu)  
Title: Real-Time Closed-World Tracking  
Author: Stephen S. Intille, James W. Davis and Aaron F. Bobick 
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: MIT Media Laboratory,  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 403 Shorter version in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR'97) November, 1996 Abstract A real-time tracking algorithm that uses contextual information is described. The method is capable of simultaneously tracking multiple, non-rigid objects when erratic movement and object collisions are common. A closed-world assumption is used to adaptively select and weight image features used for correspondence. Results of algorithm testing and the limitations of the method are discussed. The algorithm has been used to track children in an interactive, narrative playspace. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P.E. Allen and C.E. Thorpe. </author> <title> Some approaches to find ing birds in video imagery. </title> <type> Robotics Institute Technical Report 91-34, </type> <institution> Carnegie Mellon University, </institution> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: Consequently, we believe that low-resolution, non-rigid, multiple-object tracking in real-time domains like the KidsRoom requires using contextual information to change how different features are used for tracking based on contextual information. Allen's bird counting system <ref> [1] </ref> illustrates that recognizing two of the same type of objects (birds) or the same type of object in two different contexts (grounded and flying auklets) may require two entirely different vision methods.
Reference: [2] <author> A. Baumberg and D. Hogg. </author> <title> Learning flexible models from image sequences. </title> <booktitle> In Proc. European Conf. Comp. Vis., </booktitle> <volume> volume 1, </volume> <pages> pages 299-308, </pages> <address> Stockholm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: As we will discuss, we have found it is often difficult to separate the tracking from the boundary estimation problem. Therefore, some people-tracking methods that require accurate object boundary detection based on intensity <ref> [2] </ref> and optical flow [12] are difficult to apply in our tracking task.
Reference: [3] <author> A. Blake, R. Curwen, and A. Zisserman. </author> <title> Affine--invariant contour tracking with automatic control of spatiotemporal scale. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <pages> pages 66-75, </pages> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: The goal of this paper is to detail generic problems and solutions that are in any similarly complex tracking tasks. 2 Previous approaches Most real-time tracking systems that track non-rigid objects have been designed for scenes containing single, large objects such as a person [17], hand <ref> [3] </ref> or face [7] and have not been tested in domains where independent, multiple objects can interact. Adaptive correlation template tracking methods (e.g. energy-based deformable models [3]) typically assume each template varies slowly or smoothly, templates don't collide, and high-resolution support from the data is available. <p> approaches Most real-time tracking systems that track non-rigid objects have been designed for scenes containing single, large objects such as a person [17], hand <ref> [3] </ref> or face [7] and have not been tested in domains where independent, multiple objects can interact. Adaptive correlation template tracking methods (e.g. energy-based deformable models [3]) typically assume each template varies slowly or smoothly, templates don't collide, and high-resolution support from the data is available. As we will discuss, we have found it is often difficult to separate the tracking from the boundary estimation problem.
Reference: [4] <author> S.D. Blostein and T.S. Huang. </author> <title> Detecting small, moving objects in image sequences using sequential hypothesis testing. </title> <journal> IEEE Trans. Signal Proc., </journal> <volume> 39(7) </volume> <pages> 1611-1629, </pages> <year> 1991. </year>
Reference-contexts: Further the difficulty in segmenting colliding children and their rapid changes in appearance and motion prevents the use of differential motion estimators that use smooth or planar motion models <ref> [4] </ref> and tracking techniques that require reasonably stable edge computation [8]. Motion difference blob size and shape characteristics are sometimes used for tracking [15]; here we use background-differenced blobs.
Reference: [5] <author> A. Bobick, J. Davis, S. Intille, F. Baird, L. Cambell, Y. Ivanov, C. Pinhanez, A. Schutte, and A. Wilson. </author> <title> The KidsRoom: Action recognition in an interactive story environment. MIT Media Lab Perceptual Computing Group Technical Report No. 398, </title> <publisher> MIT, </publisher> <month> Dec. </month> <year> 1996. </year> <note> http://vismod.www.media.mit.edu/vismod/demos/kidsroom. </note>
Reference-contexts: The children embark upon an interactive adventure, while being instructed and observed by the room. We have constructed such an imagination space, called the KidsRoom, where a computer system tracks and analyzes the actions and interactions of people and objects <ref> [5] </ref>. Figure 1-a shows the experimental setup of the KidsRoom viewed from the stationary color camera used for tracking objects. Here four people are in the scene. <p> The algorithm can reliably maintain the number of objects in the space as objects enter and exit, and it can be tuned so that it almost never "loses" an object, even though it may swap two object labels (as tested extensively on children in the KidsRoom <ref> [5] </ref> system). Not surprisingly, our algorithm generally performs better when the objects being tracked have distinctive color features, like colored ponchos. <p> The tracking system has been used for the KidsRoom <ref> [5] </ref>, an interactive, narrative children's playspace, and could prove useful for other overhead tracking domains like observation of city street intersections, sporting events, pedestrian malls and parking lots.
Reference: [6] <author> D.D. Fu, K.J. Hammond, and M.J. Swain. </author> <title> Vision and navigation in man-made environments: looking for syrup in all the right places. </title> <booktitle> In Proc. Work. Visual Behaviors, </booktitle> <pages> pages 20-26, </pages> <address> Seattle, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Systems that have used non-geometric context in dynamic situations include Fu's shopper system <ref> [6] </ref>, Prokopowicz' active vision tracker [13], and Rosin's context-based tracking and recognition surveillance system [15].
Reference: [7] <author> G.D. Hager and K. Toyama. </author> <title> The XVision system: A general-purpose substrate for portable real-time vision applications. Comp. Vis., Graph., </title> <booktitle> and Img. Proc., </booktitle> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: The goal of this paper is to detail generic problems and solutions that are in any similarly complex tracking tasks. 2 Previous approaches Most real-time tracking systems that track non-rigid objects have been designed for scenes containing single, large objects such as a person [17], hand [3] or face <ref> [7] </ref> and have not been tested in domains where independent, multiple objects can interact. Adaptive correlation template tracking methods (e.g. energy-based deformable models [3]) typically assume each template varies slowly or smoothly, templates don't collide, and high-resolution support from the data is available.
Reference: [8] <author> D.P. Huttenlocher, J.J. Noh, and W.J. Rucklidge. </author> <title> Tracking non-rigid objects in complex scenes. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <pages> pages 93-101, </pages> <address> Berlin, Ger-many, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Further the difficulty in segmenting colliding children and their rapid changes in appearance and motion prevents the use of differential motion estimators that use smooth or planar motion models [4] and tracking techniques that require reasonably stable edge computation <ref> [8] </ref>. Motion difference blob size and shape characteristics are sometimes used for tracking [15]; here we use background-differenced blobs. However, since children are small and their difference blobs merge frequently, there is usually no single feature for an object that remains trackable for more than a few seconds.
Reference: [9] <author> S.S. Intille and A.F. Bobick. </author> <title> Closed-world tracking. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <pages> pages 672-678, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Systems that have used non-geometric context in dynamic situations include Fu's shopper system [6], Prokopowicz' active vision tracker [13], and Rosin's context-based tracking and recognition surveillance system [15]. Here we modify a tracking approach that uses context-sensitive correlation templates for tracking non-rigid objects <ref> [9] </ref> for a real-time application. 3 Closed-worlds Strat [16] has demonstrated that context-dependent visual routines are powerful tools for image understanding in complex static domains. Context is one way of addressing the knowledge-selection problem in (a) (b) by the real-time tracking algorithm. <p> We consider the context of a tracking problem to be a boundary in the space of knowledge | a boundary outside of which knowledge is not helpful in solving the tracking problem <ref> [9] </ref>. <p> For robust tracking in a complex scene, a tracker should understand the context of the current situation well enough to know which visual features of an object can be tracked from frame to frame and which features cannot. Based on these observations, a technique is described in <ref> [9] </ref> called closed-world tracking. In that off-line implementation, adaptive correlation templates are used to track small, non-rigid, colliding objects | players on a football field. <p> The closed-world assumption is also used to determine the order in which different matching situations should be considered. 1 The details of our real-time closed-world tracking algorithm differ from those described in <ref> [9] </ref> because of the limitations introduced by real-time requirements and differences in the imaging environment. However, the nature of the two tracking systems is similar. <p> This information is used for matching each object in the last frame to a blob in the new frame. (2) Image blobs are computed in each frame using background differencing; each blob's size, color, and position is recorded. (3) A local closed-world data structure exists for every blob, as in <ref> [9] </ref>, and stores which objects are assigned to the blob and how long they have been there. Two objects that are touching or nearly touching will appear as one blob; therefore, they should be assigned to the same closed-world. <p> An off-line or future system, however, could augment this information with histogram-based color algorithms and/or image templates as used in <ref> [9] </ref>. shadow pixels are a small percentage of blob pixels, (2) blob color is re-estimated as often as possible, and (3) the color is normalized for brightness. <p> A solution when more processing power is available may be to use other features that can be computed independently from the blob regions, such as correlation templates, and to partition merged blobs where possible (see <ref> [9] </ref>). A second, related architectural limitation is that the algorithm has no mechanism for handling slow variation of image features while objects are merged in a large closed-world. The algorithm is designed to adapt each frame to slowly varying matching features.
Reference: [10] <author> J. Mundy. </author> <title> Draft document on MORSE. </title> <type> Technical report, </type> <institution> General Electric Company Research and Development Center, </institution> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: Visual routines for tracking can be selected differently based on knowledge of which other objects are in the closed-world. Closed-worlds circumscribe the knowledge relevant to tracking at a given instant and therefore reduce the complexity of the tracking problem. Nagel [11] and Mundy <ref> [10] </ref> have both suggested that closed-world information is useful for building systems that extract conceptual descriptions from images and image sequences. <p> Due to the difficulty of modeling rapidly moving people (particularly small children), background-difference blobs are used as the primary visual representation. The background is removed from each frame using a YUV-based background subtraction 1 Mundy <ref> [10] </ref> has suggested that given a closed-world a system should assume a simple explanation first and then if that explanation is not consistent with the data consider more complicated explanations. method similar to the method described in [17], which uses color but not intensity intensity information.
Reference: [11] <author> H.-H. Nagel. </author> <title> From image sequences towards concep tual descriptions. </title> <journal> Image and Vision Comp., </journal> <volume> 6(2) </volume> <pages> 59-74, </pages> <year> 1988. </year>
Reference-contexts: Visual routines for tracking can be selected differently based on knowledge of which other objects are in the closed-world. Closed-worlds circumscribe the knowledge relevant to tracking at a given instant and therefore reduce the complexity of the tracking problem. Nagel <ref> [11] </ref> and Mundy [10] have both suggested that closed-world information is useful for building systems that extract conceptual descriptions from images and image sequences.
Reference: [12] <author> R. Polana and R. Nelson. </author> <title> Low level recognition of human motion. </title> <booktitle> In Proc. Work. Non-Rigid Motion, </booktitle> <pages> pages 77-82, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: As we will discuss, we have found it is often difficult to separate the tracking from the boundary estimation problem. Therefore, some people-tracking methods that require accurate object boundary detection based on intensity [2] and optical flow <ref> [12] </ref> are difficult to apply in our tracking task. Further the difficulty in segmenting colliding children and their rapid changes in appearance and motion prevents the use of differential motion estimators that use smooth or planar motion models [4] and tracking techniques that require reasonably stable edge computation [8].
Reference: [13] <author> P.N. Prokopowicz, M.J. Swain, and R.E. Kahn. </author> <title> Task and environment-sensitive tracking. </title> <booktitle> In Proc. Work. Visual Behaviors, </booktitle> <pages> pages 73-78, </pages> <address> Seattle, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Systems that have used non-geometric context in dynamic situations include Fu's shopper system [6], Prokopowicz' active vision tracker <ref> [13] </ref>, and Rosin's context-based tracking and recognition surveillance system [15]. Here we modify a tracking approach that uses context-sensitive correlation templates for tracking non-rigid objects [9] for a real-time application. 3 Closed-worlds Strat [16] has demonstrated that context-dependent visual routines are powerful tools for image understanding in complex static domains.
Reference: [14] <author> K. Rangarajan and M. Shah. </author> <title> Establishing motion correspondence. Comp. Vis., Graph., </title> <journal> and Img. Proc., </journal> <volume> 54 </volume> <pages> 56-73, </pages> <year> 1991. </year>
Reference-contexts: The best match for X is actually B2 because it keeps the distance between Y and it's best match, B1 low while still providing a good match for X. Rangarajan and Shah <ref> [14] </ref> have described a non-iterative greedy algorithm that, given a score matrix with m objects, can be used to make object-to blob matches in O (m 2 ). 4 The algorithm will find a near-optimal pairing of all objects, avoiding individual assignments that are bad while trying to keep each 4 <p> Even if objects merge and don't travel, one object can move limbs and change significantly in size and corrupt subsequent matching. The third architectural issue is match evaluation. The algorithm uses the Rangarajan and Shah greedy correspondence algorithm <ref> [14] </ref> to avoid bad global matches when making individual matches, but this strategy leads to some bad matches (e.g. most of the pass-by errors).
Reference: [15] <author> P.L. Rosin and T. Ellis. </author> <title> Detecting and classifying intruders in image sequences. </title> <booktitle> In Proc. British Mach. Vis. Conf., </booktitle> <pages> pages 24-26, </pages> <month> Sep. </month> <year> 1991. </year>
Reference-contexts: Motion difference blob size and shape characteristics are sometimes used for tracking <ref> [15] </ref>; here we use background-differenced blobs. However, since children are small and their difference blobs merge frequently, there is usually no single feature for an object that remains trackable for more than a few seconds. <p> Systems that have used non-geometric context in dynamic situations include Fu's shopper system [6], Prokopowicz' active vision tracker [13], and Rosin's context-based tracking and recognition surveillance system <ref> [15] </ref>. Here we modify a tracking approach that uses context-sensitive correlation templates for tracking non-rigid objects [9] for a real-time application. 3 Closed-worlds Strat [16] has demonstrated that context-dependent visual routines are powerful tools for image understanding in complex static domains.
Reference: [16] <author> T.M. Strat and M.A. Fischler. </author> <title> Context-based vision: recognizing objects using information from both 2D and 3D imagery. </title> <journal> IEEE Trans. Patt. Analy. and Mach. Intell., </journal> <volume> 13(10) </volume> <pages> 1050-1065, </pages> <year> 1991. </year>
Reference-contexts: Here we modify a tracking approach that uses context-sensitive correlation templates for tracking non-rigid objects [9] for a real-time application. 3 Closed-worlds Strat <ref> [16] </ref> has demonstrated that context-dependent visual routines are powerful tools for image understanding in complex static domains. Context is one way of addressing the knowledge-selection problem in (a) (b) by the real-time tracking algorithm.
Reference: [17] <author> C. Wren, A. Azarbayejani, T. Darrell, and A. Pent-land. Pfinder: </author> <title> real-time tracking of the human body. </title> <booktitle> In Proc. of the SPIE Conf. on Integration Issues in Large Commercial Media Delivery Sys., </booktitle> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: The goal of this paper is to detail generic problems and solutions that are in any similarly complex tracking tasks. 2 Previous approaches Most real-time tracking systems that track non-rigid objects have been designed for scenes containing single, large objects such as a person <ref> [17] </ref>, hand [3] or face [7] and have not been tested in domains where independent, multiple objects can interact. Adaptive correlation template tracking methods (e.g. energy-based deformable models [3]) typically assume each template varies slowly or smoothly, templates don't collide, and high-resolution support from the data is available. <p> background is removed from each frame using a YUV-based background subtraction 1 Mundy [10] has suggested that given a closed-world a system should assume a simple explanation first and then if that explanation is not consistent with the data consider more complicated explanations. method similar to the method described in <ref> [17] </ref>, which uses color but not intensity intensity information. This method correctly removes most shadowed regions. In practice the resulting thresholded blob images are noisy due to camera noise or objects that are broken apart because they have regions colored like the background.
References-found: 17

