URL: http://www.neci.nj.nec.com/homepages/mic/ps/glem.ps.gz
Refering-URL: http://www.neci.nj.nec.com/homepages/mic/publications.html
Root-URL: http://www.neci.nj.nec.com
Title: From Simple Features to Sophisticated Evaluation Functions  
Author: Michael Buro 
Keyword: automatic feature construction, GLEM, Othello  
Address: 4 Independence Way Princeton NJ 08540, USA  
Affiliation: NEC Research Institute  
Abstract: This paper discusses a practical framework for the semiautomatic construction of evaluation functions for games. Based on a structured evaluation function representation, a procedure for exploring the feature space is presented that is able to discover new features in a computational feasible way. Besides the theoretical aspects, related practical issues such as the generation of training positions, feature selection, and weight fitting in large linear systems are discussed. Finally, we present experimental results for Othello, which demonstrate the potential of the described approach. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> M. Buro. </author> <title> Experiments with Multi-Probcut and a new high-quality evaluation function for Othello. Workshop on Game-Tree Search, </title> <institution> NEC Research Institute, </institution> <year> 1997. </year>
Reference-contexts: This goal can be accomplished literally by constructing functions that map positions into <ref> [0; 1] </ref>. Alternatively, the game may provide a numerical scoring of terminal positions reflecting the win size. In this case, a reasonable evaluation objective is to estimate the final game score. In either case, experiments should be conducted to find a suitable link function g. <p> In either case, experiments should be conducted to find a suitable link function g. The most commonly used candidates are the identity function and sigmoid functions of the form g (x) = 2C=(1+exp (x))C. For instance, for modeling the winning chance an S-shaped link function g : IR ! <ref> [0; 1] </ref> can be used in order to deal with saturation. In this regard, g (x) = 1=(1 + exp (x)) is of special interest, because the weight fitting process benefits from a quickly computable derivative of g, which in this case is g (x)(1 g (x)). <p> Logistello is able to beat the best human Othello players handily, even when running only on ordinary hardware [2]. The details of Logistello's evaluation function already have been discussed in <ref> [1] </ref>. We will therefore only give a short overview and concentrate on its recent improvement, which is based on the sparse pattern approach presented above. Othello is a popular Japanese board game, played by two players on an 8x8-board using 64 two-colored discs. <p> Making the last move in an Othello game is advantageous, since it increases one's own disc count while decreasing the number of opponent's discs. Parity generalizes this observation by considering last move opportunities for every empty board region. In <ref> [1] </ref> it has been shown, that all of these features can be quickly approximated by pattern configurations built upon a raw board representation. The chosen patterns are shown in Fig. 7. Horizontal, vertical, and diagonal lines of length 4 are included for covering mobility. <p> An interesting fact is that the game knowledge encoded by the set of over a million configuration weights goes far beyond the features we intended the system to approximate in the first place <ref> [1] </ref>. This result encourages the application of GLEM to other games or even to search or decision problems in other domains. Attractive candidates are chess and Go since both games are very popular and well analyzed.
Reference: 2. <author> M. Buro. </author> <title> The Othello match of the year: Takeshi Murakami vs. </title> <journal> Logistello. ICCA Journal, </journal> <volume> 20(3) </volume> <pages> 189-193, </pages> <year> 1997. </year>
Reference-contexts: Besides the progress in selective search and automated opening book construction, the application of the techniques discussed has contributed to the considerable playing strength of this program. Logistello is able to beat the best human Othello players handily, even when running only on ordinary hardware <ref> [2] </ref>. The details of Logistello's evaluation function already have been discussed in [1]. We will therefore only give a short overview and concentrate on its recent improvement, which is based on the sparse pattern approach presented above. <p> Equipped with an evaluation function very similar to that we have just described, Logistello beat the human Othello World-champion 6-0 in August 1997 <ref> [2] </ref>. After four years of successful tournament play, Logistello ended its career in October 1997 with a straight 22-win victory in its last computer Othello tournament. Recently, the incorporation of larger patterns has improved the evaluation performance. In the current implementation, configuration weights are represented as 16 bit integers.
Reference: 3. <author> S.J. Hanson. </author> <title> Meiosis networks. </title> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <pages> pages 553-541, </pages> <year> 1990. </year>
Reference-contexts: Other approaches for constructing features or adapting the combination function while fitting weights (e.g. Morph [5], meiosis networks <ref> [3] </ref>, node splitting [11]), face similar complexity problems. Our solution is to separate these tasks in order to speed-up the process and to give many opportunities for optimization.
Reference: 4. <author> F. Hsu, S. Anantharaman, M.S. Campbell, and A. Nowatzyk. </author> <title> Deep Thought. In T.A. </title> <editor> Marsland and J. Schaeffer, editors, </editor> <booktitle> Computer, Chess, and Cognition, </booktitle> <pages> pages 55-78. </pages> <publisher> Springer Verlag, </publisher> <year> 1990. </year>
Reference-contexts: While selecting features is difficult for a machine, fitting even a large number of weights given a set of training positions is not. Research focused on the latter topic produced TD-Gammon, a world-class backgammon-program [8, 9], and contributed to Deep Blue's victory over Kasparov in 1997 <ref> [4] </ref>. In this article we go a step further towards the ultimate goal of automatic evaluation function construction. First, a generalized linear evaluation model is presented. It restricts evaluation features to boolean combinations of given atomic functions.
Reference: 5. <author> R.A. Levinson and R. Snyder. </author> <title> Adaptive pattern-oriented chess. </title> <editor> In L. Birnbaum and G. Collins, editors, </editor> <booktitle> Proceedings of the 8th International Workshop on Machine Learning, </booktitle> <pages> pages 85-89, </pages> <year> 1991. </year> <title> 5 Deep Blue searched around 200 million nodes per second in the 1997 match with Kasparov. Assuming a speed-up of four gained by using special purpose evaluation hardware and a speed of 200K nodes/sec of a state-of-the-art PC chess program leads to the given speed factor estimate. </title>
Reference-contexts: Taking into account the large number of features needed for an adequate evaluation in complex domains, and the resulting considerable effort for optimizing weights, it seems hopeless to combine feature construction and weight fitting. Other approaches for constructing features or adapting the combination function while fitting weights (e.g. Morph <ref> [5] </ref>, meiosis networks [3], node splitting [11]), face similar complexity problems. Our solution is to separate these tasks in order to speed-up the process and to give many opportunities for optimization.
Reference: 6. <author> W.H. Press, S.A. Teukolsky, W.T. Vetterling, and B.P. Flannery. </author> <title> Numerical Recipes, 2nd edition. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: In each step, this procedure updates the current weight vector in direction of the negated gradient of the error function. If features are highly correlated, this simple algorithm is known to converge slowly. Faster conjugate gradient algorithms have been developed <ref> [6] </ref>, that do not suffer from this problem.
Reference: 7. <author> A.L. Samuel. </author> <title> Some studies in machine learning using the game of checkers. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 3(3) </volume> <pages> 211-229, </pages> <year> 1959. </year>
Reference-contexts: A couple of years ago, the authors of the best game playing programs still picked not only features but also their weights in course of a tedious optimization process. This is somewhat surprising, since already in <ref> [7] </ref> Samuel proposed ways for automatically tuning weights. While selecting features is difficult for a machine, fitting even a large number of weights given a set of training positions is not.
Reference: 8. <author> G. Tesauro. </author> <title> TD-Gammon, a self-teaching backgammon program, reaches master-level play. </title> <journal> Neural Computation, </journal> <volume> 6(2) </volume> <pages> 215-219, </pages> <year> 1994. </year>
Reference-contexts: This is somewhat surprising, since already in [7] Samuel proposed ways for automatically tuning weights. While selecting features is difficult for a machine, fitting even a large number of weights given a set of training positions is not. Research focused on the latter topic produced TD-Gammon, a world-class backgammon-program <ref> [8, 9] </ref>, and contributed to Deep Blue's victory over Kasparov in 1997 [4]. In this article we go a step further towards the ultimate goal of automatic evaluation function construction. First, a generalized linear evaluation model is presented. It restricts evaluation features to boolean combinations of given atomic functions.
Reference: 9. <author> G. Tesauro. </author> <title> Temporal difference learning and TD-Gammon. </title> <journal> Communications of the ACM, </journal> <volume> 38(3) </volume> <pages> 58-68, </pages> <year> 1995. </year>
Reference-contexts: This is somewhat surprising, since already in [7] Samuel proposed ways for automatically tuning weights. While selecting features is difficult for a machine, fitting even a large number of weights given a set of training positions is not. Research focused on the latter topic produced TD-Gammon, a world-class backgammon-program <ref> [8, 9] </ref>, and contributed to Deep Blue's victory over Kasparov in 1997 [4]. In this article we go a step further towards the ultimate goal of automatic evaluation function construction. First, a generalized linear evaluation model is presented. It restricts evaluation features to boolean combinations of given atomic functions.
Reference: 10. <author> P.E. Utgoff. </author> <title> Constructive function approximation. </title> <type> Technical Report 97-4, </type> <institution> Univ. of Mass., </institution> <year> 1997. </year>
Reference-contexts: A starting point is the analysis of known features with regard to their approximation by weighted configurations as proposed by GLEM. The automatic construction of features has been studied by several authors. Utgoff <ref> [10] </ref> proposes a general evaluation function learner, called ELF, which combines the processes of constructing boolean feature combinations and weight fitting. This approach has been shown to be effective in small artificial problems, but could not convince in its application to checkers.
Reference: 11. <author> M. Wynne-Jones. </author> <title> Node splitting: A constructive algorithm for feed-forward neural networks. </title> <journal> Neural Computing and Applications, </journal> <volume> 1(1) </volume> <pages> 17-22, </pages> <year> 1993. </year>
Reference-contexts: Other approaches for constructing features or adapting the combination function while fitting weights (e.g. Morph [5], meiosis networks [3], node splitting <ref> [11] </ref>), face similar complexity problems. Our solution is to separate these tasks in order to speed-up the process and to give many opportunities for optimization.
References-found: 11

